{"title": "PDF", "author": "PDF", "url": "http://www.dvs.tu-darmstadt.de/publications/MScs/czarny2012msc.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "id": "PDF", "license": "PDF", "body": "PDF", "comments": "PDF", "commentsbody": "PDF", "raw_text": "PDF", "text": "Entwicklung einer Game AI zur\nrealistischen Lasterzeugung in\nverteilten Massively Multiplayer\nOnline Games\nDamian A. Czarny, B. Sc.\nGutachter: Prof. Alejandro Buchmann1, Ph.D.\nBetreuer: Max Lehn1, M. Sc. und Tonio Triebel2, Dipl.-Inform.\n1Databases and Distributed Systems, Technische Universit\u00e4t Darmstadt\n2Department of Computer Science IV, University of Mannheim\nMaster-Thesis\nEingereicht am 30. September 2012\nEntwicklung einer Game AI zur realistischen Lasterzeugung in verteilten Massively Multiplayer\nOnline Games\nMaster-Thesis\nEingereicht von Damian A. Czarny, B. Sc.\nTag der Einreichung: 30. September 2012\nGutachter: Prof. Alejandro Buchmann1, Ph.D.\nBetreuer: Max Lehn1, M. Sc. und Tonio Triebel2, Dipl.-Inform.\n1Databases and Distributed Systems, Technische Universit\u00e4t Darmstadt\n2Department of Computer Science IV, University of Mannheim\nTechnische Universit\u00e4t Darmstadt\nFachbereich Informatik\nFachgebiet Databases and Distributed Systems (DVS)\nProf. Alejandro BuchmannEhrenw\u00f6rtliche Erkl\u00e4rung\nHiermit versichere ich, die vorliegende Master-Thesis ohne Hilfe Dritter und nur mit den angegebenen\nQuellen und Hilfsmitteln angefertigt zu haben. Alle Stellen, die aus den Quellen entnommen wurden,\nsind als solche kenntlich gemacht worden. Diese Arbeit hat in dieser oder \u00e4hnlicher Form noch keiner\nPr\u00fcfungsbeh\u00f6rde vorgelegen. Die elektronische Fassung der Arbeit stimmt mit der gedruckten \u00fcberein.\nDarmstadt, den 30. September 2012\nDamian A. Czarny, B. Sc.\niZusammenfassung\nPeer-to-Peer -Architekturen bieten aufgrund ihrer verteilten Natur viele Vorteile gegen\u00fcber zentral orga-\nnisierten Architekturen, wie beispielsweise klassischen Client/Server-Systemen. Die Vorteile die Peer-to-\nPeer-Architekturen bieten gehen allerdings mit einer erh\u00f6hten Komplexit\u00e4t des Systems und vielen neuen\nHerausforderungen bez\u00fcglich der Netzwerkkommunikation einher. Um eine Vergleichbarkeit verschiede-\nner P2P-Implementierungen zu erm\u00f6glichen, wird am Informatik Fachgebiet Databases and Distributed\nSystems (DVS) der Technischen Universit\u00e4t Darmstadt an einer Benchmarking-Methodik mitgearbeitet\ndie diese erm\u00f6glichen soll. Dazu wurde eine Evaluationsplattform entwickelt, die mit dem P2P-MMOG\nPlanet PI4 ein Benchmarking von P2P-Gaming-Overlays erm\u00f6glicht. Ein wesentlicher Bestandteil der\nBenchmarking-Methodik ist die synthetische Generierung einer realistischen Netzwerklast. Planet PI4\nsoll u.a. dazu eingesetzt werden diese Netzwerklast f\u00fcr P2P-Gaming-Overlays zu erzeugen. Ziel dieser\nMaster-Thesis ist die konkrete Erzeugung der Netzwerklast von Planet PI4 mit dem Ansatz kontext-\nsensitiver AI-Spieler, die stellvertretend f\u00fcr Menschen das Spiel spielen.\nDas Resultat dieser Arbeit ist die Entwicklung und Implementierung einer Game AI f\u00fcrPlanet PI4 , die\neine Aufteilung der Verantwortlichkeiten in drei hierarchisch angeordneten Ebenen vornimmt. Die der-\nart entwickelte Architektur erm\u00f6glicht die zeitlich entkoppelte Ausf\u00fchrung der Komponenten auf den\nunterschiedlichen Ebenen. Weiterhin erm\u00f6glicht sie den Austausch bestimmter Komponenten oder der\nEbenen-Implementierung ohne damit gleich das ganze System zu beein\ufb02ussen. Diese Eigenschaft und\ndie fein-granulare Abkapselung einzelner Aufgabenbereiche innerhalb der Ebenen beg\u00fcnstigen die er-\nforderliche einfache und gezielte Weiterentwicklung der Game AI .\nDie drei wichtigstens Komponenten der Game AI sind das Decision Making mittels Behavior Trees zur\nAktionsbestimmung, sowie die Steering Pipeline und das Combat System zur Kombinierung, Bereitstel-\nlung und Ausf\u00fchrung nicht-primitiver Verhaltensweisen. Die Verhaltensweisen der beiden Komponenten\nwerden dabei der Decision Making -Komponente als Aktionsmenge bereitgestellt und erm\u00f6glichen dieser\nsomit die indirekte Steuerung der Spiel\ufb01gur in Planet PI4 .\nZur Evaluation des eigenen Ansatzes wurden 13 Metriken zur Messung von Verhalten und Performan-\nce in neun unterschiedlichen Testszenarien eingesetzt. Die Testszenarien erfolgten dabei unter Einsatz\ndesDiscrete Event Game Simulators , der ebenfalls Teil der Evaluationsplattform von Planet PI4 ist und\nf\u00fcr die Reproduzierbarkeit der erzeugten Last und somit auch der Evaluationsergebnisse der Master-\nThesis sorgt. Zusammenfassend lassen die Evaluationsergebnisse auf die generelle Eignung der Game\nAI-Implementierung zur Generierung der erforderlichen Netzwerklast schlie\u00dfen. Zur Beurteilung der\nErgebnisse diente auch der Vergleich zur Vorg\u00e4nger-Implementierung, welcher ergab, dass die Game\nAI-Implementierung in vielen Bereichen, wie Reproduzierbarkeit, Kon\ufb01gurierbarkeit und Realit\u00e4tsgrad,\nbessere Ergebnisse erzielt als die Vorg\u00e4nger-Implementierung, sich allerdings in Sachen genereller Spiel-\nst\u00e4rke und Performance dieser knapp geschlagen geben muss.\niiiiv ZusammenfassungInhaltsverzeichnis\n1 Einleitung 1\n1.1 Problemstellung und -beschreibung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n1.2 Zielde\ufb01nition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\n1.3 Themeneingrenzung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n1.4 Aufbau der Arbeit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2 Grundlagen 9\n2.1 Was ist ein Computerspiel? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9\n2.2 Academic AI vs. Game AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.3 Der Entwurf eines Rationalen Agenten . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\n2.4 Steering Behaviors und das Agentenmodell nach Reynolds . . . . . . . . . . . . . . . . . . . . 15\n3 Verwandte Ans\u00e4tze 17\n3.1 Methoden zur Lasterzeugung in Spielen . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3.2 Halo\u2019s AI-Architektur . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n3.3 GOAP - Goal-Oriented Action Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.4 Verfahren zur Kombinierung von Steering Behaviors . . . . . . . . . . . . . . . . . . . . . . . . 27\n3.5 Vorg\u00e4nger-Implementierung: DragonBot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\n4 Konzept und Rahmenbedingungen der Game AI 33\n4.1 Einsatzumgebung Planet PI4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n4.2 Funktionale Anforderungen der Game AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35\n4.3 Konzept der Game AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\n4.4 Behavior Tree . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n5 Design und Implementierungsdetails der Game AI 41\n5.1 Einbindung der Game AI in Planet PI4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n5.2 Game AI-Architektur . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n5.3 Operative Ebene . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\n5.3.1 Steering Pipeline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n5.3.2 Combat System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\n5.4 Taktische Ebene . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\n5.4.1 Blackboard Architektur . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57\n5.4.2 Behavior Tree Implementierung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\n5.4.3 Behavior Tags und Personality Selection . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\n5.4.4 Der Behavior Tree der Game AI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67\n5.5 Strategische Ebene . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n5.5.1 Kon\ufb01gurationsm\u00f6glichkeiten . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n5.5.2 Region Map und die strategische Zielbestimmung . . . . . . . . . . . . . . . . . . . . . 72\n6 Evaluation 75\n6.1 Ziele und Rahmenbedingungen . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n6.2 Eingesetzte Metriken . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n6.3 Allgemeiner Aufbau und Ablauf der Testszenarien . . . . . . . . . . . . . . . . . . . . . . . . . 78\n6.4 Durchgef\u00fchrte Testszenarien . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79\nv6.4.1 1. Testszenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n6.4.2 2. Testszenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\n6.4.3 3. Testszenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n6.4.4 4. Testszenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84\n6.4.5 5. Testszenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\n6.4.6 6. Testszenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\n6.4.7 7. Testszenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n6.4.8 8. Testszenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\n6.4.9 9. Testszenario . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91\n6.5 Auswertung der Ergebnisse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n7 Ausblick und Fazit 97\n7.1 Ausblick . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97\n7.2 Fazit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\nAbbildungsverzeichnis 101\nTabellenverzeichnis 103\nLiteraturverzeichnis 105\nvi Inhaltsverzeichnis1 Einleitung\nMan stelle sich folgendes \ufb01ktives Szenario vor: Es soll ein neues Massively Multiplayer Online Game\n(MMOG) entwickelt werden.\nDer Begriff MMOG bezeichnet dabei die Art von Spielen, welche darauf ausgelegt sind, einer gro\u00dfen\nAnzahl an Spielern ( massively ) ein simultan ablaufendes gemeinsames Spielen ( multiplayer ) \u00fcber das\nInternet zu erm\u00f6glichen ( online ). Hierf\u00fcr wird den Spielern eine gemeinsame virtuelle, in vielen F\u00e4llen\nauch persistente Spielwelt bereitgestellt, in jener der Spieler dazu angehalten wird, sein Voranschreiten\nim Spiel mittels kooperativer oder kompetitiver Verhaltensweisen, die wiederum jeweils kleinere oder\ngr\u00f6\u00dfere Untermengen anderer Spieler miteinschlie\u00dfen k\u00f6nnen, zu erzielen. Dieses allgemeine Konzept\neines MMOGs l\u00e4sst sich dabei auf ein breites Spektrum unterschiedlichster Spielkonzepte und somit quer\n\u00fcber eine Vielzahl von Computerspiel-(Sub)Genres anwenden. Beispiele hierf\u00fcr w\u00e4ren das First-Person\nShooter (FPS), das RealTimeStrategy (RTS) oder das Role-Playing Game(RPG) Genre.\nMan stelle sich folgende Erweiterung f\u00fcr das Szenario vor: Das MMOG soll als dem Spiel zugrundeliegendes\nNetzwerk-Overlay eine Peer-to-Peer-Architektur verwenden.\nDie Verwendung einer P2P-Architektur hat den Vorteil, dass die System-inh\u00e4rente Eigenschaft der de-\nzentralen und somit verteilten Natur ausgenutzt werden kann, um ganz im Sinne eines MMOGs, einer\nm\u00f6glichst gro\u00dfen Anzahl an Spielern ein gemeinsames spielen \u00fcber das Netzwerk zu erm\u00f6glichen. Eine\nAlternative zu dezentralen Architekturen stellen dabei zentral verteilte Architekturen dar. Als klassisches\nBeispiel w\u00e4ren an dieser Stelle Client/Server-Systeme zu nennen, welche ebenfalls die zurzeit am h\u00e4u-\n\ufb01gsten eingesetzte Netzwerkarchitektur in MMOGs darstellt.\nUnter einem Client/Server-System versteht man, wie der Name bereits andeutet, eine generelle Zwei-\nteilung in Dienstanbieter (Server) und Dienstempf\u00e4nger (Client). In einem P2P-System hingegen sind\nalle Peers gleich, sie fungieren gleichzeitig als Client und als Server. Prinzipiell ist ein solches Verhalten\nauch in Client/Server-Systemen m\u00f6glich, doch haben diese allgemein gemein, dass sie Funktionen lo-\ngisch und physisch \u00fcber mehrere Computer hinweg aufteilen, wobei jeder Rechner auf eine bestimmte\nGruppe von Funktionen zugeschnitten ist. Diese Art der Verteilung wird in der Fachliteratur als \u201evertikale\nVerteilung\u201c bezeichnet.\nZwar existieren verschiedene Client/Server-Anordnungen, die de\ufb01nieren, welche Funktionen jeweils\nzum Client oder zum Server geh\u00f6ren, jedoch ist es vor allem in MMOGs \u00fcblich, dass der Server gro\u00dfe Tei-\nle der Funktionalit\u00e4t eines Spiels beherbergt - einen sogenannten fat Server darstellt. Die Aufgaben eines\nsolchen Servers w\u00e4ren dabei z.B. die \u00dcberpr\u00fcfung und Berechnung der Auswirkungen der gew\u00fcnsch-\nten Spielerinteraktionen auf die Spielwelt, sowie die Synchronisierung der einzelnen Spielersichten der\nSpielwelt untereinander. Logischerweise bleibt in so einem Fall nicht mehr viel Funktionalit\u00e4t f\u00fcr den\nClient \u00fcbrig, sodass der Client des Spielers meistens aus nicht viel mehr besteht als einer graphischen\nSchnittstelle zum Server - ein sogenannter thin Client .\nDie Funktionalit\u00e4tsf\u00fclle und der Aspekt, dass der Server als direkte zentrale Anlaufstelle f\u00fcr alle an-\nderen Clients dient, lassen bereits erahnen, welch immense Anforderungen und damit auch Kosten auf\nServerseite anfallen k\u00f6nnen. Man stelle sich beispielsweise die erzeugte Last eines World of Warcraft\nvor, wo mehrere hundert tausend Spieler gleichzeitig1versuchen in derselben Spielwelt zu spielen. Laut\n1Zwar k\u00f6nnen alle Spieler gleichzeitig spielen, jedoch existieren Partionierungstechniken, wie Leveling oder Sharding , die\ndie tats\u00e4chlich gleichzeitig zusammenspielende Menge an Spielern in ein und derselben partiellen Spielwelt reduzieren\nund beschr\u00e4nken [56].\n1einem Bericht von Vivendi war 2006 zur Bew\u00e4ltigung dieser Last eine Serverfarm f\u00fcr World of Warcraft\nim Einsatz, die stellenweise aus mehr als 1.900 parallel laufenden Servern bestand [43].\nIn P2P-Systemen erfolgt w\u00e4hrenddessen eine sogenannte \"horizontale Verteilung\". Bei dieser Art der\nVerteilung k\u00f6nnen Client oder Server physisch in logisch gleichwertige Teile unterteilt werden. Vorteil\ndieser Einteilung ist, dass die Gesamtlast des Systems verteilt werden kann, indem jeder dieser gleich-\nwertigen Teile nur auf einem eigenen Ausschnitt der vollst\u00e4ndigen Datenmenge arbeitet. Werden weitere\nDaten aus anderen Ausschnitten ben\u00f6tigt, werden die daf\u00fcr zust\u00e4ndigen Teile erfragt und die Daten ent-\nsprechend angefordert [54, S. 55-67]. Die derart realisierte, in weiten Teilen, gleichm\u00e4\u00dfige Verteilung\nder Last auf alle Clients, erm\u00f6glicht eine starke Reduktion der Serverlast, da diese nicht mehr den Gro\u00df-\nteil der Arbeit alleine \u00fcbernehmen muss.\nZusammenfassend k\u00f6nnte zumindest in der Theorie die Verwendung von P2P-Technologien dazu bei-\ntragen, ein Spiel mit den enormen Spielerzahlen eines World of Warcrafts zu deutlich geringeren lau-\nfenden (Server-)Kosten betreiben zu k\u00f6nnen. Warum dies nicht bereits l\u00e4ngst getan wird, ist dem Um-\nstand geschuldet, dass besonders die verteilte Systemeigenschaft, die eigentlich zur Reduktion der Last\ndient, die Spielentwicklung vor eine Menge neuer Herausforderungen stellt, die bei der Entwicklung\nvon zentral organisierter Software nicht oder nur in abgeschw\u00e4chter Form auftreten. Als eine der dabei\ngr\u00f6\u00dften Herausforderungen erweist sich das L\u00f6sen des Problems des fehlenden gemeinsamen, globalen\nund synchronisierten Gesamtzustandes. Auf das Beispiel-Szenario \u00fcbertragen bedeutet dies, dass sich\ndie Bestandteile der Spiellogik des MMOGs \u00fcber eine skalierbare Vielzahl von Peers erstreckt, die sich\nauf unterschiedlichen und weit voneinander entfernten Rechnern be\ufb01nden k\u00f6nnen.\nMan stelle sich folgende Erweiterung f\u00fcr das Szenario vor: Das auf einer P2P-Architektur aufsetzende\nMMOG soll im Third Person Shooter-Genre angesiedelt sein und in einer 3D-Open World spielen.\nMit anderen Worten soll ein Spiel entwickelt werden, wo der Spieler das Spielgeschehen aus der\nSchulterperspektive seiner Spiel\ufb01gur wahrnimmt, mit dieser innerhalb einer frei erkundbaren, dreidi-\nmensionalen Spielwelt agiert und mit Schusswaffen andere Spieler oder computergesteuerte Gegner in\nEchtzeit bek\u00e4mpft. Aufgrund der Echtzeitbedingung bzw. der allgemein erh\u00f6hten Spielgeschwindigkeit\nund der Notwendigkeit einer m\u00f6glichst pr\u00e4zisen und unmittelbaren Steuerung, stellen MMOTPS eine\nbesondere Herausforderung an die Performance des Spiels dar und versch\u00e4rfen mit diesem Performance-\nAnspruch die eben vorgestellten Problembereiche verteilter Anwendungen nochmals.\nDie Performance-Herausforderung f\u00fcr verteilte Anwendungen ergibt sich hierbei in erster Line nicht\naus der Notwendigkeit der schnellen gra\ufb01schen Darstellung des Spiels, sondern \u00e4u\u00dfert sich in der er-\nh\u00f6hten Verz\u00f6gerungssensitivit\u00e4t der Netzwerkkommunikation. Diese Verz\u00f6gerungssensitivit\u00e4t bzw. die\ndaraus resultierende Anforderung einer geringen Latenz bei der Netzwerk-Kommunikation des Spiels,\nwobei die Latenz den Zeitraum zwischen einem verborgenen Ereignis und dem Eintreten einer sichtba-\nren Reaktion darauf bezeichnet, stellt die Netzwerkkomponente eines Spiels vor eine schwierige Aufgabe.\nW\u00e4hrend bei Video- oder Telefoniesoftware eine Netzwerk-Paketverz\u00f6gerung von unter 300 ms. ben\u00f6tigt\nwird, sind Onlinespiele bei einer Verz\u00f6gerung jenseits von 100 bis 150 ms. kaum mehr spielbar. Wobei\nleichte Verz\u00f6gerungen des Spielgeschehens, sogenannte Lags, in anderen Spielarten noch tolerierbar w\u00e4-\nren, kann in einem Shooter jede kleinste Verz\u00f6gerung bereits \u00fcber Sieg oder Niederlage entscheiden und\nsomit einen unmittelbaren negativen Ein\ufb02uss auf die Qualit\u00e4t der Spielerfahrung aus\u00fcben [7, S. 1].\nMan stelle sich folgende abschlie\u00dfende Erweiterung f\u00fcr das Szenario vor: Es soll eine bestehende\nP2P-Implementierung f\u00fcr das zu entwickelnde MMOTPS gefunden werden, welches den hohen\nPerformance-Anforderungen des Spiels gerecht wird.\nNachdem das zu entwickelnde Spiel feststeht, die Notwendigkeit einer leistungsstarken und skalier-\nbaren Netzwerkkomponente verdeutlicht wurde und eine P2P-Architektur als m\u00f6gliche L\u00f6sung hier-\n2 1 Einleitungf\u00fcr vorgestellt wurde, stellt sich nun die Frage, welche der zahlreichen P2P-Overlays, Architekturen\noder konkreten Implementierungen die Richtige f\u00fcr diesen Einsatzzweck ist? Eine Beantwortung die-\nser Frage gestaltet sich allerdings durchaus problematisch. Nicht nur das zahlreiche unterschiedliche\nP2P-Implementierungen existieren, so konzentrieren sich diese, aufgrund der gegen\u00fcber Client/Server-\nSystemen erh\u00f6hten Komplexit\u00e4t, meistens noch auf einige ausgew\u00e4hlte Aspekte, wie der fairen Auslas-\ntung der Peers (Incentive Mechanisms), die Verhinderung von Cheating-Versuchen (Cheating Mitigation)\noder den Informationsaustauschprozess zwischen den Peers (Game Event Dissemination) [14, 29].\nEin weiteres Problem, welches ma\u00dfgeblich den Auswahlprozess einer geeigneten P2P-Implementierung\nerschwert ist, dass die meisten Forschergruppen eigene, oft speziell auf ihr Projekt zugeschnittene, Evalu-\nierungstechniken einsetzen. So sieht man sich schnell unweigerlich mit einer F\u00fclle an unterschiedlichen\nMethoden, angewandten Metriken, verwendeten Kon\ufb01gurationen und eingesetzten Testumgebungen\nkonfrontiert. Dieser Variantenreichtum und die mangelnde Allgemeing\u00fcltigkeit der Evaluationsergeb-\nnisse erschweren die Vergleichbarkeit der P2P-Overlays untereinander entscheidend.\nAus diesem Grund wird am Informatik Fachgebiet Databases and Distributed Systems (DVS) der Tech-\nnischen Universit\u00e4t Darmstadt an einer Benchmarking-Methodik f\u00fcr Networked Virtual Environments\n(NVEs) mitgeforscht, die diese fehlende Vergleichbarkeit erm\u00f6glichen soll, indem es eine einheitli-\nche und objektive Analyse und Bewertung unterschiedlichster P2P-Overlays gew\u00e4hrleistet [29, 17].\nDie Benchmarking-Methodik ist ein wesentlicher Bestandteil der durch die Deutsche Forschungsge-\nmeinschaft (DFG) gef\u00f6rderten Forschergruppe QuaP2P - \"Verbesserung der Qualit\u00e4t von Peer-to-Peer-\nSystemen durch die systematische Erforschung von Qualit\u00e4tsmerkmalen und deren wechselseitigen Ab-\nh\u00e4ngigkeiten.\u201c [42].\nDie Benchmarking-Methodik von NVEs umfasst mit der De\ufb01nition eines einheitlichen Funktionalit\u00e4ts-\nInterfaces [17], der Identi\ufb01zierung und Aufstellung von Qualit\u00e4tsmetriken [30], dem Einsatz einer\nEvaluationsumgebung [28] und der Generierung einer realistischen Netzwerklast [30] vier wesentli-\nche Komponenten. Der DVS-Fachgebiet entwickelte dazu eine Evaluationsplattform, die mit dem P2P-\nMMOG Planet PI4 ein Benchmarking von P2P-Gaming-Overlays erm\u00f6glicht. Ein wesentlicher Bestandteil\nder Benchmarking-Methodik ist die synthetische Generierung einer realistischen Netzwerklast. Planet\nPI4soll u.a. dazu eingesetzt werden diese Netzwerklast f\u00fcr P2P-Gaming-Overlays zu erzeugen. Ziel die-\nser Master-Thesis ist die konkrete Erzeugung der Netzwerklast von Planet PI4 mit dem Ansatz kontext-\nsensitiver AI-Spieler, die stellvertretend f\u00fcr Menschen das Spiel spielen.\n1.1 Problemstellung und -beschreibung\nEs existieren zwar mehrere Methoden zur Erzeugung von Netzwerklasten, allerdings sind diese meistens\nentweder zu simpel oder f\u00fcr eine allgemeine Vergleichbarkeit unterschiedlicher P2P-Overlays unterein-\nander zu spezi\ufb01sch. Eine g\u00e4ngige Art ist beispielsweise die Nutzung der Generierung zufallsbasierter\nBewegungsabl\u00e4ufe, um die dadurch entstehenden Positions\u00e4nderungen, welche jeweils an die anderen\nPeers weiterpropagiert werden m\u00fcssen, zur Erzeugung der Netzwerklast zu benutzen. Dieser oder ande-\nre auf ihn beruhende Ans\u00e4tze konzentrieren sich mit dem Bewegungsaspekt, nur auf einen von vielen\nwichtigen Aspekten eines Computerspiels und k\u00f6nnen so gesehen nur eine ungef\u00e4hre Approximation der\ntats\u00e4chlich erzeugten Netzwerklast eines Computerspiels liefern.\nDer von der Master-Thesis entwickelte Ansatz sollte dementsprechend keine zu starken Vereinfachun-\ngen vornehmen und m\u00f6glichst alle relevanten Faktoren des Computerspiels zur Erzeugung der Netzwer-\nklast beachten.\n1.1 Problemstellung und -beschreibung 3Die meisten anderen Ans\u00e4tze beruhen auf der Erfassung und Auswertung echter Spielpartien anhand\nvon sogenannten Game Traces , die wichtige Daten des Spiels aufzeichnen. Diese Aufzeichnungen oder\nauf ihnen beruhende Verhaltensmodelle werden dann zum automatisierten Nachspielen des Spiels einge-\nsetzt. Dazu wird nicht wirklich das Spiel gespielt, sondern nur die relevanten Nachrichten zur Lasterzeu-\ngung generiert, wie z.B. Positionswechsel oder Todesmeldungen. Das Problem solcher Ans\u00e4tze ist, dass\nsie entweder nicht skalieren, weil dazu erneut echte Spielerpartien mit der entsprechenden Spieleran-\nzahl aufgezeichnet werden m\u00fcssten, oder ebenfalls zu ungenau in der Erzeugung des Netzwerklast sind.\nDie Ungenauigkeit entsteht dabei h\u00e4u\ufb01g dadurch, dass sich bei der Aufzeichnung nur auf relevante Da-\nten der Netzwerkebene beschr\u00e4nkt wird. Die damit gelernten Modelle k\u00f6nnen demzufolge nur Auskunft\n\u00fcber Aspekte geben, wie die mittlere Anzahl an Todesmeldungen oder die bevorzugte Ansteuerung von\nPositionen. Die sich gegenseitig beein\ufb02ussenden Spielprozesse oder ineinandergreifenden Interaktionen\nder Spieler im Spiel, die zu Entscheidungen wie der Ansteuerung einer Position oder dem Sterben eines\nSpielers f\u00fchren, werden dabei weitestgehend ignoriert.\nDer von Master-Thesis entwickelte Ansatz sollte dementsprechend skalierbar im Hinblick auf die Spie-\nlerzahl sein und sich nicht ausschlie\u00dflich auf f\u00fcr die Netzwerkebene relevante Daten beschr\u00e4nken. Des-\nwegen soll der Ansatz direkt auf der Spielebene ansetzen und in diesem Sinne auch die Erfassung und\nAbbildung sich gegenseitig beein\ufb02ussender kausaler Prozesse im Spiel erm\u00f6glichen, die zur Erzeugung\nder Netzwerklast als wichtig erscheinen.\nDer Ansatz der Nutzung computergesteuerter kontext-sensitiver Spieler zur Erzeugung der Netzwer-\nklast ist ein Konzept, welches genau diesem beschriebenen Anforderungspro\ufb01l gerecht zu werden scheint\nund deswegen im Rahmen dieser Master-Thesis umgesetzt werden soll. Hierbei handelt es sich im Rah-\nmen der Lasterzeugung von P2P-Systemen um einen noch recht jungen und unerprobten Ansatz, wes-\nwegen eine weitere Aufgabe dieser Master-Thesis, neben der Implementierung, auch die Evaluation bzw.\nFeststellung der generellen Eignung dieses Ansatzes zur Generierung einer realistischen Netzwerklast ist.\nDie Entwicklung computergesteuerter kontext-sensitiver Spieler ist Vergleichbar mit der Entwicklung\nvon NPCs in herk\u00f6mmlichen Computerspielen. In aller Regel \u00fcbernimmt dabei eine sogenannte Arti\ufb01cial\nIntelligence (AI)-Komponente des Computerspiels oder auch kurz Game AI genannt die Steuerung dieser\nNPCs. Der Prozess der Entwicklung einer Game AI ist hierbei stark vom jeweiligen konkreten Compu-\nterspiel abh\u00e4ngig. Das liegt vorrangig daran, dass die Game AI , wie der menschliche Spieler auch, zum\nSpielen konkrete Informationen \u00fcber das Spiel im Allgemeinen, wie z.B. \u00fcber das Spielziel oder die\nSpielmechanik, als auch Kenntnis \u00fcber das genaue Steuerungs- und Bedieninterface im Speziellen be-\nn\u00f6tigt. Daher ist die Entwicklung zur Generierung der Netzwerklast (4. Komponente der Benchmarking-\nMethodik) eng mit der konkret verwendeten Evaluationsumgebung (3. Komponente der Benchmarking-\nMethodik) verbunden.\nAls Evaluationsumgebung f\u00fcr P2P-Gaming-Overlays wird das Spiel Planet PI4 [28] eingesetzt und stetig\nweiterentwickelt. Planet PI4 ist ein auf P2P basierender MMOTPS und ist in einer 3D-Weltraumwelt ange-\nsiedelt. Das Spiel entspricht dabei weitestgehend dem \ufb01ktiv zu entwickelten Spiel des Beispielszenarios\naus der Einleitung. Dies bedeutet im Besonderen, dass mit Planet PI4 ein Spiel eingesetzt wird, welches\naufgrund seiner hohen Verz\u00f6gerungssensitivit\u00e4t, hohe Anspr\u00fcche an die zu evaluierenden P2P-Gaming-\nOverlays stellt. Die Evaluationsumgebung enth\u00e4lt dar\u00fcber hinaus noch einen Discrete-Event Simulator ,\nder eine vollst\u00e4ndige Kontrolle der Umgebung erm\u00f6glicht. Somit kann, anders als bei der ebenfalls m\u00f6g-\nlichen Evaluierung im einem realen Netzwerk, die Reproduzierbarkeit der Umgebungsein\ufb02\u00fcsse gew\u00e4hr-\nleistet werden, die z.B. bei einer Evaluation \u00fcbers Internet, wegen mangelnder Kontrollierbarkeit des\nInternets, nicht garantiert werden k\u00f6nnte.\n4 1 Einleitung1.2 Zielde\ufb01nition\nDas \u00fcbergeordnete Ziel der vorliegenden Master-Thesis ist zusammenfassend die synthetische Generie-\nrung einer realistischen Netzwerklast zu Evaluationszwecken verschiedenartiger P2P-Gaming-Overlays\nmittels einer auf besonderen Qualit\u00e4tsmerkmalen ausgerichteten Benchmarking-Methodik. Dazu soll\nunter Verwendung der Spiel- und Evaluationsumgebung Planet PI4 der Ansatz der kontext-sensitiven\nAI-Spieler, im Nachfolgenden auch als Bots bezeichnet, umgesetzt werden. Bei der Generierung einer\nrealistischen Netzwerklast wurden mit der Reproduzierbarkeit , der Skalierbarkeit , dem Realit\u00e4tsgrad\nund der Kon\ufb01gurierbarkeit vier wichtige Kriterien herausgearbeitet, dessen Erf\u00fcllung das vorrangige\nZiel der Master-Thesis darstellt.\nDas erste Kriterium der Reproduzierbarkeit bezeichnet dabei den Umstand, dass es mit dem zu ver-\nwirklichenden Ansatz m\u00f6glich sein soll, unter Zuhilfenahme des Discrete-Event Simulators , ein f\u00fcr ein\nTestszenario wiederholbares Verhalten zu generieren, sodass jedes P2P-Gaming-Overlays unter densel-\nben Voraussetzungen evaluiert und beliebig oft wiederholt werden kann.\nDas n\u00e4chste Kriterium Skalierbarkeit bedeutet, dass die L\u00f6sung mittels Bots performant genug sein\nmuss, um eine f\u00fcr ein MMOG ausreichend gro\u00dfe Anzahl an Spielern zu unterst\u00fctzen. Ein Bot vertritt\nim realen Testszenario einen menschlichen Spieler pro Peer bzw. Rechner, sodass diesem ausreichend\nRessourcen zur Verf\u00fcgung stehen sollten. Doch soll es dar\u00fcber hinaus auch m\u00f6glich sein eine Evalua-\ntion mithilfe des Simulators, welcher die Netzwerkkommunikation der Peers simuliert und kontrolliert,\nauf einem einzelnen Rechner auszuf\u00fchren. Die L\u00f6sung sollte demnach hardwareschonend genug sein,\num eine Simulation mit einer m\u00f6glichst gro\u00dfen Anzahl an Spielern in einer vertretbaren Zeit auf einem\nRechner zu gew\u00e4hrleisten.\nAls drittes und vielleicht wichtigstes Kriterium soll ein m\u00f6glichst hoher Realit\u00e4tsgrad in Bezug auf das\nVerhalten der Bots erzielt werden. Dabei wird der angestrebte Realit\u00e4tsgrad nicht prim\u00e4r an Aspekten\nwie Spielst\u00e4rke oder der Nachahmung menschlicher kooperativer oder kompetitiver Verhaltensweisen\ngemessen. Stattdessen geht es vielmehr um die Nachbildung eines menschen\u00e4hnlichen kontrollierbaren\nSpielverhaltens, welches in seiner Gesamtheit \u00fcber alle Bot-Instanzen hinweg betrachtet, eine m\u00f6glichst\ngenaue Ann\u00e4herung an von ausschlie\u00dflich menschlichen Spielern verursachten Netzwerklasten darstellt.\nErst die Generierung realistischer Lasten erm\u00f6glicht n\u00e4mlich eine aussagekr\u00e4ftige Bewertung der Quali-\nt\u00e4tsmerkmale von P2P-Overlays im Rahmen der Benchmarking-Methodik.\nAllen voran f\u00fcr die Erf\u00fcllbarkeit der beiden letztgenannten Kriterien Skalierbarkeit und Realit\u00e4tsgrad\nwird eine ausreichende Kon\ufb01gurierbarkeit bzw. Kalibrierung des Bots ben\u00f6tigt und stellt somit das\nvierte und letzte Kriterium der Zielde\ufb01nition dar. Hierbei m\u00fcssen einerseits Wege zur Anpassung der\nPerformance an die ben\u00f6tigte Spieleranzahl gefunden werden, anderseits Kon\ufb01gurations-Mechanismen\nentwickelt werden, die ein Variieren der Netzwerklast durch sp\u00fcrbare Ver\u00e4nderungen des Spielverhal-\ntens erm\u00f6glichen. Dies schlie\u00dft Einstellungsm\u00f6glichkeiten der Verhaltensweisen einzelner Bot-Instanzen,\nbestimmter Untermengen davon, oder gar der Gesamtheit aller Bot-Instanzen mit ein.\nNeben der Erf\u00fcllung der eben vorgestellten vier Kriterien soll aufgrund der gewonnenen Erfahrungs-\nwerte und Erkenntnisse aus der Vergangenheit mit diesem Ansatz (siehe dazu Abschnitt 3.5), nicht ei-\nne blo\u00dfe Bot-Implementierung umgesetzt werden, sondern vielmehr eine stabile Game AI -Architektur\ngeschaffen werden. Diese soll als Grundlage f\u00fcr Analyse und Entwicklung weiterer konkreter Bot-\nImplementierungen oder gezielter Verbesserungen der bestehenden Bot-Implementierung genutzt wer-\nden. Dabei soll gr\u00f6\u00dftm\u00f6glichen Wert auf Wiederverwendbarkeit und Austauschbarkeit der Teilkompo-\nnenten der Game AI -Architektur gelegt werden.\n1.2 Zielde\ufb01nition 51.3 Themeneingrenzung\nDie tats\u00e4chlichen Aufgaben und somit m\u00f6glichen Komponenten einer vollst\u00e4ndigen Game AI sind um-\nstritten und k\u00f6nnen je nach eingesetztem Computerspiel stark variieren. Gegenstand der Entwicklung\nder Master-Thesis soll deswegen eine Game AI sein, die sich Haupts\u00e4chlich auf den Entscheidungspro-\nzess der Auswahl der als n\u00e4chsten auszuf\u00fchrenden Aktion (Decision Making) beschr\u00e4nkt. Dabei werden\nalle relevanten Spielaspekte umfasst, mit denen sich auch ein menschlicher Spieler von Planet PI4 in der\nRegel auseinandersetzt. Mit anderen Worten geht es um die bestm\u00f6gliche Steuerung des Raumschiffes\nvonPlanet PI4 , sowie der Umsetzung und Unterst\u00fctzung von Entscheidungsprozessen zur Evaluierung\nder bestm\u00f6glichen Spielweise die einerseits zum Gewinnen des Spiels f\u00fchrt, andererseits eine m\u00f6glichst\nrealistische Nachbildung der Netzwerklast erlaubt. Demzufolge sind andere Aspekte die ebenfalls zu ei-\nnerGame AI geh\u00f6ren k\u00f6nnen, wie z.B. Animations- und Kamerakontrolle, Natural Language Processing,\nsowie die Tool-Entwicklung zur Unterst\u00fctzung der Game AI nicht Gegenstand dieser Master-Thesis.\nWeil es sich bei der zugrundeliegenden Implementierung der Master-Thesis um eine Neu-Entwicklung\nhandelt und es sich bei der Entwicklung einer vollst\u00e4ndigen Game AI um eine komplexe und arbeitsin-\ntensive Arbeit handelt, die in aller Regel von einem gr\u00f6\u00dferen Team und in einem gr\u00f6\u00dferen Zeitraum\nentwickelt wird, k\u00f6nnen erweiterte Aspekte wie Learning ,Player Prediction und Opponent Modelling\nnur rudiment\u00e4r oder gar nicht ber\u00fccksichtigt werden. Mit der Schaffung einer durchdachten Game\nAI-Architektur soll allerdings die Grundlage f\u00fcr Weiterentwicklungen geschaffen werden, die sich u.a.\nauch mit diesen Themen eingehender auseinander setzen k\u00f6nnen.\nAbschlie\u00dfend sei noch erw\u00e4hnt, dass bei der Bot-Implementierung von der Annahme ausgegangen\nwird, dass eine Bot-Instanz jeweils auf einem separaten Rechner l\u00e4uft und somit Aspekte wie Ressourcen-\nTeilung oder NPC Host Allocation keine Rollen spielen.\n1.4 Aufbau der Arbeit\nIn Kapitel 2 \u201eGrundlagen\u201c werden allgemeine und elementare Themen behandelt, die f\u00fcr das weitere\nVerst\u00e4ndnis der Arbeit erforderlich sind. Dabei werden einerseits grundlegende De\ufb01nition zu den Be-\ngriffen \u201eComputerspiel\u201c und \u201eGame AI\u201c pr\u00e4sentiert, die zur besseren Einordnung und Erfassung der\nAufgabenstellung beitragen. Andererseits werden mit der Vorstellung des Entwurfs des rationalen Agen-\nten und des Agentenmodells nach Reynolds, in diesem Kapitel bereits erste abstrakte L\u00f6sungskonzepte\npr\u00e4sentiert, auf denen der eigene konkrete Ansatz beruht.\nKapitel 3 \u201eVerwandte Ans\u00e4tze\u201c stellt alternative Konzepte oder konkrete Verfahren zum eigenen An-\nsatz vor. Im ersten Teil des Kapitels werden die in der Einleitung erw\u00e4hnten unzureichenden alternativen\nAns\u00e4tze zur realistischen Lasterzeugung detaillierter vorgestellt und konkrete Projekte aufgef\u00fchrt in de-\nnen sie eingesetzt werden. Der restliche Teil des Kapitels behandelt Konzepte, Methoden oder konkrete\nVerfahren zur Entwicklung einer Game AI oder deren wichtigsten Komponenten. Der eigene Ansatz einer\nGame AI nimmt eine Trennung der Verantwortlichkeiten und eine Einordnung dieser in unterschiedliche\nEbenen vor. Bei der Vorstellung der Alternativen in diesem Kapitel wird dieser Aufteilung Rechnung ge-\ntragen, indem ebenfalls Ebenen-gezielt verwandte Ans\u00e4tze vorgestellt werden.\nKapitel 4 \u201eKonzept und Rahmenbedingungen der Game AI\u201c und Kapitel 5 \u201eDesign und Implementie-\nrungsdetails der Game AI\u201c stellen die System-Kapitel der Arbeit dar und dienen der Beschreibung des\neigenen Ansatzes. Das erste System-Kapitel spezi\ufb01ziert mit der genauen Spielbeschreibung von Planet PI4\ndie konkrete Einsatzumgebung und das tats\u00e4chliche Einsatzfeld der Game AI . Des Weiteren erfolgt die\nVorstellung des allgemeinen Game AI -Konzepts zur Verdeutlichung der bei der Implementierung verfolg-\nten Design-Prinzipien. Das zweite System-Kapitel geht daraufhin ins Detail und konkretisiert das zuvor\n6 1 Einleitungvorgestellte Game AI -Konzept auf Klassenebene. Erg\u00e4nzt werden die Ausf\u00fchrungen mit der detaillierten\nBehandlung von wichtigen Implementierungsdetails der einzelnen Komponenten und Besonderheiten\nderGame AI -Implementierung.\nIn Kapitel 6 \u201eEvaluation\u201c erfolgt die Beschreibung der vorgenommen Validierung des eigenen Ansatzes\nin Bezug auf die Eignung zur Erzeugung einer realistischen Netzwerklast. Zur Beurteilung der Ergebnisse\nwird vor allem ein direkter Vergleich mit der Vorg\u00e4nger-Implementierung herangezogen.\nAbgeschlossen wird die Arbeit mit dem Kapitel 7 \u201eAusblick und Fazit\u201c indem einerseits die Ergebnisse\nder Evaluation und der Arbeit zusammengefasst, andererseits Bereiche f\u00fcr m\u00f6gliche Verbesserungen und\nansetzende Weiterentwicklungen vorgestellt werden.\n1.4 Aufbau der Arbeit 78 1 Einleitung2 Grundlagen\nDas Ziel dieses Kapitels ist die Schaffung einer f\u00fcr das weitere Verst\u00e4ndnis der Master-Thesis ausrei-\nchenden Grundlagenbasis. Hierzu wird im Abschnitt 2.1 \u201eWas ist ein Computerspiel?\u201c eine De\ufb01nition\ndes Begriffs Computerspiel pr\u00e4sentiert, die versucht die Quintessenz zahlreicher De\ufb01nitionen zu erfas-\nsen und in einer f\u00fcr den Rest dieser Ausarbeitung g\u00fcltigen Form zu vereinen. Dies ist wichtig, weil mit\nPlanet PI4 ein Computerspiel als direkte Einsatzumgebung f\u00fcr die zu entwickelnde Game AI eingesetzt\nwird und somit eine genaue Kenntnis dieser notwendig ist.\nDieselbe Argumentation l\u00e4sst sich ebenfalls auf den Begriff Game AI anwenden, welche die zu ver-\nwirklichende Komponente dieser Master-Thesis bezeichnet, und deswegen im n\u00e4chsten Abschnitt 2.2\n\u201eAcademic AI vs. Game AI\u201c einer eingehenden Betrachtung unterzogen wird. Die Pr\u00e4sentation einer f\u00fcr\nden Rest dieser Ausarbeitung g\u00fcltigen De\ufb01nition ist wie zuvor auch der wichtigste Bestandteil des Ab-\nschnittes.\nDer Abschnitt 2.3 \u201eDer Entwurf eines Rationalen Agenten\u201c stellt ein \u00fcbergeordnetes weit verbreitetes\nModel zur Beschreibung intelligenten Verhaltens in virtuellen Umgebungen vor. Dieses Modell beschreibt\ndie allgemeine Architektur der entwickelten Game AI und bildet somit die Grundlage des in Kapitel 4\nvorgestellten eigenen Systemansatzes und der daraus resultierenden konkreten Implementierung. Das\nKonzept \ufb01ndet ebenfalls Verwendung als Grundlage der in Abschnitt 3.2 und 3.3 vorgestellten verwand-\nten Ans\u00e4tze.\nDas entwickelte Game AI -Konzept der Master-Thesis stellt dar\u00fcberhinaus eine Erweiterung des\nreynoldschen Modells dar, welches in das Modell eines rationalen Agenten aus Abschnitt 2.3 integriert\nwird. Aus diesem Grund stellt der letzte Abschnitt 2.4 \u201eSteering Behaviors und das Agentenmodell nach\nReynolds\u201c dieses Modell vor und erl\u00e4utert das, f\u00fcr das weitere Verst\u00e4ndnis dieser Arbeit wichtige, Kon-\nzept der Steering Behaviors .\n2.1 Was ist ein Computerspiel?\nIn den 70er Jahren des vergangenen 20. Jahrhunderts entwickelte der sp\u00e4tere Atari-Gr\u00fcnder Nolan Bus-\nhnell ein Spiel namens Pong und markierte damit ein Ereignis in der Geschichte, welches aus heutiger\nSicht als die Geburtsstunde der Computerspielbranche angesehen werden kann [57]. Pong war aller-\ndings nicht das erste bekannte Computerspiel. Bereits 1952 entwickelte A. Sandy Douglas auf einem\nEDSAC2-Computer, dem ersten speicher-basierten Rechner der Welt, an der Cambridge Universit\u00e4t ein\nTic Tac Toe -Spiel mit dem Namen OXO [11]. Auf Grund der Tatsache, dass die Entwicklung des Spiels\nnicht prim\u00e4r der Unterhaltung diente, sondern der Veri\ufb01kation einiger von ihm aufgestellten Thesen im\nBereich der Mensch-Maschinen Interaktion und lange Zeit keinem breiten Publikum au\u00dferhalb der Uni-\nversit\u00e4t vorgestellt wurde, gilt stattdessen \u00f6fters auch Tennis for Two als das erste Computerspiel, das vom\namerikanischen Physiker William Higinbotham 1958 konstruiert wurde [15, S. 1] [58, S. xvii]. Daneben\ngibt es durchaus noch weitere Entwicklungen die den Anspruch erheben das erste Computerspiel zu sein\n[8] [57], allerdings mit einer jeweils deutlich kleineren Anh\u00e4ngerschaft als die beiden eben vorgestellten.\nGanz gleich welchen Titel man als das erste richtige Computerspiel ansieht, alle hatten eins gemein-\nsam: Sie waren nur einem sehr eingeschr\u00e4nkten, meist wissenschaftlichen oder akademischen Kreis von\nMenschen zug\u00e4nglich. Pong jedoch bediente zum ersten Mal erfolgreich eine spielende und vor allem\n2EDSAC steht f\u00fcr Electronic Delay Storage Automatic Calculator.\n9zahlende breite \u00d6ffentlichkeit. Eine \u00d6ffentlichkeit die auf einer einheitlichen und damals erstmal g\u00fcns-\ntigen Spiele-Hardware spielen konnte. Der Erfolg von Pong f\u00fchrte erst zu einer stetig wachsenden Zahl\nvon Variationen des Spiels, dann zu einer Lawine von Kopierversuchen Dritter und endete schlie\u00dflich mit\nder Entwicklung neuer Spielkonzepte und passender Hardware. Mit anderen Worten: Durch den Erfolg\nvonPong entstand ein neuer Massenmarkt, der zu Beginn des 21. Jahrhundert mehrere Hundert Mil-\nlionen Spieler weltweit umfasst und einer stetig wachsenden Computerspielbranche Jahresums\u00e4tze im\nzweistelligen, wenn nicht gar dreistelligen, Billionen Dollar Bereich beschert3[58, S. 34fff.] [13, S.11].\nObwohl es sich bei der Bezeichnung \u201eComputerspiel\u201c um einen sehr weit verbreiteten und gel\u00e4u\ufb01gen\nBegriff handelt, stellt sich \u00fcberraschenderweise eine pr\u00e4zise Beantwortung dieser Frage als recht proble-\nmatisch heraus. Der Grund hierf\u00fcr ist jedoch genau der Gleiche, wie f\u00fcr die f\u00e4lschliche Annahme einer\neinfachen Beantwortung: Dadurch dass der Begriff eine derart gro\u00dfe Verbreitung und \ufb02exible Verwen-\ndung besitzt, gibt es auch eine un\u00fcberschaubare Vielfalt an unterschiedlichsten Entwicklungen weltweit,\ndie sich als Computerspiel bezeichnen. Dieser Umstand und das Fehlen einer einheitlichen De\ufb01nition des\nBegriffs \u201eComputerspiel\u201c sind auch die wesentlichen Gr\u00fcnde daf\u00fcr, warum die zu Beginn dieses Abschnit-\ntes erw\u00e4hnte Debatte um das erste Computerspiel bis heute so kontrovers diskutiert wird. Die Ursache\ndaf\u00fcr wiederum resultiert ma\u00dfgeblich daraus, dass die De\ufb01nition eines Computerspiels untrennbar mit\nder Auffassung dar\u00fcber verbunden ist, was eigentlich unter einem \u201eSpiel\u201c verstanden wird. Darunter\nkann je nach subjektiver Auffassung alles M\u00f6gliche verstanden werden.\nIn [47] wird versucht sich genau dieser Problemantik anzunehmen. Nach der Untersuchung und des\nVergleichs einer Vielzahl unterschiedlicher De\ufb01nitionen, aus den verschiedensten Bereichen des Spielens,\nwird darin folgende, auf das wesentliche beschr\u00e4nkte, De\ufb01nition eines Spiels pr\u00e4sentiert:\nA game is a system in which players engage in an arti\ufb01cial con\ufb02ict, de\ufb01ned by rules, that results\nin a quanti\ufb01able outcome [47, S. 80].\nDie Hauptaussagen dieser De\ufb01nition sind dabei folgende:\n\u2022 Die Tatsache dass ein Spiel ein System ist und somit erst das Zusammenwirken der einzelnen Teile\nein komplexes Ganzes ergibt.\n\u2022 Das ein oder mehrere Spieler mit diesem System zum Erlangen einer Spielerfahrung interagieren\nm\u00fcssen.\n\u2022 Ein Spiel eine Instanz eines k\u00fcnstlichen Kon\ufb02iktes ist, welcher allerdings an Kon\ufb02ikten aus der\nwirklichen Welt angelehnt sein kann.\n\u2022 Das Regeln sowohl das Verhalten des Spielers beschr\u00e4nken, als auch das Spiel als Ganzes de\ufb01nieren.\n\u2022 Das jedes Spiel quanti\ufb01zierbare Ergebnisse liefert, sowie das Erreichen bestimmter Ziele verfolgt.\nAufbauend auf dieser De\ufb01nition eines Spiels werden in [47, S. 87ff.] vier spezielle Eigenschaften\nvorgestellt, deren intensivere Auspr\u00e4gung, nicht allerdings ihre blo\u00dfe Existenz, ein Computerspiel von\nanderen Spielformen abhebt:\n\u2022Immediate but narrow interactivity: Ein Computerspiel erm\u00f6glicht eine direkte und unmittelba-\nre Form der Interaktivit\u00e4t, allerdings ist diese durch Eingabeger\u00e4te und durch die Komplexit\u00e4t des\nSpiels stehts beschr\u00e4nkt.\n3Zum Vergleich: Um laut [48] in die Reihe der zehn erfolgreichsten Kino\ufb01lme aller Zeiten aufgenommen zu werden, wer-\nden momentan etwas mehr als 900 Millionen Dollar Einnahmen ben\u00f6tigt. Das momentan erfolgreichste Computerspiel\nModern Warfare 3 hat innerhalb von nur 16 Tagen seit der Ver\u00f6ffentlichung eine Milliarde US-Dollar Umsatz eingefahren\n[12].\n10 2 Grundlagen\u2022Manipulation of information: Ein Computerspiel basiert immer auf der Manipulation von Daten\nbzw. Informationen, wie z.B. Ein- und Ausgabedaten, Hardwaresteuerungssignale, Interne Pro-\ngrammlogik, Algorithmen, Bilder, Video, Audio, Animationen, 3D-Gra\ufb01ken usw..\n\u2022Automated complex systems: Ein Computerspiel ist ein automatisch ablaufendes komplexes Sys-\ntem, welches alleine f\u00fcr das (nahezu) direkte Fortschreiten des Spielgeschehens zust\u00e4ndig ist. In\neinem nicht auf einem Computer umgesetzten Brettspiel beispielsweise, muss der Spieler selbst\nf\u00fcr das Fortschreiten des Spiels sorgen, indem er z.B. seine Figuren bewegt oder Spielereignisse\nanderen Spielern vortr\u00e4gt. In einem Computerspiel w\u00fcrden solche Prozesse automatisiert ablaufen\nund somit dem Spieler weitestgehend abgenommen.\n\u2022Networked communication: Eine gro\u00dfe Anzahl an Spielen wird nicht ausschlie\u00dflich alleine ge-\nspielt, sondern mit anderen Spielern zusammen. Computerspiele erm\u00f6glichen es, dass die Spieler\n\u00fcber eine gro\u00dfe Distanz miteinander kommunizieren und interagieren, d.h. miteinander spielen,\nk\u00f6nnen. Moderne Computerspiele erlauben es ebenfalls, dass eine gro\u00dfe Menge an Spielern dies\nzusammen unternehmen kann.\nSeit den 1980er Jahren wird oftmals plattformspezi\ufb01sch zwischen einem Computer- und Videospiel\nunterschieden. Ein Computerspiel bezeichnet dabei ein Spiel, welches auf einem Personal Computers\n(PC) gespielt wird, wohingegen ein Videospiel ein Spiel kennzeichnet, dass f\u00fcr irgendeine Spielekonsole\nentwickelt wurde. Eine Spielekonsole ist dabei ein meist geschlossenes Hardwaresystem, welches prim\u00e4r\nzum Spielen konzipiert wurde und einen Anschluss an ein TV-Ger\u00e4t voraussetzt. Im Rahmen dieser Ab-\nschlussarbeit wird auf diese oder andere Unterscheidungen von Computerspielen verzichtet und mit dem\nBegriff Computerspiel alle Formen digitaler Spiele zusammengefasst, die obiger allgemeinen De\ufb01nition\neines Computerspiels gen\u00fcgen.\n2.2 Academic AI vs. Game AI\nK\u00fcnstliche Intelligenz (KI) bzw. Arti\ufb01cial intelligence (AI) bezeichnet in erster Linie einen Wissenschafts-\nzweig der Informatik, in dessen Zentrum der Betrachtung die (automatisierte) Schaffung von Intelligenz\nbzw. das (optimale) L\u00f6sen von intelligenten Problemen steht. Unter einem intelligenten Problem versteht\nman dabei eine zu l\u00f6sende Aufgabenstellung, welche Aufgrund ihrer Komplexit\u00e4t nicht durch einfaches\nAusprobieren aller M\u00f6glichkeiten gel\u00f6st werden kann [36, S. 1].\nDie traditionelle KI (Academic AI) hat im Laufe der Zeit den Begriff der Intelligenz aus einer Vielzahl\nunterschiedlicher Richtungen untersucht. Je nach Interpretation des Begriffs verfolgte die KI dabei einen\nanderen Weg zur Erforschung und Erschaffung intelligenter Systeme. Eine konkrete De\ufb01nition der KI\nist aufgrund dieser zeitlich gepr\u00e4gten Auslegung, was Intelligenz bedeutet, als durchaus problematisch\nanzusehen. Stuart Russell versucht jedoch in [46, S. 17f] den verschiedenen Entwicklungsstr\u00f6men der\nKI gerecht zu werden und leitet daraus vier \u00fcbergeordnete Auffassungen ab. Sie de\ufb01nieren ab wann ein\nk\u00fcnstliches System als intelligent bezeichnet werden kann.\nDemnach ist ein System genau dann intelligent, wenn dieses entweder\n\u2022 menschlich denken,\n\u2022 rational denken,\n\u2022 menschlich handeln oder\n\u2022 rational handeln kann.\nRationalit\u00e4t meint in diesem Kontext die F\u00e4higkeit, das Richtige oder das Bestm\u00f6gliche im Sinne ei-\nner vorgegebenen Richtlinie, der maximierbaren Nutzenfunktion, zu tun. Somit konzentriert sich die KI\n2.2 Academic AI vs. Game AI 11unter Betrachtung der Rationalit\u00e4t auf das optimale L\u00f6sen eines Problems. Das Entscheidende bei dieser\nBetrachtung ist die Vernachl\u00e4ssigung des Prozesses zur Entstehung des L\u00f6sungsweges. Der L\u00f6sungs-\nweg muss nur optimal unter der Nutzenfunktion sein, wie jedoch die L\u00f6sung erreicht wurde, ob durch\nBerechnungen, logisches Schlie\u00dfen oder auf menschen\u00e4hnliche Weise, ist nebens\u00e4chlich. Nach Russell\nbildet diese Auffassung von Intelligenz das rationale Handeln am besten ab und ist somit seiner Meinung\nnach die aktuell erstrebenswerteste Richtung der KI-Forschung. Russell begr\u00fcndet diese Annahme indem\ner auff\u00fchrt, dass rationales Denken hingegen immer auf korrekten logischen Schlussfolgerungen beruht\nund diese alleine nicht ausreichen um das ganze Spektrum der Rationalit\u00e4t abzudecken. So gibt es h\u00e4u-\n\ufb01g Situationen, wo man zwar nicht das beweisbar Korrekte tun kann, jedoch etwas getan werden muss.\nWenn im weiteren Verlauf dieser Ausarbeitung von der traditionellen KI die Rede ist, dann ist dabei die\nakademische Betrachtung des rationalen Handelns gemeint [46, S. 58-62].\nGame AI ist ein Sammelbegriff f\u00fcr den praktischen Einsatz einiger Teilbereiche der traditionellen KI\nund anderen Teilgebieten der Informatik in Computerspielen. Somit k\u00f6nnen Computerspiele als m\u00f6g-\nliches Anwendungsszenario f\u00fcr die von der KI entwickelten intelligenten Systeme angesehen werden.\nIm strikt akademischen Sinne bezeichnet der Begriff Game AI ausschlie\u00dflich Systeme die f\u00fcr ein in-\ntelligentes Verhalten von NPCs zust\u00e4ndig sind. Die Game AI -Entwicklung ist allerdings keine prim\u00e4r\nakademisch betriebene Aus\u00fcbung, sondern wie in Abschnitt 2.1 erw\u00e4hnt, \u00fcbernahm nach dem Erfolg\nvonPong die Industrie ma\u00dfgeblich die Weiterentwicklung von Computerspielen, sodass der Begriff Ga-\nme AI im Kontext von Computerspielen haupts\u00e4chlich von der Industrie gepr\u00e4gt worden ist. So fasst\ndiese unter dem Begriff einer Game AI s\u00e4mtliche Techniken und Systeme zur L\u00f6sung jeglicher Art von\nSteuerungs- und Kontrollproblemen zusammen. Beispielsweise w\u00fcrden die Berechnungen, die Steuerung\nund das Abspielen passender Greif-Animationen eines NPCs nach einem Gegenstand unter Umst\u00e4nden\nin den Aufgabenbereich einer Game AI fallen. Au\u00dferhalb von Computerspielen w\u00fcrde dies eher als ein\ninverses Kinematik-Problem der Kontrolltheorie aufgefasst werden [15, S. 9ff] [51, S. 4ff].\nDie gr\u00f6\u00dfte Abgrenzung zwischen industriell-gepr\u00e4gter und akademischer Sichtweise liegt allerdings\nim unterschiedlichen Probleml\u00f6sungsansatz begr\u00fcndet. In der Industrie steht nicht das optimale L\u00f6sen\neines KI-Problems im Vordergrund, sondern eine Probleml\u00f6sung die auf die Maximierung des Unterhal-\ntungswertes ausgerichtet ist. Die Probleml\u00f6sung muss sich dem zufolge in erster Linie an den Spielspa\u00df,\ndie Hardwareleistung der Kundenzielgruppe und an die Ziele des Spieldesigns ausrichten. Im Extremfall\ninteressiert sich eine Game AI \u00fcberhaupt nicht f\u00fcr optimale Ergebnisse. So k\u00f6nnte die aktuelle Schwie-\nrigkeitsmodellierung vorgeben, in bestimmten Situationen nicht optimale Aktionen zu w\u00e4hlen, um den\nSpieler nicht zu \u00fcberfordern. Auch kann im Sinne der Abwechslung die Wahl nicht optimaler Ergebnis-\nse sinnvoll erscheinen. In der akademischen Welt hingegen w\u00fcnscht man sich beweisbar wiederholbare\noptimale Ergebnisse, die dar\u00fcber hinaus am besten generell anwendbar sind [51, S. 4ff] [35, S. 4fff].\nIm Rahmen dieser Ausarbeitung wird prinzipiell vom akademischen Verst\u00e4ndnis einer Game AI ausge-\ngangen.\n2.3 Der Entwurf eines Rationalen Agenten\nStuart Russell beschreibt einen Agenten als\nAlles, was eine Umgebung (Environment) \u00fcber Sensoren (Sensors) wahrnehmen kann und in\ndieser Umgebung \u00fcber Aktuatoren (Actuators) handelt [46, S. 55].4\nDieses einfache Konzept auf eine Game AI \u00fcbertragen bedeutet, dass ein Agent ge\ufb01lterte Informationen,\nim weiteren Verlauf als Wahrnehmungen ( Perceptions ) bezeichnet, \u00fcber seine Umgebung, die Spielwelt,\n4Die englischen Begriffe in den Klammern des Zitats geh\u00f6ren nicht zum Original. Sie wurden an dieser Stelle zur Ver-\nst\u00e4ndniserleichterung der Abbildungen 1 und 2 eingef\u00fcgt, da diese die englischen Begriffe verwenden.\n12 2 Grundlagenbekommt und dann anhand dieser Informationen entscheidet, welche Aktion als n\u00e4chstes auszuf\u00fchren\nist. Der Auswahlprozess der als n\u00e4chstes auszuf\u00fchrenden Aktion wird in Game AI -Bereich als Decision Ma-\nking bezeichnet. Weiter geht man \u00fcblicherweise davon aus, dass ein Agent zwar seine eigenen Aktionen\nwahrnehmen kann, allerdings nicht immer auch dessen Wirkungen, d.h. man geht von einer Umgebung\nmit unvollst\u00e4ndigen Informationen aus. Abbildung 1 veranschaulicht diesen Zusammenhang.\nAbbildung 1: Der schematische Aufbau eines simplen rationalen Agenten. Angelehnt an [46] und [36].\nEin rationaler Agent ist in diesem Sinne ein Agent der das Richtige bzw. das Bestm\u00f6gliche tut. Um\nentscheiden zu k\u00f6nnen was das Beste ist, braucht der Agent eine Leistungsbewertungsfunktion ( Utility\nFunction ), die eine Bewertung seiner Aktionen erm\u00f6glicht. Wie diese auszusehen hat ist Anwendungs-\nabh\u00e4ngig. Wichtig ist allerdings eine nicht ergebnisorientierte Funktion zu verwenden, sondern eine die\nden vom Entwickler gew\u00fcnschten Weg zum Ziel belohnt. Ein rationaler Agent zeichnet sich dadurch\naus, dass diese Leistungsbewertung unter Betrachtung seiner Wahrnehmungen, eventuellen Vorwissen\nund den wahrscheinlichen Auswirkungen seiner m\u00f6glichen n\u00e4chsten Aktionen zu maximieren ist. Ra-\ntionalit\u00e4t sollte in der Anwesenheit von unvollst\u00e4ndigem oder unsicherem Wissen nicht mit Perfektion\nverwechselt werden. Perfektion maximiert immer die tats\u00e4chliche Leistung, Rationalit\u00e4t maximiert dage-\ngen die erwartete Leistung unter Ber\u00fccksichtigung des aktuellen Wissens. Anders ausgedr\u00fcckt versucht\nein rationaler Agent in jeder durch die Wahrnehmung gegebenen Situation die Aktion zu w\u00e4hlen, die in\nZukunft den gr\u00f6\u00dften Nutzen im Sinne der Nutzenfunktion verspricht.\nGenerell werden mindestens f\u00fcnf Agententypen unterschieden, die, mit Ausnahme des Lernenden\nAgenten , als aufeinander aufbauende Prinzipien betrachtet werden k\u00f6nnen. Nach Russel in [46, S. 72-82]\nk\u00f6nnte eine m\u00f6gliche Unterscheidung wie folgt de\ufb01niert werden:\n\u2022Einfache Re\ufb02ex-Agenten : Aktionsauswahl basiert nur auf aktueller Wahrnehmung und wird durch\nCondition-Action-Rules modelliert.\n\u2022Modellbasierte Re\ufb02ex-Agenten : Es wird ein interner Zustand und ein Weltmodell verwaltet, um\nnicht beobachtbare Aspekte zu modellieren. Nicht beobachtbare Aspekte sind beispielsweise geg-\nnerische Aktionen au\u00dferhalb des Wahrnehmungsbereiches des Agenten.\n\u2022Zielbasierte Agenten : Anhand des Weltmodells und des internen Zustandes beein\ufb02usst eine Ziel-\nfunktion die Aktionsauswahl. Suchen und Planen sind wichtige Mittel um Aktionsfolgen zu \ufb01nden,\ndie Ziele erreichen.\n\u2022Nutzenbasierte Agenten : Zielerf\u00fcllung wird auf den Nutzen analysiert, um zwischen Aktionen\noder Aktionsketten die Ziele erf\u00fcllen zu unterscheiden. Eine Nutzenfunktion bildet einen Zustand\nauf eine, den Nutzen darstellende, reelle Zahl ab.\n\u2022Lernende Agenten : Lernen erlaubt in unbekannten Umgebungen eine gegen\u00fcber dem Ausgangs-\nwissen gr\u00f6\u00dfere Kompetenz aufzubauen.\nPrinzipiell kann man einen Nutzenbasierten Agenten , egal ob mit oder ohne Lernaspekt, als den Agen-\nten bezeichnen der einem rationalen, und somit intelligenten, Agenten am n\u00e4chsten kommt. Im weiteren\n2.3 Der Entwurf eines Rationalen Agenten 13Verlauf wird mit Agent genau dieser Typ bezeichnet. Abbildung 2 fasst die wichtigsten abstrakten inter-\nnen Komponenten dieser Agentenart nochmal zusammen.\nAbbildung 2: DerNutzenbasierte Agent und seine wichtigsten Komponenten als Erweiterung des simplen Agenten\naus Abbildung 1. Angelehnt an [46] und [36].\nIan Millington und John Funge bezeichnen den Agentenentwurf als einen Bottom-Up -Entwurf, wo das\nendg\u00fcltige Spielverhalten aus dem Zusammenspiel der Agenten untereinander resultiert. Im Vergleich\ndazu w\u00fcrde ein nicht Agentenbasierter Entwurf einem Top-Down -Entwurf entsprechen, wo ein einzelnes\nSystem das Verhalten aller NPCs zentral berechnet und die auszuf\u00fchrenden Aktionen lediglich, wenn\n\u00fcberhaupt, an diese zur Ausf\u00fchrung weiter gibt [35, S. 11]. Aus diesem Grund ist dieser Ansatz, auch\nalsMultiagenten System (MAS) bezeichnet, als ein dezentrales System anzusehen. Dies ist eine f\u00fcr die\nEntwicklung der Game AI wichtige Erkenntnis, die mit Planet PI4 f\u00fcr ein Spiel entwickelt wird, welches\nmit P2P auf eine ebenfalls dezentrale Systemarchitektur setzt.\nMateas schlussfolgert in [34], dass dem Konzept des Zielbasierten Agenten bzw. seiner Erweiterungen\neine tragende Schl\u00fcsselrolle bei der Entwicklung einer guten Game AI zukommt. Begr\u00fcndet wird diese\nHypothese indem aufgef\u00fchrt wird das die wichtigste Aufgabe einer Game AI die Realisierung von f\u00fcr den\nSpieler nachvollziehbaren und autonom wirkenden Verhalten von NPCs darstellt. Glaubw\u00fcrdige NPCs\nsind die Grundlage zur Bewertung von intelligenten Verhalten, denn erst wenn das Verhalten in einen\nf\u00fcr den Spieler nachvollziehbaren Kontext gestellt wird, kann dieser zwischen intelligenten und nicht\nintelligenten Verhalten unterscheiden. Eine M\u00f6glichkeit f\u00fcr die Realisierung der Glaubw\u00fcrdigkeit von\nNPCs ist die Verwendung des eben vorgestellten Agentenkonzeptes, welches NPCs als Ziele verfolgen-\nde Agenten de\ufb01niert, die auf Grundlage ihrer aktuellen Ziele und ihrem Wissen \u00fcber die Welt, gewisse\nsichtbare Aktionen zur Zielerreichung ausf\u00fchren. Der menschliche Verstand kann durch Abstraktion kom-\nplexe Systeme, wie andere Menschen, leichter durchschauen und somit dessen Wirkung bzw. im Fall von\nNPCs deren Verhalten nachvollziehen. Indem der Spieler von der technischen Realisierung eines NPCs\nabstrahiert und diesen stattdessen als einen Ziele verfolgenden Agenten betrachtet, kann der Spieler das\nVerhalten der NPCs besser bewerten und leichter nachvollziehen. Laut Mateas sind f\u00fcr den menschlichen\nSpieler glaubw\u00fcrdige und intelligente NPCs ein wichtiger Faktor zur Schaffung einer in sich realistischen\nund lebendigen Spielwelt, die wiederum gro\u00dfe Bedeutung f\u00fcr den Spielspa\u00df eines Spieles hat.\nBei der Generierung einer realistischen Netzwerklast geht es zwar nicht prim\u00e4r um Faktoren wie den\nSpielspa\u00df oder der Erzeugung glaubhaften NPC-Verhaltens aus Sicht eines menschlichen Spielers, je-\ndoch basiert das Konzept des zielbasierten Ansatzes auf einer typisch menschlichen Abstraktionsweise\nzur Situationsbew\u00e4ltigung und erhebt dabei einen gewissen Realismus-Anspruch bei der Verhaltensge-\nnerierung. Diese beiden Eigenschaften spielen bei der m\u00f6glichst genauen Erfassung und Nachahmung\nder menschlichen Spielart eine zentrale Rolle, die wiederum die Grundlagen f\u00fcr eine realistische Gene-\nrierung der Netzwerklast darstellen.\n14 2 Grundlagen2.4 Steering Behaviors und das Agentenmodell nach Reynolds\nSteering is the reactive, non-deliberative movement of physical agents [3, S. 2].\nDer Begriff Steering bzw. Steering Behaviors im Kontext von autonomen Agenten wurde ma\u00dfgeblich\ndurch die Arbeit von Reynolds [44] aus dem Jahr 1999 gepr\u00e4gt. Steering bezeichnet darin die mittlere\nder drei hierarchisch angeordneten Ebenen der von Reynolds unternommenen Unterteilung und Struktu-\nrierung zur Aufgabe der Bewegungssteuerung eines autonomen Agenten in einer virtuellen Umgebung,\nwelche in Abbildung 3 dargestellt ist.\nAbbildung 3: Das Modell nach Reynolds zur hierarchischen Unterteilung der Verantwortlichkeiten zur Bewe-\ngungssteuerung eines autonomen Agenten. Entnommen aus [44].\nDie beiden anderen, die Steering -Ebene einschlie\u00dfenden, Ebenen sind zum Einem die dar\u00fcber ange-\nsiedelte Ebene der Action Selection und zum anderen die Locomotion -Ebene darunter. Wenn die Steering -\nEbene nach dem Zitat von [3, S. 2] als die \u201enon-deliberative\u201c-Ebene angesehen werden kann, d.h. ei-\nne Ebene darstellt, die ihre Entscheidungen ohne eines vorangestellten Abw\u00e4gungsprozesses bestimmt,\ndann kann im Gegensatz dazu die dar\u00fcber liegende Ebene der Action Selection als die \u201edeliberative\u201c-\nEbene im Modell von Reynolds bezeichnet werden. Vergleichbar mit der allgemeinen Aufgabe des Deci-\nsion Making im Konzept des rationalen Agenten aus Abschnitt 2.3 muss in dieser Ebene eine abw\u00e4gende\nEntscheidung unter Einbeziehung etwaiger Ziele, Pl\u00e4ne oder Strategien dar\u00fcber getroffen werden, wel-\nche Aktion als n\u00e4chstes am besten auszuf\u00fchren sei. Ist eine Aktion in einem Simulationszyklus bestimmt,\nwird diese zur Realisierung an die Steering -Ebene weitergereicht [44].\nDieSteering -Ebene ermittelt dabei ob die Aktionsausf\u00fchrung direkt unternommen werden kann, die\nAktion in weitere Unteraktionen zerlegt werden kann oder zus\u00e4tzliche Aktionen vorher eingeschoben\nwerden m\u00fcssen, weil z.B. vorher noch einem Hindernis ausgewichen werden muss. F\u00fcr diese Aufgabe\ngreift die Steering -Ebene auf sogenannte Steering Behaviors zur\u00fcck. Steering Behaviors sind reaktive Ver-\nhaltensweisen auf Bewegungsebene, die unter Einbeziehung lokaler Umgebungsinformationen als Ein-\ngabe, einen Steering - bzw. Bewegungsvektor als Ausgabe produzieren [3]. In [44] pr\u00e4sentiert Reynolds\nu.a. mit seek,arrival ,\ufb02ee,pursuit ,evasion ,wander undobstacle avoidance eine Basismenge von Steering\nBehaviors . Die einzelnen Steering Behaviors k\u00f6nnen dabei aufeinander aufbauen wie z.B. arrival aufseek\naufbaut, indem es dem seek-Verhalten ein Abbremsen vorm Erreichen des Ziels einf\u00fcgt. Weiter lassen\nsich ebenfalls beliebige Kombinationen anstellen, die zu komplexen und eindrucksvollen Steering Beha-\nviors f\u00fchren k\u00f6nnen. Ein Beispiel hierf\u00fcr ist die Nachbildung des Schwarmverhaltens von V\u00f6geln durch\ndas ber\u00fchmte Flocking-Steering Behavior von Reynolds. Nichtsdestotrotz stellen Steering Behaviors in der\nRegel voneinander unabh\u00e4ngige Berechnungen an, deren Ergebnisse sich mitunter auch untereinander\nwiedersprechen k\u00f6nnen. Aus diesem Grund ist eine weitere wichtige Aufgabe dieser Ebene die geschickte\nAuswahl und Kombination der einzelnen Steering Behaviors . Damit der unteren Locomotion -Ebene letz-\nten Endes ein einziges Steering -Ziel \u00fcbergeben werden kann, welches durch einen zusammenfassenden\noder ausgew\u00e4hlten Steering -Vektor repr\u00e4sentiert wird.\n2.4 Steering Behaviors und das Agentenmodell nach Reynolds 15Bei der untersten Ebene der Locomotion handelt es sich um eine reine Ausf\u00fchrungsebene. Sie be-\nsitzt die Kontrolle \u00fcber den K\u00f6rper bzw. den Gegenstand der Bewegungsausf\u00fchrung. Im Kontext des\nrationalen Agenten aus Abschnitt 2.3 w\u00fcrde es sich hierbei um die Schnittstelle zwischen der Decision\nMaking -Komponente und den Aktuatoren des Agenten handeln, die f\u00fcr die Umsetzung der gew\u00fcnschten\nAktion durch tats\u00e4chliche Handlungen in der virtuellen Agentenumgebung zust\u00e4ndig sind. Dabei k\u00f6nnen\ndie Aufgaben dieser Ebene abh\u00e4ngig von der angewandten De\ufb01nition einer Game AI (siehe Abschnitt 2.2)\noder der konkret im Einsatz be\ufb01ndlichen Game AI -Architektur vielf\u00e4ltiger Natur sein. Aufgrund dessen\nkann je nach Auffassung das Aufgabenspektrum sich von einer reinen Konvertierung des Steering -Vektors\nin konkrete Steuerungssignale \u00fcber die De\ufb01nition der Aktuatoren bzw. der Bewegungssteuerungskom-\nponenten samt dazu passendem Animationshandling erstrecken. Ein abschlie\u00dfendes Beispiel soll das\nKonzept der drei Ebenen zusammenfassend verdeutlichen.\nIn einem FPS k\u00f6nnte die Action Selection -Ebene zu dem Schluss kommen einen etwas weiter entfernten\nGegner anzugreifen, weil sich in der aktuellen Situation kein anderer Gegner in der unmittelbaren N\u00e4he\nbe\ufb01ndet. Dieses Ziel wird von der Steering -Ebene unterteilt in die Bestimmung der k\u00fcrzesten Route durch\ndas Level zur gegnerischen Position und der Verfolgung dieser Route. Da ein Gegner in der Zwischen-\nzeit aller Wahrscheinlichkeit nicht auf der Stelle stehen bleibt, wird die gegnerische Position durch eine\nPrognose der zuk\u00fcnftigen Position des Gegners ersetzt. Auf dem Weg zur wahrscheinlich zuk\u00fcnftigen Po-\nsition des Gegners muss immer wieder im ganzen Level verstreuten statischen Hindernissen ausgewichen\nwerden. Hierzu muss die Verfolgung der Route zur prognostizierten Position des Gegners hin und wie-\nder unterbrochen werden und durch tempor\u00e4re Ausweichbewegungen ersetzt werden, die im Anschluss\ndaran wieder fortgesetzt werden kann. W\u00e4hrend der Verfolgung des Pfades oder dem Ausweichen von\nHindernissen werden die dazu berechneten Steering -Vektoren an die Locomotion -Ebene weitergeben, die\ndiese letzten Endes in eine konkrete Fortbewegung und Ausf\u00fchrung von Bewegungsanimationen des vir-\ntuellen K\u00f6rpers des Agenten umsetzt.\n16 2 Grundlagen3 Verwandte Ans\u00e4tze\nDas Ziel dieser Master-Thesis ist die realistische Lasterzeugung durch Verwendung computergesteuerter\nSpieler bzw. einer Game AI , welche die Steuerung dieser Spieler \u00fcbernimmt. Wie bereits in der Einleitung\nangedeutet, ist dies im Kontext der Evaluation von P2P-Overlays nur eine von vielen M\u00f6glichkeiten zur\nLasterzeugung. Abschnitt 3.1 \u201eMethoden zur Lasterzeugung in Spielen\u201c stellt alternative Methoden und\nVerfahren zur Lasterzeugung in anderen Projekten vor.\nDer Rest dieses Kapitels behandelt Konzepte, Methoden oder konkrete Verfahren zur Entwicklung einer\nGame AI oder deren wichtigsten Komponenten. Mit dem Konzept eines rationalen Agenten aus 2.3 wurde\nbereits ein allgemeing\u00fcltiges Modell vorgestellt, das als Grundlage zur weiteren Konzeptionierung einer\nGame AI -Architektur herangezogen werden kann. Die in Abschnitt 5.2 pr\u00e4sentierte Game AI -Architektur\nder im Rahmen dieser Master-Thesis umgesetzten Game AI stelle genau solch eine Konkretisierung dar.\nAus diesem Grund wird in Abschnitt 3.2 \u201eHalo\u2019s AI-Architektur\u201c exemplarisch eine m\u00f6gliche alternative\nKonkretisierung des allgemeinen Architekturansatzes pr\u00e4sentiert, wie diese auch tats\u00e4chlich mit Halo in\neinem Computerspiel eingesetzt wird.\nDasDecision Making ist das Herzst\u00fcck beim Entwurf eines rationalen Agenten und deswegen auch\neines der wichtigsten Komponenten des eigenen Ansatzes. Bei der Vorstellung der f\u00fcnf Agententypen\ndes vorherigen Abschnitts 2.3, war jedes Mal die Art und Weise, wie die n\u00e4chste Aktion des Agenten\nausgew\u00e4hlt werden soll, das ausschlaggebende Unterscheidungskriterium. Mit anderen Worten: Die\nAgententypen oder konkrete Game AI -Implementierungen unterscheiden sich haupts\u00e4chlich bez\u00fcglich\nihrer Decision Making -Komponente. Es existiert eine Vielzahl von Verfahren zur L\u00f6sung dieses Problems\noder deren Unterst\u00fctzung. Einige in der Computerspielbranche popul\u00e4re Verfahren sind in Tabelle 1 auf-\ngelistet.\nDecision Making Verfahrensbezeichnung Bekannte Verwendungen in Computerspielen\nRule-Based System Baldur Gate, Virtua Fighters 2 und Halo\n(Hierarchical) Finite State Machines Warcraft III, Quake und Halo\nDecision Trees Black & White 2\nHierarchical Task Network Planning Killzone 2 und Unreal Tournament\nGoal-Oriented Action Planning F .E.A.R., S.T .A.L.K.E.R. und Empire: Total War\nBehavior Trees Halo 2, Crysis und Crysis 2\nScripting Systeme Neverwinter Nights und Unreal Tournament\nScheduling Systeme Elder Scrolls IV: Oblivion\nTabelle 1: Der Einsatz von Decision Making -Verfahren in modernen Computerspielen.\nDie in Tabelle 1 pr\u00e4sentierte Au\ufb02istung erhebt dabei keinen Anspruch auf Vollst\u00e4ndigkeit und k\u00f6nn-\nte somit noch um zahlreiche Variationen oder Erweiterungen, wie z.B. Goal Trees [24], eine Decision\nTree-Erweiterung, oder Kombinationen bekannter Ans\u00e4tze, wie z.B. das Knowledge-Based Behavior Sys-\ntem[26], ein Decision Tree /Finite State Maschine -Hybrid, beliebig erweitert werden.\nAufgrund der gro\u00dfen Menge an unterschiedlichen Decision Making -Systemen wird in Abschnitt 3.3\n\u201eGOAP - Goal-Oriented Action Planning\u201c mit der Vorstellung des GOAP-Ansatzes exemplarisch ein kon-\nkretes Decision Making -System detailliert vorgestellt. GOAP wurde aus der Kandidatenmenge gew\u00e4hlt,\n17weil es ein Verfahren darstellt, welches im Vergleich zum Behavior Tree -Ansatz, einen v\u00f6llig anderen\nL\u00f6sungsansatz mit unterschiedlichen Vor- und Nachteilen verfolgt. Die Unterschiedlichkeit zu Behavior\nTrees ist deswegen interessant, weil der eigene in den Kapiteln 4 und 5 vorgestellte Ansatz des Decision\nMaking darauf basiert.\nDasDecision Making ist nicht die einzig wichtige Aufgabe einer Game AI . Wie bereits in Kapitel 2\nerw\u00e4hnt, ist das entwickelte Game AI -Konzept der Master-Thesis ebenfalls eine Erweiterung des reynold-\nschen Modells aus Abschnitt 2.4 und somit die Umsetzung und Kombinierung von Steering Behaviors\neine weitere wichtige Aufgabe der entwickelten Game AI . Abschnitt 3.4 \u201eVerfahren zur Kombinierung\nvon Steering Behaviors\u201c pr\u00e4sentiert alternative Methoden zur Kombinierung von Steering Behaviors .\nDer letzte Abschnitt 3.5 \u201eVorg\u00e4nger-Implementierung: DragonBot\u201c pr\u00e4sentiert den von der Vorg\u00e4nger-\nImplementierung umgesetzten Ansatz. Des Weiteren erfolgt in hier eine Untersuchung der Erf\u00fcllung der\nin der Einleitung de\ufb01nierten Ziele der Master-Thesis. Die Vorg\u00e4nger-Implementierung spielt vor allem in\nder Evaluation des eigenen Ansatzes eine wichtige Rolle.\n3.1 Methoden zur Lasterzeugung in Spielen\nNeben dem relativ neuen und im Rahmen dieser Master-Thesis zu realisierenden Ansatz der Verwendung\nvon computergesteuerten kontext-sensitiven Spielern existieren derweil noch zwei weitere Ans\u00e4tze zur\nErzeugung einer realistischen Netzwerklast, der sich auch der Gro\u00dfteil der bisherigen Verfahren zuord-\nnen l\u00e4sst.\nDer erste Ansatz bezeichnet dabei die direkte Benutzung von statischen Game-Traces. Game-Traces\nsind dabei als Aufzeichnungen tats\u00e4chlicher von Menschen durchgef\u00fchrter Spielpartien zu verstehen.\nDiese Game-Traces k\u00f6nnen unterschiedlichste Informationen enthalten, wie z.B. s\u00e4mtliche durchgef\u00fchr-\nte Aktionen eines jeden Spielers zu jedem Zeitpunkt im Spiel oder die jeweils variierende Anzahl der\nNachbarn des vom Spieler repr\u00e4sentierten Peers. Zumeist beschr\u00e4nken sich allerdings die Game-Traces\nauf von der Applikationsebene und somit von der konkreten Spielmechanik unabh\u00e4ngigen Informatio-\nnen, wie z.B. der Positionsangabe eines jeden Spielers zu jedem Zeitpunkt im Spiel. Die zwei gr\u00f6\u00dften\nNachteile des Einsatzes von statischen Game-Traces sind, neben dem kosten- und zeitaufwendigen Erstel-\nlungsprozess oder der Abh\u00e4ngigkeit des Vorhandenseins, entsprechend der eigenen W\u00fcnsche, passender\nGame-Traces, die nicht vorhandene Skalierbarkeit und Kon\ufb01gurierbarkeit/Parametrisierbarkeit der er-\nzeugten Last. Die Vorteile sind hingegen die gew\u00e4hrleistete Reproduzierbarkeit der erzeugten Last,\nsowie die berechtigte Annahme dass diese so erzeugte Last per se als realistisch angesehen werden\nkann.\nIn [2] wird die Evaluierung des darin vorgestellten Anti-Cheating-Protokolls f\u00fcr P2P-Overlays mit eben\njenem Ansatz der direkten Verwendung von statischen Game-Traces realisiert. Dazu werden Simulatio-\nnen basierend auf den Game-Traces von Spielpartien mit jeweils 10, 25, 50, und 75 Spielern des Spiels\nXPilot [52] durchgef\u00fchrt. Pro Simulation wird anhand der Daten eines Game-Traces das Spiel nach-\ngespielt, es werden allerdings zus\u00e4tzlich vereinzelt Cheat-Versuche eingef\u00fcgt. Cheat-Versuche sind in\ndiesem Kontext unerlaubte Lese- oder Schreiboperationen oder gar Blockierungsversuche der zwischen\nden Peers ausgetauschten Spielnachrichten.\nDie Alternative zum ersten Ansatz ist die Ableitung von sogenannten Mobility - oder Behavior -Modellen\nanhand einer Vielzahl von zugrunde liegenden Game-Traces. Mit einem solchen Modell kann dann die\nentstehende Last, entsprechend eingestellter Parameter, wie z.B. der Spieleranzahl, approximiert wer-\nden. Der Vorteil dabei ist, dass nachdem ein Modell einmal aufgestellt worden ist, das eigentliche Spiel\nzur Lasterzeugung nicht mehr ben\u00f6tigt wird. Die Last wird derweilen nur noch simuliert bzw. berechnet.\n18 3 Verwandte Ans\u00e4tzeDie einfachste und bekannteste Form eines solchen Modells ist das Random Waypoint Mobility Modell\n(RWP) [23].\nBeim RWP-Modell wird jeweils zuf\u00e4llig ein Punkt auf der Karte ausgew\u00e4hlt und sich zu diesem ge-\nradewegs mit konstanter Geschwindigkeit hinbewegt. Am ausgew\u00e4hlten Punkt angekommen wird eine\ngewisse Zeit abgewartet, um im Anschluss daran erneut einen zuf\u00e4lligen Punkt auszuw\u00e4hlen und sich\nzu diesem hinzubewegen. Dieser Vorgang wird dann entsprechend endlich oft wiederholt. Abbildung\n4 (a) zeigt wie ein durch das RWP-Modell entstandenes Bewegungsverhalten f\u00fcr eine Quake 2 -Partie\n(FPS-Spiel) aussehen k\u00f6nnte. Abbildung 4 (b) zeigt hingegen wie das Referenz-Bewegungsverhalten ei-\nner echten Spielepartie Quake 2 im Vergleich dazu auszusehen hat. Der Vergleich beider Abbildungen\nzeigt, dass das RWP Model, obwohl es sich mit der Nachbildung der Bewegung nur auf einen Aspekt\nbei der Generierung der Netzwerklast beschr\u00e4nkt, dennoch gro\u00dfe Ungenauigkeiten aufweist. Die zwei\nauffallendsten M\u00e4ngel sind dabei die fehlende oder fehlerhafte Erfassung von Points ofInteressts (POI)\nund die Beschr\u00e4nkung auf ausschlie\u00dflich gerade Bewegungsabl\u00e4ufe.\nAbbildung 4: (a) Nachbildung des Bewegungspro\ufb01ls der Quake 2 -Partie aus (b) mit dem RWP-Modell. (b) Bewe-\ngungspro\ufb01l einer echten Quake 2 -Partie. Beide Gra\ufb01ken entnommen aus [53].\nAufgrund dieser oder weiterer M\u00e4ngel des RWP-Modells wurden zahlreiche Modi\ufb01kationen entwickelt\nund in anderen Projekten wie VON [19] oder MOPAR [60] eingesetzt. Einige Beispiele f\u00fcr derartige Mo-\ndi\ufb01kationen sind beispielsweise die Hinzunahme von zuf\u00e4lligen Interaktionen, wie Hitsoder Shoots , oder\nEreignissen, wie Deaths oder Respwans . Einige Modi\ufb01kationen bzw. Erweiterungen des RWP-Modells un-\nterst\u00fctzen auch die Ansteuerung von zuvor aus echten Game-Traces ausgemachten POIs oder ungerade\nbzw. kurvige Bewegungsabl\u00e4ufe. Das Networked Game Mobility Model (NGMM) [53] ist eine solche\nRWP-Modell-Erweiterung, die die beiden Letzt genannten Modi\ufb01kationen vornimmt.\nZum Erreichen der POI-Ansteuerung wird in einem vorgelagerten Pre-Processing -Schritt eine m\u00f6glichst\ngro\u00dfe Menge an Referenz-Game-Traces verarbeitet und anhand eines Popularit\u00e4tsmodells die Punkte auf\nder Karte bestimmt, die in den Game-Traces besonders h\u00e4u\ufb01g besucht worden sind. Aus diesen Daten\nwird daraufhin die Welt in station\u00e4re und mobile Punkte bzw. Areale unterteilt. Station\u00e4re Areale sind\ndie identi\ufb01zierten POIs und dienen als Ansteuerungspunkte f\u00fcr das zugrundliegende RWP-Modell. Der\nRandom Walks zwischen den station\u00e4ren Arealen ist allerdings nicht mehr komplett zuf\u00e4llig. Zur Aus-\nwahl wird n\u00e4mlich eine Verteilungsfunktion verwendet, die die zuvor gemessene Popularit\u00e4t eins POIs\nund die Entfernung zur aktuellen Position ber\u00fccksichtigt. Die Unterst\u00fctzung von nicht ausschlie\u00dflich ge-\nraden Bewegungsabl\u00e4ufen wird erreicht indem in den mobilen Arealen, die sich jeweils zwischen Paaren\nvon station\u00e4ren Arealen be\ufb01nden, die Methode der kleinsten Quadrate angewandt wird. Dabei wird ver-\nsucht eine m\u00f6glichst genaue Kurvenanpassung an die tats\u00e4chlichen Positionen der Game-Traces, die sich\ninnerhalb eines mobilen Areals be\ufb01nden, vorzunehmen und die somit gefundene Kurve als Bewegungs-\n3.1 Methoden zur Lasterzeugung in Spielen 19grundlage zu verwenden. Abbildung 5 zeigt ein mit NGMM entstandenes Bewegungspro\ufb01l, welches unter\ndenselben Bedingungen wie zuvor auch die Abbildungen 4 (a) und (b) entstanden sind.\nAbbildung 5: Nachbildung des Bewegungspro\ufb01ls der Quake 2 -Partie aus 4 (b) mit dem NGMM-Modell. Gra\ufb01k\nentnommen aus [53].\nNGMM oder vergleichbare L\u00f6sungen dieses Ansatzes erf\u00fcllen zumeist mit der Reproduzierbarkeit und\nder Skalierbarkeit zwei der vier in der Einleitung vorgestellten Bewertungskriterien zur Erzeugung einer\nrealistischen Netzwerklast. Die Reproduzierbarkeit ist dabei durch den deterministischen Erzeugungs-\nprozess der Daten gegeben und die Skalierbarkeit durch die allgemeine Anwendbarkeit des Modells\ngesichert. Die M\u00f6glichkeit der Skalierbarkeit in Bezug auf Spieleranzahl oder diverser anderer Para-\nmeter, wie z.B. bei NGMM der zu verwendeten probabilistischen Verteilungsfunktion, lassen ebenfalls\nauf eine gewisse Kon\ufb01gurierbarkeit des Ansatzes schlie\u00dfen. Womit drei der vier Bewertungskategori-\nen erf\u00fcllt scheinen. Der Nachteil dieses Ansatzes ist jedoch die weiterhin zu starke Simpli\ufb01zierung der\nLasterzeugung von Computerspielen, die mit einer Ungenauigkeit der Ergebnisse und somit einem ver-\nbesserungsw\u00fcrdigen Realit\u00e4tsgrad einhergeht. Selbst aufwendigere Modelle wie das NGMM, das einige\nAspekte der Applikationsebene wie z.B. POIs ber\u00fccksichtigt, wei\u00dft immer noch erkennbare Ungenauig-\nkeiten auf, wie u.a. der Vergleich von Abbildung 5 und Abbildung 4 (b) exemplarisch veranschaulicht.\nEin Computerspiel besteht, wie unter 2.1 aufgef\u00fchrt, aus weit mehr als Bewegungsabl\u00e4ufen oder sim-\nplen zuf\u00e4lligen Verhaltensmustern. Gerade die Komplexit\u00e4t der Spielwelt und die Vielzahl an Interakti-\nonsm\u00f6glichkeiten, sowie besonders das Zusammenspiel der Interaktionen untereinander zeichnen mo-\nderne Computerspiele aus und m\u00fcssen dementsprechend in der Lasterzeugung ber\u00fccksichtigt werden.\nBesonders der letztgenannte Punkt verlangt nach der Notwendigkeit der Reaktionsf\u00e4higkeit, statt der in\nMobility - bzw. Behavior -Modellen modellierten Form des blinden Aktionismus, welcher zu zuf\u00e4lligen und\nsomit voneinander losgel\u00f6sten Spielaktionen f\u00fchrt.\nDer Begriff Reaktion beschr\u00e4nkt sich in diesem Kontext nicht nur auf Aktionen, wie das Erwidern\ngegnerischen Feuers, sondern erfasst auch den Entschluss zu kooperativen Verhalten. Beabsichtigt bei-\nspielsweise eine Gruppe von Spielern m\u00f6glichst nah beieinander zu bleiben, um sich zusammen dem\nGegner zu stellen, so ist dies ebenfalls als eine Spielaktion zu bewerten und sollte dementsprechend\nvon einem Modell zur Lasterzeugung erfasst werden. Das kooperatives Verhalten signi\ufb01kante Auswir-\nkungen auf die erzeugte Last haben kann, l\u00e4sst sich u.a. an der Tatsache festmachen, das im erw\u00e4hnten\nBeispiel die Kollektivbildung unmittelbare Konsequenzen auf die Anzahl der Nachbarn h\u00e4tte, was wie-\nderum ma\u00dfgeblich die Menge der auszutauschenden Nachrichten innerhalb einer AOI bestimmt. Eine\nweitere Schw\u00e4che dieses Ansatzes ist es, dass die Modelle auf einer endlichen Menge von Spielinstan-\n20 3 Verwandte Ans\u00e4tzezen bzw. Game-Traces beruhen. Spielsituationen die in dieser Menge von Spielinstanzen nicht enthalten\nwaren oder nur in einer unzureichenden Anzahl, werden in einem zusammenfassenden oder m\u00f6glichst\nallgemeing\u00fcltigen Modell nicht erfasst [30].\nUm den aufgef\u00fchrten Nachteilen entgegenzuwirken wird mit dem Ansatz der computergesteuerten\nSpieler in Planet PI4 ein anderer Ansatz zur Lasterzeugung verfolgt. Ein erster Realisierungsversuch\ninPlanet PI4 wurde mit der Vorg\u00e4nger-Implementierung bereits in Abschnitt 3.5 vorgestellt. Dar\u00fcber\nhinaus existieren nur vereinzelt andere Projekte wie Colyseus [5] oder Donnybrook [6] die ebenfalls\nauf Bot-Nutzungen setzen. Sowohl Colyseus als auch Donnybrook benutzen Quake 3 als Evaluationsum-\ngebung und setzen dabei beide auf modi\ufb01zierten Standard Quake 3 -Bots zur Lasterzeugung. Colyseus\nverwendet zus\u00e4tzlich dazu noch Quake 2 und ein Eigenentwicklung, sowie entsprechende Bots zu Eva-\nluationszwecken. In Colyseus verwenden die modi\ufb01zierten Quake 3 -Bots benutzen zur Fortbewegung ein\nObstacle-Sensitive Mobility Model basierend auf Voronoi-Diagrammen. Die Ausf\u00fchrung mancher Aktio-\nnen, wie der Kampfentschluss oder die Ansteuerung von POIs, sind von Wahrscheinlichkeiten abh\u00e4ngig\ndie aus echten Game-Traces ermittelt worden sind. Andere Aktionen hingegen basieren v\u00f6llig auf den\nEntscheidungen des Bots, so z.B. das konkrete Kampfverhalten, welches Aspekte wie Ausweichbewegun-\ngen oder Zielen und Schie\u00dfen miteinschlie\u00dft.\nWas f\u00fcr Modi\ufb01kationen in Donnybrook eingesetzt werden ist nicht n\u00e4her angegeben. Da es sich hierbei\num ein Folgeprojekt von Colyseus handelt, kann davon ausgegangen werden, dass entweder dieselben\noder \u00e4hnliche Bots zum Einsatz kommen. Erw\u00e4hnenswert ist hingegen, dass in Donnybrook der Bot-\nAnsatz nicht ausschlie\u00dflich zur Lasterzeugung oder Evaluationszwecken Verwendung \ufb01ndet. Donnybrook\npr\u00e4sentiert mit sogenannten interest sets eine Alternative zu rein auf den Sichtradius beschr\u00e4nkten AOIs.\nSpieler die sich im interest set eines Peers be\ufb01nden bilden eine echte Untermenge der aktuell sichtbaren\nSpieler und repr\u00e4sentieren weiter die Spieler, dessen Aktionen aktuell die gr\u00f6\u00dfte Aufmerksamkeit des\ndurch den Peer vertretenen Spielers genie\u00dfen. In Anlehnung an die Limitierung der menschlichen Auf-\nmerksamkeit auf einige wenige unterschiedliche Aspekte gleichzeitig, wird die Anzahl der Spieler mit\nmaximal f\u00fcnf im interest set entsprechend klein gehalten. Die restlichen sichtbaren Spieler k\u00f6nnen der-\nweil nicht v\u00f6llig ignoriert werden, da ihre Aktionen nun einmal sichtbar sind und der Vollst\u00e4ndigkeits-\nhalber ebenfalls dargestellt werden m\u00fcssen. Weil diese Aktionen allerdings nicht so sehr vom Spieler\nbeachtet werden, kann an dieser Stelle eine h\u00f6her auftretende Ungenauigkeit eher toleriert werden als\nbei den Spielern im interest set die sich im Fokus des Spielers be\ufb01nden. Zur Erzielung einer weiteren Re-\nduzierung der ausgetauschten Menge an Spielinformationen und damit die sichtbaren Spieler die nicht\niminterest set liegen ein f\u00fcr den Spieler konsistentes und \ufb02\u00fcssiges Verhalten aufweisen, werden leichtge-\nwichtige Bots, sogenannte Doppelg\u00e4ngers, eingesetzt. Dabei wird mit Hilfe der bisherigen Informationen\n\u00fcber das Verhalten des zu simulierenden Spielers, die wahrscheinlich als n\u00e4chstes vom ihm auszuf\u00fch-\nrenden Aktionen soweit bestimmt und stellvertretend ausgef\u00fchrt, bis wieder neue Informationen \u00fcber\ndas tats\u00e4chliche Verhalten des Spielers vorliegen, die diese stellvertretend ausgef\u00fchrten Aktionen ent-\nweder best\u00e4tigen oder revidieren, sodass etwaige Korrekturen vorgenommen werden m\u00fcssen. Sei es zu\nEvaluationszwecken oder zur Verhaltenssimulierung in Anwesenheit unvollst\u00e4ndiger Spielerinformatio-\nnen, beiden Ans\u00e4tze zur Bot-Benutzung haben eines gemeinsam: Die Realisierung m\u00f6glichst realistischen\nmenschlichen Verhaltens.\n3.2 Halo\u2019s AI-Architektur\nHalo ist eine von Bungie entwickelte und von Microsoft vertriebene \u00fcberaus erfolgreiche FPS-\nComputerspieleserie. Der erste Teil erschien 2002 f\u00fcr die Videospielkonsole Xbox und 2003 f\u00fcr den PC.\nDem ersten Teil folgten sehr bald zwei weitere of\ufb01zielle Nachfolger und einige weitere Ableger, sowie\neine Film-Adaption. Wie es in FPS-Spielen \u00fcblich ist, muss der Spieler in Halo eine Vielzahl unterschied-\n3.2 Halo\u2019s AI-Architektur 21licher Gegner bek\u00e4mpfen, die sich in Verhalten, Ausr\u00fcstung und Aussehen voneinander unterscheiden.\nEin wesentliches Spielelement von Halo ist die Benutzung unterschiedlicher Fahrzeugtypen im Kampf.\nDie Fahrzeug-Benutzung ist jedoch nicht Spieler exklusiv. Sowohl KI-Mitspieler, als auch die KI-Gegner\nbeherrschen die Benutzung. Die Fahrzeuge k\u00f6nnen dabei auch gemeinsam bedient werden. Ein Beispiel\nhierf\u00fcr w\u00e4re ein vom Spieler gesteuerter Buggy auf dessen Lade\ufb02\u00e4che ein KI-Kamerad am befestigten\nMG die gegnerischen Truppen ins Visier nimmt.\nHalo undHalo 2 liegt zur Bew\u00e4ltigung dieser Aufgaben dieselbe in Abbildung 6 dargestellte Game AI -\nArchitektur zugrunde. Mit der vorgenommenen \u00fcbergeordneten Vierteilung in World ,Perception ,Motion\nundActor l\u00e4sst sich leicht das in Abschnitt 2.3 vorgestellte Konzept eines rationalen Agenten wiederer-\nkennen. Demnach nimmt der Agent bestimmte unge\ufb01lterte Wahrnehmungen ( Perceptions ) der Welt um\nsich herum wahr, stellt daraufhin einige Berechnungen zur Bestimmung der besten n\u00e4chsten Aktion an\n(Decision Making ) und f\u00fchrt abschlie\u00dfend dann diese \u00fcber sein Motion-System bzw. seine Aktuatoren\naus. Im Agenten selbst werden im ersten Schritt die rohen Wahrnehmungen \u00fcber die Welt auf ihre Rele-\nvanz hin \u00fcberpr\u00fcft und in eine, dem Weltmodel des rationalen Agenten \u00e4hnliche, Memory -Komponente\nzwischengespeichert. Die Memory -Komponente enth\u00e4lt demnach f\u00fcr die anschlie\u00dfende Situationsanaly-\nse nicht nur Informationen \u00fcber den aktuellen Weltzustand (aktuelle Wahrnehmungen), sondern auch\nausgew\u00e4hlte vergangene Informationen fr\u00fcherer Wahrnehmungen oder andere f\u00fcr den Kontext der Si-\ntuationsanalyse ben\u00f6tigter Informationen. Hauptaufgabe der Situationsanalyse ist es gem\u00e4\u00df der ihr zur\nVerf\u00fcgung stehenden Informationen \u00fcber die Welt und des aktuellen Emotionszustandes, welches haupt-\ns\u00e4chlich die Auswahl der verwendeten Dialognachrichten eines Bots beein\ufb02usst, sogenannte Stimuli zu\nerzeugen. Stimuli stellen vereinfachend ausgedr\u00fcckt eine Art Event dar, wie z.B. \u201eFind Enemy\u201c, \u201eSearch\na friend\u201c, \u201eDamaged\u201c oder \u201ePlayer \ufb01red!\u201c, welche an die Decision Making -Komponente weitergereicht\nwird, damit diese eine zum Stimuli und zum Bot-Typ passende Aktion bestimmen kann, die als n\u00e4chstes\n\u00fcber das Motion-System ausgef\u00fchrt werden soll [22, 9].\nAbbildung 6: Die Game AI-Architektur von Halo. Entnommen aus [9].\nDie konkrete Decision Making -Komponente ist der Hauptunterscheidungspunkt zwischen Halo und\nHalo 2 . W\u00e4hrend Halo auf einen Mix aus Rule-Based System undFinite-State Machine setzt, verwendet\nHalo 2 eine erweiterte Form eines Behavior Trees . Ein Rule-Based System oder auch Expertensystem ist ein\n22 3 Verwandte Ans\u00e4tzeauf einer Menge von Regeln, bestehend aus if/then -Statements, und einer Datenbank mit Informationen\n\u00fcber die aktuelle Welt basierendes System, das \u00fcber einen Matching-Algorithmus bestimmt welche der\nRegeln gem\u00e4\u00df der der Datenbankinformationen aktuell am besten zutrifft. Jede Regel ist wiederum mit\neiner entsprechenden Aktion verkn\u00fcpft die beim erfolgreichen matchen einer Regel ausgef\u00fchrt werden\nsoll. Ein FSM bzw. endlicher Automat ist im Grunde ein gerichteter Graph mit einer endlichen Anzahl an\nZust\u00e4nden und Transitionen. Er verh\u00e4lt sich somit \u00e4hnlich einem Baum, in dem Kanten in alle Richtungen\nund in beliebiger, aber endlicher, Zahl erlaubt sind. \u00c4hnlich zum Wurzelknoten eines Baumes muss jeder\nEndlicher Automat einen Startzustand und, analog zu den Bl\u00e4ttern eines Baumes, mindestens einen\nEndzustand auszeichnen. Zust\u00e4nde im Allgemeinen beschreiben auf abstrakte Weise das Verhalten des\nBots. Die Transitionen erm\u00f6glichen Zustands\u00fcberg\u00e4nge bzw. im Kontext des Bots Verhaltens\u00e4nderungen\n\u00fcber das Ausf\u00fchren von mit dem jeweiligen Zustand assoziierten Aktionen. Das von Halo 2 eingesetzte\nKonzept der Behavior Trees \ufb01ndest ebenfalls im eigenen Ansatz Verwendung, welcher im Rahmen dieser\nMaster-Thesis entstanden ist, und wird dementsprechend in Kapitel 4 ausf\u00fchrlich behandelt.\n3.3 GOAP - Goal-Oriented Action Planning\nGOAP ist ein von Jeff Orking f\u00fcr den First-Person Shooter F .E.A.R. (First Encounter Assault Recon) aus\ndem Jahre 2005 entwickelter Planer. Die f\u00fcr Computerspiele damals fortschrittliche KI war einer der\nGr\u00fcnde, warum F .E.A.R. u.a. von Gamespy als eins der Top-10 PC-Spiele des Jahres 2005 ausgezeichnet\nwurde5. Der GOAP-Planer ist zwar eine konkrete Implementierung die auf F .E.A.R. zugeschnitten wur-\nde, doch ver\u00f6ffentliche Orking zahlreiche Papers zum allgemeinen Ansatz seines GOAP-Planers, sodass\nseitdem auf den GOAP-Prinzipien beruhende Planer erfolgreich in mehreren modernen Computerspielen\nwieFallout 3 ,Empire: Total War oder Silent Hill: Homecoming eingesetzt werden konnten [37, S. 1].\nGOAP ist eine vereinfachte, allerdings an manchen Stellen auf erweiterte [39, S. 10-13], Version des\nSTRIPS6Planning -Systems der Stanford University aus dem Jahr 1970 [39, S. 4f]. Die Aufgabe eines\nSTRIPS-Planers oder generell irgendeines Planers ist nach Russel [46, S. 465f] de\ufb01niert als die Su-\nche nach einer Aktionsfolge von einer Ausgangssituation zu einer gew\u00fcnschten Zielsituation. Jeder\nZustands\u00fcbergang repr\u00e4sentiert dabei einen der m\u00f6glichen Folgezust\u00e4nde, welcher durch Ausf\u00fchrung\neiner entsprechenden Aktion des Agenten in der virtuellen Welt erreicht werden kann. Der Pfad zum\nZielknoten stellt dementsprechend die gesuchte Aktionsfolge vom Start- zum Zielzustand dar. Ruft man\nsich das in 2.3 vorgestellte Konzept eines rationalen Agenten wieder in Ged\u00e4chtnis zur\u00fcck, l\u00e4sst sich\nGOAP bzw. irgendein Planning -System als m\u00f6glicher Bestandteil der Decision Making -Komponente be-\ntrachten. Stellt es doch eine M\u00f6glichkeit der Auswahl der besten als n\u00e4chstes auszuf\u00fchrenden Aktion\ndar. Mit einer auf der C4++-Architektur des MIT [22, 21] basierenden Erweiterung, die Orking in [38]\nvorstellt, \ufb01ndet der GOAP-Planer als wichtigster Bestandteil der Decision Making -Komponente eben jene\nVerwendung in einem zum Konzept eines rationalen Agenten vergleichbaren \u00fcbergeordneten Ansatz.\nDas Herzst\u00fcck eines Planers ist dabei die verwendete formale Repr\u00e4sentation zur Zustands- und Ak-\ntionsbeschreibung. Sie bestimmt Ma\u00dfgeblich die M\u00e4chtigkeit des Planers, weil diese Art und Umfang\nder dem Planer zur Verf\u00fcgung stehenden Informationen bestimmt, welche wiederum zur dynamischen\nReduzierung des Suchraums genutzt werden k\u00f6nnen. Da diese eine \u00dcberpr\u00fcfung irrelevanter Aktionen\nerm\u00f6glichen, deren Folgezust\u00e4nde mit hoher Wahrscheinlichkeit nicht zum Ziel f\u00fchren und somit ver-\nworfen werden k\u00f6nnen. Eine Repr\u00e4sentation von Planungsproblemen sollte die logische Struktur des\nProblems erfassen, damit weitestgehend auf zus\u00e4tzliches Expertenwissen zur Suchraumverkleinerung\nverzichtet werden kann. Das Ziel ist es dabei eine Sprache zu \ufb01nden die Ausdrucksstark genug ist, um\n5Siehe f\u00fcr die Top-10 PC-Spiele Liste aus dem Jahr 2005: http://goty.gamespy.com/2005/pc/index6.html\n6STRIPS steht f\u00fcr Stanford Research Institute Problem Solver und bezeichnete 1970 zun\u00e4chst den Planer. Sp\u00e4ter jedoch\netablierte sich der Begriff STRIPS als Bezeichnung f\u00fcr die im STRIPS-Planer eingesetzte Repr\u00e4sentationsbeschreibung\nder Problemdom\u00e4ne.\n3.3 GOAP - Goal-Oriented Action Planning 23eine Vielzahl von Problemen abzudecken, aber dabei gleichzeitig einschr\u00e4nkend genug bleibt, um L\u00f6-\nsungen ef\ufb01zient bestimmen zu k\u00f6nnen. Es existiert eine Menge an unterschiedlichen Repr\u00e4sentationen,\ndie sich anhand dieser beiden Dimensionen unterscheiden lassen. Die von GOAP verwendete Repr\u00e4sen-\ntationsbeschreibung ist dabei eine abgewandelte Form des STRIPS -Planers und besteht nach Russel [46,\nS. 467f] aus folgenden Elementen:\n\u2022Zustand: Beschreibung eines Weltzustands anhand logischer Bedingungen in Form einer Konjunk-\ntion funktionsfreier Grundliterale. Es gilt weiter die Annahme der geschlossenen Welt, d.h. alle\nBedingungen, die in einem Zustand nicht erw\u00e4hnt werden, werden als falsch angenommen. Bei-\nspiel: Arm^Krank k\u00f6nnte den Zustand eines vom Gl\u00fcck verlassenen Agenten repr\u00e4sentieren.\n\u2022Ziel: Ein partiell spezi\ufb01zierter Zustand, der als Konjunktion positiver Grundliterale repr\u00e4sentiert\nwird. Beispiel: Der Zustand: Reich^Ber\u00fchmt^Ungl\u00fccklich erf\u00fcllt das Ziel: Reich^Ber\u00fchmt .\n\u2022Aktion: Eine Aktion oder Aktionsschema besteht aus folgenden drei Bestandteilen:\n\u2013 Bezeichner: Aktionsname und Parameterliste zur Identi\ufb01zierung. Beispiel: Fliegen(p, von,\nnach)\n\u2013 Vorbedingung(en): Konjunktion funktionsfreier positiver Grundliterale, die angeben, was in\neinem Zustand gelten muss, damit die Aktion ausgef\u00fchrt werden kann. Alle Literale m\u00fcssen\nauch in der Parameterliste erscheinen.\n\u2013 Effekt(e): Konjunktion funktionsfreier Grundliterale, die angeben, wie sich Zust\u00e4nde ver\u00e4n-\ndern, nachdem die Aktion ausgef\u00fchrt wurde. Alle Literale m\u00fcssen auch in der Parameterliste\nerscheinen.\nEine Aktion ist damit in jedem Zustand genau dann anwendbar, wenn alle Vorbedingungen die-\nser erf\u00fcllt sind. Durch die Anwendung einer Aktion wird der Zustand in einen Folgezustand unter\nAnwendung der Effekte \u00fcberf\u00fchrt, wobei nicht erw\u00e4hnte Literale unver\u00e4ndert bleiben ( STRIPS -\nAnnahme). Wenn die Vorbedingungen einer Aktion nicht erf\u00fcllt sind, kann diese auch nicht ange-\nwendet werden und somit auch keine \u00dcberf\u00fchrung in einen Folgezustand bewirken.\nMit der eben spezi\ufb01zierten STRIPS-Repr\u00e4sentation ist es nun m\u00f6glich das Ausgangsproblem, das Fin-\nden einer Aktionsfolge von einem Startzustand zu einem Zielzustand, angemessen zu beschreiben und\nzu l\u00f6sen. Dabei handelt es sich beim Zielzustand nicht ausdr\u00fccklich um ein konkretes Ziel, sondern\num einen Weltzustand der das jeweils aktuelle Ziel erf\u00fcllt. Beim GOAP-Planer handelt es sich um einen\nsogenannten regressiven Zustandsraumplaner. Vereinfachend ausgedr\u00fcckt kann man sich Planen im Zu-\nstandsraum als ein Wege- bzw. Navigationsproblem in einem Graphen vorstellen, bei dem jeder Knoten\neinen vom Startzustand tats\u00e4chlich erreichbaren Weltzustand darstellt und jede Kante die entsprechen-\nde Aktion zur Zustands\u00fcberf\u00fchrung. Aufgrund der bereitgestellten Informationen \u00fcber das Planungs-\nproblem ist es nun m\u00f6glich in jede Richtung zu suchen bzw. zu planen. Die R\u00fcckw\u00e4rts-Zustandssuche\noder Regressionsplanung sucht dabei in die entgegengesetzte Richtung, d.h. vom einem zielerf\u00fcllenden\nEndzustand aus den aktuellen Startzustand.\nDer dabei verwendete Suchalgorithmus ist eine A*-Suche, die in Computerspielen h\u00e4u\ufb01g im Bereich\ndes Path\ufb01ndings eingesetzt wird. Aufgrund der gleichartigen Probleml\u00f6sungsdom\u00e4ne kann die A*-Suche\njedoch hier ebenfalls verwendet werden. Die Kostenfunktion entspricht dabei nicht der Streckendistanz\nvon einem Knoten zum anderen, sondern berechnet sich aus den Kosten der Ausf\u00fchrung einer Aktion.\nDa sowohl Ziele durch einfache Literale beschrieben werden, als auch die durch einen Knoten repr\u00e4-\nsentierten Weltzust\u00e4nde, berechnet die Heuristik-Funktion einfach die Menge der unerf\u00fcllten Literale\nvon einem Zustand zum Ziel aus. Zusammengefasst sucht der GOAP-Planer mit der A*-Suche die Akti-\nonsfolge die ausgehend vom Zielzustand den aktuellen Startzustand erreicht und dabei die geringsten\nAktionskosten aufweist [37, S. 4-8].\n24 3 Verwandte Ans\u00e4tzeEin Beispiel soll den eben vorgestellten Planning -Prozess von GOAP zusammenfassend verdeutlichen.\nDazu stelle man sich folgendes Szenario mit dem Ziel KillTargetEnemy vor, bestehend aus einer einzigen\nBedingung: kTargetIsDead = true und den aktuellen Weltzustand mit den drei Bedingungen: kCoverI-\nsUsed=false^kTargetIsDead=false ^kWeaponIsLoaded=false vor. Erster vor der eigentlichen Planung\nauszuf\u00fchrender Schritt ist die Auswahl des zu verfolgenden Ziels. In GOAP werden Ziele nach einer\nnummerischen Priorit\u00e4t sortiert. Da in dem Beispiel nur ein Ziel existiert wird dieses als aktuelles Ziel\nausgew\u00e4hlt. N\u00e4chster Schritt ist es einen m\u00f6glichen Weltzustand zu \ufb01nden der das ausgew\u00e4hlte Ziel er-\nf\u00fcllt. In Abbildung 7 ist der oberste Zustand, beschrieben durch die Bedingungen kCoverIsUsed=false ^\nkTargetIsDead=true ^kWeaponIsLoaded=true ein solch m\u00f6glicher Zustand. Ausgehend von diesem Ziel-\nzustand, der nun den Startzustand der Suche darstellt, wird dann im n\u00e4chsten Schritt regressiv nach\neiner Aktionsfolge gesucht die zum aktuellen Weltzustand f\u00fchrt, dem Zielzustand der Suche. Dazu wer-\nden alle Aktionen betrachtet die zum aktuellen Suchzustand, im ersten Schritt der Zustand der das Ziel\nerf\u00fcllt, f\u00fchren. Existiert keine direkte Aktion die zum aktuellen Weltzustand, dem Zielzustand, f\u00fchrt,\nm\u00fcssen nach und nach die Suchzust\u00e4nde untersucht werden die eine Mindest-Ann\u00e4herung von jeweils\neiner \u00fcbereinstimmenden Bedingung an die Bedingungsmenge des Zielzustandes bedeuten. Dabei d\u00fcr-\nfen im jeweiligen Suchzustand nur relevante und konsistente Aktionen ber\u00fccksichtigt werden, was einen\nviel kleineren Verzweigungsfaktor als bei der Vorw\u00e4rtssuche ergibt. Eine Aktion ist genau dann relevant,\nwenn sie mindestens eine Bedingung des Ziels \u201cwahr\u201c macht, die nicht bereits im Vorg\u00e4ngerzustand als\n\u201cwahr\u201c galt. Eine Aktion ist genau dann konsistent, wenn durch ihre Ausf\u00fchrung keine anderen Ziele\nr\u00fcckg\u00e4ngig gemacht werden. In der Abbildung ist die auf diese Weise gefundene Aktionskette, erst Waffe\nladen dann schie\u00dfen, rot hervorgehoben und der aktuelle Weltzustand dementsprechend der Rechte der\nbeiden unteren Zust\u00e4nde.\nNach Orkin [37, S. 4ff] [39, S. 7-10] w\u00fcrden sich durch die in GOAP vorgenommene Trennung von\nAktionen und Zielen in Verbindung mit dem dynamischen L\u00f6sungsprozess der Planung eine Menge an\nVorteilen gegen\u00fcber anderen damals etablierten Decision Making -Konzepten ergeben. So w\u00fcrde eine\nErleichterung der Integration neuer Spielelemente existieren, ohne der sofortigen Gefahr eines Zusam-\nmenbrechen des Systems, da neue Aktions- oder Zielde\ufb01nitionen parallel zu den bisherigen Elemen-\nten hinzugef\u00fcgt werden k\u00f6nnen. Weiter k\u00f6nnten durch den Planungsprozess neue, vom Designer nicht\nber\u00fccksichtigte, L\u00f6sungen gefunden werden. Dies f\u00fchrt zu einem gesenkten Bedarf an ben\u00f6tigter Spe-\nzi\ufb01kation, zu einer besseren Wartbarkeit, Modularit\u00e4t und Skalierbarkeit. Ein weiterer Vorteil ist die\ngestiegene Variationsfreiheit, die u.a. dazu eingesetzt werden kann um leicht unterschiedliches Verhal-\nten zu de\ufb01nieren. Orkin schl\u00e4gt dazu die Variation der f\u00fcr einen NPC zur Verf\u00fcgung stehenden Aktionen\nvor und/oder die Variation der jeweils zugewiesenen Zielmenge.\nDie Nachteile beim Einsatz von GOAP sind auf der anderen Seite die Beschr\u00e4nktheit oder Komplexit\u00e4t\nder Repr\u00e4sentationssprache, die Komplexit\u00e4t bzw. der Berechnungsaufwand des Planungsprozesses und\ndie mangelnde Kontrolle \u00fcber das Verhalten der NPCs.\nDer GOAP-Planer verwendet mit STRIPS eine sehr einfache Repr\u00e4sentationssprache. Dies macht den\nPlaner entsprechend ef\ufb01zient, allerdings k\u00f6nnen damit nur sehr einfache Probleml\u00f6sungsdom\u00e4nen be-\nschrieben werden. Komplexere Weltbeschreibungen die nicht alleine oder nur sehr umst\u00e4ndlich mittels\nLiterale beschrieben werden k\u00f6nnen, f\u00fchren entweder zu Performance-Einbr\u00fcchen, weil die Anzahl an\nLiterale explodiert, oder die Problemdom\u00e4ne einfach nicht abgebildet werden kann. Zwei typische Pro-\nbleme von STRIPS sind z.B. das Rami\ufb01kationsproblem und das Quali\ufb01kationsproblem. Das Rami\ufb01kati-\nonsproblem bezeichnet die Schwierigkeit der Repr\u00e4sentation impliziter Effekte wie z.B. dem Effekt, dass\nsich Passagiere innerhalb des Flugzeuges, welches von A nach B unterwegs ist, ebenfalls mit diesem\n(indirekt) fortbewegen. Das Quali\ufb01kationsproblem bezeichnet die problematische Erfassung aller Um-\nst\u00e4nde die zum Scheitern einer Aktion f\u00fchren k\u00f6nnen. Beide Probleme k\u00f6nnen unter Anwendung der\nSTRIPS -Repr\u00e4sentation nur unzureichend oder gar nicht gel\u00f6st werden. Das Problem von anderen m\u00e4ch-\n3.3 GOAP - Goal-Oriented Action Planning 25Abbildung 7: Ein Beispiel f\u00fcr den von GOAP realisierten Entscheidungsprozess zur Auswahl der n\u00e4chsten Aktion.\nBeachtet werden sollte das die Planungsrichtung (Roter Pfeil) entgegengesetzt zur Ausf\u00fchrungs-\nrichtung ist. Angelehnt an Beispiel und eine Gra\ufb01k aus [37].\ntigeren Repr\u00e4sentationssprachen ist, dass sie sehr viel komplexer sind und dies direkten Ein\ufb02uss auf die\nPerformance des Planungsprozesses hat.\nDer Planungsprozess als solches ist ebenfalls als komplex anzusehen, was sich negativ auf die Lauf-\nzeit auswirkt. Selbst mit der von Millington in [35, S. 418-425] vorgeschlagenen Verbesserung, die sich\ndurch den Austausch des A*-Algorithmus durch den IDA*-Algorithmus ergibt, liegt die Rechenlaufzeit\nvon GOAP in O(mnd), wobei m die Anzahl der Ziele, n die Anzahl der m\u00f6glichen Aktionen und d die\nmaximale Suchtiefe bezeichnet. In stark dynamischen Welten in denen schnelle Reaktionen aufgrund\nsich stetig und rapide \u00e4ndernder Situationen erforderlich sind, wie Beispielsweise in Planet PI4 , k\u00f6nnten\ndie anfallenden Kosten f\u00fcr Planung bzw. st\u00e4ndiger Neu-Planung fatale Folgen f\u00fcr die Performance und\nSkalierbarkeit haben.\nDie mangelnde Kontrolle \u00fcber das generierte Verhalten der NPCs mag zwar zu den bereits erw\u00e4hn-\nten Vorteilen wie Wartbarkeit, Skalierbarkeit oder generell zu einer gestiegenen M\u00e4chtigkeit f\u00fchren,\nallerdings stellt es im Kontext von reproduzierbaren und kon\ufb01gurierbaren Verhaltensweisen einen\nentscheidenden Nachteil dar. Denn man k\u00f6nnte allenfalls einen indirekten Ein\ufb02uss auf den Aktions-\nAuswahlprozess aus\u00fcben und sich somit wieder ein St\u00fcck weit vom Gl\u00fcck abh\u00e4ngig machen, ob am\nEnde wirklich das gew\u00fcnschte bzw. aktuell zu testende Verhalten tats\u00e4chlich realisiert wird oder eben\ndoch vom Planer ein anderes Verhalten als der Situation angemessener angesehen wird.\n26 3 Verwandte Ans\u00e4tze3.4 Verfahren zur Kombinierung von Steering Behaviors\nEin wichtiger Punkt in der Steering -Ebene ist die Tatsache das Steering Behaviors in erster Linie nur Bewe-\ngungsvorschl\u00e4ge darstellen und erst die Evaluation, Auswahl oder Kombinierung dieser zum konkreten\nSteering -Ergebnis f\u00fchrt. Ein Problem dabei ist das bisherige Ans\u00e4tze zur L\u00f6sung dieses Problems verein-\nzelt zu suboptimalen, ungew\u00fcnschten oder schlichtweg katastrophalen Verhaltensweisen des Agenten\nf\u00fchren k\u00f6nnen, wie beispielsweise das Vorhandensein eines stabilen Equilibriums bzw. Gleichgewichts,\nwas zum v\u00f6lligen Stillstand des Agenten f\u00fchrt und nicht vom Agenten alleine wieder aufgel\u00f6st werden\nkann. In Abbildung 9 ist ein Beispiel f\u00fcr ein solches stabiles Equilibrium dargestellt, auf das allerdings in\nK\u00fcrze n\u00e4her eingegangen wird.\nNach Millington und Funge in [35, S. 95-108] lassen sich die vorhandenen Ans\u00e4tze zur Kombinierung\nvonSteering Behaviors inBlending undArbitration , sowie in Mischformen dieser unterscheiden. Blending -\nAns\u00e4tze f\u00fchren alle relevanten Steering Behaviors separat aus und kombinieren in Anschluss daran die\nErgebnisse unter Einbeziehung von Gewichten, Priorit\u00e4ten oder anderer Bewertungskriterien zu einem\nEndergebnis. Die einfachste Form eines Blending -Ansatzes ist es die Ergebnisse anhand vorher de\ufb01nierter\nGewichte f\u00fcr jedes Steering Behavior zusammenzurechnen. Dies bedeutet im Umkehrschluss, dass in der\nAnwesenheit mehrerer Steering Behaviors niemals ein Steering Behavior vollst\u00e4ndig alleine ausgef\u00fchrt\nwird, sondern immer ein Kompromiss aus mehreren Steering Behaviors eingegangen wird. Das gr\u00f6\u00dfte\nProblem von reinen Blending -Ans\u00e4tzen ist das zuvor schon erw\u00e4hnte Problem des Eintretens stabiler\noder instabiler Equilibrien oder generell das Problem des H\u00e4ngenbleibens, vor allem in komplexeren\noder einengenderen (Innen-)Arealen.\nAbbildung 8: Ein instabiles Equilibrium. Angelehnt an eine Gra\ufb01k aus [35, S. 100].\nAbbildung 9: Ein stabiles Equilibrium. Entnommen aus [35, S. 101].\nAbbildung 8 zeigt ein Beispiel f\u00fcr das Problem eines instabilen und Abbildung 9 f\u00fcr das eines stabilen\nEquilibriums. Beide treten genau dann auf, wenn Steering Behaviors in Kon\ufb02ikt zueinanderander ste-\nhende Steering -Ziele vorschlagen. In Abbildung 8 wird dieser Kon\ufb02ikt dargestellt, indem der Vorschlag\nzum Erreichen des Ziels dem genauen Gegenteil bzw. dem invertierten Steering -Vektor des vom Flucht-\nBehavior pr\u00e4sentierten Vorschlags entspricht. Wenn wie im Beispiel dargestellt die Gewichte wiin diesem\n3.4 Verfahren zur Kombinierung von Steering Behaviors 27Fall noch gleich sind, ist die Folge das die beiden Steering -Vektoren sich gegenseitig aufheben und der\nAgent somit zum Stillstand gelangt. Diesen Fall nennt man deswegen instabil, weil durch nummerische\nUngenauigkeiten oder andere Faktoren der Agent selbst dazu in der Lage ist aus diesem Gleichgewicht\nzu entkommen und somit doch noch ein annehmbares Verhalten zu pr\u00e4sentieren.\nEin stabiles Equilibrium hingegen ist in bestimmten Situation, wie beispielsweise der in Abbildung\n9 dargestellen, ein ernsthafteres Problem, weil der Agent sich eben nicht selbst aus dem Gleichgewicht\nbefreien kann. Im abgebildeten Beispiel w\u00fcrde der Agent zwar vlt. ebenfalls aufgrund nummerischer Un-\ngenauigkeiten sich langsam innerhalb des Sichtradius der beiden Feinde bewegen k\u00f6nnen, doch w\u00fcrde\ner sich aufgrund der sich quasi gegenseitig aufhebenden Vorschl\u00e4ge nur sehr langsam und nicht kon-\nsequent genug in eine Richtung fortbewegen um solch einem gro\u00dfen Flucht-Radius der Feinde effektiv\nentkommen zu k\u00f6nnen. Das Ergebnis ist ein Festsitzen des Agenten der sich nicht zwischen Zielerrei-\nchung und Flucht entscheiden kann.\nDasInverse Steering Behavior [3, 4] Verfahren der Universit\u00e4t Koblenz-Landau ist ein Vertreter dieses\nBlending -Ansatzes, beweist allerdings mit der Beispiel-Implementierung eines dribbelnden Fu\u00dfball spie-\nlenden Roboter Agenten, dass mit der Verwendung kostenbasierender Metriken, statt einfacher experi-\nmentell bestimmter Gewichte die meisten zuvor erw\u00e4hnten Nachteile aus den Weg ger\u00e4umt werden k\u00f6n-\nnen. Wie die Bezeichnung \u201eInverse\u201c im Namen bereits vermuten l\u00e4sst, wird dabei eine im Vergleich zum\nSteering -Ansatz von Reynolds invertierte Herangehensweise bei der Berechnung des Steerings -Outputs\nangewandt. Statt einer separaten Ausf\u00fchrung aller Steering Behaviors im ersten Schritt und anschlie-\n\u00dfender Kompromissbildung aus den Ergebnissen, wird zu aller Erst je nach Situation eine Menge an\nm\u00f6glichen Steerings bestimmt, um anschlie\u00dfend von den Steering Behaviors separat anhand einer indivi-\nduellen Kostenmetrik bewertet zu werden. Die Steering -Vorgabe welches die geringsten Kosten \u00fcber die\nMenge aller relevanten Bewertungen der Steering Behaviors aufweist, stellt nach dem Inverse Steering\nBehavior -Verfahren die ideale Kompromissl\u00f6sung zur Bew\u00e4ltigung der aktuellen Situation dar. Dabei ist\ndie Kompromissl\u00f6sung nicht ein Berechnungskompromiss wie bei einfachen Blending -Ans\u00e4tzen, wobei\ndie Kompromissl\u00f6sung im schlimmsten Fall keines der Steering Behavior -Ziele erreicht, sondern ein Aus-\nwahlkompromiss zwischen mehreren plausiblen L\u00f6sungen.\nStellt man sich die in Abbildung 10 dargestellte Situation vor, in der ein Ziel von zwei nahen statischen\nObjekten verdeckt wird, so wird im Inverse Steering Behavior -Verfahren in etwa wie folgt vorgegangen:\nIm ersten Schritt wird realisiert, dass in naher Zukunft bei Beibehaltung der aktuellen Bewegungsrich-\ntung eine Kollision mit einem statischen Hindernis statt\ufb01nden w\u00fcrde. Gesucht wird nun eine Richtungs-\n\u00e4nderung bzw. ein neuer Steering -Vektor, dessen Ausf\u00fchrung die zuk\u00fcnftige Kollision noch abwenden\nkann. Dazu werden je nach Situation oder Umgebung, auf eine nicht n\u00e4her bestimmte Weise, eine un-\nterschiedliche Menge an m\u00f6glichen L\u00f6sungsvorschl\u00e4gen bzw. Steering -Vektoren ermittelt. Im zweiten\nSchritt werden diese Steering -Vorschl\u00e4ge von allen relevanten Steering Behaviors separat untersucht. Bei\nder Untersuchung wird jeweils eine eigene f\u00fcr das Steering Behavior repr\u00e4sentative Kostenfunktion als\nBewertungsgrundlage herangezogen. Die Idee dahinter ist, dass die einzelnen Steering Behaviors nicht\nmehr f\u00fcr die Berechnung eines Steering -Vektors zust\u00e4ndig sind die ihre Absicht, wie z.B. das Erreichen\neines Ziels oder das Ausweichen vor statischen Hindernissen, am besten erf\u00fcllt, sondern eine Kosten-\nbewertung vornehmen, die diejenigen Steering -Vektoren mit den geringsten Kosten bewertet die ihre\nAbsicht am besten zu erf\u00fcllen scheint.\nIm Beispiel k\u00f6nnte das Seek Behavior nach [3] eine Bewertung anhand der graduellen Abweichung\nzur Luftlinie zum Ziel vornehmen. Mit dieser Funktion w\u00fcrden somit die Vorschl\u00e4ge \u00121und \u00124mit\n80\u000eh\u00f6here Kosten verursachen als \u00122und\u00123mit 40\u000e. Das Obstacle Avoidance Behavior w\u00fcrde hinge-\ngen das Vorhandensein von statischen Hindernissen entlang eines Steering -Vektors untersuchen. Auf das\nBespiel in der Abbildung \u00fcbertragen w\u00fcrde das bedeuten, dass \u00122Kosten von 1 und der Restkosten\n28 3 Verwandte Ans\u00e4tzeAbbildung 10: Die Evaluierung der m\u00f6glichen Ausweichbewegungen zur Verhinderung der Kollision mit Hinder-\nnissen. Angelehnt an zwei Gra\ufb01ken aus [3].\nvon 0 verursachen w\u00fcrden. Haben s\u00e4mtliche Steering Behaviors alleSteering -Vorschl\u00e4ge aus Schritt eins\nbewertet, erfolgt im n\u00e4chsten Schritt die Berechnung aller Kosten eines Vorschlag mittels eines Blen-\nding-Verfahrens, wobei die einfachste Form die direkte Aufsummierung ohne Gewichte w\u00e4re. Im \ufb01nalen\nSchritt w\u00fcrde dann der Steering -Vorschlag ausgew\u00e4hlt werden, der \u00fcber die geringsten Kosten verf\u00fcgt.\nMit der direkten Aufsummierung und der Normierung aller Kostenfunktionen auf ein Intervall von [0,1]\nw\u00fcrde im Beispiel \u00123mit 0.5 die geringsten Kosten aufweisen, da es mit \u00122die geringste Winkelabwei-\nchung aufweist und somit die geringsten seek-Kosten von 0.5, aber im Gegensatz zu \u00122ebenfalls die\ngeringste Kostenbewertung nach obstacle avoidance mit Kosten = 0 erh\u00e4lt. Tabelle 2 enth\u00e4lt nochmals\nalle Kostenbewertungen, sowie die abschlie\u00dfende Kostenaufsummierung pro Steering -Vorschlag.\n\u00121\u00122\u00123\u00124\nCSeek80 40 40 80\nCOA0 1 0 0\nh(CSeek, COA)11.5 0.5 1\nTabelle 2: Kostenbewertung der Steering -Vorschl\u00e4ge sowie ihre Kostensumme.\nDer gr\u00f6\u00dfte Vorteil bei der Verwendung der Kostenfunktion ist die relativ einfache Einbeziehung von\nzus\u00e4tzlichen high level -Wissen bei der Bewertung der Steering -Vorschl\u00e4ge. Die Steering -Ebene ist somit\nnicht wie im traditionellen Ansatz von Reynolds ausschlie\u00dflich auf lokale Informationen \u00fcber die Umge-\nbung beschr\u00e4nkt. Als m\u00f6gliches high level -Beispiel f\u00fcrs Inverse Steering Behavior -Verfahren wird in [4, S.\n226f.] die Einbeziehung des Wissen einer In\ufb02uence Map aufgef\u00fchrt. Eine In\ufb02uence Map ist eine Daten-\nstruktur die regionale Informationen \u00fcber das aktuelle Gegner- und Verb\u00fcndeten Verh\u00e4ltnis f\u00fchrt. Auf\ndas eben aufgef\u00fchrte Beispiel \u00fcbertragen w\u00fcrde das bedeuten, dass es eine dritte Kostenfunktion geben\nk\u00f6nnte, welche die Steering -Vorschl\u00e4ge in Hinblick darauf bewertet, ob diese zu mehr oder weniger stark\nvom Gegner kontrollierten Gebieten f\u00fchren oder nicht. Wie die in [3, 4] vorgestellte Umsetzung eines\ndribbelnden Fu\u00dfball spielenden Roboter-Agenten zeigt, scheint das Inverse Steering Behavior Verfahren\n3.4 Verfahren zur Kombinierung von Steering Behaviors 29f\u00e4hig zu sein auch schwierige Situationen erfolgreich zu meistern ohne dabei in bekannte Fallen zu tap-\npen, wie z.B. das H\u00e4ngenbleiben aufgrund stabiler Gleichgewichte.\nDer Nachteil der gewonnenen M\u00e4chtigkeit ist allerdings auf der anderen Seite der gestiegene Berech-\nnungsaufwand. Es m\u00fcssen einerseits mehrere situationsabh\u00e4ngige und allen voran plausible Steering -\nVorschl\u00e4ge bestimmt werden, andererseits beliebig komplexe und beliebig viele Kostenberechnungs-\nfunktionen f\u00fcr jeden einzelnen Vorschlag ausgef\u00fchrt werden. Gerade wenn man nach Reynolds die\nSteering -Ebene als die \u201enon-deliberative\u201c-Ebene auffasst, die in der Regel in jedem Entscheidungszy-\nklus eines Agenten ausgef\u00fchrt werden muss, und dementsprechend performant zu sein hat, stellt der\nerh\u00f6hte Berechnungsaufwand einen nicht zu vernachl\u00e4ssigten Umstand dar.\nEine Alternative zu Blending -Ans\u00e4tzen stellen Arbitration -Verfahren dar, die im Grunde die Gewichte\ndurch Priorit\u00e4ten ersetzen. Die Vorgabe einer Reihenfolge bei der Ausf\u00fchrung von Steering Behaviors\nverhindert die Problematik der Kombination widerspr\u00fcchlicher Steering Behavior -Ergebnisse, was das\ngr\u00f6\u00dfte Problem von Blending -Verfahren darstellt. Umgangen wird das Problem dadurch, dass immer nur\ndas Ergebnis eines Einzigen oder einer sehr kleinen Menge von Steering Behaviors zu einem bestimmten\nZeitpunkt Verwendung \ufb01ndet. Erm\u00f6glicht wird dies indem Steering Behaviors der Reihe nach ausge-\nf\u00fchrt werden bis das Erste sich signi\ufb01kant von \u201eNull\u201c unterscheidende Ergebnis ermittelt wird, wobei\neinNull-Ergebnis eines Steering Behaviors etwas lapidar ausgedr\u00fcckt bedeutet: Aktuellen Kurs halten!\nEine Alternative dazu ist es die Ausf\u00fchrung solange Fortzusetzen bis der erste Kon\ufb02ikt auftritt. Es w\u00e4re\nbeispielsweise denkbar, dass ein Steering Behavior nur den Torso eines K\u00f6rpers steuern m\u00f6chte und die\nmomentane Bewegungsrichtung unangetastet l\u00e4sst, sodass diese im Anschluss daran noch von einem\nNachfolger gesetzt werden k\u00f6nnte. Ein m\u00f6gliches Arbitration -Verfahren ist das in Abschnitt 4 vorgestell-\nte Konzept einer Steering Pipeline .\nDer Nachteil des Einsatzes einer solchen Priorisierung ist auf der anderen Seite, dass durch eine zu\nstrikte oder starre Vorgabe der Reihenfolge, nicht unbedingt alle aktuell zu Ber\u00fccksichtigten Steering Be-\nhaviors auch tats\u00e4chlich ausgef\u00fchrt und im Endergebnis beachtet werden. Stelle man sich beispielsweise\ndie Situation vor in der nicht nur statischen Hindernissen, sondern auch beweglichen Hindernissen aus-\ngewichen werden muss, so w\u00fcrde die ausschlie\u00dfliche Beachtung einer Hindernisart unter Umst\u00e4nden\nnicht die Kollision mit der anderen Art verhindern k\u00f6nnen. Aus diesem Grund wird in [35, S. 95-108]\ndie These aufgestellt, dass nur eine Kombination aus Blending und Arbitration zu einem wirklich zu-\nfriedenstellenden Ergebnis f\u00fchrt. Als Beispiel einer solchen Kombination wird ein System vorgestellt,\nwelches Steering Behaviors in mehrere Gruppen einteilt, wobei die Ausf\u00fchrung der Gruppen einer fes-\nten Reihenfolge folgt ( Arbitration ). Innerhalb der Gruppe werden alle Steering Behaviors ausgef\u00fchrt und\ndas Ergebnis mittels Blending zusammengef\u00fchrt. Eine m\u00f6gliche Aufteilung der Steering Behaviors w\u00e4re\nin eine collision avoidance -,group behavior - und single behavior -Gruppe. Die erste Gruppe w\u00e4re f\u00fcr das\nAusweichen vor statischen und beweglichen Hindernissen zust\u00e4ndig. Die zweite Gruppe f\u00fcr die Einhal-\ntung von Gruppenbewegungen, wie z.B. die Verhinderung des Zusammenpralls ( Seperation ) oder des\nAuseinanderdriftens ( Cohesion ) einzelner V\u00f6gel inmitten eines Schwarm\ufb02ugs. Letzt genannte Gruppe\nw\u00fcrde alle Steering Behaviors umfassen die sich um die Verfolgung separater Ziele des Agenten k\u00fcm-\nmern, z.B. das Erreichen eines bestimmten Punktes. Ein weiteres Beispiel f\u00fcr ein kombiniertes System\nw\u00e4re das von Reynolds getaufte prioritized acceleration allocation system [45]. Hier werden alle Steering\nBehaviors in eine feste und durch die condition checking -Ausf\u00fchrung bedingte variable Reihenfolge ge-\nbracht. Anschlie\u00dfend werden \u00e4hnlich dem Arbitration -Ansatz so lange Ergebnisse gesammelt, bis eine\nGrenze \u00fcberschritten wurde. Die Grenze wird hierbei nicht durch das Auftreten konkurrierender Ergeb-\nnisse bestimmt, sondern stellt eine f\u00fcr jeden Agenten festlegbare Beschleunigungsgrenze dar, die durch\ndas akkumulieren der einzelnen Steering Behaviors erreicht werden kann.\n30 3 Verwandte Ans\u00e4tzeMit kombinierten Ans\u00e4tzen k\u00f6nnen die Vorteile beider Ans\u00e4tze ausgenutzt werden und gleichzeitig\ndie Nachteile entsprechend abgeschw\u00e4cht werden, auch wenn diese nie ganz oder nur mit erheblichen\nMehraufwand wie beim Inverse Steering Behavior -Verfahren ausgemerzt werden k\u00f6nnen. So bleibt fest-\nzuhalten, dass es in diesem Gebiet nicht die eine richtige L\u00f6sung gibt, sondern je nach konkretem Ein-\nsatzgebiet und Anforderungen ein bestimmter Ansatz ausgew\u00e4hlt werden sollte, der am besten f\u00fcr die\njeweilige Situation zu passen scheint. Mit dem in Kapitel 4 vorgestellten Konzept einer Steering Pipeli-\nnewird zwar ein vorrangig dem Arbitration -Ansatz zugeordnetes Verfahren vorgestellt, das allerdings\nim Gegensatz zu anderen Ans\u00e4tzen einen erheblichen Vorteil bietet, auch gegen\u00fcber kombinierten An-\ns\u00e4tzen. Es erm\u00f6glicht, dass Steering Behaviors im Kon\ufb02iktfall ihre f\u00fcr sich gewonnenen Informationen\ngegenseitig austauschen k\u00f6nnen, um auf dieser Grundlage weitere Berechnungen ausf\u00fchren zu k\u00f6nnen.\n3.5 Vorg\u00e4nger-Implementierung: DragonBot\nDer Ansatz der kontext-sensitiven AI-Spieler wurde bereits in Planet PI4 in einer ersten Version\numgesetzt. Dimitri Wulffert hat im Rahmen seiner Bachelorarbeit [59] zwei unterschiedliche Bot-\nImplementierungen entwickelt, welche bereits in ersten Tests erfolgreich eingesetzt werden konnten.\nEs gelang u.a. das Erreichen einer verbesserten Genauigkeit bzw. des Realit\u00e4tsgrads der generierten\nNetzwerklast in Hinblick auf die Anzahl der Nachbarn. Die Anzahl der Nachbarn ist eine von mehre-\nren, der noch in Entwicklung be\ufb01ndlichen, Metriken (zweite Komponente) der Benchmarking-Methodik\n[30]. Erste gr\u00f6\u00dfer angelegte Tests mit bis zu 500 Spielern, zeugen auch von einer entsprechend guten\nPerformance als wichtiger Faktor des Skalierbarkeits-Kriteriums.\nAllerdings best\u00fcnde keine Notwendigkeit f\u00fcr die vorliegende Master-Thesis, wenn die bisherigen zwei\nBot-Implementierungen alle eben vorgestellten Kriterien in ausreichender Form erf\u00fcllen w\u00fcrden. Nach\neingehender Analyse beider Bot-Implementierungen wurden hinsichtlich der Erf\u00fcllung der aufgestellten\nvier Kriterien aus 1.2 folgende M\u00e4ngel aufgedeckt bzw. Verbesserungsm\u00f6glichkeiten ausgemacht:\n\u2022Reproduzierbarkeit: Beide Implementierungen erzeugen weitesgehend deterministisches und so-\nmit reproduzierbares Verhalten. Jedoch weisen einige Testdurchl\u00e4ufe Diskrepanzen auf, die auf\neine fehlerhafte oder fehlende Verwendung des zur Verf\u00fcgung gestellten Zufallszahlengenerators\nhindeuten.\n\u2022Skalierbarkeit: Die Performance der Bot-Implementierungen ist gut. Es fehlen allerdings s\u00e4mtliche\nKon\ufb01gurationsm\u00f6glichkeiten, d.h. die Bot-Implementierungen erzeugen in etwa immer dieselbe\nLast bei stets gleichbleibendem Realismus-Niveau.\n\u2022Realit\u00e4tsgrad: Erste Tests lassen zwar bereits einen guten Realit\u00e4tsgrad vermuten, doch scheint ge-\nrade in diesem Bereich noch ein gro\u00dfer Verbesserungsspielraum zu bestehen. So werden Aspekte\nwieShoot -,Hit- oder Death -Rate noch nicht genau genug abgedeckt, siehe dazu auch Abschnitt 6.\nDie Komplexit\u00e4t beider Bot-Implementierungen h\u00e4lt sich dabei ebenfalls sehr in Grenzen und kon-\nzentriert sich dementsprechend ausschlie\u00dflich auf einige Kernprozesse der Entscheidungs\ufb01ndung\n(Decision Making). Rollenverhaltens- oder Gruppenverhaltensweisen werden nur sehr rudiment\u00e4r\noder gar nicht umgesetzt. Ersteres kann beispielsweise zur Ausl\u00f6sung unterschiedlicher Verhaltens-\nweisen unter gleichen Bedingungen eingesetzt werden und letzteres stellt gerade in MMOGs einen\nwichtigen Aspekt dar und bedarf einer weiter gehenden Ber\u00fccksichtigung.\n\u2022Kon\ufb01gurierbarkeit: Bei der Lasterzeugung ist das jeweilige Spielerverhalten der ausschlaggebende\nFaktor. Es existieren zwar beim Realit\u00e4tsgrad, anders als bei der Skalierbarkeit, einige M\u00f6glichkei-\nten der Variierung des Bot-Verhaltens, doch erm\u00f6glichen diese nur eine indirekte und eine auf das\nVerhalten und somit letzen Endes auf die zu generierende Netzwerklast kaum nachvollziehbare\nKon\ufb01gurationsm\u00f6glichkeit.\n3.5 Vorg\u00e4nger-Implementierung: DragonBot 31Wie bereits am Ende von Abschnitt 1.2 angedeutet, ist ein Hauptkritikpunkt der geleisteten Vorar-\nbeit das Fehlen einer zugrundeliegenden Game AI -Architektur, welche sich Besonders an der Umsetzung\nbeider Bot-Implementierungen in einer jeweils v\u00f6llig separaten Klassenhierarchie ausmachen l\u00e4sst. Wie\nsp\u00e4ter in Abschnitt 3 behandelt, gibt es bei der Entwicklung einer Game AI zahlreiche unterschiedliche\nL\u00f6sungsans\u00e4tze, die ebenfalls ein breites Spektrum an unterschiedlichen Implementierungsm\u00f6glichkei-\nten zulassen. Dennoch gibt es gewisse Aspekte die f\u00fcr jede Game AI bzw. Bot-Implementierung eines\nComputerspiels gelten, siehe dazu Abschnitt 2, insbesondere wenn es um denselben konkreten Einsatz-\nzweck geht.\nDie teilweise nicht ausreichende Erf\u00fcllung der aufgestellten vier Kriterien, sowie der Umstand einer\nfehlenden Game AI -Architektur, die eine effektive und erfolgversprechende Weiterentwicklung entschei-\ndend erschwert, legt eine vollst\u00e4ndige Neu-Konzeptionierung, Entwicklung und Umsetzung des Ansatzes\nder kontext-sensitiven AI-Spieler f\u00fcr Planet PI4 nahe und soll im Rahmen dieser Master-Thesis entspre-\nchend realisiert werden.\n32 3 Verwandte Ans\u00e4tze4 Konzept und Rahmenbedingungen der Game AI\nDas Kapitel beschreibt das entwickelte allgemeine Game AI -Konzept zur L\u00f6sung der in der Einleitung\nde\ufb01nierten Zielvorgaben zur synthetischen Generierung einer realistischen Netzwerklast unter Einsatz\nkontext-sensitiver AI-Spieler.\nAbschnitt 4.1 \u201eEinsatzumgebung Planet PI4\u201c beschreibt dabei zuerst die konkrete Einsatzumgebung\nderGame AI . Die Beschreibungen zum Spiel sind f\u00fcr das weitere Verst\u00e4ndnis der in Abschnitt 4.2 \u201eFunk-\ntionale Anforderungen der Game AI\u201c pr\u00e4sentierten, in Hinblick auf die F\u00e4higkeit zum Spielen des Spiels,\nkonkretisierten Anforderungen und des in Abschnitt 4.3 \u201eKonzept der Game AI\u201c vorgestellten groben\nL\u00f6sungsansatzes notwendig.\nDer abschlie\u00dfende Abschnitt 4.4 \u201eBehavior Tree\u201c stellt den allgemeinen Ansatz des verwendeten De-\ncision Making -Konzepts der Game AI vor. Der Behavior Tree -Ansatz ist noch recht jung und erfreut sich\neiner stetig ansteigenden Beliebtheit. Der Ansatz entspringt, anders als viele andere Konzepte aus diesem\nBereich, nicht direkt akademischen Ge\ufb01lden, sondern ist eher ein Produkt der Games-Industrie.\n4.1 Einsatzumgebung Planet PI4\nPlanet PI4 ist ein Third-Person Shooter f\u00fcrOnline Multiplayer -Partien \u00fcber ein Peer-to-Peer -Netzwerk. Der\nSpieler \u00fcbernimmt im Spiel die Kontrolle \u00fcber ein Raumschiff in einer frei erkundbaren 3D-Weltraumwelt\ndie im Orbit des namensgebenden Planeten PI4angesiedelt ist. Der Orbit des Planeten besteht zwar gr\u00f6\u00df-\ntenteils aus Asteroiden, beherbergt jedoch dar\u00fcber hinaus noch sogenannte Upgrade Points und Schild-\ngeneratoren - die Points of Interests des Spiels. Upgrade Points sind gro\u00df\ufb02\u00e4chige Areale die vom Spieler\nerobert werden k\u00f6nnen und diesem und seinem Team daraufhin bestimmte Boni verleihen. Schildgene-\nratoren hingegen regenerieren die Lebens- und Schildenergie in der N\u00e4he be\ufb01ndlicher Spieler und sind\nim Gegensatz zu Upgrade Points etwas kleiner und k\u00f6nnen nicht erobert werden. Das Spiel wird \u00fcber eine\nTastatur/Maus-Steuerung gespielt. Zur Fortbewegung im 3D-Raum kommt die \u00fcbliche WASD-Steuerung\nzum Einsatz, wobei das Dr\u00fccken und Festhalten der Leertaste einen Geschwindigkeitsschub bewirkt -\ndenBoost . Gezielt wird mit der Maus, wobei erst durch das Ausl\u00f6sen der linken Maustaste gefeuert wird.\nAbbildung 11 zeigt einen Screenshot des Spiels aus Sicht eines Spielers, wobei Upgrade Points mit\nder Bildmarkierung 1 und Schildgeneratoren mit der Bildmarkierung 2 gekennzeichnet sind. Anders als\ndie in der Abbildung dargestellte gra\ufb01sche Benutzerober\ufb02\u00e4che (GUI) des Spiels am unteren Rand mit\nihrem Anzeige-Tupel vermuten l\u00e4sst, ist der Zustand eines Raumschiffes durch das folgende Wertetupel\nde\ufb01niert:\nSpaceshipState =fHeal th ,Shield ,Ener g yg (1)\nJedoch ist der visuell hervorgehobene Upgrade Point -Counter am unteren Rand der GUI ebenfalls f\u00fcr\nden Zustand eines Raumschiffes von gro\u00dfer Bedeutung. Was sich hinter den Elementen des Wertetupels\nverbirgt oder welche Bedeutung der Upgrade Point -Counter besitzt, wird in der folgenden Aufz\u00e4hlung\nn\u00e4her erl\u00e4utert:\n\u2022Upgrade Point-Counter [Bildmarkierung 3]: Z\u00e4hlt die Anzahl der aktuell vom eigenen Team\nkontrollierten Upgrade Points . Jeder zus\u00e4tzlich eroberte Upgrades Point bietet folgende drei Team-\nBoni, deren einzelne Effekte akkumulierbar sind:\n\u2013Die maximale Energiekapazit\u00e4t wird um 5% erh\u00f6ht\n\u2013Die maximale Endgeschwindigkeit eines Raumschiffes wird leicht erh\u00f6ht\n33Abbildung 11: Die gra\ufb01sche Benutzerober\ufb02\u00e4che von Planet PI4 . Angelehnt an eine Gra\ufb01k aus [30].\n\u2013Die maximale Schildenergie wird um 5% erh\u00f6ht\nDurch \u00c4nderungen des Upgrade Point -Counters gew\u00e4hrte Team-Boni wirken sich erst nach der Zer-\nst\u00f6rung des eigenen Raumschiffes und anschlie\u00dfendem Respawn aus.\n\u2022Health [Bildmarkierung 4]: Gibt die Lebensenergie des Schiffes in einem Prozent-Intervall von\n[0-100] an. Die Lebensenergie eines Schiffes kann entweder durch Treffer gegnerischer oder ei-\ngener Schiffe, sowie durch Kollisionen mit Asteroiden oder anderen Schiffen sinken. Sinkt die\nLebensenergie auf 0% explodiert das Raumschiff in einer netten Animation und wird mit voller\nLebensenergie an einem anderen Punkt auf der Karte respawned.\n\u2022Energy [Bildmarkierung 5]: Dient zum Antrieb des Boosts und zur Versorgung der Waffensyste-\nme. Die Benutzung l\u00e4sst das Energielevel, welches zu Beginn einer Partie in einem Prozent-Intervall\nvon [0-100] liegt, kontinuierlich sinken. Durch Eroberung von Upgrade Points kann das Intervall\nentsprechend vergr\u00f6\u00dfert werden. Anders als die Lebensenergie regeneriert sich die Energie bei\nNichtbenutzung des Boosts oder der Waffensysteme langsam aber sicher von selbst.\n\u2022Shield [Bildmarkierung 6]: Dient zur Abmilderung des erlittenen Schadens durch die Waffensys-\nteme anderer Schiffe. Die Schildenergie l\u00e4dt sich nicht von selbst auf, kann allerdings durch den\nBesuch von Schildgeneratoren regeneriert werden. Der Anfangswert des Schildes betr\u00e4gt 50 und\nkann durch die Eroberung von Upgrade Points weiter gesteigert werden.\n34 4 Konzept und Rahmenbedingungen der Game AIDas Spiel Planet PI4 ist ein reiner Multiplayer-Titel. Es enth\u00e4lt somit keine Geschichte, keine Skript-\nsequenzen oder sonstige f\u00fcr Singleplayer Spiele \u00fcblichen Spielelemente. Im Grunde gibt es auch nur\nein einziges Level, welches im Orbit des Planeten spielt. Doch ist dieses Level weder in der Levelgr\u00f6\u00dfe,\nnoch in der Team- oder Spieleranzahl fest vorgegeben oder begrenzt. Durch einen Levelgenerator lassen\nsich die Anzahl und Verteilung der Asteroiden und der POIs, sowie zahlreiche weitere Level-Parameter\neinstellen und demnach unterschiedliche Variationen diesen einen Levels generieren.\nWeiter gibt es auch kein wirkliches Spielende und auch kein fest vorgegebenes Spielziel. Man kann\nsich das Spiel viel eher als eine Art Spielwiese vorstellen, in der die Spieler auf ihre eigene Art und\nWeise spielen und dabei ihre eigenen festgelegten Ziele verfolgen k\u00f6nnen. M\u00f6glich w\u00e4re es z.B., dass\njeder Spieler in einer Jeder-gegen-Jeden-Manier alleine ein Team vertritt und am Ende derjenige Spieler\ngewinnt, der die meisten Raumschiffe abschie\u00dfen konnte. Genauso gut k\u00f6nnte man dieses Prinzip auf\nzwei oder mehrere konkurrierende Teams \u00fcbertragen, sodass das Team gewinnt, welches zusammen be-\ntrachtet die meisten Absch\u00fcsse erzielt hat. Eine andere Variante w\u00e4re es vorher festgelegtes Zeitfenster\nzu w\u00e4hlen und das Team zum Sieger zu ernennen, welches nach Ablauf der Zeit die meisten Upgrade\nPoints beherrscht. In Kapitel 6 werden diese und andere unterschiedliche Spielarten zur Evaluation des\neigenen Ansatzes eingesetzt. Die zu entwickelnde Game AI sollte idealerweise \ufb02exibel genug sein um je\nnach Spielmodi ihr Verhalten entsprechend anpassen zu k\u00f6nnen.\n4.2 Funktionale Anforderungen der Game AI\nIn Abschnitt 1.2 wurden die \u00fcbergeordneten Ziele der Master-Thesis vorgestellt. Diese Ziele gilt es zu\nerf\u00fcllen, damit die durch den Ansatz der computergesteuerten Spieler (Bots) generierte Netzwerklast\nerfolgreich zur Evaluation von P2P-Overlay-Netzwerken eingesetzt werden kann. Damit diese Lasterzeu-\ngung realisiert werden kann, m\u00fcssen die eingesetzten Bots die F\u00e4higkeit entwickeln das Spiel Planet PI4\nerfolgreich spielen zu k\u00f6nnen. Folgende Au\ufb02istung an funktionalen Anforderungen de\ufb01niert dazu die\nvon den Bots zu erbringende minimale Leistung, unterteilt in die Kategorien Bewegung, Kampf und wei-\ntere Interaktionen:\nBewegung:\n\u2022 Das Raumschiff im 3D-Weltraum bewegen (vorw\u00e4rts, seitlich und r\u00fcckw\u00e4rts \ufb02iegen)\n\u2022 Einen beliebigen Punkt auf der Karte ansteuern\n\u2022 W\u00e4hrend des Fluges den Boost benutzen\n\u2022 Bewegliche Spieler verfolgen und abfangen\n\u2022 Die Karte eigenst\u00e4ndig erkunden\n\u2022 Statischen Hindernissen bzw. Asteroiden ausweichen\n\u2022 Beweglichen Objekten bzw. anderen Raumschiffen ausweichen\nKampf:\n\u2022 Ein stehendes oder bewegliches Ziel anvisieren\n\u2022 Das Feuer auf stehende oder bewegliche Ziele er\u00f6ffnen\n\u2022 Im Stillstand oder w\u00e4hrend der Bewegung anvisieren und schie\u00dfen\n\u2022 Eine Position bzw. POI (Upgrade Point oder Schildgenerator) verteidigen oder angreifen\n\u2022 Vor anderen Raumschiffen \ufb02iehen\nWeitere Interaktionen:\n\u2022 POIs lokalisieren\n\u2022Upgrade Points erobern\n4.2 Funktionale Anforderungen der Game AI 35\u2022 Schildgeneratoren benutzen\n\u2022 Informationen (z.B. gefundene Gegner, POIs) an Mitspieler weitergeben\n\u2022 Unterst\u00fctzung anfordern und leisten\n4.3 Konzept der Game AI\nDas entwickelte Game AI -Konzept der Master-Thesis stellt eine Erweiterung des reynoldschen Modells\naus Abschnitt 2.4 dar und sieht eine Aufteilung der Verantwortlichkeiten der Game AI in eine strategi-\nsche, taktische und operative Ebene vor. Die dabei vorgenommene Einteilung ist namentlich und in ihrer\nWirkungsdauer (lang-mittel-kurz) der in der Unternehmensplanung g\u00e4ngigen Art der Unterscheidung\nbei der Auslegung und Reichweite von Planungszielen nachempfunden [18, S. 88ff.]. Die Erweiterung\ndes reynoldschen Modells beschr\u00e4nkt sich dabei nicht nur auf die Umbenennung der Ebenen, sondern \u00e4u-\n\u00dfert sich auch in der Umdeutung und erweiterten Auslegung des Verantwortungsbereichs der einzelnen\nEbenen, die in der folgenden Aufz\u00e4hlung n\u00e4her erl\u00e4utert werden:\n\u2022Strategische Ebene (langfristig): Diese Ebene ist f\u00fcr die Aufstellung und nachhaltige Verfolgung\nl\u00e4ngerfristiger bzw. \u00fcbergeordneter Zielsetzungen zust\u00e4ndig. Daf\u00fcr m\u00fcssen immer wieder neue\nImpulse zu dessen Nachverfolgung gesetzt werden. Hier wird bestimmt auf welche Art und Weise\noder genauer gesagt, unter welchen Parameterbedingungen die Ziele im Weiteren verfolgt wer-\nden sollen. Dies hat vor allem Auswirkungen auf den Aktionsauswahlprozess der taktischen Ebene.\nEbenfalls sind hier l\u00e4ngerfristige Berechnungen oder Analysewerkzeuge angesiedelt, dessen per-\nmanente Neuberechnung entweder nicht n\u00f6tig oder zu aufwendig erscheint.\nDer Verantwortungsbereich dieser Ebene w\u00fcrde im Agentenmodell nach Reynolds als ein eher un-\ntergeordneter Bestandteil der Action Selection -Ebene interpretiert werden. Aufgrund der Gr\u00f6\u00dfe und\nBedeutung der strategischen Aspekte f\u00fcr die Game AI vonPlanet PI4 , wird im erweiterten Modell\ndieser Verantwortungsbereich aus der Action Selection -Ebene herausgezogen und in einer eigenen\nstrategischen Ebene vereint. Da die strategische Ebene Vorgaben f\u00fcr den Aktionsauswahlprozess\ndes Agenten de\ufb01niert, kann diese Ebene des Weiteren als eine der Action Selection -Ebene \u00fcberge-\nordnete Ebene betrachtet werden.\n\u2022Taktische Ebene (mittelfristig): Die Aufgabe der Ebene ist die Konkretisierung und Erf\u00fcllung der\nZiele der strategischen Ebene unter Beachtung der einzuhaltenden strategischen Rahmenbedin-\ngungen oder Vorgaben. Dazu ist die Bestimmung und Ausf\u00fchrung der zur Erf\u00fcllung notwendigen\nAktionen notwendig. Zur Realisierung dieser Aufgabe ist hier als wichtigste Komponente das Herz-\nst\u00fcck des rationalen Agenten angesiedelt - das Decision Making .\nDie taktische Ebene entspricht somit weitestgehend der Action Selection -Ebene nach Reynolds, oh-\nne dessen strategische Aspekte.\n\u2022Operative Ebene (kurzfristig): In dieser Ebene geht es um die direkte und kurzfristige Realisie-\nrung der Ziele bzw. um die Umsetzung der ausgew\u00e4hlten Aktionen der taktischen Ebene. Dabei\nk\u00f6nnen bei Bedarf zur direkten Reaktion auf pl\u00f6tzliche Situations\u00e4nderungen weitere unmittelbar\nwirksame Aktionen eingestreut werden, wie z.B. das Ausweichen vor Hindernissen.\nDiese Ebene ist vergleichbar mit der Steering -Ebene nach Reynolds, die der \u00fcbergeordneten\nAktionsauswahl-Ebene einen Zugriff auf eine Menge von abstrakten Behaviors zur Erf\u00fcllung der\nZiele erm\u00f6glicht, statt der direkten \u00dcbergabe der Aktuator-Steuerung. Im Unterschied zur Stee-\nring-Ebene, beschr\u00e4nken sich die von operativen Ebene de\ufb01nierten Behaviors nicht ausschlie\u00dflich\naufSteering Behaviors , sondern bieten zus\u00e4tzlich auch andere Spielrelevante Behaviors an, wie\n36 4 Konzept und Rahmenbedingungen der Game AIdie Bek\u00e4mpfung eines Feindes, der Eroberung oder Verteidigung eines Upgrade Points oder die\nWiederherstellung der Lebensenergie mittels Schildgenerator.\nDieses so erweiterte Modell nach Reynolds kann in einem zweiten Schritt in das Konzept eines ratio-\nnalen (nutzenbasierten) Agenten aus Abschnitt 2.3 integriert werden. Eine m\u00f6gliche Integration k\u00f6nnte\nwie in Abbildung 12 dargestellt aussehen und stellt gleichzeitig das eigentliche Game AI -Konzept dieser\nMaster-Thesis dar.\nAbbildung 12: DasGame AI -Konzept als Erweiterung des Agentenmodells nach Reynolds und der Integration\ndessen in das Konzept eines rationalen (nutzenbasierten) Agenten.\nEin Vergleich des Game AI -Konzepts mit dem nutzenbasierten Agenten aus Abbildung 2 des Abschnitts\n2.3 zeigt, dass alle Elemente des nutzenbasierten Agenten auch im Game AI -Konzept ber\u00fccksichtigt wer-\nden, nur dass die Anordnung der Ebenenzugeh\u00f6rigkeit der Elemente entsprechend angepasst und um\nAspekte der reynoldschen Modellerweiterung erg\u00e4nzt worden ist.\nDasWorld Model und die Sensoren des Agenten bieten in diesem Sinne nicht mehr ausschlie\u00dflich\nderDecision Making -Komponente Zugriff auf Welt- und Zustandsinformationen bzw. auf aktuelle Wahr-\nnehmungen an, sondern weiten den Zugriff auf alle Ebene des Agenten aus. Weiter wird der Actua-\ntors-Zugriff, wie bereits in der Beschreibung der drei Ebenen erw\u00e4hnt, der Decision Making -Komponente\nentzogen und die operative Ebene dazwischen geschaltet. Die Aufgabe der Bewertung der Aktionsaus-\nf\u00fchrung ( Utility Function ) wird dabei der strategischen Ebene zugeordnet, da diese die Ausf\u00fchrung der\ntaktischen Ebene \u00fcberwacht, die wiederum f\u00fcr den Aktionsauswahlprozess bzw. f\u00fcr das Decision Making\nzust\u00e4ndig ist. Durch die Zuordnung der Utility Function zur strategischen Ebene k\u00f6nnen die durch die\nBewertung gewonnenen Erkenntnisse direkt in Form von neuen Vorgaben und angepassten Kon\ufb01guratio-\nnen an die taktische Ebene weitergeleitet werden und somit das Verhalten des Agenten St\u00fcck f\u00fcr St\u00fcck\nden langfristigen Zielvorgaben entsprechend angepasst werden.\n4.4 Behavior Tree\nBehavior Trees stellen eine Modellierungsart zur Beschreibung von komplexen Verhaltensweisen dar, wel-\nche bereits in einigen modernen Computerspielen wie Halo 2 &Halo 3 ,Crysis &Crysis 2 oder Spore\nzum Einsatz kam. Am ehesten l\u00e4sst sich ein Behavior Tree mit einem Hierarchical Finite State Maschine\n(HFSM) [35, S. 318-331] vergleichen, welcher anstelle von Zust\u00e4nden als elementare Konstruktions-\neinheit \u201eTasks\u201c verwendet und um Aspekte wie Scheduling , reaktives Planen und Aktionsausf\u00fchrung\nerweitert. Die Bezeichnung \u201eTree\u201c ist dabei allerdings als irref\u00fchrend anzusehen, da es sich in Wahrheit\n4.4 Behavior Tree 37um einen gerichteten azyklischen Graphen (DAG) handelt. Ein Knoten kann n\u00e4mlich zwecks Wiederver-\nwendbarkeit von Verhaltensbeschreibungen innerhalb des Graphen mehrere Eltern haben und nicht wie\nein Baum nur einen Einzigen. Jedoch wird im weiteren Verlauf, auf Grund der etablierten Verwendung\ndes Begriffs \u201eBehavior Tree\u201c an dieser nicht ganz korrekten Bezeichnung festgehalten [10].\nAlle Tasks besitzen zur gleichartigen Handhabung ein gemeinsames Interface, welches die R\u00fcckgabe\neines Statuscodes \u00fcber die erfolgreiche oder fehlgeschlagene Ausf\u00fchrung der Tasks vorschreibt. Tasks\nk\u00f6nnen dabei wie Zust\u00e4nde eines HFSM aus Sub-Tasks bestehen, was eine hierarchische Anordnung von\nVerhaltensweisen erm\u00f6glicht. Im Allgemeinen werden drei Arten von Tasks unterschieden:\n\u2022Condtion: Bedingungen \u00fcberpr\u00fcfen Eigenschaften des aktuellen Weltzustands. H\u00e4u\ufb01g \ufb01ndet nur\neine simple \u00dcberpr\u00fcfung von Zustandswerten statt, allerdings k\u00f6nnen Bedingungen auch kom-\nplexere Berechnungen darstellen, wie z.B. die Berechnung und anschlie\u00dfende \u00dcberpr\u00fcfung des\nSichtradius eines Charakters.\n\u2022Action: Aktionen f\u00fchren zu \u00c4nderungen des Weltzustands oder des internen Zustandes des Cha-\nrakters. Beispielsweise das Ausf\u00fchren einer Animation oder einer Path\ufb01nding-Routine.\n\u2022Composite: Ein Kompositum ist ein Container f\u00fcr andere Tasks ( Condition ,Action undComposi-\nte) und erm\u00f6glicht somit die Hierarchische Anordnung von Tasks. Die einzelnen Composite -Tasks\nunterscheiden sich allerdings nicht durch ihre Menge an Sub-Tasks, sondern auch anhand ihrer\nAusf\u00fchrungssemantik der Sub-Tasks. Ein Behavior Tree verf\u00fcgt meistens \u00fcber mindestens folgende\nzwei grundlegende Composite -Arten:\n\u2013 Selector: Ein Selektor bestimmt die Ausf\u00fchrungsreihenfolge der Sub-Tasks, wo jedoch bei\nder ersten erfolgreich ausf\u00fchrbaren Task die Composite -Tasks ebenfalls als Erfolgreich gilt.\nBeispiele f\u00fcr Ausf\u00fchrungsreihenfolgen w\u00e4ren eine Links-nach-Rechts Traversierung oder eine\nZufallsauswahl.\n\u2013 Sequence: Eine Sequenz bestimmt ebenfalls eine Ausf\u00fchrungsreihenfolge, wobei jedoch die\nComposite -Tasks erst dann als Erf\u00fcllt angesehen wird, wenn jede Sub-Tasks erfolgreich ausge-\nf\u00fchrt werden kann.\nConditions undActions be\ufb01nden sich dabei ausschlie\u00dflich an Bl\u00e4ttern des Baums, wohingegen innere\nKnoten aus Composite -Tasks bestehen [35, S. 334-340].\nDer komplete Behavior Tree repr\u00e4sentiert somit alle m\u00f6glichen Aktionen, die ein Charakter ausf\u00fchren\nkann. Der Pfad von der Wurzel zu einem Blattknoten stellt dabei den Entscheidungsprozess der Auswahl\nder n\u00e4chsten auszuf\u00fchrenden Aktion des Charakters in der jeweiligen Situation dar. Gew\u00f6hnlich wird\ndabei eine Tiefensuche durchgef\u00fchrt, die allerdings durch entsprechende Composite -Tasks Implemen-\ntierungen, z.B. Random Selectors , f\u00fcr jeden Teilbaum separat angepasst werden kann. Werden mehrere\nGame-Zyklen f\u00fcr die Ausf\u00fchrung einer Task gebraucht, so kann sich entweder die letzte gew\u00e4hlte Task\ngemerkt und diese im n\u00e4chsten Schritt weiter ausgef\u00fchrt werden oder die Traversierung des Baums f\u00e4ngt\nwieder von der n\u00e4chst h\u00f6heren Task-Ebene bzw. sogar von der Wurzel aus erneut an [35, S. 334-340].\nDie von Alex Champamdard [10, 40] suggerierte Zielorientierung von Behavior Trees ergibt sich, wenn\nman die Composite -Tasks als zu erf\u00fcllende Ziele und die Sub-Tasks als die Menge der m\u00f6glichen Wege\ndiese Ziele zu erreichen betrachtet. Composite -Tasks erm\u00f6glichen dar\u00fcber hinaus auch die Priorisierung\nder Ziele untereinander, indem Ziele entweder in eine hierarchische Beziehung zueinander gestellt wer-\nden oder die Ausf\u00fchrungsreihenfolge einer Composite -Task die Zielauswahl direkt bestimmt. Abbildung\n13 zeigt einen exemplarischen Behavior Tree f\u00fcr das Eintreten in einen Raum. Ein Knoten mit einem\nFragezeichen bezeichnet dabei einen Selektor und ein Knoten mit einem Pfeil eine Sequenz. Alle Bl\u00e4tter\ndie nicht mit einem Fragezeichen am Ende des Bezeichners enden sind Actions , ansonsten handelt es\n38 4 Konzept und Rahmenbedingungen der Game AIsich um eine Condition . Der Wurzel-Selektor w\u00e4hlt je nach verwendeter Ausf\u00fchrungsreihenfolge einen\nder beiden Sequenzen aus. In diesem Beispiel kann man von einer links-nach-rechts Priorisierung aus-\ngehen. Wird demnach die linke Sequenz ausgew\u00e4hlt, pr\u00fcft die erste Condition , ob die T\u00fcr offen ist.\nSollte diese offen sein, wird mit einer erfolgreichen Ausf\u00fchrung der \u201eMove (into room)\u201c-Aktion die Se-\nquenz ebenfalls erfolgreich abgeschlossen. Da f\u00fcr den Erfolg eines Selektors nur eines seiner Kinder\nerfolgreich sein muss, ist in diesem konstruierten Beispiel die Wurzel ebenfalls Erfolgreich ausgef\u00fchrt\nworden. W\u00fcrde allerdings eine Task der Sequenz im linken Teilbaum scheitern, so w\u00fcrde die ganze Se-\nquenz scheitern und nach dem zur\u00fcckspringen zur Wurzel w\u00fcrde der linke Teilbaum ausprobiert werden.\nAbbildung 13: Beispiel f\u00fcr einen Behavior Tree f\u00fcrs Eintreten in einen Raum. Entnommen aus [35, S. 339].\nDie Vorteile eines Behaivor Trees sind die Verwendung eines restriktiven Vokabulars und der Fokussie-\nrung auf Tasks als zentrale Konstruktionseinheit, was das Verst\u00e4ndnis bei der Modellierung des Verhal-\ntens von NPCs deutlich erleichtert, da man im Gegensatz zu HFSMs nicht mehr in Zust\u00e4nden denken\nmuss. Die Trennung von Zielen und Verhalten, welche diese Erf\u00fcllen, die Wiederverwendbarkeit von\nVerhaltensweisen und die Modi\ufb01zierbarkeit bzw. Parametrisierbarkeit der Ausf\u00fchrungsreihenfolgen er-\nm\u00f6glichen einen \ufb02exiblen und vor allem leicht erweiterbaren Ansatz zur Beschreibung von komplexen\nVerhalten. M\u00f6gliche Erweiterungen sind u.a. die Verwendung von Selektoren die eine parallele Ausf\u00fch-\nrung ihrer Sub-Tasks unterst\u00fctzen, die Anwendung des Decorator Patterns auf Tasks (siehe dazu auch\nAbschnitt 4) oder die Integration von Team-Tasks, wie sie u.a. in Crysis [41] Verwendung \ufb01ndet.\nEin Nachteil von BTs kommt dann zum Tragen, wenn man tats\u00e4chlich Zust\u00e4nde statt Verhalten mo-\ndellieren will, was immer dann der Fall sein kann, wenn auf externe Ereignisse reagiert werden soll.\nEin Beispiel w\u00e4re das Abbrechen einer Patrouille bei pl\u00f6tzlichem Feindkontakt. Dies ist prinzipiell eben-\nfalls mit einem BT modellierbar, doch um einiges umst\u00e4ndlicher als mit einem HFSM. So wurde z.B.\nf\u00fcr Halo 2 die Erweiterung der Behavior Stimuli entworfen, die eine Event-Mechanik in den BT einf\u00fcgt.\nW\u00fcrde in dem eben aufgef\u00fchrten Patrouillen-Beispiel ein Feindkontakt gemeldet, so h\u00e4tte dies eine Sti-\nmuli-Erzeugung zur Folge, welche an einer oder mehreren de\ufb01nierten Stellen entsprechende spezielle\nVerhaltensweisen zum Umgang mit Feinden in den Baum einf\u00fcgen w\u00fcrde. Diese w\u00e4ren zeitlich befristet\nund somit nach einer gewissen Zeit wieder aus dem Baum entfernt werden [20].\n4.4 Behavior Tree 39Ein weiterer Nachteil von BTs ist, dass die Art und Weise wie die Aktionsauswahl ermittelt wird, eine\nForm des reaktiven Planens darstellt - einer sehr simplen Form der Planung. Selektoren erm\u00f6glichen\ndas Ausprobieren bestimmter Verhaltensweisen. Scheitern diese werden alternative Verhaltensweisen\nausprobiert. Ein Charakter kann in diesem Sinne nicht vorausschauend agieren, da er um eine Aktion\nzu evaluieren diese erst Ausf\u00fchren muss. Au\u00dferdem ist die Auswahl der Aktion oder der Aktionsket-\nten durch die Traversierung des BTs fest vorgegeben ist. Mit anderen Worten, auch wenn einem BT\nalle m\u00f6glichen Aktionen bekannt sind, verf\u00fcgt dieser nicht \u00fcber die M\u00f6glichkeit selbst zu bestimmen,\nwelche Aktionskette am besten auszuf\u00fchren ist. Er kann nur die Aktionskette \ufb01nden, die vom Designer\nf\u00fcr die jeweilige Situation als die beste erdacht wurde. Auf der anderen Seite wird somit im Gegen-\nsatz zum im Abschnitt 3.3 vorgestellten Decision Making -Konzept GOAP eine dank der deterministischen\nAusf\u00fchrungssemantik der Composite -Tasks viel st\u00e4rkere und direktere Ausf\u00fchrungskontrolle gew\u00e4hrleis-\ntet. Eine wichtige Voraussetzung f\u00fcr die Reproduzierbarkeit und Kon\ufb01gurierbarkeit der zu erzeugenden\nNetzwerklast.\n40 4 Konzept und Rahmenbedingungen der Game AI5 Design und Implementierungsdetails der Game AI\nDieses Kapitel beschreibt die genaue Umsetzung des Game AI -Konzepts und der aufgestellten funktio-\nnalen Anforderungen an diese aus Kapitel 4. Dazu wird das konkrete Design des Systems und seiner\nSubsysteme vorgestellt, sowie auf zahlreiche wichtige Implementierungsdetails eingegangen.\nIm ersten Abschnitt 5.1 \u201eEinbindung der Game AI in Planet PI4\u201c wird die Integration der Game AI in\ndas Computerspiel Planet PI4 beschrieben. Dazu werden die Abh\u00e4ngigkeiten zum System des Spiels und\ndie Einbindung der Game AI in den Spielablauf erl\u00e4utert.\nDer Abschnitt 5.2 \u201eGame AI-Architektur\u201c beschreibt die Realisierung des Game AI -Konzeptes auf Klas-\nsenebene. Dabei wird besonders der nicht-lineare Informations\ufb02uss im System beschrieben und welche\nKonsequenzen daraus entstehen.\nDie restlichen drei Abschnitte des Kapitels beschreiben die Realisierung der Subsysteme der operativen\n(Abschnitt 5.3), taktischen (Abschnitt 5.4) und strategischen Ebene (Abschnitt 5.5).\n5.1 Einbindung der Game AI in Planet PI4\nPlanet PI4 verwendet als zugrundeliegende 3D-Engine die Irrlicht Engine [1]. Irrlicht ist eine \u201eopen\nsource high performance realtime 3D engine\u201c, die Cross Platform -Entwicklungen und zahlreiche Fea-\ntures g\u00e4ngiger kommerzieller 3D-Engines unterst\u00fctzt. Planet PI4 und Irrlicht sind jeweils in C++ ent-\nwickelt worden, weswegen auch die Game AI in dieser Sprache geschrieben wurde. Die Game AI ist\nein wesentlicher Bestandteil der Planet PI4 -Architektur, ist jedoch als eigenst\u00e4ndige Komponente inso-\nweit abgekapselt, dass sich das Wissen der Game AI auf einige wenige Irrlicht-Datentypen und auf eine\n\u00fcberschaubare Menge an Planet PI4 -Schnittstellen oder Klassen beschr\u00e4nkt. Aus diesem Grund wird\nin den weiteren Ausf\u00fchrungen nur auf Aspekte von Planet PI4 und Irrlicht n\u00e4her eingegangen die f\u00fcr\ndas Verst\u00e4ndnis der Game AI -Entwicklung unerl\u00e4sslich sind. F\u00fcr genauere Ausf\u00fchrungen zur Planet PI4 -\nArchitektur oder Planet PI4 im Allgemeinen sei an dieser Stelle auf [27] und [25] verwiesen.\nDas Klassendiagramm aus Abbildung 14 zeigt, wie die Game AI inPlanet PI4 eingebunden wird. Um\ndieGame AI mit dem Spiel zu verbinden, muss die Game AI die zwei Schnittstellen IBotundITask imple-\nmentieren. IBotgibt dabei die Implementierung folgender Initialisierungsmethode vor:\npublic virtual void init(IGameStateView* state, IShipControl* shipControl,\nITaskEngine* taskEngine, IRandom* random)\nDiese Methode wird von der Game AI implementiert und vom Spiel automatisch einmal in der In-\nitialisierungsphase aufgerufen. Somit \u00fcbergibt das Spiel vor dem eigentlichen Spielstart die wichtigsten\nInformations- und Steuerungsobjekte an die Game AI , die hinter folgenden Schnittstellen versteckt sind:\n\u2022IGameStateView: Bietet Zugang zum aktuell partiell beobachtbaren Spielzustand. Partiell deswe-\ngen, weil in einem P2P-Spiel niemals s\u00e4mtliche (globale) Informationen einem Peer und somit\neinem Spieler zur Verf\u00fcgung stehen, sondern nur ausgew\u00e4hlte (partielle) Informationen die ma\u00df-\ngeblich von der aktuellen AOI abh\u00e4ngen. Bereitgestellt werden u.a. Informationen zu in der N\u00e4he\nbe\ufb01ndlichen Raumschiffen und statischen Objekten wie Asteroiden, Upgrade Points und Schild-\ngeneratoren. Dabei wird auf andere Raumschiffe \u00fcber RemoteShip -Klasse zugegriffen, wobei bei\nTeamkameraden erst der Umweg \u00fcber die PlayerId -Klasse genommen werden muss. Die stati-\nschen Objekte verf\u00fcgen mit der IStaticObject -Schnittstelle \u00fcber einen einheitlichen Zugriff. Die\n41Abbildung 14: Klassendiagramm zur Einbindung einer Game AI inPlanet PI4 .\nIGameStateView -Schnittstelle bietet dar\u00fcber hinaus noch Informationen \u00fcber den eigenen aktu-\nellen Health -Zustand, sowie den maximal erlaubten Health -Wert.\n\u2022IShipControl: Bietet Zugriff auf die \u00fcber die IShip -Schnittstelle zur Verf\u00fcgung gestellten Infor-\nmationen \u00fcber den aktuellen Zustand des Schiffes. IShip enth\u00e4lt u.a. Positions-, Orientierungs-,\nGeschwindigkeits- und Rotationsangaben, sowie Informationen \u00fcber Teamzugeh\u00f6rigkeit und die\neigene PlayerId . Diese Informationen von IShip werden um weitere Schiffsinformationen, wie etwa\naktueller Schildzustand oder Energielevel erg\u00e4nzt. Die zweite Aufgabe der Schnittstelle ist es der\nGame AI -Steuerungsm\u00f6glichkeiten des eigenen Raumschiffs zur Verf\u00fcgung zu stellen. Die Steue-\nrungsm\u00f6glichkeiten sind dabei dieselben, die auch dem Spieler \u00fcber die Tastatur/Maus Steuerung\nangeboten werden, d.h. Methoden zur Bewegung im Raum, eine Boost -Aktivierungsmethode, so-\nwie eine \ufb01re() -Methode.\n\u2022ITaskEngine: Bietet einerseits Zugriff auf die aktuelle Spielzeit, andererseits meldet sich die Game\nAI\u00fcber diese Schnittstelle mit folgender Methode bei der TaskEng\u00edne vonPlanet PI4 an:\npublic virtual void addTask(ITask* task, int ms, int ofs = 0)\nDieTaskEngine ist f\u00fcr die korrekte Ausf\u00fchrung von Subprozessen zust\u00e4ndig, wie z.B. der Game\nAI-Ausf\u00fchrung. Der zweite Parameter gibt an in welchem Millisekunden-Intervall die Task bzw. die\nGame AI ausgef\u00fchrt werden soll.\n42 5 Design und Implementierungsdetails der Game AI\u2022IRandom: Bietet mehrere Methoden zur deterministischen Erzeugung von Zufallszahlen, die \u00fcber\nalle Game-Instanzen hinweg dieselben Zahlenreihen erzeugen. Dies ist notwendig um reproduzier-\nbare Ergebnisse im Sinn der Lasterzeugung zu garantieren.\nDamit die IBot.init() -Methode \u00fcberhaupt ausgef\u00fchrt werden kann, muss die GameAI -Klasse der Ga-\nmeApplication -Klasse bekannt gemacht werden. Dies ist leider momentan nur durch direkte \u00c4nderung\nam Code m\u00f6glich. Die GameApplication -Klasse verwaltet welche konkrete Game AI -Implementierung ein-\ngesetzt werden soll. Eine neue Implementierung muss entsprechend diesem Auswahlprozess hinzugef\u00fcgt\nwerden.\nDie alleinige GameApplication -Bekanntmachung ist allerdings nicht ausreichend. Sie deckt nur die In-\nitialisierungsphase ab und muss somit um die in der Beschreibung zur ITaskEngine -Schnittstelle erw\u00e4hnte\nAnmeldung der Game AI bei der TaksEngine vonPlanet PI4 erg\u00e4nzt werden. Damit diese gelingt, muss\ndieGameAI -Klasse die ITask -Schnittstelle implementieren, sodass sie sich als ITask -Objekt der TaskEngine\nmittels eines Aufrufs der addTask() -Methode selbst \u00fcbergeben kann. Jede ITask -Realisierung muss dabei\nfolgende Methode implementieren:\nprotected virtual Result executeTask()\nDieexecuteTask() -Methode wird nach der Initialisierungsphase von der TaskEngine wiederholt aufge-\nrufen. Wenn m\u00f6glich entspricht das Intervall zwischen den einzelnen Methoden-Aufrufen dabei dem\n\u00fcbergebenen Intervall-Parameter bei der Anmeldung. Mit diesem Callback-Mechanismus wird mit jedem\nexecuteTask() -Aufruf, der Game AI entsprechende Zeit zur Verf\u00fcgung gestellt, um eigene Berechnungen\nzur Aktionsauswahl und anschlie\u00dfender Aktionsausf\u00fchrung mittels der IShipControl -Schnittstelle vorzu-\nnehmen. Der R\u00fcckgabetyp Result dient dabei als Statusmeldung die von der TaskEngine entsprechend\ninterpretiert werden kann.\n5.2 Game AI-Architektur\nWie die Abbildung 14 aus dem vorherigen Abschnitt bereits zeigte, ist die GameAI -Klasse die Schnitt-\nstelle zwischen dem Spiel Planet PI4 und der Game AI bzw. dem dadurch repr\u00e4sentierten Bot. Die Ga-\nmeAI -Klasse hat somit die Kenntnis \u00fcber die vorgestellten Informations- und Steuerungsobjekte und\nimplementiert zur Integration in den Spielablauf die beiden wichtigen Schnittstellen IBotundITask . Die\nkonkrete Implementierung der GameAI -Klasse ist dabei leichtgewichtig, was haupts\u00e4chlich daran liegt,\ndass sie alle Verantwortlichkeiten zur Bestimmung und Ausf\u00fchrung der n\u00e4chsten Aktion bzw. den dazu\ngeh\u00f6rigen Berechnungen an andere Klassen weiterleitet. Die Aufgaben der GameAI -Klasse beschr\u00e4nken\nsich somit auf folgende drei Aspekte:\n\u2022 Realisiert die Anbindung an Planet PI4 und den Spielablauf. Dient der GameApplication -Klasse als\nparametrisierbare Facade -Klasse [16, S. 212-222] f\u00fcr den Bot.\n\u2022 Ist f\u00fcr die Erstellung und Parametrisierung der konkret zu verwendeten Implementierungen zust\u00e4n-\ndig, an die die Verantwortlichkeiten zur Bestimmung der n\u00e4chsten Aktion weitergereicht werden.\nEin wichtiger Punkt ist hier die Weiterleitung oder Bereitstellung der Informations- und Steue-\nrungsobjekte an die verantwortlichen Objekte.\n\u2022 Leitet nach Aufruf der executeTask() -Methode die Bestimmung und Ausf\u00fchrung der n\u00e4chsten Akti-\non an daf\u00fcr zust\u00e4ndige Klassen bzw. Objekte weiter.\nDie angesprochene Weiterleitung der Verantwortlichkeiten wird dabei nicht anhand einiger weniger di-\nrekt der GameAI -Klasse bekannter Klassen realisiert. Das Klassendiagramm aus Abbildung 15 zeigt, dass\n5.2 Game AI-Architektur 43Abbildung 15: Die Game AI-Architektur mit dem Zusammenspiel der wichtigsten Komponenten und Subsysteme.\nstattdessen f\u00fcr die Aufgabe der Aktionsbestimmung und -ausf\u00fchrung ein Ge\ufb02echt aus drei Subsystemen\neingesetzt wird. Die Bezeichnung und die Aufgabenbereiche dieser Subsysteme entspricht weitestgehend\nder konzeptionellen Beschreibung der drei Ebenen der Gama AI aus Abschnitt 4.3.\nAbbildung 15 zeigt das hierarchische Zusammenspiel der Hauptkomponenten der drei Subsysteme mit\nderGameAI -Klasse. Die GameAI -Klasse st\u00f6\u00dft dazu den Aktionsauswahl-Prozess mit dem Aufruf des Faca-\nde-Objekts der strategischen Ebene bzw. des strategischen Subsystems an. In diesem Subsystem be\ufb01nden\nsich, wie in den anderen auch, weitere Klassen und Komponenten auf die sp\u00e4ter noch in den einzelnen\nAbschnitten zum jeweiligen Subsystem n\u00e4her eingegangen wird.\nNachdem das strategische Subsystem seine Berechnungen beendet hat, gibt es die Informationen an\ndie taktische Ebene weiter, dazu de\ufb01niert das taktische Subsystem selber auf welche Art und Weise und\nzu welchem Zweck zus\u00e4tzliche Informationen, Entscheidungen oder Zielvorgaben ihm hinzugef\u00fcgt wer-\nden k\u00f6nnen. Nachdem alles Notwendige weitergereicht worden ist, leitet das strategische Subsystem den\nDecision Making -Auswahlprozess des taktischen Subsystems ein, an dessen Ende immer die getroffene\nEntscheidung \u00fcber die als n\u00e4chstes auszuf\u00fchrende Aktion steht. Das taktische Subsystem hat dabei aller-\ndings keinen direkten Zugriff zur Steuerung des Schiffs, wie dieser z.B. \u00fcber IShipControl -Schnittstelle\nm\u00f6glich w\u00e4re, um damit die gew\u00fcnschte Aktion selber auszuf\u00fchren. Stattdessen erh\u00e4lt das taktische\nSubsystem Zugriff auf die von der operativen Ebene angebotenen Aktionen zur Steuerung des Schiffs\n\u00fcber das entsprechende Facade -Objekt des operativen Subsystems.\nDas operative Subsystem kapselt somit alle vom Agenten ausf\u00fchrbaren Aktionen in einer eigenen\nSchnittstelle. Bei den angebotenen Aktionen handelt es sich nicht nur um die direkte Weiterleitung\nprimitiver Befehle an die daf\u00fcr zust\u00e4ndigen Schnittstellen wie z.B. der IShipControl -Schnittstelle. Die\n44 5 Design und Implementierungsdetails der Game AIoperative Ebene bietet vielmehr wie die Steering -Ebene von Reynolds bestimmte komplexere Behaviors\nan, die bereits die Kombination bestimmter Aktionsausf\u00fchrungen auf Low Level -Ebene einschlie\u00dft. Im\nGegensatz zur reynoldschen Steering -Ebene beschr\u00e4nken sich die dabei angebotenen Behaviors nicht nur\nauf die Bewegung des Agenten, sondern Erweitern das Konzept auf Behaviors zur Bek\u00e4mpfung von Geg-\nnern, der Eroberung von Upgrade Points und der Wiederherstellung der Lebensenergie mit Hilfe von\nSchildgeneratoren. Ein Beispiel soll dieses Zusammenspiel verdeutlichen.\nMan stelle sich vor, die taktische Ebene unterst\u00fctze einen Decision Making -Prozess, der die unter-\nschiedlichen Charakterz\u00fcge eines Bot-Agenten ber\u00fccksichtigt. Die strategische Ebene k\u00f6nnte solche Cha-\nraktereigenschaften setzen und so z.B. bestimmen, dass der momentane Bot sehr aggressiv spielen soll.\nMit dieser strategischen Vorgabe w\u00fcrde der Decision Making -Prozess der taktischen Ebene eventuell an-\ndere Aktionen ausw\u00e4hlen, als er es f\u00fcr nicht aggressive Bots tun w\u00fcrde. Diese so getroffene Auswahl\neiner eher aggressiven Aktion w\u00fcrde dann von der taktischen Ebene zur Ausf\u00fchrung an die operative\nEbene weitergereicht werden. Nehme man weiter an es handelt sich dabei um die Aktion \u201eFightEne-\nmy XY\u201c, dann w\u00fcrde die operative Ebene versuchen diesen Befehl auszuf\u00fchren, k\u00f6nnte aber davor vlt.\nfeststellen, dass der Feind sich hinter einem Asteroiden be\ufb01ndet und somit nicht direkt unter Beschuss\ngenommen werden kann. Die operative Ebene w\u00fcrde in so einer Situation keine Fehlermeldung an die\ntaktische Ebene zur\u00fcckgeben und somit nicht anschlie\u00dfend den Dienst verweigern. Sie w\u00fcrde eher die\nAusf\u00fchrung der eigentlichen Fight -Aktion ignorieren und stattdessen versuchen einen Weg zu \ufb01nden\ndem Asteroiden auszuweichen, damit im Anschluss daran der Feind schlie\u00dflich erfolgreich angegriffen\nwerden kann. Wenn die taktische Ebene in darauffolgenden Spielzyklen irgendwann eine andere n\u00e4chste\nAktion als die Fight -Aktion bestimmen w\u00fcrde und der Agent noch mit dem Ausweichen des Asteroiden\nbesch\u00e4ftigt w\u00e4re oder soeben das Ausweichen beendet w\u00fcrde, so kann es durchaus vorkommen, dass\ndieFight -Aktion, obwohl von der taktischen Ebene \u00fcber mehrere Spielzyklen zur Ausf\u00fchrung bestimmt,\nnicht einmal tats\u00e4chlich ausgef\u00fchrt worden ist.\nEin wichtiger Aspekt beim Zusammenspiel der Ebenen ist, dass die Ausf\u00fchrungsfrequenz jedes ein-\nzelnen Subsystems unabh\u00e4ngig voneinander regulierbar ist. Dazu wird ein zur Initialisierungszeit ein-\nstellbarer Prozess -Parameter des entsprechenden Facade -Objekts gesetzt. Der Prozess -Parameter ist dem\nIntervall-Parameter der addTask() -Methode der TaskEngine vonPlanet PI4 nachempfunden und soll die\nZeit zwischen zwei aufeinanderfolgenden Ausf\u00fchrungen bestimmen. Weil die Auslassung von Aktionen\nnicht ratsam erscheint, sollte zumindest das operative Subsystem mit dem gleichen Intervall betrieben\nwerden, wie die GameAI -Klasse. Somit wird sichergestellt, dass immer eine Aktion ausgef\u00fchrt wird, auch\nwenn es sich dabei nur um die Wiederholung der letzten Aktion handelt, weil die Neuberechnungen der\ntaktischen Ebene in einem Zyklus ausgelassen wurden.\nAuch wenn eines oder mehrere der Subsysteme im aktuellen Spielzyklus ausgelassen werden sollen,\nso werden doch immer alle drei Facade -Objekte in jedem Zyklus aufgerufen und ausgef\u00fchrt, da diese f\u00fcr\ndie Entscheidung der (Nicht-)Ausf\u00fchrung zust\u00e4ndig sind. Es wird demnach unabh\u00e4ngig der Auslassung\neiniger Subsysteme immer an der in Abbildung 16 dargestellten Ausf\u00fchrungsreihenfolge festgehalten,\ndie jeweils von der TaskEngine vonPlanet PI4 ausgehend beginnt.\nDamit das Facade -Objekt der operativen Ebene immer eine Aktion zur Ausf\u00fchrung bestimmen kann,\nspeichert sich das taktische Facade -Objekt seine jeweils letzte, f\u00fcr die operative Ebene relevante, Aktions-\nbestimmung und reicht diese im Falle eines auslassenden Berechnungszyklus der taktischen Ebene an die\noperative Ebene weiter. Das strategische Facade -Objekt muss keine letzte Aktion zwischenspeichern, da\ndiese nur Kon\ufb01gurationen an der taktischen Ebene vornimmt, die von dieser sowieso gespeichert werden\nm\u00fcssen.\n5.2 Game AI-Architektur 45Abbildung 16: Die feste Ausf\u00fchrungsreihenfolge der Komponenten der Game AI und der von Planet PI4 innerhalb\neines Spielzyklus.\nDamit die drei Ebenen ihrer Arbeit nachgehen k\u00f6nnen, m\u00fcssen sie vor allem irgendwie einen Zu-\ngriff auf die von Planet PI4 bereitgestellten Informationen und Steuerungsm\u00f6glichkeiten erhalten. Dabei\nwerden die von einer Ebene ben\u00f6tigten Schnittstellen in der Regel an das jeweilige Facade -Objekt ei-\nner Ebene zur Initialisierungszeit direkt weitergereicht. So wird z.B. die IShipControl -Schnittstelle an\ndasFacade -Objekt der operativen Ebene weitergereicht, da diese f\u00fcr die tats\u00e4chliche Aktionsrealisie-\nrung zust\u00e4ndig ist. Beim Zugriff auf Informationen die keine Listener -Anmeldung (siehe Abschnitt 5.4)\nvoraussetzen wird jedoch mit der Bereitstellung einer eigenen IWorlState -Schnittstelle ein anderer Weg\ndes gemeinsamen Zugriffs gew\u00e4hlt. Der Grund hierf\u00fcr ist, dass die der Game AI bereitgestellten Infor-\nmationen sich im Grunde auf alle vier im vorherigen Abschnitt vorgestellten Schnittstellen verteilen\nund dar\u00fcber hinaus noch zus\u00e4tzlich zu reinen Informationen andere Funktionen bereitstellen, wie z.B.\ndie Steuerungsfunktionen von IShipControl . Zur Vermeidung der Unterscheidung der einzelnen Schnitt-\nstellen bei der Bot-Implementierung und zur Vermeidung der unn\u00f6tigen Gew\u00e4hrung nicht zwingend\nerforderlicher Zugriffsrechte auf Planet PI4 (z.B. Steuerungsm\u00f6glichkeiten). Werden alle reinen Spielin-\nformationen die f\u00fcr den Bot in irgendeiner Weise relevant sind in der IWorldSate -Schnittstelle geb\u00fcndelt\nund allen drei Ebenen ein direkter Zugriff darauf gew\u00e4hrt. Mit dieser B\u00fcndelung der Informationen in\neiner Schnittstelle wird au\u00dferdem ganz im Sinne des Interface Segregation Principle (ISP) [32] erreicht,\ndass die drei Ebenen zumindest im wichtigen Informationsbeschaffungskontext nicht von anderen f\u00fcr\nsie irrelevanten \u00c4nderungen, wie z.B. \u00c4nderungen an der Raumschiffsteuerung, betroffen werden. So-\nmit sind die drei Ebenen der Game AI ein St\u00fcck mehr gegen\u00fcber zuk\u00fcnftigen Refactoring-Ma\u00dfnahmen\nzur S\u00e4uberung der Schnittstellen vorbereitet, deren im Zuge der Weiterentwicklung des Spiels durchaus\nals realistisch anzunehmen sind.\nDas Anbieten einer einheitlichen Informationsschnittstelle die vom konkreten Informationsbezug ab-\nstrahiert, erm\u00f6glicht auch zuk\u00fcnftige Performance-Optimierungen. K\u00f6nnen an dieser Stelle doch leicht\nleistungskritische Aufrufe, wie die Abfrage aller in der n\u00e4her be\ufb01ndlicher Schiffe zwischengespeichert\nwerden und somit der Zugriff darauf beschleunigt werden. Ein Zwischenspeichern und Cachen ist deswe-\ngen auch eine erfolgsversprechende Optimierung, weil die Aufteilung der Game AI in drei voneinander\nabgekapselten Hierarchieebenen keinen direkten Informations\ufb02uss erlaubt. Abfrageergebnisse wie die\nNachbarschaftsliste k\u00f6nnen nicht ohne weiteres zwischen den Ebenen weitergereicht werden, sondern\nerfolgen voneinander unabh\u00e4ngig und k\u00f6nnen sich somit innerhalb eines Zyklus wiederholen.\n46 5 Design und Implementierungsdetails der Game AI5.3 Operative Ebene\nDie operative Ebene ist die unterste der drei Ebenen der vorgestellten Game AI -Hierarchie aus Abschnitt\n5.2. Ihre Aufgabe ist die Umsetzung der Ziele der taktischen Ebene. Dazu wird eine Menge an Ak-\ntionen de\ufb01niert und der taktischen Ebene \u00fcber die IOptController -Schnittstelle zur Verf\u00fcgung gestellt.\nDie angebotenen Aktionen sind dabei keine primitiven Aktionen, wie das Abfeuern eines Schusses oder\nder Ausf\u00fchrung einer einfachen Steuerungsbewegung, sondern komplexe Aktionen die aus der kombi-\nnierten Ausf\u00fchrung oder Mehrfachausf\u00fchrung primitiver Aktionen bestehen k\u00f6nnen. Welche konkreten\nkomplexen Aktionen genau bereitgestellt werden, listet und erl\u00e4utert kurz die folgende Aufz\u00e4hlung:\n\u2022Arrive Position: Eine beliebige Position soll erreicht werden ohne dabei \u00fcber das eigentliche Posi-\ntionsziel hinauszuschie\u00dfen.\n\u2022Capture Upgrade Point: EinUpgrade Point soll angesteuert und erobert werden.\n\u2022Evade Enemy: Erm\u00f6glicht die Flucht vor beweglichen Zielen, d.h. vorrangig vor gegnerischen\nRaumschiffen.\n\u2022Fight Enemy: Erm\u00f6glicht das Abfangen und Bek\u00e4mpfen (gegnerischer) Raumschiffe.\n\u2022Flee: Es soll sich so schnell wie m\u00f6glich von einem Punkt entfernt werden.\n\u2022Pursue Enemy: Erm\u00f6glicht die Verfolgung bzw. das Abfangen (gegnerischer) Raumschiffe.\n\u2022Reset: Setz den internen Zustand der operativen Ebene zur\u00fcck. Davon sind allen voran Zustands-\nbehaftete Berechnungen betroffen.\n\u2022Restore Energy: Ein Schildgenerator soll angesteuert werden und die Lebenenergie aufgeladen\nwerden.\n\u2022Wander: Es soll eine bestimmte Region der Spielwelt erkundet werden.\nAbbildung 17: DieIOptController -Schnittstelle die den Leistungskatalog der operativen Ebene de\ufb01niert.\nJede dieser sieben Aktionen verf\u00fcgt dabei \u00fcber mehrere Parameter die die genaue Aktionsausf\u00fch-\nrung ma\u00dfgeblich beein\ufb02ussen. Abbildung 17 zeigt die Methodensignatur der Aktionen, welche die\njeweiligen Parameter einer Aktion de\ufb01niert. Aus Gr\u00fcnden der \u00dcbersicht wurden einige wenige Para-\nmeter und genaue Typspezi\ufb01zierer wie const-, Pointer- oder Referenzangaben ausgelassen. Die genauen\nParameterbedeutungen oder m\u00f6gliche Restriktionen wie Intervall-Beschr\u00e4nkungen k\u00f6nnen direkt den\nCode-Kommentaren entnommen werden.\n5.3 Operative Ebene 47Die angebotenen Aktionen werden zwar wie in Abbildung 15 dargestellt von der OptController -Klasse,\nwelche die IOptController -Schnittstelle implementiert, bereitgestellt, doch wird die tats\u00e4chliche Aktions-\numsetzung an die zwei Subsysteme Steering Pipeline undCombat System weiterreicht. Das Strukturdia-\ngramm aus Abbildung 18 verdeutlicht diese Weiterleitung der Verantwortlichkeiten, wobei die Steering\nPipeline f\u00fcr die Umsetzung der Bewegungsaktionen Arrive ,Evade ,Flee,Pursue und Wander und das\nCombat System f\u00fcr die Kampfaktionen FightEnemy ,CaptureUP undRestoreEnergy zust\u00e4ndig ist. Neben\nder Bereitstellung der Aktionen nach au\u00dfen ist die Organisation, Verwaltung und Kon\ufb01guration der Akti-\nonsausf\u00fchrung mittels ausgew\u00e4hlter Subsysteme eine weitere wichtige Aufgabe der OptController -Klasse.\nAbbildung 18: Die Struktur der operativen Ebene und die Abh\u00e4ngigkeiten zu anderen Systemebenen.\nZwischen der konkreten OptController -Realisierung und den Subsystemen be\ufb01nden sich keine weiteren\nZugriffs-Schnittstellen. Aus diesem Grund ist auf den ersten Blick die Kopplung zwischen diesen als hoch\nanzusehen. Dar\u00fcber hinaus stellt es gleichzeitig einen Versto\u00df gegen das Dependency Inversion Principle\n(DIP) [33] dar, welches die Wiederverwendung von h\u00f6heren Ebenen mittels gemeinsamer Abstraktionen\nforciert. M\u00f6chte man andere Subsysteme verwenden oder bestehende Implementierungen austauschen\nist es unter Umst\u00e4nden ratsamer eine neue IOptController -Realisierung zu implementieren. Dieser Nach-\nteil wird allerdings an dieser Stelle bewusst in Kauf genommen. Denn anders als beim Standard-DIP-Fall\nist die Logik der h\u00f6heren Ebene, d.h. die von der OptController -Klasse realisierte Logik, vergleichsweise\nsimpel und eine Wiederverwendung entsprechend von geringem Nutzen. Auf der anderen Seite hingegen\nist die Wiederverwendung der Subsysteme, die die eigentliche Logik zur Aktionsrealisierung enthalten\nvon bedeutend gr\u00f6\u00dferem Nutzen.\nUm die Wiederverwendung der Subsysteme zu erleichtern, de\ufb01nieren die Subsysteme mit den Schnitt-\nstellen ISteeringShip und ICombatShip die Informationen oder Steuerungsoperationen die sie ben\u00f6ti-\n48 5 Design und Implementierungsdetails der Game AIgen um ihrer Aufgabe nachgehen zu k\u00f6nnen. Diese Schnittstellen werden von den beiden Klassen\nSteeringShip und CombatShip implementiert, die wiederum von der OptController -Klasse erstellt wer-\nden. Damit ist die OptController -Klasse \u00fcber die Implementierung der Subsystem-Schnittstellen daf\u00fcr\nzust\u00e4ndig die ausgew\u00e4hlten Informationen und Steuerungsm\u00f6glichkeiten, die ihr \u00fcber den direkten Zu-\ngriff auf die IWorldState -Schnittstelle und die IShipControll -Schnittstelle zur Verf\u00fcgungen stehen, an die\nSubsysteme weiterzuleiten. Diese Designentscheidung entkoppelt die Subsysteme vollst\u00e4ndig von Pla-\nnet PI4 -Schnittstellen wie IShipControl und was im Zuge der Wiederverwendbarkeit noch viel wich-\ntiger erscheint von eigenen Schnittstellen-Kreationen der Game AI wie die IWorldState -Schnittstelle.\nDiese Entkopplung erleichtert somit erheblich den Einsatz der Subsysteme in v\u00f6llig unterschiedlichen\nIOptController -Implementierungen oder gar in vollst\u00e4ndig anderen Bot-Implementierung wie z.B. der\nin Abschnitt 3.5 vorgestellten Vorg\u00e4nger-Implementierung von Dimitri Wulffert oder zuk\u00fcnftigen Bot-\nImplementierungen.\n5.3.1 Steering Pipeline\nDie Aufgabe der Steering Pipeline als Subsystem der operativen Ebene ist die Implementierung und Ver-\nwaltung von Bewegungsaktionen bzw. von Steering Behaviors , die von der IOptController -Schnittstelle\ndem restlichen System zur Verf\u00fcgung gestellt werden. Steering Behaviors wurden in Abschnitt 2.4\nausf\u00fchrlich vorgestellt. Dabei wurden mehrere M\u00f6glichkeiten der Realisierung einer solchen Steering -\nKomponente pr\u00e4sentiert, sowie auf etwaige Vor- und Nachteile dieser eingegangen. Der Ansatz der\nSteering Pipeline l\u00e4sst sich in diesem Kontext der Arbitration -Fraktion zuordnen, wobei das gr\u00f6\u00dfte Unter-\nscheidungskriterium zu anderen Arbitration oder auch Steering -Ans\u00e4tzen der kooperative Charakter der\neinzelnen Steering Behaviors untereinander darstellt. Entwickelt wurde der Ansatz erstmals von Marcin\nChady und u.a. von Millington und Funge in [35, S. 108-120] ausf\u00fchrlich vorgestellt. Obwohl der An-\nsatz einer Steering Pipeline viele Vorteile bietet, \ufb01ndet er doch in kommerziellen Computerspielen bisher\nkeine nennenswerte Verwendung.\nAbbildung 19: (a) Die generelle Struktur der Steering Pipeline . Angelehnt an [35, S. 108]. (b) Der Aufbau\nund die Elemente der SteeringForce -Datenstruktur, die von der hier vorgestellten Steering Pipeli-\nne-Implementierung verwendet wird.\nAbbildung 19 (a) zeigt den generellen Aufbau einer Steering Pipeline nach Millington und Funge. Dem-\nnach besteht die Steering Pipeline mitTargeter ,Decomposer ,Constraint undActuator aus vier wichtigen\nKomponentenarten und mit SteeringForce aus einer zentralen Datenstruktur. Mit Ausnahme der Actuator -\nKomponentenart verbergen sich hinter den anderen Arten die einzelnen Steering Behaviors . Die Steering\n5.3 Operative Ebene 49Behaviors werden den einzelnen Komponentenarten zugeordnet und somit der dargestellten hierarchi-\nschen Komponenten-Struktur unterstellt. Die Verwendung einer Hierarchie bedeutet nichts anderes als\neine Gruppen-Priorisierung der Steering Behaviors , wie es f\u00fcr Arbitration -Ans\u00e4tze \u00fcblich ist. Das Besonde-\nre an der Steering Pipeline ist nun, das mit der Verwendung einer gemeinsamen Ergebnis-Datenstruktur\n(SteeringForce ) eine M\u00f6glichkeit geschaffen wird wie ausgew\u00e4hlte Steering Behaviors miteinander kom-\nmunizieren k\u00f6nnen, um somit ihre Ergebnisse untereinander austauschen zu k\u00f6nnen. Aus diesem Grund\nbeschreiben Millington und Funge den Steering Pipeline -Ansatz als \u201ecooperative arbitration approach\u201c,\ndessen einzelne Komponenten und konkrete Realisierungen im Rahmen dieser Master-Thesis im Folgen-\nden n\u00e4her erl\u00e4utert werden sollen.\nTargeters spezi\ufb01zieren die konkreten Steering Behaviors die von au\u00dfen aus aufgerufen werden k\u00f6n-\nnen. Sie sind voneinander unabh\u00e4ngig und pro Spielzyklus sollte jeweils nur ein bestimmter Targeter\nausgef\u00fchrt werden, weswegen Targeters auch nicht untereinander zu kommunizieren brauchen. Targeters\nde\ufb01nieren sozusagen das Bewegungsziel des Agenten. Abbildung 20 zeigt die von der Game AI imple-\nmentierte Targeter -Menge. Ein Vergleich mit der Methodenspezi\ufb01kation der IOptController -Schnittstelle\naus Abbildung 17 zeigt, dass hier die durch Methoden repr\u00e4sentierten Aktionen beinahe 1:1 abgebildet\nworden sind. Einzig die Existenz des Face Targeters mag hier vielleicht auffallend erscheinen, dessen feh-\nlen allerdings insoweit erkl\u00e4rt werden kann, dass der Face Targeter einSteering Behavior implementiert,\nwelches als zu rudiment\u00e4r bzw. low level m\u00e4\u00dfig f\u00fcr die einmalige Ausf\u00fchrung von der taktische Ebene\naus angesehen werden kann und deswegen dieser auch nicht angeboten werden muss.\nAbbildung 20: Vererbungshierarchie der Targeter -Menge der Steering Pipeline .\nF\u00fcr die Funktionsweise der Steering Pipeline ist die Existenz des Face Targeters hingegen von elemen-\ntarer Bedeutung. Denn obwohl die Targeter -Ausf\u00fchrung von der taktischen Ebene aus betrachtet, die\n\u00fcber IOptController einen indirekten bzw. gekapselten Zugang zur Targeter -Ausf\u00fchrung erlangt, als von-\neinander unabh\u00e4ngig betrachtet wird und pro Spielzyklus sich f\u00fcr jeweils eines der von einem Targeter\nrepr\u00e4sentierten Steering Behavior entschieden werden muss, so k\u00f6nnen die Targeter zur Realisierung ihres\nSteering Behaviors jedoch auf beliebige Weise untereinander zugreifen. Dies wird im konkreten Design\ndadurch realisiert, dass den Targeters Zugang zur SteeringPipeline -Klasse gew\u00e4hrt wird, welches die Men-\nge der Targeters verwaltet. Somit k\u00f6nnen Targeters , wie im urspr\u00fcnglichen Steering -Modell nach Reynolds\nauf den Ergebnissen untereinander aufbauen und somit durch die Kombination und Erweiterung der Er-\ngebnisse einzelner Targeters komplexe Steering Behaviors realisieren. Der Face Targeter implementiert mit\nder Ausrichtung des Raumschiffes auf eine bestimmte Position oder ein bestimmtes Objekt ein Steering\nBehavior , welches vom Arrive Targeter verwendet wird, das wiederum von fast allen anderen Targeters\nf\u00fcr die eigenen Berechnungen benutzt wird.\nDamit die einzelnen Targeters auf den Ergebnissen der anderen Targeters aufbauen k\u00f6nnen und damit\nebenfalls die Targeter -Ergebnisse weiter entlang der Steering Pipeline gereicht werden k\u00f6nnen, wird mit\nderSteeringForce -Datenstruktur fortw\u00e4hrend an einem gemeinsamen Ergebnis gearbeitet. Die Targeters\nf\u00fchren wie die Steering Behaviors von Reynolds nicht die Aktionen direkt aus, sondern sie halten ihre\nErgebnisse in einer Instanz der SteeringForce -Datenstruktur fest. Aus diesen Grund implementieren alle\nTargeters die in Abbildung 20 dargestellte ITargeter -Schnittstelle, die aus folgender Methode besteht:\n50 5 Design und Implementierungsdetails der Game AISteeringForce calcSteeringGoal()\nAnders als bei Reynolds umfasst die SteeringForce -Datenstuktur nicht ausschlie\u00dflich einen einzel-\nnen Beschleunigungs-Vektor, sondern gleich mehrere f\u00fcr die Steuerung des Raumschiffes wichtige\nSteuerungs-Variablen. Welche das konkret sind kann der Abbbildung 19 (b) entnommen werden. Ei-\nnige Elemente dienen dabei nicht der Steuerung des Schiffes, sondern eher dem Informationsaustausch\nzwischen den einzelnen Targeters . Ein Biespiel hierf\u00fcr ist die Berechnung des aktuellen Richtungsvektors\nzum Ziel (direction), dieser enth\u00e4lt keine Steuerungsanweisung, wird aber von vielen Targerts zur wei-\nteren Berechnung ben\u00f6tigt.\nDie Ergebnis-Struktur kann von den einzelnen Targeters um jeweils weitere Teilergebnisse erweitert\nwerden. Damit Targeters nicht unbewusst bereits gespeicherte Ergebnisse \u00fcberschreiben, wurde der Da-\ntenstruktur ein Mechanismus hinzugef\u00fcgt, womit \u00fcberpr\u00fcft werden kann, ob bestehende Ergebnisele-\nmente bereits von anderen Targeters gesetzt wurden. Dies wurde realisiert indem jedem Datenelement\neine boolsche isDataElementSet -Variable hinzugef\u00fcgt wurde, die allerdings \u00dcbersichthalber in der Ab-\nbildung weggelassen wurden. Die isActive ()-Methode \u00fcberpr\u00fcft, ob \u00fcberhaupt eins der Datenelemente\ngesetzt wurde und somit das Ergebnis g\u00fcltig ist. Die clear() -Methode setzt die boolschen isDataElement-\nSet-Variablen wieder auf \u201efalse\u201c zur\u00fcck.\nDecomposers nehmen die Zielvorgabe, repr\u00e4sentiert durch die Berechnungsergebnisse der Steering-\nForce -Datenstruktur, eines Targeters entgegen und versuchen durch Zerlegung in weitere Unterziele die\nverbesserte und effektivere Umsetzung dieses Ziels. Zum Beispiel k\u00f6nnte ein Path\ufb01nding Decomposer zur\nRoutenbestimmung f\u00fcr weit entfernte Punkte auf der Karte eingesetzt werden. Daf\u00fcr k\u00f6nnte ein path\nplanning -Algorithmus oder ein K\u00fcrzeste-Wege-Algorithmus eingesetzt werden. Ein weiterer Decompo-\nserk\u00f6nnte hingegen f\u00fcr die Routenverfolgung zust\u00e4ndig sein und eventuell auftretende Abweichungen\ndurch das Hinzuf\u00fcgen neuer Zwischenziele korrigieren. Dies ist ebenfalls ein Beispiel daf\u00fcr, dass die\nDecomposer , wie in Abbildung 19 angedeutet, in einer festen Reihenfolge angeordnet sind und nachein-\nander ihre Arbeit erledigen.\nIn der aktuellen Steering Pipeline -Implementierung der Game AI ist zwar eine IDecomposer -Schnittstelle\nde\ufb01niert und somit der Decomposer -Einsatz vorgesehen, jedoch existieren momentan noch keine konkre-\nten Schnittstellen-Realisierungen. Dieser Umstand ist in erster Line dem bewussten Verzicht auf den\nEinsatz einer Path\ufb01nding -Routine geschuldet. Path\ufb01nding -Algorithmen \ufb01nden zugegebenerma\u00dfen in fast\njedem (gr\u00f6\u00dferen) Spiel Verwendung, dennoch gibt es in Planet PI4 drei wichtige Gr\u00fcnde die gegen einen\nEinsatz sprechen:\n\u2022 Wegen des dezentralen Charakters des Spiels existieren keine globalen Informationen \u00fcber das ak-\ntuelle Level und m\u00fcssten somit von der Game AI selbst erkundet und verwaltet werden.\n\u2022 Aus dem ersten Grund ergibt sich ein nicht zu untersch\u00e4tzender Berechnungs- und Speicherauf-\nwand, der zu einer unmittelbaren Verschlechterung der Skalierbarkeit der Game AI und somit von\nPlanet PI4 f\u00fchren w\u00fcrde. Die in Abschnitt 1.2 formulierte Zielsetzung der Master-Thesis hebt die\nSkalierbarkeit als ein wichtiges zu erf\u00fcllendes Kriterium hervor.\n\u2022Path\ufb01nding ist immer dann von gro\u00dfen Nutzen, wenn oft statischen Hindernissen ausgewichen\nwerden muss oder sich innerhalb enger verschlungener Innenareale bewegt wird, wo ein reak-\ntives statt vorrauschauendes Ausweichen vor Hindernissen zu neuen Hindernissen oder sogar in\nSackgassen f\u00fchrt. In Planet PI4 ist man hingegen in gro\u00df\ufb02\u00e4chigen Au\u00dfenarealen unterwegs, wo\nvereinzelt Asteroiden den Weg versperren und somit reaktives Ausweichen als ausreichend er-\nscheinen mag.\n5.3 Operative Ebene 51Vor allem die beiden Letzt genannten Gr\u00fcnde lassen davon ausgehen das der Einsatz von Path\ufb01nding\ninPlanet PI4 in keinem ausreichenden Verh\u00e4ltnis von Aufwand und Ertrag steht, der den Einsatz recht-\nfertigen w\u00fcrde.\nConstraints \u00fcberpr\u00fcfen ob die Ziele der Targeter bzw. die Unterziele der Decomposer realisiert werden\nk\u00f6nnen. Jedes Constraint untersucht dabei einen bestimmten Aspekt, welcher vom gew\u00fcnschten Ver-\nhalten zur Zielrealisierung nicht verletzt werden darf. Wird von einem Constraint solch eine Verletzung\nerkannt, berechnet sie selbst eine m\u00f6gliche L\u00f6sung. Der L\u00f6sungsbildungsprozess beachtet bei der Ver-\nhinderung der Constraint -Verletzung die \u00fcbergeordnete Zielvorgabe, versucht demnach die bestm\u00f6gliche\nZielrealisierung ohne dabei den vom Constraint repr\u00e4sentierten Aspekt zu verletzen. Abbildung 19 zeigt\ndasConstraints wieDecomposers in einer festen Reihenfolge abgearbeitet werden. Somit wird sicherge-\nstellt, dass die vorgeschlagenen L\u00f6sungen der Constraints dahingehend \u00fcberpr\u00fcft werden k\u00f6nnen, ob\ndiese nicht wiederum andere Constraints verletzen. Der Unterschied zu Decomposers besteht allerdings\ndarin, dass Constraints in einer Schleife angeordnet sein k\u00f6nnen, da solange die L\u00f6sung \u00fcberpr\u00fcft wer-\nden muss bis wirklich alle Constraints mit dieser einverstanden sind. Hierbei besteht nat\u00fcrlich die Gefahr\neiner Endlosschleife, sodass nach einer gewissen Zeit der Schleifendurchlauf abgebrochen werden muss\nund eine L\u00f6sung der Constraints oder ein Default-Verhalten ausgew\u00e4hlt wird. Die operative Ebene der\nGame AI implementiert die in Abbildung 21 dargestellten zwei Constraints :\nAbbildung 21: Vererbungshierarchie der Constraint -Menge der Steering Pipeline .\n\u2022Obstacle Avoidance: Untersucht ob sich in naher Zukunft eine Kollision mit Asteroiden ereignen\nk\u00f6nnte. Neben Asteroiden existieren mit Upgrade Points und Schildgeneratoren noch zwei weitere\nstatische Objektarten. Diese k\u00f6nnen allerdings ignoriert werden, weil sie jeweils ein masseloses\nGebiet bezeichnen, mit dem das Raumschiff nicht kollidieren kann.\nIn der aktuellen Implementierung wird zum Ausweichen vor Asteroiden im ersten Schritt die Men-\nge der nahen Asteroiden auf die Menge der Asteroiden in Bewegungsrichtung reduziert. Anschlie-\n\u00dfend wird ermittelt ob bei Beibehaltung der gew\u00fcnschten Richtung in den n\u00e4chsten paar Spiel-\nzyklen einem dieser Asteroiden zu nahe gekommen wird bzw. eine Kollision geschehen w\u00fcrde.\nDem ersten Asteroiden auf denn diese Annahme zutritt wird dann versucht auszuweichen. Dies\ngeschieht in dem nach einem festen Muster sechs m\u00f6gliche Ausweichrouten um den Asteroiden\nherum bestimmt werden. Die Ausweichrouten werden dann mit dem urspr\u00fcnglich gew\u00fcnschten\nPositionsziel verglichen. Dazu wird die Entfernung vom Ende der Ausweichroute zum Positionsziel\nermittelt und die Ausweichrouten in aufsteigender Entfernungsweite sortiert. Abschlie\u00dfend wird\nnacheinander gepr\u00fcft, ob die Ausweichroute auf ihrem Weg eine unmittelbare, d.h. nicht in meh-\nreren Spielzyklen m\u00f6gliche, Kollision mit einen anderen Asteroiden der zuvor reduzierten Menge\nverursachen w\u00fcrde. Wenn nicht, wird diese Ausweichroute als neues Bewegungsziel de\ufb01niert und\nals Ergebnis zur\u00fcckgegeben. Wird eine Kollision gefunden wird die n\u00e4chste Ausweichroute unter-\n52 5 Design und Implementierungsdetails der Game AIsucht. Scheitern alle wird eine Default-Bewegung (ein nach links oder rechts driften) eingeleitet,\num die Ausgangslage zu ver\u00e4ndern und somit vielleicht in naher Zukunft eine g\u00fcltige Ausweich-\nroute zu bestimmen.\n\u2022Collsion Avoidance: Ermittelt ob sich in naher Zukunft eine Kollision mit einem anderen Raum-\nschiff ereignen k\u00f6nnte. Dazu wird die Menge der nahen Schiffe untersucht. Dabei wird f\u00fcr alle\nSchiffe ermittelt ob und, wenn ja, wann diese in naher Zukunft mit dem eigenen Schiff kollidie-\nren k\u00f6nnten. Es wird anschlie\u00dfend dem Schiff versucht auszuweichen, welches an der n\u00e4chst-\nwahrscheinlichen Kollision beteiligt ist. Wichtig ist an dieser Stelle, dass nicht dem in Bezug auf\nEntfernung am n\u00e4chsten kommenden Schiff ausgewichen wird, sondern unter Ber\u00fccksichtigung\nder Eigenen Richtung und Geschwindigkeit, sowie der des anderen Raumschiffes, ermittelt wird\nwann die erste Kollision mit einem Raumschiff sich ereignen k\u00f6nnte und dem entsprechend Ge-\ngenma\u00dfnahmen eingeleitet werden. Zur Bestimmung der Ausweichbewegung wird auf die Berech-\nnungen des Evade Targeters zur\u00fcckgegriffen, welche eine Bewegung bestimmt die entgegengesetzt\nzu der des zu \ufb02iehenden Schiffes einleitet. Dadurch das die Collison Avoidance -Ausf\u00fchrung nur von\nkurzer Dauer ist, wird der eigentliche Kurs nur f\u00fcr kurze Zeit verlassen. Anschlie\u00dfend wird der\nurspr\u00fcngliche Kurs weiterverfolgt.\nDie beiden Constraints implementieren die IConstraint -Schnittstelle. Die suggestSteeringGoal() -\nMethode ist f\u00fcr die Untersuchung des aktuellen Ziels, repr\u00e4sentiert durch den Parameter desired-\nForce, auf Constraint -Verletzungen verantwortlich. Jedes Constraint und jeder suggestSteeringGoal() -\nMethodenaufruf ist weiter mit einer Priorit\u00e4t versehen. Damit wird der Steering Pipeline ein Mechanismus\nbereitgestellt um im Kon\ufb02iktfall der Constraints die Berechnung weniger priorisierter Constraints zu un-\nterbinden.\nDer Actuator ist f\u00fcr die endg\u00fcltige Ausf\u00fchrung der in der Steering Pipeline unternommenen\nBewegungs-Berechnungen zust\u00e4ndig. \u00c4hnlich der Locomotion -Ebene des Modells nach Reynolds aus Ab-\nschnitt 2.4 ist die Aufgabe des Actuators die Ergebnisse der SteeringForce -Datenstruktur zu interpretieren\nund in Befehle die das Spiel versteht umzuwandeln. Anders als bei den anderen Komponentenarten\ngibt es pro Charakter nur eine einzige Actuator -Instanz. Unterschiedliche Actuator -Instanzen k\u00f6nnen\nallerdings die Andersartigkeit verschiedener Bot-Typen charakterisieren, da es in Planet PI4 allerdings\nnur den Raumschiff-Agententypen gibt, ist dies hier nicht erforderlich. Es w\u00e4re aber denkbar das ein\nMutterschiff- Actuator \u00fcber erweiterte Steuerungsm\u00f6glichkeiten verf\u00fcgen k\u00f6nnte und deswegen eine an-\ndere Umsetzung der Steering Behavior in Spielbefehle erfordern w\u00fcrde. Abbildung 22 zeigt die IActua-\ntor-Schnittstelle und ihre einzige Implementierung ShipActuator zur Umsetzung der Steering Behaviors in\nSteuerbefehle eines Raumschiffes. Der einzigen Methode der IActuator -Schnittstelle werden dabei beide\nErgebnisse \u00fcbergeben, d.h. das gew\u00fcnschte Ziel der Targeter/Decomposer -Ebene, sowie die eventuell vor-\nhandenen Korrekturma\u00dfnahmen der Constraint -Ebene. Es ist die Aufgabe des Actuators zu entscheiden\nwelche davon auszuf\u00fchren ist und in welchem Ausma\u00df.\nAbbildung 22: Vererbungshierarchie der ShipActuator -Klasse der Steering Pipeline .\n5.3 Operative Ebene 535.3.2 Combat System\nDas in Abschnitt 2.4 vorgestellte Modell von Reynolds ordnete zwischen die Aktionsauswahlebene und\nder Ausf\u00fchrungsebene die Steering -Ebene. Die Steering -Ebene umfasst dabei ausschlie\u00dflich Bewegungs-\naspekte. Die eben beschriebene Steering Pipeline kann dabei als eine m\u00f6gliche Komponente der Steering -\nEbene nach Reynolds betrachtet werden. In Planet PI4 existieren jedoch nicht ausschlie\u00dflich primitive\nAktionen zur Bewegungssteuerung. Mit der \ufb01re()-Methode wird ebenfalls vom Spiel eine M\u00f6glichkeit zur\nSteuerung des Kampfverhaltens angeboten. Mit dem Einsatz des Combat Systems wird der Grundgedanke\ndesSteering -Modells nach Reynolds, n\u00e4mlich die Aufteilung des Aktionsbestimmungsprozesses auf drei\nhierarchisch angeordnete Ebenen, auf andere als zur Bewegungssteuerung beschr\u00e4nkte primitive Aktio-\nnen erweitert. Dies ist mit einer der Gr\u00fcnde, weshalb die operative Ebene nicht einfach Steering -Ebene\ngenannt werden kann. Denn daf\u00fcr umfasst sie neben der Berechnung von Steering -Verhalten ( Targeters\nundConstraints derSteering Pipeline ) und deren ( Locomotion -)Ausf\u00fchrung ( Actuator derSteering Pipeli-\nne) noch den Aspekt der Kampfsteuerung (Combat System).\nAbbildung 23: DieCombatSystem -Klasse und die ICombatShip -Schnittstelle, welche die vom Combat System ben\u00f6-\ntigten Informationen und Steuerungsbefehle zur Aktionsrealisierung de\ufb01niert. Die Parameter der\nICombatShip -Schnittstelle wurden zur besseren \u00dcbersicht weggelassen.\nAbbildung 23 zeigt das aktuelle Version des Combat Systems derGame AI folgende zwei Kampfaktio-\nnen anbietet, die basierend auf der \ufb01re() -Methode des Spiels und der Verwendung ausgew\u00e4hlter Steering\nBehaviors derSteering Pipeline ein jeweils abstrakteres Kampverhalten spezi\ufb01zieren als die blo\u00dfe Ausf\u00fch-\nrung der \ufb01re() -Methode es zu lassen w\u00fcrde:\n\u2022Capture Upgrade Point: EinUpgrade Point soll angesteuert und erobert werden. Gegner im unmit-\ntelbaren Sichtradius werden entlang des Fluges zum Upgrade Point beschossen aber nicht weiter\nverfolgt. Stattdessen wird der Upgrade Point angesteuert. Am Upgrade Point angekommen werden\nsolange gegnerische Schiffe innerhalb oder in der N\u00e4he des Upgrade Points angegriffen bis dieser\n54 5 Design und Implementierungsdetails der Game AIerobert wurde. Wie gro\u00df der Kampfradius dabei die Gr\u00f6\u00dfe des Upgrade Points \u00fcberschreitet ist\nabh\u00e4ngig vom enemyDetectionRange -Parameter der Methode. Der Parameter gibt an um welchen\nFaktor die Gr\u00f6\u00dfe des Upgrade Points erweitert werden soll. \u00dcbergibt man z.B. enemyDetectionRange\n= 1.0 wird nur innerhalb des Upgrade Points auf Gegner reagiert. Gibt man einen Wert gr\u00f6\u00dfer\n1.0 an, wird auch au\u00dferhalb gek\u00e4mpft. Gibt man einen Wert nahe oder gleich 0.0 an, wird we-\nder au\u00dferhalb noch innerhalb gek\u00e4mpft. Sollten keine Gegner vorhanden sein wird solange am\nMittelpunkt des Upgrade Points ausgeharrt bis dieser erobert oder erfolgreich verteidigt wurde.\nWichtig ist, dass an dieser Stelle nicht \u00fcberpr\u00fcft wird, welchem Team der Upgrade Point angeh\u00f6rt\noder wann dieser erobert wurde. Die Aktionsauswahlebene muss demnach bestimmen, welcher\nUpgrade Point zu welchem Zweck (Eroberung/Verteidigung) angesteuert wird und die Aktionsaus-\nf\u00fchrung in dem Moment unterlassen, wenn dieser Zweck entweder erf\u00fcllt oder gescheitert ist. Ein\nGrund f\u00fcr das Scheitern k\u00f6nnte beispielsweise der eigene Tod und ein weit weg gelegener respaw-\nned Punkt sein.\n\u2022Fight Enemy: Ein gegnerisches Schiff soll bek\u00e4mpft werden. \u00c4hnlich dem Capture Upgrade Point -\nVerhalten wird erstmals der Gegner angesteuert, falls dieser sich au\u00dfer Reichweite be\ufb01ndet. Anders\nals beim Upgrade Point handelt es sich hierbei nicht um einen statischen Punkt auf der Karte, wel-\nchen man mittels arrive -Ausf\u00fchrung ansteuern kann, sondern um ein bewegliches Ziel, dass mittels\npursue -Anwendung abgefangen werden soll (siehe dazu Abbildung 23).\nBe\ufb01ndet sich der Gegner in Reichweite des Waffensystems wird dieser in Abh\u00e4ngigkeit der Parame-\nterwerte FireRate undFireAccuracy beschossen. FireRate gibt dabei die Feuerrate an, die de\ufb01niert\nin welchem Spielzyklus-Intervall geschossen werden soll. Ein Wert von 1.0 gibt an das man in\njedem Spielzyklus feuern soll, wohingegen ein Wert von 0.5 bedeutet, dass man nur durchschnitt-\nlich in jedem zweiten Spielzyklus feuert. FireAccuracy de\ufb01niert ab welchem Schusswinkel gefeuert\nwerden soll. Bei einem Wert von 1.0 wird der Gegner beschossen wenn dieser sich gerade am\nRand des Sichtfeldes be\ufb01ndet, wohingegen ein Wert nahe 0 bedeutet, dass man nur schie\u00dft wenn\ndieser sich in der Mitte des Sichtfeldes be\ufb01ndet und sozusagen nicht verfehlt werden kann. Die\nHilfsmethode checkCoveredTarget() \u00fcberpr\u00fcft ob das Ziel von einem Asteroiden verdeckt wird und\ndementsprechend gefeuert werden soll oder nicht. Der Parameter circleAroundOn de\ufb01niert ob am\nStandard-Verhalten, dem Stoppen des Schiffes und Feuern aus dem Stand, falls die Entfernung\nzum Ziel zu gering wird, festgehalten wird oder ob stattdessen ein Verhalten aktiviert werden soll,\nwelches den Gegner mit voller Geschwindigkeit trotz n\u00e4chster N\u00e4he ansteuert und auf die Collisi-\non Avoidance derSteering Pipeline zur Kollisionsverhinderung vertrauend einen Kreis \ufb02iegt, um im\nAnschluss sich wieder auf den Feind zu st\u00fcrzen.\n\u2022Restore Energy: Spezi\ufb01ziert genau das gleiche Verhalten wie Capture Upgrade Point nur das nicht\neinUpgrade Point , sondern ein Schildgenerator ange\ufb02ogen wird.\n5.4 Taktische Ebene\nDie taktische Ebene ist die mittlere der drei Hierarchieebenen der Game AI -Architektur aus Abschnitt 5.2.\nIhre zentrale Aufgabe ist der Aktionsauswahlprozess bzw. das Decision Making . Wie der Einleitungstext\nzum Related Works Kapitel und insbesondere die Au\ufb02istung in Tabelle 1 andeuteten existieren zahlrei-\ncheDecision Making -Techniken. Im Rahmen der Master-Thesis wurde sich f\u00fcr den Einsatz von Behavior\nTrees (BTs) entschieden. Das allgemeine Konzept, sowie Vor- und Nachteile von BTs wurden bereits in\nAbschnitt 4.4 behandelt.\nAbbildung 24 zeigt den allgemeinen Aufbau der taktischen Ebene und die Abh\u00e4ngigkeiten zu anderen\nTeilen des Systems. Die Struktur der Ebene, wie auch das Aussehen der ITactController -Schnittstelle sind\n5.4 Taktische Ebene 55voll und ganz auf den Einsatz von BTs als Decision Making -System ausgerichtet. So bietet die ITactCon-\ntroller -Schnittstelle mit der performNextAction() -Methode die M\u00f6glichkeit den Decision Making -Prozess\nanzusto\u00dfen. Ob dieser erfolgreich verlaufen ist oder nicht gibt das BT spezi\ufb01sche Ergebnis-Enum BE-\nHAVIOR_STATUS an, auf welches etwas sp\u00e4ter noch genauer eingegangen wird. Die beiden Methoden\nresetBTStatus() undgetBlackboard() geben der strategischen Ebene die M\u00f6glichkeit den BT-Status zu-\nr\u00fcckzusetzen und \u00fcber den direkten Zugriff aufs Blackboard gezielt Informationen oder Vorgaben an\ndieDecision Making -Komponente weiter zugeben. Mit der setBehaviorTag() -Methode wird eine M\u00f6glich-\nkeit zum selektiven Ausschluss bestimmter Teilb\u00e4ume des BTs vom Aktionsauswahlprozess nach au\u00dfen\nhin angeboten. Dies erm\u00f6glicht eine Erweiterung des allgemeinen BT-Konzeptes auf das ebenfalls sp\u00e4-\nter noch n\u00e4her eingegangen wird. Der so vorgenommene Entwurf der ITactControler -Schnittstelle ist\nzwar einerseits nicht ganz so elegant gel\u00f6st wie auf der operativen Ebene, wo sich hinter der IOptCon-\ntroller -Schnittstelle unterschiedliche Realisierungsm\u00f6glichkeiten verbergen k\u00f6nnten, andererseits ist die\nDe\ufb01nition einer allgemeinen Decision Making -Schnittstelle um einiges schwieriger. Die einzelnen Deci-\nsion Making -Techniken unterscheiden sich teilweise sehr stark voneinander und die enge Verzahnung\nzwischen der strategischen und taktischen Ebene erfordert einen gewissen White-Box -Zugriff. Nichtsde-\nstotrotz w\u00e4re die weitere Entkopplung und die Verallgemeinerung der ITactController -Schnittstelle ein\nm\u00f6glicher Ansatzpunkt f\u00fcr zuk\u00fcnftige Refactoring-Ma\u00dfnahmen.\nAbbildung 24: Die Struktur der taktischen Ebene und die Abh\u00e4ngigkeiten zu anderen Systemebenen.\nDie eigentliche BT-Implementierung besteht aus einem Ge\ufb02echt aus mehreren Klassen und wird in Ab-\nbildung 24 stellvertretend durch die BehaviorTree -Klasse repr\u00e4sentiert. Die tats\u00e4chliche Realisierung wird\nin Abschnitt 5.4.2 ausf\u00fchrlich vorgestellt. F\u00fcr die folgenden Ausf\u00fchrungen zur allgemeinen Struktur ist\njedoch die Vorstellung der BT-Implementierung als ein eigenst\u00e4ndiges Subsystem v\u00f6llig ausreichend.\nF\u00fcr den Bau der konkreten BT-Instanz ist die BTBuilder -Klasse zust\u00e4ndig. Dies bedeutet sie de\ufb01niert\nund instanziiert den BT-Baum, der letzten Endes von der Game AI zur Aktionsbestimmung verwendet\nwird. Dieser wird in Abschnitt 5.4.4 vorgestellt. Die BTBuilder -Klasse wird von der TactController -Klasse\nmit den ben\u00f6tigten Informationen und Schnittstellen die zum Bau des BTs notwendig sind versorgt.\n56 5 Design und Implementierungsdetails der Game AIDieBehaviorTreeManager -Klasse ist f\u00fcr die Verwaltung und den Funktionszugriff einer BT-Instanz zu-\nst\u00e4ndig. Sie sorgt ebenfalls daf\u00fcr, dass die BT-Instanz Zugriff zu aktuellen Informationen des Spiels\nerh\u00e4lt und \u00fcber ein Blackboard -Informationen innerhalb des Baums austauschen kann. Erl\u00e4uterungen\nzum Blackboard sind im nachfolgenden Abschnitt 5.4.1 zu \ufb01nden. Realisiert wird der Informations-\nund Blackboard -Zugriff dadurch, dass eine Instanz der WorldStateBlackboard -Klasse erstellt und diese\nan die BT-Instanz weitergebenen wird. Die WorldStateBlackbord -Klasse verbindet den Zugriff auf die\nIWorldState -Schnittstelle aus dem AI.GameAI -Package mit dem Zugriff auf eine vom konkreten Verwen-\ndungszweck unabh\u00e4ngige Blackboard -Realisierung.\nWie bereits bei der Beschreibung zur IWorldState -Schnittstelle erw\u00e4hnt, enth\u00e4lt die Schnittstelle nicht\nalle vom Spiel bereitgestellte Informationen. Die GameStatusListener -Klasse ist f\u00fcr die Integration der\nfehlenden Informationen in das Blackboard zust\u00e4ndig. Dazu meldet sie sich nach dem Listener -Prinzip\nbei der IShipControll - und IGameStateView -Schnittstelle f\u00fcr entsprechende eventbasierte Informationen\nan und wird bei Eintreffen eines Events dar\u00fcber informiert. Ein Beispiel f\u00fcr ein solches Event ist die\nZerst\u00f6rung des eigenen Schiffes oder die Menge an regenerierten Shield -Punkten bei der Benutzung von\nSchildgeneratoren.\nEin Sonderfall stellt dabei die Kommunikation mit anderen Raumschiffen, insbesondere mit Team-\nkameraden da. Hier wird ebenfalls ein Listener -Konzept zum Empfang von Informationen angeboten.\nDar\u00fcber hinaus gibt es allerdings auch die M\u00f6glichkeit selber Nachrichten an andere Spieler zu versen-\nden. Der Kommunikationsaspekt mit anderen Schiffen wurde im aktuellen Stand der Game AI noch nicht\numgesetzt. Eine m\u00f6gliche Verwendung wurde allerdings an dieser Stelle vorgesehen. In Kapitel 7 wird\nauch kurz auf eine m\u00f6gliche Realisierung und Integration in das Konzept von BTs eingegangen.\n5.4.1 Blackboard Architektur\nEin wichtiger Aspekt bei der Realisierung des BT-Ansatzes ist die Beantwortung der Frage, wie der Infor-\nmationsaustausch zwischen den einzelnen Knoten im Baum realisiert werden soll. Dazu gibt es mehrere\nM\u00f6glichkeiten. Eine M\u00f6glichkeit w\u00e4re die einzelnen Knoten des Baums zu parametrisieren und die be-\nn\u00f6tigten Daten entlang des Baumes weiterzureichen. Dies ist allerdings nicht ohne weiteres m\u00f6glich,\nwenn man eine der St\u00e4rken des BT-Ansatzes - die Wiederverwendbarkeit der Teilb\u00e4ume - nicht einb\u00fc-\n\u00dfen will. Denn f\u00fcr die Weiterreichung der Daten entlang des Baumes muss explizites Wissen dar\u00fcber\nvorliegen, welche konkreten Informationen von den darunterliegenden Ebenen tats\u00e4chlich ben\u00f6tigt wer-\nden, was wiederum die genaue Kenntnis der eingesetzten Teilb\u00e4ume voraussetzt. Ein Austauschen der\nunteren Ebene f\u00fchrt somit unweigerlich zu einer Code-\u00c4nderung der oberen Ebene. In [50] wird eine\nM\u00f6glichkeit der BT-Parametrisierung vorgestellt, die mittels Annotationen und einer Lookup -Mechanik\nversucht diesem Problem entgegen zu wirken. Dazu werden beliebig gro\u00dfe Teilb\u00e4ume in unterschiedli-\nche, evtl. verschachtelte, Scope -Schichten unterteilt. Innerhalb einer Scope -Schicht werden die Parameter\nder einzelnen BT-Knoten automatisch mit den aktuell bekannten Parameterwerten bef\u00fcllt. Existiert in der\naktuellen Scope -Schicht kein passender Wert wird in der n\u00e4chst h\u00f6heren Scope -Schicht gesucht. Dieses\nKonzept stellt eine Erweiterung des Blackboard -Ansatzes f\u00fcr BTs dar, der den Datenaustausch im Baum\n\u00fcber eine externe Schicht erm\u00f6glicht. Im Konzept eines Parametrisierbaren BTs k\u00f6nnten Blackboards da-\nzu eingesetzt werden um den Daten- Lookup der aktuellen Parameterwerte innerhalb einer Scope -Schicht\nzu realisieren.\nDasBlackboard kann sich als die Informationszentrale oder als den Datenspeicher der BT-Realisierung\nvorgestellt werden. Blackboard -Architekturen werden eigentlich prim\u00e4r zur Koordination des Verhaltens\nmehrerer autonomer Agenten eingesetzt [21]. Dies wird realisiert in dem alle Agenten Nachrichten\n\u00fcber eine gemeinsame Informationseinheit - das Blackboard - austauschen. Das Blackboard ist neben der\nSammlung und Bereitstellung von Informationen auch f\u00fcr deren Synchronisierung zust\u00e4ndig. Ein Black-\n5.4 Taktische Ebene 57board kann sich auch als eine Tafel aus dem Klassenzimmer vorgestellt werden, wo die ganze Klasse\nzusammen an einer gemeinsamen L\u00f6sung arbeitet. Diese Tafel ist f\u00fcr jeden zugreifbar und jeder Sch\u00fc-\nler kann durch L\u00f6sen von Teilproblemen einen gewissen eigenen Anteil zum L\u00f6sungsprozess beisteuern,\nder mit der restlichen Klasse geteilt wird. Dieser Verwendungsgedanke des gemeinsamen L\u00f6sungspro-\nzesses l\u00e4sst sich ebenfalls auf BTs \u00fcbertragen. Stellt man sich die Wurzel eines BT-Baumes als die zu\nl\u00f6sende Aufgabe an einer Tafel vor, so zerlegen die einzelnen Teilb\u00e4ume das Problem in viele kleine-\nre einfacher zu l\u00f6sende Teilprobleme. Die dabei erzielten Ergebnisse werden im Anschluss daran auf\nderBlackboard -Tafel ver\u00f6ffentlicht, damit an anderer Stelle im Baum anhand der aktuellen Ergebnisse\nweitere Berechnungen angestellt werden k\u00f6nnen die zur L\u00f6sung des \u00fcbergeordneten Problems beitragen.\nTats\u00e4chlich ist der Blackboard -Ansatz die am weitesten verbreitete Art der Integration eines Datenaus-\ntauschmechanismus innerhalb von BTs [35, S. 361-365]. Zwar stellt das Konzept der Parametrisierten\nBTs mit unterschiedlichen Scope -Schichten eine Erweiterung des einfachen Blackboard -Ansatzes dar, doch\nwurde sich bei der BT-Realisierung der Game AI f\u00fcr den Einsatz des urspr\u00fcnglichen Blackboard -Einsatzes\nentschieden, erg\u00e4nzt um ein paar simple Parametrisierungs-Features. Der Grund hierf\u00fcr ist die Simplizi-\nt\u00e4t des allgemeinen Blackboard -Ansatzes und des damit verbundenen geringeren Performance-Verlustes\nder u.a. durch die Verwaltung unterschiedlicher Scope -Bereiche anfallen k\u00f6nnte.\nIn der Blackboard -Realisierung der taktischen Ebene werden die Daten anhand des folgenden Musters\nimBlackboard hinterlegt:\nBlackboardEntry<ValueType>: key:String || value:ValueType || timeStamp:unsigned int\nDer key-Parameter dient dabei der eindeutigen Identi\ufb01zierung des Blackboard -Eintrags und muss ent-\nsprechend vom Typ unique sein. Der timeStamp -Wert dient zur Ermittlung der Aktualit\u00e4t des entspre-\nchenden Eintrags. Mithilfe der any-Datenstruktur aus dem boost -Package existieren keine Beschr\u00e4nkun-\ngen was den ValueType desBlackboard -Eintrags anbelangt. Auch die Verwendung von Typspezi\ufb01zierer\nwie Pointer, Referenz oder const sind gestattet. Die Unterst\u00fctzung von const impliziert allerdings das\nBlackboard -Eintr\u00e4ge nicht ihren unter value gespeicherten Wert \u00e4ndern k\u00f6nnen. Um dennoch eine Un-\nterst\u00fctzung von sich \u00e4ndernden Blackboard -Eintr\u00e4gen zu gestatten, wird der gesamte Eintrag vom Black-\nboard selbstst\u00e4ndig gel\u00f6scht und durch einen neuen Eintrag mit dem ver\u00e4nderten value-Wert ersetzt. Die\nBlackboard -Klasse bietet im Gro\u00dfen und Ganzen eine kleine Menge an unterschiedlichen \u00f6ffentlichen\nsetData() - und getData() -Methoden, die den Zugriff auf das Blackboard steuern.\nDiese simple Realisierung eines Blackboards weist auf der anderen Seite zwei Nachteile auf. Der gr\u00f6\u00dfte\nNachteil ist das allgemeine Problem des Blackboard -Ansatzes, dass durch die Trennung der Datenebene\nvon der Strukturebene des BTs nicht ohne weiteres ersichtlich ist, wie und wo die Daten innerhalb des\nBaums verwendet werden. Mit anderen Worten der Informations\ufb02uss im BT ist nur schwer zu erkennen.\nDer zweite Nachteil ist der simplen Realisierung und der Verwendung eines einzigen Blackboards im\nganzen Baum geschuldet. Denn ohne Kontrollmechanismen oder der Einf\u00fchrung von Scope -Schichten\nk\u00f6nnen Eintr\u00e4ge ohne Kenntnisnahme betroffener Knoten beliebig \u00fcberschrieben werden. So k\u00f6nnte\nbeispielsweise ein nextEnemy -Eintrag von zwei unterschiedlichen Stellen im Baum gesetzt werden und\nvon einem Ausf\u00fchrungsknoten gelesen werden. Dies k\u00f6nnte durchaus ein gewolltes Verhalten im Baum\nsein, doch ebenso gut k\u00f6nnte dies auch ein ungewollter Fall sein, der zu nicht beabsichtigten und schwer\nnachvollziehbaren Verhaltensst\u00f6rungen f\u00fchren k\u00f6nnte.\n5.4.2 Behavior Tree Implementierung\nAbbildung 25 zeigt wie die in Abschnitt 4.4 vorgestellten Komponenten eines BTs im System umgesetzt\nwerden. Die gemeinsame Oberklasse aller Komponenten ist die abstrakte TaskNode -Klasse. Sie gibt die\nImplementierung einer execute() - und einer reset() -Methode vor. Die execute() -Methode dient dazu die\n58 5 Design und Implementierungsdetails der Game AIKnotenausf\u00fchrung von der aktuellen Knotenart zu abstrahieren und damit einen einheitlichen Zugriff\nnach au\u00dfen anzubieten. Mit dem WorldStateBlackboard -Parameter wird den einzelnen Knoten der Zu-\ngriff auf den aktuellen Spielkontext gew\u00e4hrt, sowie mit dem Zugriff auf ein Blackboard der gemeinsame\nDatenaustausch im Baum erm\u00f6glicht. Die \u00dcbergabe zur Ausf\u00fchrungszeit, statt zur Initialisierungszeit\nerm\u00f6glicht den Austausch der tats\u00e4chlich verwendeten Blackboard -Instanz zur Laufzeit. Aktuell wird\nnur eine einzige Blackboard -Instanz f\u00fcr denselben Baum benutzt. Eine sp\u00e4tere Erweiterung zur Ver-\nwendung mehrerer oder unterschiedlicher Blackboard -Instanzen um z.B. ein Scoping wie in Abschnitt\n5.4.1 vorgestellt zu realisieren, w\u00e4re damit zumindest erheblich erleichtert. Nach der Ausf\u00fchrung der\nexecute() -Methode wird mit der R\u00fcckgabe eines Elements des BEHAVIOR_STATUS -Enums die Knotenaus-\nf\u00fchrung bewertet. Die jeweiligen Enum-Elemente haben dabei folgende Bedeutung f\u00fcr die Traversierung\ndes Baums:\n\u2022BS_SUCCESS: Die Ausf\u00fchrung war erfolgreich. Fahre je nach aktueller Ausf\u00fchrungssemantik im\nBaum weiter fort.\n\u2022BS_FAILURE: Die Ausf\u00fchrung ist fehlgeschlagen. Fahre je nach aktueller Ausf\u00fchrungssemantik im\nBaum weiter fort.\n\u2022BS_ERROR: W\u00e4hrend der Ausf\u00fchrung ist ein schwerwiegender Fehler aufgetreten. Die BT-\nAusf\u00fchrung wird teilweise oder komplett eingestellt.\n\u2022BS_RUNNING: Der Knoten konnte seine Ausf\u00fchrung innerhalb des aktuellen Ausf\u00fchrungszyklus\nnicht beenden. Die BT-Traversierung wird angehalten und gegebenenfalls im n\u00e4chsten Zyklus an\nderselben Stelle fortgesetzt. Dies kann passieren, wenn die Ausf\u00fchrung mehr als einer IOptControl-\nler-Aktion versucht wird. Dabei handelt es sich um eine inh\u00e4rente Condition des Baums und muss\nnicht im Baum via Condition -Knoten extra modelliert werden.\n\u2022BS_IGNORE: Bedeutet das die Ausf\u00fchrung des aktuellen Knoten unterbunden oder ausgelassen\nwird. Wird verwendet in Kombinationen mit Behavior Tags , die eine Erweiterung des BT-Konzeptes\ndarstellen und in Abschnitt 5.4.3 n\u00e4her erl\u00e4utert werden.\nCompositeTaskNode\nWichtig ist im Kontext der Traversierung von BTs zu verstehen, dass die Statusmeldung BS_FAILURE\nkeine Fehlermeldung darstellt. Eine BS_FAILURE -Statusmeldung bezeichnet fehlgeschlagene Ausf\u00fchrun-\ngen, wie z.B. die Nicht-Erf\u00fcllung einer Condition im Baum, die je nach aktiver Traversierungssemantik\nunterschiedliche Auswirkungen nach sich ziehen kann. Die Traversierungssemantik wird dabei von den\nCompositeTaskNode -Knoten oder kurz Composite -Knoten bestimmt. Composite -Knoten k\u00f6nnen andere Tas-\nkNode -Knoten \u00fcber die addChild() -Methode als Kinder aufnehmen, was die hierarchische Anordnung der\nKnoten im Baum erm\u00f6glicht. Weil ein Composite -Knoten andere Knoten als Kinder aufnimmt, bestimmt\ndiese auch die Ausf\u00fchrungsreihenfolge der Kinder und wie die entsprechenden Statusmeldungen dieser\ninterpretiert werden sollen.\nEine allgemeine Handhabung \u00fcber alle Composite -Knoten hinweg, erfolgt beim Umgang mit der\nBS_RUNNING -Statusmeldung. Dazu wird mit dem currentPos -Attribut der Index des aktuell aktiven\nKindes abgespeichert, damit im Falle einer Fortf\u00fchrung im N\u00e4chsten Zyklus der Kindknoten direkt aus-\ngef\u00fchrt werden kann.\nDie Art der Traversierung ist der Punkt indem sich die unterschiedlichen Ableitungen der abstrakten\nCompositeTaskNode -Klasse voneinander unterscheiden. Neben der Realisierung der bereits in Abschnitt\n4.4 vorgestellten Traversierungsarten eines Selectors und einer Sequenz wurde zus\u00e4tzlich noch ein Perso-\nnality Selector entwickelt. Ein Personality Selector sortiert die Kinder nach einer Personality -Evaluierung\n5.4 Taktische Ebene 59Abbildung 25: Klassendiagramm der wichtigsten \u00fcbergeordneten Komponenten der BT-Implementierung.\nund f\u00fchrt diese entsprechend dieser Reihenfolge aus. Der Personality Selector ist nur ein Teil einer Erwei-\nterung des allgemeinen BT-Konzeptes und wird in Abschnitt 5.4.3 ausf\u00fchrlicher erl\u00e4utert.\nActionTaskNode\nDie Ausf\u00fchrung von Aktionsknoten f\u00fchrt entweder zu \u00c4nderungen des Weltzustands bzw. des Agenten-\nzustands oder andererseits zu \u00c4nderungen des internen Zustands des BTs. Alle Aktionen erben von der\nabstrakten Klasse ActionTaskNode . Die abstrakte Klasse gibt die Verwendung eines resultBBKeys -Strings\nvor, welche mit der Ausf\u00fchrung der storeResult() -Methode innerhalb der execute() -Methodenausf\u00fchrung\ndie Speicherung des Aktionsergebnisses als Eintrag im Blackboard realisiert. Das Ergebnis einer Aktion\nh\u00e4ngt von der Aktionsart ab, die wiederum durch die Art der Zustands\u00e4nderung bestimmt wird.\nDie Aktionen, die den Weltzustand bzw. den Zustand des Agenten \u00e4ndern, werden innerhalb ihrer\nAusf\u00fchrung durch die IOptController -Schnittstelle bereitgestellten Aktionen der operativen Ebene aus-\ngef\u00fchrt. In diesem Sinne de\ufb01niert die taktische Ebene folgende f\u00fcnf Aktionsgegenst\u00fccke zur operativen\nEbene: CaptureUPAction ,FightEnemyAction ,EvadeAction ,WanderAction undRestoreShieldAction . Die Ak-\ntionen verf\u00fcgen \u00fcber eine Reihe von Setter -Methoden, die die einzelnen Parameter der operativen Akti-\nonsgegenst\u00fccke entgegen nehmen. Dabei k\u00f6nnen Parameter-Werte entweder die Werte direkt enthalten\noder stattdessen ein Blackboard -Key spezi\ufb01zieren. Alle Parameter die als Blackboard -Key angegeben wor-\nden sind, werden vor der Ausf\u00fchrung des IOptController -Aktionsgegenst\u00fccks in der execute() -Methode\nneu vom Blackboard geladen. Da diese Form von Aktionen tats\u00e4chliches Agenten-Verhalten produziert\nund somit nicht im Blackboard als Aktionsresultat hinterlegt werden kann, speichert diese Art von Ak-\ntionen Blackboard -Eintr\u00e4ge die das Aktionsverhalten dokumentieren. Beispielsweise speichert die Figh-\ntEnemyAction dieIShip -Instanz des zuletzt angegriffenen Schiffes ab, welche wiederum an einer anderen\nStelle im BT abgefragt werden kann. Tats\u00e4chlich geschieht genau dies in der aktuellen BT-Instanz die in\n60 5 Design und Implementierungsdetails der Game AIAbschnitt 5.4.4 vorgestellt wird. Dort wird im jeweils n\u00e4chsten Aktionszyklus m\u00f6glicherweise gepr\u00fcft,\nob das letzte angegriffene Schiff noch in Reichweite ist und dementsprechend weiter angegriffen oder\nstattdessen ein neues Ziel ausgew\u00e4hlt werden soll.\nAktionen die den internen Zustand des BTs \u00e4ndern rufen keine Aktionen der IOptController -\nSchnittstelle auf. Momentan sind folgende drei Determine -Aktionen implementiert, die die Spielwelt\nauf bestimmte Objekte untersuchen und das Ergebnis im Blackboard abspeichern Sollte kein Ergebnis\ngefunden werden wird ein BS_FAILURE zur\u00fcckgegeben:\n\u2022DetermineNearestShipInRangeAction: Untersucht die nahe Nachbarschaft auf das n\u00e4chste feind-\nliche und/oder befreundete Schiff und speichert eine Referenz der IShip -Instanz im Blackboard ab.\nEin Enum-Parameter gibt dabei die gew\u00fcnschte Schiffsart an und ein Range -Parameter den Such-\nraum.\n\u2022DetermineNearestUPInRegionAction: Untersucht die Region auf das n\u00e4chste eroberte und/oder\nnicht eroberte UP-Vorkommen und speichert eine Referenz der Upgrade Point -Instanz im Blackboard\nab. Ein Enum-Parameter gibt dabei den gesuchten Eroberungsstatus an und ein anderer die Such-\nregion.\n\u2022DetermineNearestSGInRangeAction: Untersucht die nahe Nachbarschaft auf das n\u00e4chste SG-\nVorkommen und speichert eine Referenz der Schildgenerator-Instanz im Blackboard ab. Ein Range -\nParameter gibt dabei den gew\u00fcnschten Suchraum an.\nConditionTaskNode\nAktionsausf\u00fchrungen k\u00f6nnen Zustands\u00e4nderungen der Welt, des Agenten oder des BT herbeif\u00fchren.\nConstraints stellen hingegen Abfragen und Bedingungsformulierungen auf genau dieser Zustandsmenge\ndar. Jeder ConditionTaskNode -Knoten oder kurz Condition -Knoten erbt dabei von der abstrakten Klasse\nConstraintTaskNode , die wie die anderen abstrakten Klassen der BT-Implementierung die Realisierung\nderTaskNode.execute() -Methode an ihre Spezialisierungen weitergibt. Zus\u00e4tzlich de\ufb01niert sie allerdings\ndas jedes Contraint aus min. zwei Operanden besteht, deren Verwaltung in der abstrakten Klasse selber\nrealisiert ist. Wie bei der Parametrisierung von Aktionen k\u00f6nnen die Contraint -Operanden entweder\njeweils direkt den Wert eines beliebigen Typs T1 bzw. T2 annehmen oder einen Blackboard -Key enthalten,\nder bei jedem neuen Aufruf der Getter -Methode f\u00fcr ein neu Laden des im Blackboard hinterlegten Wertes\ngenutzt wird. Abbildung 26 zeigt welche ConstraintTaskNode -Ableitungen im System existieren:\n\u2022ArithmeticCondition: Hilfsklasse die zwei Zahlen vom gleichen arithmetischen Typ \u00fcbernimmt\nund verschiedene Vergleichsoperatoren (<,>,>=,<=,==,!=) auf diese anwendet.\n\u2022ShipStatusCondition: Pr\u00fcft entweder die aktuelle Schiffsenergie, den Health - oder den Shield -\nWert des Schiffs gegen einen arithmetischen Zahlenwert unter Anwendung eines arithmetischen\nVergleichoperators.\n5.4 Taktische Ebene 61Abbildung 26: Vererbungshierarchie und Typspezi\ufb01kation der Conditions der BT-Implementierung.\n\u2022ComplexCombatCondition: Pr\u00fcft den Complex Combat -Value, der die aktuelle Schiffsenergie, den\nHealth -Wert und ein Team/Enemy -Verh\u00e4ltnis umfasst, gegen einen arithmetischen Zahlenwert un-\nter Anwendung eines arithmetischen Vergleichsoperators. Durch die Angabe von Gewichten ist\ndie Priorisierung der drei Faktoren m\u00f6glich. Die genaue Berechnungsformel des Complex Combat -\nValues lautet dabei wie folgt:\n62 5 Design und Implementierungsdetails der Game AI\u2022BBEntryCondition: Pr\u00fcft auf Existenz oder Aktualit\u00e4t eines Blackboard -Eintrags. T1 spezi\ufb01ziert\ndabei den Typ des Eintrags und T2 ist vom unsigned int -Typ des timeStamp -Parameters. Die \u00dcber-\npr\u00fcfung ist notwendig da Determine -Aktionen nicht zwingend ein Ergebnis produzieren m\u00fcssen\noder das letzte Ergebnis entsprechend lange zur\u00fcck liegen kann. Beispielsweise kann die Determi-\nneNearestShipInRange -Aktion keine anderen Schiffe in der N\u00e4he \ufb01nden und legt dementsprechend\nkeinen neuen Ergebnis-Eintrag im Blackboard ab.\n\u2022EqualCondition: Pr\u00fcft beliebige Objekte vom nicht arithmetischen Typ T auf Gleichheit.\n\u2022ObjectInRangeCondition: Abstrakte Klasse die Objekte vom beliebigen Typ T1 entgegen nimmt,\nihre Entfernung zum eigenen Raumschiff bestimmt und gegen einen \ufb02oat-Zahlenwert pr\u00fcft. Dabei\nwird in der execute() -Methode der Condition dasTemplate Method-Pattern [16, S. 366-372] ange-\nwendet, welche die Berechnung und den Vergleich selber de\ufb01niert aber die dabei zu verwendete\nPositionsangabe des Objektes an seine Unterklassen weiterleitet. Die dabei zu implementierende\nMethode ist folgende:\nPosition3d getObjectPos(WorldStateBlackboard* pBlackboard);\nDie zwei Spezialisierungen PlayerInRangeCondition nimmt ein beliebiges Schiff entgegen und ISta-\nticObjectInRangeCondition einIStaticObjekt -Objekt, welches entweder ein Asteroid, Upgrade Point\noder ShieldGenerator -Objekt sein darf.\n\u2022ObjectInRegionCondition: Gleiches Prinzip wie bei der ObjectInRangeCondition nur, dass nicht\ngegen einen \ufb02oat-Zahlenwert gepr\u00fcft wird, sondern ob die Position des Objektes sich innerhalb\noder au\u00dferhalb der \u00fcbergebenen Region be\ufb01ndet.\nDecoratorTaskNode\nDecoratorTaskNode -Knoten bzw. kurz Decorator -Knoten sind nach dem Decorator -Patten [16, S. 199-211]\nentworfen, welches eine Alternative zur Unterklassenbildung darstellt, um die Funktionalit\u00e4t einer Klasse\nzu erweitern, ohne dabei Modi\ufb01kation am bestehenden Code vorzunehmen. Dazu wird die zu erweitern-\nde Klasse mit der neuen Klasse umwickelt, indem diese dasselbe Interface implementiert und die zu\nerweiternde Klasse als Klassenelement entgegen nimmt. Von au\u00dfen sind beide Klassen nicht voneinan-\nder zu unterscheiden. Ein beliebtes Beispiel ist das dekorieren von GUI-Fenstern. Eine GUI-Fenster Klasse\nwird beispielsweise mit einem Rahmen- Decorator versehen. Immer wenn das Fenster gezeichnet werden\nsoll, f\u00fcgt der vorgeschaltete Decorator einen Rahmen um das Fenster hinzu. Zur eigentlichen Darstellung\ndes Fensterinhaltes ruft der Rahmen- Decorator , nach dem Zeichnen des Rahmens, die entsprechende\ndraw() -Methode der Fenster-Klasse auf. Eine \u00e4hnliche Verwendung schlagen Champandard in [40] oder\nMillington und Funge in [35, S. 345-351] f\u00fcr BTs vor.\nEinDecorator -Knoten nimmt in diesem Sinne genau einen anderen TaskNode -Knoten auf, implemen-\ntiert selber die TaskNode -Schnittstelle des zu dekorierenden Objektes und f\u00fcgt dieser zus\u00e4tzliche Funktio-\nnalit\u00e4t hinzu. Ein beliebtes Beispiel f\u00fcr einen Decorator ist ein Limit Decorator der die Knoten-Aufrufe des\nzu dekorierenden Knotens z\u00e4hlt und ab einem bestimmen Limit die weitere Ausf\u00fchrung verhindert. Mit\ndem Behavior Tag Decorator und dem Personality Decorator existieren im Game AI -System genau zwei un-\nterschiedliche Decorators . Beide Decorators sind allerdings Bestandteil jeweils einer eigens entwickelten\nErweiterung des allgemeinen BT-Prinzips, auf das im nachfolgenden Abschnitt gesondert eingegangen\nwird.\n5.4.3 Behavior Tags und Personality Selection\nBehavior Tags sind ein nicht n\u00e4her spezi\ufb01zierter Prunning -Mechanismus in Halo 2 [20], der dazu ange-\nwandt wird bestimmte Bereiche des Baumes ein- und auszuschalten. Im einen Baum k\u00f6nnte beispielswei-\n5.4 Taktische Ebene 63se die Verhaltenslogik mehrerer Bot-Typen kodiert sein, wie z.B. Fahrer, Beifahrer oder Fu\u00dfg\u00e4nger. Ein\nFu\u00dfg\u00e4nger ben\u00f6tigt allerdings die im Baum enthaltene Logik zum Steuern eines Fahrzeuges nicht, sodass\ndiese entsprechend weggelassen werden kann. Was die Gr\u00f6\u00dfe des Baumes reduziert und gleichzeitig die\nTraversierungsgeschwindigkeit erh\u00f6ht. In Halo 2 sind Behavior Tags als Bit-Vektoren kodiert die eine par-\ntielle Zustandsbeschreibung des Agenten angeben, die einem Knoten zugewiesen und zur Laufzeit mit\ndem aktuellen Agentenzustand verglichen werden kann. Wird die partielle Zustandsbeschreibung vom\nBehavior Tag vom aktuellen Agentenzustand erf\u00fcllt bleibt der Teilbaum aktiv, ansonsten wird er deakti-\nviert bzw. geprunnt.\nDiese Art von Behavior Tags wird nicht 1:1 in der Game AI auf der taktischen Ebene umgesetzt, der\nGrundgedanke des Prunnings von bestimmten Teilb\u00e4umen bleibt allerdings erhalten. Dazu wird in erster\nLinie mithilfe des Behavior Tag Decorators einem beliebigen Knoten im BT ein String-Tag zugewiesen,\nwie dies beispielsweise in Abbildung 27 bei den Knoten FightInRegion ,FightNotInRegion ,DaredavelTactic ,\nTactismTactic undScardyCatTactic der Fall ist. Der Tag steht zwar in der Abbildung jeweils am Knoten,\njedoch ist dies nur eine vereinfachte visualisierte Darstellung daf\u00fcr, dass an dieser Stelle eigentlich zwei\nKnoten stehen m\u00fcssten. So besteht beispielsweise der FightInRegion -Knoten in Wirklichkeit aus dem\nvorgeschalteten Dekorierer-Knoten mit dem Tag \u201eTag.FIR\u201c. Erst darunter w\u00fcrde als Kindknoten der zu\ndekorierende FightInRegion -Knoten kommen.\nAbbildung 27: Beispielhafter Einsatz von Behavior Tags .\nDie Aufgabe des Decorator -Knoten zur Ausf\u00fchrungszeit ist es vor der Ausf\u00fchrung seines Kindes im\nBlackboard nachzuschauen, ob es einen Eintrag mit dem String-Tag als Key gibt. Existiert solch ein Key\nund entspricht der Value-Eintrag dem boolschen \u201efalse\u201c-Wert, so wird ein BS_IGNORE an den Elternk-\nnoten des Decorators zur\u00fcckgegeben und die aktuelle Ausf\u00fchrung des Unterbaums unterbunden. Wird\nkein Eintrag oder einer mit dem boolschen \u201etrue\u201c-Wert gefunden, so wird der aktuelle Tag-Pfad im Black-\nboard abgespeichert und der Unterbaum entsprechend ausgef\u00fchrt. Die Speicherung des aktuellen Pfades\nerm\u00f6glicht das Prunning bestimmter Teilb\u00e4ume in Abh\u00e4ngigkeit der durch den Baum und Behavior Tag\nDecorator aufgebauten Tag-Hierarchie. M\u00f6chte man in Abbildung 27 beispielsweise den linken Daredevil -\nKnoten entfernen, nicht jedoch den rechten im FightNotInRegion -Teilbaum, so kann dies mit folgendem\nBlackboard -Eintrag realisiert werden:\n64 5 Design und Implementierungsdetails der Game AIBlackboardEntry<bool> = {\"`Tag.FIR.Tag.DDT\"', false}\nM\u00f6chte man hingegen einen ganzen Unterbaum prunnen, z.B. den in Abbildung 27 rechten FightNotIn-\nRegion - Unterbaum, so reicht folgender Blackboard -Eintrag:\nBlackboardEntry<bool> = {\"`Tag.FNIR\"', false}\nEin Sonderfall existiert wenn ein Knoten \u00fcberall im Baum entfernt werden soll, unabh\u00e4ngig der aktuel-\nlen Hierarchie. Realisiert wird dies dadurch, dass ein jeder Decorator -Knoten neben dem aktuellen Pfad\n+ Knoten-Tag zuerst einmal nur nach einem Blackboard -Eintrag mit seinem Tag sucht. So w\u00fcrde bei-\nspielweise der folgende Blackboard -Eintrag alle beide DaredevilTactic -Knoten aus dem Baum entfernen:\nBlackboardEntry<bool> = {\"`Tag.DDT\"', false}\nDas Setzen von Behavior Tag -Eintr\u00e4gen ins Blackboard wird \u00fcber die ITactController -Schnittstelle bzw.\n\u00fcber deren setBehaviorTag() -Methode gesteuert und somit auch der Strategischen Ebene zur Verf\u00fcgung\ngestellt.\nDie Motivation f\u00fcr die Personality -Erweiterung ist der Umstand, dass Spieler unterschiedlich auf ein\nund dieselbe Spielsituation reagieren k\u00f6nnen. W\u00e4hrend beispielsweise Spieler A bei einer \u00dcbermacht\nfeindlicher Spieler direkt die Flucht ergreifen w\u00fcrde, k\u00f6nnte Spieler B eine Herausforderung in der\n\u00dcbermacht sehen und sich blindlings in den Kampf st\u00fcrzen. In BTs k\u00f6nnen solch unterschiedliche Ver-\nhaltensweisen f\u00fcr ein und dieselbe Situation modelliert und in den Baum integriert werden. Das Problem\ndabei ist jedoch, dass im allgemeinen Modell bei Alternativen die Verwendung von Selektoren vorgese-\nhen ist. Selektoren gehen solange die Menge der Alternativen von links nach rechts durch bis die erste\nerfolgreich war. Diese Vorgehensweise f\u00fchrt dazu, dass weiter rechts modellierte Alternativen evtl. nie-\nmals ausgef\u00fchrt werden, weil die weiter links stehenden immer erfolgreich sind und somit stattdessen\nausgef\u00fchrt werden. Ein weiterer Nachteil ist die immer gleiche Traversierungsreihenfolge derselben BT-\nInstanz. Es wird eben immer von links nach rechts gegangen ganz egal welche Art von Bot-Spieler\nsimuliert wird. Um diesen Nachteilen entgegenzuwirken wurde mit dem Personality Selector einCompo-\nsiteTaskNode de\ufb01niert der eine neue Art der Traversierung im Baum erm\u00f6glicht.\nDerPersonality Selector berechnet den Personality Value all seiner Kinder und sortiert diese danach\nin absteigender Ordnung. Anschlie\u00dfend werden nacheinander solange die sortierten Kinder ausgef\u00fchrt\nbis das erste erfolgreich war oder bis alle fehlgeschlagen sind. Damit der Personality Value der Kinder\nberechnet werden kann, m\u00fcssen die Kinder zun\u00e4chst mit dem Personality Decorator dekoriert worden\nsein. Abbildung 28 zeigt die wichtigsten Klassenelemente beider Personality -Komponenten.\nAbbildung 28: Die Elemente der Personality -Erweiterung.\nDerPersonality Decorator f\u00fcgt einem Knoten Personality Traits hinzu. Ein Personality Trai t ist dabei ein\n(String,Value)-Paar welches eine Charaktereigenschaft oder einen Gem\u00fctszustand des Agenten quan-\nti\ufb01ziert. Es k\u00f6nnen einem Knoten beliebig viele, aber durch den String-Key eindeutig identi\ufb01zierbare,\nPersonality Traits \u00fcber die addTrait() -Methode hinzugef\u00fcgt werden. Die Werte sind dabei vom Typ \ufb02oat\n5.4 Taktische Ebene 65und m\u00fcssen im Intervall [0,1] liegen. In dem Moment, wo ein Personlity Trait einem Knoten \u00fcber den\nDekorator hinzuf\u00fcgt wird, \ufb01ndet eine Bewertung des modellierten Verhaltens des zu dekorierenden Kno-\ntens statt. Stellt man sich beispielsweise einen Aggressivit\u00e4tswert vor der einem Knoten mit dem Wert\n1.0 zugewiesen wird. Dies w\u00fcrde bedeuten das Verhalten das durch den Knoten realisiert wird ist als\naggressiv zu bewerten und sollte von aggressiven Charakteren bevorzugt werden.\nDem Personality Selector k\u00f6nnen ebenfalls Personality Traits \u00fcber die addPreferenceTrait() -Methode\nhinzugef\u00fcgt werden. Jedoch besitzen diese Traits hierbei eine andere Bedeutung. Personality Traits be-\nwerten nicht das vom Unterbaum des Personality Selectors modellierte Verhalten, wie dies bei Personality\nDecorators der Fall ist, sondern sie de\ufb01nieren welche Personality Traits bei der Verhaltensauswahl be-\nr\u00fccksichtigt werden sollen und wenn ja mit welchem Gewicht dies getan werden soll. Das Besondere an\ndieser Stelle ist, dass zwar die zu beachtenden Personality Traits und ihre Gewichte zur Initialisierungs-\nzeit feststehen, jedoch nicht ihre genaue Auspr\u00e4gung. Aus diesem Grund sollte der \ufb02oat-Paramter der\naddPreferenceTrait() -Methode, der das Gewicht des Personality Traits de\ufb01niert, nicht mit der Auspr\u00e4gung\nverwechselt werden, die bei der Decorator -Methode \u00fcbergeben wird. Zur Ausf\u00fchrungszeit kommt dem\nString-Key des Personality Traits aufPersonality Selector -Ebene zwei Aufgaben zu. Erstens die Identi\ufb01-\nzierung der Personality Trait -Verwendung auf der Unterebene, d.h. auf Decorator -Ebene und zweites die\nIdenti\ufb01zierung mit dem String-Key korrespondierenden Blackboard -Eintrages, der die aktuelle Auspr\u00e4-\ngung des Personality Traits aufPersonality Selector -Ebene enth\u00e4lt. Ein Beispiel soll dies Zusammenspiel\nverdeutlichen.\nAbbildung 29: Beispielhafter Einsatz der Personality-Erweiterung.\nIn Abbildunng 29 wird ein Pesonality Selector FightTactic alsCompositeTaskNode -Knoten verwendet.\nDiesem werden die drei Personality Traits Aggressor ,Explorer und Tactism hinzugef\u00fcgt. Den drei al-\nternativen Verhaltensweisen, zwischen denen es auszuw\u00e4hlen gilt, werden ebenfalls Personality Traits\nhinzugef\u00fcgt. Die Menge der Traits muss dabei nicht der des Selectors entsprechen. Beispielsweise wird\nderDaredevilTactic nur der Aggressor Trait mit der Auspr\u00e4gung 1.0 zugewiesen. W\u00e4hrend der Ausf\u00fchrung\nsucht der Personality Selector imBlackboard nach den Auspr\u00e4gungen f\u00fcr seine drei Traits und bekommt\nz.B. dabei folgendes Ergebnis heraus:\nAggressor = 0.8, Explorer = 0.6 , Tactism = 0\nIm n\u00e4chsten Schritt wird der Personality Value eines jeden Kindes nach folgender Formel berechnet:\n66 5 Design und Implementierungsdetails der Game AIWas in Kombination mit den Auspr\u00e4gungen des Personality Selectors und den in Abbildung 29 darge-\nstellten Werten der drei Decorators zu folgender Personality Value -Sortierung f\u00fchrt:\nPersonality Value(DaredevilTactic) = 62%\nPersonality Value(ScardyCatTactic) = 49%\nPersonality Value(TactismTactic) = 46%\nDiese Liste wird im letzten Schritt dann von oben nach unten bis zum Ende abgearbeitet oder beim ersten\nAufkommen eines BS_SUCCESS ,BS_RUNNING oder BS_ERROR beendet. Dadurch das die Auspr\u00e4gungen\nimBlackboard hinterlegt sind und die strategische Ebene jederzeit die M\u00f6glichkeit besitzt \u00fcber die ITact-\nController -Schnittstelle diese zur Laufzeit zu \u00e4ndern k\u00f6nnen f\u00fcr ein und dieselbe BT-Instanz mehrere\nTraversierungsreihenfolgen existieren die sich zur Laufzeit \u00e4ndern k\u00f6nnen.\n5.4.4 Der Behavior Tree der Game AI\nAbbildung 30: Oberste Ebene des konkreten Behavior Trees derGame AI .\nAbbildung 30 zeigt die erste Ebene des konkreten BT-Baums welcher von der BTBuilder -Klasse reali-\nsiert wird. In der aktuellen Version des BTBuilders wird der Bau direkt im Code de\ufb01niert. Der Root-Knoten\n5.4 Taktische Ebene 67wird zu Beginn jeder Iteration als erstes angesteuert. Wurde der Aktionsauswahlprozess in der vorheri-\ngen Iteration nicht beendet und der BT-Status von au\u00dfen nicht zur\u00fcckgesetzt, wird das jeweils als letzte\nbesuchte Kind direkt angesteuert und die Traversierung an dieser Stelle fortgesetzt. Ist dies nicht der Fall\nwerden die drei Alternativen von links nach rechts durchgegangen.\nDie erste Alternative FightInRegion de\ufb01niert wie innerhalb einer Ziel-Region gek\u00e4mpft werden soll,\nfalls diese erreicht worden ist wird die nahe Umgebung auf Gegner und auf nicht eingenommene Up-\ngrade Points hin untersucht. Eine Region ist ein durch die Cuboid -Klasse de\ufb01nierter 3D-Raum der zur\nOrientierung im Level verwendet und von der strategischen Ebene bereitgestellt und de\ufb01niert wird. Im\nCombatTactic -Knoten erfolgt dann die Entscheidung welcher der beiden Objekt-Typen angesteuert wer-\nden soll. Falls die Ziel-Region erreicht wurde aber weder Feinde noch Upgrade Points in der N\u00e4he sind,\nscheitert die erste Alternative und die zweite Alternative wird ausprobiert. Ein solches Scheitern ist in der\nAbbildung nicht direkt ersichtlich, weil diese sich erst im Unterbaum von CombatTactic ereignen k\u00f6nnte.\nAus diesem Grund ist auch der Knoten rot-markiert, um zu verdeutlichen dass an dieser Stelle noch ein\ngr\u00f6\u00dferer Unterbaum existiert, auf den sp\u00e4ter noch genauer eingegangen wird. Die zweite Alternative ist\nbereits in der Abbildung komplett dargestellt und w\u00fcrde eine Erkundung der Region durchf\u00fchren. Wur-\nde hingegen die Ziel-Region noch nicht erreicht wird zum SeekToRegion -Knoten gesprungen und versucht\ndiese Alternative erfolgreich auszuf\u00fchren. SeekToRegion untersucht dabei als erstes ob Feine in der N\u00e4he\nsind und wenn ja wird im FightTactic -Knoten bestimmt auf welche Weise gek\u00e4mpft werden soll. Wurden\nkeine Feinde gesichtet wird \u00fcber die WanderAction ein beliebiger Punkt in der Ziel-Region angesteuert\num sich der Region weiter zu n\u00e4hern.\nAbbildung 31: Der modellierte Auswahlprozess des CombatTactic -Unterbaums. Es wird entweder keine Aktion,\ndieCaptureUP -Aktion oder der FightTactic -Unterbaum zur n\u00e4heren Auswahl des konkreten Kampf-\nverhaltens ausgew\u00e4hlt.\n68 5 Design und Implementierungsdetails der Game AIAbbildung 31 zeigt wie der Unterbaum des in Abbildung 30 abgebildeten CombatTactic -Knotens kon-\nkret aussieht. Der Kontext des Knotens ist das die Ziel-Region bereits erreicht wurde und die Nahe\nUmgebung auf Feinde und auf nicht eingenommene Upgrade Points untersucht wurde. Der Baum reali-\nsiert dabei eine Art if-then -Konstrukt welches folgendes besagt: Wenn nur Feinde in der N\u00e4he sind oder\nnur nicht vom eigenen Team besetzt Upgrade Points gefunden worden sind, dann f\u00fchre f\u00fcr den ersten\nFall den FightTactic -Knoten und im zweiten Fall die CaptureAction aus. Treffen beide Umst\u00e4nde zu lass die\nWahl von einem Personality Selector erledigen der zwischen beiden ausw\u00e4hlt. Trift keiner der Umst\u00e4nde\nzu gilt der Unterbaum als gescheitert und weil CombatTactic der letzte Knoten in einer Sequenzt der ers-\nten Alternative auf oberster Ebene ist, scheitert somit auch diese komplett und die N\u00e4chste Alternative\nwird ausgew\u00e4hlt.\nAbbildung 32: Der modellierte Auswahlprozess des FightTactic -Unterbaums zur Wahl der gew\u00fcnschten Kampftak-\ntik von gegnerischen Schiffen im freien Raum. Zur Wahl stehen drei unterschiedliche Taktiken.\nAbbildung 32 pr\u00e4sentiert den FightTactic -Unterbaum, der bestimmt auf welche Art gegnerische Schiffe\nbek\u00e4mpft werden sollen. Der Unterbaum wird an verschiedenen Stellen des Baumes benutzt. So z.B.\nvermehrt innerhalb des CombatTactic -Unterbaums, der ersten Alternative im \u00fcbergeordneten BT-Baum,\nals auch in der SeekToRegion -Alternative. Wie in der Abbildung zur erleichterten Darstellung nicht jedes\nMal der komplette Unterbaum des FightTactic -Knotens dargestellt wird, so muss der FightTactic -Knoten\nbzw. andere BT-Knoten im Baum nicht jedes Mal neu de\ufb01niert werden. Einmal de\ufb01niert k\u00f6nnen an un-\nterschiedlichen Stellen im Baum Referenzen auf diese wiederverwendet werden.\nDerFightTactic -Knoten ist genau genommen ein Personality Selector -Knoten und w\u00e4hlt wie bereits in\nAbschnitt 5.4.3 als Beispiel aufgef\u00fchrt zwischen den drei unterschiedlichen Kampftaktiken DaredevilTac-\ntic,TactismTactic undScardyCatTactic . Jede der drei Taktiken wird mit Personality Decorators bzw. mit Per-\nsonality Traits die in gestrichelten K\u00e4stchen \u00fcber den Knoten in der Abbildung visualisiert sind versehen.\nSie beschreiben abstrakt das modellierte Verhalten. Die aggressive Verhaltensweise der DaredevilTactic -\nVariante bevorzugt immer den direkten Kampf, wohingegen die ScardyCatTactic erst die Situation mittels\nderComplexCombatCondition evaluiert und nur wenn dieser Wert und somit der Glaube an einen Sieg\n5.4 Taktische Ebene 69hoch genug ist wird dann tats\u00e4chlich gek\u00e4mpft, ansonsten die immer die Flucht angetreten. Die Tactism-\nTactic -Variante verh\u00e4lt sich wie die ScardyCatTactic , nur mit dem Unterschied das sie vor der Fluchtantritt\nnoch die M\u00f6glichkeit der Benutzung eines nahen Schildgenerators in Betracht zieht.\n5.5 Strategische Ebene\nDie strategische Ebene ist die oberste oder abstrakteste der Game AI -Hierarchie. Ihre Aufgabe ist die \u00fcber-\ngeordnete langfristige Zielvorgabe und die Unterst\u00fctzung der Zielerf\u00fcllung durch die unteren Ebenen.\nAbbildung 33 zeigt den generellen Aufbau der Ebene und die Operationen die von der IStratController -\nSchnittstelle angeboten werden.\nDie strategische Ebene ist die Ebene die direkt mit der GameAI -Klasse verbunden ist und somit die Ebe-\nne die von dieser die Aufgabe zur Aktionsauswahl weitergereicht bekommt. Dazu ruft die GameAI -Klasse\ndieperformNextAction() -Methode der IStratController -Schnittstelle in jedem Spielzyklus neu auf. Neben\nder Aufgabe der Weiterleitung des Aktionsauswahlprozesses an die taktische Ebene, ist diese Ebene f\u00fcr\ndie Kon\ufb01gurierung der taktischen Ebene, sowie f\u00fcr die Regionsvorgabe zust\u00e4ndig. Ersteres wird direkt\nvon der StratController -Klasse im Zusammenspiel mit der PersonalityManager -Klasse umgesetzt. Letzte-\nres wird von der RegionMapManager -Klasse implementiert. Die Nachfolgenden Unterabschnitte gehen\nauf genau diese zwei Aspekte n\u00e4her ein. Die restlichen Methoden der IStratController -Schnittstelle die-\nnen ebenfalls dazu die Realisierung dieser Aufgaben zu kon\ufb01gurieren und werden deshalb entsprechend\nihres Kontextes erl\u00e4utert.\nAbbildung 33: Die Struktur der strategischen Ebene und die Abh\u00e4ngigkeiten zu anderen Systemebenen.\n5.5.1 Kon\ufb01gurationsm\u00f6glichkeiten\nDie Kon\ufb01gurierungsma\u00dfnahmen beschr\u00e4nken sich zurzeit auf zwei wesentliche Punkte. Der erste ist die\nDe\ufb01nition und Quanti\ufb01zierung globaler Blackboard -Parameter, die im Aktionsauswahlprozess des BTs\nverwendet werden. Eine Aktion wie FightEnemyAction beispielsweise erm\u00f6glicht die Angabe mehrerer\nParameter wie FireRate oder FireAccuracy . Diese Parameter k\u00f6nnen entweder w\u00e4hrend des Baus in der\nBTBuilder -Klasse de\ufb01niert werden oder zur Laufzeit jeweils aus dem Blackboard gelesen werden. Mit\nder De\ufb01nition globaler Parameter k\u00f6nnen Default-Werte f\u00fcr die einzelnen Aktionen de\ufb01niert werden.\n70 5 Design und Implementierungsdetails der Game AIDies hat bei einer breiten Verwendung der Default-Werte den Vorteil, dass an einer zentralen Stelle im\nCode die Parameter mehrerer Aktionen gleichzeitig angepasst werden k\u00f6nnen. Mit der \u00c4nderung oder\nAnpassung der globalen Blackboard -Parameter kann somit das Bot-Verhalten ma\u00dfgeblich und einfach\nbeein\ufb02usst werden. Die globalen Blackboard -Parameter sind nicht nur auf Aktionsparameter beschr\u00e4nkt.\nDie Anpassung des EnemyDetectionRange -Parameters beispielsweise de\ufb01niert den Bereich indem Gegner\nerkannt werden, worauf u.a. LastEnemyInRangeCondition pr\u00fcft. Die kontext-abh\u00e4ngige Bestimmung und\nVerwaltung unterschiedlicher Parameter f\u00fcr jede Aktion ist ebenfalls m\u00f6glich und w\u00fcrde eine noch ge-\nnauere Steuerung des Bot-Verhaltens erm\u00f6glichen. Der Aufwand und die P\ufb02ege der unterschiedlichen\nParameter ist allerdings dann entsprechend gr\u00f6\u00dfer als bei der Verwendung einiger weniger Default-\nParameter.\nDie De\ufb01nition der globalen Blackboard -Parameter \ufb01ndet zurzeit in der addGlobalBBParameters() -\nMethode der StratController -Klasse hart-codiert statt. Dazu wird \u00fcber die ITactController -Schnittstelle\nauf eine Instanz der WorldStateBlackboard -Klasse zugegriffen und \u00fcber deren setData() -Methoden die\nglobalen Parameter in das Blackboard eingef\u00fcgt.\nDie zweite Form der Kon\ufb01gurationsma\u00dfnahmen der strategischen Ebene betrifft den Einsatz von\nPers\u00f6nlichkeits-Eigenschafen innerhalb des BTs zur Steuerung des Bot-Verhaltens. Wie bereits in Ab-\nschnitt 5.4.3 erw\u00e4hnt, ist die Personality -Erweiterung dazu gedacht, eine neue Traversierungsreihenfolge\nin den Baum zu integrieren, die in Abh\u00e4ngigkeit zur aktuellen Pers\u00f6nlichkeit des Bots erfolgt. Die strate-\ngische Ebene ist der Ort, in der genau diese Pers\u00f6nlichkeit f\u00fcr einen Bot de\ufb01niert, ausgew\u00e4hlt und evtl.\nim Laufe des Spiels angepasst wird. Dazu bietet die IStratController -Schnittstelle nicht die M\u00f6glichkeit\nder eigenen Pers\u00f6nlichkeitsde\ufb01nition anhand einer Zusammenstellung von Personality Traits an, son-\ndern erm\u00f6glicht \u00fcber die choosePersoPro\ufb01l() -Methode die Auswahl eines von mehreren vorgefertigten\nPers\u00f6nlichkeits-Pro\ufb01len. Wie die Abbildung 33 zeigt, existieren aktuell folgende f\u00fcnf Pro\ufb01le, die jeweils\nvon einem Element des Personality Pro\ufb01le -Enums identi\ufb01ziert werden:\n\u2022PERSO_AGGROKILLER: Zieht die Bek\u00e4mpfung und Verfolgung gegnerischer Schiffe der Erobe-\nrung und der Verteidigung von Upgrade Points vor. Im Kampf wird unabh\u00e4ngig der Spielsituation\nbis zum letzten Health Point gek\u00e4mpft.\n\u2022PERSO_AGGROCONQUEROR: Zieht die Eroberung und die Verteidigung von Upgrade Points der\nBek\u00e4mpfung und Verfolgung gegnerischer Schiffe vor. Im Kampf wird unabh\u00e4ngig der Spielsituati-\non bis zum letzten Health Point gek\u00e4mpft.\n\u2022PERSO_EXPOKILLER: Zieht die Bek\u00e4mpfung und Verfolgung gegnerischer Schiffe der Eroberung\nund der Verteidigung von Upgrade Points vor. Im Kampf wird die Flucht ergriffen, falls der Sieg\nnicht sehr wahrscheinlich erscheint.\n\u2022PERSO_STDCONQUEROR: Zieht die Eroberung und die Verteidigung von Upgrade Points der Be-\nk\u00e4mpfung und Verfolgung gegnerischer Schiffe vor. Im Kampf wird je nach Situation die direkte\nKonfrontation gesucht, die Flucht ergriffen oder ein nahegelegener Schildgenerator angesteuert.\n\u2022PERSO_STDKILLER: Zieht die Bek\u00e4mpfung und Verfolgung gegnerischer Schiffe der Eroberung\nund der Verteidigung von Upgrade Points vor. Im Kampf wird je nach Situation die direkte Konfron-\ntation gesucht, die Flucht ergriffen oder ein nahegelegener Schildgenerator angesteuert.\nDiePersonalityManager -Klasse ist f\u00fcr die Spezi\ufb01zierung der Pro\ufb01le und die Einp\ufb02ege des aktuell aus-\ngew\u00e4hlten Pro\ufb01ls in das Blackboard zust\u00e4ndig. Die Einp\ufb02ege erfolgt dabei durch den Aufruf der add-\nPro\ufb01lSettingsToBB() -Methode, welches die entsprechenden Personality Traits eines Pro\ufb01ls ins Blackboard\n5.5 Strategische Ebene 71abspeichert. Das Pers\u00f6nlichkeits-Pro\ufb01l PERSO_AGGROKILLER besteht beispielsweise aus folgender Perso-\nnality Trait -Menge:\nKiller = 1.f\nAggressor = 1.f\nMit dieser Menge wird das in der PERSO_AGGROKILLER -Beschreibung spezi\ufb01zierte Verhalten im BT\nrealisiert. Die Wahl eines Pro\ufb01ls hat allerdings nicht nur Auswirkungen auf die Traversierungsreihen-\nfolge der Personality Selectors im Baum. Die Pro\ufb01lauswahl beein\ufb02usst dar\u00fcber hinaus auch den Einsatz\nvonBehavior Tags .Behavior Tags erm\u00f6glichen, wie in Abschnitt 5.4.3 vorgestellt, die tempor\u00e4re Aktivie-\nrung bzw. Deaktivierung bestimmter Teile des Baums. Das Pers\u00f6nlichkeits-Pro\ufb01l PERSO_AGGROKILLER\nbeispielsweise verwendet folgende Behavior Tags :\nBlackboardEntry<bool> = {\"'Tag.FNIR.Tag.TT\"', false}\nBlackboardEntry<bool> = {\"'Tag.FNIR.Tag.SCT\"', false}\nMit diesen beiden Behaviors Tags wird die Ausf\u00fchrung der in Abbildung 32 modellierten Kampftakti-\nkenTactismTactic undScardyCatTactic deaktiviert. Das bedeutet selbst wenn die \u00fcbriggebliebene Dare-\ndevilTactic fehlschl\u00e4gt, wird keine der anderen Alternativen ausprobiert. Au\u00dferdem kann sich in diesem\nUnterbaum auch bei der Anpassung der Personality Trait -Auspr\u00e4gungen des Pro\ufb01ls niemals eine an-\ndere Traversierungsreihenfolge im Unterbaum ergeben, weil solange diese beiden Behaviors Tags aktiv\nsind nur eine einzige Alternative zur Auswahl steht. Zu beachten ist, dass die Deaktivierung der bei-\nden Kampftaktiken nur die Instanzen im Unterbaum von FightNotInRegion betrifft, nicht jedoch die der\nanderen Stellen im Baum, da diese au\u00dferhalb der FNIR spezi\ufb01zierten Behavior Tag -Hierarchie liegen.\nSo wird beispielsweise im FightInRegion -Unterbaum nach wie vor alle drei Kampftaktiken evaluiert und\ngegebenenfalls nacheinander ausgef\u00fchrt.\n5.5.2 Region Map und die strategische Zielbestimmung\nDie Aufgaben der RegionMapManager -Klasse der strategischen Ebene sind die Erstellung und Verwaltung\nderRegion Map , die Erfassung der aktuellen Region, die Bestimmung eines jeweils neuen Regionsziels\nund die Propagation der Regionsinformationen an die taktische Ebene. Nachfolgend werden diese un-\nterschiedlichen Aufgaben kurz erl\u00e4utert.\nErstellung und Verwaltung der Region Map\nDieRegion Map nimmt eine r\u00e4umliche Aufteilung des aktuellen Levels in 3D-Quadrate mit Hilfe der Cubo-\nid-Klasse vor. Dazu wird in Abh\u00e4ngigkeit des \u00fcber die setStartRegionMapRange() -Methode der IStratCon-\ntroller -Schnittstelle \u00fcbergebenen Parameters die Gr\u00f6\u00dfe des 3D-Quadrats zur Initialisierungszeit festge-\nlegt. Dieses 3D-Quadrat wird daraufhin in acht gleichgro\u00dfe Teil-Quadrate zerlegt, welche zur De\ufb01nition\nder Regionen der Region Map eingesetzt werden. Der Mittelpunkt des \u00fcbergeordneten 3D-Quadrats ent-\nspricht dabei immer der Null-Position des Raums, sodass die Teil-Quadrate um die Null-Position des\nRaums herum gebildet werden. Abbildung 34 veranschaulicht den Aufbau eines 3D-Quadrats und Abbil-\ndung 35 den eben beschriebenen Aufteilungsprozess.\nBei jedem von der RegionMapManager -Klasse erkannten Regionswechsel, wird einmal auf die globale\nRegions-Zugeh\u00f6rigkeit aller in Sichtweite be\ufb01ndlichen Upgrade Points gepr\u00fcft. Wird bei der \u00dcberpr\u00fcfung\nfestgestellt, dass sich Upgrade Points au\u00dferhalb der Region Map be\ufb01nden, so erfolgt eine Region Map -\nErweiterung um den Faktor der Initialisierungsgr\u00f6\u00dfe. Bei jeder Erweiterung wird demnach zus\u00e4tzlich\neine neue Unterebene mit 8 Regionen erstellt. Die Anzahl der zu verwalteten Regionen entwickelt sich\nexponentiell mit steigender Ebenen-Tiefe. Um die dadurch evtl. entstehende Speicherlast zu reduzieren,\nwerden nur die Unterregionen erstellt und im Speicher gehalten die aktuell relevant sind. Alle nicht\n72 5 Design und Implementierungsdetails der Game AIAbbildung 34: Aufbau des 3D-Quadrats einer Region mit einer Initialisierungsgr\u00f6\u00dfe von 40000.\nAbbildung 35: Aufteilung des 3D-Quadrats einer Region in seine 8 Unterregionen.\nben\u00f6tigte Regionen werden entweder nicht erstellt oder wieder gel\u00f6scht, sodass immer nur eine \u00fcber-\nschaubare Anzahl an Regionen im Speicher gleichzeitig gehalten werden muss.\nErfassung der aktuellen Region innerhalb der Region Map\nDie strategische Ebene ruft in jedem ihrer Zyklen die RegionMapManager -Klasse zur \u00dcberpr\u00fcfung der\naktuellen Region auf. Dazu wird im ersten Schritt die aktuelle Position des Schiffes auf die Regionszuge-\nh\u00f6rigkeit zur aktuellen Region des vergangenen Zyklus \u00fcberpr\u00fcft. Falls die Position zur alten aktuellen\nRegion geh\u00f6rt, ist die \u00dcberpr\u00fcfung an dieser Stelle bereits beendet, falls nicht muss die neue Region\nermittelt werden. Dazu wird beginnend von der obersten Ebene der Region Map sich von Ebene zu Ebe-\nne gesucht. Diese Top Down -Suche ist deswegen m\u00f6glich, weil die Gr\u00f6\u00dfe der \u00fcbergeordneten Region\ngenau der Gr\u00f6\u00dfe aller Unterregionen entspricht. Wurde die aktuelle Region gefunden, die sich immer\nauf der untersten Ebene der Region Map be\ufb01ndet, ersetzt die neue Region die alte aktuelle Region in der\nRegionMapManager -Klasse f\u00fcr zuk\u00fcnftige Regionszugeh\u00f6rigkeits-Vergleiche. Dar\u00fcber hinaus werden die\n3D-Quadrat-Ausma\u00dfe der neuen aktuellen Region, die \u00fcber die Cuboid -Klasse de\ufb01niert werden, an die\ntaktische Ebene als aktuelle Region weitergegeben.\nBestimmung eines Regionsziels\nDieRegionMapManager -Klasse ist ebenfalls f\u00fcr die Bestimmung der Region zust\u00e4ndig, die als n\u00e4chstes\n5.5 Strategische Ebene 73von der taktischen Ebene angesteuert werden soll. Durch die Vorgabe einer Zielregion wird die takti-\nsche Ebene nicht sofort dazu aufgefordert diese Region zu erreichen, sondern es dient als langfristige\nstrategische Zielvorgabe. Es ist also durchaus eine g\u00fcltige und gew\u00fcnschte taktische Entscheidung die\nErreichung der Zielregion solange aufzuschieben, bis nahe Gegner erfolgreich bek\u00e4mpft wurden.\nAktuell wird zur Zielbestimmung entweder ein Random Walk zwischen beliebigen Regionen oder ei-\nnem zwischen Regionen mit bekannten Upgrade Point -Vorkommen eingesetzt. Der Random Walk zwi-\nschen beliebigen Regionen dient einerseits der Entdeckung neuer Regionen mit Upgrade Points und an-\nderseits der \u00dcberpr\u00fcfung auf eine notwendige Map-Erweiterung. Die andere Random Walk -Variante soll\ndie bevorzugte Ansteuerung von POIs simulieren. Anders als bei der ersten Random Walk -Art wird die\nZielregion, nach der Untersuchung auf Upgrade Points , nicht sofort wieder verlassen, sondern eine Zeit\nlang als Zielregion beibehalten. Somit wird der taktischen Ebene eine gewisse Zeit gelassen evtl. Erobe-\nrungen oder Verteidigungen von Upgrade Points in der Region vorzunehmen. Ein einstellbarer Tweaker\ngibt dabei das gew\u00fcnschte Verh\u00e4ltnis zwischen der den Random Walk-Varianten an.\nDieRegion Map bietet zusammenfassend dem Bot die F\u00e4higkeit zur Erfassung des Levels. Das Potenzi-\nal dieser F\u00e4higkeit wird zurzeit noch nicht v\u00f6llig ausgenutzt. Es kann davon ausgegangen werden, dass\nerst mit der Integration koordinierten Gruppenverhaltens das wahre Potenzial der Region Map ausge-\nsch\u00f6pft wird. Denn die Region Map bietet allen voran eine l\u00fcckenlose Erfassung des Levels an, welche\nzum Informationsaustausch zwischen den Bots genutzt werden kann. Dabei kann die Granularit\u00e4t der\nRegionsgr\u00f6\u00dfe beliebig angepasst werden.\n74 5 Design und Implementierungsdetails der Game AI6 Evaluation\nDieses Kapitel beschreibt den Ansatz zur Evaluation der in Kapitel 4 pr\u00e4sentierten Bot-Implementierung\nzur Generierung einer realistischen Netzwerklast. Abschnitt 6.1 \u201eZiele und Rahmenbedingungen\u201c de\ufb01-\nniert die Zielbestimmung und Zieleingrenzung der Evaluation und beschreibt des Weiteren die Testplatt-\nform und den Einsatz des Discrete Event Game Simulators zur Evaluation.\nDie Evaluation umfasst 9 verschiedene Testdurchl\u00e4ufe, die zu jeweils unterschiedlichen Bedingun-\ngen ablaufen. Abschnitt 6.2 \u201eEingesetzte Metriken\u201c stellt die f\u00fcr die Evaluation eingesetzten Metriken\nvor, die zur Erfassung der in Abschnitt 6.4 \u201eDurchgef\u00fchrte Testszenarien\u201c pr\u00e4sentierten Evaluationser-\ngebnisse der neun verschiedenen Testdurchl\u00e4ufe. Abschnitt 6.3 \u201eAllgemeiner Aufbau und Ablauf der\nTestszenarien\u201c beschreibt zuvor den allgemeinen Aufbau und Ablauf der durchgef\u00fchrten Testszenarien.\nDazu wird vor allem auf die Rolle des Discrete Event Game Simulators eingegangen, welcher ma\u00dfgeblich\nden Ablauf und die Kon\ufb01guration der Testszenarien bestimmt.\nDer abschlie\u00dfende Abschnitt 6.5 \u201eAuswertung der Ergebnisse\u201c der Evaluation wertet die gewonnenen\nErgebnisse anhand der Metriken aus und versucht einige Schl\u00fcsse und Aussagen betreffend der Eignung\nzur Erzeugung der Netzwerklast zutreffen.\n6.1 Ziele und Rahmenbedingungen\nDas Hauptziel der Evaluation ist die \u00dcberpr\u00fcfung ob und in welchem Ausma\u00df die in Abschnitt 1.2\nde\ufb01nierten vier Kriterien Reproduzierbarkeit ,Skalierbarkeit ,Realit\u00e4tsgrad undKon\ufb01gurierbarkeit\nvom implementierten Ansatz aus Kapitel 4 erf\u00fcllt werden. Anhand der \u00dcberpr\u00fcfung dieser Kriteri-\nen soll die konkrete Bot-Implementierung daraufhin untersucht werden, ob diese zur synthetischen\nGenerierung einer realistischen Netzwerklast zu Evaluationszwecken verschiedenartiger P2P-Overlays\ngeeignet erscheint. Dar\u00fcber hinaus soll anhand der Evaluationsergebnisse ebenfalls ein erster Eindruck\ndavon gewonnen werden, ob der allgemeine Ansatz der Bot-Implementierung, n\u00e4mlich die Verwendung\nkontext-sensitiver AI-Spieler zur Lasterzeugung , eine ernst zu nehmende Alternative im Vergleich zu\nden anderen, in Abschnitt 3.1 vorgestellten, Ans\u00e4tzen der Lasterzeugung darstellt.\nBei der Untersuchung wird nicht der Anspruch auf die abschlie\u00dfende Beantwortung der Frage nach\nder Geeignetheit der Bot-Implementierung bzw. des allgemeinen Ansatzes zur Lasterzeugung erhoben.\nSolch eine umfassende Evaluation w\u00fcrde ein breites Spektrum an verschiedenen Testreihen unter Be-\nr\u00fccksichtigung aussagekr\u00e4ftiger und evaluierter Netzwerk-Metriken zur Messung der G\u00fcte der generier-\nten Netzwerklast erfordern. Dies w\u00fcrde insbesondere eine genaue Untersuchung der dabei tats\u00e4chlich\ngenerierten Netzwerklast und dem Vergleich dieser mit Referenzdaten echter Netzwerklasten oder der\ngenerierten Last alternativer Ans\u00e4tze mit einschlie\u00dfen. Die aussch\u00f6pfende und allen voran Netzwerk\ntechnisch orientierte Beantwortung dieser Frage wird somit nachfolgenden Arbeiten im Rahmen des\nQuaP2P-Forschungsprojektes \u00fcberlassen, welches das \u00fcbergeordnete Projekt dieser Master-Thesis dar-\nstellt. Aus diesem Grund ist das Ziel der Evaluation dieser Master-Thesis eine erste (grobe) Untersuchung\nder generellen Geeignetheit der Bot-Implementierung bzw. des Ansatzes zur Lasterzeugung als Grundla-\nge f\u00fcr eventuell weiterf\u00fchrende, exaktere oder aufwendigere Evaluationen.\nZur Evaluation wird ein Discrete Event Game Simulator des DVS-Fachbereichs [31, 30] eingesetzt. Der\nSimulator ist in der Lage das Spiel mit mehreren Peers, statt in einem realen Netzwerk, in einer vom\nSimulator kontrollierten und reproduzierbaren Umgebung auszuf\u00fchren. Echtzeit Game-Events, die \u00fcber\ndas Netzwerk weitergleitet werden m\u00fcssten, werden vom Simulator abgefangen und an die betreffenden\n75Peers unter Ber\u00fccksichtigung der simulierten Netzwerk-Charakteristik weitergeleitet. Die aktuell unter-\nst\u00fctzen Overlay-Netzwerke sind pSense [49], BubbleStorm [55] und eine Client/Server -Version namens\nCUSP . Die Simulierung des Netzwerks und die m\u00f6gliche Abschaltung der gra\ufb01schen Spieldarstellung er-\nm\u00f6glichen, unter der Voraussetzung der Verf\u00fcgbarkeit ausreichender Systemleistung und -ressourcen,\neine Beschleunigung der tats\u00e4chlichen Spielausf\u00fchrung. Die Evaluation wurde auf einem Computer mit\nfolgenden technischen Eckdaten ausgef\u00fchrt:\n\u2022CPU: Intel Core 2 Duo T9600 (2,8 GHz)\n\u2022RAM: 4 GB\n\u2022OS:Ubuntu 12.04.1 LTS (32-Bit)\n6.2 Eingesetzte Metriken\nF\u00fcr die Untersuchung der generellen Eignung zur Lasterzeugung der Bot-Implementierung werden da-\nbei die in der Tabelle 3 aufgef\u00fchrten Metriken zur Beurteilung des Bot-Verhaltens de\ufb01niert und in den\ndurchgef\u00fchrten Testdurchl\u00e4ufen verwendet. Es handelt sich dabei um relativ simple Metriken, deren\nBezeichnungen gr\u00f6\u00dftenteils selbsterkl\u00e4rend sind. Beispielsweise erfasst die Shot Accuracy -Metrik die\nSchussgenauigkeit in Prozent. Die meisten Metriken k\u00f6nnen sich dabei entweder auf eine Bot-Instanz im\nSchnitt oder auf alle Bot-Instanzen eines gesamten Testdurchlaufs beziehen. Die Bezeichner-Erg\u00e4nzung\n\u201e(Team)\u201c weist zus\u00e4tzlich auf eine m\u00f6gliche Auswertung \u00fcber die aggregierte Menge der Bot-Instanzen\neines Teams hin.\nBezeichnung Abk\u00fcrzung Wertebereich Relevante Kriterien\nNumber of Kills Kills# Zin [0,1[ Kon\ufb01gurierbarkeit\nNumber of Deaths Deaths# Zin [0,1[ Kon\ufb01gurierbarkeit\n(Team) Kill/Death-Ratio (T)KD-Ratio % in [0,1[ Realit\u00e4tsgrad\nNumber of Shots Shots# Zin [0,1[ Kon\ufb01gurierbarkeit\nNumber of Hits Hits# Zin [0,1[ Kon\ufb01gurierbarkeit\nShots per Player per Min. PShots Qin [0,1[ Kon\ufb01gurierbarkeit\nHits per Player per Min. PHits Qin [0,1[ Kon\ufb01gurierbarkeit\nShot Accuracy Accuracy % in [0,100] Kon\ufb01gurierbarkeit, Realit\u00e4tsgrad\n(Team) Upgrade Point Score (T)UP-Score Qin [0,1[ Kon\ufb01gurierbarkeit, Realit\u00e4tsgrad\nSimulation Time Time Minutes in [0,1[ Kon\ufb01gurierbarkeit, Skalierbarkeit\nSimulation Memory VIRT Memory VIRT Mega Bytes in [0, 1[Skalierbarkeit\nSimulation Memory RES Memory RES Mega Bytes in [0, 1[Skalierbarkeit\nMeasurement Bias Bias % in [0,100] Reproduzierbarkeit\nTabelle 3: Au\ufb02istung der in der Evaluation verwendeten Metriken mit Wertebereichsangabe und der Zuordnung\nzu relevanten Kriterien.\nIn der Tabelle 3 wird weiterhin eine Zuordnung von Metriken zu relevanten Kriterien vorgenommen.\nDiese Zuordnung soll die Bedeutung der Metriken f\u00fcr bestimmte Kriterien hervorheben, auf die in der\nAuswertung der einzelnen Testdurchl\u00e4ufe noch n\u00e4her eingegangen wird. Die Anzahl der abgefeuerten\nSch\u00fcsse beispielsweise, welche von der Shots -Metrik erfasst wird, bestimmt direkt die Menge der \u00fcbertra-\ngenden Nachrichten im Netzwerk. Anders als auf Client/Server -Systemen basierenden Spielen, m\u00fcssen\nbeiP2P-Spielen Spielinformationen in der Regel im Netzwerk mittels Nachrichten weitergereicht wer-\nden. In Planet PI4 ist das Abfeuern von Sch\u00fcssen eine solch weiterzureichende Spielinformation und\n76 6 Evaluationdemnach ihr Aufkommen eine wichtige Stellschraube zur Kalibrierung der Netzwerklast.\nIm Folgenden werden kurz die Metriken oder der Kriterienbezug erl\u00e4utert, deren Bedeutung oder\ndessen Beziehung evtl. nicht sofort ersichtlich erscheinen:\n\u2022(T)KD-Ratio: Misst das Verh\u00e4ltnis zwischen Kills undDeaths eines Bots. Die effektive Vernichtung\nder gegnerischen Schiffe ist neben der Eroberung von Upgrade Points eines der m\u00f6glichen zentra-\nlen Spielziele von Planet PI4 . Aus diesem Grund ist das Team Kill/Death -Verh\u00e4ltnis ein wichtiger\nIndikator f\u00fcr die Spielst\u00e4rke eines Bots und erm\u00f6glicht den F\u00e4higkeiten-Vergleich zum Spielen des\nSpiels zwischen verschiedenen Bot-Implementierungen, Bot-Kon\ufb01gurationen oder menschlichen\nSpielern.\nAnders als die Anzahl der Sch\u00fcsse eine direkte Kalibrierung der Netzwerklast erm\u00f6glicht, ist die\nAuswirkung der Anpassung der KD-Ratio f\u00fcr die Netzwerklast nicht direkt ersichtlich. Allerdings\nerm\u00f6glicht die KD-Ratio die Bewertung des Bot-Verhaltens in Bezug auf den Realit\u00e4tsgrad der er-\nzeugten Last. Im Spiel k\u00f6nnen beispielsweise Deaths nicht nur durch feindliche Absch\u00fcsse erfolgen,\nsondern ebenfalls durch Friendly Fire , der Kollision mit Team-Bots oder dem Zusammenprall mit\nAsteroiden. Diese Deaths werden jedoch den Verursachern nicht als regul\u00e4re Kills zugeschrieben,\nsodass im Laufe eines Spiels sich mehr Deaths ereignen k\u00f6nnen als Kills. Unterstellt man weiter\nmenschlichen Spielern die erfolgreiche Vermeidung solcher \u201enegativen\u201c Deaths , so sollte eine Bot-\nImplementierung eine KD-Ratio , \u00fcber alle Bot-Instanzen eines Spiels betrachtet, von \u00191 anstre-\nben. Ein Wert von genau 1 w\u00fcrde n\u00e4mlich bedeuten, dass alle Deaths von regul\u00e4ren Killsverursacht\nworden sind und somit keine \u201enegativen\u201c Deaths vorkamen. Mit so einem Ergebnis w\u00fcrde gezeigt\nwerden, dass die erzeugte Netzwerklast als realistisch anzunehmen sei, dass sie durch menschen-\n\u00e4hnliches Verhalten erzeugt worden ist.\n\u2022Time: Gibt die ben\u00f6tigte Zeit eines Testdurchlaufs oder den gemittelten Wert mehrerer Test-\ndurchl\u00e4ufe im Simulator an. Weil die Simulation je nach verf\u00fcgbaren Ressourcenkapazit\u00e4ten,\ndie Berechnung des Spielgeschehens beschleunigen bzw. bei Belastung verlangsamen kann, ist\ndie ben\u00f6tigte Berechnungszeit des Simulators ein grober Indikator f\u00fcr die Performance der Bot-\nImplementierung. Um einen Richtwert zur Beurteilung der Performance zu haben, wird die\nVorg\u00e4nger-Implementierung von Dimitri Wulffert (siehe Abschnitt 3.5) als Referenz herangezo-\ngen.\n\u2022Memory: Gibt den durchschnittlichen Speicherverbrauch des Simulatorprozesses w\u00e4hrend der\nAusf\u00fchrung eines Testdurchlaufes oder mehrerer Testdurchl\u00e4ufe im Schnitt an. Wie bei der Ti-\nme-Metrik dient dies zur ersten groben Einsch\u00e4tzung der Speicherauslastung, indem gegen die\nVorg\u00e4ngerimplementierung gepr\u00fcft wird.\n\u201eVIRT\u201c bezeichnet dabei die virtuelle Gr\u00f6\u00dfe eines Prozesses und ist die Summe seines aktuell be-\nlegten Speichers.\n\u201eRES\u201c bezeichnet dabei die tats\u00e4chliche bzw. physikalische Gr\u00f6\u00dfe eines Prozesses und ist die Sum-\nme seines aktuell belegten Speichers.\n\u2022Bias: Misst die Metrik-Abweichung f\u00fcr wiederholte Testdurchl\u00e4ufe zur \u00dcberpr\u00fcfung der Repro-\nduzierbarkeit der Ergebnisse. Der Bias wird ermittelt, indem die proztentuelle Abweichung aller\nMetriken zwischen den einzelnen Simulationswiederholungen berechnet und im Anschluss daran\ngemittelt wird. Eine Angabe von 0% bedeutet, dass es keine Abweichung zwischen den Ergebnissen\nermittelt werden konnte.\n6.2 Eingesetzte Metriken 77Der Bias dient somit der \u00dcberpr\u00fcfung auf Nicht-Determinismus der Simulationsabl\u00e4ufe. Die Re-\nproduzierbarkeit wird dabei gr\u00f6\u00dftenteils vom Simulator gew\u00e4hrleistet, der die Kontrolle \u00fcber\ndie simulierte Umgebung besitzt und diese zur Generierung deterministischer Prozessabl\u00e4ufe ein-\nsetzt. Nichtsdestotrotz werden in der Bot-Implementierung stochastische Prozesse verwendet, z.B.\nzur Bestimmung des Random Walks zwischen Regionen der strategischen Ebene (siehe Abschnitt\n5.5.2). Damit solche Prozesse nicht die deterministische Eigenschaft der Simulation verletzen, bie-\ntet das Spiel die Benutzung eines vom Simulator kontrollierbaren Zufallszahlengenerators an, der\nf\u00fcr stochastische Prozesse reproduzierbare pseudo-Zufallszahlenreihen produziert.\n6.3 Allgemeiner Aufbau und Ablauf der Testszenarien\nEin Testdurchlauf bezeichnet eine durch eine Menge von Ausf\u00fchrungsparametern kon\ufb01gurierte Spiel-\nausf\u00fchrung mit einer festgelegten Spieleranzahl und Spieldauer. Damit die in Abschnitt 6.2 de\ufb01nierten\nMetriken reproduzierbare Ergebnisse produzieren, erfolgt die Spielausf\u00fchrung unter Einsatz des Discrete\nEvent Game Simulators . Abbildung 36 zeigt dabei den generellen Testaufbau.\nAbbildung 36: \u00dcbersicht des allgemeinen Testaufbaus. Angelehnt an [31].\nMit der De\ufb01nition des Scenario-Files werden unterschiedliche Spielparameter f\u00fcr die Simulation oder\nSpielausf\u00fchrung de\ufb01niert, wie beispielsweise Spieleranzahl, Spieldauer, Seed-Parameter des Zufallszah-\nlengenerators oder die Auswahl des zu simulierenden P2P-Overlays. Das in der Scenario-File de\ufb01nierte\nSpielszenario wird vom Simulator daraufhin zur Ausf\u00fchrungszeit kontrolliert umgesetzt, d.h. der Simu-\nlator k\u00fcmmert sich um die Initialisierung, Verwaltung und Terminierung der verschiedenen Spielinstan-\nzen, sowie um die pseudo Netzwerk-Kommunikation dieser untereinander zur Spielzeit. Somit kann jede\nSpielinstanz im Simulator als ein zu simulierender Peer betrachtet werden.\nIn der Abbildung wird ein Peer als ein drei schichtiges System dargestellt. Die oberste Ebene ist\ndieNetwork Application -Ebene, welche die eigentliche Logik der zu simulierenden Anwendung ent-\nh\u00e4lt. Im Rahmen dieser Evaluation geht es dabei um das MMOG -Spiel Planet PI4 , f\u00fcr welches die\nBot-Implementierung entwickelt wurde. Es k\u00f6nnte aber auch eine beliebig andere verteilte Anwendung\nsein, wie beispielsweise das Search Overlay vonBubbleStorm [55].\n78 6 EvaluationAlle Network Applications abstrahieren dabei durch die Verwendung einer gemeinsamen System-\nSchicht in gewisser Weise von der eigentlichen System-Ausf\u00fchrung in einem verteilten Netzwerk. Die\nSystem-Schicht bzw. das System Interface bietet den Anwendungen Zugriff auf gemeinsame Funktiona-\nlit\u00e4ten, wie die eigentliche Abwicklung der Netzwerk-Kommunikation, das Scheduling oder die Ausf\u00fch-\nrung bestimmter Anwendungsereignisse (Events) auf Netzwerkebene. Eine f\u00fcr die Evaluation wichtige\ngemeinsame Funktionalit\u00e4t ist die Bereitstellung von Statistik- und Logging-Mechanismen zur Erfassung\nund Speicherung gew\u00fcnschter Anwendungs- und Netzwerkdaten. Die somit erfassten Daten werden in\neiner Datenbank hinterlegt und k\u00f6nnen anschlie\u00dfend ausgewertet werden. Es existieren bereits einige\nBerechnungs-Skripte oder Visualisierungsm\u00f6glichkeiten \u00fcber Gnuplot zur Aufbereitung der Daten. Zur\nBestimmung der Metrik-Daten aus Abschnitt 6.2 und zur Ergebniserfassung und -auswertung in Ab-\nschnitt 6.4 wurden gr\u00f6\u00dftenteils auf bereits vorhandenes zur\u00fcckgegriffen.\nDie unterste der drei Ebenen eines Peers ist die Runtime Engine -Ebene. Sie spezi\ufb01ziert welches konkre-\nte Netzwerk \u00fcber den Overlay Simulator simuliert werden sollen, oder ob die Testausf\u00fchrung \u00fcber ein\nreales Netzwerk ausgef\u00fchrt werden soll.\nDer Ablauf einer jeden Simulation erfolgt dabei nach demselben Muster. Der Simulator startet das\nSpiel zum Simulationsstartzeitpunkt und l\u00e4sst danach in einem bestimmten Intervall nacheinander wei-\ntere Peers das Spiel beitreten. Die Erfassung der globalen Statistiken erfolgt dabei zum Startzeitpunkt\nder Simulation und wird jeweils zum Eintrittszeitpunkt eines Peers, durch dessen individuelle Statistiken\nerweitert. Das Spiel wird dann die gew\u00fcnschte Zeit lang gespielt, w\u00e4hrend die Statistik-Daten in der\nDatenbank hinterlegt werden. Terminiert wird das Spiel zum Endzeitpunkt der Simulation ohne zuvor\neinen Prozess zum geordneten Austritt der einzelnen Peers auszuf\u00fchren. Im Anschluss auf einen Test-\ndurchlauf werden die Ergebnisse \u00fcber Skripte und Gnuplot aufgearbeitet.\nUm die Bias-Abweichung zu ermitteln, wird zus\u00e4tzlich jeder Testdurchlauf zwei Mal ausgef\u00fchrt. Mit\ndem Bias soll getestet werden, ob die Ergebnisse der Testdurchl\u00e4ufe auch reproduzierbar sind. Der Bias\nbezieht sich dabei nicht auf die Ergebnisse der Laufzeit- und Speichermessung, da diese nur grob erfasst\nwerden k\u00f6nnen und aufgrund externer Faktoren schwanken k\u00f6nnen. Gra\ufb01sche Ergebnisverl\u00e4ufe wie z.B.\nderUP Score -Verlauf werden ebenfalls nicht ber\u00fccksichtigt. Die in den Testszenarien aufgef\u00fchrten Metrik-\nErgebnisse sind immer die Ergebnisse der ersten Testausf\u00fchrung, die Ergebnisse der zwei zus\u00e4tzlichen\nWiederholungen zur Ermittlung des Bias werden nicht extra aufgef\u00fchrt, sondern werden nur anhand\neiner m\u00f6glichen Bias-Abweichung angezeigt.\nF\u00fcr die Zeit- und Speichermessung wird Ubuntus System\u00fcberwachungsprogramm \u201etop\u201c verwendet.\n6.4 Durchgef\u00fchrte Testszenarien\nIn diesem Abschnitt werden die Ergebnisse der einzelnen Testszenarien pr\u00e4sentiert. Die Pr\u00e4sentation\nfolgt dabei folgendem Schema: Als erstes gibt eine kurze Beschreibung Auskunft \u00fcber die Besonderheit\ndes Testszenarios, was sich vor allem auf abweichende Parametereinstellungen konzentriert. Danach\nfolgt die tabellarische Darstellung der Simulationsparameter. Die Parameterdarstellung ist aufgeteilt in\nSimulator- und Spieleinstellungen in einer gemeinsamen und den Bot-Einstellungen in einer separaten\nTabelle. Falls die Bot-Parameter zwischen den Teams unterschiedlich sind, erfolgt die Darstellung der\nBot-Parameter in jeweils einer eigenen Tabelle. Im Anschluss daran werden die Metrik-Ergebnisse in ta-\nbellarischer und gra\ufb01scher Form pr\u00e4sentiert.\nAbschlie\u00dfend noch einige allgemeine Erl\u00e4uterungen zum besseren Verst\u00e4ndnis der Simulationspara-\nmeter. Der Simulationsparameter Join-Verhalten gibt das Eintrittsverhalten der Peers zum Simulations-\nstart an. Linear in 00:01 bezeichnet dabei einen linearen Eintrittsprozess in einem 1-Sekunden Takt. Der\n6.4 Durchgef\u00fchrte Testszenarien 79Seed-Parameter gibt den gleichnamigen Wert f\u00fcr den Zufallszahlengenerator des Simulators an. Die Ab-\nk\u00fcrzen UP und SG stehen f\u00fcr Upgrade Point undShield Generator . Die Personality Pro\ufb01le -Einstellungen\nentsprechen dabei den in Abschnitt 5.5.1 pr\u00e4sentierten Pro\ufb01len und Erl\u00e4uterungen.\n6.4.1 1. Testszenario\nIm ersten Testszenario treten zwei gleich kon\ufb01gurierte Teams gegeneinander an. Allen Bots wird so-\nmit das PERSO_AGGROKILLER -Pro\ufb01l zugewiesen, was die Bek\u00e4mpfung gegnerischer Schiffe der UP-\nEroberung deutlich bevorzugt.\nSimulationsparameter:\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nSpieleranzahl: 16 Join-Verhalten: Linear in 00:01\nTeam-Anzahl: 2 Netzwerk-Overlay: CUSP\nVerteilung: 8 vs. 8 UP-Anzahl: 9\nSpieldauer: 20 Minuten SG-Anzahl: 9\nAsteroiden-Anzahl: 225 Seed: 42\nTabelle 4: Simulator- und Spielparameter f\u00fcr das 1. Testszenario.\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nPersonality Pro\ufb01le: PERSO_AGGROKILLER Fire Accuracy: 100%.\nEnemy Detection Range: 25000 Fire Rate: 70%.\nUP Detection Range: 50000\nTabelle 5: Bot-Parameter von Team Alpha & Bravo f\u00fcr das 1. Testszenario.\nMetrik-Ergebnisse:\nMetrik Auspr\u00e4gung Metrik Auspr\u00e4gung Metrik Auspr\u00e4gung\nShots#: 41048 Accuracy: 61.22% UP-Score: 2.38\nPShots: 128.28 Kills#: 261 Bias: 0%\nHits#: 25128 Deaths#: 289 Time: 11:33\nPHits: 78.53 KD-Ratio: 90.03% Memory VIRT: 184 MB\nMemory RES: 110.5 MB\nTabelle 6: Metrik-Ergebnisse von Team Alpha & Bravo f\u00fcr das 1. Testszenario.\n80 6 EvaluationAbbildung 37: Upgrade Point Score Verlauf f\u00fcr das 1. Testszenario.\n6.4.2 2. Testszenario\nIm zweiten Testszenario wird im Grunde das erste Testszenario erneut ausgef\u00fchrt, nur die Fire Accuracy -\nEinstellung der Bots wird deutlich reduziert. Damit soll untersucht werden, ob dadurch die Schussh\u00e4u-\n\ufb01gkeit, Schussgenauigkeit und Kills-Anzahl beein\ufb02usst werden.\nSimulationsparameter:\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nSpieleranzahl: 16 Join-Verhalten: Linear in 00:01\nTeam-Anzahl: 2 Netzwerk-Overlay: CUSP\nVerteilung: 8 vs. 8 UP-Anzahl: 9\nSpieldauer: 20 Minuten SG-Anzahl: 9\nAsteroiden-Anzahl: 225 Seed: 42\nTabelle 7: Simulator- und Spielparameter f\u00fcr das 2. Testszenario.\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nPersonality Pro\ufb01le: PERSO_AGGROKILLER Fire Accuracy: 10%.\nEnemy Detection Range: 25000 Fire Rate: 70%.\nUP Detection Range: 50000\nTabelle 8: Bot-Parameter von Team Alpha & Bravo f\u00fcr das 2. Testszenario.\n6.4 Durchgef\u00fchrte Testszenarien 81Metrik-Ergebnisse:\nMetrik Auspr\u00e4gung Metrik Auspr\u00e4gung Metrik Auspr\u00e4gung\nShots#: 59622 Accuracy: 41.90% UP-Score: 3.6\nPShots: 186.32 Kills#: 276 Bias: 0%\nHits#: 24979 Deaths#: 296 Time: 12:22\nPHits: 78.06 KD-Ratio: 93.24% Memory VIRT: 189.5 MB\nMemory RES: 116.5 MB\nTabelle 9: Metrik-Ergebnisse von Team Alpha & Bravo f\u00fcr das 2. Testszenario.\nAbbildung 38: Upgrade Point Score Verlauf f\u00fcr das 2. Testszenario.\n82 6 Evaluation6.4.3 3. Testszenario\nIm dritten Testszenario wird im Grunde das erste Testszenario erneut ausgef\u00fchrt, nur die Fire Rate -\nEinstellung der Bots wird deutlich reduziert. Damit soll untersucht werden, ob dadurch die Schussh\u00e4u-\n\ufb01gkeit, Schussgenauigkeit und Kills-Anzahl beein\ufb02usst werden.\nSimulationsparameter:\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nSpieleranzahl: 16 Join-Verhalten: Linear in 00:01\nTeam-Anzahl: 2 Netzwerk-Overlay: CUSP\nVerteilung: 8 vs. 8 UP-Anzahl: 9\nSpieldauer: 20 Minuten SG-Anzahl: 9\nAsteroiden-Anzahl: 225 Seed: 42\nTabelle 10: Simulator- und Spielparameter f\u00fcr das 3. Testszenario.\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nPersonality Pro\ufb01le: PERSO_AGGROKILLER Fire Accuracy: 100%\nEnemy Detection Range: 25000 Fire Rate: 40%\nUP Detection Range: 50000\nTabelle 11: Bot-Parameter von Team Alpha & Bravo f\u00fcr das 3. Testszenario.\nMetrik-Ergebnisse:\nMetrik Auspr\u00e4gung Metrik Auspr\u00e4gung Metrik Auspr\u00e4gung\nShots#: 20915 Accuracy: 59.87% UP-Score: 3.29\nPShots: 65.36 Kills#: 146 Bias: 0%\nHits#: 12521 Deaths#: 158\nPHits: 39.13 KD-Ratio: 92.41%\nTabelle 12: Metrik-Ergebnisse von Team Alpha & Bravo f\u00fcr das 3. Testszenario.\n6.4 Durchgef\u00fchrte Testszenarien 83Abbildung 39: Upgrade Point Score Verlauf f\u00fcr das 3. Testszenario.\n6.4.4 4. Testszenario\nIm vierten Testszenario wird das Personality Pro\ufb01le des Bots ge\u00e4ndert. Mit der Wahl des PER-\nSO_AGGROCONQUEROR -Pro\ufb01ls wird die Eroberung von Upgrade Points jetzt der Bek\u00e4mpfung gegne-\nrische Schiffe im freien Raum vorgezogen. In den ersten drei Testszenarien war dies genau anderes\nherum der Fall. Hier sind besonders die Auswirkungen auf den UP Score , die Kills-Anzahl und den UP\nScore -Verlauf, sowie auf die Laufzeit- und Speichermessung interessant.\nSimulationsparameter:\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nSpieleranzahl: 16 Join-Verhalten: Linear in 00:01\nTeam-Anzahl: 2 Netzwerk-Overlay: CUSP\nVerteilung: 8 vs. 8 UP-Anzahl: 9\nSpieldauer: 20 Minuten SG-Anzahl: 9\nAsteroiden-Anzahl: 225 Seed: 42\nTabelle 13: Simulator- und Spielparameter f\u00fcr das 4. Testszenario.\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nPersonality Pro\ufb01le: PERSO_AGGROCONQUEROR Fire Accuracy: 100%\nEnemy Detection Range: 25000 Fire Rate: 70%\nUP Detection Range: 50000\nTabelle 14: Bot-Parameter von Team Alpha & Bravo f\u00fcr das 4. Testszenario.\n84 6 EvaluationMetrik-Ergebnisse:\nMetrik Auspr\u00e4gung Metrik Auspr\u00e4gung Metrik Auspr\u00e4gung\nShots#: 27345 Accuracy: 50.52% UP-Score: 3.87\nPShots: 85.45 Kills#: 161 Bias: 0%\nHits#: 13815 Deaths#: 168 Time: 3:15\nPHits: 43.17 KD-Ratio: 95.83% Memory VIRT: 147.5 MB\nMemory RES: 74.5 MB\nTabelle 15: Metrik-Ergebnisse von Team Alpha & Bravo f\u00fcr das 4. Testszenario.\nAbbildung 40: Upgrade Point Score Verlauf f\u00fcr das 4. Testszenario.\n6.4 Durchgef\u00fchrte Testszenarien 856.4.5 5. Testszenario\nIm f\u00fcnften Testszenario wird wieder das Personality Pro\ufb01le des Bots ge\u00e4ndert. Diesmal wird aber nicht\nwieder ein anderes Pro\ufb01l gew\u00e4hlt, sondern zwei Unterschiedliche innerhalb eines Teams verwendet. Die\ndabei verwendeten Pro\ufb01le sind die des 1. und 4. Testszenarios. Aus diesem Grund sollten die Ergebnisse\nirgendwo dazwischen liegen.\nSimulationsparameter:\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nSpieleranzahl: 16 Join-Verhalten: Linear in 00:01\nTeam-Anzahl: 2 Netzwerk-Overlay: CUSP\nVerteilung: 8 vs. 8 UP-Anzahl: 9\nSpieldauer: 20 Minuten SG-Anzahl: 9\nAsteroiden-Anzahl: 225 Seed: 41\nTabelle 16: Simulator- und Spielparameter f\u00fcr das 5. Testszenario.\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\n1. Personality Pro\ufb01le: 4 x PERSO_AGGROKILLER Fire Accuracy: 100%\n2. Personality Pro\ufb01le: 4 x PERSO_AGGROCONQUEROR Fire Rate: 70%\nEnemy Detection Range: 25000 UP Detection Range: 50000\nTabelle 17: Bot-Parameter von Team Alpha & Bravo f\u00fcr das 5. Testszenario.\nMetrik-Ergebnisse:\nMetrik Auspr\u00e4gung Metrik Auspr\u00e4gung Metrik Auspr\u00e4gung\nShots#: 44541 Accuracy: 68.84% UP-Score: 3.8\nPShots: 139.19 Kills#: 291 Bias: 0%\nHits#: 30664 Deaths#: 308\nPHits: 95.83 KD-Ratio: 94.48%\nTabelle 18: Metrik-Ergebnisse von Team Alpha & Bravo f\u00fcr das 5. Testszenario.\n86 6 EvaluationAbbildung 41: Upgrade Point Score Verlauf f\u00fcr das 5. Testszenario.\n6.4.6 6. Testszenario\nIn diesem Testszenario wird die Asteroiden-, Spieler- und UP-Anzahl erh\u00f6ht und die Teamanzahl auf eins\nreduziert. Es soll getestet werden, ob der Bot trotz der erschwerten Bedingungen dazu in der Lage ist\nalle UPs zu \ufb01nden. Die andere interessante Frage ist, wie realistisch geht der Bot dabei vor? Ist der Bot\ndazu in der Lage unbeschadet die UPs zu erobert oder kollidiert er w\u00e4hrenddessen immer wieder mit\nden vielen statischen und beweglichen Hindernissen? Die KD-Ratio sollte eine Antwort auf diese Frage\nliefern k\u00f6nnen.\nSimulationsparameter:\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nSpieleranzahl: 31 Join-Verhalten: Linear in 00:01\nTeam-Anzahl: 1 Netzwerk-Overlay: CUSP\nVerteilung: 31 vs. 0 UP-Anzahl: 18\nSpieldauer: 20 Minuten SG-Anzahl: 0\nAsteroiden-Anzahl: 270 Seed: 42\nTabelle 19: Simulator- und Spielparameter f\u00fcr das 6. Testszenario.\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nPersonality Pro\ufb01le: PERSO_AGGROCONQUEROR Fire Accuracy: 100%\nEnemy Detection Range: 25000 Fire Rate: 70%\nUP Detection Range: 50000\nTabelle 20: Bot-Parameter von Team Alpha f\u00fcr das 6. Testszenario.\n6.4 Durchgef\u00fchrte Testszenarien 87Metrik-Ergebnisse:\nMetrik Auspr\u00e4gung Metrik Auspr\u00e4gung\nShots#: 0 Kills#: 0\nHits#: 0 Deaths#: 56\nUP-Score: 13.92 Bias: 0%\nTabelle 21: Metrik-Ergebnisse von Team Alpha f\u00fcr das 6. Testszenario.\nAbbildung 42: Upgrade Point Score Verlauf f\u00fcr das 6. Testszenario.\n6.4.7 7. Testszenario\nDieses Szenario entspricht genau dem 6. Testszenario, nur mit dem Unterschied, dass hier die alte Im-\nplementierung zu Vergleichszwecken getestet wird.\nSimulationsparameter:\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nSpieleranzahl: 31 Join-Verhalten: Linear in 00:01\nTeam-Anzahl: 1 Netzwerk-Overlay: CUSP\nVerteilung: 31 vs. 0 UP-Anzahl: 18\nSpieldauer: 20 Minuten SG-Anzahl: 0\nAsteroiden-Anzahl: 270 Seed: 42\nTabelle 22: Simulator- und Spielparameter f\u00fcr das 7. Testszenario.\n88 6 EvaluationTeam Alpha:\n\u2022 Der DragonBot (Vorg\u00e4nger-Implementierung) in seiner Standard-Kon\ufb01guration.\nMetrik-Ergebnisse:\nMetrik Auspr\u00e4gung Metrik Auspr\u00e4gung\nShots#: 0 Kills#: 0\nHits#: 0 Deaths#: 144\nUP-Score: 11.62 Bias: 0%\nTabelle 23: Metrik-Ergebnisse von Team Alpha f\u00fcr das 7. Testszenario.\nAbbildung 43: Upgrade Point Score Verlauf f\u00fcr das 7. Testszenario.\n6.4.8 8. Testszenario\nIn diesem Testszenario werden die Simulationsparameter der ersten Testszenarien wiederverwendet. Al-\nlerdings wird hier nicht die neue Bot-Implementierung, sondern die alte Bot-Implementierung getestet.\nDieses Szenario soll die entsprechenden Vergleichswerte produzieren, allen voran f\u00fcr einen Vergleich der\nLaufzeit und des Speicherverbrauchs.\n6.4 Durchgef\u00fchrte Testszenarien 89Simulationsparameter:\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nSpieleranzahl: 16 Join-Verhalten: Linear in 00:01\nTeam-Anzahl: 2 Netzwerk-Overlay: CUSP\nVerteilung: 8 vs. 8 UP-Anzahl: 9\nSpieldauer: 20 Minuten SG-Anzahl: 9\nAsteroiden-Anzahl: 225 Seed: 42\nTabelle 24: Simulator- und Spielparameter f\u00fcr das 8. Testszenario.\nTeam Alpha & Bravo:\n\u2022 Der DragonBot (Vorg\u00e4nger-Implementierung) in seiner Standard-Kon\ufb01guration.\nMetrik-Ergebnisse:\nMetrik Auspr\u00e4gung Metrik Auspr\u00e4gung Metrik Auspr\u00e4gung\nShots#: 53819 Accuracy: 51.66% UP-Score: 3.73\nPShots: 168.18 Kills#: 260 Bias: 11.3%\nHits#: 27806 Deaths#: 327 Time: 8:38\nPHits: 86.89 KD-Ratio: 79.51% Memory VIRT: 180 MB\nMemory RES: 92 MB\nTabelle 25: Metrik-Ergebnisse von Team Alpha & Bravo f\u00fcr das 8. Testszenario.\nAbbildung 44: Upgrade Point Score Verlauf f\u00fcr das 8. Testszenario.\n90 6 Evaluation6.4.9 9. Testszenario\nIm letzten Szenario tritt die neue gegen die alte Implementierung zur Messung der allgemeinen Spiel-\nst\u00e4rke an. Des Weiteren soll \u00fcberp\u00fcft werden, ob die erh\u00f6hte Team-Anzahl irgendwelche Auswirkungen\nauf die Daten aus\u00fcbt.\nSimulationsparameter:\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nSpieleranzahl: 15 Join-Verhalten: Linear in 00:01\nTeam-Anzahl: 3 Netzwerk-Overlay: CUSP\nVerteilung: 5 vs. 5 vs. 5 UP-Anzahl: 9\nSpieldauer: 20 Minuten SG-Anzahl: 9\nAsteroiden-Anzahl: 225 Seed: 42\nTabelle 26: Simulator- und Spielparameter f\u00fcr das 9. Testszenario.\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nPersonality Pro\ufb01le: PERSO_AGGROKILLER. Fire Accuracy: 100%\nEnemy Detection Range: 35000 Fire Rate: 100%\nUP Detection Range: 50000\nTabelle 27: Bot-Parameter von Team Alpha f\u00fcr das 9. Testszenario.\nParameter Auspr\u00e4gung Parameter Auspr\u00e4gung\nPersonality Pro\ufb01le: PERSO_STDCONQUEROR. Fire Accuracy: 100%\nEnemy Detection Range: 35000 Fire Rate: 100%\nUP Detection Range: 50000\nTabelle 28: Bot-Parameter von Team Bravo f\u00fcr das 9. Testszenario.\nTeam Charlie:\n\u2022 Der DragonBot (Vorg\u00e4nger-Implementierung) in seiner Standard-Kon\ufb01guration.\nMetrik-Ergebnisse:\nTeam Kills Deaths KD-Ratio UP-Score Bias\nAlpha: 72 96 75% 1.63 6.12%\nBravo: 70 135 51,85% 2.90 4.45%\nCharlie: 119 60 198.33% 3.11 12.4%\nAlle: 261 291 89.69% 2.55 7.66%\nTabelle 29: Metrik-Ergebnisse von Teams f\u00fcr das 9. Testszenario.\n6.4 Durchgef\u00fchrte Testszenarien 91Abbildung 45: Upgrade Point Score Verlauf f\u00fcr das 9. Testszenario.\nAbbildung 46: Kill/Death-Ratio Verlauf der einzelnen Teams f\u00fcr das 9. Testszenario.\n6.5 Auswertung der Ergebnisse\nDie Ergebnisse der ersten zwei Testszenarien zeigen, dass der Bot-Parameter Fire Accuracy zur Justie-\nrung der Schussgenauigkeit eingesetzt werden kann. Diese ist besonders f\u00fcr die realistische Abbil-\ndung menschlichen Kampfverhaltens wichtig. Zieht man auch die anderen Testszenarien heran, kann\ndie Schussgenauigkeit in einem Bereich zwischen 40-70% eingestellt werden, je nachdem welche ande-\nren Parameter sich noch zus\u00e4tzlich auf die Schussgenauigkeit auswirken. Besonders auff\u00e4llig ist in diesem\nZusammenhang der Anstieg der Schussgenauigkeit im 5. Testszenario gegen\u00fcber dem 1. und 3. Testsze-\n92 6 Evaluationnario um ca. 10% bei gleichbleibender maximaler Fire Accuracy . Eine m\u00f6gliche Erkl\u00e4rung hierf\u00fcr ist die\nMischung der Bot-Teams mit unterschiedlichen Personality Pro\ufb01les . Die PERSO_AGGROCONQUEROR -Bots\nbevorzugen ein Ansteuern nicht eroberter UPs gegen\u00fcber der Bek\u00e4mpfung gegnerischer Schiffe im freien\nWeltall, auch wenn diese sie leicht abschie\u00dfen k\u00f6nnen, weil sie z.B. direkt hinter Ihnen \ufb02iegen. Scheinbar\nsind sie in dieser An\ufb02ugphase f\u00fcr PERSO_AGGROKILLER -Bots besonders leichte und treffsichere Beute.\nDer Vergleich zwischen 1. und 3. Testszenario zeigt, dass der Bot-Parameter Fire Rate die Schussh\u00e4u-\n\ufb01gkeit direkt beein\ufb02usst. Anders als bei der Justierung der Schussgenauigkeit \u00fcber den Fire Accuracy -\nParameter, wird hierbei allerdings die Kills-Anzahl, als Nebeneffekt ebenfalls deutlich mit beein\ufb02usst. Es\nscheint wohl eine st\u00e4rkere Abh\u00e4ngigkeit zwischen Schussh\u00e4u\ufb01gkeit und Kill-Anzahl als zwischen Schuss-\ngenauigkeit und Kill-Anzahl in der Bot-Implementierung zu geben. Ob diese Abh\u00e4ngigkeiten realistisch\nsind, kann erst ein Vergleich mit echten Referenzdaten kl\u00e4ren.\nMit der Auswahl des Personality Pro\ufb01les l\u00e4sst sich klar das Bot-Verhalten dahingehend steuern, ob be-\nvorzugt gegnerische Schiffe bek\u00e4mpft ( PERSO_AGGROKILLER ) oder eher Upgrade Points erobert werden\nsollen ( PERSO_AGGROCONQUEROR ). Ein Beleg f\u00fcr diese Aussage ist die unterschiedliche Kills-Anzahl,\nSchussh\u00e4u\ufb01gkeit und die Anzahl und Art der UP-Eroberungen. Die abweichende Schussh\u00e4u\ufb01gkeit und\ndie dadurch bedingte geringere Kills-Anzahl ergeben sich wohl aus der Tatsache, dass mehr Zeit mit der\nAnsteuerung von UPs als mit der Bek\u00e4mpfung der Gegner verbracht wird. Weiter wird mit der Pro\ufb01l-\nauswahl ma\u00dfgeblich die Geschwindigkeit der Ersteroberung der Upgrade Points und die Intensit\u00e4t der\nEroberungswechsel bestimmt. Ersteres l\u00e4sst sich anhand der durchschnittlichen H\u00f6he des UP Scores und\ndenAverage -Verl\u00e4ufen der UP Score -Gra\ufb01ken (Abbildungen 37-40) ableiten. Letzteres wird durch die UP\nScore -Verl\u00e4ufe der jeweiligen Teams deutlich. W\u00e4hrend in den Abbildungen 37-39 eher wenig Wechsel\nstatt\ufb01nden, erfolgen nach Abbildung 40 im 4. Testszenario mehrere UP-Wechsel pro Spielminute. Ein\nm\u00f6glicher Grund, warum gerade in der Anfangsphase der ersten 3 Testszenarien sehr wenige Eroberun-\ngen statt\ufb01nden, ist die Tatsache, dass die Startpunkte der beiden Teams sehr nah beieinanderliegen und\nsomit diese sich direkt in den Kampf st\u00fcrzen. W\u00fcrden die Basen der Teams weiter auseinanderliegen,\nw\u00fcrden die UP-Verl\u00e4ufe aller Wahrscheinlichkeit eine gr\u00f6\u00dfere \u00c4hnlichkeit zum 4. Testszenario aufweisen.\nDie Ergebnisse des 5. Testszenarios zeigen, dass mit der Mischung der Teams zwar nicht die Anzahl der\nKills zwischen die der Ergebnisse der ersten drei Testszenarien und dem 4. Testszenario justiert werden\nkann, daf\u00fcr allerdings die Art und Weise der UP-Eroberungen. Sowohl der Zeitpunkt der Ersterobe-\nrung der UPs, als auch die Intensit\u00e4t der Eroberungswechsel liegt genau zwischen beiden Testszenarien-\nGruppen.\nDas 6. und 7. Testszenario enthalten jeweils Bots die nur zu einem Team geh\u00f6ren. Mit diesen Sze-\nnarien soll untersucht werden, wie sich die neue Bot-Implementierung im Vergleich zur Vorg\u00e4nger-\nImplementierung bei der Bewegung im Raum und der Eroberung der Upgrade Points verh\u00e4lt. Dazu\nwurden die Map-Parameter bez\u00fcglich Asteroiden-, UP und Spieleranzahl erh\u00f6ht, um somit erschwer-\nte Bedingungen zu simulieren. Wie die Ergebnisse des 6. Testszenarios zeigen, \ufb01ndet die neue Bot-\nImplementierung 15 von 18 Upgrade Points und das ziemlich schnell. Die Vorg\u00e4nger-Implementierung\n\ufb01ndet die Upgrade Points in einer vergleichbaren Geschwindigkeit, jedoch ist bei 12 von 18 Upgrade\nPoints bereits Schluss. Die anderen Testszenarien mit 9 UPs zeigen, dass sowohl vom neuen, als auch\nvom alten Bot nur max. 8 UPs gefunden und erobert werden. Ein kleiner Anteil der UPs muss somit in\nrelativ weiten Abstand zu den anderen UPs liegen, sodass die Bots Schwierigkeiten haben diese zu \ufb01nden.\nBei der Erl\u00e4uterung der KD-Ratio -Metrik in Abschnitt 6.2 wurde aufgef\u00fchrt, dass diese zur Beurtei-\nlung der realistischen Bewegung des Bots im Raum herangezogen werden kann. Sie gibt an, ob alle\nDeaths von regul\u00e4ren Kills verursacht worden sind und eben nicht durch andere Todesarten, wie dem\nZusammensto\u00df mit Asteroiden oder befreundeten Schiffen. Die ersten 5 Testszenarien zeigen, dass der\n6.5 Auswertung der Ergebnisse 93Bot mit einer KD-Ratio von \u00fcber 90% sehr gut in der Lage ist sich im Raum zu bewegen. Allerdings\nzeigt erst der KD-Ratio -Vergleich zwischen dem 6. und 7. Testszenario mit erh\u00f6hter Hindernisdichte,\ndass die neue Bot-Implementierung fast 3-mal geschickter darin ist Hindernissen auszuweichen als die\nVorg\u00e4nger-Implementierung. Das diese Erkenntnis nicht nur auf Umgebungen ohne Gegner beschr\u00e4nkt\nist, zeigt die KD-Ratio der Vorg\u00e4nger-Implementierung von ca. 80% im 8. Testszenario.\nDas letzte Testszenario erfasst die Spielst\u00e4rke der einzelnen Bots im direkten Vergleich. W\u00e4hrend der\nKampf um die UPs relativ ausgeglichen erscheint, besonders zwischen der Vorg\u00e4nger-Implementierung\nund den PERSO_STDCONQUEROR -Bots, dominiert die Vorg\u00e4nger-Implementierung nach dem ersten\nViertel das Spiel deutlich im Hinblick auf das Kill/Death -Verh\u00e4ltnis. Anders als im Kampf um die UPs,\nist hier jedoch eher das Team mit den PERSO_AGGROKILLER -Bots dazu in der Lage mit der Vorg\u00e4nger-\nImplementierung mitzuhalten. Im ersten Viertel des Spiels ist sie sogar das klar dominierende Team,\nverliert diese Dominanz aber wieder. Ein Grund hierf\u00fcr ist sicherlich der geringe UP Score des Teams.\nW\u00e4hrend am Anfang ausgeglichene Verh\u00e4ltnisse gelten, kann sich der Bot sehr gut behaupten. Der\nVorg\u00e4nger-Implementierung gelingt es aber durch die UP-Eroberung sich nach und nach einen Boni-\nVorteil bez\u00fcglich Hitpoints undEnergy zu verschaffen. Die PERSO_STDCONQUEROR -Bots die sich eben-\nfalls diesen Vorteil erk\u00e4mpfen, k\u00f6nnen diesen jedoch nicht ausnutzen. Die ungesch\u00fctzte An\ufb02ugphase zu\ndenUpgrade Points oder eine zu geringe EnemyDetectionRange um die Upgrade Points herum, werden\nhier aller Wahrscheinlichkeit nach die Gr\u00fcnde f\u00fcr die Unterlegenheit sein. In weiteren Testl\u00e4ufen sollte\nuntersucht werden, wie sich gemischte Teams gegen die Vorg\u00e4nger-Implementierung behaupten oder\nwas f\u00fcr Auswirkungen die Justierung der EnemyDetectionRange zur Folge h\u00e4tte.\nBeim 1., 2., 4. und 8. Testszenario wurden Laufzeit- und Speichermessungen vorgenommen. Die ersten\ndrei Testszenarien wurden dabei mit der neuen Bot-Implementierung ausgef\u00fchrt und das letzte mit der\nVorg\u00e4nger-Implementierung. Generell lassen die Daten auf eine leicht erh\u00f6hte virtuelle Speichernutzung\nvon bis zu 5% und eine h\u00f6here physikalische Speicherlast von ca. 20-25% der neuen Implementierung\ngegen\u00fcber der Alten schlie\u00dfen. Die Laufzeit weicht besonders in dem 2. Testszenario, welches die \u00e4hn-\nlichsten Eckdaten im Vergleich zum 8. Testszenario aufweist, um ca. 43% nach oben hin ab. Auf der\nanderen Seite lassen die Ergebnisse des 4.Testszenarios erahnen, dass die neue Bot-Implementierung\nauch eine bessere Lau\ufb02eistung und Speicherlast als die Vorg\u00e4nger-Implementierung vorweisen kann. Im\n4. Testszenario wurde eine niedrigere Speicherlast von ca. 23% und eine um mehr als die H\u00e4lfte der Zeit\nbeschleunigte Simulationsberechnung ermittelt. Allerdings ist besonders der Vergleich zwischen dem 4.\nund 8. Testszenario mit Vorsicht zu genie\u00dfen, da die Eckdaten der Simulationen, wie Kills-Anzahl und\nSchussh\u00e4u\ufb01gkeit, hier besonders stark voneinander abweichen.\nAls letzten Punkt l\u00e4sst sich festhalten, dass nur die Simulation einen Bias von 0% aufweisen, die\nauschlie\u00dflich die neue Bot-Implementierung untersuchen. Das bedeutet, dass jede dieser Simulation\nzwei Mal exakt dieselben Ergebnisse produziert hat. Damit sind die gewonnen Ergebnisse dieser Test-\nszenarien mit dem Simulator reproduzierbar und das Repoduzierbarkeits-Kriterium aus Abschnitt 1.2\nvollst\u00e4ndig erf\u00fcllt. Die Simulationen hingegen mit Beteiligung der alten Bot-Implementierung wei\u00dfen\neine Ergebnisabweichung von ca. 10% auf, was eindeutig auf einen Nichtdeterminismus der alten Bot-\nImplementierung schlie\u00dfen l\u00e4sst. Da aber das 7. Testszenario ebenfalls einen Bias von 0% besitzt, be-\ndeutet dies, dass der Nichtdeterminusmus der Vorg\u00e4nger-Implementierung sich aus dem Kampfverhalten\ndes Bots zu ergeben scheint.\nZusammenfassend zeigen die Ergebnisse der Evaluation das die neue Bot-Implementierung dazu in\nder Lage ist das Spiel auf einem hohen Niveau zu spielen, besonders in Hinblick auf die F\u00e4higkeit zur\nVermeidung von Kollisionen und der Erkundung des Raums - beides Aspekte, wo gerade die alte Im-\nplementierung ihre Schw\u00e4chen hat. Weiter konnte gezeigt werden, dass viele wichtige Parameter der\nLasterzeugung, wie die Bevorzugungseinstellung von Kills gegen\u00fcber der Eroberung von UPs, sowie\n94 6 Evaluationdie Anpassung der Schussgenauigkeit oder der Schussh\u00e4u\ufb01gkeit von der Bot-Implementierung gezielt\nsteuerbar sind. Was eine f\u00fcr die Generierung der Netzwerklast wichtige Eigenschaft der neuen Bot-\nImplementierung darstellt. Auf der anderen Seite geht diese neue M\u00e4chtigkeit zu Lasten der Perfor-\nmance. Im Allgemeinen weist die neue Implementierung eine gegen\u00fcber der alten Bot-Implementierung\nschlechtere Performance auf, die sich allerdings in einem noch tolerierbaren Rahmen zu bewegen scheint.\nWie gro\u00df der Performance-Unterschied tats\u00e4chlich ist und welche eventuellen negativen Auswirkungen\ndieser Umstand mit sich f\u00fchren kann, m\u00fcssen weitere und genauere Test zeigen.\n6.5 Auswertung der Ergebnisse 9596 6 Evaluation7 Ausblick und Fazit\nDer in dieser Arbeit vorgestellte Ansatz zur Erzeugung einer realistischen Netzwerklast mittels kontext-\nsensitiver AI-Spieler stellt noch kein vollkommen ausgereiftes Produkt dar. Vielmehr wurde eine solide\nund funktionsf\u00e4hige erste Version fertiggestellt, die bereits viele der in der Einleitung de\ufb01nierten Ziele\nin einem zufriedenstellenden Ma\u00dfe erf\u00fcllt und somit als Grundlage f\u00fcr weitere Arbeiten genutzt werden\nkann. Welche Ziele in welchem Ausma\u00df weshalb dabei erreicht wurden, fasst der Abschnitt 7.2 \u201eFazit\u201c\nzusammen.\nAbschnitt 7.1 \u201eAusblick\u201c stellt hingegen zuvor vier wichtige Bereiche f\u00fcr weiterf\u00fchrende Entwicklun-\ngen vor und skizziert dabei ebenfalls erste m\u00f6gliche L\u00f6sungsans\u00e4tze f\u00fcr diese. Die ersten beiden w\u00fcrden\nzu einer Verbesserung der Verhaltenssteuerung bzw. des zur Verf\u00fcgung stehenden Verhaltensrepertoires\ndes Bots f\u00fchren, wohingegen die anderen beiden m\u00f6gliche Performance-Verbesserungen behandeln.\n7.1 Ausblick\nDas Konzept der Personality Traits aus Abschnitt 5.4.3 erm\u00f6glicht die Beein\ufb02ussung der Traversierung\ndes BT-Baumes. Dies ist sowohl zur Kompilierzeit, als auch zur Laufzeit m\u00f6glich. Wie in der Evalua-\ntion gezeigt, k\u00f6nnen somit leicht Teams mit unterschiedlichen Bot-Verhaltensweisen zusammengestellt\nwerden. Momentan h\u00e4ngt die Traversierungsentscheidung der Personality Selectors nur von der kon\ufb01gu-\nrierten Pers\u00f6nlichkeitseinstellung des Bots ab. Eine m\u00f6gliche Verbesserung w\u00e4re diese Auswahl durch\nzus\u00e4tzliche Spielzustandsinformationen zu erweitern. Zwar k\u00f6nnen auf diese mittels Conditions zuge-\ngriffen werden, die sich innerhalb der Unterb\u00e4ume die von den Personality Selectors ausgew\u00e4hlt werden\nbe\ufb01nden, und somit zum Scheitern des Unterbaums eingesetzt werden, doch wird die eigentliche Tra-\nversierungsreihenfolge davon nicht beein\ufb02usst. Eine Einbeziehung von Spielinformationen zur Zeit der\nTraversierungsauswahl k\u00f6nnte zu einer leichteren Modellierung komplexerer Verhaltensentscheidungen\nf\u00fchren.\nDas einzig v\u00f6llig verpasste Teilziel bei der Entwicklung der Bot-Implementierung ist die fehlende\nBer\u00fccksichtigung oder Unterst\u00fctzung von Gruppenverhalten. Gruppenverhalten stellt einen wichtigen\nAspekt eines MMOGs dar und sollte von einer Wert auf Realismus legenden Bot-Implementierung be-\nr\u00fccksichtigt werden. Au\u00dferdem liegt die Vermutung nahe, dass die Steuerung des Gruppenverhaltens\nein f\u00fcr die Lasterzeugung wichtiger Faktor darstellt, da diese die die Anzahl der Nachbarn eines peers\nmitbeein\ufb02ussen sollte. Die Anzahl der Menge der Nachbarn hat wiederum unmittelbaren Ein\ufb02uss auf\ndie Menge der auszutauschenden Nachrichten zwischen den peers und bestimmt dadurch indirekt die\nIntensit\u00e4t der Netzwerklast.\nDie Integration von Gruppenverhalten in die Bot-Implementierung sollte dabei nicht als vom Beha-\nvior Tree abgekoppeltes (Sub-)System erfolgen. Vielmehr sollte \u00e4hnlich der in Crysis 2 umgesetzten\nBT-Erweiterung [41] die Integration des Gruppenverhalten als fester Bestandteil des Behavior Trees\nerfolgen. Die Entscheidung zur Partizipation an Gruppenverhalten sollte somit das Ergebnis des Ent-\nscheidungsprozesses der BT-Traversierung sein und nicht von au\u00dfen vorgegeben oder entschieden wer-\nden. Die Integration jedes m\u00f6glichen Gruppenverhaltens als fester Bestandteil des Baums sollte dabei\nebenfalls vermieden werden. So eine Integration w\u00fcrde nicht nur die Gr\u00f6\u00dfe des BT-Baumes unn\u00f6tig ver-\ngr\u00f6\u00dfern, sondern auch negative Auswirkungen auf die Laufzeit haben, da in jedem Entscheidungszyklus\ndie Gruppenverhaltens-Knoten des BTs bei der Traversierung mitber\u00fccksichtigt werden k\u00f6nnten, auch\nwenn diese aktuell gar nicht relevant sind. Denn die Nicht-Relevanz m\u00fcsste \u00fcber Conditions -Abfragen\n97jedes Mal aufs Neue erst \u00fcberpr\u00fcft werden.\nDas Konzept der Behavior Tags aus Abschnitt 5.4.3 k\u00f6nnte hingegen zur Integration bestimmter Grup-\npenverhaltensweisen in den BT zur Laufzeit eingesetzt werden. Die Behavior Tags k\u00f6nnten zur Akti-\nvierung und Deaktivierung bestimmter Platzhalter-Knoten im Baum eingesetzt werden, um ein Event-\nbasiertes Einf\u00fcgen von aktuell zu ber\u00fccksichtigten Gruppenverhalten in die daf\u00fcr vorgesehenen Platzhal-\nter zu erm\u00f6glichen. Die Platzhalter-Knoten m\u00fcssten entsprechend noch entwickelt werden, die Mechanik\nzum Auf\ufb01nden, sowie der Aktivierung und Deaktivierung der Platzhalter im Baum m\u00fcsste bereits mit der\naktuellen Version der Behavior Tags funktionieren. Des Weiteren k\u00f6nnte zur Bestimmung der aktuell zu\nber\u00fccksichtigen Gruppenverhaltensweisen eine Erweiterung des in Abschnitt 5.4.1 pr\u00e4sentierten Black-\nbaords eingesetzt werden. Mit Hilfe des Blackboards werden die Daten innerhalb des BT ausgetauscht.\nDieses Prinzip lie\u00dfe sich relativ leicht auf den Daten-Austausch zwischen den einzelnen Bot-Instanzen\n\u00fcber die bereits vorhandenen Kommunikations-Mechanismen realisieren. Allerdings m\u00fcsste auf die Syn-\nchronisierung der Daten auf dem Blackboard geachtet werden, da durch m\u00f6gliche Nachrichtenverz\u00f6ge-\nrungen verursachte Inkonsistenzen nicht auszuschlie\u00dfen sind.\nDie Lau\ufb02eistung kann bereits mit dem Process -Parameter der drei Ebenen etwas reguliert werden, da\ndieser bestimmt in welchem Zyklus die einzelnen Ebenen ausgef\u00fchrt werden. Die Evaluation zeigte aller-\ndings, dass unabh\u00e4ngig davon die allgemeine Performance hinter der Vorg\u00e4nger-Implementierung liegt,\nwas jedoch aufgrund der h\u00f6heren Komplexit\u00e4t und der viel gr\u00f6\u00dferen Menge an beteiligten Klassen und\nObjekten nicht weiter verwundert. Nichtsdestotrotz l\u00e4sst sich die Performance wahrscheinlich durch das\nCachen der IWorldSate -Informationen deutlich verbessern. Weil es keinen linearen Daten\ufb02uss innerhalb\ndes Bots gibt, k\u00f6nnen bereits abgerufene oder aufbearbeitete Informationen nicht einfach direkt wei-\ntergereicht werden. Die IWorldState -Schnittstelle jedoch bietet einen zentralen Zugriffspunkt auf viele\nwichtige Informationen an, der von \u00fcberall aus im Bot genutzt wird. W\u00fcrden die Informationen dieser\nSchnittstelle oder oft ben\u00f6tigte Ergebnisse zwischengespeichert werden, k\u00f6nnte die Ausf\u00fchrung einiger\naufwendiger Abfragen vermieden werden. Ein Beispiel hierf\u00fcr w\u00e4re der Zugriff auf die Liste naher As-\nteroiden, die sowohl von der Hinderniserkennung, als auch vom Combat System separat abgerufen und\nauf sehr \u00e4hnliche Art und Weise durchsucht wird.\nWie die Evaluation zeigte liegt nicht nur die Lau\ufb02eistung hinter der Vorg\u00e4nger-Implementierung\nzur\u00fcck, sondern auch die Speicherauslastung ist im Schnitt etwas h\u00f6her. Die wahrscheinlich gr\u00f6\u00dfte\nSpeicherbelastung wird durch die Verwaltung des Behavior Trees verursacht. Dieser wird zur Initiali-\nsierungszeit einmal vollst\u00e4ndig erstellt und nahezu unver\u00e4ndert bis zum Ende der Partie im Speicher\ngehalten. Eine Verbesserungsm\u00f6glichkeit w\u00e4re die Entwicklung eines feingranularen Erstellungsprozes-\nses, welcher sowohl die gezielte Erstellung einzelner Unterb\u00e4ume erm\u00f6glicht, als auch die Verschiebung\ndieser Erstellung zu einem beliebigen Zeitpunkt der Laufzeit. Eine Art BT-Library k\u00f6nnte den Erstel-\nlungsprozess und den Zugriff auf bereits erstellte Knoten verwalten, sodass die eigentliche Baumstruktur\nlediglich aus Platzhalterknoten besteht, die erst zur Traversierungszeit die erforderlichen Knoten aus\nderBT-Library anfordern. Die Platzhalterknoten k\u00f6nnten leicht als neue Decorator -Knotenart integriert\nwerden und demzufolge den bereits existierenden Erstellungsprozess des BT nutzen.\n7.2 Fazit\nMit dieser Arbeit wurde erfolgreich ein Grundstein f\u00fcr die synthetische Generierung einer realistischen\nNetzwerklast zu Evaluationszwecken verschiedenartiger P2P-Overlays mit dem Einsatz kontext-sensitiver\nAI-Spieler in Planet PI4 geschaffen. Unabh\u00e4ngig der in Abschnitt 7.1 ausgemachten Problembereiche und\nden diesbez\u00fcglichen Verbesserungsvorschl\u00e4gen, konnte anhand der Evaluationsergebnisse aus Kapitel 6\neindeutig eine generelle Eignung der aktuellen Version zur Generierung und vor allem zur Steuerung der\nNetzwerklast nachgewiesen werden. Weiterhin konnte die Evaluation zeigen, dass alle vier in Abschnitt\n98 7 Ausblick und Fazit1.2 de\ufb01nierten Ziele w\u00e4hrend der Entwicklung beachtet wurden und von der aktuellen Version des Bots\nin einer zufriedenstellenden Weise erf\u00fcllt werden. Diese Beurteilung erm\u00f6glichte insbesondere der direk-\nte Vergleich mit der Vorg\u00e4nger-Implementierung, die im Hinblick auf die Kriterien Reproduzierbarkeit,\nRealit\u00e4tsgrad und der Kon\ufb01gurierbarkeit der Netzwerklast der neuen Implementierung unterliegt. Ein-\nzig in Sachen Skalierbarkeit konnte sich die aktuelle Bot-Implementierung nicht gegen\u00fcber der alten\nImplementierung durchsetzen, der dabei gemessene Performance Unterschied scheint allerdings nicht\nbesorgniserregend gro\u00df zu sein, ist aber auf der anderen Seite auch nicht als vernachl\u00e4ssigbar klein zu\nerachten.\nEines der Gr\u00fcnde f\u00fcr die im Vergleich zur Vorg\u00e4nger-Implementierung schlechtere Performance ist das\nkomplexere und aufwendigere Design des neuen Bots. Wie in Kapitel 4 aufgef\u00fchrt sind in der neuen\nImplementierung zahlreiche Klassen auf verschiedenen Ebenen im Einsatz. Besonders die Aufteilung in\nverschiedene Ebenen und der dadurch bedingte erh\u00f6hte Bedarf an Schnittstellen zur sauberen Entkop-\npelung, sowie der Verzicht auf einen einfachen linearen Informations\ufb02uss im Bot gehen eindeutig zu\nLasten der Performance. Der L\u00f6sungsansatz der alten Vorg\u00e4nger-Implementierung beruht, wie in [59]\nund teilweise in Abschnitt 3.5 beschrieben, stattdessen eher auf einer simpleren Systemstrukturierung.\nDas komplexere Systemdesign hat allerdings einen nicht zu untersch\u00e4tzenden Vorteil gegen\u00fcber der al-\nten Implementierung, es erlaubt eine saubere Trennung der Verantwortlichkeiten im Bot. Dar\u00fcber hinaus\nstellt die vorgenommene Ebenen Auf- und Einteilung eine Erweiterung des Konzeptes von Reynolds dar\n(siehe Abschnitt 2.4), welches wiederum ein sehr etabliertes und weit verbreitetes Konzept darstellt.\nEin Beispiel soll diesen Vorteil verdeutlichen: In der Evaluation wurde ermittelt, dass die Bot-\nImplementierung zu \u00fcber 90% dazu in der Lage ist Hindernissen auszuweichen. Das Ziel einer m\u00f6glichen\nWeiterentwicklung k\u00f6nnte beispielsweise die Ausbesserung der fehlenden 10% sein. Wenn weitere Unter-\nsuchungen dazu noch ergeben w\u00fcrden, dass die fehlenden 10% nur aufgrund der vereinzelten Kollision\nmit Asteroiden und nicht mit befreundeten Schiffen verursacht werden. So w\u00e4re der Ort der Ausbesse-\nrung bei einer Weiterentwicklung des Bots schnell indenti\ufb01ziert, da das Design den Ort der statischen\nHinderniserkennung mit der ObstacleAvoidance -Klasse der Steering Pipeline der operativen Ebene an ei-\nner genau de\ufb01nierten Stelle vorsieht. Die ObstacleAvoidance -Klasse k\u00f6nnte jetzt in dem Beispiel entweder\ndahingehend verbessert werden oder sogar komplett ausgetauscht werden, ohne dass damit das ganze\nSystem bzw. die anderen Ebenen betroffen w\u00e4ren. Das Beispiel zeigt demnach, dass die saubere Trennung\nbesonders im Hinblick auf zuk\u00fcnftige Weiterentwicklungen einen wichtigen Vorteil bietet.\n7.2 Fazit 99100 7 Ausblick und FazitAbbildungsverzeichnis\n1 Der schematische Aufbau eines simplen rationalen Agenten. Angelehnt an [46] und [36]. 13\n2 Der Nutzenbasierte Agent und seine wichtigsten Komponenten als Erweiterung des simplen\nAgenten aus Abbildung 1. Angelehnt an [46] und [36]. . . . . . . . . . . . . . . . . . . . . . . 14\n3 Das Modell nach Reynolds zur hierarchischen Unterteilung der Verantwortlichkeiten zur\nBewegungssteuerung eines autonomen Agenten. Entnommen aus [44]. . . . . . . . . . . . . 15\n4 (a) Nachbildung des Bewegungspro\ufb01ls der Quake 2 -Partie aus (b) mit dem RWP-Modell.\n(b) Bewegungspro\ufb01l einer echten Quake 2 -Partie. Beide Gra\ufb01ken entnommen aus [53]. . . 19\n5 Nachbildung des Bewegungspro\ufb01ls der Quake 2 -Partie aus 4 (b) mit dem NGMM-Modell.\nGra\ufb01k entnommen aus [53]. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\n6 Die Game AI-Architektur von Halo. Entnommen aus [9]. . . . . . . . . . . . . . . . . . . . . . 22\n7 Ein Beispiel f\u00fcr den von GOAP realisierten Entscheidungsprozess zur Auswahl der n\u00e4chs-\nten Aktion. Beachtet werden sollte das die Planungsrichtung (Roter Pfeil) entgegengesetzt\nzur Ausf\u00fchrungsrichtung ist. Angelehnt an Beispiel und eine Gra\ufb01k aus [37]. . . . . . . . . 26\n8 Ein instabiles Equilibrium. Angelehnt an eine Gra\ufb01k aus [35, S. 100]. . . . . . . . . . . . . . 27\n9 Ein stabiles Equilibrium. Entnommen aus [35, S. 101]. . . . . . . . . . . . . . . . . . . . . . . 27\n10 Die Evaluierung der m\u00f6glichen Ausweichbewegungen zur Verhinderung der Kollision mit\nHindernissen. Angelehnt an zwei Gra\ufb01ken aus [3]. . . . . . . . . . . . . . . . . . . . . . . . . 29\n11 Die gra\ufb01sche Benutzerober\ufb02\u00e4che von Planet PI4 . Angelehnt an eine Gra\ufb01k aus [30]. . . . . 34\n12 Das Game AI -Konzept als Erweiterung des Agentenmodells nach Reynolds und der Inte-\ngration dessen in das Konzept eines rationalen (nutzenbasierten) Agenten. . . . . . . . . . 37\n13 Beispiel f\u00fcr einen Behavior Tree f\u00fcrs Eintreten in einen Raum. Entnommen aus [35, S. 339]. 39\n14 Klassendiagramm zur Einbindung einer Game AI inPlanet PI4 . . . . . . . . . . . . . . . . . . 42\n15 Die Game AI-Architektur mit dem Zusammenspiel der wichtigsten Komponenten und Sub-\nsysteme. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n16 Die feste Ausf\u00fchrungsreihenfolge der Komponenten der Game AI und der von Planet PI4\ninnerhalb eines Spielzyklus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n17 Die IOptController -Schnittstelle die den Leistungskatalog der operativen Ebene de\ufb01niert. . 47\n18 Die Struktur der operativen Ebene und die Abh\u00e4ngigkeiten zu anderen Systemebenen. . . 48\n19 (a) Die generelle Struktur der Steering Pipeline . Angelehnt an [35, S. 108]. (b) Der Aufbau\nund die Elemente der SteeringForce -Datenstruktur, die von der hier vorgestellten Steering\nPipeline -Implementierung verwendet wird. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\n20 Vererbungshierarchie der Targeter -Menge der Steering Pipeline . . . . . . . . . . . . . . . . . . 50\n21 Vererbungshierarchie der Constraint -Menge der Steering Pipeline . . . . . . . . . . . . . . . . . 52\n22 Vererbungshierarchie der ShipActuator -Klasse der Steering Pipeline . . . . . . . . . . . . . . . 53\n23 Die CombatSystem -Klasse und die ICombatShip -Schnittstelle, welche die vom Combat Sys-\ntemben\u00f6tigten Informationen und Steuerungsbefehle zur Aktionsrealisierung de\ufb01niert.\nDie Parameter der ICombatShip -Schnittstelle wurden zur besseren \u00dcbersicht weggelassen. 54\n24 Die Struktur der taktischen Ebene und die Abh\u00e4ngigkeiten zu anderen Systemebenen. . . 56\n25 Klassendiagramm der wichtigsten \u00fcbergeordneten Komponenten der BT-Implementierung. 60\n26 Vererbungshierarchie und Typspezi\ufb01kation der Conditions der BT-Implementierung. . . . . 62\n27 Beispielhafter Einsatz von Behavior Tags . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64\n28 Die Elemente der Personality -Erweiterung. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65\n29 Beispielhafter Einsatz der Personality-Erweiterung. . . . . . . . . . . . . . . . . . . . . . . . . 66\n10130 Oberste Ebene des konkreten Behavior Trees derGame AI . . . . . . . . . . . . . . . . . . . . . 67\n31 Der modellierte Auswahlprozess des CombatTactic -Unterbaums. Es wird entweder keine\nAktion, die CaptureUP -Aktion oder der FightTactic -Unterbaum zur n\u00e4heren Auswahl des\nkonkreten Kampfverhaltens ausgew\u00e4hlt. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n32 Der modellierte Auswahlprozess des FightTactic -Unterbaums zur Wahl der gew\u00fcnschten\nKampftaktik von gegnerischen Schiffen im freien Raum. Zur Wahl stehen drei unterschied-\nliche Taktiken. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69\n33 Die Struktur der strategischen Ebene und die Abh\u00e4ngigkeiten zu anderen Systemebenen. . 70\n34 Aufbau des 3D-Quadrats einer Region mit einer Initialisierungsgr\u00f6\u00dfe von 40000. . . . . . . 73\n35 Aufteilung des 3D-Quadrats einer Region in seine 8 Unterregionen. . . . . . . . . . . . . . . 73\n36 \u00dcbersicht des allgemeinen Testaufbaus. Angelehnt an [31]. . . . . . . . . . . . . . . . . . . . 78\n37 Upgrade Point Score Verlauf f\u00fcr das 1. Testszenario. . . . . . . . . . . . . . . . . . . . . . . . 81\n38 Upgrade Point Score Verlauf f\u00fcr das 2. Testszenario. . . . . . . . . . . . . . . . . . . . . . . . . 82\n39 Upgrade Point Score Verlauf f\u00fcr das 3. Testszenario. . . . . . . . . . . . . . . . . . . . . . . . 84\n40 Upgrade Point Score Verlauf f\u00fcr das 4. Testszenario. . . . . . . . . . . . . . . . . . . . . . . . 85\n41 Upgrade Point Score Verlauf f\u00fcr das 5. Testszenario. . . . . . . . . . . . . . . . . . . . . . . . 87\n42 Upgrade Point Score Verlauf f\u00fcr das 6. Testszenario. . . . . . . . . . . . . . . . . . . . . . . . 88\n43 Upgrade Point Score Verlauf f\u00fcr das 7. Testszenario. . . . . . . . . . . . . . . . . . . . . . . . 89\n44 Upgrade Point Score Verlauf f\u00fcr das 8. Testszenario. . . . . . . . . . . . . . . . . . . . . . . . 90\n45 Upgrade Point Score Verlauf f\u00fcr das 9. Testszenario. . . . . . . . . . . . . . . . . . . . . . . . 92\n46 Kill/Death-Ratio Verlauf der einzelnen Teams f\u00fcr das 9. Testszenario. . . . . . . . . . . . . . 92\n102 AbbildungsverzeichnisTabellenverzeichnis\n1 Der Einsatz von Decision Making -Verfahren in modernen Computerspielen. . . . . . . . . . . 17\n2 Kostenbewertung der Steering -Vorschl\u00e4ge sowie ihre Kostensumme. . . . . . . . . . . . . . . 29\n3 Au\ufb02istung der in der Evaluation verwendeten Metriken mit Wertebereichsangabe und der\nZuordnung zu relevanten Kriterien. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n4 Simulator- und Spielparameter f\u00fcr das 1. Testszenario. . . . . . . . . . . . . . . . . . . . . . . 80\n5 Bot-Parameter von Team Alpha & Bravo f\u00fcr das 1. Testszenario. . . . . . . . . . . . . . . . . 80\n6 Metrik-Ergebnisse von Team Alpha & Bravo f\u00fcr das 1. Testszenario. . . . . . . . . . . . . . . 80\n7 Simulator- und Spielparameter f\u00fcr das 2. Testszenario. . . . . . . . . . . . . . . . . . . . . . . 81\n8 Bot-Parameter von Team Alpha & Bravo f\u00fcr das 2. Testszenario. . . . . . . . . . . . . . . . . 81\n9 Metrik-Ergebnisse von Team Alpha & Bravo f\u00fcr das 2. Testszenario. . . . . . . . . . . . . . . 82\n10 Simulator- und Spielparameter f\u00fcr das 3. Testszenario. . . . . . . . . . . . . . . . . . . . . . . 83\n11 Bot-Parameter von Team Alpha & Bravo f\u00fcr das 3. Testszenario. . . . . . . . . . . . . . . . . 83\n12 Metrik-Ergebnisse von Team Alpha & Bravo f\u00fcr das 3. Testszenario. . . . . . . . . . . . . . . 83\n13 Simulator- und Spielparameter f\u00fcr das 4. Testszenario. . . . . . . . . . . . . . . . . . . . . . . 84\n14 Bot-Parameter von Team Alpha & Bravo f\u00fcr das 4. Testszenario. . . . . . . . . . . . . . . . . 84\n15 Metrik-Ergebnisse von Team Alpha & Bravo f\u00fcr das 4. Testszenario. . . . . . . . . . . . . . . 85\n16 Simulator- und Spielparameter f\u00fcr das 5. Testszenario. . . . . . . . . . . . . . . . . . . . . . . 86\n17 Bot-Parameter von Team Alpha & Bravo f\u00fcr das 5. Testszenario. . . . . . . . . . . . . . . . . 86\n18 Metrik-Ergebnisse von Team Alpha & Bravo f\u00fcr das 5. Testszenario. . . . . . . . . . . . . . . 86\n19 Simulator- und Spielparameter f\u00fcr das 6. Testszenario. . . . . . . . . . . . . . . . . . . . . . . 87\n20 Bot-Parameter von Team Alpha f\u00fcr das 6. Testszenario. . . . . . . . . . . . . . . . . . . . . . . 87\n21 Metrik-Ergebnisse von Team Alpha f\u00fcr das 6. Testszenario. . . . . . . . . . . . . . . . . . . . . 88\n22 Simulator- und Spielparameter f\u00fcr das 7. Testszenario. . . . . . . . . . . . . . . . . . . . . . . 88\n23 Metrik-Ergebnisse von Team Alpha f\u00fcr das 7. Testszenario. . . . . . . . . . . . . . . . . . . . . 89\n24 Simulator- und Spielparameter f\u00fcr das 8. Testszenario. . . . . . . . . . . . . . . . . . . . . . . 90\n25 Metrik-Ergebnisse von Team Alpha & Bravo f\u00fcr das 8. Testszenario. . . . . . . . . . . . . . . 90\n26 Simulator- und Spielparameter f\u00fcr das 9. Testszenario. . . . . . . . . . . . . . . . . . . . . . . 91\n27 Bot-Parameter von Team Alpha f\u00fcr das 9. Testszenario. . . . . . . . . . . . . . . . . . . . . . . 91\n28 Bot-Parameter von Team Bravo f\u00fcr das 9. Testszenario. . . . . . . . . . . . . . . . . . . . . . . 91\n29 Metrik-Ergebnisse von Teams f\u00fcr das 9. Testszenario. . . . . . . . . . . . . . . . . . . . . . . . 91\n103104 TabellenverzeichnisLiteraturverzeichnis\n[1] Features. URL http://irrlicht.sourceforge.net/features/ . letzter Zugriff am 29.09.2012.\n[2] Nathaniel E. Baughman, Marc Liberatore, and Brian Neil Levine. Cheat-proof playout for centrali-\nzed and peer-to-peer gaming. IEEE/ACM Transactions on Networking , 22:1\u201317, 2007.\n[3] Heni Ben Amor, Jan Murray, and Oliver Obst. Fast, neat and under control: Inverse steering beha-\nviors for physical autonomous agents, 2003.\n[4] Heni Ben Amor, Jan Murray, and Oliver Obst. AI Game Programming Wisdom 3 , chapter Fast, Neat\nand Under Control: Inverse Steering Behaviors for Physical Autonomous Agents, pages 221\u2013232.\nCharles River Media, 2006.\n[5] Ashwin Bharambe. Colyseus: A distributed architecture for online multiplayer games. In In Proc.\nSymposium on Networked Systems Design and Implementation (NSDI , pages 3\u201306, 2006.\n[6] Ashwin Bharambe, John R. Douceur, Jacob R. Lorch, Thomas Moscibroda, Jeffrey Pang, Srinivasan\nSeshan, and Xinyu Zhuang. Donnybrook: Enabling large-scale, high-speed, peer-to-peer games,\n2008.\n[7] Michael S. Borella. Source models of network game traf\ufb01c. Computer Communications , 23:403\u2013\n410, 2000.\n[8] Brookhaven National Lab. The First Video Game? before \u2019pong,\u2019 there was \u2019tennis for two\u2019. Website.\nhttp://www.bnl.gov/bnlweb/history/higinbotham.asp , letzter Zugriff am 29.09.2012.\n[9] Chris Butcher and Jaime Griesemer. The illusion of intelligence: The integration of ai and level\ndesign in halo, 2002.\n[10] Alex J. Champandard. Behavior trees for next-gen game ai. Website, Dec 2008. http:\n//aigamedev.com/insider/article/behavior-trees/ , letzter Zugriff am 29.09.2012.\n[11] D.S. Cohen. Oxo aka Noughts and Crosses - the \ufb01rst video game. Website. http://classicgames.\nabout.com/od/computergames/p/OXOProfile.htm , letzter Zugriff am 29.09.2012.\n[12] Johnny Cullen. Modern warfare 3 hits $1 billion in 16 days \u2013 info. Website, Dec 2011. http://\nwww.vg247.com/2011/12/12/mw3-hits-1-billion-in-16-days/ , letzter Zugriff am 29.09.2012.\n[13] Entertainment Software Association. Essential Facts about the Computer and Video Game Indus-\ntry. Technical report, Entertainment Software Association, 2011. http://www.theesa.com/facts/\npdfs/ESA_EF_2011.pdf , letzter Zugriff am 29.09.2012.\n[14] Lu Fan, Phil Trinder, and Hamish Taylor. Design issues for peer-to-peer massively multiplayer online\ngames, 2009.\n[15] J.D. Funge. Arti\ufb01cial Intelligence for Computer Games: An Introduction . Ak Peters Series. Peters,\n2004.\n[16] Erich Gamma. Entwurfsmuster . Addison-Wesley Verlag, 1st edition, 2004.\n[17] Christian Gro\u00df, Max Lehn, Christoph M\u00fcnker, Alejandro Buchmann, and Ralf Steinmetz. Towards\na comparative performance evaluation of overlays for networked virtual environments. In IEEE,\neditor, Proceedings of the 11th IEEE International Conference on Peer-to-Peer Computing , pages 34\u201343.\nIEEE, Sep 2011.\n105[18] Thorsten Hagenloch. Einf\u00fchrung in die Betriebswirtschaftslehre: Theoretische Grundlagen und Ma-\nnagementlehre . Books on Demand GmbH, Norderstedt, Germany, 2009.\n[19] S.-Y. Hu and G.-M. Liao. Von: A scalable peer-to-peer network for virtual environments. IEEE\nNetwork , 20 No. 4:22\u201331, 2006.\n[20] Damian Isla. Handling Complexity in the Halo 2 AI. In Game Developers Conference , March 2005.\nURL http://www.gamasutra.com/gdc2005/features/20050311/isla_01.shtml . letzter Zugriff\nam 29.09.2012.\n[21] Damian Isla and Bruce Blumberg. Blackboard architectures. AI Game Programming Wisdom , pages\n333\u2013344, 2002.\n[22] Damian Isla, Robert Burke, Marc Downie, and Bruce Blumberg. A layered brain architecture for\nsynthetic creatures. In Proceedings of the 17th international joint conference on Arti\ufb01cial intelligence -\nVolume 2 , IJCAI\u201901, pages 1051\u20131058, San Francisco, CA, USA, 2001. Morgan Kaufmann Publishers\nInc.\n[23] David B. Johnson and David A. Maltz. Dynamic source routing in ad hoc wireless networks. In\nMobile Computing , pages 153\u2013181. Kluwer Academic Publishers, 1996.\n[24] Geraint Johnson. AI Game Programming Wisdom 3 , chapter Goal Trees, pages 301\u2013310. Charles\nRiver Media, 2006.\n[25] Denis Lapiner. Gameplay design and implementation for a massively multiplayer online game.\nBachelor thesis, Technische Universit\u00e4t Darmstadt, Germany, Mar 2011.\n[26] Nachi Lau. AI Game Programming Wisdom 4 , chapter Knowledge-Based Behavior System: A Deci-\nsion Tree/Finite State Machine Hybrid, pages 265\u2013274. Charles River Media, 2008.\n[27] Max Lehn. Implementation of a peer-to-peer multiplayer game with realtime requirements. Mas-\nter\u2019s thesis, Technische Universit\u00e4t Darmstadt, Germany, Oct 2009.\n[28] Max Lehn, Christof Leng, Robert Rehner, Tonio Triebel, and Alejandro Buchmann. An online gaming\ntestbed for peer-to-peer architectures. In Proceedings of ACM SIGCOMM \u00b411. ACM, August 2011.\nDemo.\n[29] Max Lehn, Tonio Triebel, and Wolfgang Effelsberg. Benchmarking p2p gaming overlays. 2011.\n[30] Max Lehn, Benjamin Guthier, Robert Rehner, Tonio Triebel, Stephan Kopf, and Wolfgang Effelsberg.\nGeneration of synthetic workloads for peer-to-peer gaming benchmarks. 2012.\n[31] Christof Leng, Max Lehn, Robert Rehner, and Alejandro Buchmann. Designing a testbed for large-\nscale distributed systems. In Proceedings of ACM SIGCOMM \u00b411. ACM, August 2011. Poster.\n[32] Robert C. Martin. The interface segregation principle. The C++ Report , 8, August 1996. URL\nhttp://www.objectmentor.com/resources/articles/isp.pdf .\n[33] Robert C. Martin. The dependency inversion principle. The C++ Report , May 1996. URL http:\n//www.objectmentor.com/resources/articles/dip.pdf .\n[34] Michael Mateas. Expressive ai: Games and arti\ufb01cial intelligence. In Proceedings of International\nDiGRA Conference , 2003.\n[35] Ian Millington and John Funge. Arti\ufb01cial Intelligence for Games, Second Edition . Morgan Kaufmann\nPublishers Inc., 2nd edition, 2009.\n106 Literaturverzeichnis[36] Alexander Nareyek. Review: Intelligent agents for computer games. In T . Anthony Marsland and\nIan Frank, editors, Computers and Games, Second International Conference, CG 2000, Hamamatsu,\nJapan, October 26-28, 2000, Revised Papers , volume 2063 of Lecture Notes in Computer Science ,\npages 414\u2013422. Springer, 2000.\n[37] Jeff Orkin. Applying Goal-Oriented Action Planning to Games. AI Game Programming Wisdom , 2:\n217\u2013228, 2003.\n[38] Jeff Orkin. Agent architecture considerations for real-time planning. In in Games.\u201d Arti\ufb01cial Intelli-\ngence & Interactive Digital Entertainment (AIIDE . AAAI Press, 2005.\n[39] Jeff Orkin. Three States and a Plan: The A.I. of F .E.A.R. In Game Developers Conference , 2006.\n[40] Jeff Orkin. Getting started with decision making and control systems. AI Game Programming\nWisdom , 4:257\u2014-264, 2008.\n[41] Ricardo Pillosu. Coordinating agents with behaviour trees, 2009. Presentation.\n[42] DFG Forschergruppe QuaP2P . Website. http://www.quap2p.tu-darmstadt.de/ , Zugriff am\n22.12.2011.\n[43] Jon Radoff. Anatomy of an Mmorpg. Website, Aug 2008. http://radoff.com/blog/2008/08/22/\nanatomy-of-an-mmorpg/ , letzter Zugriff am 29.09.2012.\n[44] Craig Reynolds. Steering behaviors for autonomous characters, 1999.\n[45] Craig W . Reynolds. Flocks, herds, and schools: A distributed behavioral model. In Computer Gra-\nphics , pages 25\u201334, 1987.\n[46] S. J. Russell and P . Norvig. K\u00fcnstliche Intelligenz: Ein moderner Ansatz . Pearson Studium, 2nd\nedition, 2004.\n[47] Eric Salen, Katie und Zimmerman. Rules of play: Game design fundamentals . MIT Press, 2003.\n[48] Mark Schmidt. Die erfolgreichsten Kino-Filme aller Zeiten. Website, Sep 2008. http://\nmark-schmidt.suite101.de/kino-die-erfolgreichsten-filme-aller-zeiten-a48386 , letz-\nter Zugriff am 29.09.2012.\n[49] Arne Schmieg, Michael Stieler, Sebastian Jeckel, Patric Kabus, Bettina Kemme, and Alejandro Buch-\nmann. psense - maintaining a dynamic localized peer-to-peer structure for position based multicast\nin games. In Proceedings of the 2008 Eighth International Conference on Peer-to-Peer Computing , P2P\n\u201908, pages 247\u2013256, Washington, DC, USA, 2008. IEEE Computer Society.\n[50] Alexander Shoulson, Francisco M. Garcia, Matthew Jones, Robert Mead, and Norman I. Badler.\nParameterizing behavior trees. In Proceedings of the 4th international conference on Motion in Games ,\nMIG\u201911, pages 144\u2013155, Berlin, Heidelberg, 2011. Springer-Verlag.\n[51] Pieter Spronck. Adaptive Game AI . Datawyse/Universitaire Pers Masstricht, 2005.\n[52] Bjorn Stabell and Ken Ronny Schouten. The story of xpilot. Crossroads , 3(2):3\u20136, November 1996.\nURL http://doi.acm.org/10.1145/332132.332134 .http://www.xpilot.org , letzter Zugriff am\n29.09.2012.\n[53] Swee Ann Tan, William Lau, and Allan Loh. Networked game mobility model for \ufb01rst-person-\nshooter games. In Proceedings of 4th ACM SIGCOMM workshop on Network and system support for\ngames , NetGames \u201905, pages 1\u20139, New York, NY, USA, 2005. ACM.\nLiteraturverzeichnis 107[54] M. Tanenbaum, A. und van Steen. Verteilte Systeme: Prinzipien und Paradigmen . Pearson Studium,\n2nd edition, 2008.\n[55] Wesley W . Terpstra, Jussi Kangasharju, Christof Leng, and Alejandro P . Buchmann. Bubblestorm:\nresilient, probabilistic, and exhaustive peer-to-peer search. In Proceedings of the 2007 conference on\nApplications, technologies, architectures, and protocols for computer communications , SIGCOMM \u201907,\npages 49\u201360, New York, NY, USA, 2007. ACM.\n[56] Jim Waldo. Scaling in games and virtual worlds. Commun. ACM , 51(8):38\u201344, August 2008.\n[57] David Winter. Pong-Story: The site of the \ufb01rst video game. Website. http://www.pong-story.\ncom/intro.htm , letzter Zugriff am 29.09.2012.\n[58] Mark J. P. Wolf. The Video Game Explosion: A History from Pong to Playstation and Beyond . Green-\nwood Press, 2008.\n[59] Dimitri Wulffert. Arti\ufb01cial intelligence for a massively multiplayer online game. Bachelor thesis,\nTechnische Universit\u00e4t Darmstadt, Germany, Mar 2011.\n[60] A. P . Yu and S. T . Vuong. Mopar: a mobile peer-to-peer overlay architecture for interest management\nof massively multiplayer online games. In Proceedings of the international workshop on Network and\noperating systems support for digital audio and video , NOSSDAV \u201905, pages 99\u2014-104, New York, NY,\nUSA, 2005. ACM.\n108 Literaturverzeichnis", "language": "PDF", "image": "PDF", "pagetype": "PDF", "links": "PDF"}