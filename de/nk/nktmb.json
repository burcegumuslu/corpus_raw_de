{"title": "PDF", "author": "PDF", "url": "https://beckassets.blob.core.windows.net/product/readingsample/865401/9783642150098_excerpt_001.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "id": "PDF", "license": "PDF", "body": "PDF", "comments": "PDF", "commentsbody": "PDF", "raw_text": "PDF", "text": "Springer-\nLehrbuch\nWahrscheinlichkeitsrechnung\nund\nschlie\u00dfende\nStatistik\nBearbeitet\nvon\nKarl\nMosler,\nFriedrich\nSchmid\n4.,\nverb.\nAufl.\n2010.\nTaschenbuch.\nXII,\n347\nS.\nPaperback\nISBN\n978\n3\n642\n15009\n8\nFormat\n(B\nx\nL):\n0\nx\n0\ncm\nGewicht:\n551\ng\nWeitere\nFachgebiete\n>\nMathematik\n>\nStochastik\n>\nWahrscheinlichkeitsrechnung\nZu\nInhaltsverzeichnis\nschnell\nund\nportofrei\nerh\u00e4ltlich\nbei\nDie\nOnline-\nFachbuchhandlung\nbeck-\nshop.de\nist\nspezialisiert\nauf\nFachb\u00fccher,\ninsbesondere\nRecht,\nSteuern\nund\nWirtschaft.\nIm\nSortiment\nfinden\nSie\nalle\nMedien\n(B\u00fccher,\nZeitschriften,\nCDs,\neBooks,\netc.)\naller\nVerlage.\nErg\u00e4nzt\nwird\ndas\nProgramm\ndurch\nServices\nwie\nNeuerscheinungsdienst\noder\nZusammenstellungen\nvon\nB\u00fcchern\nzu\nSonderpreisen.\nDer\nShop\nf\u00fchrt\nmehr\nals\n8\nMillionen\nProdukte.\nKapitel 2\nZufallsvariable und\nVerteilungen\nBei manchen Zufallsvorg \u00a8angen interessiert man sich weniger f \u00a8ur das konkrete\nErgebnis \u03c9\u2208\u2126 als f \u00a8ur eine reelle Zahl, die von \u03c9abh\u00a8angt. So wird sich ein\nRoulettespieler, der auf Colonne setzt, nicht so sehr f \u00a8ur die ausgespielte Zahl\n\u03c9interessieren, sondern eher f \u00a8ur den von \u03c9abh\u00a8angenden Nettogewinn aus\ndem Spiel. Ein Aktienbesitzer wird sich weniger f \u00a8ur das sehr komplexe Ergeb-\nnis\u03c9des Zufallsvorganges\u201dEntwicklung an der B \u00a8orse\u201c interessieren als f \u00a8ur\nden Kurs seiner Aktie an einem Stichtag. Bei der Untersuchun g von Haus-\nhalten interessiert sich ein Marktforscher meist nicht f \u00a8ur alle Spezi\ufb01ka eines\nbeobachteten Haushalts, sondern nur f \u00a8ur bestimmte Merkmale, wie z.B. das\nverf\u00a8ugbare monatliche Haushalteinkommen oder die monatlichen Ausgaben\nf\u00a8ur Kleidung.\nIn der deskriptiven Statistik ist ein Merkmal eine prinzipiell beobachtba-\nre und durch eine Zahl beschreibbare Eigenschaft von statis tischen Einhei-\nten, beispielsweise Individuen, Haushalten oder Unterneh men. Die Menge der\nstatistischen Einheiten, die Tr \u00a8ager eines Merkmals sind und \u00a8uber die etwas\nausgesagt werden soll, wird dort Grundgesamtheit genannt. In der Wahr-\nscheinlichkeitsrechnung und schlie\u00dfenden Statistik ents pricht die Ergebnis-\nmenge der Grundgesamtheit und die Zufallsvariable dem Merkmal.\nIm folgenden Abschnitt werden die wichtigsten mit Zufallsv ariablen zusam-\nmenh\u00a8angenden Begri\ufb00e erl \u00a8autert und an einfachen Beispielen illustriert.\nK. Mosler, F. Schmid, Wahrscheinlichkeitsrechnung und schlie\u00dfende Statistik ,\nSpringer-Lehrbuch, 4th ed., DOI 10.1007/978-3-642-15010-4_2,  \n\u00a9 Springer-Verlag Berlin Heidelberg 2011  42 2. Zufallsvariable und Verteilungen\n2.1 Grundbegri\ufb00e\nWir setzen voraus, dass ein Zufallsvorgang mit Ergebnismen ge \u2126 gegeben\nist. Die Menge der interessierenden Ereignisse sei durch di e Ereignisalgebra\nAgegeben, und f \u00a8ur alle Ereignisse A\u2208Asei eine Wahrscheinlichkeit P(A)\nde\ufb01niert.\nUnter einer Zufallsvariablen versteht man formal eine Funktion\nX: \u2126\u2212\u2192R,\n\u03c9/ma\u221asto\u2212\u2192X(\u03c9).\nDie Zufallsvariable Xordnet also jedem Ergebnis \u03c9des Zufallsexperimentes\neine reelle Zahl X(\u03c9) =xzu. Die Zahl xwirdWert oderRealisierung\nder Zufallsvariablen Xgenannt. Hier ist sorgf \u00a8altig zwischen den Symbolen\nXundxzu unterscheiden. xstellt eine reelle Zahl dar, Xdagegen eine\nFunktion. Zufallsvariable werden allgemein mit Gro\u00dfbuchs taben wie X, Y, Z\noderX1, X2, . . .bezeichnet, ihre Realisationen dann mit den entsprechende n\nKleinbuchstaben x, y, z bzw.x1, x2, . . ..\nBeispiel 2.1 (vgl. Beispiel 1.4): Eine M \u00a8unze mit den Seiten K(= Kopf)\nundZ(= Zahl) wird dreimal geworfen. Die Ergebnismenge besteht a us acht\nm\u00a8oglichen Ergebnissen,\n\u2126 ={(K, K, K ),(K, K, Z ), . . . ,(Z, Z, Z )}.\nBezeichne Xin Abh \u00a8angigkeit von \u03c9\u2208\u2126die\u201dAnzahl Kopf\u201c,\nX(\u03c9) =Anzahl K in \u03c9.\nO\ufb00enbar wird mehreren Ergebnissen durch Xdie gleiche Zahl zugeordnet;\nz.B. ist\nX((Z, K, Z )) =X((K, Z, Z )) =X((Z, Z, K )) = 1 .\nBeispiel 2.2 (vgl. Beispiel 1.3): Beim Roulette ist die Meng e der Ergebnisse\n\u2126 ={0,1, . . .,36}. Ein Spieler setzt einen Euro auf die erste Colonne C1,\nC1={1,4,7,10,13,16,19,22,25,28,31,34};\nvgl. Abbildung 1.2. Wenn die Roulettekugel auf eine der Zahl en in C1f\u00a8allt,\nerh\u00a8alt der Spieler das Dreifache seines Einsatzes ausgezahlt. Ihn interessiert\nin der Regel nicht die ausgespielte Zahl, sondern sein Netto gewinn, den wir\nmitYbezeichnen. Yist eine Funktion von \u03c9, also eine Zufallsvariable. Es\ngilt\nY(\u03c9) =/braceleftbigg\u22121,falls\u03c9 /\u2208C1,\n2,falls\u03c9\u2208C1.2.1. Grundbegriffe 43\nBei manchen Zufallsvorg \u00a8angen kommt es nur darauf an, ob ein Ereignis A\neintritt oder nicht. Dies kann man durch eine so genannte Indikatorvaria-\nbleX=1Azum Ausdruck bringen. Die Zufallsvariable, die lediglich d as\nEintreten von Aanzeigt, wird durch\nX(\u03c9) =1A(\u03c9) =/braceleftbigg1, falls\u03c9\u2208A,\n0, falls\u03c9\u2208A,\nde\ufb01niert. Wenn Aeintritt, nimmt sie den Wert x= 1 an; wenn Anicht\neintritt, den Wert x= 0. Komplement, Durchschnitt und Vereinigung von\nEreignissen entsprechen einfachen Rechenoperationen der Indikatorvariablen.\nO\ufb00enbar gilt (jeweils f \u00a8ur alle \u03c9\u2208\u2126)\n1\u2126(\u03c9) = 1 ,\n1\u00f8(\u03c9) = 0 ,\n1A\u2229B(\u03c9) = 1A(\u03c9)\u22271B(\u03c9) =1A(\u03c9)\u00b71B(\u03c9),\n1A\u222aB(\u03c9) = 1A(\u03c9)\u22281B(\u03c9) = 1\u2227(1A(\u03c9) +1B(\u03c9)),\nwobei das Symbol \u2227das Minimum und das Symbol \u2228das Maximum zweier\nZahlen bezeichnet, z.B. \u22122\u222717 =\u22122 und 1 .2\u22280.5 = 1.2.\nBeispiel 2.2 (Fortsetzung): Den Nettogewinn beim Setzen au f die erste Co-\nlonne kann man mit Hilfe einer Indikatorvariablen schreibe n,\nY(\u03c9) = 2\u00b71C1(\u03c9)\u22121\u00b71C1(\u03c9) = 2\u00b71C1(\u03c9)\u2212(1\u22121C1(\u03c9))\n= 3\u00b71C1(\u03c9)\u22121.\nViele Zufallsvorg \u00a8ange haben selbst Zahlen als Ergebnisse, dann ist \u2126 \u2282R.\nWenn das Ergebnis \u03c9selbst als Merkmal interessiert, kann man dies durch\ndie Zufallsvariable\nX(\u03c9) =\u03c9, \u03c9\u2208\u2126,\nalso durch die identische Abbildung, zum Ausdruck bringen.\nBeispiel 2.3 (vgl. Beispiel 1.2): Werfen eines W \u00a8urfels mit \u2126 ={1,2, . . .,6}.\nWenn die geworfene Augenzahl als solche von Interesse ist, b etrachtet man\ndie Zufallsvariable\nX(i) =i f\u00a8ur i= 1,2, . . .,6.\nSehr wichtig ist es, die Zufallsvariable Xund ihren Wert xsorgf\u00a8altig zu\nunterscheiden. Formal ist Xeine Funktion und xeine Zahl. Inhaltlich besteht\nder Unterschied darin, dass Xdie Situation ex ante beschreibt, bevor sich das\nzuf\u00a8allige Geschehen ereignet, w \u00a8ahrend xsich auf die Situation ex post bezieht,\nwenn sich das zuf \u00a8allige Geschehen ereignet hat und sein Ergebnis feststeht.\n\u00a8UberXk\u00a8onnen Wahrscheinlichkeitsaussagen getro\ufb00en werden, \u00a8uberxjedoch\nnicht.44 2. Zufallsvariable und Verteilungen\n2.1.1 Verteilungsfunktion\nEine Zufallsvariable Xnimmt ihre Werte mit bestimmten Wahrscheinlichkei-\nten an. Das grundlegende Hilfsmittel, um mit diesen Wahrsch einlichkeiten zu\nrechnen, ist die Verteilungsfunktion vonX. Dies ist die Funktion\nFX:R\u2212\u2192 [0,1],\nx/ma\u221asto\u2212\u2192 FX(x) =P({\u03c9|X(\u03c9)\u2264x}).\nStattFX(x) schreibt man auch F(x),wenn keine Verwechslungen zu erwarten\nsind. Die Verteilungsfunktion der Zufallsvariablen Xordnet also jeder Zahl x\ndie Wahrscheinlichkeit eines Ereignisses zu, n \u00a8amlich des Ereignisses, dass X\nden Wert xoder einen kleineren Wert annimmt. F \u00a8ur dieses Ereignis schreibt\nman auch k \u00a8urzer\n{X\u2264x}={\u03c9|X(\u03c9)\u2264x}\nund f\u00a8ur seine Wahrscheinlichkeit unter Weglassung der geschwei ften Klam-\nmern\nP(X\u2264x) =P({\u03c9|X(\u03c9)\u2264x}).\nHierbei haben wir stillschweigend vorausgesetzt, dass f \u00a8ur jedes x\u2208Rdiese\nMenge ein Ereignis ist, also {X\u2264x}\u2208A gilt. Die Funktion\nB/ma\u221asto\u2212\u2192P(X\u2208B)\nhei\u00dftVerteilung der Zufallsvariablen X, wobei Balle Teilmengen von R\ndurchl \u00a8auft, die ein Ereignis beschreiben, d.h. f \u00a8ur die{\u03c9|X(\u03c9)\u2208B}\u2208A ist.\nEigenschaften der Verteilungsfunktion Die Verteilungsfunktion Fei-\nner Zufallsvariablen Xbesitzt allgemein die folgenden Eigenschaften:\n1.Fistmonoton wachsend :F(x)\u2264F(y) f\u00a8urx < y.\nDie Monotonie folgt sofort daraus, dass f \u00a8urx < y die Mengeninklusion\n{X\u2264x}\u2282{X\u2264y}gilt.\n2.Fw\u00a8achstvon null bis eins :\nlim\nx\u2192\u2212\u221eF(x) = 0 und lim\nx\u2192\u221eF(x) = 1.\nDies liegt zum einen daran, dass f \u00a8urx\u2192\u2212\u221e die Menge{X\u2264x}gegen\ndie leere Menge \u00d8 konvergiert und dass P(\u00d8) = 0 ist, zum anderen\ndaran, dass die Menge {X\u2264x}f\u00a8urx\u2192\u221e gegen \u2126 konvergiert und\nP(\u2126) = 1 ist.2.1. Grundbegriffe 45\n3.Fistrechtsstetig , d.h. der Funktionswert F(x) ist an jeder Stelle x\ngleich dem rechtsseitigen Limes , d.h.\nlimy\u2192x\ny>xF(y) =F(x).\nAuf den Beweis der Rechtsstetigkeit wollen wir verzichten. Man beach-\nte, dass eine Verteilungsfunktion im Allgemeinen nicht ste tig ist. Sie\nkann Spr \u00a8unge aufweisen, an denen der linksseitige Limes\nlimy\u2192x\ny<xF(x)\nkleiner als der Funktionswert F(x) ist.\nDie drei Eigenschaften einer Verteilungsfunktion lassen s ich kurz so zusam-\nmenfassen: Eine Verteilungsfunktion w \u00a8achst monoton von 0 (bei x=\u2212\u221e)\nbis 1 (bei x=\u221e) und ist rechtsstetig.\nUmgekehrt kann man zu jeder gegebenen Funktion F, die diese drei Eigen-\nschaften besitzt, eine Zufallsvariable Xso konstruieren, dass Fdie Vertei-\nlungsfunktion von Xist.\nBeispiel 2.2 (Fortsetzung): Die Zufallsvariable X\u201dNettogewinn\u201c bei Setzen\nvon 1eauf die erste Colonne hat die Verteilungsfunktion\nF(x) =\uf8f1\n\uf8f4\uf8f2\n\uf8f4\uf8f30 f \u00a8urx <\u22121,\n25\n37f\u00a8ur\u22121\u2264x <2,\n1 f \u00a8urx\u22652.\n\u22121 0 1 2 316\n-xF(x)\ntt\nAbbildung 2.1: Verteilungsfunktion der Zufallsvariablen\u201dNettogewinn\u201d in Bei-\nspiel 2.246 2. Zufallsvariable und Verteilungen\nMan sieht in Abbildung 2.1, dass der Graph von Fan den Stellen x=\u22121\nundx= 2springt, Faber rechtsstetig ist.\nBeispiel 2.1 (Fortsetzung): Beim dreimaligen Werfen der M \u00a8unze nehmen wir\nan, dass es sich um ein Laplace-Experiment handelt. Dies bed eutet, dass jede\nder Ergebnisfolgen aus K(= Kopf) und Z(= Zahl) die gleiche Wahrschein-\nlichkeit besitzt. F \u00a8ur die Zufallsvariable X=\u201dAnzahl Kopf\u201c gilt dann\nP(X= 0) =1\n8, P (X= 1) =3\n8,\nP(X= 2) =3\n8, P (X= 3) =1\n8,\nund f\u00a8ur die Verteilungsfunktion\nF(x) =\uf8f1\n\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f4\uf8f30 f \u00a8urx <0,\n0.125 f \u00a8ur 0\u2264x <1,\n0.5 f \u00a8ur 1\u2264x <2,\n0.875 f \u00a8ur 2\u2264x <3,\n1 f \u00a8urx\u22653.\nIn vielen Anwendungen der Wahrscheinlichkeitsrechnung ge n\u00a8ugt es, statt ei-\nner Zufallsvariablen Xlediglich ihre Verteilungsfunktion zu untersuchen. Oft\nist es kompliziert oder \u00a8uberhaupt nicht m \u00a8oglich, \u2126 und die Abbildungsvor-\nschrift X: \u2126\u2192Rexplizit anzugeben, jedoch lassen sich die Wahrscheinlich -\nkeiten, mit denen eine Zufallsvariable bestimmte Werte ann immt oder der\nVerlauf ihrer Verteilungsfunktion aus sachlogischen Erw \u00a8agungen unmittelbar\nbestimmen. Eine explizite Angabe der Ergebnismenge \u2126 und pu nktweise De-\n\ufb01nition einer Zufallsvariablen XalsX(\u03c9), \u03c9\u2208\u2126,ist in der Regel nicht n \u00a8otig\nund aus Sicht des Anwenders ohne Belang.\nBeispiel 2.4: Die Lebensdauer eines elektronischen Bautei ls wird durch die\nBedingungen seiner Herstellung, die Umst \u00a8ande seiner Nutzung und durch\nzahlreiche weitere Ein\ufb02 \u00a8usse bestimmt. Wir fassen die Lebensdauer deshalb\nals Zufallsvariable auf und bezeichnen sie mit X. Die im konkreten Fall rea-\nlisierte Dauer X(\u03c9)h\u00a8angt dann vom Ergebnis \u03c9des ihr zugrundeliegenden\nZufallsvorgangs ab. Um \u03c9\u2208\u2126und die Zuordnung \u03c9/ma\u221asto\u2192X(\u03c9)zu beschrei-\nben, m \u00a8usste man s \u00a8amtliche Ein\ufb02ussfaktoren spezi\ufb01zieren, was praktisch kau m\nm\u00a8oglich ist. Besser ist es, ganz darauf zu verzichten und sich durch sachbezo-\ngene\u00a8Uberlegungen eine Vorstellung vom Verlauf der Verteilungs funktion zu\nverscha\ufb00en. Man kann zeigen (siehe unten Abschnitt 2.4.2), dass, wenn das\nBauteil in einem bestimmten Sinn nicht\u201daltert\u201c, die folgende Verteilungs-\nfunktion (mit geeignetem Parameter \u03bb) angemessen ist:\nF(x) =/braceleftbigg0, fallsx <0,\n1\u2212e\u2212\u03bbx,fallsx\u22650.2.1. Grundbegriffe 47\nZahlreiche weitere Beispiele \ufb01nden sich in den folgenden Ab schnitten 2.3 und\n2.4\u00a8uber spezielle Verteilungen.\nDie Verteilungsfunktion Feiner Zufallsvariablen gibt die Wahrscheinlichkeit\nf\u00a8ur alle Ereignisse der Form {X\u2264x},x\u2208R,an. Hieraus kann man die\nWahrscheinlichkeiten f \u00a8ur alle anderen interessierenden Ereignisse ableiten.\nDie Wahrscheinlichkeit, dass Xin ein \u2013 beschr \u00a8anktes oder unbeschr \u00a8anktes \u2013\nIntervall1f\u00a8allt, l\u00a8asst sich in besonders einfacher Weise aus der Verteilungs-\nfunktion berechnen:\nP(X > x ) = 1\u2212P(X\u2264x) = 1\u2212F(x),\nP(a < X\u2264b) = P(X\u2264b)\u2212P(X\u2264a)\n=F(b)\u2212F(a),\nwenn a < b ist. F\u00a8ur das Ereignis{X=x}gilt\nP(X=x) =P(X\u2264x)\u2212P(X < x ) =F(x)\u2212limy\u2192x\ny<xF(y). (2.1)\nHieraus folgert man\nP(X\u2265a) = 1\u2212P(X < a ) = 1\u2212limy\u2192a\ny<aF(y)\nund analog\nP(a\u2264X\u2264b) =P(X\u2264b)\u2212P(X < a ) =F(b)\u2212limy\u2192a\ny<aF(y),\nwenn a\u2264bist.\n2.1.2 Quantilfunktion\nF\u00a8ur eine gegebene Zahl xistFX(x) die Wahrscheinlichkeit, dass Xh\u00a8ochstens\nden Wert xannimmt. Umgekehrt kann man, wenn eine Wahrscheinlichkeit\npgegeben ist, fragen, welchen Wert xdie Zufallsvariable mit Wahrschein-\nlichkeit pnicht \u00a8uberschreitet. Hierbei ist allerdings Vorsicht geboten. W enn\ndie Verteilungsfunktion stetig ist und streng monoton w \u00a8achst, besitzt sie eine\neindeutige Umkehrfunktion QX:p/ma\u221asto\u2212\u2192xp, 0< p < 1, genannt Quantil-\nfunktion . Dies ist im folgenden Beispiel der Fall.\nBeispiel 2.4 (Fortsetzung): Die Lebensdauer eines elektro nischen Bauteils\nwerde als Zufallsvariable Xmit der Verteilungsfunktion\nFX(x) =/braceleftbigg0, fallsx <0,\n1\u2212e\u2212x,fallsx\u22650,\n1Dazu geh \u00a8oren die abgeschlossenen Intervalle [ a, b], die o\ufb00enen Intervalle ] a, b[, die halb-\no\ufb00enen Intervalle [ a, b[ und ] a, b], sowie die Halbgeraden [ c,\u221e[, ]c,\u221e[, ]\u2212\u221e, c] und ] \u2212\u221e, c[,\nwobei a,bundcreelle Zahlen sind mit a < b.48 2. Zufallsvariable und Verteilungen\nangesehen. O\ufb00enbar ist FXstetig und f \u00a8urx\u22650streng monoton wachsend.\nDie Quantilfunktion ist in diesem Fall gleich der gew \u00a8ohnlichen Umkehrfunk-\ntion von FX. F\u00a8ur jedes p\u2208]0,1[gilt n\u00a8amlich\nFX(x) =p\u21d41\u2212e\u2212x=p\u21d4x=\u2212ln(1\u2212p),\nalso\nQX(p) =xp=\u2212ln(1\u2212p) = ln/parenleftbigg1\n1\u2212p/parenrightbigg\n.\nDiese Quantilfunktion ist zusammen mit der Verteilungsfun ktion in Abbil-\ndung 2.2.a abgebildet.\nWenn die Verteilungsfunktion jedoch Spr \u00a8unge macht, gibt es nicht f \u00a8ur jedes p\nein solches xpund, wenn \u2013 wie im obigen Beispiel 2.1 \u2013 die Verteilungsfunkt ion\nzum Teil waagrecht verl \u00a8auft, ist dieses xpnicht immer eindeutig bestimmt.\nDie folgende allgemeine De\ufb01nition tr \u00a8agt dem Rechnung:\nF\u00a8ur eine Zufallsvariable Xmit Verteilungsfunktion FXhei\u00dft die Funktion\nQX: ]0,1[\u2212\u2192 R,\np/ma\u221asto\u2212\u2192 QX(p) = min{x|FX(x)\u2265p},\nQuantilfunktion vonX.Der Wert der Quantilfunktion xp=QX(p) hei\u00dft\np-Quantil vonX.Dasp-Quantil xpist demnach die kleinste Zahl x\u2208R\nmit der Eigenschaft, dass FX(x) den Wert perreicht oder \u00a8uberspringt. Es\nwird auch als p\u00b7100%-Punkt bezeichnet. Statt QXundFXschreiben wir im\nFolgenden k \u00a8urzer QundF, wenn nur eine Zufallsvariable Xin Frage kommt.\nDer Graph der Quantilfunktion Qh\u00a8angt eng mit dem der Verteilungsfunk-\ntionFzusammen (siehe Abbildung 2.2.a bis c): Er ist nichts andere s als\ndie Spiegelung des Graphen von Fan der 45-Grad-Linie. Dabei gehen et-\nwaige Spr \u00a8unge von F(in der Abbildung als senkrechte Linien gestrichelt)\nin waagrechte Abschnitte des Graphen von Q\u00a8uber, und etwaige waagrechte\nAbschnitte des Graphen von Fwerden zu senkrechten Linien (das sind die\nSpr\u00a8unge) des Graphen von Q.\nBeispiel 2.5: Eine Zufallsvariable Xnehme die drei Werte 0.3,1.2und2.4\nan, und zwar mit den Wahrscheinlichkeiten\nP(X= 0.3) = 0 .2, P(X= 1.2) = 0 .4, P(X= 2.4) = 0 .4.\nDie Verteilungsfunktion und die Quantilfunktion von Xsind in Abbildung\n2.2.b dargestellt.2.1. Grundbegriffe 49\n116\n-. . . . . . . . . . . . . . . . . . . . . . . . . . . .\n........ ........ ........ ........ ........ ....... ....... ....... ....... ....... ....... ....... ...... ...... ...... ...... ...... ...... ...... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. . ... ... ... . .. ... . .. ... . .. .. . ... . .. .. . .. . ... . .. . .. . .. .. . .. . .. . .. . . .. . .. . .. . .. . . . .. . .. . . .. . . . .. . . .. . . . .. . . .. . . . .. . . .. . . . . ..\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n.............................................................................................................................................................................................................................................\n......................................\nVerteilungsfunktion\nQuantilfunktiona)\n1x1\np6\n-. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n. . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . .\n...... ....\n............................\n...........................\n. . . . . . . . . . . . . . . . . . .\n...................\nsss\nsssb)\n1 x1\np6\n-. . . . . . . . . . . . . . . . . . . . . . . . .................................................................................. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ................................................................................... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n. .. .. .. .. . .. .. . .. .. .. .. .. ... .. .. .. . .. ... .. .. .... ... .... ... .... .... ... .... .... ... ... ..... ... ..\n.........................\n.........................\n............ . . . . . . . . . . . . . . . . . . . . . . . .\n............................\n...c)\nAbbildung 2.2: Drei Verteilungsfunktionen und ihre Quanti lfunktionen50 2. Zufallsvariable und Verteilungen\nF\u00a8ur einige Quantile verwendet man spezielle Namen:\nx0.5 Median\nx0.25 x0.5x0.75 Quartile\nx0.2x0.4x0.6x0.8 Quintile\nx0.1x0.2x0.3x0.4x0.5x0.6x0.7x0.8x0.9Dezile\nWenn die Zufallsvariable Xgen\u00a8ugend viele verschiedene Werte annimmt,\nlassen sich diese Quantile wie folgt interpretieren:\n\u2022Der Median x0.5teilt die reelle Achse in zwei Teile, die jeweils ungef \u00a8ahr\n50% der Wahrscheinlichkeitsmasse tragen.\n\u2022Die Quartile x0.25,x0.5undx0.75teilen die reelle Achse in vier Teile\nein, auf denen jeweils ungef \u00a8ahr ein Viertel der Wahrscheinlichkeitsmasse\nliegt. Analog interpretiert man Quintile und Dezile.\nIm Beispiel 2.4 sind Median und oberes Dezil durch\nx0.5= ln/parenleftbigg1\n1\u22120.5/parenrightbigg\n= ln 2 = 0 .69und\nx0.9= ln 10 = 2 .30\ngegeben, im Beispiel 2.5 durch y0.5= 1.2undy0.9= 2.4.\nIm Beispiel 2.4 liegt links und rechts vom Median jeweils exa kt die H \u00a8alfte der\nWahrscheinlichkeitsmasse. Es ist n \u00a8amlich\nP(X < x 0.5) = F(ln 2) = 1\u2212e\u2212ln 2= 0.5und\nP(X > x 0.5) = 1\u2212lim\nx\u2192ln 2\nx<ln 2F(x) = 1\u2212/parenleftbig\n1\u2212e\u2212ln 2/parenrightbig\n= 0.5.\nIm Beispiel 2.5 hingegen haben wir\nP(X < x 0.5) = P(X <1.2) = 0 .2und\nP(X > x 0.5) = P(X >1.2) = 0 .4.\nWie man sieht, tre\ufb00en bei Zufallsvariablen, die wie die im Be ispiel 2.5 mit\nrelativ gro\u00dfer Wahrscheinlichkeit einzelne Werte annehme n, die obigen Inter-\npretationen nicht genau zu. Weitere Hinweise zur Berechnun g von Quantilen\n\ufb01nden sich im Abschnitt 2.4. In der statistischen Literatur und Software kom-\nmen auch auch andere De\ufb01nitionen von Quantilen vor.\nEigenschaften der Quantilfunktion Die Quantilfunktion Qhat\u00a8ahnli-\nche formale Eigenschaften wie die Verteilungsfunktion: Si e ist\n1.monoton wachsend , d.h. f \u00a8urp < p\u2032istQ(p)\u2264Q(p\u2032),2.1. Grundbegriffe 51\n2.linksstetig , aber im Allgemeinen nicht stetig.\nVerteilungsfunktion Fund Quantilfunktion Qsind wie folgt miteinander ver-\nkn\u00a8upft:\nF(Q(p))\u2265p f\u00a8urp\u2208]0,1[,\nQ(F(x))\u2264x f\u00a8urx\u2208R.\nMan beachte, dass die beiden Ungleichheitszeichen im Allge meinen nicht\ndurch Gleichheitszeichen ersetzt werden d \u00a8urfen.\n2.1.3 Diskrete Zufallsvariable\nIn der elementaren Wahrscheinlichkeitsrechnung untersch eidet man zwei Ty-\npen von Zufallsvariablen, diskrete und stetige Variable. I m Umgang mit die-\nsen beiden Typen von Zufallsvariablen werden unterschiedl iche mathemati-\nsche Hilfsmittel benutzt; zum Einen das Rechnen mit endlich en und unend-\nlichen Summen, zum Anderen die Di\ufb00erential- und Integralre chnung.\nEine Zufallsvariable Xhei\u00dftdiskret , wenn es entweder\n\u2022endlich viele Punkte x1, x2, . . . , x Joder\n\u2022abz\u00a8ahlbar unendlich viele Punkte x1, x2, x3, . . .\nso gibt, dass\npj=P(X=xj)>0 f\u00a8ur alle jsowie/summationdisplay\njpj= 1\ngilt. Die Menge\nTX={x1, x2, . . . , x J}bzw. TX={x1, x2, . . .}\nhei\u00dftTr\u00a8agervonX.Der Tr \u00a8ager einer diskreten Zufallsvariablen ist die Menge\naller Werte, die Xmit einer positiven Wahrscheinlichkeit annimmt. Es gilt\nP(X\u2208TX) = 1. Die Funktion\nf(x) =fX(x) =/braceleftbiggpj,fallsx=xjf\u00a8ur ein j ,\n0 sonst,\nhei\u00dftWahrscheinlichkeitsfunktion vonX. Sie kann etwa mittels eines\nStabdiagramms graphisch dargestellt werden.\nDieVerteilung der diskreten Variablen Xist durch die Paare ( xj, pj), j=\n1,2, . . .,eindeutig bestimmt, denn f \u00a8ur jede Menge Bgilt\nP(X\u2208B) =/summationdisplay\nj|xj\u2208Bpj.52 2. Zufallsvariable und Verteilungen\n0 1 2 36\n-xf(x)\ntt t\nt\n0 1 2 36\n-xF(x)\ntttt\nAbbildung 2.3: Wahrscheinlichkeitsfunktion und Verteilu ngsfunktion von\u201dAnzahl\nKopf\u201c im Beispiel 2.1\nDabei erstreckt sich die Summe \u00a8uber alle pj, f\u00a8ur die xjinBliegt. Insbesondere\nist\nF(x) =P(X\u2264x) =/summationdisplay\nj|xj\u2264xpj\ndie Verteilungsfunktion an der Stelle x\u2208R. DieVerteilungsfunktion einer\ndiskreten Zufallsvariablen ist o\ufb00enbar eine Treppenfunkt ion, deren Spr \u00a8unge\nan den Stellen xj\u2208TXliegen. Die Sprungh \u00a8ohe an der Stelle xjist gleich\nF(xj)\u2212limx\u2192xj\nx<xjF(x) =pj,\nalso gleich der Wahrscheinlichkeit f \u00a8urxj.\nBeispiel 2.1 (Fortsetzung): Beim dreifachen Wurf einer M \u00a8unze werden al-\nle m\u00a8oglichen Ergebnisse als gleich wahrscheinlich angenommen (Laplace-Ex-\nperiment). Dann ist X(= Anzahl Kopf) eine diskrete Zufallsvariable mit\nWahrscheinlichkeitsfunktion\nf(x) =\uf8f1\n\uf8f4\uf8f4\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f4\uf8f4\uf8f30.125,fallsx= 0,\n0.375,fallsx= 1,\n0.375,fallsx= 2,\n0.125,fallsx= 3,\n0 sonst.\nWahrscheinlichkeitsfunktion und Verteilungsfunktion si nd in Abbildung 2.3\ndargestellt.2.1. Grundbegriffe 53\n0 x6\n-xf(x)\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . .. . . . . . . . . .. . . . . . . .. . . . . . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . .. . . . . .. . . .. . . .. . . .. . . .. . . .. .. . . .. . . .. . . .. .. . . .. .. . . .. .. .. . . .. .. .. .. . . .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. . . .. . . .. . . . . .. . . . . . . . . . . . . . . . . .. . . . . .. . . .. . . .. .. . . .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. .. .. . . .. .. .. . . .. .. . . .. .. . . .. . . .. . . .. .. . . .. . . .. . . .. . . .. . . .. . . . . .. . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . . . .. . . . . . . .. . . . . . . . . .. . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ........................................................................................................\n......\n....\n...\n...\n...\n...\n....\n....\n.....\n.....\n......\n......\n.......\n.......\n........\n........\n.........\n.........\n..........\n..........\n...........\n..........\n...........\n...........\n............\n............\n............\n............\n............\n............\n...........\n...........\n..........\n...........\n..........\n..........\n.........\n.........\n........\n........\u0001\n\u0001 \u000bF(x)\nAbbildung 2.4: Dichte f(x) und Verteilungsfunktion F(x)\n2.1.4 Stetige Zufallsvariable\nEine Zufallsvariable Xnennt man stetig , wenn sich ihre Verteilungsfunktion\nFXals Integral einer Funktion fX:R\u2192[0,\u221e[ schreiben l \u00a8asst, d.h. wenn\nFX(x) =x/integraldisplay\n\u2212\u221efX(t)dtf\u00a8ur alle x\u2208R. (2.2)\nDie Funktion fX(x) hei\u00dft dann Dichtefunktion , kurz: Dichte , vonX, und\nman sagt, Xseistetig verteilt . Statt FX(x) und fX(x) schreibt man auch\nF(x) bzw. f(x).\nDie Verteilungsfunktion einer stetigen Zufallsvariablen ist also eine Stamm-\nfunktion ihrer Dichtefunktion; in Abbildung 2.4 entsprich t der Wert F(x) dem\nInhalt der punktierten Fl \u00a8ache unterhalb des Graphen der Dichte f. Durch\nDi\ufb00erenzieren der Verteilungsfunktion erh \u00a8alt man die Dichte,\nf(x) =F\u2032(x),\nvorausgesetzt die Verteilungsfunktion Fist an der Stelle xtats\u00a8achlich dif-\nferenzierbar. Bei den stetigen Zufallsvariablen, die im Fo lgenden untersucht\nwerden, ist die Verteilungsfunktion an h \u00a8ochstens ein oder zwei Stellen nicht\ndi\ufb00erenzierbar. An diesen Stellen macht die Dichte einen Sp rung.\nEigenschaften der Dichtefunktion Die wesentlichen Eigenschaften sind:\n1.Nichtnegativit \u00a8atf(x)\u22650 f\u00a8ur alle x\u2208R,54 2. Zufallsvariable und Verteilungen\n2.Normiertheit\u221e/integraltext\n\u2212\u221ef(x)dx= 1.\nDie beiden Eigenschaften folgen aus der Monotonie von Fund der Tatsache,\ndass lim x\u2192\u221eF(x) = 1 ist. Umgekehrt l \u00a8asst sich zu jeder Funktion f, die\ndiese beiden Eigenschaften hat, eine stetige Zufallsvaria ble konstruieren, die\nfals Dichte besitzt.\nEine Besonderheit stetiger Zufallsvariablen besteht dari n, dass f \u00a8ur jede gege-\nbene Zahl xdie Wahrscheinlichkeit, dass Xden Wert xannimmt, gleich null\nist. Da Fstetig ist, gilt n \u00a8amlich f \u00a8ur jedes x\u2208R\nlimy\u2192x\ny<xF(y) =F(x),\nund deshalb wegen (2.1)\nP(X=x) = 0.\nDennoch gibt es Mengen B, f\u00a8ur die P(B)>0 ist, insbesondere gilt o\ufb00enbar\nP(X\u2208R) = 1.\nWahrscheinlichkeiten f \u00a8ur Intervalle Speziell bestimmen wir nun die\nWahrscheinlichkeit eines Intervalls, das durch aundbbegrenzt wird, a < b.\nEs gilt:\nP(a < X\u2264b) = F(b)\u2212F(a)\n=b/integraldisplay\n\u2212\u221ef(t)dt\u2212a/integraldisplay\n\u2212\u221ef(t)dt=b/integraldisplay\naf(t)dt .\nDaP(X=a) =P(X=b) = 0 ist, gilt auch\nP(a < X\u2264b) =P(a\u2264X\u2264b) =P(a\u2264X < b ) =P(a < X < b ).\nDie Wahrscheinlichkeit, dass eine stetige Zufallsvariabl eXin ein Intervall\nmit den Grenzen aundbf\u00a8allt, ergibt sich also als Integral \u00a8uber die Dichte\nvonXin den Grenzen aundb; siehe Abbildung 2.5. Ob die Grenzen zum\nIntervall geh \u00a8oren oder nicht, ist dabei gleichg \u00a8ultig.\nMan beachte, dass eine Dichte auch Werte gr \u00a8o\u00dfer als 1 annehmen kann. Der\nWert f(x) gibt also nicht etwa die Wahrscheinlichkeit an, dass Xden Wert\nxannimmt (diese ist gleich null), vielmehr ist\nf(x) = lim\n\u03b5\u219201\n\u03b5P(x\u2264X\u2264x+\u03b5),2.1. Grundbegriffe 55\n0a b6\n-xf(x)\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . .. . . . . . . . . .. . . . . . . .. . . . . . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . .. . . . . .. . . .. . . .. . . .. . . .. . . .. .. . . .. . . .. . . .. .. . . .. .. . . .. .. .. . . .. .. .. .. . . .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. . . .. . . .. . . . . .. . . . . . . . . . . . . . . . . .. . . . . .. . . .. . . .. .. . . .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. .. .. . . .. .. .. . . .. .. . . .. .. . . .. . . .. . . .. .. . . .. . . .. . . .. . . .. . . .. . . . . .. . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . . . .. . . . . . . .. . . . . . . . . .. . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ........................................................................................................\n.......................................................................................................................................................\n..........\n..........\n.........\n.........\n........\n........\u0001\n\u0001 \u000bF(b)\u2212F(a)\nAbbildung 2.5: Wahrscheinlichkeit f \u00a8ur ein Intervall mit den Grenzen aundb\n0a b6\n-xf(x)\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . .. . . . . . . . . .. . . . . . . .. . . . . . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . .. . . . . .. . . .. . . . . .. . . .. . . .. . . .. .. . . .. . . .. .. . . .. .. . . .. .. . . .. .. .. . . .. .. .. .. .. . . .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. . . .. . . .. . . . . . . . . .. . . . . .. . . . . . . . . .. . . .. . . .. . . .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. .. .. .. . . .. .. .. . . .. .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. . . .. . . . . .. . . .. . . . . .. . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . . . .. . . . . . . .. . . . . . . . . .. . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .......................................................................................................................................................\n....................................................................................................................................................... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n...........\n...........\n...........\n...........\n...........\n...........\u0001\u0001 \u000bf(a)\u00b7(b\u2212a)\nAbbildung 2.6: Approximation der Wahrscheinlichkeit f \u00a8ur ein Intervall mit den\nGrenzen aundb\nd.h.f(x) ist n \u00a8aherungsweise gleich 1 /\u03b5mal der Wahrscheinlichkeit, dass Xin\nein kleines Intervall bei xf\u00a8allt, das die L \u00a8ange\u03b5besitzt. Die Wahrscheinlich-\nkeit, dass Xin ein kleines Intervall [ a, b] f\u00a8allt, kann deshalb in erster N \u00a8aherung\ndurch\nP(a\u2264X\u2264b)\u2248f(a)(b\u2212a)\napproximiert werden; vgl. Abbildung 2.6.\nTr\u00a8ager Wir kommen nun zum allgemeinen Begri\ufb00 des Tr \u00a8agers einer Zu-\nfallsvariablen X. Unter dem Tr\u00a8agervonXverstehen wir die kleinste abge-56 2. Zufallsvariable und Verteilungen\nschlossene2Menge TX\u2282Rmit der Eigenschaft\nP(X\u2208TX) = 1.\nTXist also die kleinste abgeschlossene Menge, au\u00dferhalb dere r sich keine\nWahrscheinlichkeitsmasse be\ufb01ndet. Falls Xendlich diskret verteilt ist, bilden\ndie Punkte xj, die mit positiver Wahrscheinlichkeit pjangenommen werden,\neine endliche Menge; diese ist abgeschlossen und daher der T r\u00a8ager von X.\nFallsXstetig verteilt ist, gibt es keine einzelnen Punkte, die mit positiver\nWahrscheinlichkeit angenommen werden; hier ben \u00a8otigen wir die allgemeinere\nForm der De\ufb01nition des Tr \u00a8agers. Alle Beispiele stetiger Verteilungen in diesem\nLehrbuch haben ein abgeschlossenes Intervall (beschr \u00a8ankt oder unbeschr \u00a8ankt)\nals Tr \u00a8ager.\nQuantilfunktion Da die Verteilungsfunktion einer stetigen Zufallsvaria-\nblen stetig ist, nimmt ihre Quantilfunktion die folgende ei nfache Form an:\nQ(p) = min{x|F(x) =p},0< p < 1.\nZur Bestimmung eines Quantils xpmuss man lediglich die kleinste L \u00a8osung x\nder Gleichung F(x) =paufsuchen. In allen Beispielen des Lehrbuchs wird\ndie L\u00a8osung der Gleichung eindeutig sein.\nBeispiel 2.6: In einer Fernsehshow wird ein Gl \u00a8ucksrad in Bewegung gesetzt\nund der Stillstand abgewartet. Es sei\nX=Position des Gl \u00a8ucksrads in Grad bei Stillstand.\nDer Mechanismus ist so konstruiert, dass keine Winkel bevor zugt auftreten.\nMan kann deshalb davon ausgehen, dass Xeine stetige Zufallsvariable mit\nder folgenden Dichte ist:\nf(x) =/braceleft\uf8ecigg1\n360,falls 0\u2264x\u2264360,\n0 sonst.\nF\u00a8ur die Verteilungsfunktion gilt dann\nF(x) =\uf8f1\n\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f30, fallsx <0,\n1\n360x,falls 0\u2264x <360,\n1, fallsx\u2265360.\n2Eine Menge T\u2282Rhei\u00dftabgeschlossen , wenn alle Randpunkte von Tals Elemente\nzuTgeh\u00a8oren. Jedes abgeschlossene Intervall, jede endliche Verei nigung abgeschlossener\nIntervalle und jede endliche Menge sind in diesem Sinne abge schlossen. Auch N,Rund\n[0,\u221e[ sind abgeschlossene Mengen.2.1. Grundbegriffe 57\n0 3601\n3600.016\n-xf(x)\nt t\n.....\n0 36016\n-xF(x)\n.................................................................................................................................................................................................................................................................\n.................................................................................................................................................................................................................................................................\n................................................................................................................................................................................................................................................................. . . . . . . . . . . . .\nAbbildung 2.7: Dichte und Verteilungsfunktion des\u201dangezeigten Winkels\u201c in Bei-\nspiel 2.6\nTr\u00a8ager der Verteilung ist das Intervall [0,360]; vgl. Abbildung 2.7. Die Quan-\ntilfunktion ermittelt man durch Au\ufb02 \u00a8osung der Gleichung p=F(x)nach\nx=Q(p), also\nQ(p) = 360 pf\u00a8ur 0< p < 1.\nDas untere Quartil z.B. ist x0.25=Q(0.25) = 90 .\nBeispiel 2.4 (Fortsetzung): Wir betrachten wieder die Lebe nsdauer Xeines\nelektronischen Bauteils mit der Verteilungsfunktion\nF(x) =/braceleftbigg0, fallsx <0,\n1\u2212e\u2212x,fallsx\u22650.\nDaFf\u00a8ur alle x/\\e}atio\\slash= 0di\ufb00erenzierbar ist, erhalten wir die Dichte\nf(x) =/braceleftbigg\n0,fallsx <0,\ne\u2212x,fallsx\u22650.\nIn diesem Beispiel ist der Tr \u00a8ager gleich [0,\u221e[. Die Dichte ist in Abbildung\n2.8 dargestellt.\nIntervallwahrscheinlichkeiten Zum Schluss dieses Abschnitts fassen wir\ndie Formeln f \u00a8ur die Wahrscheinlichkeit, dass Xin ein Intervall f \u00a8allt, noch\neinmal tabellarisch zusammen. Je nach Verteilungstyp gilt Folgendes:58 2. Zufallsvariable und Verteilungen\n0 1 2 3 41\nxf(x)\n.... .... ........ .... .... .... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. .. .. .. .. .. . . .. .. .. .. .. . . .. .. .. . . .. .. .. . . .. .. .. . . .. .. . . .. .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. . . .. . . .. . . .. . . .. .. . . . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . . . .. . . .. . . .. . . . . .. . . .. . . . . .. . . . . .. . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . . . .. . . . . .. . . . . . . .. . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . . . .. . . . . . . .. . . . . . . . . .. . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . .t\nAbbildung 2.8: Dichte der Lebensdauerverteilung im Beispi el 2.4\nallgemein stetige Verteilung diskrete Verteilung\nP(a < X\u2264b)F(b)\u2212F(a)/integraldisplayb\naf(x)dx/summationdisplay\nj|a<x j\u2264bpj\nP(X\u2264b) F(b)/integraldisplayb\n\u2212\u221ef(x)dx/summationdisplay\nj|xj\u2264bpj\nP(X > a ) 1\u2212F(a)/integraldisplay\u221e\naf(x)dx/summationdisplay\nj|xj>apj\n2.1.5 A\ufb03n-lineare Transformation von Zufallsvariablen\nH\u00a8au\ufb01g kennt man die Verteilung einer Zufallsvariablen Xund ist an der Ver-\nteilung einer anderen Zufallsvariablen Yinteressiert, die mit Xdurch eine\nmonoton wachsende a\ufb03n-lineare Transformation \u2013 d.h. eine Nullpunkts-\nverschiebung und/oder Skalen \u00a8anderung \u2013 verkn \u00a8upft ist. Im Folgenden geben\nwir die Verteilungsfunktion, die Quantilfunktion und \u2013 im F all einer stetigen\nVariablen \u2013 die Dichte von Yan.\nGegeben sei die Verteilungsfunktion FXeiner Zufallsvariablen X. Mita, b\u2208R\nundb >0 wird durch Y=a+bXeine weitere Zufallsvariable de\ufb01niert. Dann\ngilt:2.1. Grundbegriffe 59\n1. Die Verteilungsfunktion FYvonYist\nFY(y) =FX/parenleftbiggy\u2212a\nb/parenrightbigg\n, y\u2208R, (2.3)\ndenn f \u00a8urb >0 gilt\nFY(y) =P(a+bX\u2264y) =P/parenleftbigg\nX\u2264y\u2212a\nb/parenrightbigg\n=FX/parenleftbiggy\u2212a\nb/parenrightbigg\n.\n2. Wenn xp=QX(p) das p-Quantil von Xist, so ist\nyp=a+b xp (2.4)\ndasp-Quantil von Y=a+b X, 0< p < 1. Dies folgt direkt aus der\nDe\ufb01nition des Quantils.\n3. Falls Xstetig verteilt ist mit Dichte fX, ist auch Ystetig verteilt. Y\nbesitzt die Dichte\nfY(y) =1\nbfX/parenleftbiggy\u2212a\nb/parenrightbigg\n. (2.5)\nMan erh \u00a8alt sie durch Di\ufb00erenzieren der Verteilungsfunktion (2.3) . So-\nweitFXdi\ufb00erenzierbar ist, gilt f \u00a8ury\u2208R\nFY(y) = FX/parenleftbiggy\u2212a\nb/parenrightbigg\n,\nd\ndyFY(y) =d\ndyFX/parenleftbiggy\u2212a\nb/parenrightbigg\n,\nfY(y) = F\u2032\nX/parenleftbiggy\u2212a\nb/parenrightbigg\n\u00b71\nb=1\nb\u00b7fX/parenleftbiggy\u2212a\nb/parenrightbigg\n.\nBeispiel 2.6 (Fortsetzung): Mit dem rotierenden Gl \u00a8ucksrad wird in der Fern-\nsehshow folgendes Gewinnspiel verbunden. Ein zuvor bestim mter Kandidat\nerh\u00a8alt als Gewinn in jedem Fall 999 eausgezahlt. Der Gewinn erh \u00a8oht sich\npro Grad des angezeigten Winkels um 9.99 e. Wie lautet die Wahrschein-\nlichkeitsverteilung des Gewinns?\nDie Gewinnfunktion (in e) lautet g(x) = 999+9 .99x, wobei xder angezeigte\nWinkel ist, 0\u2264x\u2264360. Das Minimum ist g(0) = 999 , das Maximum\ng(360) = 999+9 .99\u00b7360 = 4595 .40. Als Zufallsvariable Ygeschrieben, ist der\nGewinn eine a\ufb03n-lineare Transformation der Zufallsvariab lenX, n\u00a8amlich\nY= 999 + 9 .99X .60 2. Zufallsvariable und Verteilungen\nDaXstetig verteilt ist mit der Dichte\nfX(x) =/braceleft\uf8ecigg1\n360,falls 0\u2264x\u2264360,\n0 sonst,\nfolgt, dass Yebenfalls stetig verteilt ist und wegen Formel (2.5) die Dic hte\nfY(y) =1\n9.99fX/parenleftbiggy\u2212999\n9.99/parenrightbigg\nbesitzt, also (unter Anpassung der Intervallgrenzen f \u00a8ur y)\nfY(y) =\uf8f1\n\uf8f4\uf8f2\n\uf8f4\uf8f31\n9.99\u00b7360,falls 999\u2264y\u22644595.40,\n0 sonst.\n2.1.6 Unimodalit \u00a8at\nUnter den Wahrscheinlichkeitsverteilungen sind diejenig en ausgezeichnet, de-\nren Dichte bzw. Wahrscheinlichkeitsfunktion f(x) in Abh \u00a8angigkeit von x\nzun\u00a8achst anw \u00a8achst und dann wieder abf \u00a8allt. Solche Verteilungen sind in den\nobigen Beispielen 2.1 und 2.6 aufgetreten; siehe Abbildung 2.9. Sie werden\nalsunimodal odereingip\ufb02ig bezeichnet. Zur genauen De\ufb01nition m \u00a8ussen\nwir zwischen stetigen und diskreten Zufallsvariablen unte rscheiden.\nUnimodale stetige Verteilung Eine stetige Wahrscheinlichkeisvertei-\nlung mit der Dichte fhei\u00dftunimodal , wenn es mindestens einen Wert xM\ngibt, f \u00a8ur den\nf(x)\u2264f(y)\u2264f(xM) f\u00a8ur alle x, ymitx < y < x M\nund f(xM)\u2265f(y)\u2265f(x) f\u00a8ur alle x, ymitxM< y < x\ngilt. Jeder solche Wert xMwirdModus genannt. O\ufb00enbar kann eine uni-\nmodale stetige Verteilung mehrere Modi besitzen, diese bil den ein Intervall.\nBeispiel 2.7: Die Verteilung mit der Dichte (siehe Abbildun g 2.10 links)\nf(x) =/braceleftbigg1\u2212|x|,falls\u22121\u2264x\u22641,\n0 sonst,\nist unimodal mit einem eindeutigen Modus, n \u00a8amlich xM= 0.\nBeispiel 2.6 (Fortsetzung): O\ufb00enbar ist die Verteilung aus Beispiel 2.6 uni-\nmodal und jeder Punkt des Intervalls [0,360]ist ein Modus; vgl. Abbildung\n2.9 rechts.2.1. Grundbegriffe 61\n0 1 2 36\n-xf(x)\ntt t\nt\n0 3601\n3600.016\n-xf(x)\nt t\n.....\nAbbildung 2.9: Wahrscheinlichkeitsfunktion aus Beispiel 2.1 und Dichtefunktion aus\nBeispiel 2.6\nBeispiel 2.8: Abbildung 2.10 rechts zeigt die Dichte einer s tetigen Verteilung,\ndie nicht unimodal ist.\nUnimodale diskrete Verteilung Wir betrachten nun die Wahrschein-\nlichkeitsverteilung einer diskreten Zufallsvariablen X. Der Tr \u00a8ager von Xsei\naufsteigend geordnet,\nxj\u2264xk,wenn j < k ,\nund es sei pj=P(X=xj),/summationtext\njpj= 1.Die Verteilung von Xhei\u00dftunimo-\ndal, wenn es mindestens einen Wert xM=xj\u2217mitP(X=xM) =pj\u2217gibt,\nf\u00a8ur den\npj\u2264pk\u2264pj\u2217f\u00a8ur alle j, kmitj < k < j\u2217\nund pj\u2217\u2265pk\u2265pjf\u00a8ur alle j, kmitj\u2217< k < j(2.5)\ngilt. Jeder solche Wert xMwirdModus genannt.\nBeispiel 2.1 (Fortsetzung): Die Verteilung beim dreifache n M\u00a8unzwurf (vgl.\nAbbildung 2.9 links) ist unimodal. Sie besitzt zwei Modi, n \u00a8amlich xM1= 1\nundxM2= 2.\nWenn eine Verteilung unimodal ist, l \u00a8asst sich ihre W \u00a8olbung (vgl. Abschnitt\n2.2.4) anschaulich interpretieren. Unimodale Verteilung en besitzen \u2013 gegen-\n\u00a8uber allgemeinen Verteilungen \u2013 zahlreiche g \u00a8unstige Eigenschaften. So las-\nsen sich beispielsweise Absch \u00a8atzungen von Wahrscheinlichkeiten durch die\nTschebysche\ufb00-Ungleichung (Abschnitt 2.2.3) verbessern, wenn die zu-\ngrundeliegende Verteilung unimodal ist. Eine umfassende D arstellung der62 2. Zufallsvariable und Verteilungen\n\u22121 0 10.00.20.40.60.81.01.2\n-6\nxf(x)\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ........................................................................................................................................................................................................................................\n.........................................................................................................................................................................................................................................\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\u22121 0 10.00.20.40.60.81.01.2\n-6\nxf(x)\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .......................................................................................................................................................................................................................... ........................................................................................................................................................................................................................... ........................................................................................................................................................................................................................... ........................................................................................................................................................................................................................... . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nAbbildung 2.10: Unimodale (Beispiel 2.7) und nicht unimoda le (Beispiel 2.8) Ver-\nteilung\nEigenschaften unimodaler Verteilungen \ufb01ndet man in Dharma dhikari und\nJoag-dev (1988).\n2.1.7 Symmetrie\nIn vielen F \u00a8allen schwankt eine Zufallsvariable um einen zentralen Wer t. Wenn\ndie Abweichungen nach oben und unten mit den gleichen Wahrsc heinlichkei-\nten auftreten, spricht man von einer symmetrischen Wahrsch einlichkeitsver-\nteilung.\nSeiXeine Zufallsvariable und c\u2208Reine Zahl. Wenn\nP(X\u2264c\u2212y) =P(X\u2265c+y) f\u00a8ur alle y\u2208R\ngilt, sagt man, Xseisymmetrisch zu cverteilt . Gleichbedeutend gilt\nP(X\u2212c\u2264\u2212y) =P(\u2212(X\u2212c)\u2264\u2212y) f\u00a8ur alle y, mit anderen Worten, die\nbeiden Zufallsvariablen\nX\u2212cund\u2212(X\u2212c) haben die gleiche Verteilung.\nWenn Xstetig verteilt ist mit Dichte f(x) und Verteilungsfunktion F(x), ist\ndie Symmetrie der Verteilung gleichbedeutend mit\nF(c\u2212y) = 1\u2212F(c+y) f\u00a8ur alle y\u22650. (2.6)\nDurch Di\ufb00erenzieren von (2.6) folgt\nf(c\u2212y) =f(c+y) f\u00a8ur alle y\u22650. (2.7)2.2. Verteilungsparameter 63\nUmgekehrt kann man leicht durch Integration zeigen, dass au s (2.7) wiederum\n(2.6) folgt, beide Bedingungen also in \u00a8aquivalenter Weise die Symmetrie einer\nstetigen Zufallsvariablen charakterisieren.\nBeispiel 2.9: Zwei Beispiele f \u00a8ur Dichten von symmetrischen Verteilungen \ufb01n-\ndet man in Abbildung 2.4 und 2.7. Die in Abbildung 2.4 dargest ellte Dichte\nist o\ufb00enbar symmetrisch zu c= 0, w\u00a8ahrend die Dichte in Abbildung 2.7 sym-\nmetrisch zu c= 180 ist; vgl. auch Beispiel 2.6. Die erste Dichte geh \u00a8ort zur\nKlasse der Normalverteilungen, die zweite zur Klasse der Re chteckverteilun-\ngen. Beides sind wichtige Klassen von symmetrischen Vertei lungen, die wir\nin den Abschnitten 2.4.1 und 2.4.4 ausf \u00a8uhrlich behandeln werden.\n2.2 Verteilungsparameter\nIn diesem Abschnitt wollen wir einige Gr \u00a8o\u00dfen einf \u00a8uhren, die die Verteilung ei-\nner Zufallsvariablen im Hinblick auf ihre Lage, Streuung un d Schiefe beschrei-\nben. Sie werden Verteilungsparameter genannt, da sie einerseits von der\nVerteilung abh \u00a8angen, andererseits die Verteilung unter bestimmten Aspek ten\ncharakterisieren.\n2.2.1 Erwartungswert\nAls Erstes soll die allgemeine Lage einer Zufallsvariablen Xbeschrieben wer-\nden. Ist Xdiskret, so ist die Verteilung von Xdurch die Gesamtheit der\nm\u00a8oglichen Werte xjund ihrer Wahrscheinlichkeiten pjgegeben. Ist Xstetig,\nso ist die Verteilung durch die Dichte f(x) bestimmt. Der Erwartungswert\nder Verteilung von Xist folgenderma\u00dfen de\ufb01niert3:\nE[X] =\uf8f1\n\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f3/summationtext\njxjpj, fallsXdiskret,\n\u221e/integraltext\n\u2212\u221exf(x)dx, fallsXstetig.\nMan schreibt auch E[X] =\u00b5X.\nBei einer diskreten Zufallsvariablen Xwerden also alle Werte xjaus dem\nTr\u00a8ager von Xmit den zugeh \u00a8origen Wahrscheinlichkeiten pj=P(X=xj)\ngewichtet und aufsummiert, bei einer stetigen Zufallsvari ablen tritt an die\nStelle der Summe ein Integral.\n3Es gibt Zufallsvariable (mit unendlichem Tr \u00a8ager), bei denen die den Erwartungswert\nde\ufb01nierende Summe bzw. das Integral einen unendlichen Wert ergeben oder \u00a8uberhaupt\nnicht konvergieren. Zum Beispiel besitzt die stetige Zufal lsvariable mit der Dichte f(x) =\n1\n\u03c0(1+x2), x\u2208R, keinen Erwartungswert, da das uneigentliche IntegralR\u221e\n\u2212\u221ex1\n\u03c0(1+x2)dx\nnicht konvergiert. Weitere Beispiele liefern die Pareto-V erteilungen in Abschnitt 2.4.3.64 2. Zufallsvariable und Verteilungen\nBeispiel 2.2 (Fortsetzung): Beim Roulette erh \u00a8alt man\n\u2022den dreifachen Einsatz, wenn man auf Colonne gesetzt hat (un d die\ngesetzte Colonne erscheint),\n\u2022den 36-fachen Einsatz, wenn man auf Zahl gesetzt hat (und die gesetzte\nZahl erscheint).\nDie Nettoauszahlung ist in beiden F \u00a8allen eine diskrete Zufallsvariable,\nXColonne =/braceleftbigg\n2,falls die Colonne erscheint,\n\u22121,falls nicht,\nbzw.\nXZahl=/braceleftbigg35,falls die Zahl erscheint,\n\u22121,falls nicht.\nF\u00a8ur die Erwartungswerte gilt\nE[XColonne ] = (\u22121)\u00b725\n37+ 2\u00b712\n37=\u22121\n37,\nE[XZahl] = (\u22121)\u00b736\n37+ 35\u00b71\n37=\u22121\n37.\nO\ufb00enbar stellt der Erwartungswert einer Zufallsvariablen Xnicht immer\neinen m \u00a8oglichen Wert von Xdar. So nimmt im Beispiel die Zufallsvariable\nXColonne nur die beiden Werte \u22121 und 2 an. Ihr Erwartungswert ist jedoch\nE[XColonne ] =\u22121\n37; er geh \u00a8ort nicht zum Tr \u00a8ager von XColonne .\nIstXeine stetige Zufallsvariable, so gilt P(X=x) = 0 f \u00a8ur alle x\u2208R.\nDie Berechnung des Erwartungswerts kann deshalb nicht wie b ei diskreten\nZufallsvariablen erfolgen. Vielmehr wird bei stetigen Zuf allsvariablen nach\nder obigen Formel jeder Wert xaus dem Tr \u00a8ager mit der Dichte f(x) gewichtet\nund dann integriert. Dabei kann man den Integrationsbereic h auf den Tr \u00a8ager\nbeschr \u00a8anken, da au\u00dferhalb des Tr \u00a8agers die Dichte gleich null ist.\nBeispiel 2.6 (Fortsetzung): Die Zufallsvariable Xhat die Dichte f(x) =1\n360,\nfalls0\u2264x\u2264360,f(x) = 0sonst. Ihr Erwartungswert ist\nE[X] =\u221e/integraldisplay\n\u2212\u221exf(x)dx=360/integraldisplay\n0x1\n360dx= 180 .\nErwartungswert einer transformierten Zufallsvariablen H\u00a8au\ufb01g be-\nn\u00a8otigt man nicht den Erwartungswert von Xselbst, sondern den einer trans-\nformierten Zufallsvariablen Y=g(X). Die Transformation kann beispiels-\nweise eine a\ufb03n-lineare Funktion Y=a+bX, eine Potenz wie Y=X2oder2.2. Verteilungsparameter 65\nY=X3oder eine Exponentialfunktion Y= exp Xsein. F \u00a8ur eine beliebige\nFunktion g:R\u2192Rberechnet man den Erwartungswert der transformierten\nZufallsvariablen Y=g(X) mit der Formel\nE[g(X)] =\uf8f1\n\uf8f4\uf8f4\uf8f2\n\uf8f4\uf8f4\uf8f3/summationtext\njg(xj)pj, fallsXdiskret,\n\u221e/integraltext\n\u2212\u221eg(x)fX(x)dx, fallsXstetig.\nBeispiel 2.2 (Fortsetzung): Wir betrachten die Zufallsvar iablen XColonne und\nXZahlsowie die Funktion g(x) =x2.Dann ist\nE/bracketleftbig\nX2\nColonne/bracketrightbig\n= (\u22121)2\u00b725\n37+ 22\u00b712\n37=73\n37= 1.97,\nE/bracketleftbig\nX2\nZahl/bracketrightbig\n= (\u22121)2\u00b736\n37+ 352\u00b71\n37=1261\n37= 34.08.\nBeispiel 2.6 (Fortsetzung):\na) F\u00a8ur die Zufallsvariable Xmit Dichte fX(x) =1\n360,falls0\u2264x\u2264360,gilt\nE[X2] =+\u221e/integraldisplay\n\u2212\u221ex2fX(x)dx=360/integraldisplay\n0x21\n360dx=1\n3601\n3x3/vextendsingle/vextendsingle/vextendsingle/vextendsingle360\n0= 43200 .\nb) Nachdem der Kandidat eine weitere Runde erreicht hat, bie tet ihm der\nShowmaster das folgende Spiel an: Wenn das Gl \u00a8ucksrad in der Stellung x\nstehen bleibt, erh \u00a8alt der Kandidat\n1000\u00b7exp/parenleft\uf8ecigx\n360/parenright\uf8ecig\ne\nausgezahlt. Wie hoch ist der Erwartungswert der Auszahlung ?\nDer Erwartungswert betr \u00a8agt\nE/bracketleftbigg\n1000\u00b7exp/parenleftbiggX\n360/parenrightbigg/bracketrightbigg\n=360/integraldisplay\n01000\u00b7exp/parenleft\uf8ecigx\n360/parenright\uf8ecig1\n360dx\n= 10001\n360360\u00b7exp/parenleft\uf8ecigx\n360/parenright\uf8ecig/vextendsingle/vextendsingle/vextendsingle/vextendsingle360\n0\n= 1000 e1\u22121000 = 1718 .28e.\nRechnen mit dem Erwartungswert Transformiert man die Werte der\nZufallsvariablen Xmit einer a\ufb03n-linearen Abbildung x/ma\u221asto\u2192a+b x, so erh \u00a8alt66 2. Zufallsvariable und Verteilungen\nman eine neue Zufallsvariable Ymit den Werten Y(\u03c9) =a+b X(\u03c9),\u03c9\u2208\u2126.\nDer Erwartungswert der transformierten Zufallsvariablen Y=a+bXist\ndann gleich\nE[a+bX] =a+b E[X]. (2.8)\nAnschaulich besagt die Formel (2.8), dass die Erwartungswe rtbildung mit der\nAddition einer Konstanten und der Multiplikation einer Zah l\u201dvertauscht\u201c\nwerden kann.\nBeweis Im Fall einer stetigen Variablen Xmit Dichte fgilt\nE[a+bX] =/integraldisplay\u221e\n\u2212\u221e(a+bx)f(x)dx=/integraldisplay\u221e\n\u2212\u221eaf(x)dx+/integraldisplay\u221e\n\u2212\u221ebxf(x)dx\n=a/integraldisplay\u221e\n\u2212\u221ef(x)dx+b/integraldisplay\u221e\n\u2212\u221exf(x)dx=a\u00b71 +b E[X].\nFallsXdiskret ist, ist auch a+bXeine diskrete Zufallsvariable und es gilt\nE[a+bX] =/summationdisplay\nj(a+bxj)pj=/summationdisplay\njapj+/summationdisplay\njbxjpj\n=a/summationdisplay\njpj+b/summationdisplay\njxjpj=a+b/summationdisplay\njxjpj\n=a+b E[X]. /square\nBeispiel 2.10: Die Zufallsvariable Xgebe das Bruttomonatsgehalt eines zu-\nf\u00a8allig ausgew \u00a8ahlten Angestellten einer Unternehmensholding wieder. Vo nX\nsei nur der Erwartungswert \u00b5X= 4700ebekannt. Tarifverhandlungen erga-\nben eine Lohnsteigerung um einen Sockelbetrag von 300eund eine zus \u00a8atz-\nliche lineare Erh \u00a8ohung von 3%. Das Bruttogehalt nach der Tariferh \u00a8ohung\nbetr\u00a8agtY= 300 + 1 .03X. Sein Erwartungswert betr \u00a8agt dann\nE[Y] = E[300 + 1 .03X] = 300 + 1 .03E[X]\n= 300 + 1 .03\u00b74700 = 5141e.\nEs ist hier nicht erforderlich, die Wahrscheinlichkeitsfu nktion der Zufallsva-\nriablen Yzu kennen.\nZentrierung Zieht man von einer Zufallsvariablen Xihren Erwartungs-\nwert ab, so erh \u00a8alt man die zentrierte Zufallsvariable X\u2212\u00b5X. Sie hat\nwegen (2.8) den Erwartungswert\nE[X\u2212\u00b5X] =\u00b5X\u2212\u00b5X= 0.\nWenn Xsymmetrisch zu einem bekannten Wert cverteilt ist und der Er-\nwartungswert existiert, gilt\nE[X] =c .2.2. Verteilungsparameter 67\nBeweis Die Symmetrie der Verteilung besagt (s.o. Abschnitt 2.1.7) , dass\nX\u2212cwie\u2212X+cverteilt ist, also auch den gleichen Erwartungswert besitz t.\nFolglich ist\nE[X\u2212c] = E[\u2212X+c],\nE[X]\u2212c=\u2212E[X] +c ,\n2E[X] = 2 c ,\nworaus die Behauptung E[X] =cfolgt. /square\nErwartungswert als Lageparameter Nicht nur f \u00a8ur symmetrische Ver-\nteilungen charakterisiert der Erwartungswert die Lage ein er Zufallsvariablen.\nWegen (2.8) gilt n \u00a8amlich: Wird die Zufallsvariable Xum die Konstante aauf\nder reellen Achse verschoben, so verschiebt sich der Erwart ungswert um die\ngleiche Konstante, E[a+X] =a+E[X]. Ein Verteilungsparameter, der diese\nEigenschaft besitzt, hei\u00dft lage\u00a8aquivariant . Wird Xmit einem Skalenfaktor\nb >0 multipliziert, so ist E[bX] =b E[X]. Ein Verteilungsparameter, der sich\num den gleichen Skalenfaktor \u00a8andert, wird skalen \u00a8aquivariant genannt.\nEinen Verteilungsparameter, der lage- und skalen \u00a8aquivariant ist, nennt man\neinenLageparameter . Demnach ist der Erwartungswert ein Lageparameter.\nWegen Gleichung (2.4) ist auch jedes Quantil xpvonXein Lageparameter,\ninsbesondere der Median x0.5.\nErwartungswert und Median sind nicht nur Lageparameter, si e beschreiben\nauch \u2013 in unterschiedlicher Weise \u2013 ein\u201dZentrum\u201c der Verteilung. Wenn die\nVerteilung symmetrisch zu einem Wert cist, sind beide gleich diesem Wert\nc. Im Allgemeinen sind Erwartungswert und Median jedoch vers chieden.\nWeitere Zentralit \u00a8atseigenschaften des Erwartungswerts h \u00a8angen mit der Vari-\nanz der Zufallsvariablen zusammen. Sie werden im folgenden Abschnitt be-\nhandelt.\n2.2.2 Varianz\nNeben der Lage einer Zufallsvariablen, die durch den Erwart ungswert cha-\nrakterisiert wird, ist ihre Streuung von besonderem Intere sse. Sie wird durch\ndie Varianz beschrieben. Die Varianz vonX,\nV[X] =E/bracketleft\uf8ecig\n(X\u2212\u00b5X)2/bracketright\uf8ecig\n,\nist der Erwartungswert der Zufallsvariablen g(X) = (X\u2212\u00b5X)2,also der Er-\nwartungswert der quadrierten Abweichung der Zufallsvaria blenXvon ihrem68 2. Zufallsvariable und Verteilungen\nErwartungswert \u00b5X.F\u00a8ur diskrete bzw. stetige Verteilungen ist die Varianz\ndurch die Formeln\nV[X] =\uf8f1\n\uf8f4\uf8f2\n\uf8f4\uf8f3/summationtext\nj(xj\u2212\u00b5X)2pj, fallsXdiskret,\n\u221e/integraltext\n\u2212\u221e(x\u2212\u00b5X)2fX(x)dx, fallsXstetig ,\ngegeben. O\ufb00enbar kann die Varianz keinen negativen Wert ann ehmen.4Die\npositive Wurzel aus der Varianz,\n\u03c3[X] = +/radicalbig\nV[X],\nhei\u00dftStandardabweichung . Weitere Notationen f \u00a8ur Standardabweichung\nund Varianz sind\n\u03c3X=\u03c3[X], \u03c32\nX=\u03c32[X] =V ar[X] =V[X].\nZur Berechnung der Varianz ist die folgende Formel n \u00a8utzlich:\nV[X] =E[X2]\u2212\u00b52\nX (2.9)\nIn (2.9) gen \u00a8ugt es, \u00b5Xsowie E[X2] zu berechnen, was meistens weniger Auf-\nwand als die Berechnung mit Hilfe der obigen De\ufb01nitionsform el erfordert.\nDer Beweis von (2.9) folgt aus\nE[(X\u2212\u00b5X)2] = E[X2]\u22122E[X\u00b7\u00b5X] +\u00b52\nX\n=E[X2]\u22122E[X]\u00b7\u00b5X+\u00b52\nX\n=E[X2]\u2212\u00b52\nX. /square\nBeispiel 2.2 (Fortsetzung): Wir betrachten wieder beim Rou lette die Zufallsva-\nriablen XColonne undXZahl.Beide haben den gleichen Erwartungswert \u22121\n37.\nF\u00a8ur die Varianzen ergibt sich\nV[XColonne ] = E[X2\nColonne ]\u2212(E[XColonne ])2\n=73\n37\u2212/parenleftbigg\n\u22121\n37/parenrightbigg2\n= 1.9722,\n\u03c3[XColonne ] = 1 .40,\nV[XZahl] = E[X2\nZahl]\u2212(E[XZahl])2\n=1261\n37\u2212/parenleftbigg\n\u22121\n37/parenrightbigg2\n= 34.0804,\n\u03c3[XZahl] = 5 .84.\n4Es gibt allerdings Zufallsvariable, bei denen diese Summe b zw. dieses Integral unendlich\ngro\u00df werden, also keine endliche Varianz existiert. Beispi ele sind die t-verteilten Variablen\nmit\u03bd\u22642 Freiheitsgraden (Abschnitt 4.3.2).2.2. Verteilungsparameter 69\nIn diesem Beispiel kann man die Varianzen (und Standardabwe ichungen) als\nRisikoma\u00dfe interpretieren. O\ufb00ensichtlich birgt ,,Setzen auf Zahl\u201c mehr Risi-\nko (im Sinne m \u00a8oglicher Schwankungen der Auszahlung nach oben wie nach\nunten!) als ,,Setzen auf Colonne\u201c.\nBeispiel 2.6 (Fortsetzung): Die Varianz des Ergebnisses Xberechnet man mit\nder Formel (2.9) als\nV[X] =E[X2]\u2212\u00b52\nX= 43 200\u22121802= 10 800 .\nDie Standardabweichung ist dann \u03c3[X] =\u221a\n10 800 = 103 .92.\nTransformiert man Xzur Zufallsvariablen Y=a+bX,a, b\u2208R, so\u00a8andern\nsich Varianz und Standardabweichung wie folgt:\nV[a+bX] = b2V[X],\n\u03c3[a+bX] =|b|\u03c3[X].(2.10)\nDies folgt sofort aus den De\ufb01nitionen und der Lage- und Skale n\u00a8aquivarianz\ndes Erwartungswerts:\nV[Y] = E[(Y\u2212\u00b5Y)2] =E[(b(X\u2212\u00b5X))2]\n=b2E[(X\u2212\u00b5X)2] =b2V[X]\nVarianz und Standardabweichung einer Zufallsvariablen we rden also durch\ndie Addition einer Konstanten nicht beein\ufb02usst; beide Vert eilungsparameter\nsindlageinvariant . Sie\u00a8andern sich, wenn Xmit einem positiven Skalenfak-\ntor multipliziert wird. Die Varianz multipliziert sich dan n mit dem Quadrat\ndes Faktors, w \u00a8ahrend sich die Standardabweichung mit dem Faktor selbst\nmultipliziert. Beide Verteilungsparameter messen demzuf olge die Streuung\nvonX. Die Standardabweichung ist skalen \u00a8aquivariant , die Varianz ist es\njedoch nicht.\nBeispiel 2.10 (Fortsetzung): Das Bruttomonatsgehalt Xhabe die Standard-\nabweichung \u03c3X= 950e.Nach einer allgemeinen Gehaltserh \u00a8ohung um einen\nSockelbetrag von 300eund3%linear betr \u00a8agt das Gehalt Y= 300 + 1 .03X.\nF\u00a8ur die Standardabweichung von Ygilt dann\n\u03c3Y=/radicalbig\nV[300 + 1 .03X] = 1 .03\u03c3X\n= 1.03\u00b7950 = 978 .5e.\nGenerell sind Varianz und Standardabweichung gr \u00a8o\u00dfer oder gleich null. Von\nInteresse ist der Fall der kleinsten Streuung, wenn also die Varianz (und damit\nauch die Standardabweichung) gleich null ist. Es l \u00a8asst sich zeigen, dass\nV[X] = 0\u21d0\u21d2 P(X=\u00b5X) = 170 2. Zufallsvariable und Verteilungen\ngilt, die Varianz von Xalso genau dann verschwindet, wenn X(mit Wahr-\nscheinlichkeit 1) konstant gleich seinem Erwartungswert i st.\nDie nachfolgende Minimaleigenschaft des Erwartungswerts rechtfertigt seine\nInterpretation als Schwerpunkt der Verteilung. Es ist\nmin\na\u2208RE[(X\u2212a)2] =E[(X\u2212\u00b5X)2], (2.11)\nd.h. der Erwartungswert ist der Punkt, von dem die mittlere q uadratische\nAbweichung der Zufallsvariablen minimal ist. Die Streuung der Verteilung\num einen Punkt aist also am kleinsten f \u00a8ura=\u00b5X.Der Begri\ufb00\u201dSchwer-\npunkt\u201c kommt aus der Physik; er erkl \u00a8art sich wie folgt: Wenn man die Wahr-\nscheinlichkeiten pjeiner diskreten Verteilung als Massen an den zugeh \u00a8origen\nPunkten xjder reellen Achse befestigt, so entspricht der Erwartungsw ert der\nVerteilung gerade dem physikalischen Schwerpunkt dieser P unktmassen.\nBeweis Der Beweis von (2.11) folgt aus\nE[(X\u2212a)2] = E[((X\u2212\u00b5X) + (\u00b5X\u2212a))2]\n=E[(X\u2212\u00b5X)2] +\n2E[(X\u2212\u00b5X)(\u00b5X\u2212a)]/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n=0+(\u00b5X\u2212a)2.\nDie rechte Seite (und damit auch die linke Seite) ist o\ufb00ensic htlich minimal,\nwenn man a=\u00b5Xw\u00a8ahlt. /square\n2.2.3 Ungleichung von Tschebysche\ufb00\nErwartungswert \u00b5Xund Varianz \u03c32\nXsind Parameter der Lage bzw. der Streu-\nung einer Zufallsvariablen X. Wir geben eine von \u03c32\nXabh\u00a8angige Mindestwahr-\nscheinlichkeit daf \u00a8ur an, dass Xin ein Intervall vorgegebener Breite f \u00a8allt, das\nseinen Erwartungswert symmetrisch umgibt.\nDieUngleichung von Tschebysche\ufb00 besagt, dass f \u00a8ur jede positive Zahl \u03b5\nP(|X\u2212\u00b5X|< \u03b5)\u22651\u2212\u03c32\nX\n\u03b52(2.12)\ngilt. Dies hei\u00dft, die Wahrscheinlichkeit f \u00a8ur das Ereignis\n{\u00b5X\u2212\u03b5 < X < \u00b5 X+\u03b5}\nl\u00a8asst sich durch die Schranke 1 \u2212(\u03c32\nX/\u03b52) nach unten absch \u00a8atzen. Die Wahr-\nscheinlichkeit, dass Xin das Intervall ] \u00b5X\u2212\u03b5, \u00b5X+\u03b5[ f\u00a8allt, ist also umso2.2. Verteilungsparameter 71\ngr\u00a8o\u00dfer, je kleiner \u03c32\nXist. O\ufb00enbar ist die Ungleichung nur f \u00a8ur\u03b52\u2265\u03c32\nXinter-\nessant, da sonst die rechte Seite negativ wird.\nAuch die Wahrscheinlichkeit des Komplement \u00a8arereignisses, dass Xnicht in\ndas angegebene Intervall f \u00a8allt, l\u00a8asst sich mit der Tschebysche\ufb00-Ungleichung\nabsch\u00a8atzen, und zwar nach oben wie folgt:\nP(|X\u2212\u00b5X|\u2265\u03b5)\u2264\u03c32\nX\n\u03b52. (2.13)\nBeweis Die Ungleichung (2.13) ist zur Ungleichung (2.12) \u00a8aquivalent. Um\nUngleichung (2.13) einzusehen, de\ufb01nieren wir eine neue Zuf allsvariable Z, die\ndurch\nZ(\u03c9) =/braceleft\uf8ecigg\n\u03b52,falls|X(\u03c9)\u2212\u00b5X|\u2265\u03b5,\n0 sonst,\ngegeben ist. O\ufb00enbar gilt\nZ(\u03c9)\u2264(X(\u03c9)\u2212\u00b5X)2,\nE[Z]\u2264E[(X\u2212\u00b5X)2] =\u03c32\nX,\nE[Z] = \u03b52\u00b7P(|X\u2212\u00b5X|\u2265\u03b5).\nAlso ist\nP(|X\u2212\u00b5X|\u2265\u03b5)\u2264\u03c32\nX\n\u03b52,\nwie behauptet. /square\nBeispiel 2.11: Sei Xdie Verweildauer (in Tagen) eines zuf \u00a8allig ausgew \u00a8ahlten\nPatienten in einem Gro\u00dfklinikum. Erwartungswert \u00b5X= 10und Standard-\nabweichung \u03c3X= 4seien bekannt. Wie gro\u00df ist mindestens die Wahrschein-\nlichkeit, dass der Patient mehr als f \u00a8unf, aber weniger als f \u00a8unfzehn Tage im\nKrankenhaus verbringt? Es ist\nP(5< X < 15) = P(|X\u221210|<5)\u22651\u221242\n52=9\n25.\nSetzt man \u03b5=\u03bb\u03c3X(mit einem \u03bb >1), so ergeben sich zwei \u00a8aquivalente\nVersionen der Tschebysche\ufb00-Ungleichung,\nP(|X\u2212\u00b5X|< \u03bb\u03c3 X)\u22651\u22121\n\u03bb2 bzw.\nP(|X\u2212\u00b5X|\u2265\u03bb\u03c3X)\u22641\n\u03bb2.\nDie zweite Ungleichung erh \u00a8alt man aus der ersten, indem man zum Komple-\nment\u00a8arereignis \u00a8ubergeht. O\ufb00enbar kann man in der ersten Ungleichung das\n\u201d<\u201c-Zeichen durch\u201d\u2264\u201c ersetzen, da sich hierdurch die Wahrscheinlichkeit\nnicht verringert.72 2. Zufallsvariable und Verteilungen\nF\u00a8ur\u03bb= 2 und \u03bb= 3 erhalten wir Absch \u00a8atzungen f \u00a8ur die Wahrscheinlichkeit,\ndassXin den so genannten Zwei- bzw.Drei-Sigma-Bereich f\u00a8allt, n \u00a8amlich\nP\uf8eb\n\uf8ec\uf8ed\u00b5X\u22122\u03c3X< X < \u00b5 X+ 2\u03c3X/bracehtipupleft/bracehtipdownright/bracehtipdownleft /bracehtipupright\nZwei-Sigma-Bereich\uf8f6\n\uf8f7\uf8f8\u22653\n4,\nP\uf8eb\n\uf8ec\uf8ed\u00b5X\u22123\u03c3X< X < \u00b5 X+ 3\u03c3X/bracehtipupleft/bracehtipdownright/bracehtipdownleft /bracehtipupright\nDrei-Sigma-Bereich\uf8f6\n\uf8f7\uf8f8\u22658\n9.\nDies sind sehr grobe Absch \u00a8atzungen, die f \u00a8ur beliebige Verteilungen gelten.\nSie lassen sich verfeinern, wenn weitere Informationen \u00a8uber die Verteilung\nvorliegen, etwa wenn man voraussetzen kann, dass Xnormalverteilt ist (vgl.\nAbschnitt 2.4.4).\nBeispiel 2.12: Die Verteilung von Xbeschreibe die Verteilung des Bruttomo-\nnatseinkommens in einer Gemeinde (in e). Es sei \u00b5X= 2500 und\u03c3X= 750\nbekannt. Dann liegen mindestens 75% der Einkommen zwischen 1000eund\n4000e. Mindestens 8/9\u00b7100% der Einkommen liegen zwischen 250eund\n4750e.\n2.2.4 Schiefe und W \u00a8olbung\nNeben Ma\u00dfzahlen zur Charakterisierung der Lage und Streuun g der Vertei-\nlung einer Zufallsvariablen Xgibt es noch solche, die die Form der Verteilung\ncharakterisieren, so genannte Formparameter , auch Gestaltparameter\ngenannt.\nSchiefe Von Bedeutung ist hier zun \u00a8achst die Abweichung der Verteilung\nvon einer symmetrischen Verteilung gleicher Lage und Streu ung. Im Folgen-\nden betrachten wir zwei Ma\u00dfe f \u00a8ur diese Abweichung. Als Momentenschiefe ,\nkurz:Schiefe , de\ufb01niert man\n\u03b31[X] =E/bracketleft\uf8ecigg/parenleftbiggX\u2212\u00b5X\n\u03c3X/parenrightbigg3/bracketright\uf8ecigg\n=E[(X\u2212\u00b5X)3]\n\u03c33\nX.\nEs gilt\n\u03b31[X] =E[X3]\u22123E[X2]\u00b5X+ 3E[X]\u00b52\nX\u2212\u00b53\nX\n\u03c33\nX\n=E[X3]\u22123E[X2]\u00b5X+ 2\u00b53\nX\n\u03c33\nX.2.2. Verteilungsparameter 73\nIst die Verteilung von Xsymmetrisch zu c, so gilt \u00b5X=cund man sieht\nleicht, dass die Verteilung von ( X\u2212\u00b5X)3und\u2212(X\u2212\u00b5X)3\u00a8ubereinstimmt.\nDaraus folgt, dass bei einer symmetrischen Verteilung E[(X\u2212\u00b5X)3] = 0 und\ndamit \u03b31[X] = 0 ist.\nMan beachte, dass die Umkehrung nicht gilt: Aus \u03b31[X] = 0 kann nicht die\nSymmetrie der Verteilung von Xgefolgert werden. Ist \u03b31[X]/\\e}atio\\slash= 0, so ist die\nVerteilung asymmetrisch, wobei man\nbei\u03b31[X]>0 vonRechtsschiefe (d.h.Linkssteilheit ),\nbei\u03b31[X]<0 vonLinksschiefe (d.h.Rechtssteilheit )\nspricht. Im ersten Fall \u00a8uberwiegen gr \u00a8o\u00dfere positive Werte von X\u2212\u00b5X, im\nzweiten Fall gr \u00a8o\u00dfere negative Werte; vgl. Abbildung 2.11 und 2.12. \u03b31[X] ist\nnicht normiert, sondern kann prinzipiell beliebige Werte a nnehmen.\n0 1 2 3 4 5 6 7 800.10.20.3\nxf(x)\n-6\n................................................................. ................................................. ............................ .................... ............... ............ .......... ......... ......... . .. .. .. . . . . . . . .. .. .. .. . . .... ... . ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ......... ... ...... ......... . ........ .. ....... . ..... ... ... ..... . ..... .... . .... ... . .... ... .. .... .... . .... ... .. .... .. .. ... ... .. ... ... . .. ... .. .. ... .. . ... .. ... . .. .. ... . .. .. .. . .. ... .. . .. .. .. .. . .. .. .. . .. . .. .. . .. .. .. . . .. .. .. . . .. .. .. . . .. .. . .. . .. . .. . .. . .. . .. . . .. . .. .. .\nAbbildung 2.11: Dichtefunktion einer stetigen rechtsschi efen Verteilung\nIm Gegensatz zur Momentenschiefe ist die Quartilsschiefe \u03b3Q\n1[X] beschr \u00a8ankt.\nIhre De\ufb01nition lautet\n\u03b3Q\n1[X] =[Q(0.75)\u2212Q(0.5)]\u2212[Q(0.5)\u2212Q(0.25)]\n[Q(0.75)\u2212Q(0.5)] + [ Q(0.5)\u2212Q(0.25)]\n=Q(0.75) + Q(0.25)\u22122\u00b7Q(0.5)\nQ(0.75)\u2212Q(0.25),(2.13)\nwobei Q(p) dasp-Quantil der Verteilung von Xbezeichnet. F \u00a8ur beliebige X\ngilt\n\u22121\u2264\u03b3Q\n1[X]\u22641.74 2. Zufallsvariable und Verteilungen\n0 2 4 6 8 10x 0.000.050.100.150.200.250.30P(X=x)\n-6\nt t t ......................t\n......................................................t\n...........................................................................................................t\n......................................................................................................................................................................................................................t\n.................................................................................................................................................................................................................................................................................................t\n......................................................................................................................................................................................................................................................t\n.................................................................................................................................t\n.................................t\nAbbildung 2.12: Wahrscheinlichkeitsfunktion einer diskr eten linksschiefen Vertei-\nlung\nIm Fall einer symmetrischen Verteilung ist Q(0.75)\u2212Q(0.5) = Q(0.5)\u2212\nQ(0.25), also \u03b3Q\n1[X] ebenfalls gleich null. Die Umkehrung gilt auch hier nicht:\nAus\u03b3Q\n1[X] = 0 kann nicht auf die Symmetrie der Verteilung von Xgeschlos-\nsen werden. Wenn die Quartilsschiefe ungleich null ist, bez eichnet man die\nVerteilung als rechtsschief (wenn \u03b3Q\n1[X]>0) bzw. linkssschief (wenn\n\u03b3Q\n1[X]<0) im Sinne der Quartilsschiefe.\nWird Xa\ufb03n-linear transformiert, Y=a+bX, so\u00a8andert sich \u03b31o\ufb00enbar\nnicht, \u03b31[X] =\u03b31[Y]; ebenso gilt \u03b3Q\n1[X] =\u03b3Q\n1[Y]. Beide Ma\u00dfzahlen der Schie-\nfe sind daher sowohl lage- als auch skaleninvariant.\nW\u00a8olbung Ein weiterer, h \u00a8au\ufb01g untersuchter Gestaltparameter ist die W\u00a8ol-\nbung, die auch als Kurtosis bezeichnet wird. Sie ist durch\n\u03b32[X] =E/bracketleft\uf8ecigg/parenleftbiggX\u2212\u00b5X\n\u03c3X/parenrightbigg4/bracketright\uf8ecigg\n=E[(X\u2212\u00b5X)4]\n\u03c34\nX\nde\ufb01niert. Die W \u00a8olbung ist o\ufb00enbar lage- und skaleninvariant. F \u00a8ur beliebige\nXgilt\u03b32[X]\u22651. Der Wert \u03b32[X] = 1 ergibt sich f \u00a8ur eine Zufallsvariable\nXmit Zweipunktverteilung mit P(X=\u22121) = P(X= 1) =1\n2. Bei der\nNormalverteilung (siehe Abschnitt 2.4.4) gilt \u03b32[X] = 3. Die W \u00a8olbung ei-\nner symmetrischen unimodalen Verteilung misst, wie spitz d ie Dichte bzw.\ndie Wahrscheinlichkeitsfunktion um den Erwartungswert \u00b5Xherum verl \u00a8auft\nund wie viel Wahrscheinlichkeitsmasse auf den Flanken der V erteilung liegt.2.3. Spezielle diskrete Verteilungen 75\nSymmetrische unimodale Verteilungen mit einer W \u00a8olbung gr \u00a8o\u00dfer als 3 sind\nalso um \u00b5Xherum spitzer und haben mehr Masse auf den Flanken als die\nNormalverteilung. Die Ma\u00dfzahl \u03b32\u22123 wird als Exzess bezeichnet.\nDer Parameter \u03b32sollte nur f \u00a8ur solche Verteilungen berechnet werden, die\nsymmetrisch oder angen \u00a8ahert symmetrisch und unimodal sind, da die obige\nInterpretation bei anderen Verteilungen nicht zutri\ufb00t.\nBeispiele zur Berechnung der Momentenschiefe, der Quartil sschiefe und der\nW\u00a8olbung \ufb01nden sich in den Abschnitten 2.4.2 und 2.4.4 \u00a8uber spezielle stetige\nVerteilungen. Die \u00a8Ubersicht in Abschnitt 2.4.6 enth \u00a8alt die Momentenschiefe\nund die W \u00a8olbung von einigen weiteren, h \u00a8au\ufb01g angewandten Wahrscheinlich-\nkeitsverteilungen.\n2.3 Spezielle diskrete Verteilungen\nIn diesem Abschnitt behandeln wir einige diskrete Verteilu ngen, die zum\nKernbestand der Wahrscheinlichkeitsrechnung geh \u00a8oren, da sie bei den unter-\nschiedlichsten Anwendungen auftreten.\nDie drei zun \u00a8achst beschriebenen Verteilungen treten im Zusammenhang m it\nder Bernoulli-Versuchsreihe auf. Ein Zufallsexperiment, bei dem man sich\nnur daf \u00a8ur interessiert, ob ein Ereignis Aeintritt oder nicht, nennt man ein\nBernoulli-Experiment . Das Eintreten von Awird auch als Erfolg , das\nEintreten von AalsMisserfolg bezeichnet. Eine Bernoulli-Versuchsreihe\nist die n-malige unabh \u00a8angige Durchf \u00a8uhrung eines Bernoulli-Experiments; vgl.\nAbschnitt 1.3.4. Sei Aidas Ereignis, dass beim i-ten Experiment ein Erfolg\neintritt, und sei \u03c0=P(Ai) f\u00a8uri= 1,2, . . ., n . Die Ereignisse A1, A2, . . ., A n\nwerden als global unabh \u00a8angig angenommen. Die Indikatorvariable\n1Ai=/braceleftbigg1,fallsAieintritt (\u201dErfolg\u201c),\n0,fallsAinicht eintritt (\u201dMisserfolg\u201c),\nist eine Zufallsvariable, die anzeigt, ob Aieintritt oder nicht.\nBeispiel 2.13: Ein fairer W \u00a8urfel werde n-mal geworfen. Sei Adas Ereignis,\neine\u201d6\u201c zu w \u00a8urfeln, Aider Erfolg beim i-ten Wurf. Wenn die Ereignisse\nAiglobal unabh \u00a8angig sind, handelt es sich um eine Bernoulli-Versuchsreih e.\nMan kann zeigen, dass die Aigenau dann global unabh \u00a8angig sind, wenn keine\nder m\u00a8oglichen Folgen von Augenzahlen bevorzugt auftritt, d.h. j ede die gleiche\nWahrscheinlichkeit besitzt; vgl. Beispiel 1.26 .\nEin Grundmodell, an dem viele Begri\ufb00e der Wahrscheinlichke itsrechnung\nerl\u00a8autert werden k \u00a8onnen, ist das folgende Urnenmodell : Eine Urne ist ein76 2. Zufallsvariable und Verteilungen\nmit Kugeln gef \u00a8ullter Beh \u00a8alter, aus dem einzelne Kugeln in zuf \u00a8alliger Weise\ngezogen werden. Die Ziehungswahrscheinlichkeit ist f \u00a8ur jede Kugel die gleiche.\nSpeziell enthalte eine Urne NKugeln, von denen Mrot und N\u2212Mwei\u00df\nsind. Nacheinander werden insgesamt nKugeln aus der Urne gezogen. Sei\nAidas Ereignis, dass die i-te Ziehung eine rote Kugel erbringt. Jede einzelne\nsolche Ziehung ist o\ufb00enbar ein Bernoulli-Experiment.\nBeimZiehen mit Zur \u00a8ucklegen wird die gezogene Kugel jedes Mal wieder\nin die Urne gelegt und mit den \u00a8ubrigen Kugeln gemischt, so dass jede weitere\nZiehung das gleiche Zufallsexperiment wie die erste Ziehun g darstellt. Daher\nk\u00a8onnen die Ereignisse A1, . . ., A nals global unabh \u00a8angig angesehen werden.\nDas Ziehen mit Zur \u00a8ucklegen ist deshalb eine Bernoulli-Versuchsreihe mit\n\u03c0=P(Ai) =M\nNf\u00a8ur alle i= 1,2, . . ., n .\nIm Unterschied dazu besteht das Ziehen ohne Zur \u00a8ucklegen ausnZiehun-\ngen, bei denen eine Kugel gezogen, aber nicht wieder in die Ur ne zur \u00a8uckgelegt\nwird. Da der Anteil der roten Kugeln in der Urne bei einer Zieh ung davon\nabh\u00a8angt, wie viele rote Kugeln in den vorhergehenden Ziehungen gezogen\nwurden, sind die Ereignisse A1, . . . , A nnicht unabh \u00a8angig, und das Ziehen\nohne Zur \u00a8ucklegen ist keine Bernoulli-Versuchsreihe.\n2.3.1 Binomialverteilung\nWir gehen von einer Bernoulli-Versuchsreihe aus und betrac hten die Zufalls-\nvariable\nX=n/summationdisplay\ni=11Ai.\nO\ufb00enbar kann Xdie Werte 0 ,1,2, . . ., n annehmen. Die Zufallsvariable X\nz\u00a8ahlt die eingetretenen Ereignisse Ai, sie gibt an, wie oft bei der n-maligen\nunabh \u00a8angigen Durchf \u00a8uhrung des Bernoulli-Experiments ein Erfolg aufgetre-\nten ist.\nBeispiel 2.14: F \u00a8ur eine Bernoulli-Versuchsreihe der L \u00a8angen= 4gebe man\nalle m\u00a8oglichen Folgen von Ergebnissen an, bei denen genau zwei Erf olge ein-\ntreten.Dies sind o\ufb00ensichtlich die Folgen:2.3. Spezielle diskrete Verteilungen 77\nA1, A2,A3,A4\nA1,A2, A3,A4\nA1,A2,A3, A4\nA1, A2, A3,A4\nA1, A2,A3, A4\nA1,A2, A3, A4\nEs sind/parenleftbig4\n2/parenrightbig\n= 6verschiedene Folgen.\nBei einer Bernoulli-Versuchsreihe der L \u00a8angengibt es/parenleftbign\nk/parenrightbig\nFolgen, bei de-\nnen genau k-mal ein Erfolg eintritt. Da zu kErfolgen jeweils n\u2212kMiss-\nerfolge geh \u00a8oren, ist die Wahrscheinlichkeit jeder dieser Folgen (wege n der\nUnabh \u00a8angigkeit der Wiederholungen) gleich\n\u03c0k(1\u2212\u03c0)n\u2212k.\nDaraus folgt\nP(X=x) =/parenleftbiggn\nx/parenrightbigg\n\u03c0x(1\u2212\u03c0)n\u2212xf\u00a8urx= 0,1, . . ., n . (2.14)\nEine diskrete Zufallsvariable Xmit dieser Wahrscheinlichkeitsfunktion hei\u00dft\nbinomialverteilt mit den Parametern nund\u03c0, in Zeichen: X\u223cB(n, \u03c0).\nDie Verteilung B(n, \u03c0) von Xhei\u00dftBinomialverteilung , ihr Tr \u00a8ager ist\nTX={0,1, . . ., n}.Abbildung 2.12 zeigt die Wahrscheinlichkeitsfunktion der\nBinomialverteilung mit n= 10 und \u03c0= 0.7.\nDie Gesamtheit der Binomialverteilungen B(n, \u03c0) mitn\u2208Nund\u03c0\u2208]0,1[ bil-\ndet eine Verteilungsfamilie , in der die einzelne Verteilung durch die beiden\nParameter nund\u03c0charakterisiert ist.\nIm Spezialfall n= 1, d.h., wenn X\u223cB(1, \u03c0), hei\u00dft XBernoulli-verteilt .\nIn diesem Fall gilt\nP(X= 1) = \u03c0 ,\nP(X= 0) = 1\u2212\u03c0 .\nBeispiel 2.15 (Ziehen mit Zur \u00a8ucklegen): Eine Urne enth \u00a8alt zehn Kugeln, da-\nvon drei rote. Es werden drei Kugeln mit Zur \u00a8ucklegen gezogen. Wie gro\u00df ist\ndie Wahrscheinlichkeit, mindestens zwei rote Kugeln zu zie hen?\nBezeichne Xdie Anzahl der roten Kugeln unter den drei gezogenen Kugeln.\nDann ist ( \u0592\u2192Calc/SPSS)\nX\u223cB/parenleftbigg\nn= 3, \u03c0=3\n10= 0.3/parenrightbigg78 2. Zufallsvariable und Verteilungen\n0 1 2 30.00.10.20.30.40.5\nxP(X=x)\n-6\n..........................................................................................................................\n.............................................................................................................................................................\n....................................................................\n..........tt\nt\nt\n0 1 2 3x 0.00.51.0FX(x) =P(X\u2264x)\n-6\nttt t\nAbbildung 2.13: Wahrscheinlichkeitsfunktion und Verteil ungsfunktion\nvonB(n= 3, \u03c0= 0.3) im Beispiel 2.15 (Ziehen mit Zur \u00a8ucklegen)\nund\nP(X\u22652) = 1\u2212P(X= 0)\u2212P(X= 1)\n= 1\u2212/parenleftbigg3\n0/parenrightbigg\n\u00b70.30\u00b70.73\u2212/parenleftbigg3\n1/parenrightbigg\n\u00b70.31\u00b70.72= 0.216.\nErwartungswert und Varianz einerB(1, \u03c0)-verteilten Zufallsvariablen las-\nsen sich leicht direkt ausrechnen. Es ist\nE[X] = 1\u00b7\u03c0+ 0\u00b7(1\u2212\u03c0) =\u03c0 ,\nE[X2] = 12\u00b7\u03c0+ 02(1\u2212\u03c0) =\u03c0 ,\nund deshalb\nV[X] =E[X2]\u2212(E[X])2=\u03c0\u2212\u03c02=\u03c0(1\u2212\u03c0).\nF\u00a8ur eine B(n, \u03c0)\u2212verteilte Zufallsvariable Xgelten die Formeln\nE[X] =n\u03c0und V[X] =n\u03c0(1\u2212\u03c0). (2.15)\nWir beweisen sie hier nicht, da sie in einfacher Weise mit Hil fsmitteln des\nKapitels 3 hergeleitet werden k \u00a8onnen.\nTabellen Da sich f \u00a8ur gr\u00a8o\u00dfere ndie Wahrscheinlichkeiten der Binomialver-\nteilung nur umst \u00a8andlich\u201dvon Hand\u201c berechnen lassen, sind in Tabelle 1 im\nAnhang dieses Buchs die Wahrscheinlichkeiten P(X=x) f\u00a8urX\u223cB(n, \u03c0)\nundn= 1,2, . . .,15,20,30 sowie \u03c0= 0.05,0.10, . . . , 0.50 tabelliert. F \u00a8ur\n\u03c0 >0.5 benutzt man die Beziehung\nX\u223cB(n, \u03c0)\u21d0\u21d2 n\u2212X\u223cB(n, \u03c0\u2032= 1\u2212\u03c0).2.3. Spezielle diskrete Verteilungen 79\nBeweis Wenn Xdie Zahl der\u201dErfolge\u201c Aieiner Bernoulli-Versuchsreihe\nbeschreibt, dann beschreibt die Zufallsvariable Y=n\u2212Xn\u00a8amlich die Zahl\nder\u201dMisserfolge\u201c Ai. Die Unabh \u00a8angigkeit der Folge A1, . . . , A nzieht die Un-\nabh\u00a8angigkeit der Folge A1, . . .,Annach sich. Es gilt P(Ai) = 1\u2212\u03c0f\u00a8ur\ni= 1, . . ., n . Also handelt es sich bei den Aiebenfalls um eine Bernoulli-\nVersuchsreihe, und Y=n\u2212Xist binomialverteilt mit den Parametern n\nund\u03c0\u2032= 1\u2212\u03c0. /square\nBeispiel 2.16: Es sei X\u223cB(n= 10, \u03c0= 0.8).Man bestimme P(X\u22659).Die\ngesuchte Wahrscheinlichkeit betr \u00a8agt\nP(X\u22659) = P(X= 9) + P(X= 10)\n=P(Y= 1) + P(Y= 0)\n= 0.2684 + 0 .1074 = 0 .3758,\nwobei f \u00a8urY=n\u2212X\u223cB(n= 10, \u03c0\u2032= 0.2)die Werte der Tabelle 1 verwendet\nwurden.\n2.3.2 Poisson-Verteilung\nWir gehen wieder von einer Bernoulli-Versuchsreihe aus, tr e\ufb00en aber spezielle\nAnnahmen \u00a8uber die Parameter nund\u03c0. Wir nehmen an, dass das Bernoulli-\nExperiment sehr h \u00a8au\ufb01g wiederholt wird, nalso gro\u00df ist. Andererseits sei die\nWahrscheinlichkeit \u03c0=P(A) f\u00a8ur einen Erfolg sehr klein. Awird deshalb ein\n\u201dseltenes Ereignis\u201c genannt. Die Anzahl Xder Erfolge bei nVersuchen ist\ndann binomialverteilt, X\u223cB(n, \u03c0),mit\nP(X=x) =/parenleftbiggn\nx/parenrightbigg\n\u03c0x(1\u2212\u03c0)n\u2212xf\u00a8urx= 0,1,2, . . ., n . (2.16)\nIn diesem Ausdruck l \u00a8asst man nun\n\u2022ngegen unendlich und zugleich\n\u2022\u03c0gegen null gehen, derart, dass n\u03c0gegen eine positive Zahl \u00b5konver-\ngiert.\nDie Binomialwahrscheinlichkeit (2.16) konvergiert bei di esem Grenz \u00a8ubergang,\nund zwar gegen\nlim\n\u03c0\u21920,n\u2192\u221e\nn\u03c0\u2192\u00b5/parenleftbiggn\nx/parenrightbigg\n\u03c0x(1\u2212\u03c0)n\u2212x=e\u2212\u00b5\u00b5x\nx!. (2.17)\nMan kann zeigen, dass der Limes f \u00a8ur jede nichtnegative ganze Zahl xde\ufb01niert\nund gr \u00a8o\u00dfer als null ist. F \u00a8ur die Exponentialfunktion gilt die Reihendarstellung\ne\u00b5= exp( \u00b5) =\u221e/summationdisplay\nk=0\u00b5k\nk!, \u00b5\u2208R.80 2. Zufallsvariable und Verteilungen\nSummiert man die rechte Seite der Gleichung (2.17) \u00a8uber alle x= 0,1,2, . . .,\nergibt sich deshalb (mit Summationsindex xstattk)\n\u221e/summationdisplay\nx=0e\u2212\u00b5\u00b5x\nx!=e\u2212\u00b5\u221e/summationdisplay\nx=0\u00b5x\nx!\n=e\u2212\u00b5e\u00b5=e0= 1.\nDer Limes de\ufb01niert also eine Wahrscheinlichkeitsfunktion . Eine diskrete Zu-\nfallsvariable Xmit der Wahrscheinlichkeitsfunktion\nP(X=x) =e\u2212\u00b5\u00b5x\nx!f\u00a8urx= 0,1,2, . . . ,\nheisstPoisson-verteilt5mit Parameter \u00b5 >0,in Zeichen: X\u223cPo(\u00b5). Der\nTr\u00a8ager von XistTX=N\u222a{0}={0,1,2, . . .}.\nTabellen Die Wahrscheinlichkeiten P(X=x) lassen sich leicht berechnen.\nF\u00a8ur Werte von \u00b5zwischen 0 .1 und 10 sind sie au\u00dferdem in Tabelle 2 des\nAnhangs tabelliert.\nF\u00a8ur kleine \u00b5zeigt die Poisson-Verteilung eine starke Asymmetrie (Rech ts-\nschiefe), w \u00a8ahrend die Verteilung f \u00a8ur gr\u00a8o\u00dfere \u00b5fast symmetrisch ist. Abbil-\ndung 2.14 illustriert dies anhand zweier Poisson-Verteilu ngen mit \u00b5= 2 bzw.\n\u00b5= 12.\nViele\u00a8okonomische und technische Sachverhalte k \u00a8onnen mit Poisson-verteilten\nZufallsvariablen beschrieben werden. Beispielsweise l \u00a8asst sich die Anzahl der\nin einem bestimmten Zeitraum ankommenden Kunden in einem Be dienungs-\nsystem h \u00a8au\ufb01g auf diese Weise modellieren; vgl. Abschnitt 3.3.2.\nDie Poisson-Verteilung Po(\u00b5) kann man wegen der erw \u00a8ahnten Limesbezie-\nhung als Approximation der Binomialverteilung B(n, \u03c0) f\u00a8ur kleines \u03c0\nund gro\u00dfes nau\ufb00assen. In diesem Fall gilt die N \u00a8aherung\n/parenleftbiggn\nx/parenrightbigg\n\u03c0x(1\u2212\u03c0)n\u2212x\u2248e\u2212\u00b5\u00b5x\nx!mit\u00b5=n\u03c0 .\nEine gebr \u00a8auchliche Faustregel lautet, dass die Approximation im konkreten\nFall als zul \u00a8assig angesehen werden kann, wenn die drei Bedingungen\n\u03c0\u22640.1, n\u226550 und n\u03c0\u22649\nerf\u00a8ullt sind.\nBeispiel 2.17: 50 S \u00a8auglinge erhalten eine bestimmte Impfung. Die Wahr-\nscheinlichkeit, dass ein S \u00a8augling die Impfung nicht vertr \u00a8agt, ist \u03c0= 0.05.\n5Sim\u00b4 eon Denis Poisson (1781\u20131840)2.3. Spezielle diskrete Verteilungen 81\n0 2 4 6 8 100.00.10.20.36\n-rr r\nr\nr\nrrrrr r xf(x)\nPo(2)\n0 5 10 15 20 250.00.10.20.36\n-xf(x)\nPo(12)\nr rrrrrrrrrrr rrrrrrrrrrrrr rr\nAbbildung 2.14: Wahrscheinlichkeitsfunktion der Poisson -Verteilung\nPo(\u00b5) mit \u00b5= 2 bzw. \u00b5= 12\nDie Reaktionen der einzelnen S \u00a8auglinge auf die Impfung sind unabh \u00a8angig\nvoneinander. Sei\nX=Anzahl der S \u00a8auglinge, die die Impfung nicht vertragen.\nMan berechne P( X= 0), P(X= 1), P(X= 2), P(X\u22653)exakt und approxi-\nmativ und vergleiche die Werte der Wahrscheinlichkeiten ( \u0592\u2192Calc/SPSS).\nEs gilt X\u223cB(n= 50, \u03c0= 0.05).Wegen \u03c0\u22640.1,n\u226550undn\u03c0= 2.5\u22649\nk\u00a8onnen wir die Verteilung von Xdurch die Poisson-Verteilung Po(\u00b5= 2.5)\napproximieren. Die exakten und gen \u00a8aherten Wahrscheinlichkeiten sind:\nB(n= 50, \u03c0= 0.05) Po(\u00b5= 2.5)\nP(X= 0) 0.0769 0.0821\nP(X= 1) 0.2025 0.2052\nP(X= 2) 0.2611 0.2565\nP(X\u22653) 0.4595 0.4562\nErwartungswert und Varianz einer Zufallsvariablen X\u223cPo(\u00b5) sind\nE[X] =\u00b5 , V [X] =\u00b5 .82 2. Zufallsvariable und Verteilungen\nSowohl der Erwartungswert einer Poisson-Verteilung als au ch ihre Varianz\nsind also gleich dem Parameter \u00b5der Verteilung. Dies macht man sich an-\nschaulich daran klar, dass die Po(\u00b5)-Wahrscheinlichkeiten die Grenzwerte\nvonB(n, \u03c0)-Wahrscheinlichkeiten sind. Erwartungswert und Varianz einer\njeden B(n, \u03c0)-Verteilung betragen n\u03c0bzw.n\u03c0(1\u2212\u03c0). Wegen n\u03c0\u2192\u00b5muss\nder Erwartungswert im Limes gleich \u00b5sein. Ebenso gilt wegen \u03c0\u21920 f\u00a8ur die\nVarianz die Limesbeziehung n\u03c0(1\u2212\u03c0)\u2192\u00b5. Dies l \u00a8asst sich auch exakt zeigen:\nBeweis Es gilt\nE[X] =\u221e/summationdisplay\nx=0xe\u2212\u00b5\u00b5x\nx!=e\u2212\u00b5\u221e/summationdisplay\nx=1x\u00b5x\nx!\n=e\u2212\u00b5\u221e/summationdisplay\nx=1\u00b5\u00b5x\u22121\n(x\u22121)!=\u00b5e\u2212\u00b5\u221e/summationdisplay\nx=0\u00b5x\nx!=\u00b5 .\nDie zweite dieser Gleichungen ergibt sich durch Weglassen d es ersten Sum-\nmanden (der gleich null ist), die vierte durch \u00a8Ubergang vom Summations-\nindex x(beginnend mit eins) zum Summationsindex x\u22121 (beginnend mit\nnull).\nUm die Varianz von X\u223cPo(\u00b5) zu bestimmen, berechnen wir zun \u00a8achst\nE[X2],\nE[X2] =\u221e/summationdisplay\nx=0x2e\u2212\u00b5\u00b5x\nx!=e\u2212\u00b5\u221e/summationdisplay\nx=1x2\u00b5x\nx!\n=e\u2212\u00b5\u221e/summationdisplay\nx=1\u00b5x\u00b5x\u22121\n(x\u22121)!=\u00b5e\u2212\u00b5\u221e/summationdisplay\nx=0(x+ 1)\u00b5x\n(x)!\n=\u00b5/bracketleft\uf8ecigg\ne\u2212\u00b5\u221e/summationdisplay\nx=0x\u00b5x\nx!+e\u2212\u00b5\u221e/summationdisplay\nx=0\u00b5x\nx!/bracketright\uf8ecigg\n=\u00b5[\u00b5+ 1] = \u00b52+\u00b5\nHierbei erh \u00a8alt man wie oben die zweite Gleichung durch Weglassen des ers ten\nSummanden (der gleich null ist) und die vierte durch die glei che Umindizie-\nrung. Es folgt V[X] =E[X2]\u2212\u00b52\nX=\u00b52+\u00b5\u2212\u00b52=\u00b5. /square\n2.3.3 Geometrische Verteilung\nWir kehren zur \u00a8uck zur Bernoulli-Versuchsreihe und nehmen an, dass das\nzugrunde liegende Bernoulli-Experiment im Prinzip belieb ig oft wiederholt\nwerden kann. Es interessiert nun der Zeitpunkt des ersten\u201dErfolges\u201c, d.h.\ndes erstmaligen Eintretens des relevanten Ereignisses. Di e Zufallsvariable X2.3. Spezielle diskrete Verteilungen 83\ngebe an, beim wievielten Versuch das Ereignis erstmals eint ritt. Man kann X\nin der Form\nX= min/braceleft\uf8ecigg\nn/vextendsingle/vextendsingle/vextendsingle/vextendsingle/vextendsinglen/summationdisplay\ni=11Ai= 1/braceright\uf8ecigg\nschreiben. Der Tr \u00a8ager von Xumfasst o\ufb00ensichtlich die nat \u00a8urlichen Zahlen,\nTX=N. Wenn der erste Erfolg beim x-ten Versuch eintritt, gehen ihm genau\nx\u22121 Misserfolge voraus. Es ist\nP(X= 1) = \u03c0 ,\nP(X= 2) = \u03c0(1\u2212\u03c0),\nP(X= 3) = \u03c0(1\u2212\u03c0)2,usw.\nEine Zufallsvariable Xmit der Wahrscheinlichkeitsfunktion\nP(X=x) =\u03c0(1\u2212\u03c0)x\u22121f\u00a8urx\u2208N\nhei\u00dftgeometrisch verteilt mit Parameter \u03c0, in Zeichen: X\u223cG(\u03c0). Der\nTr\u00a8ager von XistTX=N.\n0 2 4 6 8 10 12 14 16 18 200.36\n-xf(x)\nrrrrrrrrrrrrrrrrrrrr\nAbbildung 2.15: Wahrscheinlichkeitsfunktion der geometr ischen Verteilung G(\u03c0),\n\u03c0=1\n6\nMan rechnet mit Hilfe der unendlichen geometrischen Reihe l eicht nach, dass\nsich die Wahrscheinlichkeiten insgesamt zu eins addieren:\n\u221e/summationdisplay\nx=1P(X=x) =\u221e/summationdisplay\nx=1\u03c0(1\u2212\u03c0)x\u22121=\u03c0\u00b71\n1\u2212(1\u2212\u03c0)= 1\nAus den Einzelwahrscheinlichkeiten von Xl\u00a8asst sich mit der endlichen geo-84 2. Zufallsvariable und Verteilungen\nmetrischen Reihe die Verteilungsfunktion bestimmen. An jeder der Stellen\nk= 1,2,3, . . .gilt\nF(k) =k/summationdisplay\ni=1\u03c0(1\u2212\u03c0)i\u22121= 1\u2212(1\u2212\u03c0)k,\nund allgemein f \u00a8ur beliebige x\u2208R\nF(x) =/braceleftbigg0, fallsx <1,\n1\u2212(1\u2212\u03c0)k,fallsk\u2264x < k + 1.\nBeispiel 2.18: Aus einer Urne mit 10Kugeln (davon 4rot und 6wei\u00df) wird\nmit Zur \u00a8ucklegen zuf \u00a8allig gezogen. Wie gro\u00df ist die Wahrscheinlichkeit, dass\na) bei der dritten Ziehung zum ersten Mal eine rote Kugel gezo gen wird,\nb) fr\u00a8uhestens bei der dritten Ziehung zum ersten Mal eine rote Kug el ge-\nzogen wird?\nMit\nX=Nummer der Ziehung, bei der zum ersten Mal\neine rote Kugel gezogen wird,\ngilt\nX\u223cG(\u03c0= 0.4).\nzu a) Es ist\nP(X= 3) = 0 .4\u00b70.62= 0.144.\nzu b) Es ist\n\u221e/summationdisplay\nx=3P(X=x) = 1\u2212P(X= 1)\u2212P(X= 2)\n= 1\u22120.4\u22120.4\u00b70.6 = 0 .36.\nErwartungswert undVarianz einer G(\u03c0)-verteilten Zufallsvariablen X\nsind\nE[X] =1\n\u03c0, V [X] =1\u2212\u03c0\n\u03c02.\nBeweis Der Erwartungswert von Xist die Summe einer unendlichen Rei-\nhe,\nE[X] =\u221e/summationdisplay\nk=1k\u03c0(1\u2212\u03c0)k\u22121.2.3. Spezielle diskrete Verteilungen 85\nEs gilt\nE[X]\n\u03c0=\u221e/summationdisplay\nk=1k(1\u2212\u03c0)k\u22121\n=\u221e/summationdisplay\nk=1(1\u2212\u03c0)k\u22121\n/bracehtipupleft/bracehtipdownright/bracehtipdownleft/bracehtipupright\n=1\n\u03c0+\u221e/summationdisplay\nk=1(k\u22121)(1\u2212\u03c0)k\u22121.\nDie erste Summe der letzten Gleichung ist eine geometrische Reihe; sie hat\nden Wert1\n1\u2212(1\u2212\u03c0)=1\n\u03c0. Wir untersuchen nun die zweite Summe:\n\u221e/summationdisplay\nk=1(k\u22121)(1\u2212\u03c0)k\u22121= (1\u2212\u03c0)\u221e/summationdisplay\nk=1(k\u22121)(1\u2212\u03c0)k\u22122\n= (1\u2212\u03c0)\u221e/summationdisplay\nk=2(k\u22121)(1\u2212\u03c0)k\u22122\n= (1\u2212\u03c0)\u221e/summationdisplay\nk=1k(1\u2212\u03c0)k\u22121\n= (1\u2212\u03c0)E[X]\n\u03c0\nMan erh \u00a8alt also\nE[X]\n\u03c0=1\n\u03c0+ (1\u2212\u03c0)\u00b7E[X]\n\u03c0\nund daraus E[X] =1\n\u03c0. Die Varianz wird auf \u00a8ahnliche Weise berechnet. /square\nMan beachte, dass der Erwartungswert umso gr \u00a8o\u00dfer ist, je kleiner \u03c0ist. Das\nleuchtet unmittelbar ein, denn bei kleinem \u03c0ist zu erwarten, dass es l \u00a8anger\nals bei gro\u00dfem \u03c0dauert, bis Aerstmals eintritt. \u00a8Ahnliches gilt f \u00a8ur die Varianz;\nsie ist umso gr \u00a8o\u00dfer, je kleiner \u03c0ist.\nBeispiel 2.19: Beim\u201dMensch- \u00a8Argere-Dich-Nicht\u201c-Spiel wird so lange gew \u00a8ur-\nfelt, bis die erste\u201d6\u201c erscheint. Die Zufallsvariable Xsei de\ufb01niert als die\nNummer des Wurfes, bei dem erstmals eine Sechs auftritt. Dan n istXgeo-\nmetrisch verteilt, X\u223cG(\u03c0)mit\u03c0=1\n6und es gilt E[X] = 6. Man ben \u00a8otigt\nalso im Durchschnitt sechs Versuche, um erstmals eine\u201d6\u201c zu w \u00a8urfeln.\nIn Teilen der Literatur wird die geometrische Verteilung et was anders de\ufb01-\nniert, n \u00a8amlich als Zahl Yder\u201dMisserfolge\u201c bis zum ersten Erfolg. O\ufb00enbar\nist dann Y=X\u22121, wobei Xim hier de\ufb01nierten Sinne geometrisch verteilt\nist. Es gilt\nP(Y=y) =\u03c0(1\u2212\u03c0)y.86 2. Zufallsvariable und Verteilungen\nDer Erwartungswert von Yist\nE[Y] =E[X\u22121] =E[X]\u22121 =1\n\u03c0\u22121 =1\u2212\u03c0\n\u03c0,\ndie Varianz ist\nV[Y] =V[X] =1\u2212\u03c0\n\u03c02.\n2.3.4 Hypergeometrische Verteilung\nZuf\u00a8alliges Ziehen mit Zur \u00a8ucklegen ist ein Beispiel f \u00a8ur eine Bernoulli-Versuchs-\nreihe, da bei jeder Wiederholung die gleiche Ausgangssitua tion vorliegt und\ndaher die\u201dErfolge\u201c der einzelnen Versuche global unabh \u00a8angig sind. Beim\nZiehen ohne Zur \u00a8ucklegen ist dies, wie wir jetzt sehen werden, nicht der Fall .\nWir betrachten wiederum Ziehungen aus einer Urne mit NKugeln, davon sei-\nenMrot und N\u2212Mwei\u00df. Es werden nKugeln nacheinander ohne Zur \u00a8uck-\nlegen und ohne Ber \u00a8ucksichtigung der Reihenfolge gezogen. Sei\nAi= bei der i-ten Ziehung wird eine rote Kugel gezogen.\nDann ist\nP(A1) =M\nN=\u03c0 ,\nP(A2) = P(A2|A1)\u00b7P(A1) +P(A2/vextendsingle/vextendsingleA1)\u00b7P(A1)\n=M\u22121\nN\u22121\u00b7M\nN+M\nN\u22121\u00b7N\u2212M\nN=M2\u2212M+MN\u2212M2\n(N\u22121)N\n=M(N\u22121)\n(N\u22121)N=M\nN=\u03c0 .\nA1undA2sind jedoch nicht unabh \u00a8angig, da\nP(A1\u2229A2) =M\nN\u00b7M\u22121\nN\u22121/\\e}atio\\slash=M\nN\u00b7M\nN=P(A1)\u00b7P(A2).\nWegen der fehlenden Unabh \u00a8angigkeit der Ziehungen ist das Ziehen ohne\nZur\u00a8ucklegen keine Bernoulli-Versuchsreihe. Wie beim Ziehen m it Zur\u00a8ucklegen\nkann man jedoch auch hier die Verteilung der Zufallsvariabl en\nX= Anzahl der bei nVersuchen gezogenen roten Kugeln\nherleiten. Da es nicht darauf ankommt, in welcher Reihenfol ge rote und wei\u00dfe\nKugeln gezogen werden, gibt es (vgl. Abschnitt 1.2.3)\n/parenleftbigN\nn/parenrightbig\nM\u00a8oglichkeiten, nKugeln aus NKugeln ohne Zur \u00a8ucklegen aus-\nzuw\u00a8ahlen,2.3. Spezielle diskrete Verteilungen 87\n/parenleftbigM\nx/parenrightbig\nM\u00a8oglichkeiten, xrote Kugeln aus Mroten Kugeln ohne Zur \u00a8ucklegen\nauszuw \u00a8ahlen,\n/parenleftbigN\u2212M\nn\u2212x/parenrightbig\nM\u00a8oglichkeiten, n\u2212xwei\u00dfe Kugeln aus N\u2212Mwei\u00dfen Kugeln\nohne Zur \u00a8ucklegen auszuw \u00a8ahlen.\nNach dem klassischen Wahrscheinlichkeitsbegri\ufb00 ergibt si ch daraus die Wahr-\nscheinlichkeitsfunktion:\nP(X=x) =/parenleftbigM\nx/parenrightbig\n\u00b7/parenleftbigN\u2212M\nn\u2212x/parenrightbig\n/parenleftbigN\nn/parenrightbigf\u00a8urx\u2208{0,1, . . ., n}\nmitx\u2264Mund\nn\u2212x\u2264N\u2212M .\nEine solche diskrete Zufallsvariable Xnennt man hypergeometrisch ver-\nteilt, in Zeichen: X\u223cH(n, N, M ).Die hypergeometrische Verteilung hat\ndrei Parameter, n, NundMmitn, N\u2208N,n\u2264N,M\u2208{0,1, . . ., N}.\nDabei kommt die Einschr \u00a8ankung x\u2264Mdadurch zustande, dass nicht mehr\nrote Kugeln gezogen werden k \u00a8onnen als in der Urne sind, und die Ein-\nschr\u00a8ankung n\u2212x\u2264N\u2212Mdadurch, dass nicht mehr wei\u00dfe Kugeln, als\nin der Urne vorhanden sind, gezogen werden k \u00a8onnen. Die Anzahl der gezo-\ngenen roten Kugeln ist demnach mindestens n\u2212(N\u2212M) und h \u00a8ochstens M,\nau\u00dferdem ist sie mindestens 0 und h \u00a8ochstens n. Der Tr \u00a8ager von Xist die\nMenge\nTX=/braceleftbig\nmax{0, n\u2212N+M}, . . .,min{n, M}/bracerightbig\n.\nBeispiel 2.20: Eine Warensendung enth \u00a8alt zehn elektronische Bauteile, von\ndenen drei defekt sind. Aus der Sendung werden zwei Bauteile zuf\u00a8allig und\nohne Zur \u00a8ucklegen entnommen und gepr \u00a8uft. Wie gro\u00df ist die Wahrscheinlich-\nkeit, dass darunter mindestens ein defektes Bauteil ist?\nSei\nX=Anzahl der defekten Bauteile unter den zwei entnommenen.\nDann gilt ( \u0592\u2192Calc/SPSS) X\u223cH(n= 2, N= 10, M= 3)und damit\nP(X\u22651) = 1\u2212P(X= 0) = 1\u2212/parenleftbig3\n0/parenrightbig/parenleftbig7\n2/parenrightbig\n/parenleftbig10\n2/parenrightbig=8\n15= 0.5333.88 2. Zufallsvariable und Verteilungen\n0 1 20.00.10.20.30.40.5\nxP(X=x)\n-6\n........................................................................................................................................................................................................\n........................................................................................................................................................................................................\n.............................t t\nt\n0 1 20.00.51.0\nxFX(x) =P(X\u2264x)\n-6\nttt\nAbbildung 2.16: Wahrscheinlichkeitsfunktion und Verteil ungsfunktion von H(n=\n2, N= 10, M= 3) im Beispiel 2.20 (Ziehen ohne Zur \u00a8ucklegen)\nF\u00a8urn= 1 stimmt die hypergeometrische Verteilung H(n= 1, N, M ) mit der\nBernoulli-Verteilung B(n= 1, \u03c0=M\nN)\u00a8uberein. F \u00a8urn >1 gibt es Unterschie-\nde zur Binomialverteilung, die sich durch den unterschiedl ichen Ziehungsmo-\ndus erkl \u00a8aren.\nApproximation Andererseits ist unmittelbar klar, dass dann, wenn sich\nviele Kugeln in der Urne be\ufb01nden und nur wenige Kugeln gezoge n werden,\nkein gro\u00dfer Unterschied zwischen dem Ziehen mit und ohne Zur \u00a8ucklegen be-\nsteht. F \u00a8ur jedes feste xundngilt die Grenzbeziehung\n/parenleftbigM\nx/parenrightbig/parenleftbigN\u2212M\nn\u2212x/parenrightbig\n/parenleftbigN\nn/parenrightbig\u2212\u2212\u2212\u2212\u2192\nN\u2192\u221e\nM\u2192\u221e\nM\nN\u2192\u03c0/parenleftbiggn\nx/parenrightbigg\n\u03c0x(1\u2212\u03c0)n\u2212x.\nDie Wahrscheinlichkeiten der hypergeometrischen Verteil ungH(n, N, M ) k\u00a8on-\nnen deshalb durch die einer Binomialverteilung B(n, \u03c0=M\nN) approximiert\nwerden. F \u00a8ur die Zul \u00a8assigkeit der Approximation im konkreten Fall ist die fol-\ngendeFaustregel \u00a8ublich:n\nN\u22640.05.Der Quotientn\nNhei\u00dftAuswahlsatz .\nBeispiel 2.21: Aus einer Urne mit 100 Kugeln (davon 50 roten) werden drei\nKugeln ohne Zur \u00a8ucklegen gezogen. Wie gro\u00df ist die Wahrscheinlichkeit, das s\ngenau eine rote unter den drei gezogenen Kugeln ist?\nMit\nX=Anzahl der roten Kugeln unter den drei gezogenen2.4. Spezielle stetige Verteilungen 89\ngiltX\u223cH(n= 3, N= 100 , M= 50) und deshalb\nP(X= 1) =/parenleftbig50\n1/parenrightbig/parenleftbig50\n2/parenrightbig\n/parenleftbig100\n3/parenrightbig= 0.3788.\nDa der Auswahlsatzn\nN=3\n100klein genug ist, d \u00a8urfen wir diese Wahrschein-\nlichkeit auch n \u00a8aherungsweise mithilfe der Binomialverteilung bestimmen . Es\ngiltM\nN=50\n100= 0.5und approximativ X\u223cB(n= 3, \u03c0= 0.5). Aus der\nBinomialverteilungstabelle (Tabelle 1 im Anhang) erhalte n wir P(X= 1)\u2248\n0.3750.\nErwartungswert undVarianz vonX\u223cH(n, N, M ) sind\nE[X] = nM\nN,\nV[X] = nM\nN/parenleftbig\n1\u2212M\nN/parenrightbigN\u2212n\nN\u22121.\nMit\u03c0=M\nNerhalten wir\nE[X] = n\u03c0 ,\nV[X] = n\u03c0(1\u2212\u03c0)N\u2212n\nN\u22121.\nW\u00a8ahrend es beim Erwartungswert keinen Unterschied zwischen dem Ziehen\nmit und ohne Zur \u00a8ucklegen gibt, verh \u00a8alt es sich mit der Varianz anders: Wegen\nN\u2212n\nN\u22121<1,fallsn >1,\nist die Varianz von Xbeim Ziehen ohne Zur \u00a8ucklegen kleiner als beim Ziehen\nmit Zur \u00a8ucklegen. Im Extremfall n=N, d.h. wenn alle Kugeln aus der Urne\nentnommen werden, gilt sogar V[X] = 0,denn dann ist P(X=M) = 1.\n2.4 Spezielle stetige Verteilungen\nIn diesem Abschnitt behandeln wir verschiedene stetige Ver teilungen, die zum\nKernbestand der Wahrscheinlichkeitsrechnung geh \u00a8oren und in vielen Anwen-\ndungen eine Rolle spielen. Anders als bei den diskreten Vert eilungen des Ab-\nschnitts 2.3, die s \u00a8amtlich aus dem Urnenmodell mit bzw. ohne Zur \u00a8ucklegen\nentwickelt werden konnten, liegen diesen stetigen Verteil ungen sehr unter-\nschiedliche Modellans \u00a8atze zugrunde. Einige von ihnen werden wir in sp \u00a8ateren\nAnwendungen erl \u00a8autern.90 2. Zufallsvariable und Verteilungen\n\u03b1 \u03b21\n\u03b2\u2212\u03b16\n-xf(x)\nt t\n\u03b1 \u03b216\n-xF(x)\n.................................................................................................................................................................................................................................................................\n.................................................................................................................................................................................................................................................................\n.................................................................................................................................................................................................................................................................\nAbbildung 2.17: Dichte und Verteilungsfunktion der Rechte ckverteilung R(\u03b1, \u03b2)\n2.4.1 Rechteckverteilung\nEine Zufallsvariable Xhei\u00dftrechteckverteilt mit Parametern \u03b1, \u03b2\u2208R,\n\u03b1 < \u03b2 , in Zeichen: X\u223cR(\u03b1, \u03b2),wenn sie die Dichte\nf(x) =/braceleftbigg1\n\u03b2\u2212\u03b1,falls\u03b1\u2264x\u2264\u03b2,\n0 sonst,\nbesitzt. Die Rechteckverteilung wird auch als uniforme Verteilung oder\nstetige Gleichverteilung bezeichnet.\nDer Tr \u00a8ager der Rechteckverteilung ist TX= [\u03b1, \u03b2]. Auf dem Intervall [ \u03b1, \u03b2] ist\ndie Verteilungsfunktion linear mit konstanter Steigung 1 /(\u03b2\u2212\u03b1), ansonsten\nist sie konstant, also (vgl. Abbildung 2.17)\nF(x) =\uf8f1\n\uf8f2\n\uf8f30,fallsx < \u03b1 ,\nx\u2212\u03b1\n\u03b2\u2212\u03b1,falls\u03b1\u2264x\u2264\u03b2,\n1,fallsx > \u03b2 .\nDie Rechteckverteilung R(\u03b1, \u03b2) ist dann ein sinnvolles Modell f \u00a8ur eine Zufalls-\nvariable X, wenn man wei\u00df, dass Xnur Werte zwischen \u03b1und\u03b2annimmt\nund innerhalb des Intervalls [ \u03b1, \u03b2] keine Werte\u201dbevorzugt\u201c auftreten. Dann\nh\u00a8angt die Wahrscheinlichkeit daf \u00a8ur, dass Xin ein Teilintervall von [ \u03b1, \u03b2] f\u00a8allt,\nnur von der L \u00a8ange des Teilintervalls ab und ist proportional dieser L \u00a8ange.\nBeispiel 2.22: Ein Autofahrer gibt seinen Wagen zur Inspekt ion und muss\ndeshalb mit der Stra\u00dfenbahn fahren. Er wei\u00df nur, dass die Z \u00a8uge im Zehn-\nMinuten-Rhythmus verkehren und geht zur Haltestelle, um au f den n \u00a8achsten2.4. Spezielle stetige Verteilungen 91\nZug zu warten. Sei Xseine Wartezeit an der Haltestelle (in Minuten). Wel-\nche Wahrscheinlichkeitsverteilung f \u00a8urXbietet sich an?\nO\ufb00enbar ist X\u223cR(\u03b1= 0, \u03b2= 10) eine plausible Annahme.\nBeispiel 2.6 (Fortsetzung): In dem Spiel des Fernseh-Showm asters bezeichne\nXden angezeigten Winkel in Grad bei Stillstand des Gl \u00a8ucksrads. Dann ist\nX\u223cR(\u03b1= 0, \u03b2= 360) eine sinnvolle Verteilungsannahme.\nUnter den Rechteckverteilungen ist die mit den Parametern \u03b1= 0 und \u03b2= 1\nvon besonderer Bedeutung. Eine Zufallsvariable Z\u223cR(0,1) hat die Dichte\nfZ(x) =/braceleftbigg1,falls 0\u2264x\u22641,\n0 sonst,\nund die Verteilungsfunktion\nFZ(x) =\uf8f1\n\uf8f2\n\uf8f30, falls x <0 ,\nx, falls 0\u2264x\u22641,\n1, falls x >1 .\nMan nennt ein solches Z\u223cR(0,1) auch standard-rechteckverteilt . Wir\nzeigen nun, dass eine a\ufb03n-lineare Transformation der Zufal lsvariablen Zwie-\nder rechteckverteilt ist. Sei \u03b1, \u03b2\u2208R, \u03b1 < \u03b2, und\nX=\u03b1+ (\u03b2\u2212\u03b1)Z .\nDann ist X\u223cR(\u03b1, \u03b2).\nBeweis Wegen der Formel (2.5) f \u00a8ur die Dichte einer a\ufb03n transformierten\nVariablen gilt\nf(x) =1\n\u03b2\u2212\u03b1fZ/parenleftbiggx\u2212\u03b1\n\u03b2\u2212\u03b1/parenrightbigg\n, x\u2208R.\nEs folgt\nf(x) =/braceleftbigg1\n\u03b2\u2212\u03b1,falls 0\u2264x\u2212\u03b1\n\u03b2\u2212\u03b1\u22641,d.h. falls \u03b1\u2264x\u2264\u03b2 ,\n0 sonst .\nAlso ist X\u223cR(\u03b1, \u03b2). /square\nWenn eine Zufallsvariable Xallgemein rechteckverteilt ist, d.h. X\u223cR(\u03b1, \u03b2),\nzeigt man entsprechend, dass die Zufallsvariable\nX\u2212\u03b1\n\u03b2\u2212\u03b1\u223cR(0,1)\nstandard-rechteckverteilt ist.92 2. Zufallsvariable und Verteilungen\nErwartungswert und Varianz DaX\u223cR(\u03b1, \u03b2) symmetrisch zur Mitte\ndes Intervalls [ \u03b1, \u03b2] verteilt ist, ist der Erwartungswert gleich dem Mittel-\npunkt des Intervalls,\nE[X] =\u03b1+\u03b2\n2.\nDie Varianz betr \u00a8agt\nV[X] =(\u03b2\u2212\u03b1)2\n12.\nBeweis Um die Varianz von Xzu bestimmen, berechnen wir zun \u00a8achst die\nVarianz einer standard-rechteckverteilten Zufallsvaria blenZ\u223cR(0,1).Es ist\nE[Z] =1\n2,\nE/bracketleftbig\nZ2/bracketrightbig\n=/integraldisplay1\n0z2\u00b71dz=z3\n3/vextendsingle/vextendsingle/vextendsingle/vextendsingle1\n0=1\n3,\nund daraus folgt\nV[Z] = E/bracketleftbig\nZ2/bracketrightbig\n\u2212(E[Z])2\n=1\n3\u2212/parenleftbigg1\n2/parenrightbigg2\n=1\n12.\nNach den Rechenregeln (2.8) und (2.10) f \u00a8ur Erwartungswert und Varianz\neiner a\ufb03n-linear transformierten Zufallsvariablen erhal ten wir\nV[X] = V[\u03b1+ (\u03b2\u2212\u03b1)Z] =V[(\u03b2\u2212\u03b1)Z]\n= (\u03b2\u2212\u03b1)2V[Z] =(\u03b2\u2212\u03b1)2\n12./square\nBeispiel 2.23: Bei der Produktion von Automobilen muss ein b estimmter Ar-\nbeitsgang per Hand ausgef \u00a8uhrt werden. Gehen Sie davon aus, dass die Dauer\nXdes Arbeitsganges mindestens sieben Minuten und h \u00a8ochstens zw \u00a8olf Minuten\nbetr\u00a8agt.\na) Berechnen Sie den Erwartungswert und die Standardabweic hung der\nDauer des Arbeitsganges X, indem Sie eine Rechteckverteilung unter-\nstellen.\nb) Bestimmen Sie die Quantilfunktion von Xund berechnen Sie den 90%-\nPunkt. Wie ist dieser zu interpretieren?2.4. Spezielle stetige Verteilungen 93\nzu a) Es ist \u03b1= 7,\u03b2= 12,\nE[X] =12 + 7\n2= 9.5 [Minuten ],\n/radicalbig\nV[X] =/radicalbigg\n(12\u22127)2\n12= 1.44 [Minuten ].\nzu b) Um die Quantilfunktion zu bestimmen, m \u00a8ussen wir\nF(x) =x\u22127\n12\u22127=p ,7\u2264x\u226412,\nf\u00a8ur0< p < 1nachxau\ufb02\u00a8osen. Es ist\nQ(p) =xp= 7 + 5 p .\nDer90%-Punkt ist Q(0.9) = 7 + 5\u00b70.9 = 11 .5 [Minuten ], d.h. mit Wahr-\nscheinlichkeit 0.9ist der Arbeitsgang nach 11.5Minuten beendet.\nWir zeigen nun eine wichtige Eigenschaft der Rechteckverte ilung, die man f \u00a8ur\ndie Monte-Carlo-Simulation (siehe Abschnitt 3.3.3) ben \u00a8otigt:\nSeiFeine vorgegebene Verteilungsfunktion und Qdie zugeh \u00a8orige Quantil-\nfunktion,\nQ(p) = min{x|F(x)\u2265p}.\nIstZeineR(0,1)-verteilte Zufallsvariable und X=Q(Z), dann hat Xdie\nVerteilungsfunktion F.\nBeweis Es gilt n \u00a8amlich f \u00a8ur jedes x\u2208R\nFX(x) = P(X\u2264x) =P(Q(Z)\u2264x)\n=P(F(Q(Z))\u2264F(x))\n=P(Z\u2264F(x)) =F(x)./square\nWenn Feine stetige Funktion ist, gilt dar \u00a8uber hinaus, dass\nF(X)\u223cR(0,1),\nd.h. dass F(X) eine Rechteckverteilung in [0 ,1] besitzt.\nBeweis F\u00a8urz\u2208[0,1] gilt\nFF(X)(z) = P(F(X)\u2264z) =P(Q(F(X))\u2264Q(z))\n=P(X\u2264Q(z)) = F(Q(z)) =z ./square94 2. Zufallsvariable und Verteilungen\n0 1 2 3\u03bb= 1\u03bb= 2\u03bb= 36\n-xf(x)\n... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. . ... ... ... ... ... . .. ... ... ... . .. ... ... . .. ... .. . ... ... . .. ... .. . ... .. . ... .. . ... . .. ... . .. .. . ... . .. ... . .. .. . ... . .. . .. .. . ... . .. .. . .. . ... . .. . .. .. . .. . ... . .. . .. . .. .. . .. . .. . .. . .. . .. . ... . .. . .. . .. . .. . .. . .. . .. . .. . .. . . . .. . .. . .. . .. . .. . .. . . .. . .. . .. . . . .. . .. . .. . . .. . .. . . . .. . .. . . .. . .. . . . .. . . .. . .. . . . .. . . .. . .. . . . .. . . .. . . . .. . . .. . . . .. . . .. . . . .. . .. . . . .. .. .. . .. . . . .. .. .. . .. .. . .. . . .. . . . .. .. .. .. . . .. .. .. .. .. . . .. . . .. .. . . .. . . .. .. .. .. .. . . .. .. .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. . . .. .. .. .. . . .. .. .. .. .. .. .. . . .. . . .. .. . . .. .. .. .. . . .. .. . . .. . . .. .. .. .. . . .. .. . . .. .. .. .. . . .. .. . . .. . . .. .. . . .. .. .. .. . . .. .. .. .. . . .. .. .. .. .. . . .. .. .. .. . . .. . . .. .. .. .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. ........ ...... ...... ...... ...... ...... ...... ...... ...... ...... ...... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... .... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. . ... ... ... . .. ... .. . ... .. . ... .. . ... . .. .. . ... . .. .. . ... . .. . .. .. . .. . ... . .. . .. . .. . .. . .. . .. . .. . .. . .. . .. . .. . .. . . . .. . .. . .. . . .. . .. . . . .. . .. . . .. . . . .. . . .. . . . .. . . .. . . . .. . .. .. . .. . . .. . . . .. .. . . .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. . . .. . . .. .. .. .. . . .. .. . . .. .. .. .. .. .. .. . . .. . . .. .. .. .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. .. .. . . .. .. . . .. .. .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. . . .. .. .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. .. .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. .. .. . . .. .. . . .. . . .. ............... ............. ............. ............ ............ ............ ........... ........... ........... .......... .......... .......... .......... ......... ......... ......... ......... ........ ........ ........ ........ ........ ....... ....... ....... ....... ....... ...... ...... ...... ...... ...... ...... ...... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... .... .... .... .... .... .... .... .... .... .... .... .... .... .... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. . ... ... . .. ... . .. ... . .. .. . ... . .. . .. .. . .. . .. . ... . .. . .. . .. . .. . . . .. . .. . .. . . .. . .. . . . .. . .. . . .. . . . .. . . .. . . . .. .. .. . .. . . . .. .. . . .. . . .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. . . .. .. . . .. . . .. .. . . .. .. .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. .. .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . . . .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. ..ttt\nAbbildung 2.18: Dichtefunktion der Exponentialverteilun gExp(\u03bb) mit Parameter\n\u03bb= 1,2 und 3\n2.4.2 Exponentialverteilung\nEine stetige Zufallsvariable Xnennt man exponentialverteilt mit Parame-\nter\u03bb >0,in Zeichen: X\u223cExp(\u03bb), falls ihre Dichte durch\nf(x) =/braceleftbigg0, falls x <0,\n\u03bbe\u2212\u03bbx, falls x\u22650,\ngegeben ist. Der Tr \u00a8ager von Xist demnach TX= [0,\u221e[.\nO\ufb00enbar ist fdie Ableitung der folgenden Verteilungsfunktion F,\nF(x) =/braceleftbigg0 , falls x <0,\n1\u2212e\u2212\u03bbx, falls x\u22650.\nDie Abbildungen 2.18 und 2.19 zeigen die Dichte bzw. die Vert eilungsfunktion\nvon Exponentialverteilungen mit verschiedenen Parameter n\u03bb. Wenn \u03bbgro\u00df\nist, be\ufb01ndet sich relativ viel Wahrscheinlichkeitsmasse i n der N \u00a8ahe von 0\nund die Dichte f \u00a8allt mit wachsendem xrasch ab. Wenn \u03bbklein ist, ist es2.4. Spezielle stetige Verteilungen 95\n0 1 2 3 416\n-xF(x)\n.... .... .... .... .... .... .... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. .. .. .. .. .. .. . . .. .. .. .. .. . . .. .. .. . . .. .. .. . . .. .. .. . . .. .. . . .. .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . . . .. . . .. . . .. . . . . .. . . .. . . . . .. . . . . .. . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . . . .. . . . . .. . . . . . . .. . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . . . .. . . . . . . . . .. . . . . . . .. . . . . . . . . . . .. . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . . . .. . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . .\n......... ......... ......... ........ ........ ........ ........ ....... ....... ....... ....... ....... ....... ...... ...... ...... ...... ...... ...... ..... ..... ..... ..... ..... ..... ..... ..... .... .... .... .... .... .... .... .... .... .... .... .... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. .. .. .. . . .. .. .. . . .. . . .. .. . . .. . . .. . . .. . . .. . . .. . . .. . . . . .. . . .. . . . . .. . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nt\u03bb= 3\n\u03bb= 1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nAbbildung 2.19: Verteilungsfunktion der Exponentialvert eilung Exp(\u03bb) f\u00a8ur\u03bb= 1\nund 3\numgekehrt: Es liegt relativ wenig Wahrscheinlichkeitsmas se bei null und die\nDichte f \u00a8allt mit wachsendem xnur langsam. Die Rolle von \u03bbkann auch an\nder Quantilfunktion demonstriert werden. Es ist (vgl. Absc hnitt 2.1.2)\nQ(p) =xp=\u22121\n\u03bbln(1\u2212p).\nF\u00a8ur jedes feste pist das p-Quantil xpalso umso kleiner, je gr \u00a8o\u00dfer\u03bbist. Der\nMedian x0.5betr\u00a8agt\nx0.5=\u2212ln 0.5\n\u03bb=0.6931\n\u03bb.\nErwartungswert undVarianz einer Zufallsvariablen X\u223cExp(\u03bb) sind\nE[X] =1\n\u03bb, V [X] =1\n\u03bb2.\nDer Erwartungswert und die Varianz sind also umso kleiner, j e gr\u00a8o\u00dfer\u03bbist.96 2. Zufallsvariable und Verteilungen\nBeweis Den Erwartungswert berechnet man mittels partieller Integ ration,\nE[X] =/integraldisplay\u221e\n\u2212\u221exf(x)dx=/integraldisplay\u221e\n0x\u00b7(\u03bbe\u2212\u03bbx)dx\n=\u2212x e\u2212\u03bbx/vextendsingle/vextendsingle\u221e\n0+/integraldisplay\u221e\n01\u00b7e\u2212\u03bbxdx\n=\u2212x e\u2212\u03bbx/vextendsingle/vextendsingle\u221e\n0\u22121\n\u03bbe\u2212\u03bbx/vextendsingle/vextendsingle\u221e\n0\n=\u22120 + 0\u22120 +1\n\u03bb,\nalso\u00b5=E[X] =1\n\u03bb. Ebenso erh \u00a8alt man mit zweifacher partieller Integration\nE[X2] =/integraldisplay\u221e\n0x2\u03bbe\u2212\u03bbxdx=2\n\u03bb2.\nHieraus ergibt sich V[X] =E[X2]\u2212\u00b52=1\n\u03bb2. /square\nSchiefe Wir berechnen nun die Momentenschiefe \u03b31[X] und die Quartils-\nschiefe \u03b3Q\n1[X] einer Zufallsvariablen X\u223cExp(\u03bb). Sie betragen\n\u03b31[X] = 2, \u03b3Q\n1[X] =ln 4\u2212ln 3\nln 3= 0.2619,\nh\u00a8angen also beide nicht von \u03bbab. Sowohl die Momentenschiefe als auch die\nQuartilsschiefe einer Exponentialverteilung sind positi v und zeigen Rechts-\nschiefe (= Linkssteilheit) an.\nBeweis Laut De\ufb01nition ist die Momentenschiefe gleich\n\u03b31[X] =E[X3]\u22123E[X2]\u00b5X+ 2\u00b53\nX\n\u03c33\nX.\nMithilfe dreimaliger partieller Integration erh \u00a8alt man E[X3] =6\n\u03bb3und daher\n\u03b31[X] =E[X3]\u22123E[X2]\u00b5X+ 2\u00b53\nX\n\u03c33\nX\n=6\n\u03bb3\u221232\n\u03bb21\n\u03bb+ 2/parenleftbig1\n\u03bb/parenrightbig3\n/parenleftbig1\n\u03bb/parenrightbig3= 2.\nZur Berechnung der Quartilsschiefe\n\u03b3Q\n1=Q(0.75) + Q(0.25)\u22122\u00b7Q(0.5)\nQ(0.75)\u2212Q(0.25)2.4. Spezielle stetige Verteilungen 97\nben\u00a8otigen wir die Quantile\nQ(0.25) =\u22121\n\u03bbln (1\u22120.25) =1\n\u03bbln/parenleftbigg4\n3/parenrightbigg\n,\nQ(0.5) =\u22121\n\u03bbln (1\u22120.50) =1\n\u03bbln 2,\nQ(0.75) =\u22121\n\u03bbln (1\u22120.75) =1\n\u03bbln 4.\nEs ergibt sich\n\u03b3Q\n1[X] =ln 4 + ln/parenleftbig4\n3/parenrightbig\n\u22122\u00b7ln 2\nln 4\u2212ln/parenleftbig4\n3/parenrightbig =ln/parenleftbig4\u00b74\n3\u00b722/parenrightbig\nln 3\n=ln/parenleftbig4\n3/parenrightbig\nln 3=ln 4\u2212ln 3\nln 3= 0.2619. /square\nDie Exponentialverteilung ist geeignet zur Modellierung v on Lebensdauern\nvon technischen Ger \u00a8aten und von Wartezeiten in Bedienungssystemen. Sie\nhat die folgende interessante Eigenschaft, die im Folgende n alsGed\u00a8achtnis-\nlosigkeit interpretiert wird: F \u00a8urX\u223cExp(\u03bb) und t, s > 0 gilt\nP(X > t +s|X > t ) =P(X > t +s)\nP(X > t )=1\u2212F(t+s)\n1\u2212F(t)\n=e\u2212\u03bb(t+s)\ne\u2212\u03bbt=e\u2212\u03bbs=P(X > s ),\nalso\nP(X > t +s|X > t ) =P(X > s ). (2.18)\nDie bedingte Wahrscheinlichkeit, dass die Lebensdauer Xden Wert t+s\n\u00a8uberschreitet unter der Bedingung, dass sie bereits den Wer tt\u00a8uberschritten\nhat, ist also gleich der (nicht bedingten) Wahrscheinlichk eit, dass die Lebens-\ndauer den Wert s\u00a8uberschreitet. Umgekehrt l \u00a8asst sich zeigen, dass eine stetige\nZufallsvariable X, die die Eigenschaft (2.18) besitzt, eine Exponentialvert ei-\nlung haben muss. Wenn f \u00a8ur eine diskrete Zufallsvariable (2.18) zutri\ufb00t, ist\nsie geometrisch verteilt.\nDie Eigenschaft (2.18) l \u00a8asst sich so als\u201dGed\u00a8achtnislosigkeit\u201c interpretieren:\nBetr\u00a8agt das Alter eines Ger \u00a8ats bereits tZeiteinheiten, so ist die Wahrschein-\nlichkeit, dass seine Funktionst \u00a8uchtigkeit noch mindestens sweitere Zeitein-\nheiten anh \u00a8alt, ebenso gro\u00df wie die Wahrscheinlichkeit, dass ein gleic hartiges\nneues Ger \u00a8at mindestens sZeiteinheiten lang funktionst \u00a8uchtig ist. Das Ger \u00a8at\n\u201dvergisst\u201c also in jedem Zeitpunkt tsein Alter.\nOb f\u00a8ur ein bestimmtes Objekt die Eigenschaft der Ged \u00a8achtnislosigkeit zutri\ufb00t\noder nicht, kann nat \u00a8urlich nur durch inhaltliche \u00a8Uberlegungen festgestellt98 2. Zufallsvariable und Verteilungen\nwerden. Falls sie zutri\ufb00t, ist die Lebensdauer exponential verteilt, wobei der\nParameter \u03bbnoch zu bestimmen ist.\nBeispiel 2.24: Ein Ingenieur unterstellt, dass die Lebensd auerXeines be-\nstimmten Typs von Gl \u00a8uhlampen (in Stunden) durch eine Exponentialvertei-\nlung mit E[X] = 800 beschrieben werden kann ( \u0592\u2192Calc/SPSS).\na) Wie gro\u00df ist die Wahrscheinlichkeit, dass eine zuf \u00a8allig ausgew \u00a8ahlte Gl \u00a8uh-\nlampe l \u00a8anger als 1000Stunden brennt?\nb) Welche Brenndauer wird nur mit einer Wahrscheinlichkeit von10%\n\u00a8uberschritten?\nzu a) Es ist E[X] =1\n\u03bb= 800 ,also\u03bb=1\n800.Deshalb ist\nP(X >1000) = e\u22121\n800\u00b71000=e\u221210\n8= 0.29.\nzu b) Gesucht ist der 90%-Punkt x0.9. Es ist\nx0.9=\u22121\n\u03bbln(1\u22120.9) = 1842 .07.\nIm Folgenden treten mehrfach Wahrscheinlichkeiten der For mP(X > x ) auf.\nAllgemein wird f \u00a8ur eine nichtnegative Zufallsvariable Xdie Funktion\nS(x) = 1\u2212F(x) =P(X > x ), x\u22650,\n\u00a8Uberlebensfunktion (englisch: survival function ) von Xgenannt. Ist X\neine Lebensdauer, so gibt S(x) an, wie gro\u00df die Wahrscheinlichkeit ist, den\nZeitpunkt xzu\u00a8uberleben. Ein weiterer wichtiger Begri\ufb00 in diesem Zusam-\nmenhang ist die Ausfallrate (englisch: hazard rate )\nh(x) =f(x)\nS(x)=f(x)\n1\u2212F(x), x\u22650.\nO\ufb00enbar gilt\nh(x) =\u2212d\ndxln (S(x)), (2.19)\nd.h. die Ausfallrate ist gleich dem negativen Wert der logar ithmischen Ab-\nleitung der \u00a8Uberlebensfunktion. Umgekehrt l \u00a8asst sich durch Integration aus\nder Ausfallrate die \u00a8Uberlebensfunktion und damit die Verteilungsfunktion\nbestimmen; es gilt\nS(x) = exp/parenleftbigg\n\u2212/integraldisplayx\n0h(t)dt/parenrightbigg\n,\nF(x) = 1\u2212S(x) = 1\u2212exp/parenleftbigg\n\u2212/integraldisplayx\n0h(t)dt/parenrightbigg\n.2.4. Spezielle stetige Verteilungen 99\nF\u00a8ur ein kleines Zeitintervall \u2206 xist\nh(x)\u2206x=f(x)\u2206x\nS(x)\u2248P(x < X\u2264x+ \u2206x)\nP(X > x )\n=P(x < X\u2264x+ \u2206x|X > x ).\nh(x)\u2206xgibt also n \u00a8aherungsweise die Wahrscheinlichkeit an, dass ein Objekt\nim Intervall ] x, x+ \u2206x] ausf\u00a8allt unter der Bedingung, dass es den Zeitpunkt\nxerlebt.\nSpeziell sei Xexponentialverteilt, X\u223cExp(\u03bb) . Dann ist S(x) =e\u2212\u03bbxund\nf(x) =\u03bbe\u2212\u03bbx, also\nh(x) =f(x)\nS(x)=\u03bbe\u2212\u03bbx\ne\u2212\u03bbx=\u03bbf\u00a8urx\u22650.\nBei der Exponentialverteilung ist demnach die Ausfallrate konstant und h \u00a8angt\nnicht vom Alter xdes Objektes ab. Man kann leicht (n \u00a8amlich durch Integrati-\non der konstanten Ausfallrate \u03bb) mit Hilfe von Formel (2.19) zeigen, dass die\nExponentialverteilung sogar die einzige Lebensdauervert eilung ist, die die-\nse Eigenschaft besitzt. Die Konstanz der Ausfallrate entsp richt o\ufb00enbar der\nGed\u00a8achtnislosigkeit der Exponentialverteilung.\n2.4.3 Pareto-Verteilung\nWir beginnen mit einem Anwendungsbeispiel. Aus einer Grund gesamtheit\nvon Haushalten werde auf zuf \u00a8allige Weise ein Haushalt ausgew \u00a8ahlt und sein\nEinkommen mit Xbezeichnet. Dann ist Xeine Zufallsvariable. F \u00a8ur jedes\nxentspricht der Wert der Verteilungsfunktion F(x) von Xdem Anteil der\nHaushalte, die ein Einkommen von xoder weniger beziehen. S(x) = 1\u2212F(x)\nentspricht dem Anteil der Haushalte mit einem Einkommen gr \u00a8o\u00dfer als x.\nPareto6untersuchte die Einkommensverteilungen wohlhabender Hau shalte\nund stellte dabei fest, dass die empirischen Verteilungen \u2013 besonders f \u00a8ur gro\u00dfe\nEinkommen x\u2013 der approximativen Beziehung\nln(S(x))\u2248A\u2212\u03b1lnx (2.20)\ngen\u00a8ugen. Dies ist eine (approximative) lineare Gleichung in de n logarithmier-\nten Gr \u00a8o\u00dfen ln( S(x)) und ln x. Tr\u00a8agt man in einem doppelt logarithmischen\nKoordinatensystem den Anteil S(x) gegen xab, so ergibt sich n \u00a8aherungsweise\neine Gerade mit Steigung \u2212\u03b1.\n6Vilfredo Pareto (1848\u20131923)100 2. Zufallsvariable und Verteilungen\nBeschr \u00a8anken wir uns nun auf die Verteilung der Einkommen, die ein be stimm-\ntes Niveau c\u00a8ubersteigen, und nehmen an, dass (2.20) mit geeigneten Zahl en\nAund\u03b1exakt gilt: ln( S(x)) =A\u2212\u03b1lnxf\u00a8urx > c. Dies ist zur Gleichung\nS(x) =eAx\u2212\u03b1\u00a8aquivalent, also zur Gleichung\nF(x) = 1\u2212S(x) = 1\u2212eAx\u2212\u03b1f\u00a8urx > c .\nWegen der Beschr \u00a8ankung der Grundgesamtheit auf Haushalte mit Mindest-\neinkommen csetzen wir F(x) = 0 f \u00a8urx\u2264c. Speziell gilt F(c) = 0 und daher\neAc\u2212\u03b1= 1, d.h. eA=c\u03b1. Insgesamt folgt\nF(x) =\uf8f1\n\uf8f2\n\uf8f30, falls x < c ,\n1\u2212/parenleft\uf8ecigc\nx/parenright\uf8ecig\u03b1\n, falls x\u2265c.\nEine Zufallsvariable Xmit dieser Verteilungsfunktion hei\u00dft Pareto-verteilt\nmit Parametern c >0 und \u03b1 >0, in Zeichen: X\u223cPar(\u03b1, c). Der Tr \u00a8ager von\nX\u223cPar(\u03b1, c) istTX= [c,\u221e[,die Dichte\nf(x) =\uf8f1\n\uf8f2\n\uf8f30, falls x < c ,\n\u03b1\nc/parenleft\uf8ecigc\nx/parenright\uf8ecig\u03b1+1\n=\u03b1c\u03b1x\u2212\u03b1\u22121, falls x\u2265c.\nc\u03b1\nc\nxf(x)\n-6\n... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. .. .. .. .. .. .. . . .. .. .. .. .. . . .. .. .. .. .. . . .. .. .. . . .. .. .. .. . . .. .. . . .. .. .. . . .. .. . . .. .. .. . . .. .. . . .. .. . . .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. . . .. . . .. . . .. .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . . . .. . . .. . . .. . . .. . . . . .. . . .. . . . . .. . . .. . . .. . . . . .. . . .. . . . . .. . . . . .. . . .. . . . . .. . . . . .. . . . . .. . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . . . .. . . . . .. . . . . .. . . . . .. . . . . . . .. . . . . .. . . . . . . .. . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . . . .. . . . . . . .. . . . . . . . . .. . .\n........................ .\nc1\nxF(x)\n-6\n... ... .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. .. .. .. .. .. .. . . .. .. .. .. .. .. . . .. .. .. .. .. . . .. .. .. .. .. . . .. .. .. . . .. .. .. .. . . .. .. .. . . .. .. .. . . .. .. .. . . .. .. . . .. .. . . .. .. .. . . .. .. . . .. .. . . .. .. . . .. .. . . .. .. . . .. .. . . .. . . .. .. . . .. .. . . .. . . .. .. . . .. . . .. .. . . .. . . .. . . .. .. . . .. . . .. . . .. .. . . .. . . .. . . .. . . .. . . .. . . .. .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . . . .. . . .. . . .. . . .. . . .. . . .. . . . . .. . . .. . . .. . . .. . . . . .. . . .. . . .. . . . . .. . . .. . . .. . . . . .. . . .. . . . . .. . . .. . . . . .. . . .. . . . .. . . . . . . . . . . . . . . . . . . . .\nAbbildung 2.20: Dichte und Verteilungsfunktion der Pareto -Verteilung Par(\u03b1=\n2.5, c= 4)2.4. Spezielle stetige Verteilungen 101\nBeispiel 2.25: Von den Studierenden an einer exklusiven Pri vatuniversit \u00a8at sei\nbekannt, dass jeder ein verf \u00a8ugbares Monatseinkommen von mindestens 1500e\nhat. Es sei gem \u00a8a\u00dfPar(\u03b1= 2.1, c= 1500) verteilt ( \u0592\u2192SPSS).\na) Berechnen Sie den Median der Einkommensverteilung.\nb) Wie viel Prozent der Studierenden haben 2500eoder mehr zur Ver-\nf\u00a8ugung?\nzu a) Gesucht ist also x0.5.Es gilt:\nF(x0.5) = 1\u2212/parenleftbigg1500\nx0.5/parenrightbigg2.1\n= 0.5\n/parenleftbigg1500\nx0.5/parenrightbigg2.1\n= 0.5\n1500\nx0.5= 0.51\n2.1\nx0.5= 2086 .60.\nDer Median betr \u00a8agt2086.60e. zu b) Wir berechnen\n1\u2212F(2500) = 1\u2212/parenleft\uf8ecigg\n1\u2212/parenleftbigg1500\n2500/parenrightbigg2.1/parenright\uf8ecigg\n= 0.3421.\n34.2%der Studierenden verf \u00a8ugen\u00a8uber ein Einkommen von mehr als 2500e.\nErwartungswert und Varianz Wir wollen noch Erwartungswert und\nVarianz einer Par(\u03b1, c)-Verteilung bestimmen. Dazu berechnen wir E[Xn]\nf\u00a8ur beliebiges n\u2208N,\nE[Xn] =/integraldisplay\u221e\ncxn\u03b1c\u03b1x\u2212\u03b1\u22121dx\n=\u03b1c\u03b1/integraldisplay\u221e\ncxn\u2212\u03b1\u22121dx\n=\u03b1c\u03b11\nn\u2212\u03b1xn\u2212\u03b1/vextendsingle/vextendsingle/vextendsingle/vextendsingle\u221e\nc,falls\u03b1 > n ,\n=\u03b1c\u03b11\n\u03b1\u2212ncn\u2212\u03b1=\u03b1cn\n\u03b1\u2212n.\nDie Integration erfordert, dass \u03b1 > n ist. F\u00a8urErwartungswert undVari-\nanzeiner Pareto-Verteilung erhalten wir\n\u00b5=E[X] =\u03b1c\n\u03b1\u22121,falls\u03b1 >1,102 2. Zufallsvariable und Verteilungen\nV[X] =E/bracketleftbig\nX2/bracketrightbig\n\u2212\u00b52=\u03b1c2\n\u03b1\u22122\u2212/parenleftbigg\u03b1c\n\u03b1\u22121/parenrightbigg2\n,\nV[X] =\u03b1c2\n(\u03b1\u22122)(\u03b1\u22121)2,falls\u03b1 >2.\nBeispiel 2.25 (Fortsetzung): Erwartungswert und Standard abweichung der\nPareto-Verteilung mit \u03b1= 2.1undc= 1500 berechnet man wie folgt:\nE[X] =2.1\u00b71500\n1.1= 2 863 .64e,\nV[X] =2.1\u00b715002\n0.1\u00b71.12= 39 049 586 .78e2,\n/radicalbig\nV[X] = 6 248 .97e.\nIstX\u223cPar(\u03b1, c) und ist c\u2032> c, so gilt f \u00a8urx > c\u2032\nP(X > x|X > c\u2032) =P(X > x )\nP(X > c\u2032)=/parenleftbigc\nx/parenrightbig\u03b1\n/parenleftbigc\nc\u2032/parenrightbig\u03b1=/parenleftbiggc\u2032\nx/parenrightbigg\u03b1\n.\nDiebedingte Verteilung vonXunter der Bedingung X > c\u2032ist also wieder\neine Pareto-Verteilung. Sie hat denselben Parameter \u03b1wie die nicht bedingte\nVerteilung; ihr anderer Parameter ist c\u2032.\nBeispiel 2.26: Die Einkommen (in e) der Mitglieder eines noblen Golfklubs\nseienPar(\u03b1, c)-verteilt mit \u03b1= 2.4undc= 200 000 . Wie ist das Einkommen\nderjenigen Teilgesamtheit der Mitglieder verteilt, deren Einkommen minde-\nstens c\u2032= 300 000ebetr\u00a8agt?\nNach obiger \u00a8Uberlegung ist dieses Einkommen Par(\u03b1= 2.4;c\u2032= 300 000) -\nverteilt.\n2.4.4 Normalverteilung\nEine Zufallsvariable Xhei\u00dftnormalverteilt oderGau\u00df-verteilt7mit Pa-\nrametern \u00b5\u2208Rund\u03c32>0, in Zeichen: X\u223cN/parenleftbig\n\u00b5, \u03c32/parenrightbig\n, wenn ihre Dichte\ndurch\nf(x) =1\n\u03c3\u221a\n2\u03c0e\u22121\n2(x\u2212\u00b5\n\u03c3)2\n, x\u2208R,\ngegeben ist.\n7Carl Friedrich Gau\u00df (1777\u20131855)2.4. Spezielle stetige Verteilungen 103\nu6\n-u\u03d5(u)\n0. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . .. . . . . . . . . .. . . . . . . .. . . . . . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . .. . . . . .. . . .. . . .. . . . . .. .. . . .. . . .. . . .. . . .. .. . . .. .. . . .. .. .. . . .. .. .. . . .. .. .. .. .. . . .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. .. .. . . .. . . .. . . .. . . . . . . .. . . . . . . . . .. . . . . . . .. . . .. . . .. . . .. .. .. .. . . .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. .. .. .. . . .. .. .. . . .. .. .. . . .. .. . . .. .. . . .. . . .. . . .. . . .. .. . . . . .. . . .. . . .. . . . . .. . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . . . .. . . . . . . .. . . . . . . . . .. . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . ........................................................................................................\n......\n....\n...\n...\n...\n...\n....\n....\n.....\n.....\n......\n......\n.......\n.......\n........\n........\n.........\n.........\n..........\n..........\n...........\n..........\n...........\n...........\n............\n............\n............\n............\n............\n............\n...........\n...........\n..........\n...........\n..........\n..........\n.........\n.........\n........\n........\u0001\n\u0001 \u000b\u03a6(u)\nAbbildung 2.21: Dichte \u03d5(u) der Standard-Normalverteilung\nIm Spezialfall \u00b5= 0 und \u03c32= 1 hei\u00dft die Verteilung Standard-Normal-\nverteilung . In diesem Buch bezeichnen wir eine standard-normalvertei lte\nZufallsvariable mit U,U\u223cN(0,1), und ihre Dichte mit \u03d5(u). Es ist\n\u03d5(u) =1\u221a\n2\u03c0e\u22121\n2u2, u\u2208R.\nZwischen der Normalverteilungsdichte fmit Parametern \u00b5und\u03c32und der\nStandard-Normalverteilungsdichte \u03d5besteht o\ufb00enbar die folgende Beziehung:\nf(x) =1\n\u03c3\u03d5/parenleftbiggx\u2212\u00b5\n\u03c3/parenrightbigg\n, x\u2208R.\nDie Formel entspricht der Formel (2.5) f \u00a8ur die Dichte einer a\ufb03n-linear trans-\nformierten Variablen. Auf die a\ufb03n-lineare Transformation sbeziehung zwi-\nschen UundXwerden wir unten genauer eingehen.\nEigenschaften der Dichtefunktion Die Dichtefunktion \u03d5(u), u\u2208R,\nder Standard-Normalverteilung hat folgende wesentliche E igenschaften (vgl.\nAbbildung 2.21):\n1.\u03d5(u) hat sein Maximum an der Stelle u= 0 mit \u03d5(0) =1\u221a\n2\u03c0= 0.39894.\n2.\u03d5(u) ist symmetrisch zu c= 0, d.h. \u03d5(\u2212u) =\u03d5(u) f\u00a8ur alle u\u2208R.\n3.\u03d5(u) ist positiv f \u00a8ur alle u\u2208Rund geht sowohl f \u00a8uru\u2192\u221e als auch f \u00a8ur\nu\u2192\u2212\u221e gegen 0.\n4.\u03d5(u) besitzt Wendepunkte an den Stellen u= 1 und u=\u22121.104 2. Zufallsvariable und Verteilungen\nInsbesondere ist eine standard-normalverteilte Zufallsv ariable U\u223cN(0,1)\nunimodal mit eindeutigem Modus 0 und nimmt Werte auf der ganz en reellen\nAchse an. Aus den Eigenschaften von \u03d5folgen unmittelbar die Eigenschaften\nder Dichte f(x) einer beliebigen Normalverteilung N(\u00b5, \u03c32), n\u00a8amlich:\n1.f(x) hat sein Maximum an der Stelle x=\u00b5mit\nf(\u00b5) =1\n\u03c3\u00b71\u221a\n2\u03c0=1\n\u03c3\u00b70.3989.\n2.f(x) ist symmetrisch zu \u00b5, d.h. f(\u00b5\u2212x) =f(\u00b5+x) f\u00a8ur alle x\u2208R.\n3.f(x) ist positiv f \u00a8ur alle x\u2208Rund geht sowohl f \u00a8urx\u2192\u221e als auch f \u00a8ur\nx\u2192\u2212\u221e gegen 0.\n4.f(x) besitzt Wendepunkte an den Stellen x=\u00b5+\u03c3undx=\u00b5\u2212\u03c3.\nEine normalverteilte Zufallsvariable X\u223cN(\u00b5, \u03c32) ist unimodal mit eindeu-\ntigem Modus \u00b5und nimmt beliebig gro\u00dfe und kleine Werte an.\nVerteilungsfunktion Die zur Standard-Normalverteilung geh \u00a8orende Ver-\nteilungsfunktion wird mit \u03a6 bezeichnet,\n\u03a6 (u) =u/integraldisplay\n\u2212\u221e\u03d5(t)dt ,\nvgl. Abbildung 2.23. Dieses Integral l \u00a8asst sich nicht durch bekannte Funk-\ntionen wie Polynome oder Exponentialfunktionen ausdr \u00a8ucken oder sonst auf\neinfache Weise berechnen. Eine Wertetabelle f \u00a8ur \u03a6(u) \ufb01ndet man als Tabelle\n4 im Tabellenanhang. Manche Taschenrechner geben ebenfall s die Werte von\n\u03a6 (u) aus.\nDennoch lassen sich einige Eigenschaften derVerteilungsfunktion \u03a6 di-\nrekt ableiten:\n1. \u03a6 ist streng monoton wachsend , da\n\u03a6\u2032(u) =\u03d5(u)>0.\n2. Da die Dichtefunktion \u03d5symmetrisch zu 0 ist, folgt f \u00a8ur die Verteilungs-\nfunktion\n\u03a6 (u) = 1\u2212\u03a6 (\u2212u), u\u2208R.\nInsbesondere ist \u03a6 (0) =1\n2.2.4. Spezielle stetige Verteilungen 105\n\u221214\u221212\u221210\u22128\u22126\u22124\u22122 0 2 4 6 8 10 12 140.56\n- \u001b xf(x)\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . .. . . . . . . .. . . . . .. . . .. . . . . .. . . .. . . . . .. .. . . . . .. . . .. . . .. . . .. .. . . .. . . .. .. . . .. . . .. .. .. . . .. .. . . .. .. .. .. . . .. .. .. .. .. .. .. .. . . .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. .. .. . . .. .. . . .. . . . . .. . . . . .. . . . . . . . . . . . . . . . . .. . . . . .. . . . . .. . . .. .. . . .. .. .. .. . . .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. .. . . .. .. .. .. .. .. .. .. . . .. .. .. .. . . .. .. . . .. .. .. . . .. . . .. .. . . .. . . .. .. . . .. . . .. . . .. . . . . .. .. . . . . .. . . .. . . . . .. . . .. . . . . .. . . . . . . .. . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . .. . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . . . . . .N(0,1)\n. . . . . . . . . . . . . .N(0,4)\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .. . . . . . .. . . . . .. .. . . . . . .. . . .. .. . . . .. . . .. ... . . .. . .. .. . ... .. . .. .. .. .... .. .. .. ... ... .. ... ... ... ... ... ... ... .... ... ... .. ...... .. .. .. .. .... .. . .. . . .. . .. . . . . . . . .. . . .. . . . . .. . . .. . .. . .. .. .. .. . .... .. ... .. ... .. ... .... ... ... ... ... ... ..... ... .. .. ... ... .. .. .. .. .. .. .. . .. . .. . .. ... . .. . . .. . . ... .. . . . . .. . . . .. . . . .. . . . . . . .. . . . . .. . . . . . . . . . .. . . . . . . . . . . . . . . . . . . . . .. . . . .. . . . .. . . . .N(2,1)\n. . . . .. . . . ... . . .. ..................................................................................................................................................................................................... .... . . .. . . . .. .\nAbbildung 2.22: Dichten verschiedener Normalverteilunge n\n\u22123\u22122\u22121 0 1 2 3u 0.00.20.40.60.81.0\u03a6(u)\n-6\n. .. . . . . . . . . . . . . . . . .. . . . . . . . . .. . . . . . . .. . . . . . .. . . . .. . . .. . . . .. . .. . . .. .. . .. . .. .. .. .. . .. .. .. . .... .... . ....... ........ ........ ........ ........ ......... ......... ......... ......... .......... .......... .......... ........... ........... ........... ........... ............ ............ ............ ............ ........... ........... ........... ........... .......... .......... .......... ......... ......... ......... ......... ........ ........ ........ ........ ...... .. .... ... . ... .. ... . .. .. .. . .. . .. .. . . .. . .. . . . .. . . .. . . . .. . . . . .. . . . . . . .. . . . . . . . .. . . . . . . . . . . . . . .. . . . . . .\n. . . . . . . . . . . . . . . . . .\n.........\nAbbildung 2.23: Verteilungsfunktion \u03a6( u) der Standardnormalverteilung\nDa die Verteilungsfunktion \u03a6 streng monoton wachsend ist, b esitzt sie eine\nUmkehrfunktion. F \u00a8ur jedes p\u2208]0,1[ erh \u00a8alt man deshalb das p-Quantil der\nStandard-Normalverteilung\nup=Q(p) = \u03a6\u22121(p)\nals eindeutige L \u00a8osung der Gleichung \u03a6 ( u) =p.Es gilt hier\n\u03a6/parenleftbig\n\u03a6\u22121(p)/parenrightbig\n=p f\u00a8ur 0< p < 1,\n\u03a6\u22121(\u03a6 (u)) =u f\u00a8ur\u2212\u221e< u <\u221e.\nAus der Eigenschaft \u03a6 ( u) = 1\u2212\u03a6 (\u2212u) folgt f \u00a8ur die Quantilfunktion die\nentsprechende Eigenschaft\n\u03a6\u22121(p) =\u2212\u03a6\u22121(1\u2212p),d.h. up=\u2212u1\u2212p.106 2. Zufallsvariable und Verteilungen\nDie Quantile der Standard-Normalverteilung erh \u00a8alt man aus Tabelle 4 im\nAnhang, indem man sie\u201dr\u00a8uckw\u00a8arts\u201c liest. Einige besonders h \u00a8au\ufb01g verwendete\nQuantile upsind in Tabelle 3 zusammengestellt.\nErwartungswert und Varianz einer standard-normalverteilten Zufallsva-\nriablen U\u223cN(0,1) lauten\nE[U] = 0, V [U] = 1.\nBeweis E[U] = 0 folgt sofort aus der Symmetrie der Dichte zu 0. Die\nVarianz von Uberechnet man mit partieller Integration wie folgt:\nV[U] = E/bracketleftbig\nU2/bracketrightbig\n\u2212(E[U])2=E/bracketleftbig\nU2/bracketrightbig\n=/integraldisplay\u221e\n\u2212\u221eu2\u03d5(u)du=/integraldisplay\u221e\n\u2212\u221eu\u00b7[u\u00b7\u03d5(u)]du\n=\u2212u\u00b7\u03d5(u)|\u221e\n\u2212\u221e+/integraldisplay\u221e\n\u2212\u221e\u03d5(u)du\n= (\u22120 + 0) + 1 = 1\nHierbei wurde verwendet, dass\nu\u00b7\u03d5(u) =u\u00b71\u221a\n2\u03c0e\u2212u2\n2\ndie Stammfunktion \u2212\u03d5(u) besitzt und dass\nlim\nu\u2192\u221eu\u00b7\u03d5(u) = lim\nu\u2192\u2212\u221eu\u00b7\u03d5(u) = 0.\n/square\nBeispiel 2.27: Es sei U\u223cN(0,1)-verteilt ( \u0592\u2192Calc/SPSS).\na) Man bestimme P(U >0.5)undP(\u22121\u2264U\u22642).\nb) Man bestimme den 20%- und den 70%-Punkt von U.\nc) Man bestimme bso, dass P(\u2212b\u2264U\u2264b) = 0.9.\nzu a) Wir berechnen\nP(U >0.5) = 1\u2212P(U\u22640.5) = 1\u2212\u03a6 (0.5)\n= 1\u22120.6915 = 0 .3085,\nP(\u22121\u2264U\u22642) = P(U\u22642)\u2212P(U\u2264\u22121) = \u03a6 (2)\u2212\u03a6 (\u22121)\n= \u03a6 (2)\u2212(1\u2212\u03a6 (1)) = 0 .9772\u22121 + 0.8413\n= 0.8185.2.4. Spezielle stetige Verteilungen 107\nDabei wurden die Werte von \u03a6(2)und\u03a6(1)der Tabelle 4 entnommen.\nzu b) Gesucht wird das 0.2-Quantil (bzw. das 0.7-Quantil). E s muss also\ngelten: P(U\u2264u) = \u03a6 ( u) = 0.2 (bzw.0.7). Tabelle 3 liefert u0.2=\u2212u0.8=\n\u22120.8416.Aus Tabelle 4 erh \u00a8alt man durch lineare Interpolation u0.7= 0.5244.\nzu c) Es gilt\nP(\u2212b\u2264U\u2264b) = P(U\u2264b)\u2212P(U\u2264\u2212b) = \u03a6 ( b)\u2212\u03a6 (\u2212b)\n= \u03a6 ( b)\u2212(1\u2212\u03a6 (b)) = 2\u00b7\u03a6 (b)\u22121.\nDaraus folgt 2\u00b7\u03a6 (b)\u22121 = 0.9, also \u03a6 (b) = 0.95.Aus Tabelle 3 ergibt sich\nb= 1.6449.\nIm Folgenden betrachten wir wieder eine Normalverteilung N/parenleftbig\n\u00b5, \u03c32/parenrightbig\nund\ndiskutieren die a\ufb03n-lineare Transformation, durch die sie mit der Standard-\nNormalverteilung N(0,1) verkn \u00a8upft ist. Grundlegend sind die folgenden Aus-\nsagen:\n1. Ist X\u223cN/parenleftbig\n\u00b5, \u03c32/parenrightbig\n, so gilt f \u00a8ur die standardisierte Variable\nX\u2212\u00b5\n\u03c3\u223cN(0,1).\n2. Ist U\u223cN(0,1) und sind \u00b5\u2208Rund\u03c3 >0, so gilt f \u00a8ur die mit \u00b5und\u03c3\ntransformierte Zufallsvariable\n\u03c3U+\u00b5\u223cN/parenleftbig\n\u00b5, \u03c32/parenrightbig\n.\nBeweis Die erste Aussage weist man so nach: Die Verteilungsfunktio n der\nstandardisierten Variablen ist\nFX\u2212\u00b5\n\u03c3(u) = P/parenleftbiggX\u2212\u00b5\n\u03c3\u2264u/parenrightbigg\n=P(X\u2264\u03c3u+\u00b5) =FX(\u03c3u+\u00b5)\n=\u03c3u+\u00b5/integraldisplay\n\u2212\u221e1\u221a\n2\u03c0\u03c3e\u22121\n2(x\u2212\u00b5\n\u03c3)2\ndx\n=u/integraldisplay\n\u2212\u221e1\u221a\n2\u03c0e\u22121\n2y2dy= \u03a6 (u) f\u00a8uru\u2208R.\nHier haben wir beim Integrieren\nx\u2212\u00b5\n\u03c3=ymit x=\u00b5+\u03c3y ,dy\ndx=1\n\u03c3unddx=\u03c3dy108 2. Zufallsvariable und Verteilungen\nsubstituiert. Da die Verteilungsfunktion vonX\u2212\u00b5\n\u03c3gleich \u03a6 ist, ist\nX\u2212\u00b5\n\u03c3\u223cN(0,1).\nDie zweite Aussage zeigt man auf \u00a8ahnliche Weise. /square\nAus der ersten Aussage folgt\nFX(x) = \u03a6/parenleftbiggx\u2212\u00b5\n\u03c3/parenrightbigg\nf\u00a8urx\u2208R.\nWenn X\u223cN/parenleftbig\n\u00b5, \u03c32/parenrightbig\nist, l\u00a8asst sich die Verteilungsfunktion vonXdurch\ndie Standard-Normalverteilungsfunktion \u03a6 ausdr \u00a8ucken. F \u00a8ur die Dichte von\nXgilt\nfX(x) =F\u2032\nX(x) =1\n\u03c3\u03d5/parenleftbiggx\u2212\u00b5\n\u03c3/parenrightbigg\n,\nund das p-Quantil ist gem \u00a8a\u00df (2.4) gleich\nxp=\u00b5+\u03c3 up,\nwobei updasp-Quantil der Standard-Normalverteilung bezeichnet.\nWir k\u00a8onnen nun leicht den Erwartungswert und die Varianz einer normal-\nverteilten Zufallsvariablen X\u223cN/parenleftbig\n\u00b5, \u03c32/parenrightbig\nbestimmen. Xist die a\ufb03n-lineare\nTransformation einer standard-normalverteilten Zufalls variablen U,\nX=\u00b5+\u03c3U , U\u223cN(0,1),\nalso gilt\nE[X] =\u00b5+\u03c3E[U] =\u00b5 .\nDies folgt auch unmittelbar aus der Symmetrie der N/parenleftbig\n\u00b5, \u03c32/parenrightbig\n-Verteilung zu\n\u00b5. Weiter ist\nV[X] =V[\u00b5+\u03c3U] =\u03c32V[U] =\u03c32.\nDie beiden Parameter \u00b5und\u03c32einer Normalverteilung lassen sich also als\nErwartungswert bzw.Varianz interpretieren.\nSchiefe und Kurtosis Da eine Normalverteilung symmetrisch zu \u00b5ist,\nsind sowohl die Momentenschiefe \u03b31als auch die Quartilsschiefe \u03b3Q\n1gleich\nnull. F \u00a8ur die W \u00a8olbung \u03b32ergibt sich mittels mehrfacher partieller Integration\n\u03b32=\u221e/integraldisplay\n\u2212\u221eu4\u03d5(u)du= 3.2.4. Spezielle stetige Verteilungen 109\nBeispiel 2.28: Es sei X\u223cN/parenleftbig\n\u00b5= 2, \u03c32= 25/parenrightbig\n(\u0592\u2192Calc/SPSS).\na) Man berechne P(X >3)undP(0\u2264X\u22642).\nb) Man bestimme den 80%- und 95%-Punkt von X.\nc) Man bestimme aso, dass P(2\u2212a\u2264X\u22642 +a) = 0.9ist.\nzu a) Es ist\nP(X >3) = 1\u2212P(X\u22643) = 1\u2212FX(3)\n= 1\u2212\u03a6/parenleftbigg3\u22122\n5/parenrightbigg\n= 1\u2212\u03a6 (0.2)\n= 1\u22120.5793 = 0 .4207,\nP(0\u2264X\u22642) = P(X\u22642)\u2212P(X\u22640) = FX(2)\u2212FX(0)\n= \u03a6/parenleftbigg2\u22122\n5/parenrightbigg\n\u2212\u03a6/parenleftbigg0\u22122\n5/parenrightbigg\n= \u03a6 (0)\u2212\u03a6 (\u22120.4)\n= \u03a6 (0)\u2212(1\u2212\u03a6 (0.4))\n= 0.5\u22121 + 0.6554 = 0 .1554.\nzu b) Gesucht sind die Quantile x0.8undx0.95.Man berechnet sie als\nx0.8=\u00b5+\u03c3u0.8= 2 + 5\u00b70.8416 = 6 .2081,\nx0.95=\u00b5+\u03c3u0.95= 2 + 5\u00b71.6449 = 10 .2245.\nzu c) Es ist\n0.9 = P(2\u2212a\u2264X\u22642 +a)\n= \u03a6/parenleftbigg2 +a\u22122\n5/parenrightbigg\n\u2212\u03a6/parenleftbigg2\u2212a\u22122\n5/parenrightbigg\n= \u03a6/parenleft\uf8eciga\n5/parenright\uf8ecig\n\u2212\u03a6/parenleftbigg\u2212a\n5/parenrightbigg\n= 2 \u03a6/parenleft\uf8eciga\n5/parenright\uf8ecig\n\u22121.\nDaraus folgt \u03a6(a\n5) = 0.95,a\n5=u0.95= 1.6449und damit a= 8.2245.\nUnter dem zentralen Schwankungsintervall der Breite 2 aversteht man\ndas Intervall\n[\u00b5\u2212a, \u00b5+a].\nF\u00a8urX\u223cN/parenleftbig\n\u00b5, \u03c32/parenrightbig\ngilt\nP(X\u2208[\u00b5\u2212a, \u00b5+a]) = P(\u00b5\u2212a\u2264X\u2264\u00b5+a)\n= \u03a6/parenleftbig\u00b5+a\u2212\u00b5\n\u03c3/parenrightbig\n\u2212\u03a6/parenleftbig\u00b5\u2212a\u2212\u00b5\n\u03c3/parenrightbig\n= \u03a6/parenleftbiga\n\u03c3/parenrightbig\n\u2212\u03a6/parenleftbig\u2212a\n\u03c3/parenrightbig\n= 2 \u03a6/parenleftbiga\n\u03c3/parenrightbig\n\u22121.110 2. Zufallsvariable und Verteilungen\nBesonders h \u00a8au\ufb01g verwendete zentrale Schwankungsintervalle einer N/parenleftbig\n\u00b5, \u03c32/parenrightbig\n-\nVerteilung sind die so genannten Ein-, Zwei- und Drei-Sigma-Bereiche .\nSie lauten:\nP(\u00b5\u2212\u03c3\u2264X\u2264\u00b5+\u03c3) = 2 \u03a6 (1)\u22121 = 0.6826,\nP(\u00b5\u22122\u03c3\u2264X\u2264\u00b5+ 2\u03c3) = 2 \u03a6 (2)\u22121 = 0.9544,\nP(\u00b5\u22123\u03c3\u2264X\u2264\u00b5+ 3\u03c3) = 2 \u03a6 (3)\u22121 = 0.9974.\nMan vergleiche die durch die Normalverteilung gegebenen Wa hrscheinlich-\nkeiten dieser Intervalle mit den allgemeinen Wahrscheinli chkeitsschranken,\ndie die Tschebysche\ufb00-Ungleichung (Abschnitt 2.2.3) liefe rt: Der Zwei-Sigma-\nBereich einer beliebigen Verteilung hat mindestens die Wah rscheinlichkeit\n0.7500 und der Drei-Sigma-Bereich die Wahrscheinlichkeit 0 .8889. Man sieht\ndaran, dass die Annahme einer zugrundeliegenden Normalver teilung sch \u00a8arfe-\nre Aussagen \u00a8uber die Wahrscheinlichkeiten erlaubt.\nNormalverteilungen eignen sich in vielen Anwendungsf \u00a8allen gut dazu, um\nso genannte Fehlerverteilungen zu beschreiben. Hierbei kann es sich um\neinenMessfehler handeln, d.h. die zuf \u00a8allige Abweichung eines Messwerts\nvom\u201dwahren Wert\u201c der zu messenden Gr \u00a8o\u00dfe. Dies spielt insbesondere in den\nNaturwissenschaften und der Technik eine wichtige Rolle. A uch lassen sich\noftFertigungs- oder Produktionsfehler (das sind Abweichungen von vor-\ngegebenen Sollgr \u00a8o\u00dfen) gut durch normalverteilte Zufallsvariable beschrei ben.\nAuch im Bereich der Wirtschafts- und Sozialwissenschaften wird die Nor-\nmalverteilung gerne verwendet, vor allem als Verteilung ei ner\u201dSt\u00a8orgr\u00a8o\u00dfe\u201c,\nn\u00a8amlich der Di\ufb00erenz zwischen dem beobachteten Wert eines Me rkmals und\nseinem durch ein theoretisches Modell vorhergesagten Wert . Dies l \u00a8asst sich\ndann rechtfertigen, wenn die beobachtete Abweichung vom th eoretischen\nWert durch eine Vielzahl von unabh \u00a8angigen kleinen Abweichungen zustande-\nkommt; vgl. den Zentralen Grenzwertsatz (Abschnitt 3.2.4) .\nBeispiel 2.29: Das tats \u00a8achliche Gewicht Xeiner (zuf \u00a8allig ausgew \u00a8ahlten) Kaf-\nfeepackung in Gramm sei normalverteilt mit \u00b5= 1000 und\u03c3= 10. Wie\ngro\u00df ist die Wahrscheinlichkeit, dass das tats \u00a8achliche Gewicht geringer als\n985 Gramm ist?\nEs ist X\u223cN/parenleftbig\n\u00b5= 1000 , \u03c32= 100/parenrightbig\n.F\u00a8ur die gesuchte Wahrscheinlichkeit\nergibt sich\nP(X <985) = \u03a6/parenleftbigg985\u22121000\n10/parenrightbigg\n= \u03a6 (\u22121.5) = 1\u2212\u03a6 (1.5)\n= 1\u22120.9332 = 0 .0668.2.4. Spezielle stetige Verteilungen 111\nBeispiel 2.30: Sei K0= 40eder Schlusskurs einer bestimmten Aktie an\nder Frankfurter B \u00a8orse am heutigen Tag, und bezeichne Kden morgigen\nSchlusskurs der Aktie. \u00a8Uber die Verteilung der Ein-Tagesrendite (in %)\nR=K\u2212K0\nK0\u00b7100\ntri\ufb00t ein Anleger die Annahme R\u223cN/parenleftbig\n0, \u03c32= 16/parenrightbig\n. Wie gro\u00df ist dann die\nWahrscheinlichkeit, dass der Schlusskurs Kam morgigen Tag 38eoder we-\nniger betr \u00a8agt?\nAus den Annahmen folgt, dass\nK=K0+K0R\n100\u223cN/parenleftbigg\n\u00b5K= 40, \u03c32\nK=402\u00b716\n1002= 0.42\u00b716/parenrightbigg\n,\nalso\nP(K\u226438) = \u03a6/parenleftbigg38\u221240\n0.4\u00b74/parenrightbigg\n= \u03a6 (\u22121.25) = 1\u2212\u03a6 (1.25)\n= 1\u22120.8944 = 0 .1056.\nDie Normalverteilungsannahme erweist sich in vielen wirts chaftswissenschaft-\nlichen Anwendungen als problematisch. Eine Aktienrendite wie im Beispiel\n2.30 ist schon deshalb nicht exakt normalverteilt, weil sie nicht kleiner als\n\u2212100% (das entspricht dem Totalverlust) werden kann. Weiter beobachtet\nman in den meisten Anwendungsf \u00a8allen, dass empirische Renditeverteilungen\nsowohl in der Mitte der Verteilung als auch an den Flanken der Verteilung\nstark von der Normalverteilung abweichen.\nOb und inwiefern die Annahme einer Normalverteilung eine hi nreichend ge-\nnaue Approximation darstellt, ist im konkreten Anwendungs fall sorgf \u00a8altig zu\npr\u00a8ufen. Auf dieses Problem kommen wir im Abschnitt 6.4.2 zur \u00a8uck.\n2.4.5 Lognormalverteilung\nIstXnormalverteilt mit den Parametern \u00b5\u2208Rund\u03c32>0, so nennt man\nY=eXlognormalverteilt mit diesen Parametern, in Zeichen:\nY\u223cLN/parenleftbig\n\u00b5, \u03c32/parenrightbig\n.\nO\ufb00ensichtlich ist eine nichtnegative Zufallsvariable Ygenau dann lognormal-\nverteilt, wenn ln Ynormalverteilt ist. Wir leiten zun \u00a8achst f \u00a8ur gegebene Werte\nder Parameter \u00b5und\u03c32die Verteilungsfunktion und die Dichte von Yher.\nF\u00a8ury >0 gilt\nFY(y) = P(Y\u2264y) =P(eX\u2264y)\n=P(X\u2264lny) = \u03a6/parenleftbigglny\u2212\u00b5\n\u03c3/parenrightbigg\n,112 2. Zufallsvariable und Verteilungen\ndaX\u223cN(\u00b5, \u03c32) verteilt ist. Insgesamt erhalten wir\nFY(y) =\uf8f1\n\uf8f2\n\uf8f30, fallsy\u22640,\n\u03a6/parenleftbigglny\u2212\u00b5\n\u03c3/parenrightbigg\n,fallsy >0.\nUm den Median y0.5vonYzu ermitteln, setzen wir FY(y0.5) = 0.5; es folgt\nlny0.5\u2212\u00b5\n\u03c3= 0,also\ny0.5=e\u00b5.\nDurch Di\ufb00erenzieren von FY(y) erh\u00a8alt man die Dichte von Y. Es ist\nfY(y) =\uf8f1\n\uf8f2\n\uf8f30, fallsy\u22640,\n1\n\u03c3y\u03d5/parenleftbigglny\u2212\u00b5\n\u03c3/parenrightbigg\n,fallsy >0.\n0 5 1000.10.20.30.40.50.6\nxf(x)\n-6\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .LN(1,1)\n...... ............................... ............................................. ......................................... ................................ ....................... ................. ........... ....... ..... . . . . ..... ..... ...... ....... ....... ....... ....... ....... ....... ....... ....... ....... ....... ....... ....... ....... ....... ...... ...... ...... ...... ...... ...... ...... ...... ...... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... ..... .... . ..... ..... .. ... .... . ..... . .... . .... . .... . ... .... .... . ... .... . ... .. .. ... . ... . ... . ... . ... . ... . .. .. .. .. . ... . .. . .. .. . .. . .. .. . .. . .. .. . .. . . .. . .. .. . . .. . .. . .. . . .. . . . . .. .. . . .. . . .. . . .. . . .. . . .. . . .. . . .. . . . . .. . . .. . . . .. . . . .. . . .. . . . . .. . . . .. . . . . . .. . . . .. . . . . . .. . . . .. . . . . . . .. . . . . . .. . . . . .. . . . . . . .. . . . . . . .. . . . . . . .. . . . . . . . . .. . . . . . . . .. . . . . . . . .. . . . . . . . . . .. . . . . . . . . . .. . . . . . . . . . . .. . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . . .. . . . LN(1,2)\n................................................................................................................................................................................................................................................................... ................................................................................................................................................................................................................................................................................ ....... ... ... .... ... ... .. .... .. ... .. .. .. .. .. .. . .. ... .. .. .. .. . ... . .. . .. .. . . .. .. . . .. .. . . .. . . .. .. .. . . .. . . . ... . . .. .. . . .. .. . . .. .. . . . . ... . . . .. . . .. .. . . . . .. . . . ... .. . . .. . . . . .. . . . . .. . . . ... . . .. .. . .. . .. . . .. .. . . .. .. . . . ... . . . . .. . . . . .. . . . . .. .. . . .. . . . . .. . . .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . LN(2,1)\n. . .. ............................................................... .. . . . .. . . . . . . . . . . .. . .. .. .. .. .. .. .. .. .. ... ... ... ... ... .. ... ... ... ... ... .. ... ... .. ... .. ... .. .. ... .. .. .. ... .. .. ... .. .. .. .. .. .. .. .. . .. .. .. .. .. . .. .. . .. .. . .. ... . .. . .. .. . .. . .. . .. . .. .. . .. . .. . .. . . .. . .. . . .. .. . .. . . .. . . .. . . .. . . .. . .. .. . . . .. . . . .. . . .. . . . ... . . .. . . . .. . . . . .. . . . . ..................... LN(2,2)\n...............................................................................................................................................................................................\nAbbildung 2.24: Dichtefunktionen verschiedener Lognorma lverteilungen2.4. Spezielle stetige Verteilungen 113\nMan rechnet leicht aus, dass die Dichte an der Stelle y=e\u00b5\u2212\u03c32ihr einziges\nMaximum besitzt. Die Lognormalverteilung ist daher unimod al mit eindeu-\ntigemModus\nyM=e\u00b5\u2212\u03c32.\nErwartungswert und Varianz Bei den Parametern \u00b5und\u03c32einer log-\nnormalverteilten Zufallsvariablen Yist Vorsicht geboten: Sie sind gleich dem\nErwartungswert und der Varianz von X= lnY, aber keineswegs von Yselbst.\nVielmehr gilt\nE[Y] = e\u00b5+\u03c32\n2,\nV[Y] = e2\u00b5+\u03c32(e\u03c32\u22121).\nH\u00a8au\ufb01g wird die lognormale Verteilung mit Hilfe zweier andere r Gr\u00a8o\u00dfen pa-\nrametrisiert, n \u00a8amlich mit ihrem Median \u03be=y0.5und dem Quotienten\n\u03b7=y0.5\nyM\naus Median und Modus. Dann ist\n\u03be=e\u00b5>0, \u03b7 =e\u03c32>1.\nEs gilt \u00b5= ln\u03beund\u03c32= ln\u03b7, also\nFY(y) =\uf8f1\n\uf8f2\n\uf8f30, fallsy\u22640,\n\u03a6/parenleftbigglny\u2212ln\u03be\u221aln\u03b7/parenrightbigg\n,fallsy >0.\nMit den Parametern \u03beund\u03b7lassen sich Erwartungswert und Varianz o\ufb00enbar\nso ausdr \u00a8ucken:\nE[Y] =\u03be\u221a\u03b7 , V [Y] =\u03be2\u03b7(\u03b7\u22121).\nJede Lognormalverteilung ist rechtsschief. Als Momentens chiefe ergibt sich\n\u03b31=/radicalbig\n\u03b7\u22121(\u03b7+ 2)>0,\nda\u03b7 >1 ist. F \u00a8ur die W \u00a8olbung gilt\n\u03b32=\u03b74+ 2\u03b73+ 3\u03b72\u22123>3.\nBeispiel 2.31: Die Verteilung der verf \u00a8ugbaren Einkommen (in 1000e) in ei-\nner Gesamtheit von Haushalten sei durch LN/parenleftbig\n\u00b5= 0.9, \u03c32= 0.1/parenrightbig\ngegeben.\nMan berechne Erwartungswert, Standardabweichung, Median und Modus die-\nser Einkommensverteilung.114 2. Zufallsvariable und Verteilungen\nBezeichne Ydas Einkommen eines zuf \u00a8allig ausgew \u00a8ahlten Haushaltes. Der\nModus ist yM=e0.9\u22120.1= 2.2255, der Median \u03be=e0.9= 2.4596, der Ge-\nstaltparameter \u03b7=e0.1= 1.1052. Weiter erhalten wir\nE[Y] = \u03be\u221a\u03b7= 2.5857,/radicalbig\nV[Y] =/radicalbig\n\u03be2\u03b7(\u03b7\u22121) = 0 .8387.\nDie Lognormalverteilung hat wichtige Anwendungen in der An alyse von Ren-\nditeverteilungen am Aktienmarkt; siehe Beispiel 3.14 im Ab schnitt 3.2.4 und\ndas Zahlenbeispiel im Kapitelanhang ( \u0592\u2192Calc/SPSS).\n2.4.6 \u00a8Ubersicht \u00a8uber einige spezielle Verteilungen\nDie folgende \u00a8Ubersicht enth \u00a8alt Erwartungswert, Varianz und Tr \u00a8ager aller bis-\nher eingef \u00a8uhrten speziellen Verteilungen. F \u00a8ur alle au\u00dfer der hypergeometri-\nschen Verteilung sind auch die Momentenschiefe und die W \u00a8olbung aufgef \u00a8uhrt.2.4. Spezielle stetige Verteilungen 115X\u223c E[X] V[X] TX \u03b31 \u03b32\nB(n, \u03c0) n\u03c0 n\u03c0(1\u2212\u03c0) {0,1, . . ., n}1\u22122\u03c0/radicalbig\nn\u03c0(1\u2212\u03c0)1\u22126\u03c0(1\u2212\u03c0)\nn\u03c0(1\u2212\u03c0)+ 3\nH(n, N, M ) nM\nNnM\nN/parenleftbigg\n1\u2212M\nN/parenrightbiggN\u2212n\nN\u22121{x|x\u2208N\u222a{0},0\u2264x\u2264M,\n0\u2264n\u2212x\u2264N\u2212M}\nPo(\u00b5) \u00b5 \u00b5 N\u222a{0}1\u221a\u00b51\n\u00b5+ 3\nG(\u03c0)1\n\u03c01\u2212\u03c0\n\u03c02N2\u2212\u03c0\u221a1\u2212\u03c09\u22129\u03c0+\u03c02\n1\u2212\u03c0\nN(0,1) 0 1 R 0 3\nN(\u00b5, \u03c32) \u00b5 \u03c32R 0 3\nR(\u03b1, \u03b2)\u03b1+\u03b2\n2(\u03b2\u2212\u03b1)2\n12[\u03b1, \u03b2] 09\n5\nExp(\u03bb)1\n\u03bb1\n\u03bb2[0,\u221e[ 2 9\nPar(\u03b1, c)\u03b1c\n\u03b1\u22121, \u03b1 >1\u03b1c2\n(\u03b1\u22122)(\u03b1\u22121)2, \u03b1 >2 [c,\u221e[2(\u03b1+ 1)\u221a\u03b1\u22122\n(\u03b1\u22123)\u221a\u03b1, \u03b1 >36(\u03b13+\u03b12\u22126\u03b1\u22122)\n\u03b1(\u03b1\u22123)(\u03b1\u22124)+ 3, \u03b1 >4\nLN(\u00b5, \u03c32) e\u00b5+\u03c32\n2 e2\u00b5+\u03c32/parenleft\uf8ecig\ne\u03c32\u22121/parenright\uf8ecig\n[0,\u221e[/radicalbig\ne\u03c32\u22121 (e\u03c32+ 2) e4\u03c32+ 2e3\u03c32+ 3e2\u03c32\u22123116 2. Zufallsvariable und Verteilungen\n2.5 Erg \u00a8anzungen\n2.5.1 Borel-Mengen, Verteilung einer Zufallsvariablen\nMit Hilfe der Verteilungsfunktion Feiner Zufallsvariablen Xkann man be-\nsonders leicht die Wahrscheinlichkeit daf \u00a8ur angeben, dass Xin ein gegebenes\nIntervall f \u00a8allt. Aus der Verteilungsfunktion l \u00a8asst sich jedoch auch f \u00a8ur allge-\nmeinere Mengen Bvon reellen Zahlen die Wahrscheinlichkeit\nP(X\u2208B) =P({\u03c9|X(\u03c9)\u2208B})\nableiten. Beispielsweise, wenn Bdie Vereinigung von disjunkten Intervallen\nist, ergibt sich P(X\u2208B) als Summe der Wahrscheinlichkeiten der einzel-\nnen Intervalle. Man kann beweisen, dass durch die Verteilun gsfunktion von\nXdie Wahrscheinlichkeiten P(X\u2208B) f\u00a8ur alle B\u2208Bbestimmt sind. Da-\nbei istBdas Mengensystem der so genannten Borel-Mengen ; dies sind\ndie Mengen, die sich durch wiederholte Ereignisoperatione n aus Intervallen\nbilden lassen. Die Borel-Mengen bilden eine Ereignisalgeb ra (vgl. Abschnitt\n1.1.2). Dar \u00a8uber hinaus besitzen sie folgende Eigenschaft: Die Vereini gung von\nabz\u00a8ahlbar vielen Mengen in Bist wieder eine Menge in B. Die Borel-Mengen\nbilden demnach eine Ereignis- \u03c3-Algebra .\nAlle f\u00a8ur Anwendungen interessanten Mengen sind Borel-Mengen. (E s ist sogar\nausgesprochen schwierig, \u00a8uberhaupt eine Menge zu \ufb01nden, die keine Borel-\nMenge ist.) Die Funktion\nB/ma\u221asto\u2212\u2192P(X\u2208B), B\u2208B,\nhei\u00dftWahrscheinlichkeitsverteilung , kurz: Verteilung , vonX. Die Ver-\nteilung von Xist durch die Verteilungsfunktion\nx/ma\u221asto\u2212\u2192P(X\u2208]\u2212\u221e, x]), x\u2208R,\nschon vollst \u00a8andig festgelegt.\nDie Verteilung einer diskreten Zufallsvariablen Xist bereits durch die Ein-\nzelwahrscheinlichkeiten pj=P(X=xj),j= 1,2,3, . . .bestimmt. Die Ver-\nteilung einer stetigen Zufallsvariablen Xist durch ihre Dichte f(x), x\u2208R,\neindeutig festgelegt.\n2.5.2 Erwartungswert einer Wette als subjektive Wahr-\nscheinlichkeit\nIm Abschnitt 1.4.2 wurde bereits auf die Begr \u00a8undung subjektiver Wahr-\nscheinlichkeiten durch Wetten hingewiesen.2.5. Erg \u00a8anzungen 117\nEine Wette biete die Auszahlung von 100 e, falls ein bestimmtes Ereignis\nAeintritt, andernfalls eine Auszahlung von 0 e. Die Auszahlung ist dann\neine diskrete Zufallsvariable mit zwei Auspr \u00a8agungen: P(X= 100) = \u03c0und\nP(X= 0) = 1\u2212\u03c0, mit x1= 100 , p1=\u03c0, x2= 0 und p2= 1\u2212\u03c0. Der\nErwartungswert betr \u00a8agt\nE[X] =x1\u00b7p1+x2\u00b7p2= 100 \u03c0+ 0(1\u2212\u03c0) = 100 \u03c0 .\nDie subjektive Wahrscheinlichkeit f \u00a8ur das Eintreten des Ereignisses Al\u00a8asst\nsich ermitteln, indem der Spieler befragt wird, welchen Bet rag er maximal\nbereit sei, f \u00a8ur die Wette einzusetzen.\nMan geht davon aus, dass der Spieler\u201drisikoneutral\u201c ist, das bedeutet, dass\nsein maximaler Einsatz gleich dem Erwartungswert einer Wet te ist. Ist eine\nPerson also bereit, einen Einsatz von Mzu leisten, so kann man aus der\nBeziehung\nM=E[X] = 100 \u03c0\nableiten, dass ihre subjektive Wahrscheinlichkeit \u03c0den Wert \u03c0=M\n100hat.\nDerartige \u00a8Uberlegungen spielen bei vielen wirtschaftlichen Fragest ellungen\neine Rolle. Beim Abschluss einer Versicherung etwa h \u00a8angt die H \u00a8ohe der Ver-\nsicherungspr \u00a8amie, die der Versicherungsnehmer maximal zu zahlen bereit ist,\nvon der Wahrscheinlichkeit ab, die er dem Eintritt des Versi cherungsfalles\nzubilligt.\nErg\u00a8anzende Literatur zu Kapitel 2:\nDie in den Literaturhinweisen zu Kapitel 1 aufgef \u00a8uhrten B \u00a8ucher enthalten\nAusf\u00a8uhrungen \u00a8uber Zufallsvariablen und deren Verteilungen. Zahlreiche spe-\nzielle diskrete und stetige Verteilungen werden in Johnson et al. (2005, 1994,\n1995) sowie in Patil et al. (1975) ausf \u00a8uhrlich behandelt.118 2. Zufallsvariable und Verteilungen\n2.6 Anhang: Verwendung von Excel/Calc und\nSPSS\nF\u00a8ur konkrete Anwendungen der Wahrscheinlichkeitsrechnung und f\u00a8ur stati-\nstische Auswertungen stehen leistungsf \u00a8ahige Computerprogramme zur Ver-\nf\u00a8ugung. Weit verbreitet sind die Softwarepakete Microsoft/circleRExcel (bzw. sein\nFreeware-Pendant OpenO\ufb03ce.org Calc) und SPSS.8\nIn diesem Kapitelanhang sowie in Anh \u00a8angen zu den Kapiteln 4 bis 7 wer-\nden wir deshalb einige knappe Hinweise geben, wie die zuvor d argestellten\nBerechnungen und statistischen Verfahren am Computer mit H ilfe von Ex-\ncel/Calc oder SPSS durchgef \u00a8uhrt werden k \u00a8onnen. Dabei beziehen wir uns auf\nBeispiele des Lehrbuchtextes. Es emp\ufb01ehlt sich f \u00a8ur den Leser, diese Beispiele\nam Computer nachzurechnen. Daten zu den Beispielen sind im I nternet unter\nwww.wisostat.uni-koeln.de/statblb verf\u00a8ugbar.\nEine knappe Einf \u00a8uhrung in die Verwendung von Excel ist im Lehrbuch\u201dDe-\nskriptive Statistik und Wirtschaftsstatistik\u201c (Mosler un d Schmid, 2009) zu\n\ufb01nden. Dort wird der Umgang mit Excel-Tabellen und die Durch f\u00a8uhrung von\nAufgaben der deskriptiven Statistik mit Excel beschrieben .\nDa die Vorgehensweisen in Excel und Calc beinahe identisch s ind, werden\nim weiteren Verlauf die Calc-Notationen verwendet. Auf fun ktionale Unter-\nschiede wird an den entsprechenden Stellen hingewiesen. In sbesondere sei\nangemerkt, dass Dezimalzahlen in Calc mit einem Komma, in SP SS jedoch\nmit einem Punkt geschrieben werden. F \u00a8ur Details \u00a8uber die verschiedenen\nVersionen von Calc und SPSS sei auf deren Online-Hilfefunkt ionen sowie auf\ndie am Ende dieses Abschnitts genannte Literatur verwiesen .\nIm Folgenden bezeichnen Angaben in dieser Schrift Befehle und Buttons\naus dem Calc- bzw. SPSS-Men \u00a8u. Namen von Funktionen einschlie\u00dflich ihrer\nArgumente werden in dieser Schriftart notiert. Text, der per Hand eingegeben\nwerden muss, erscheint in dieser Schrift . (Rechen-) Befehle in der Komman-\ndozeile werden zum Beispiel als = A1 + A2 hervorgehoben.\nCalc Alle Zahlen k \u00a8onnen vom Benutzer f \u00a8ur die Ausgabe\u201dgerundet\u201d ange-\nzeigt werden. Im Folgenden runden wir die Ergebnisse auf vie r Dezimalstellen\n(Format / Zellen / Zahlen \u0592\u2192Auswahl von Zahl beiKategorie \u0592\u2192\nEingabe von 4 in Feld Nachkommastellen undOK). Die Zwischenrech-\nnungen f \u00a8uhrt Calc dabei stets mit allen verf \u00a8ugbaren Dezimalstellen durch.\nSPSS In der Variablenansicht kann unter Dezimalstellen eingestellt\nwerden, wieviele Nachkommastellen die zu einer bestimmten Variablen geh \u00a8o-\nrenden Zahlen aufweisen sollen.\n8Calc sowie weitere OpenO\ufb03ce-Programme k \u00a8onnen unter www.de.openoffice.org her-\nuntergeladen werden.2.6. Anhang: Verwendung von Excel/Calc und SPSS 119\nF\u00a8ur viele Aufgaben der Wahrscheinlichkeitsrechnung und der schlie\u00dfenden\nStatistik bieten die beiden Softwarepakete Funktionen an, die im Rahmen\nvon\u201dMen\u00a8us\u201c aufgerufen werden k \u00a8onnen.\nCalc Die im Folgenden verwendeten Funktionen von Calc sind, sola nge nicht\nanders erkl \u00a8art, im Men \u00a8u unter Einf\u00a8ugen/Funktion (Kategorie Statistik )\nzu \ufb01nden. Weiterhin weisen die auf Wahrscheinlichkeitsver teilungen bezoge-\nnen Funktionen eine bestimmte Struktur auf. Diese sieht bei spielsweise bei\nder Normalverteilung so aus: Verteilungsfunktion und Dich te an der Stelle\nxerh\u00a8alt man mithilfe von NORMVERT(x;Mittelwert;Standabwn;Kumuliert) ,\nwobei\nNORMVERT(x;Mittelwert;Standabwn; wahr)die Verteilungsfunktion und\nNORMVERT(x;Mittelwert;Standabwn; falsch )die Dichte aufruft.\nNORMINV(p;Mittelwert;Standabwn) berechnet die Quantilfunktion an der Stel-\nlep.\nBei einer diskreten Verteilung wird die Wahrscheinlichkei tsfunktion statt der\nDichte berechnet (s.u.). Anstelle von wahrkann man auch jeden beliebigen\nWert/\\e}atio\\slash= 0 eingeben, anstelle von falsch gen\u00a8ugt auch eine 0.\nSPSS Um Daten mit SPSS zu analysieren, beginnt man so: Man liest ei -\nne Datenmatrix in die Datenansicht ein, de\ufb01niert sodann eine Variable\nin der Variablenansicht und weist ihr Daten zu. Dabei muss zumindest\neine metrisch skalierte Variable in der Variablenansicht de\ufb01niert und in\nder Datenansicht initialisiert (z.B. = 0 gesetzt) werden, u m diese dann als\nZielvariable der statistischen Analyse verwenden zu k \u00a8onnen (vgl. Angele\n(2010)).\nDie im Folgenden verwendeten Funktionenfamilien \ufb01ndet man im Men \u00a8u unter\nTransformieren/Berechnen . Namen von Funktionen besitzen in SPSS\neinen typischen Aufbau, der am Beispiel der Binomialvertei lung verdeutlicht\nwerden soll.\nCDF.BINOM(q,n,p) \u223c=CDF (Cumulative Distribution Function) be-\ndeutet Zugri\ufb00 auf die Verteilungsfunktion,\nPDF.BINOM(q,n,p) \u223c=PDF (Probability Density Function) Zugri\ufb00 auf\ndie Dichtefunktion bzw. Wahrscheinlichkeitsfunktion,\nIDF.BINOM(q,n,p) \u223c=IDF (Inverse Distribution Function) Zugri\ufb00 auf\ndie Quantilfunktion,\nRV.BINOM(q,n,p) \u223c=RV (Random Variable) generiert binomialverteilte\nZufallszahlen.\nZur Binomialverteilung (Beispiel 2.15, Seite 77):\nCalc Binomialwahrscheinlichkeiten lassen sich mit der Funktio n\nBINOMVERT(Anzahl Erfolge; Versuche; Erfolgswahrscheinl ichkeit; Kumuliert)\nberechnen. Im Beispiel ist P(X\u22652) gesucht.120 2. Zufallsvariable und Verteilungen\nEs gilt P(X\u22652) = 1\u2212P(X\u22641) = 1\u2212P(X= 0)\u2212P(X= 1). Die L \u00a8osung\nergibt sich f \u00a8urX\u223cB(3,0.3) aus\nP(X\u22652) = 1\u2212BINOMVERT(0;3;0,3; falsch )\n\u2212BINOMVERT(1;3;0,3; falsch )\n= 0.216,\noder alternativ aus\nP(X\u22652) = 1\u2212BINOMVERT(1;3;0,3; wahr)= 0.216.\nSPSS In SPSS l \u00a8asst sich die gesuchte Wahrscheinlichkeit mit den Funktion en\nCDF.BINOM(q,n,p) oderPDF.BINOM(q,n,p) bestimmen:\nP(X\u22652) = 1\u2212PDF.BINOM(0,3,0.3) \u2212PDF.BINOM(1,3,0.3)\n= 1\u2212CDF.BINOM(1,3,0.3)\n= 0.216\nZur Berechnung der Bernoulli-Verteilung enth \u00a8alt SPSS auch die Funktionen\nCDF.BERNOULLI(q,p) bzw.PDF.BERNOULLI(q,p) .\nCalc F\u00a8ur die Berechnung der Binomialverteilung steht in Calc au\u00dfe rdem\ndie Funktion B(Anzahl Versuche; Erfolgswahrscheinlichkeit; a; b) f\u00a8ur\nP(a\u2264X\u2264b) zur Verf \u00a8ugung. Mittels a= 0 kann man auch die kumulierte\nWahrscheinlichkeit P(X\u2264b) berechnen. Im obigen Beispiel gilt dann:\nP(X\u22652) = 1\u2212B(3;0,3;0;1) =B(3;0,3;2;3) = 0.216\nAu\u00dferdem steht in Calc zus \u00a8atzlich noch die Funktion KRITBINOM(Versuche;\nErfolgswahrscheinlichkeit;Alpha) zur Verf \u00a8ugung. Dies ist die Quantilfunktion\nder Binomialverteilung. Sie gibt das kleinste kan, f\u00a8ur das P(X\u2264k)\u2265\u03b1\ngilt. F \u00a8urX\u223cB(n= 3, \u03c0= 0.3) und \u03b1= 0.8 berechnet man:\nk=KRITBINOM(3;0,3;0,8) = 2\nBeachten Sie, dass Excel die Funktion Bnicht unterst \u00a8utzt!\nZur Poissonverteilung (Beispiel 2.17, Seite 80):\nCalc Wahrscheinlichkeiten Poisson-verteilter Zufallsvariab len werden in Calc\nmit der Funktion POISSON(x;Mittelwert;Kumuliert) berechnet. Dabei ent-\nspricht xder Anzahl der F \u00a8alle, w \u00a8ahrend Mittelwert f\u00a8ur den Erwartungswert\n\u00b5steht. Im Beispiel 2.17 ist X\u223cPo(2.5). Man erh \u00a8alt\nP(X= 1) = POISSON(1;2,5; falsch )= 0.2052,\nP(X\u22653) = 1\u2212P(X\u22642) = 1\u2212POISSON(2;2,5; wahr)= 0.4562.2.6. Anhang: Verwendung von Excel/Calc und SPSS 121\nSPSS Zur Berechnung von Poisson-Wahrscheinlichkeiten k \u00a8onnen die Funk-\ntionen CDF.POISSON(q,mittel) undPDF.POISSON(q,mittel) aufgerufen wer-\nden. In SPSS entspricht qder Anzahl xundmittel dem Mittelwert \u00b5der\nPoisson-Verteilung. F \u00a8ur die Beispielaufgabe erh \u00a8alt man\nP(X= 1) = PDF.POISSON(1,2.5) = 0.2052,\nP(X\u22653) = 1\u2212P(X\u22642) = 1\u2212CDF.POISSON(2,2.5) = 0.4562.\nZur hypergeometrischen Verteilung (Beispiel 2.20, Seite 87):\nGesucht ist P(X\u22651),wenn X\u223cH(n= 2, N= 10, M= 3).\nCalc Die L\u00a8osung dieser Aufgabe ergibt sich unter Benutzung der Funkti on\nHYPGEOMVERT(X;n;M;N) als\nP(X\u22651) = 1\u2212P(X= 0) = 1\u2212HYPGEOMVERT(0;2;3;10) = 0.5333.\nBei Calc (und Excel) ist es nicht m \u00a8oglich, kumulierte Wahrscheinlichkeiten\nder hypergeometrischen Verteilung direkt abzurufen. Man k ann sich aber mit\neiner einfachen Tabelle behelfen; vgl. Beispiel22.xls .\nSPSS Zur L \u00a8osung derselben Aufgabe mit SPSS wird die Funktion\nPDF.HYPER(q,gesamt,stichpr,tre\ufb00er) benutzt. Anders als Calc erlaubt es SPSS\nzus\u00a8atzlich, mit der Funktion CDF.HYPER(q,gesamt,stichpr,tre\ufb00er) kumulierte\nWahrscheinlichkeiten der hypergeometrischen Verteilung direkt zu berechnen.\nDaP(X= 0) = P(X\u22640) gilt, l \u00a8asst sich die gegebene Aufgabenstellung mit\njeder der beiden erw \u00a8ahnten Funktionen l \u00a8osen:\nP(X\u22651) = 1\u2212P(X= 0) = 1\u2212PDF.HYPER(0,10,2,3)\n= 1\u2212CDF.HYPER(0,10,2,3) = 0.5333\nZur Exponentialverteilung (Beispiel 2.24, Seite 98):\nCalc Beispiel 2.24 wird in Calc mit der Funktion EXPONVERT(x;Lambda;\nKumuliert) berechnet. F \u00a8ur die in dem Beispiel unter a) gesuchte Wahrschein-\nlichkeit erh \u00a8alt man\nP(X >1000) = 1\u2212EXPONVERT(1000;1\n800;wahr)= 0.2865.\nSPSS SPSS stellt die Funktionengruppe\u2217.EXPzur Verf \u00a8ugung. Man berech-\nnet\nP(X >1000) = 1\u2212CDF.EXP(1000,1\n800)= 0.2865.\nMit dieser Funktionengruppe kann auch Aufgabenteil b) leic ht gel\u00a8ost werden:\nx0.9=IDF.EXP(0.9,1\n800)= 1842 .07122 2. Zufallsvariable und Verteilungen\nZur Pareto-Verteilung (Beispiel 2.25, Seite 101):\nCalc Bei Calc (und Excel) ist keine Funktion f \u00a8ur die Berechnung der Pareto-\nVerteilung verf \u00a8ugbar.\nSPSS In SPSS ist die Funktionenfamilie\u2217.PARETO implementiert. Aufga-\nbenteil a) l \u00a8asst sich mittels der Quantilfunktion IDF.PARETO(p,schwelle,form)\nl\u00a8osen:\nF(x0.5) = 0.5 =\u21d2x0.5=IDF.PARETO(0.5,1500,2.1) = 2086 .60\nF\u00a8ur Aufgabenteil b) verwendet man die Verteilungsfunktion\nCDF.PARETO(q,schwelle,form) :\n1\u2212F(2500) = 1\u2212CDF.PARETO(2500,1500,2.1) = 0.3421\nZur Normalverteilung (Beispiele 2.27 und 2.28, Seiten 106 und 109):\nCalc Rund um die Normalverteilung stellt Calc mehrere Funktione n zur\nVerf\u00a8ugung. Zur L \u00a8osung der ersten Teilaufgabe aus Beispiel 2.27 a) kann die\nVerteilungsfunktion STANDNORMVERT(z) eingesetzt werden. Es gilt\nP(U >0.5) = 1\u2212\u03a6(0.5)\n= 1\u2212STANDNORMVERT(0,5) = 0.3085.\nBeachten Sie, dass die Funktion STANDNORMVERT(z) immer kumuliert\nist, da sie die Verteilungsfunktion \u03a6 der Standardnormalve rteilung darstellt.\nM\u00a8ochte man die Dichtefunktion der Standardnormalverteilun g berechnen, so\nbenutzt man die Funktion NORMVERT(z;0;1; falsch ).\nZur Ermittlung der Quantile x0.2bzw.x0.7mittels Calc wird auf die Quan-\ntilfunktion STANDNORMINV(Wahrsch) zur\u00a8uckgegri\ufb00en:\nx0.2=STANDNORMINV(0,2) =\u22120.8416\nx0.7=STANDNORMINV(0,7) = 0.5244\nNeben der Verteilungsfunktion und der Quantilfunktion der Standardnor-\nmalverteilung bietet Calc auch die entsprechenden Funktio nen f\u00a8ur allgemeine\nNormalverteilungen der Form N(\u00b5, \u03c32) an.\nIm Beispiel 2.28 ist X\u223cN(\u00b5= 2, \u03c32= 25). Die Wahrscheinlichkeit P(X >\n3) l\u00a8asst sich mit der Funktion NORMVERT(x;Mittelwert;Standabwn;Kumuliert)\nberechnen:\nP(X >3) = 1\u2212P(X\u22643) = 1\u2212NORMVERT(3;2;5; wahr)= 0.4207\nDie Quantile xpwerden durch die Funktion NORMINV(Wahrsch;Mittelwert;\nStandabwn) berechnet,\nx0.8=NORMINV(0,8;2;5) = 6.2081,\nx0.95=NORMINV(0,95;2;5) = 10.2243.2.6. Anhang: Verwendung von Excel/Calc und SPSS 123\nSPSS In SPSS lassen sich diese Aufgaben mit Hilfe der Funktionenf amilie\n\u2217.NORMAL(. . . ) bearbeiten. Die Bestimmung von P(X >3) l\u00a8asst sich mit\nder Funktion CDF.NORMAL(q,mittel,stdAbw) wie folgt bewerkstelligen:\nP(X >3) = 1\u2212P(X\u22643)\n= 1\u2212CDF.NORMAL(3,2,5) = 0.4207\nDie Berechnung der Quantile xpkann mit der Funktion\nIDF.NORMAL(p,mittel,stdAbw) \u00a8ahnlich wie in Calc vorgenommen werden:\nx0.8=IDF.NORMAL(0.8,2,5) = 6.2081\nx0.95=IDF.NORMAL(0.95,2,5) = 10.2243\nZur Lognormalverteilung (Abschnitt 2.4.5):\nCalc Calc bietet die Verteilungsfunktion und die Quantilfunkti on der Log-\nnormalverteilung LN(\u00b5, \u03c32). H\u00a8au\ufb01g wird von Aktienkursen angenommen,\ndass sie lognormalverteilt sind. Sei Stder Kurs einer bestimmten Aktie zur\nZeittund gelte\nSt= exp( \u03b1+\u03b2\u00b7t+\u03c3\u00b7Zt),d.h.\nln(St) = \u03b1+\u03b2\u00b7t+\u03c3\u00b7ZtmitZt\u223cN(0, t).\nDann ist St\u223cLN(\u03b1+\u03b2\u00b7t, \u03c32). Als Beispiel sei \u03b1= 1, t= 2, \u03b2=\n0.5 und \u03c3= 5 gew \u00a8ahlt. Gesucht sei P(S1)>1. In Calc wird die Aufga-\nbe mit der Funktion LOGNORMVERT(x;Mittelwert;Standabwn) gel\u00a8ost. Ach-\ntung: Hier sind mit Mittelwert undStandabwn die Parameter \u00b5und\u03c32der\nLN(\u00b5, \u03c32)-Verteilung bezeichnet! F \u00a8ur die genannten Parameter erhalten wir\ndann \u00b5=\u03b1+\u03b2\u00b7t= 1 + 2\u00b70,5 = 2 und damit\nP(S1>1) = 1\u2212P(S1\u22641) = 1\u2212LOGNORMVERT(1;2;5) = 0.6554.\nDie Quantile xpder Lognormalverteilung werden mit der Funktion LOGINV(p;\nMittelwert;Standabwn) bestimmt. Der Median der Lognormalverteilung ist\nmit den genannten Parametern\nx0.5=LOGINV(0,5;2;5) = 7.3890.\nSPSS Die L \u00a8osung der obigen Aufgabe ist in SPSS unter Verwendung der\nFunktionenfamilie\u2217.LNORMAL(q,a,b) m\u00a8oglich. Dabei entspricht (anders als\nin Calc!) adem Median e\u00b5undbdem Parameter \u03c3der Lognormalverteilung\nLN(\u00b5, \u03c32) sowie qdem Argument der Verteilungsfunktion. Mit den obigen\nParametern erhalten wir\nP(S1>1) = 1\u2212P(S1\u22641)\n= 1\u2212CDF.LNORMAL(1,exp(2),5) = 0.6554,\nx0.5=IDF.LNORMAL(0.5,exp(2),5) = 7.3890.124 2. Zufallsvariable und Verteilungen\nLiteratur zur Verwendung von Computerprogrammen:\nElementare Einf \u00a8uhrungen in die Durchf \u00a8uhrung statistischer Verfahren mit\nExcel und SPSS bieten Monka et al. (2008) und Hafner und Waldl (2001).\nZwerenz (2007) stellt den Einsatz von Excel bei vielf \u00a8altigen Aufgabenstel-\nlungen der Statistik dar und beinhaltet dar \u00a8uber hinaus interaktive Zahlen-\nbeispiele und Simulationen. Eine allgemeine Einf \u00a8uhrung in Excel bieten die\nBrosch \u00a8uren RRZN (2006) und RRZN (2007).9\nAls anwendungsnaher Einstieg in SPSS f \u00a8ur Wirtschaftswissenschaftler ist\nEckstein (2008) zu empfehlen. Angele (2010) leitet dar \u00a8uber hinaus zur Im-\nplementierung von Verfahren in SPSS an. Toutenburg und Heum ann (2008)\nist ein Lehrbuch der Wahrscheinlichkeitsrechnung und schl ie\u00dfenden Stati-\nstik, das zahlreiche Beispiele zur Verwendung von SPSS mit W irtschaftsdaten\nenth\u00a8alt.\nM\u00a8oglichkeiten der Auswertung von Daten mit dem Computer biet en auch in-\nteraktive Lernprogramme wie Teach/Me (Lohninger, 2002) un d die Software\nvon Schaich und M \u00a8unnich (2001).\n9N\u00a8aheres im Internet unter www.uni-koeln.de/RRZK/dokument ation/handbuecher/,\n\u201dDie Handb \u00a8ucher des RRZ Niedersachsen (RRZN)\u201c.", "language": "PDF", "image": "PDF", "pagetype": "PDF", "links": "PDF"}