{"title": "Basiswissen Medizinische Statistik (Springer-Lehrbuch) - PDF Free Download", "author": "Guest", "url": "https://epdf.tips/basiswissen-medizinische-statistik-springer-lehrbuch.html", "hostname": "epdf.tips", "description": "Christel Wei\u00df Basiswissen Medizinische Statistik Christel Wei\u00dfBasiswissen Medizinische Statistik 4., \u00fcberarbeitete ...", "sitename": "EPDF.TIPS", "date": "2015-05-18", "id": null, "license": null, "body": null, "comments": "", "commentsbody": null, "raw_text": null, "text": "Christel Wei\u00df Basiswissen Medizinische Statistik\nChristel Wei\u00df\nBasiswissen Medizinische Statistik 4., \u00fcberarbeitete Auflage Mit 40 Abbildungen, 15 Tabellen und 9 \u00dcbersichten\n13\nDr. Christel Wei\u00df, Dipl.-Math.\nProf. Dr. Berthold Rzany, M. Sc.\nUniversit\u00e4tsklinikum Mannheim Medizinische Fakult\u00e4t der Universit\u00e4t Heidelberg Medizinische Statistik Ludolf-Krehl-Str. 7\u201311 68135 Mannheim\nDivision of Evidence Based Medicine (dEBM) Klinik f\u00fcr Dermatologie, Venerologie und Allergologie Charit\u00e9 \u2013 Universit\u00e4tsmedizin Berlin Campus Charit\u00e9 Mitte Charit\u00e9platz 1 10117 Berlin\nBibliografische Information der Deutschen Bibliothek Die Deutsche Bibliothek verzeichnet diese Publikation in der Deutschen Nationalbibliografie; detaillierte bibliografische Daten sind im Internet \u00fcber http://dnb.d-nb.de abrufbar.\nISBN-13\n978-3-540-71460-6\nDieses Werk ist urheberrechtlich gesch\u00fctzt. Die dadurch begr\u00fcndeten Rechte, insbesondere die der \u00dcbersetzung, des Nachdrucks, des Vortrags, der Entnahme von Abbildungen und Tabellen, der Funksendung, der Mikroverfilmung oder der Vervielf\u00e4ltigung auf anderen Wegen und der Speicherung in Datenverarbeitungsanlagen, bleiben, auch bei nur auszugsweiser Verwertung, vorbehalten. Eine Vervielf\u00e4ltigung dieses Werkes oder von Teilen dieses Werkes ist auch im Einzelfall nur in den Grenzen der gesetzlichen Bestimmungen des Urheberrechtsgesetzes der Bundesrepublik Deutschland vom 9. September 1965 in der jeweils geltenden Fassung zul\u00e4ssig. Sie ist grunds\u00e4tzlich verg\u00fctungspflichtig. Zuwiderhandlungen unterliegen den Strafbestimmungen des Urheberrechtsgesetzes.\nSpringer Medizin Verlag springer.de \u00a9 Springer Medizin Verlag Heidelberg 1999, 2002, 2005, 2008 Produkthaftung: F\u00fcr Angaben \u00fcber Dosierungsanweisungen und Applikationsformen kann vom Verlag keine Gew\u00e4hr \u00fcbernommen werden. Derartige Angaben m\u00fcssen vom jeweiligen Anwender im Einzelfall anhand anderer Literaturstellen auf ihre Richtigkeit \u00fcberpr\u00fcft werden. Die Wiedergabe von Gebrauchsnamen, Handelsnamen, Warenbezeichnungen usw. in diesem Werk berechtigt auch ohne besondere Kennzeichnung nicht zu der Annahme, dass solche Namen im Sinne der Markenschutz-Gesetzgebung als frei zu betrachten w\u00e4ren und daher von jedermann benutzt werden d\u00fcrften. Planung: Kathrin N\u00fchse, Heidelberg Projektmanagement: Axel Treiber, Heidelberg Umschlaggestaltung & Design: deblik Berlin Satz: Reproduktionsfertige Autorenvorlage Druck- und Bindearbeiten: St\u00fcrtz, W\u00fcrzburg SPIN 12037018 Gedruckt auf s\u00e4urefreiem Papier\n15/2117 \u2013 5 4 3 2 1 0\nV Vorwort\nVorwort zur vierten Auflage Es gibt keine gute Medizin ohne Biostatistik. Dieser Satz wird m\u00f6glicherweise bei einigen Medizinstudenten auf Unverst\u00e4ndnis sto\u00dfen. Warum sollte sich ein Mediziner mit Biostatistik befassen, und warum ist dieses Fach Teil der \u00e4rztlichen Ausbildung? \u2013 \u00c4rztliches Handeln muss auf Wissen basieren. Ansonsten verfallen wir Zuf\u00e4llen und Halbwahrheiten, die auch dadurch nicht besser werden, dass sie mantrahaft wiederholt werden. Dies w\u00e4re unter ethischen, medizinischen und \u00f6konomischen Aspekten nicht vertretbar. Medizinische Forschung ohne Statistik ist nicht m\u00f6glich. Ist Biostatistik unattraktiv? Keineswegs! Es gibt sogar Mediziner, die dieses Fach faszinierend finden. Erst eine statistische Analyse erm\u00f6glicht es, Daten zu strukturieren, Zusammenh\u00e4nge aufzudecken, Ergebnisse zu interpretieren und in der Praxis anzuwenden. Jeder Arzt, der wissenschaftliche Publikationen gelesen oder selbst erstellt hat, wei\u00df dies. Den meisten Studenten wird dies sp\u00e4testens beim Schreiben ihrer Doktorarbeit bewusst. Der schlechte Ruf, der diesem Fach vorauseilt, ist dadurch begr\u00fcndet, dass statistische Methoden auf mathematischen Formeln basieren, die f\u00fcr manche ein Gr\u00e4uel sind. Als Anwender der Statistik muss man diese Formeln jedoch nicht herleiten k\u00f6nnen oder gar auswendig lernen (zumal die Rechnungen \u00fcblicherweise von einer geeigneten Software durchgef\u00fchrt werden). Man sollte vielmehr verstehen, wie statistische Methoden sinnvoll in der Medizin angewandt werden. Jedem, der diesem Fachgebiet unbefangen begegnet, erschlie\u00dfen sich \u00e4u\u00dferst interessante Anwendungsm\u00f6glichkeiten. Ziel dieses Buches ist es, Studenten und interessierten \u00c4rzten einen kompetenten \u00dcberblick \u00fcber die wichtigsten statistischen Anwendungen in der Medizin zu geben. Dar\u00fcber hinaus gew\u00e4hrt dieses Buch einen umfassenden \u00dcberblick \u00fcber epidemiologische Studien. Es ist nicht nur Studenten bei deren Klausur- und Examensvorbereitungen n\u00fctzlich, sondern auch als Nachschlagekompendium geeignet. \u2013 F\u00fcr die vierte Auflage wurde der gesamte Text \u00fcberarbeitet, aktualisiert und an einigen Stellen erg\u00e4nzt. Das bew\u00e4hrte didaktische Konzept wurde beibehalten. Alle Methoden werden verst\u00e4ndlich dargestellt und anhand von einfachen Beispielen erl\u00e4utert. Die mathematischen Formeln werden nicht nur aufgelistet, sondern auch \u2013 soweit dies mit schulmathematischen Kenntnissen m\u00f6glich ist \u2013 hergeleitet. Diese Abhandlungen sind jedoch nicht in den laufenden Text eingebettet. Der Leser kann bei\nVI\nVorwort\nInteresse die Formeln nachvollziehen; f\u00fcr das grunds\u00e4tzliche Verst\u00e4ndnis des Stoffes ist dies jedoch nicht erforderlich. Des Weiteren wurden die MultipleChoice-Aufgaben erg\u00e4nzt. Man findet man sie \u2013 separat f\u00fcr jedes Buchkapitel \u2013 mit kommentierten L\u00f6sungen auf den Internet-Seiten des Springer-Verlages unter www.lehrbuch-medizin/medstatistik. Viele haben zum Gelingen dieses Buches beigetragen. Ich danke sehr herzlich meinem Coautoren, Herrn Prof. Dr. med. Berthold Rzany, Sc. M. (Master of Science in Clinical Epidemiology), f\u00fcr seine wertvolle Hilfe und zahlreiche medizinisch-fachliche Ratschl\u00e4ge. Er war als Mediziner und Epidemiologe bereits Coautor der ersten drei Auflagen und auch bei der vierten Auflage (insbesondere bei den Kapiteln 13 bis 16) ma\u00dfgeblich beteiligt. Ferner bedanke ich mich bei meinen Mitarbeitern Herrn Joachim Brade, Frau Sylvia B\u00fcttner \u02c7 und Frau Rosemarie Cern\u00fd. Herr Brade hat den gesamten Text der Kapitel 1 bis 12 durchgearbeitet, kritisch kommentiert und zahlreiche eigene Ideen ein\u02c7 flie\u00dfen lassen. Frau B\u00fcttner und Frau Cern\u00fd haben mich ebenfalls mit sehr viel Engagement und didaktischen Anregungen unterst\u00fctzt. Sie zeichnen sich verantwortlich f\u00fcr die graphischen Darstellungen und das gesamte Layout. Danken m\u00f6chte ich auch Frau Kathrin N\u00fchse und Herrn Axel Treiber vom Springer-Verlag f\u00fcr die hervorragende Zusammenarbeit. Zahlreiche Leser haben mir \u00c4nderungsvorschl\u00e4ge zukommen lassen; auch ihnen sei herzlich gedankt. Nicht zuletzt danke ich meinen beiden T\u00f6chtern Judith und Miriam f\u00fcr ihr Verst\u00e4ndnis und ihre emotionale Unterst\u00fctzung. Wie sieht die Zukunft der Biostatistik aus? Unser Wissen und unser Handeln werden sich \u2013 im Sinne der Evidenzbasierten Medizin \u2013 immer mehr auf das kollektive Gesamtwissen st\u00fctzen. Deshalb wird dieses Fach f\u00fcr die klinische und die forschende Medizin immmer wichtiger werden. Weitere Informationen, Zusammenfassungen, Multiple-Choice-Aufgaben und ein Statistik-Lexikon findet man im Internet unter www.lehrbuch-medizin/ medstatistik und www.ma.uni-heidelberg/inst/biom. Selbstverst\u00e4ndlich freue ich mich \u00fcber Anregungen und konstruktive Kritik an\n[[email protected]](/cdn-cgi/l/email-protection)\n.\nChristel Wei\u00df\nMannheim, im Oktober 2007\nVII\n1976 1976 \u2013 1983 1986 \u2013 1992\n1991 1991 1992 \u2013 heute seit November 1999\nAbitur Studium der Mathematik und Physik an der Johannes-Gutenberg-Universit\u00e4t Mainz Wissenschaftliche Mitarbeiterin an der Abteilung f\u00fcr Experimentelle Chirurgie an der Universit\u00e4t Heidelberg Promotion zum Doctor scientiarum humanarum Anerkennung als Medizinischer Informatiker durch die GMDS Mathematikerin am Universit\u00e4tsklinikum Mannheim Leiterin der Abteilung f\u00fcr Medizinische Statistik\nSchl\u00fcsselbegriffe:\nBasiswissen Medizinische Statistik\nsind fett und kursiv hervorgehoben\nInhaltliche Struktur: klare Gliederung durch alle Kapitel 38\nLeitsystem: schnelle Orientierung \u00fcber alle Kapitel\n3\nKapitel 3 \u00b7 H\u00e4ufigkeiten\n3.1\nH\u00e4ufigkeiten bei diskreten Merkmalen\n3.1.1\nAbsolute und relative H\u00e4ufigkeiten\nUm sich einen \u00dcberblick bez\u00fcglich wesentlicher Eigenschaften eines Merkmals anzueignen, beginnt man mit der H\u00e4ufigkeitsverteilung. Diese Verteilung beschreibt, wie h\u00e4ufig die einzelnen Merkmalsauspr\u00e4gungen in der Stichprobe zu finden sind. k\n\u00a6n\ni\nInfo: zus\u00e4tzliche\n=n\n(3.1)\ni =1\nInformationen zum jeweiligen Thema\ni Bei dem Summen-Zeichen \u01b6 handelt es sich um den griechischen z Buchstaben Sigma. Damit werden Summen in verk\u00fcrzter Schreibweise k\ndargestellt. Der Ausdruck\n\u00a6n\ni\nentspricht der Summe n1 + n2 + ... + nk .\ni =1\nVerweise auf Kapitel, Tabellen, Herleitungen und Beispiele:\nIn der Praxis gewinnt man die H\u00e4ufigkeiten am einfachsten durch das Erstellen einer Strichliste oder \u2013 weniger m\u00fchsam \u2013 mittels einer \u203a Beispiel 3.1). geeigneten Software (z z\ndeutlich herausgestellt und leicht zu finden\nBeispiel 3.1 Wir betrachten das qualitative Merkmal \u201eBlutgruppe\u201c mit den Daten der in Tabelle 2.1 aufgelisteten Stichprobe von n = 71 Beobachtungseinheiten. Es ergeben sich folgende H\u00e4ufigkeiten: Auspr\u00e4gung absolute H\u00e4ufigkeiten relative H\u00e4ufigkeiten n1 = 28 A1 =Blutgruppe 0 h1 = 39 %\nBeispiele: zum besseren Verst\u00e4ndnis des Stoffes\nTabellen: klar und \u00fcbersichtlich gegliedert\nA2 =Blutgruppe A\nn2 = 31\nh2 = 44 %\nA3 =Blutgruppe B\nn3 = 9\nh3 = 13 %\nA4 =Blutgruppe AB\nn4 = 3\nh4 = 4 %\nSumme\nn = 71\n100%\n! Die relative H\u00e4ufigkeit wird oft in Prozentwerten angegeben. Da der z\nAusdruck Prozent \u201evon Hundert\u201c bedeutet, sind derlei Angaben nur bei einem hinreichend gro\u00dfen Stichprobenumfang sinnvoll. Wenn man bei kleineren Stichproben mit weniger als 50 Beobachtungseinheiten Prozente berechnet, t\u00e4uscht man eine h\u00f6here Genauigkeit vor als in Wirklichkeit vorhanden ist. In diesen F\u00e4llen sollte man anstelle der Prozentangaben einfache Quotienten bevorzugen \u2013 wie z. B.: Die relative H\u00e4ufigkeit der Blutgruppe A bei den m\u00e4nnlichen Studenten betr\u00e4gt 10/23.\nCave: Vorsicht Fallstricke!\nNavigation: Seitenzahl und Kapitelnummer f\u00fcr die schnelle Orientierung\n3\n39 3.1 H\u00e4ufigkeiten bei diskreten Merkmalen\nAbb. 3.1 Kreisdiagramm; Darstellung der H\u00e4ufigkeiten des Merkmals \u201eBlutgruppe\u201c (Beispiel 3.1)\nZahlreiche Abbildungen: veranschaulichen komplizierte und komplexe Sachverhalte\nMathematische Herleitung des Korrelationskoeffizineten nach Pearson Es ist offenkundig, dass die Kovarianz sxy genau dann maximal wird, wenn der Zusammenhang funktional ist und durch eine lineare Gleichung y = a + bx exakt beschrieben werden kann. Dann erh\u00e4lt man nach den Definitionen der Kovarianz und der Varianz in (5.1) und (4.6): n\n\u00a6x y i\ns xy =\ni\n\u2212 nxy\ni =1\nn\n\u00a6 x (a + bx ) \u2212 nx (a + bx ) i\n= n \u22121 F\u00fcr die Varianz s y 2 ergibt sich: n\n\u00a6( y\ni\n\u2212 y )2\nn\ni\ni =1\nn \u22121\n=\nb( \u00a6 xi2 \u2212 nx 2 ) i =1\nn \u22121\n= bsx 2\nn\nb2 \u00a6 ( xi \u2212 x )2\n= i =1 = b2 sx 2 s y 2 = i =1 n \u22121 n \u22121 F\u00fcr positives b ist s y = bsx und s xy = bs x 2 = sx \u22c5 s y . F\u00fcr negatives b folgt ana-\nHerleitungen: Logisches Nachvollziehen einer Formel zum besseren Verst\u00e4ndnis\nlog: s y = \u2212 bsx und sxy = \u2212 sx \u22c5 s y . Da es sich hierbei um die beiden Extremf\u00e4lle handelt, folgt f\u00fcr die Kovarianz: \u2212 sx \u22c5 s y \u2264 sxy \u2264 sx \u22c5 s y . Daraus ergibt sich f\u00fcr sxy den Korrelationskoeffizienten r = : \u22121 \u2264 r \u2264 1 . sx \u22c5 s y\nMerke Anhand eines Diagramms lassen sich bei quantitativen Merkmalen folgende Eigenschaften ablesen: \u0177 Lage: In welchem Bereich konzentrieren sich die Werte? Welches ist der gr\u00f6\u00dfte, welches der kleinste Wert? Welche Auspr\u00e4gungen sind h\u00e4ufig, welche selten oder gar nicht vertreten? \u0177 Streuung: Streuen die Werte weit um den Mittelwert? Gibt es Ausrei\u00dfer? \u0177 Form: Hat die Verteilung eine besondere Form? Ist sie symmetrisch oder schief? Wie viele Gipfel sind erkennbar?\nAufz\u00e4hlungen: Lerninhalte \u00fcbersichtlich pr\u00e4sentiert\nMerke: das Wichtigste auf den Punkt gebracht\nSagen Sie uns Ihre Meinung! www.lehrbuch-medizin.de\nwww.lehrbuch-medizin/medstatistik\nDie Website zum Buch\nLexikon xVerstehen: nicht nur Formeln, auch die Begriffe machen Statistik kompliziert. Im Lexikon finden Sie \u00fcber 290 Begriffe erkl\u00e4rt\nLerncenter x\u00dcberblicken: die wichtigsten Punkte der einzelnen Kapitel kurz zusammengefasst xAnwenden: stapelweise Examensfragen der Statistik mit L\u00f6sungskommentaren\nxAbhaken: angegebene Lernziele verdeutlichen Lernerfolg in Bezug auf Gegenstandskatalog\nAnmerkungen? Fragen? 7\n[[email protected]](/cdn-cgi/l/email-protection)\nWir freuen uns!\nSagen Sie uns die Meinung!\nLiebe Leserin und lieber Leser, Sie wollen gute Lehrb\u00fccher lesen, wir wollen gute Lehrb\u00fccher machen: dabei k\u00f6nnen Sie uns helfen!\nLob und Kritik, Verbesserungsvorschl\u00e4ge und neue Ideen k\u00f6nnen Sie auf unserem Feedback-Fragebogen unter www.lehrbuch-medizin.de gleich online loswerden. Als Dankesch\u00f6n verlosen wir jedes Jahr Buchgutscheine f\u00fcr unsere Lehrb\u00fccher im Gesamtwert von 500 Euro.\nWir sind gespannt auf Ihre Antworten! Ihr Lektorat Lehrbuch Medizin\nXIII Inhaltsverzeichnis\nInhaltsverzeichnis Teil I:\nDeskriptive Statistik\n1 1.1 1.2 1.3 1.4 1.5\nEinleitung Die Bedeutung der Statistik f\u00fcr die Medizin 3 Zur Geschichte der medizinischen Statistik 4 Der Status der medizinischen Statistik 11 Die Phasen einer medizinischen Studie 13 Anwendungen in Beruf und Studium 15\n2 2.1 2.2 2.3 2.4 2.5\nTheoretische Grundlagen Grundgesamtheit und Stichprobe 19 Die Aufgaben der deskriptiven Statistik 20 Merkmale 21 Besondere Problematiken 29 Listen und Tabellen 32\n3 3.1 3.2 3.3 3.4\nH\u00e4ufigkeiten H\u00e4ufigkeiten bei diskreten Merkmalen 39 H\u00e4ufigkeiten bei stetigen Merkmalen 42 Die empirische Verteilungsfunktion 46 2-dimensionale H\u00e4ufigkeiten 49\n4 4.1 4.2 4.3 4.4 4.5\nDie Beschreibung eines Merkmals Die Methoden der univariaten Statistik 55 Lagema\u00dfe 55 Streuungsma\u00dfe 64 Formma\u00dfe 69 Der Vergleich mehrerer Stichproben 73\n5 5.1 5.2 5.3 5.4\nDie Beschreibung eines Zusammenhangs Die Methoden der bivariaten Statistik 79 Die Korrelationsanalyse 80 Die Regressionsanalyse 88 Weitere Techniken 94\nXIV Teil II:\nWahrscheinlichkeitsrechung\n6 6.1 6.2 6.3 6.4 6.5\nWahrscheinlichkeiten in der Medizin Die Aufgaben der Wahrscheinlichkeitsrechnung 101 Das Rechnen mit Wahrscheinlichkeiten 102 Wahrscheinlichkeiten in der Epidemiologie 111 Bev\u00f6lkerungsstatistiken 114 Diagnostische Tests 118\n7 7.1 7.2 7.3\nDiskrete Verteilungen Diskrete Zufallsvariable 125 Die Binomialverteilung 129 Andere diskrete Verteilungen 136\n8 8.1 8.2 8.3 8.4 8.5\nStetige Verteilungen Stetige Zufallsvariable 145 Die Normalverteilung 148 S\u00e4tze der Wahrscheinlichkeitsrechnung 155 Die Verteilung von \u00dcberlebenszeiten 162 Pr\u00fcfverteilungen 166\nTeil III:\nInduktive Statistik\n9 9.1 9.2 9.3 9.4\nSch\u00e4tzverfahren Grundlagen 173 Punktsch\u00e4tzungen 173 Intervallsch\u00e4tzungen 177 Abschlie\u00dfende Bemerkungen 184\n10 10.1 10.2 10.3\nDas Prinzip eines statistischen Tests Die Durchf\u00fchrung eines Tests 189 Testentscheidung und Konsequenzen 195 Klassifikation der Testmethoden 202\nXV Inhaltsverzeichnis\n11 11.1 11.2 11.3 11.4\nLagetests t-Tests 207 Rangsummentests 215 Vorzeichentests 222 Ausblick auf komplexere Methoden 224\n12 12.1 12.2 12.3 12.4\nTests zum Vergleich von H\u00e4ufigkeiten Der Binomialtest f\u00fcr eine Stichprobe 229 Chi2-Tests 231 Der exakte Test nach Fisher 243 Ausblick auf die logistische Regression 245\nTeil IV: Epidemiologie (Coautor: Prof. Dr. Berthold Rzany, Sc. M., Master of Science in Clinical Epidemiology) 13 13.1 13.2 13.3 13.4 13.5\nEpidemiologische Studien Aufgaben und Ziele der Epidemiologie 249 Der Inhalt epidemiologischer Studien 250 Klassifikation nach formalen Aspekten 251 Fehlerquellen 255 Die Studienplanung 258\n14 14.1 14.2 14.3 14.4 14.5\nRisikostudien Einleitung 263 Deskriptive Studien 264 Fall-Kontroll-Studien 267 Kohortenstudien 272 Der Nachweis einer Kausalit\u00e4t 277\n15 15.1 15.2\nStudien zu Diagnostik und Pr\u00e4vention Diagnosestudien 281 Pr\u00e4ventionsstudien 288\n16 16.1 16.2 16.3\nStudien zu Therapie und Prognose Therapiestudien 295 Prognosestudien 306 Evidenzbasierte Medizin 310\nXVI Anhang Tabellen 317 Glossar Englisch-Deutsch 324 Abk\u00fcrzungen \u2013 Abbreviations 327 Weiterf\u00fchrende Literatur 328 Sach- und Personenregister 329 \u00dcbersicht 1: \u00dcbersicht 2: \u00dcbersicht 3: \u00dcbersicht 4: \u00dcbersicht 5: \u00dcbersicht 6: \u00dcbersicht 7: \u00dcbersicht 8: \u00dcbersicht 9:\nDie Skalenniveaus 26 Univariate Datenbeschreibung \u2013 geeignete Ma\u00dfzahlen und graphische Darstellungen 73 Rechenregeln f\u00fcr Wahrscheinlichkeiten 111 Kenngr\u00f6\u00dfen diagnostischer Tests 122 Analoge Begriffe aus der deskriptiven Statistik und der Wahrscheinlichkeitsrechnung 128 Diskrete Verteilungen 142 Stetige Verteilungen 170 Statistische Tests 204 Studientypen 250\n1\nEinleitung 1.1\nDie Bedeutung der Statistik f\u00fcr die Medizin 3\n1.2\nZur Geschichte der medizinischen Statistik 4\n1.2.1\nDie historische Entwicklung der Statistik 5\n1.2.2\nDie Methodik in der medizinischen Wissenschaft 6\n1.2.3\nAnwendungen der Statistik in der Medizin 8\n1.3\nDer Status der medizinischen Statistik 11\n1.4\nDie Phasen einer medizinischen Studie 13\n1.5\nAnwendungen in Beruf und Studium 15\n3 1.1 Die Bedeutung der Statistik f\u00fcr die Medizin\n1.1\nDie Bedeutung der Statistik f\u00fcr die Medizin\nJeder medizinische Wissenschaftler und jeder praktisch t\u00e4tige Arzt wei\u00df aus Erfahrung, dass alle Erkenntnisse und Entscheidungen in der Medizin mit einer gewissen Unsicherheit verbunden sind. In diesem Punkt unterscheiden sich die Biowissenschaften grundlegend von den exakten Naturwissenschaften: W\u00e4hrend die Zusammenh\u00e4nge in der Mathematik oder der theoretischen Physik determiniert und damit berechenbar sind (etwa aufgrund einer mathematischen Gleichung oder eines physikalischen Gesetzes), unterliegen die Zust\u00e4nde und Vorg\u00e4nge bei biologischen Systemen nicht nur naturwissenschaftlichen Gesetzen, sondern auch dem Zufall. Aus diesem Grund lassen sich die Eigenschaften eines Individuums oder medizinisch-biologische Abl\u00e4ufe allenfalls absch\u00e4tzen, aber niemals exakt berechnen oder vorhersagen. Im Allgemeinen sind zwar zahlreiche Faktoren bekannt, die ein bestimmtes Merkmal beeinflussen. So ist etwa das K\u00f6rpergewicht eines Menschen abh\u00e4ngig von dessen Alter und Geschlecht; au\u00dferdem sind genetische Einfl\u00fcsse, die K\u00f6rpergr\u00f6\u00dfe, pathologische und psychische Besonderheiten sowie eine Reihe weiterer Einflussgr\u00f6\u00dfen ma\u00dfgebend. Es wird jedoch niemals m\u00f6glich sein, alle das K\u00f6rpergewicht bestimmenden Faktoren zu benennen und deren Einfluss im Einzelnen zu quantifizieren. Dazu sind die Vorg\u00e4nge und Zusammenh\u00e4nge im menschlichen Organismus viel zu komplex und von unserem Verstand nicht mehr nachvollziehbar. Man geht deshalb davon aus, dass das K\u00f6rpergewicht \u2013 wie alle anderen physiologischen Parameter \u2013 letztlich auch dem Zufall unterliegt. Ebenso kennt man bei fast allen Krankheiten diverse Faktoren, die deren Entstehen m\u00f6glicherweise verursachen oder deren Auftreten beg\u00fcnstigen. So wei\u00df man beispielsweise, dass bei Menschen, die in permanenter Anspannung leben, stark rauchen sowie unter erh\u00f6htem Blutdruck und starkem \u00dcbergewicht leiden, die Gefahr eines Herzinfarkts besonders hoch ist, und jeder verantwortungsbewusste Arzt wird einen Risikopatienten darauf hinweisen. Dessen ungeachtet gibt es Personen, die mit all diesen Risikofaktoren steinalt werden, ohne jemals einen Herzinfarkt zu erleiden \u2013 wie zum Beispiel Winston Churchill, der an seinem 90. Geburtstag auf die Frage, wie er so alt geworden sei, geantwortet haben soll: \u201eSmoking, drinking and \u2013 first of all \u2013 no sports\u201c. Andererseits bietet eine vermeintlich gesunde Lebensweise, die alle bekannten Risikofaktoren ausschlie\u00dft, keinen zuverl\u00e4ssigen Schutz vor dieser Krankheit.\n1\n4\n1\nKapitel 1 \u00b7 Einleitung\nSchlie\u00dflich ist auch hier der Zufall mitentscheidend. Aus diesem Grund kann bei keinem Menschen pr\u00e4zise vorhergesagt werden, ob eine bestimmte Krankheit im Laufe seines Lebens eintreten wird oder nicht. In Einzelf\u00e4llen kann der Zufall zu extremen Werten oder zu unerwarteten Ereignissen f\u00fchren. Deshalb erlebt jeder Mediziner hin und wieder \u00dcberraschungen \u2013 angenehmer oder unangenehmer Art. Dies gilt f\u00fcr den Wissenschaftler, dessen Forschungsergebnisse stets eine gewisse Irrtumswahrscheinlichkeit beinhalten, ebenso wie f\u00fcr den behandelnden Arzt, der den Verlauf einer Krankheit nicht vorhersehen kann und niemals mit absoluter Sicherheit wei\u00df, ob eine therapeutische Ma\u00dfnahme den gew\u00fcnschten Erfolg erzielen wird. Die Statistik als die Wissenschaft des Zufalls stellt nun Methoden zur Verf\u00fcgung, die es erm\u00f6glichen, trotz der Unberechenbarkeit der Einzelf\u00e4lle allgemein g\u00fcltige Aussagen herzuleiten. Diese bilden die Basis f\u00fcr jede neue wissenschaftliche Erkenntnis und jedes daraus abgeleitete \u00e4rztliche Handeln. Wann immer ein Arzt eine Entscheidung zu treffen hat, wird er sich an seiner eigenen Erfahrung sowie an diesen allgemeinen Grunds\u00e4tzen orientieren. Dieses Vorgehen garantiert zwar nicht, dass eine Entscheidung in jedem Fall richtig ist und zum erhofften Ergebnis f\u00fchrt. Sie ist aber nachvollziehbar, und das Risiko einer Fehlentscheidung ist minimiert. Der Zufall wird bei dieser Vorgehensweise nicht eliminiert, aber quantifiziert und damit kontrollierbar gemacht. Neues Wissen in der Medizin kann nur unter Anwendung statistischer Methoden gewonnen werden. Auch wenn pers\u00f6nliche Erfahrungen nach wie vor eine wichtige S\u00e4ule des \u00e4rztlichen Entscheidungsprozesses darstellen, sind die Kenntnis biometrischer Methoden und die F\u00e4higkeit, deren Resultate sinnvoll zu interpretieren, unabdingbar. Insofern ist Statistik f\u00fcr die Medizin unentbehrlich, sowohl um Forschung zu betreiben als auch, um deren Ergebnisse praktisch anzuwenden.\n1.2\nZur Geschichte der medizinischen Statistik\nDie Medizin ist eine Jahrtausende alte Wissenschaft. Dennoch ist es erst in den vergangenen Jahrzehnten \u00fcblich geworden, neue Erkenntnisse in der medizinischen Forschung mit statistischen Methoden abzusichern. Um diesen erstaunlich langen Prozess nachvollziehen zu k\u00f6nnen, ist es notwendig, sich mit der historischen Ent-\n5 1.2 Zur Geschichte der medizinischen Statistik\nwicklung der Statistik zu befassen und au\u00dferdem einige Aspekte der Medizingeschichte zu beleuchten. 1.2.1\nDie historische Entwicklung der Statistik\n\u2022 Anf\u00e4nge. Das prim\u00e4re Anwendungsgebiet der Statistik bestand ur spr\u00fcnglich in der Staatsbeschreibung. Bereits im 4. Buch Mose \u201eNumeri\u201c wird eine Volksz\u00e4hlung erw\u00e4hnt; ferner sind aus dem Altertum Volksz\u00e4hlungen aus \u00c4gypten und Griechenland bekannt. Dabei ging es vorwiegend um die Beschreibung geographischer, politischer und wirtschaftlicher Besonderheiten, wie sie heute noch im Statistischen Jahrbuch der Bundesrepublik Deutschland ver\u00f6ffentlicht werden. Aus den Methoden der Staatsbeschreibung entwickelte sich die beschreibende oder deskriptive Statistik, deren Aufgabe darin besteht, Zust\u00e4nde und Vorg\u00e4nge \u00fcbersichtlich darzustellen. Bis heute werden Methoden der deskriptiven Statistik in vielen Bereichen der Wirtschaft, der Verwaltung, des Versicherungswesens und bei der Volksz\u00e4hlung angewandt, wo statistische Erhebungen als Grundlage f\u00fcr Planungen dienen. Sehr lange Zeit \u2013 bis ins 18. Jahrhundert hinein \u2013 wurde Statistik fast ausschlie\u00dflich f\u00fcr staatliche Zwecke benutzt. Dies erkl\u00e4rt dieselbe etymologische Wurzel der W\u00f6rter \u201eStatistik\u201c und \u201eStaat\u201c (vom lateinischen Wort \u201estatus\u201c = Zustand, Beschaffenheit). \u2022 16. - 19. Jahrhundert. In England begann man zu Beginn des 16. Jahrhunderts auf Veranlassung des Lordkanzlers Thomas Cromwell (1485-1540), alle Geburts- und Todesf\u00e4lle systematisch in Kirchenb\u00fcchern aufzuzeichnen. Dies veranlasste John Graunt (1620-1674) dazu, basierend auf Londoner Geburts- und Sterberegistern, Gesetzm\u00e4\u00dfigkeiten bez\u00fcglich der Bev\u00f6lkerungsbewegung herzuleiten. Graunt gilt als der Begr\u00fcnder der Demographie; sein Werk bildete sp\u00e4ter die Grundlage f\u00fcr die Berechnung von Lebensversicherungen. Kurze Zeit danach widerlegte der englische Arzt und Schriftsteller John Arbuthnot (1667-1735) die These, dass M\u00e4dchen- und Knabengeburten gleich h\u00e4ufig seien, indem er Daten aus Kirchenb\u00fcchern auswertete. Auch in Deutschland wurden seit dem Ende des 17. Jahrhunderts Kirchenb\u00fccher gef\u00fchrt. Das bahnbrechende Werk der deutschen Bev\u00f6lkerungsstatistik mit dem Titel \u201eDie g\u00f6ttliche Ordnung in den Ver\u00e4nderungen des menschlichen Geschlechts\u201c wurde von dem preu\u00dfischen Feldprediger Johann Peter S\u00fc\u00dfmilch (17071767) erstellt. Die Gesetzm\u00e4\u00dfigkeiten, die er dabei entdeckte, f\u00fchrte er auf das Wirken Gottes zur\u00fcck. Diese Art von Statistik, die dazu\n1\n6\n1\nKapitel 1 \u00b7 Einleitung\ndiente, Bev\u00f6lkerungsentwicklungen quantitativ zu beschreiben, bezeichnete man als politische Arithmetik. Daneben gab es eine Anwendergruppe mit g\u00e4nzlich anderen Interessen: Ihnen ging es darum, die Gewinnchancen bei Gl\u00fccksspielen zu berechnen. Dadurch wurden Mathematiker wie Galileo Galilei (1564-1642), Blaise Pascal (1623-1662), Christiaan Huygens (1629-1695) und Pierre Simon Marquis de Laplace (1749-1827) zur Berechnung von bestimmten Wahrscheinlichkeiten und zu theoretischen Abhandlungen angeregt. Sie haben damit die Wahrscheinlichkeitsrechnung wesentlich bereichert. In diesem Zusammenhang ist auch der deutsche Mathematiker Carl Friedrich Gau\u00df (1777-1855) zu nennen, der u. a. die Normalverteilung und deren Bedeutung f\u00fcr die angewandte Statistik beschrieben hat. \u2022 Moderne Statistik. Die Wahrscheinlichkeitsrechnung ist die Grundlage der induktiven Statistik, die es erm\u00f6glicht, aufgrund einer relativ kleinen Stichprobe Aussagen bez\u00fcglich einer weitaus gr\u00f6\u00dferen Grundgesamtheit herzuleiten. Diese Methoden wurden erst im 20. Jahrhundert entwickelt. Besonders hervorzuheben sind dabei William Sealy Gosset (1876-1937), der die t-Verteilung herleitete, Karl Pearson (1857-1936), der die Korrelations- und Regressionsanalysen vorantrieb, und Sir Ronald Aylmer Fisher (1890-1962), auf den u. a. die Varianzanalyse zur\u00fcckgeht. Diese und andere Verfahren haben entscheidend dazu beigetragen, dass die Statistik in den Bio- und Sozialwissenschaften mittlerweile breite Anwendung findet. 1.2.2\nDie Methodik in der medizinischen Wissenschaft\nDie Medizin als eine Wissenschaft, deren Zweck darin besteht, kranken Menschen zu helfen, ist so alt wie die Menschheit selbst. Als eine moderne Wissenschaft im heutigen Sinne kann sie jedoch erst seit dem 19. Jahrhundert aufgefasst werden. \u2022 Antike. \u00dcber eine sehr lange Zeit \u2013 von der Antike bis ins 19. Jahrhundert hinein \u2013 konnten Beobachtungen am kranken Menschen fast ausschlie\u00dflich durch unmittelbare Sinneseindr\u00fccke des behandelnden Arztes erfasst werden. Diese Beobachtungen waren naturgem\u00e4\u00df subjektiv und die daraus gezogenen Schlussfolgerungen h\u00e4ufig spekulativ. Generell gab es zwei unterschiedliche Ans\u00e4tze bez\u00fcglich der Wahl einer geeigneten Therapie: den theoretischen und den empirischen. Der Theoretiker suchte nach den Krankheitsursachen und leitete dann durch logisch-konsequente Schlussfolgerungen eine seiner Meinung nach n\u00fctzliche therapeutische Ma\u00dfnahme her. Diese dogmatische Methode basierte auf unverr\u00fcckbaren, nie\n7 1.2 Zur Geschichte der medizinischen Statistik\nzuvor \u00fcberpr\u00fcften Grundannahmen, die generell nicht in Frage gestellt wurden. Der Empiriker gr\u00fcndete seine Entscheidungen auf pers\u00f6nliche Erfahrungen und \u00fcberpr\u00fcfte sie in jedem Einzelfall. Allerdings waren die dadurch gewonnenen Erkenntnisse ungeregelt, da sie lediglich auf einzelnen, zuf\u00e4lligen Beobachtungen beruhten. Die Autorit\u00e4ten der beiden griechischen \u00c4rzte Hippokrates von Kos (ca. 460-370 v. Chr.) und Galen aus Pergamon (130-201) f\u00fchrten dazu, dass die dogmatische Methode (also der theoretische Ansatz) bis ins 16. Jahrhundert allgemein anerkannt war. Wegen der Autorit\u00e4tsgl\u00e4ubigkeit jener Zeit wagte es niemand, sich kritisch mit ihr auseinander zu setzen. Eine moderne Wissenschaft im heutigen Sinne konnte auf diese Weise freilich nicht entstehen. \u2022 Renaissance. Der Ursprung f\u00fcr die Wissenschaftlichkeit der Medizin lag in der Renaissance. Ein herausragender Wissenschaftler jener Epoche war Galileo Galilei, der weniger durch seine Einzelleistungen auf den Gebieten der Mathematik, Physik und Astronomie Bedeutung erlangte als vielmehr dadurch, dass er die moderne Naturwissenschaft auf objektiven Beobachtungen und nachvollziehbaren Experimenten aufbaute. Naturvorg\u00e4nge wurden fortan nicht mehr theologisch oder philosophisch erkl\u00e4rt, sondern aus Naturgesetzen hergeleitet. Diese neue Methode begr\u00fcndete eine rasante Entwicklung der Physik und der Chemie, was sp\u00e4ter auch die Medizin nachhaltig beeinflussen sollte. Nach der Einf\u00fchrung naturwissenschaftlicher Methoden in die Medizin wurden subjektive Sinneseindr\u00fccke durch objektive Messwerte ersetzt, die sich mathematisch analysieren lassen. Erkenntnisse, die man auf diese Weise erh\u00e4lt, sind nachvollziehbar und bilden wiederum die Grundlage f\u00fcr weitere Forschungen. Die Fortschritte in den Naturwissenschaften haben sich in vielfacher Hinsicht segensreich auf die Medizin ausgewirkt. Sie f\u00fchrten zu einem umfangreichen Wissen bez\u00fcglich der Vorg\u00e4nge im menschlichen K\u00f6rper und damit zu einem besseren Verst\u00e4ndnis der K\u00f6rperfunktionen beim gesunden und beim kranken Menschen. Basierend auf naturwissenschaftlichen Erkenntnissen wurden technische Apparate entwickelt, die eine exakte Messung von physiologischen Parametern erlaubten und im Laufe der Zeit ungeahnte M\u00f6glichkeiten in Diagnostik und Therapie er\u00f6ffneten. \u2022 Aufkl\u00e4rung. Man erkannte allm\u00e4hlich, dass sich alle medizini schen Ph\u00e4nomene theoretisch auf naturwissenschaftliche Gesetze zur\u00fcckf\u00fchren lassen. Im 17. Jahrhundert dachten deshalb einige \u00c4rzte euphorisch, dass man bald in der Lage sein werde, die Ursachen aller Krankheiten zu ergr\u00fcnden und wirksame Therapien zu\n1\n8\n1\nKapitel 1 \u00b7 Einleitung\nentwickeln. Es setzte sich dann jedoch \u2013 beginnend im 18. Jahrhundert zur Zeit der Aufkl\u00e4rung \u2013 die Erkenntnis durch, dass physikalisches und chemisches Grundwissen daf\u00fcr bei weitem nicht ausreicht. So besann man sich auf eine Methode zur Erkenntnisgewinnung, die bereits ein Jahrhundert zuvor von dem englischen Philosophen Francis Bacon (1561-1626) propagiert worden war. Sie beinhaltete die Beobachtung zahlreicher Einzelf\u00e4lle, die l\u00fcckenlose Aufzeichnung der erhobenen Daten und deren rechnerische Auswertung. Dieser Ansatz vermittelte objektive Erkenntnisse, die jedoch vom Zufall beeinflusst waren. Er bedeutete einen Wechsel von einem ehemals theoretisch-dogmatischen hin zu einem empirischen Ansatz. So begann allm\u00e4hlich die Statistik, Einzug in die Medizin zu halten. Statistische Methoden erm\u00f6glichen es, Erfahrungen abzusichern \u2013 auch dann, wenn diese (noch) nicht auf molekularer oder zellul\u00e4rer Ebene erkl\u00e4rt werden k\u00f6nnen. \u2022 20. Jahrhundert. Es sollte allerdings noch bis weit ins 20. Jahr hundert dauern, ehe statistische Methoden in den Biowissenschaften akzeptiert wurden. Dies lag nicht zuletzt daran, dass allgemein anerkannte Richtlinien bez\u00fcglich der medizinischen Forschung am Menschen fehlten. Diese wurden erst im Jahre 1964 auf der 18. Generalversammlung des Welt\u00e4rztebundes in Helsinki erarbeitet. Heute herrscht weitgehend Konsens dar\u00fcber, dass \u2013 au\u00dfer der Anwendung naturwissenschaftlicher Erkenntnisse \u2013 die Beobachtung von Individuen und die damit verbundene Datenanalyse f\u00fcr die medizinische Forschung unverzichtbar sind. 1.2.3\nAnwendungen der Statistik in der Medizin\n\u2022 Wurzeln in England. Der Forderung Bacons, zahlreiche Einzel f\u00e4lle zu beobachten und auszuwerten, stand zun\u00e4chst entgegen, dass sich die Medizin bis ins 18. Jahrhundert hinein traditionellerweise nur mit einzelnen Patienten befasste. Bacons neuer Erfahrungsbegriff war grundlegend daf\u00fcr, dass fortan klinische Studien durchgef\u00fchrt und die daraus erhobenen Daten analysiert wurden. Er kam zun\u00e4chst in England, wenn auch z\u00f6gerlich, zur Anwendung. Aufgrund dieser Entwicklungen ist es nicht erstaunlich, dass die ersten medizinischen Publikationen mit statistischen Analysen in England erschienen. Edward Jenner (1749-1823) verifizierte statistisch die prophylaktische Wirkung der Kuhpockenimpfung. Der Rechtsanwalt Edwin Chadwick (1800-1890) beschrieb die Gesundheit der arbeitenden Klassen in England und gab damit der Hygienebewegung wichtige Impulse. Seine Daten gr\u00fcndeten sich auf statistische Ana-\n9 1.2 Zur Geschichte der medizinischen Statistik\nlysen von William Farr (1807-1883), der Berichte \u00fcber Todesursachen in England publiziert hatte. John Snow (1813-1858) entdeckte, dass das Cholera-Risiko in London mit der Qualit\u00e4t des Trinkwassers zusammenhing. Seine Forschungsarbeiten z\u00e4hlen zu den ersten und spektakul\u00e4rsten Leistungen auf dem Gebiet der Epidemiologie. Freilich waren die damals verwendeten statistischen Verfahren nicht zu vergleichen mit den heute gebr\u00e4uchlichen. Es handelte sich \u00fcberwiegend um einfache arithmetische Operationen. Dennoch war diese Vorgehensweise geeignet, die theoretisch-dogmatische Medizin grundlegend zu reformieren und in ihrer Methodik den Naturwissenschaften anzupassen. Pionierarbeit auf diesem Gebiet leistete der bereits erw\u00e4hnte Sir Ronald Aylmer Fisher, der sich u. a. intensiv mit den Themen \u201eVersuchsplanung und -auswertung\u201c befasste. \u2022 Auswirkungen auf Europa. Im 18. Jahrhundert entstanden in einigen europ\u00e4ischen St\u00e4dten wie z. B. in Paris oder Wien Krankenh\u00e4user, die die Beobachtung gr\u00f6\u00dferer Kollektive erm\u00f6glichten. Als der Begr\u00fcnder der klinischen Statistik gilt Pierre Charles Alexandre Louis (1787-1872), der eine naturwissenschaftlich orientierte Medizin vertrat. Er \u00fcberpr\u00fcfte die Wirkung des Aderlasses und wies \u2013 nachdem diese Methode Jahrhunderte lang angewandt worden war \u2013 mittels statistischer Analysen nach, dass dieses Mittel nutzlos oder gar sch\u00e4dlich war. Ignaz Philipp Semmelweis (1818-1865) war der erste bekannte Mediziner im deutschsprachigen Raum, der den Nutzen einer neuen Therapie mit statistischen Methoden belegte. Semmelweis war seit 1846 Assistent in der Geburtsklinik des Wiener Allgemeinen Krankenhauses, die aus zwei Abteilungen bestand. Die Mortalit\u00e4tsraten der W\u00f6chnerinnen differierten sehr stark: Zwischen 1841 und 1846 starben in der einen Abteilung durchschnittlich 9,9%, in der anderen dagegen nur 3,4% der Frauen. In der Abteilung mit der geringeren Mortalit\u00e4tsrate arbeiteten nur Hebammen. In der anderen Abteilung waren \u00c4rzte und Studenten, die auch Leichen sezierten, als Geburtshelfer t\u00e4tig. Die Mortalit\u00e4tsrate in der Abteilung der \u00c4rzte war gro\u00dfen Schwankungen unterworfen. Semmelweis beobachtete, dass sie immer dann besonders hoch war, wenn viele pathologische Studien durchgef\u00fchrt wurden. In Zeiten allerdings, in denen keine Leichen seziert wurden, waren die Mortalit\u00e4tsraten in beiden Abteilungen etwa gleich. Dieser Zusammenhang war f\u00fcr Semmelweis zun\u00e4chst nicht erkl\u00e4rbar. Das ausschlaggebende Moment f\u00fcr seine Entdeckung war der Tod seines Freundes und Kollegen Jakob Kolletschka, der sich beim Sezieren versehentlich mit dem Messer verletzt hatte. Semmelweis erkannte beim Studium des Sektionsprotokolls die Parallelit\u00e4t der beiden Krankheits-\n1\n10\n1\nKapitel 1 \u00b7 Einleitung\nbilder des Kindbettfiebers und des Wundfiebers. Er vermutete, dass die Ursachen in beiden F\u00e4llen dieselben waren: Die \u00c4rzte und Studenten aus der pathologischen Abteilung \u00fcbertrugen den geb\u00e4renden Frauen \u201eLeichenteilchen\u201c, die das Kindbettfieber verursachten. Dies war in der damaligen Zeit, als bakteriologische Erreger noch unbekannt waren, eine sehr gewagte Hypothese. Semmelweis setzte gegen den Widerstand seiner Kollegen hygienische Ma\u00dfnahmen durch; die Sterblichkeit sank daraufhin drastisch auf unter 2% in beiden Abteilungen. Im Jahr 1861 ver\u00f6ffentlichte er seine Entdeckung in einer ausf\u00fchrlichen Arbeit, die auch eine statistische Analyse beinhaltete. Obwohl Semmelweis seine Hypothese eindrucksvoll best\u00e4tigen konnte, wurden seine aus heutiger Sicht bahnbrechenden Erkenntnisse zu seinen Lebzeiten nicht anerkannt. Etwas sp\u00e4ter, im Jahre 1865, stellte der Augustinerm\u00f6nch Gregor Johann Mendel (18221884) seine Vererbungsgesetze vor, die er nach einer langen und m\u00fchsamen Forschungsarbeit ebenfalls mit statistischen Methoden verifiziert hatte. Auch diese Erkenntnisse fanden zun\u00e4chst keine gro\u00dfe Beachtung. \u2022 Entwicklung in Deutschland. Die in England, Paris oder Wien durchgef\u00fchrten Studien nahmen deutsche \u00c4rzte kaum zur Kenntnis. Es gab Kommunikationsprobleme, die nicht nur sprachlicher Art waren. Dies lag u. a. am damals herrschenden Zeitgeist. Deutschland stand unter dem Einfluss der romantischen Naturphilosophie, bei der das Individuum im Vordergrund stand. Ein Vertreter dieser Denkrichtung war beispielsweise der Begr\u00fcnder der Hom\u00f6opathie Christian Friedrich Samuel Hahnemann (1755-1843). Eine bev\u00f6lkerungsbezogene und naturwissenschaftlich orientierte Medizin sowie die Anwendung statistischer Methoden konnten sich bei dieser Grundeinstellung kaum durchsetzen. Au\u00dferdem war man bis zur Mitte des 19. Jahrhunderts gewohnt, dass Wissenschaftler den deterministischen Verlauf eines Geschehens angeben konnten. Man forderte Gewissheit und nicht Unsicherheit. Semmelweis konnte jedoch im Einzelfall nicht vorhersagen, ob eine Frau die Geburt \u00fcberleben w\u00fcrde; er konnte nur gewisse Wahrscheinlichkeiten angeben. Diese fundamentale Eigenschaft der Statistik \u2013 sie erlaubt keine gesicherten Aussagen bez\u00fcglich eines Einzelfalls, sondern nur f\u00fcr eine gro\u00dfe Menge von Personen oder Objekten \u2013 wird auch heute noch von vielen Anwendern emotional als Nachteil anstatt als n\u00fcchterne Tatsache angesehen. Im \u00dcbrigen l\u00e4sst sich das Ph\u00e4nomen, wonach neue Methoden zun\u00e4chst sehr skeptisch beurteilt werden, bis in die heutige Zeit hinein beobachten.\n11 1.3 Der Status der medizinischen Statistik\n\u2022 20. Jahrhundert. Aus all diesen Gr\u00fcnden hat sich die Anwendung der Statistik in der Medizin lange verz\u00f6gert. Ein weiterer Grund f\u00fcr die mangelnde Akzeptanz lag in der Statistik selbst. Erst im 20. Jahrhundert wurden Methoden entwickelt, mit denen sich anhand einer relativ kleinen Stichprobe allgemein g\u00fcltige Zusammenh\u00e4nge nachweisen lassen. Diese Methoden haben der medizinischen Wissenschaft enorme Impulse verliehen. Dem Internisten Paul Martini (1889-1964) sowie den Biostatistikern Arthur Linder (1904-1993) und Erna Weber (1897-1988), deren B\u00fccher lange Zeit als Standardwerke galten, ist es zu verdanken, dass die von England ausgehenden Ideen auch im deutschen Sprachgebiet bekannt und praktisch umgesetzt wurden. Nicht zuletzt hat das Aufkommen leistungsf\u00e4higer Computer und benutzerfreundlicher Software seit Beginn der 1980er Jahre zu einer enormen Vereinfachung und Beschleunigung statistischer Berechnungen gef\u00fchrt. Auch diese neuere Entwicklung hat entscheidend zur Akzeptanz der Statistik in der Medizin beigetragen. Seit den 1990er Jahren werden zunehmend multiple Methoden entwickelt, bei denen mehrere Einflussgr\u00f6\u00dfen simultan untersucht werden, und die eine sehr effiziente Datenanalyse erm\u00f6glichen. Diese werden in einer Biomathematik-Vorlesung f\u00fcr Mediziner normalerweise nicht detailliert behandelt. Interessierte Leser seien auf weiterf\u00fchrende Literatur verwiesen [1, 2, 4, 10].\n1.3\nDer Status der medizinischen Statistik\n\u2022 Medizinische Statistik oder Biostatistik. Sie hat sich mittlerweile als ein eigenst\u00e4ndiges, interdisziplin\u00e4res Fachgebiet etabliert, das statistische Probleme behandelt, die sich aus medizinischen Fragestellungen ergeben. Im weiteren Sinne z\u00e4hlen dazu die Planung und Durchf\u00fchrung von medizinisch-wissenschaftlichen Studien sowie die Datenanalyse mit statistischen Methoden. Sie ist einerseits Teilgebiet der Biomathematik, andererseits geh\u00f6rt sie zur Stochastik. In engem Zusammenhang dazu steht die Biometrie. Dieser Wissenschaftszweig befasst sich mit der mathematischen Modellierung von zufallsabh\u00e4ngigen Ph\u00e4nomenen in der Medizin, Pharmazie, Biologie und Landwirtschaft.\n1\n12\n1\nKapitel 1 \u00b7 Einleitung\n! F\u00fcr den Begriff \u201eBiometrie\u201c existieren unterschiedliche Definitionen. z\nW\u00e4hrend er einerseits als Synonym f\u00fcr Biostatistik verstanden wird, bezieht er sich in der Informatik auf die Verarbeitung individueller k\u00f6rperlicher Merkmale wie etwa dem Fingerabdruck zum Identit\u00e4tsnachweis von Personen. Auf diese spezielle Bedeutung wird in diesem Buch nicht eingegangen.\n\u2022 Biomathematik. Dieses Fach behandelt die Theorie und Anwen dung mathematischer Methoden im Bereich der Biowissenschaften. Sie beinhaltet au\u00dfer der Statistik noch weitere mathematische Disziplinen. \u2022 Stochastik. Dieser Begriff umfasst den gesamten Wissenschaftsbe reich, der sich mit der mathematischen Behandlung von Zufallserscheinungen befasst. Teilgebiete der Stochastik sind:\n\u0177 die Statistik, \u0177 die Wahrscheinlichkeitsrechnung sowie \u0177 fachspezifische Anwendungsgebiete. \u2022 Statistik. Im allgemeinen Sinne versteht man darunter eine Me thode, mit der Daten analysiert werden, um so zu neuen Erkenntnissen zu gelangen. Man unterscheidet generell zwischen deskriptiver und induktiver Statistik. W\u00e4hrend in der deskriptiven Statistik Daten strukturiert, zusammengefasst und \u00fcbersichtlich dargestellt werden, erm\u00f6glicht die induktive Statistik den Schluss \u00fcber den Beobachtungsbereich hinaus auf die dar\u00fcber liegende Grundgesamtheit. Mit den Methoden der induktiven Statistik lassen sich Hypothesen, die vor Studienbeginn aufgestellt werden, \u00fcberpr\u00fcfen und statistisch absichern. In den letzten zwanzig Jahren hat sich eine weitere Form der Datenanalyse herauskristallisiert \u2013 n\u00e4mlich die explorative Statistik. Deren Ziel besteht darin, bei einer gro\u00dfen Datenmenge Auff\u00e4lligkeiten und Hinweise auf m\u00f6gliche Zusammenh\u00e4nge zu entdecken und darauf basierend neue Hypothesen zu generieren. \u2022 Wahrscheinlichkeitsrechnung. Sie befasst sich mit den mathema tisch-theoretischen Gesetzm\u00e4\u00dfigkeiten, auf denen die Verfahren der induktiven Statistik basieren. Zu den fachspezifischen Anwendungsgebieten z\u00e4hlen u. a. die medizinische Statistik, die Qualit\u00e4tssicherung und die Entscheidungstheorie in der Unternehmensforschung.\n13 1.4 Die Phasen einer medizinischen Studie\n1.4\nDie Phasen einer medizinischen Studie\nDie Medizin ist eine empirische Wissenschaft, deren Erkenntnisse auf Erfahrungen basieren. Ein Forschungsprozess beginnt in der Regel damit, dass ein Wissenschaftler, nachdem er hinreichend viele Erfahrungen gesammelt hat, nach l\u00e4ngerem Nachdenken oder aufgrund einer genialen Idee einen Zusammenhang entdeckt, der bis dahin noch unbekannt gewesen ist. Diese neue Erkenntnis ist allerdings zun\u00e4chst nicht mehr als eine vage Vermutung. Um sie zu verifizieren, muss eine wissenschaftliche Studie durchgef\u00fchrt werden. \u2022 Beginn einer Studie. Zun\u00e4chst sollte sich der Forscher in der so genannten Erkundungsphase anhand von relevanter Literatur \u00fcber den aktuellen Wissensstand kundig machen und eventuell mit kompetenten Fachleuten dar\u00fcber diskutieren, ob die geplante Studie sinnvoll und notwendig ist. Danach wird er in der theoretischen Phase seine Vermutung als Hypothese formulieren und versuchen, diese in eine logisch konsistente Theorie einzubetten. Damit ist die Hypothese theoretisch abgesichert und herleitbar. Diese Art wissenschaftlicher Methodik \u2013 das Herleiten einer neuen Hypothese aus einer bekannten Theorie \u2013 nennt man deduktiv. \u2022 Statistische Analyse. Streng deduktiv arbeitet man fast nur in der reinen Mathematik. Neue mathematische S\u00e4tze werden aus bekannten Theorien hergeleitet; weitergehende Studien oder Experimente sind dazu nicht notwendig. Erkundungsphase - Literaturstudium, Diskussion mit Fachleuten etc. | Theoretische Phase - Formulierung einer Hypothese, Einbetten in eine Theorie | Analytisch-statistische Phase - Planung, Datenerhebung, -beschreibung und -analyse | Interpretation der Ergebnisse - Entscheidung f\u00fcr oder gegen die Hypothese Abb. 1.1 Die Phasen einer medizinischen Studie\n1\n14\n1\nKapitel 1 \u00b7 Einleitung\nDa jedoch eine Theorie in der Medizin niemals vollst\u00e4ndig sein kann und deshalb die Realit\u00e4t nicht in allen Details genau beschreibt, muss die zu verifizierende Hypothese empirisch best\u00e4tigt werden. Dazu ist die analytisch-statistische Phase erforderlich. Diese beinhaltet eine detaillierte Planung sowie die Datenerhebung und Datenauswertung mit statistischen Methoden. Bei retrospektiven Studien sind die Daten in der Regel bereits dokumentiert und m\u00fcssen nur noch in passender Weise aufbereitet werden; bei prospektiven Beobachtungsstudien oder experimentellen Studien sind die Daten zun\u00e4chst zu erheben, ehe sie statistisch analysiert werden k\u00f6nnen. \u2022 Interpretation der Ergebnisse. Wenn die Ergebnisse der statisti schen Analyse die Theorie best\u00e4tigen, wird man sich f\u00fcr die Richtigkeit der daraus hergeleiteten Hypothese entscheiden. Diese ist damit zwar nicht bewiesen im mathematischen Sinne, aber doch wesentlich besser abgesichert als vor der statistischen Analyse. Eine falsche Entscheidung ist hierbei nicht ausgeschlossen \u2013 dieses Risiko ist jedoch kalkulierbar. Falls das Ergebnis der Datenanalyse mit der Theorie nicht in Einklang zu bringen ist, muss \u00fcberpr\u00fcft werden, ob die Theorie einen Fehler enth\u00e4lt, oder ob die analytisch-statistische Phase nicht optimal verlaufen ist. Eventuell kann eine Wiederholung der Studie in modifizierter Form in Erw\u00e4gung gezogen werden. Die Methode, wonach vom Besonderen (n\u00e4mlich der Stichprobe) auf das Allgemeine (die Grundgesamtheit) geschlossen wird, nennt man induktiv. Dieses Verfahren wurde aus den Naturwissenschaften \u00fcbernommen. Auch bei naturwissenschaftlichen Experimenten werden \u2013 \u00e4hnlich wie bei medizinischen Studien \u2013 Daten erhoben und ausgewertet, um funktionale Zusammenh\u00e4nge zu erkennen und diese dann zu allgemein g\u00fcltigen Naturgesetzen zu erkl\u00e4ren. Allerdings unterscheiden sich naturwissenschaftliche Experimente in einem wichtigen Punkt von medizinischen Untersuchungen. In den Naturwissenschaften arbeitet man unter kontrollierten Bedingungen im Labor; der Zufall spielt dabei keine oder allenfalls eine untergeordnete Rolle. Dagegen hat man es in der Medizin mit Individuen zu tun, bei denen die potentiellen Einflussgr\u00f6\u00dfen wegen ihrer Vielzahl und Komplexit\u00e4t kaum kontrollierbar sind. Aus diesem Grund m\u00fcssen sich alle Wissenschaftler, die menschliche Eigenschaften untersuchen \u2013 seien es Mediziner, Psychologen, Soziologen oder Politologen \u2013, mit dem Zufall und mit Statistik auseinander setzen.\n15 1.5 Anwendungen in Beruf und Studium\n1.5\nAnwendungen in Beruf und Studium\nDie meisten medizinischen Publikationen (Artikel in Fachzeitschriften, Dissertationen und Habilitationen) beinhalten statistische Analysen. Ausnahmen bilden allenfalls Publikationen in F\u00e4chern wie Geschichte oder Ethik der Medizin sowie Einzelfalldarstellungen, bei denen nur ein einziger oder einige wenige, besonders interessante F\u00e4lle untersucht und beschrieben werden. Diese liefern m\u00f6glicherweise Hinweise auf andere, \u00e4hnlich gelagerte F\u00e4lle. Sie lassen jedoch im Gegensatz zu einer Stichprobenuntersuchung keine Verallgemeinerungen zu. Alle Mediziner, die forschen und publizieren, ben\u00f6tigen statistische Methoden, um Untersuchungen durchzuf\u00fchren, deren Ergebnisse darzustellen und zu verallgemeinern. Die Statistik ist dabei eine unentbehrliche Hilfswissenschaft \u2013 \u00e4hnlich wie die Mathematik in der Physik. Auch ein praktisch t\u00e4tiger Arzt betreibt Statistik \u2013 wenn auch nicht in formalisierter Form, sondern eher auf intuitive Art und Weise. Wenn er etwa einen Laborwert danach bewertet, ob er innerhalb oder au\u00dferhalb des Normbereichs liegt, wenn er aufgrund eines diagnostischen Tests zu beurteilen versucht, ob eine bestimmte Krankheit vorliegt oder nicht, wenn er aufgrund vorhandener Symptome eine Diagnose stellt, wenn er den zu erwartenden Nutzen und die Risiken einer Therapie gegeneinander abw\u00e4gt und sich dann f\u00fcr oder gegen eine bestimmte Ma\u00dfnahme entscheidet \u2013 dann liegen all diesen Entscheidungen, oft unbewusst, statistische Analysen zugrunde. Theoretische Kenntnisse auf diesem Gebiet lassen erkennen, dass man bei spontanen, intuitiven Entscheidungen oft einem gro\u00dfen Irrtum unterliegt. Sie tragen deshalb wesentlich dazu bei, vorsichtig zu entscheiden und verantwortungsbewusst zu handeln. Im \u00dcbrigen ist jeder Arzt \u2013 unabh\u00e4ngig von seinem Arbeitsgebiet \u2013 angehalten, sich permanent weiterzubilden, da sich das medizinische Wissen rasant vermehrt. Dabei ben\u00f6tigt er statistische Kenntnisse, um gute von schlechten Studien zu unterscheiden und um die Relevanz der dargestellten Ergebnisse f\u00fcr seine Patienten oder sein Labor beurteilen zu k\u00f6nnen. Nicht zuletzt schult die Biomathematik einen Anwender im problemorientierten, logisch-analytischen Denken. Auch diese F\u00e4higkeiten sind f\u00fcr einen Arzt unentbehrlich.\n1\n16\n1\nKapitel 1 \u00b7 Einleitung\nInsofern ist die Besch\u00e4ftigung mit der Biostatistik als Vorbereitung f\u00fcr den k\u00fcnftigen Beruf n\u00fctzlich und sinnvoll. Im Allgemeinen ist ein Student sp\u00e4testens beim Erstellen seiner Dissertation gezwungen, sich mit Statistik auseinander zu setzen. Zum einen ist dies notwendig, um relevante Fachartikel und Vortr\u00e4ge zu verstehen und zu bewerten; zum anderen liegt fast jeder Dissertation eine statistische Datenanalyse zugrunde. Es ist f\u00fcr einen Doktoranden der Medizin oder f\u00fcr einen in der Forschung t\u00e4tigen Arzt durchaus empfehlenswert, sich dabei von einem Statistiker beraten zu lassen. Dies ist aber nur dann hilfreich, wenn er selbst zumindest \u00fcber elementare, statistische Kenntnisse verf\u00fcgt \u2013 so wie dieses Buch sie zu vermitteln sucht.\n2\nTheoretische Grundlagen 2.1\nGrundgesamtheit und Stichprobe 19\n2.2\nDie Aufgaben der deskriptiven Statistik 20\n2.3\nMerkmale 21\n2.3.1\nGrundbegriffe 21\n2.3.2\nZiel- und Einflussgr\u00f6\u00dfen 22\n2.3.3\nKlassifikation nach Skalenniveau 23\n2.3.4\nDiskrete und stetige Merkmale 25\n2.3.5\nSkalentransformationen 25\n2.3.6\nMerkmalsauspr\u00e4gungen 28\n2.4\nBesondere Problematiken 29\n2.5\nListen und Tabellen 32\n19\n2\n2.1 Grundgesamtheit und Stichprobe\n2.1\nGrundgesamtheit und Stichprobe\nDie Hypothesen, die in den Bio- und Sozialwissenschaften aufgestellt werden, beziehen sich meist auf eine sehr gro\u00dfe Anzahl von Individuen oder Objekten. Es w\u00e4re aus organisatorischen und zeitlichen Gr\u00fcnden viel zu aufwendig oder sogar vollkommen unm\u00f6glich, die gesamte Population zu untersuchen, auf die eine Hypothese zutreffen k\u00f6nnte. Dies ist im Allgemeinen auch gar nicht notwendig. Die moderne Statistik stellt n\u00e4mlich Methoden zur Verf\u00fcgung, die es erm\u00f6glichen, basierend auf einer relativ kleinen Stichprobe allgemein g\u00fcltige Aussagen bez\u00fcglich einer weitaus gr\u00f6\u00dferen Grundgesamtheit herzuleiten. Eine Total- oder Vollerhebung wird daher nur in Ausnahmef\u00e4llen durchgef\u00fchrt. Beispielsweise beruhen die Todesursachenstatistiken, die im j\u00e4hrlich erscheinenden Statistischen Jahrbuch der Bundesrepublik Deutschland ver\u00f6ffentlicht werden, medizinische Register oder die Ergebnisse einer politischen Wahl auf einer Vollerhebung. Im Allgemeinen beschr\u00e4nkt man sich jedoch \u2013 insbesondere in der medizinischen Forschung \u2013 auf die Untersuchung einer relativ kleinen Teilmenge, n\u00e4mlich der Stichprobe, und \u00fcbertr\u00e4gt die daraus gewonnenen Erkenntnisse auf die Grundgesamtheit. Dies ist allerdings nur unter der Voraussetzung sinnvoll, dass die charakteristischen Eigenschaften der Stichprobe \u2013 abgesehen von zuf\u00e4llig bedingten Abweichungen \u2013 mit denen der Grundgesamtheit \u00fcbereinstimmen. Eine solche Stichprobe hei\u00dft repr\u00e4sentativ. Bei vielen Untersuchungen ist man vor das Problem gestellt, aus einer konkret vorgegebenen Grundgesamtheit eine repr\u00e4sentative Stichprobe zu w\u00e4hlen. Ein Beispiel hierf\u00fcr stellt eine Umfrage vor einer politischen Wahl dar. Die Grundgesamtheit besteht in diesem Fall aus allen wahlberechtigten B\u00fcrgern. Um eine Prognose zu erstellen, beschr\u00e4nkt man sich auf eine Stichprobe von einigen tausend Personen. Diese Stichprobe muss repr\u00e4sentativ und hinreichend gro\u00df sein, damit sie das endg\u00fcltige Wahlergebnis in brauchbarer Weise widerspiegelt. Bei Untersuchungen in der Medizin ist die Problemstellung h\u00e4ufig umgekehrt: Gegeben sind eine oder mehrere konkrete Stichproben (beispielsweise Patienten, die im Rahmen einer klinischen Studie beobachtet werden). Dann ist zu kl\u00e4ren, wie die dazugeh\u00f6rende Grundgesamtheit beschaffen ist und ob die Stichprobenergebnisse auf diese \u00fcbertragbar sind. Eine Antwort auf diese Frage beruht mehr auf sachlogischen als auf wahrscheinlichkeitstheoretischen\n20\n2\nKapitel 2 \u00b7 Theoretische Grundlagen\n\u00dcberlegungen und ist eng mit dem jeweiligen Forschungsvorhaben verkn\u00fcpft. Oft l\u00e4sst sich die entsprechende Grundgesamtheit gar nicht konkret angeben. Man sollte sich in jedem Fall davor h\u00fcten, allzu weit reichende Schlussfolgerungen zu ziehen, die sich hinterher als falsch herausstellen k\u00f6nnten. Dieses Problem kann man zwar umgehen, indem man eine Untersuchung nur f\u00fcr einen speziellen, eng begrenzten Personenkreis durchf\u00fchrt und diesen als Grundgesamtheit auffasst. Allerdings gelten die dadurch gewonnenen Ergebnisse nur eingeschr\u00e4nkt auf die Menge der untersuchten Personen und lassen sich nicht verallgemeinern.\n2.2\nDie Aufgaben der deskriptiven Statistik\nAus dem obigen Abschnitt geht hervor, dass bei einer Stichprobenuntersuchung die statistische Analyse aus zwei Teilen besteht. Zun\u00e4chst werden die Daten der Stichprobe ausgewertet mit dem Ziel, deren charakteristische Eigenschaften zu beschreiben. Dies ist das Aufgabengebiet der deskriptiven Statistik. Dazu z\u00e4hlen im Einzelnen:\n\u0177 das Zusammenfassen und Ordnen der Daten in Tabellen, \u0177 das Erstellen von Diagrammen und \u0177 das Berechnen charakteristischer Kenngr\u00f6\u00dfen oder Ma\u00dfzahlen \u203a Kapitel 4). (z. B. Mittelwert und Standardabweichung, z\nAbb. 2.1 Grundgesamtheit und Stichprobe\nGrundgesamtheit\nStichprobe\ndeskriptive Statistik\ninduktive Statistik\n21 2.3 Merkmale\n2\nWenn zwei oder mehrere Stichproben miteinander zu vergleichen sind (beispielsweise zwei Therapiegruppen bei einer klinischen Studie), sollte man zun\u00e4chst f\u00fcr jede einzelne Stichprobe graphische Darstellungen erstellen und geeignete Kenngr\u00f6\u00dfen berechnen. Damit l\u00e4sst sich bereits \u00fcberblicken, ob und wie sich die Stichproben unterscheiden. In einem zweiten Schritt versucht man dann, mit geeigneten Methoden der induktiven Statistik die Ergebnisse, die aus den Stichproben gewonnen wurden, zu verallgemeinern und statistisch abzusichern. So gesehen, ist die deskriptive Statistik die Vorstufe zur induktiven Statistik. Beide Teilbereiche sind zur Datenanalyse notwendig und erg\u00e4nzen sich.\n2.3\nMerkmale\n2.3.1\nGrundbegriffe\n\u2022 Untersuchungseinheiten. Die Personen oder Objekte einer Stich probe werden als Untersuchungseinheiten (oder Merkmalstr\u00e4ger) bezeichnet. In der medizinischen Forschung handelt es sich dabei meist um Patienten, Probanden, Versuchstiere oder Laborproben. \u2022 Beobachtungseinheiten. Das sind die kleinsten Einheiten, an de nen die einzelnen Beobachtungen registriert werden. H\u00e4ufig sind die Beobachtungseinheiten mit den Untersuchungseinheiten identisch. Oft ist es jedoch angebracht, die Untersuchungseinheiten n\u00e4her zu spezifizieren. Wenn etwa bei Patienten beide Augen untersucht werden, versteht man unter den Untersuchungseinheiten die Patienten und unter den Beobachtungseinheiten die einzelnen Augen. Wenn Patienten im Rahmen einer Studie mehrmals untersucht werden, dann ist eine Beobachtungseinheit identisch mit einem Patienten bezogen auf eine einzelne Untersuchung. \u2022 Merkmale. Die Beobachtungseinheiten sind durch bestimmte Merkmale charakterisiert \u2013 das sind Eigenschaften, die f\u00fcr die zu untersuchende Fragestellung relevant sind und statistisch ausgewertet werden. Andere Eigenschaften der Beobachtungseinheiten sind \u2013 zumindest im Rahmen der jeweiligen Studie \u2013 uninteressant. Anstelle von Merkmalen spricht man auch von Variablen oder Zufallsvariablen, insbesondere dann, wenn damit Rechnungen durchgef\u00fchrt oder mathematische Gleichungen erstellt werden.\n22\nKapitel 2 \u00b7 Theoretische Grundlagen\n\u2022 Merkmalsauspr\u00e4gungen. Darunter versteht man die Werte oder Auspr\u00e4gungen, die ein bestimmtes Merkmal annehmen kann.\n2\nDie Art der Merkmale ist entscheidend f\u00fcr die Planung und Durchf\u00fchrung einer Studie, insbesondere f\u00fcr den erforderlichen Stichprobenumfang und die geeigneten Analysemethoden. Deshalb sind zu Beginn der Planungsphase die zu erfassenden Merkmale genau festzulegen und deren Eigenschaften zu spezifizieren. Merkmale lassen sich nach verschiedenen Aspekten klassifizieren:\n\u0177 nach ihrer Funktion bei der statistischen Analyse (z\u203a Abschnitt 2.3.2),\n\u0177 nach ihrem Skalenniveau (z\u203a Abschnitt 2.3.3) \u0177 und danach, ob sie diskret oder stetig sind (z\u203a Abschnitt 2.3.4). 2.3.2\nZiel- und Einflussgr\u00f6\u00dfen\nMerkmale lassen sich grob einteilen in Ziel- und Einflussgr\u00f6\u00dfen. Der eigentliche Zweck einer Studie besteht darin, Erkenntnisse \u00fcber eine oder mehrere Zielgr\u00f6\u00dfen zu gewinnen. Die Merkmale, die in einem funktionalen Zusammenhang zu den Zielgr\u00f6\u00dfen stehen und diese m\u00f6glicherweise beeinflussen, hei\u00dfen Einflussgr\u00f6\u00dfen. Diese lassen sich wiederum unterteilen in:\n\u0177 Faktoren, die erfasst und ausgewertet werden (im engeren Sinne versteht man unter den Einflussgr\u00f6\u00dfen nur die Faktoren),\n\u0177 St\u00f6rgr\u00f6\u00dfen, die im Versuchsplan nicht ber\u00fccksichtigt sind oder nicht erfasst werden, und\n\u0177 Begleitmerkmale, die zwar erfasst, aber im Rahmen der aktuellen Studie nicht ausgewertet werden (z. B. Nebenwirkungen bei einer klinisch-kontrollierten Studie). Abb. 2.2 Einflussgr\u00f6\u00dfen und Zielgr\u00f6\u00dfen\nSt\u00f6rgr\u00f6\u00dfen Faktor(en)\nBegleitmerkmal(e)\nZielgr\u00f6\u00dfe(n)\n23 2.3 Merkmale\n2\nBeispiel 2.1 Die Hypothese \u201eZigarettenrauchen beeinflusst das Entstehen eines Lungenkarzinoms\u201c impliziert, dass \u201edas Entstehen eines Lungenkarzinoms\u201c die Zielgr\u00f6\u00dfe ist, w\u00e4hrend \u201eZigarettenrauchen\u201c der zu untersuchende Faktor ist. \u00dcblicherweise werden noch weitere Faktoren wie etwa Alter und Geschlecht der Untersuchungseinheiten analysiert. Individuelle Besonderheiten \u2013 die erfasst, aber nicht explizit ausgewertet werden \u2013 sind m\u00f6gliche Begleitmerkmale. Zu den St\u00f6rgr\u00f6\u00dfen z\u00e4hlen genetische Veranlagungen, Umweltbelastungen etc. \u2013 also Merkmale, die ebenfalls das Entstehen eines Lungenkarzinoms beeinflussen, aber nicht explizit erfasst werden. ! St\u00f6rgr\u00f6\u00dfen k\u00f6nnen nicht-verzerrend (wie in Beispiel 2.1) oder verzerrend z\nsein. Die nicht-verzerrenden sind verantwortlich f\u00fcr die zufallsbedingte Streuung der Versuchsergebnisse. Die verzerrenden (Confounder) sind gef\u00e4hrlicher: Sie werden mitunter f\u00e4lschlicherweise in einen kausalen Zusammenhang mit der Zielgr\u00f6\u00dfe gebracht und k\u00f6nnen dadurch zu Fehlinterpretationen verleiten. Sie sind jedoch bei einer sorgf\u00e4ltigen Ver\u203a Abschnitt 13.4.2). suchsplanung vermeidbar (z\nEs geht bei einer statistischen Analyse letztlich darum, herauszufinden, von welchen Faktoren eine bestimmte Zielgr\u00f6\u00dfe abh\u00e4ngt und diese Zusammenh\u00e4nge in geeigneter Weise zu beschreiben. 2.3.3\nKlassifikation nach Skalenniveau\nJedes Merkmal l\u00e4sst sich einem bestimmten Skalenniveau zuordnen. Dieses gibt Auskunft \u00fcber das Messniveau und dar\u00fcber, wie die entsprechenden Daten weiterverarbeitet werden k\u00f6nnen. \u2022 Nominalskala. Sie hat das niedrigste Niveau; die Auspr\u00e4gungen unterscheiden sich nur begrifflich voneinander. Beispiele stellen die Augenfarbe oder die Blutgruppe dar. Eine spezielle Form bilden die Alternativmerkmale (die auch als dichotome oder bin\u00e4re Merkmale bezeichnet werden) mit nur zwei Auspr\u00e4gungen. So ist etwa das Geschlecht mit den Auspr\u00e4gungen \u201em\u00e4nnlich\u201c und \u201eweiblich\u201c ein Alternativmerkmal, ebenso der Rhesusfaktor mit den Auspr\u00e4gungen \u201epositiv\u201c und \u201enegativ\u201c. Auch ein Zustand, bei dem nach \u201epathologisch\u201c und \u201enicht pathologisch\u201c unterschieden wird oder Fragen, die sich mit \u201eja\u201c oder \u201enein\u201c beantworten lassen, sind als Alternativmerkmale anzusehen. \u2022 Ordinalskala (oder Rangskala). Sie besitzt ein h\u00f6heres Niveau als die Nominalskala; die Auspr\u00e4gungen dieser Merkmale lassen sich in einer nat\u00fcrlichen Rangfolge anordnen. Ein bekanntes Beispiel bilden\n24\n2\nKapitel 2 \u00b7 Theoretische Grundlagen\nZensuren mit den Auspr\u00e4gungen 1 bis 6. Auch klinische Scores sind ordinal skaliert, ebenso das Merkmal \u201eTherapieerfolg\u201c mit den m\u00f6glichen Abstufungen \u201evollst\u00e4ndig geheilt\u201c bis hin zu \u201ePatient verstorben\u201c oder ein Krebsstadium mit den Auspr\u00e4gungen I bis IV. Nominal und ordinal skalierte Merkmale werden zusammenfassend als qualitative (oder kategoriale) Merkmale bezeichnet. Es ist allgemein \u00fcblich, diese Merkmale zahlenm\u00e4\u00dfig zu codieren. So kann das Geschlecht einer Person durch die Zahlen 0 (m\u00e4nnlich) und 1 (weiblich) angegeben werden; der Therapieerfolg l\u00e4sst sich mit nat\u00fcrlichen Zahlen 0, 1, 2, ... beschreiben. Diese Zahlen haben jedoch keine rechnerische Bedeutung. Man kann zwar zwei Auspr\u00e4gungen A und B eines nominalen Merkmals durch A = B oder A B miteinander in Beziehung setzen; bei einem ordinalen Merkmal l\u00e4sst sich eine der Relationen A = B, A < B oder A > B angeben. Mathematische Operationen wie beispielsweise die Bildung einer Differenz oder eines Quotienten sind jedoch sinnlos. Es leuchtet ein, dass bei qualitativen Merkmalen weder der Abstand zwischen zwei Auspr\u00e4gungen noch deren Verh\u00e4ltnis definiert ist. \u2022 Intervallskala (oder Abstandsskala). Sie hat einen h\u00f6heren Infor mationsgehalt als die Ordinalskala. Die Auspr\u00e4gungen unterscheiden sich zahlenm\u00e4\u00dfig. Bei diesen Merkmalen ist ein Nullpunkt festgelegt (z. B. bei der Temperatur in Celsius-Graden); daher gibt es auch negative Messwerte. Es ist m\u00f6glich und sinnvoll, die Differenz zwischen zwei Auspr\u00e4gungen A \u00ed B anzugeben. \u2022 Verh\u00e4ltnisskala (oder Ratioskala). Sie hat einen absoluten Null punkt; ansonsten k\u00f6nnen nur positive Messwerte auftreten. Au\u00dfer der Differenz kann auch das Verh\u00e4ltnis A : B zwischen zwei Auspr\u00e4gungen bestimmt werden (falls B 0). Beispiel 2.2 Das Merkmal \u201eTemperatur in Celsiusgraden\u201c hat einen festgelegten Nullpunkt (Gefrierpunkt des Wassers) und ist deshalb intervallskaliert. Beim Vergleich der beiden Auspr\u00e4gungen 20\u00b0C und 40\u00b0C l\u00e4sst sich zwar der Abstand berechnen; es w\u00e4re aber unsinnig, die Werte in ein Verh\u00e4ltnis zu setzen und zu sagen, 40\u00b0C seien doppelt so warm wie 20\u00b0C. Viele Merkmale in der Medizin sind verh\u00e4ltnisskaliert: etwa das K\u00f6rpergewicht, der Cholesteringehalt oder die Leukozytenanzahl pro \u00b5l Blut. Vergleiche der Art \u201e10.000 Leukozyten pro \u00b5l Blut sind doppelt so viel wie 5.000\u201c sind bei diesen Merkmalen durchaus sinnvoll. Auch die Temperaturangabe in Kelvin-Graden kann als verh\u00e4ltnisskaliert aufgefasst werden.\n25 2.3 Merkmale\n2\nIntervall- oder verh\u00e4ltnisskalierte Merkmale werden als quantitativ oder metrisch skaliert bezeichnet. Diese Strukturen findet man vor allem im physikalisch-naturwissenschaftlichen Umfeld und damit auch in der Medizin. 2.3.4\nDiskrete und stetige Merkmale\n\u2022 Diskret. Ein Merkmal hei\u00dft diskret, wenn es nur abz\u00e4hlbar viele Werte annehmen kann. Alle qualitativen Merkmale sind trivialer Weise diskret. Quantitative Merkmale sind dann diskret, wenn die Merkmalsauspr\u00e4gungen durch einen Z\u00e4hlvorgang ermittelt werden. Beispiele sind die Anzahl der Schwangerschaften einer Frau oder die Anzahl richtig gel\u00f6ster Klausuraufgaben in Tabelle 2.1. \u2022 Stetig. Ein stetiges Merkmal kann dagegen alle Werte innerhalb eines bestimmten Intervalls annehmen; die Auspr\u00e4gungen werden in der Regel durch einen Messvorgang ermittelt. Beispiele sind die K\u00f6rpergr\u00f6\u00dfe oder der Blutdruck. Allerdings l\u00e4sst die begrenzte Messgenauigkeit bei der Bestimmung eines stetigen Merkmals nur abz\u00e4hlbar viele Auspr\u00e4gungen zu. So wird die K\u00f6rpergr\u00f6\u00dfe meist in der Einheit cm in ganzen Zahlen angegeben, wobei im Einzelfall aufoder abgerundet wird. Deshalb ist bei praktischen Untersuchungen letzten Endes jedes Merkmal diskret. Andererseits sind stetige Merkmale bei Anwendern der Statistik recht beliebt, da sie sich im Hinblick auf die Informationsgewinnung effizienter und h\u00e4ufig einfacher analysieren lassen als diskrete Merkmale. Statistische Analysemethoden, die ein stetiges Merkmal voraussetzen, k\u00f6nnen dann angewandt werden, wenn das relevante Merkmal innerhalb eines bestimmten Bereichs zahlreiche, fein abgestufte Auspr\u00e4gungen hat (wie z. B. die Leukozytenanzahl pro \u00b5l Blut). Insofern ist eine Unterscheidung zwischen diskreten und stetigen Merkmalen nicht nur theoretisch, sondern auch f\u00fcr praktische Anwendungen sinnvoll. 2.3.5\nSkalentransformationen\nEs ist generell m\u00f6glich, ein h\u00f6heres Skalenniveau auf ein niedrigeres zu transformieren. Jede Verh\u00e4ltnisskala ist automatisch eine Intervallskala; diese wiederum kann als eine Ordinalskala aufgefasst werden. Die Nominalskala kann grunds\u00e4tzlich jedem Merkmal zugeordnet werden.\n26\nKapitel 2 \u00b7 Theoretische Grundlagen\n\u00dcbersicht 1: Die Skalenniveaus\n2\nMerkmalsart\nVergleich 2er Auspr\u00e4gungen\nSkalenniveau Beispiele\nHinweise\nqualitativ\nNominalskala Blutgruppe, Rhesusfaktor\nniedrigstes Niveau\n\u0177\nqualitativ\nOrdinalskala (Rangskala)\nZensuren, med. Scores\nRangfolge ist definiert\n\u0177\nquantitativ Intervallskala (Abstandsskala)\nTemperatur in CelsiusGraden\nSkala mit festgelegtem Nullpunkt, Abstand ist definiert\n\u0177\nquantitativ Ratioskala (Verh\u00e4ltnisskala)\nLeukozytenanzahl pro \u00b5l Blut, K\u00f6rpergr\u00f6\u00dfe\nh\u00f6chstes Niveau, Skala mit absolutem Nullpunkt, Verh\u00e4ltnis ist definiert\n\u0177\nA = B oder A\u2260 B\nA = B oder A\u2260 B \u0177 A=B, A > B oder A< B A = B oder A\u2260 B \u0177 A=B, A > B oder A< B \u0177 d = A\u2212 B\nA = B oder A\u2260 B \u0177A=B, A > B oder A< B \u0177 \u0177\nd = A\u2212 B c = A: B\nBeispiel 2.3 Wir betrachten das Merkmal \u201eZigarettenkonsum eines Patienten\u201c. Die Merkmalsart und das Skalenniveau sind abh\u00e4ngig von der Art, wie man dieses Merkmal erfasst: Auspr\u00e4gungen Merkmalsart Skala quantitativ; Menge des pro Tag Verh\u00e4ltnisskala konsumierten Tabaks in Gramm stetig Anzahl der pro Tag quantitativ; Verh\u00e4ltnisskala gerauchten Zigaretten diskret Nichtraucher \u2013 schwacher Raucher \u2013 m\u00e4\u00dfiger Raucher \u2013 qualitativ Ordinalskala starker Raucher qualitativ; Nichtraucher \u2013 Raucher Nominalskala bin\u00e4r\n27 2.3 Merkmale\n2\nDas Beispiel 2.3 macht deutlich, dass eine Reduktion des Skalenniveaus einerseits mit einer einfacheren Messtechnik einhergeht, andererseits einen Informationsverlust beinhaltet. Dennoch ist eine Skalentransformation bei praktischen Anwendungen zuweilen sinnvoll. Um beispielsweise bei Routineuntersuchungen den Glukosegehalt im Blut zu bestimmen, ist es nicht notwendig, diesen exakt in mg zu erfassen. Stattdessen verwendet man Teststreifen mit den Ergebnissen \u201enegativ\u201c und \u201epositiv\u201c. Im Einzelfall ist stets abzuw\u00e4gen, ob es sinnvoll ist, das Skalenniveau zugunsten eines einfachen Messverfahrens zu reduzieren. In den folgenden Kapiteln wird gezeigt, dass statistische Analysemethoden f\u00fcr quantitative (und insbesondere f\u00fcr stetige) Merkmale differenziertere Auswertungen erm\u00f6glichen als Methoden f\u00fcr qualitative Merkmale. Eine Skalentransformation sollte man deshalb nur dann durchf\u00fchren, wenn praktische Gr\u00fcnde dies erfordern, und ansonsten versuchen, ein m\u00f6glichst hohes Niveau beizubehalten. Wenn jedoch Zweifel bestehen, ob ein h\u00f6heres Skalenniveau \u00fcberhaupt angenommen werden kann, sollte man sicherheitshalber das n\u00e4chst niedrigere zugrunde legen. Beispiel 2.4 Die Wahl des ad\u00e4quaten Skalenniveaus ist nicht immer einfach oder unumstritten. So werden in der Regel Zensuren als quantitativ-diskrete Merkmale angesehen, und es entspricht g\u00e4ngiger Praxis, Durchschnittsnoten (also Mittelwerte) zu berechnen. Dies ist aber nicht korrekt. Die Differenz zwischen zwei Noten ist n\u00e4mlich nicht sinnvoll definiert. So ist etwa der Unterschied zwischen den Noten 4 (ausreichend) und 6 (ungen\u00fcgend) keinesfalls gleichzusetzen mit dem Unterschied zwischen den Noten 2 (gut) und 4. Auch das Berechnen von Verh\u00e4ltnissen (etwa: Die Note 2 ist doppelt so gut wie die 4) ist nicht angebracht. Lediglich die Rangfolge der Auspr\u00e4gungen 1 bis 6 ist sinnvoll. Demnach handelt es sich nur um ein ordinal skaliertes (also ein qualitatives) Merkmal. ! Eine Schwierigkeit ergibt sich bei begrifflich unscharfen Bezeichnungen, z\ndie hin und wieder bei ordinal skalierten Merkmalen auftreten. W\u00e4hrend sich die Auspr\u00e4gungen eines nominal skalierten Merkmals in der Regel eindeutig bestimmen lassen und die Werte eines quantitativen Merkmals hinreichend exakt gez\u00e4hlt oder gemessen werden, sind die Grenzen zwischen den Auspr\u00e4gungen eines ordinalskalierten Merkmals oft unscharf. Dies kann zu ungenauen Ergebnissen und zu fehlerhaften Schlussfolgerungen f\u00fchren. Bei ordinal skalierten Daten sollte man deshalb darauf achten, dass die Abgrenzungen zwischen den einzelnen Auspr\u00e4gungen m\u00f6glichst genau definiert und nachvollziehbar sind.\n28\n2\nKapitel 2 \u00b7 Theoretische Grundlagen\nMerke Um geeignete Analysemethoden w\u00e4hlen zu k\u00f6nnen, sind vor der Datenerfassung unbedingt folgende Punkte zu kl\u00e4ren: 1. Fragestellung (Hypothese) der Studie formulieren 2. Geeignete Ziel- und Einflussgr\u00f6\u00dfen ausw\u00e4hlen 3. Spezifische Eigenschaften f\u00fcr jedes Merkmal bestimmen\n2.3.6\nMerkmalsauspr\u00e4gungen\nNachdem zu Beginn einer Studie festgelegt worden ist, welche Merkmale erhoben und welche Skalenniveaus zugrunde gelegt werden, ist f\u00fcr jedes Merkmal eine Auspr\u00e4gungsliste zu erstellen. Bei quantitativen Merkmalen handelt es sich dabei um die Mess- oder Z\u00e4hlwerte. Die Auspr\u00e4gungen qualitativer Merkmale werden h\u00e4ufig numerisch codiert. Dabei ist auf zwei Dinge zu achten:\n\u0177 Die Liste muss vollst\u00e4ndig sein, damit jeder Beobachtung eine Auspr\u00e4gung zugeordnet werden kann. Dies bedeutet, dass auch sehr seltene Auspr\u00e4gungen repr\u00e4sentiert sind. \u0177 Sie muss disjunkt sein. Das hei\u00dft: Je zwei Auspr\u00e4gungen bzw. deren Codierungen sind unterscheidbar und schlie\u00dfen sich gegenseitig aus. Die Zuordnung Codierung \u013c Auspr\u00e4gung muss also f\u00fcr beide Richtungen eindeutig sein. Der Vollst\u00e4ndigkeit wegen f\u00fcgt man bei qualitativen Merkmalen h\u00e4ufig eine Auspr\u00e4gung der Art \u201eSonstiges\u201c oder \u201enicht feststellbar\u201c hinzu. Bei quantitativen Merkmalen (z. B. bei der K\u00f6rpergr\u00f6\u00dfe) werden hin und wieder Auspr\u00e4gungen wie etwa \u201e < 150 cm \u201c oder \u201e \u2265 200 cm \u201c angegeben. Dabei ist allerdings zu bedenken, dass das Skalenniveau sinkt. Wenn man bei einem ordinalen Merkmal wie dem Therapieerfolg in die Auspr\u00e4gungsliste \u201enicht feststellbar\u201c aufnimmt, reduziert sich das Niveau auf das einer Nominalskala. Eine sinnvolle Auspr\u00e4gungsliste ist nicht zuletzt abh\u00e4ngig von der konkreten Fragestellung. So ist beispielsweise f\u00fcr das Merkmal \u201eGeschlecht\u201c eine Liste mit den Auspr\u00e4gungen \u201em\u00e4nnlich\u201c und \u201eweiblich\u201c in der Regel vollst\u00e4ndig und disjunkt. Es sind jedoch auch Situationen denkbar, in denen eine zus\u00e4tzliche Auspr\u00e4gung wie \u201eintersexuell\u201c oder \u201enicht feststellbar\u201c erforderlich ist. Bei quantitativen Merkmalen sind das Messverfahren und die Messgenauigkeit zu ber\u00fccksichtigen. W\u00e4hrend man das K\u00f6rpergewicht von Erwachsenen in der Regel in ganzzahligen kg-Werten erfasst, erscheint dies bezogen auf das K\u00f6rpergewicht von Neugeborenen nicht sinnvoll.\n29 2.4 Besondere Problematiken\n2\nBeispiel 2.5 Die Auspr\u00e4gungsliste f\u00fcr das Merkmal \u201eAugenfarbe\u201c mit den Codierungen: 1 = blau 2 = gr\u00fcn 3 = braun 4 = grau Summe aus diesen Zahlen = Farbkombination ist weder vollst\u00e4ndig (es fehlt eine Auspr\u00e4gung f\u00fcr die Augenfarbe von Albinos) noch disjunkt (die Codierungen f\u00fcr die Farbe \u201ebraun\u201c und die Kombination \u201eblaugr\u00fcn\u201c sind nicht unterscheidbar). Die folgende Liste erf\u00fcllt dagegen die Bedingungen bez\u00fcglich Vollst\u00e4ndigkeit und Disjunktheit: 1 = blau 2 = gr\u00fcn 4 = braun 8 = grau 16 = Sonstiges Summe aus diesen Zahlen = Farbkombination Es ist auch m\u00f6glich, f\u00fcr jede der vier Farben eine eigene Variable einzuf\u00fchren, die die Werte 0 (nein) und 1 (ja) annehmen kann. Wenn alle vier Variablen den Wert 0 haben, bedeutet dies \u201eSonstiges\u201c; bei Farbkombinationen nehmen mehrere Variable den Wert 1 an. Diese Variablen enthalten alle Informationen des Merkmals \u201eAugenfarbe\u201c in codierter Form. Man bezeichnet sie als \u201eDummyvariablen\u201c. ! Bez\u00fcglich der Anzahl der Auspr\u00e4gungen bei qualitativen Merkmalen z\nsollte man darauf achten, dass sie in einem sinnvollen Verh\u00e4ltnis zur Anzahl der Beobachtungseinheiten steht. Es ist wenig hilfreich bei der Datenanalyse, wenn viele Auspr\u00e4gungen nur vereinzelt vorkommen, weil sich dann ein Zusammenhang mit einem anderen Merkmal nicht mehr nachweisen l\u00e4sst.\n2.4\nBesondere Problematiken\nBei der Durchf\u00fchrung medizinischer Studien gibt es eine Reihe von Besonderheiten bez\u00fcglich der Analyse der Daten: \u2022 Klinische Scores und Skalen. Quantitative Merkmale lassen sich effizienter auswerten als qualitative. Daraus resultierte die Tendenz, Sachverhalte, die eigentlich nur qualitativ beschreibbar sind, quantitativ messbar zu machen. Dies f\u00fchrte dazu, dass in den letzten Jahren eine Vielzahl von klinischen Scores und Skalen eingef\u00fchrt wurde, mit denen komplexe Merkmale \u2013 wie etwa der Allgemeinzustand eines Patienten \u2013 erfasst werden. Man spricht dabei etwas abf\u00e4llig auch von \u201eweichen Daten\u201c im Gegensatz zu \u201eharten Daten\u201c, die sich exakt messen lassen. Ein Beispiel stellt der Apgar-Score dar, der zur Beurteilung des Zustands Neugeborener herangezogen wird. Diesem Score liegen Einsch\u00e4tzungen f\u00fcr mehrere Merkmale (Herzfrequenz, Atmung, Muskeltonus, Reflexe und Hautfarbe) zugrunde, die jeweils mit 0, 1\n30\n2\nKapitel 2 \u00b7 Theoretische Grundlagen\noder 2 Punkten bewertet werden. Die Summe ergibt dann einen Scorewert zwischen 0 und 10. Ein anderes Beispiel ist die Karnofsky-Skala, die verwendet wird, um den Allgemeinzustand eines Patienten zu beschreiben. Sie kann Werte zwischen 0 und 100 annehmen. Zur Beschreibung der Schmerzintensit\u00e4t dient die visuelle Analog-Skala, auf der ein Patient auf einer 10 cm langen Linie sein Schmerzempfinden markieren soll. Es liegt nahe, solche Merkmale als quantitativ anzusehen und entsprechend zu analysieren. Folgendes ist dazu anzumerken:\n\u0177 Es handelt sich bei den Score- oder Skalenwerten keineswegs um Mess- oder Z\u00e4hlwerte, sondern um Einsch\u00e4tzungen, die in gewisser Weise subjektiv sind. \u0177 Zwei benachbarte Auspr\u00e4gungen sind nicht unbedingt \u00e4quidistant. So ist etwa beim Merkmal \u201eHerzfrequenz\u201c des Apgar-Scores der Unterschied zwischen 0 (kein Herzschlag) und 1 (Frequenz unter 100) nicht gleichzusetzen mit dem Unterschied zwischen 1 und 2 (Frequenz \u00fcber 100). \u0177 Es erscheint sogar problematisch, zwei gleiche Auspr\u00e4gungen miteinander in Beziehung zu setzen. So besagt ein Apgar-Wert von 7 lediglich, dass zwei oder drei Merkmale nicht optimal ausgepr\u00e4gt sind. Das bedeutet jedoch nicht unbedingt, dass der Zustand zweier Neugeborener mit dem Apgar-Wert 7 identisch ist. Demnach handelt es sich bei diesen Scores und Skalen bestenfalls um ordinal skalierte, aber nicht um quantitative Merkmale. Dies sollte man bei der Datenanalyse und der Pr\u00e4sentation der Ergebnisse beachten. \u2022 Ausrei\u00dfer. Dies sind extrem hohe oder extrem niedrige Werte, bei denen fraglich ist, ob sie unter denselben Bedingungen wie die anderen Werte der Datenreihe entstanden sind. Die Einstufung eines Wertes als Ausrei\u00dfer muss in erster Linie inhaltlich motiviert sein. Man erkennt Ausrei\u00dfer am ehesten anhand einer graphischen Darstellung. Wie soll man dann verfahren? Zun\u00e4chst sollte man nachforschen, wie diese Werte entstanden sind. M\u00f6glicherweise handelt es sich um Mess- oder Dokumentationsfehler oder pathologische Besonderheiten. Wenn sich herausstellt, dass es sich um fehlerhafte Werte handelt, muss man sie von der Analyse ausschlie\u00dfen. Ansonsten ist es sinnvoll, die Analysen zweimal durchzuf\u00fchren: mit und ohne Ausrei\u00dfer. Wenn sich die Ergebnisse \u00e4hneln, spielen die Ausrei\u00dfer keine gro\u00dfe Rolle. Wenn sie sich jedoch unterscheiden, sollte man auf statistische Verfahren zur\u00fcckgreifen, die unempfindlich gegen Ausrei\u00dfer sind.\n31 2.4 Besondere Problematiken\n2\n\u2022 Surrogatmerkmale. Manche Krankheiten k\u00f6nnen nicht direkt oder nur mit einem hohen Aufwand diagnostiziert werden. Dann behilft man sich gerne mit so genannten Surrogatmerkmalen, die eine Funktionsst\u00f6rung anzeigen und die einfach zu bestimmen sind. So wird beispielsweise der Kreatinin-Wert herangezogen, um ein Nierenversagen nachzuweisen. Gegen Surrogatvariable ist nichts einzuwenden, sofern sie in engem und validiertem Zusammenhang mit der zu evaluierenden Krankheit stehen. Dies sollte man kritisch hinterfragen und beim Ziehen von Schlussfolgerungen eine gewisse Vorsicht walten lassen! \u2022 Ungenaue Definitionen. Vorsicht ist geboten, wenn Zielgr\u00f6\u00dfen untersucht und beschrieben werden, die nicht klar definiert sind. Ein Beispiel ist das Merkmal \u201eTherapieerfolg\u201c. Im Allgemeinen verbindet man damit etwas Positives \u2013 dennoch ist dieser Begriff per se keineswegs exakt definiert: Nicht nur eine vollst\u00e4ndige Heilung, sondern auch eine Besserung der Symptome oder des Allgemeinzustands kann als Erfolg gewertet werden. Eine exakte Definition solcher Merkmale ist erforderlich, damit der Leser einer Publikation praxisrelevante Schlussfolgerungen ziehen und Vergleiche anstellen kann. \u2022 Falsche oder unvollst\u00e4ndige Informationen. H\u00e4ufig ist man beim Einholen von Informationen auf die Mithilfe von Patienten oder deren Angeh\u00f6rigen angewiesen. Dabei kann es vorkommen, dass die befragten Personen falsche oder unvollst\u00e4ndige Angaben machen \u2013 sei es unbewusst, weil sie sich nicht richtig erinnern, oder absichtlich, weil sie aus Scham oder anderen Gr\u00fcnden gewisse Dinge verschweigen. Nicht jeder Patient wird uneingeschr\u00e4nkt die Wahrheit sagen, wenn er nach seinem Nikotin- oder Alkoholkonsum gefragt wird. Bei manchen Studien muss man auf die mitunter mangelhafte Dokumentation in Patientenakten zur\u00fcckgreifen. Es ist schwierig, derlei Datenmaterial auszuwerten. Entsprechende Vorsicht ist bei der Interpretation der Ergebnisse geboten! \u2022 Zensierte Daten. Bei \u00dcberlebenszeitstudien wird die Zeit unter sucht, die bis zum Eintreten eines bestimmten Ereignisses (etwa bis zum Tod eines Patienten) vergeht. Mehrere Gr\u00fcnde k\u00f6nnen dazu f\u00fchren, dass sich im Einzelfall die \u00dcberlebenszeit nicht exakt feststellen l\u00e4sst: Sei es, dass der Patient w\u00e4hrend der Studie ausscheidet (etwa wegen mangelnder Bereitschaft zur weiteren Teilnahme oder weil der Kontakt zum Studienleiter abrei\u00dft), oder dass er am Ende der Studie noch lebt (jede Studie ist zeitlich limitiert). Dann kennt man nur die Zeitspanne, die \u00fcberlebt wurde \u2013 was danach geschieht,\n32\n2\nKapitel 2 \u00b7 Theoretische Grundlagen\nbleibt unbekannt. Solche Zeiten nennt man zensiert. Es w\u00fcrde zu verzerrten Ergebnissen f\u00fchren, wenn man alle zensierten Daten bei der Analyse eliminieren w\u00fcrde. Mit speziellen Verfahren (z. B. \u203a Abschnitt 16.2) ist es Kaplan-Meier-Methode oder Logrank-Test, z m\u00f6glich, zensierte Daten bei der Analyse zu ber\u00fccksichtigen. Freilich sollte man eine Studie so anlegen, dass zensierte Daten so weit wie m\u00f6glich vermieden werden.\n2.5\nListen und Tabellen\n\u2022 Listen. Bei einer Studie ist darauf zu achten, dass f\u00fcr jede einzelne Beobachtungseinheit alle relevanten Informationen (Ort und Zeit der Untersuchungen, die untersuchenden Personen, die erhobenen Daten, Besonderheiten etc.) sorgf\u00e4ltig in einer Liste dokumentiert werden. Falls ein Datum nicht erhoben werden kann, ist dies mit Angabe von Gr\u00fcnden zu vermerken. Zu einem sp\u00e4teren Zeitpunkt ist kaum noch nachvollziehbar, warum eine Information fehlt \u2013 ob beispielsweise nur die Dokumentation vergessen wurde (das sollte freilich nicht passieren), oder ob und warum ein Wert nicht gemessen wurde. F\u00fcr die statistische Analyse sind diese Informationen mitunter sehr wichtig. \u2022 Tabellen. Die f\u00fcr die statistische Analyse relevanten Daten wer den in einer Tabelle \u00fcbersichtlich zusammengefasst. Diese stellt die Basis f\u00fcr alle nachfolgenden Analysemethoden und f\u00fcr die daraus resultierenden Erkenntnisse dar. Eine Tabelle wird \u00fcblicherweise mit einer Software (z. B. dem Tabellenkalkulationsprogramm Excel) erstellt. Sie enth\u00e4lt folgende Elemente:\n\u0177 Tabellenzeilen. F\u00fcr jede Beobachtungseinheit ist eine eigene Zeile mit einer eindeutigen Identifikationsnummer in der ersten Spalte reserviert. Namen oder Initialen sind \u2013 nicht zuletzt aus Datenschutzgr\u00fcnden \u2013 zur Identifikation ungeeignet. \u0177 Tabellenspalten. Jede Spalte enth\u00e4lt die Daten eines bestimmten Merkmals. Angaben dazu findet man in der ersten Tabellenzeile, dem so genannten Tabellenkopf. \u0177 Legende. Wenn die Tabelle Teil einer Publikation oder einer Dissertation ist, sollten weitere Informationen, die zum Verst\u00e4ndnis notwendig sind (Abk\u00fcrzungen, Ma\u00dfeinheiten etc.), in der Legende oder \u00dcberschrift enthalten sein.\n33 2.5 Listen und Tabellen\n2\n! Fehlende Daten m\u00fcssen gekennzeichnet werden (etwa durch einen z\nPunkt). Sie sollten nach M\u00f6glichkeit vermieden werden, da sich dadurch der Stichprobenumfang reduziert und die Ergebnisse ungenauer werden.\nOft enth\u00e4lt eine Tabelle in der letzten Zeile oder in der letzten Spalte Randsummen (die so genannten Spalten- bzw. Zeilensummen), Mittelwerte oder H\u00e4ufigkeiten. Falls es zweckm\u00e4\u00dfig erscheint, kann sie nach einem oder mehreren Merkmalen sortiert sein. Die Tabelle auf der folgenden Doppelseite enth\u00e4lt die Daten von sieben Merkmalen, die bei 71 Studenten im ersten klinischen Semester erfasst wurden. Sie dient als Grundlage f\u00fcr diverse statistische Analysen, die in den folgenden Kapiteln erl\u00e4utert werden. Alle Ergebnisse lassen sich anhand dieser Tabelle explizit nachvollziehen. Charakteristische Eigenschaften der erhobenen Merkmale und deren Zusammenh\u00e4nge treten jedoch \u2013 zumindest auf den ersten Blick \u2013 anhand einer Tabelle nicht in Erscheinung. Deshalb ist es erforderlich, die Daten anschaulich graphisch darzustellen und die Merkmale quantitativ zu beschreiben. Dabei empfiehlt sich folgendes Vorgehen:\n\u0177 Zun\u00e4chst wird jedes Merkmal einzeln \u2013 also unabh\u00e4ngig von den anderen und separat f\u00fcr jede Stichprobe \u2013 mittels deskriptiver Statistik untersucht. Geeignete Methoden werden in den Kapiteln 3 und 4 vorgestellt. \u0177 Danach lassen sich einfache Zusammenh\u00e4nge beschreiben. Hinweise dazu findet man in Kapitel 5. \u0177 Mit Methoden der induktiven Statistik l\u00e4sst sich nachweisen, ob und mit welcher Irrtumswahrscheinlichkeit die Stichprobenergebnisse verallgemeinerbar sind. Dieses Thema ist Gegenstand der Kapitel 9 bis 12. ! \u00dcblicherweise wird eine Tabelle mit dem Tabellenkalkulationsprogramm z\nExcel, das im Office-Paket der Firma Microsoft enthalten ist, angelegt. Diese Software ist f\u00fcr die Datenerfassung geeignet; auch einfache statistische Berechnungen lassen sich damit durchf\u00fchren. F\u00fcr Analysen der induktiven Statistik empfiehlt sich jedoch ein leistungsstarkes Statistikprogrammpaket wie beispielsweise SAS oder SPSS.\n34\n2\nKapitel 2 \u00b7 Theoretische Grundlagen\nTabelle 2.1. Geschlecht (M = m\u00e4nnlich, W = weiblich), Blutgruppe, Rhesusfaktor, Raucher, K\u00f6rpergr\u00f6\u00dfe in cm, K\u00f6rpergewicht in kg und die Anzahl richtig gel\u00f6ster Klausuraufgaben ID\nGeschlecht\nBlutgruppe\nRhesusfaktor\nRaucher\nGr\u00f6\u00dfe\nGewicht\nKlausur\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44\nM M M M M M M M M M M M M M M M M M M M M M M W W W W W W W W W W W W W W W W W W W W W\nA 0 B A 0 0 A A 0 B 0 0 A 0 A A A 0 A 0 AB A 0 0 A 0 A B 0 A 0 0 A A 0 A 0 B A 0 A A 0 B\n+ + \u2013 + + + + + + + \u2013 + + + + + + \u2013 + + + \u2013 + + + + \u2013 + + + + + + + \u2013 \u2013 + + + + + + \u2013 +\nja ja nein nein nein nein ja ja nein nein nein nein nein nein nein nein nein nein nein nein nein nein nein nein nein nein nein nein nein ja nein nein nein nein nein nein nein nein nein ja ja ja nein nein\n172 193 193 180 180 180 182 179 186 180 190 196 178 177 176 175 186 178 185 180 165 178 179 164 167 170 179 156 156 168 172 168 170 175 169 168 176 173 163 157 169 172 168 170\n82 106 75 75 90 90 70 72 80 80 80 84 69 71 65 65 85 79 85 85 61 60 74 52 55 56 75 46 50 63 60 60 57 52 65 58 69 56 60 50 60 65 62 53\n6 10 8 11 2 10 8 12 3 9 10 4 8 9 11 4 10 7 9 5 8 11 8 1 7 7 9 8 12 9 6 4 10 3 9 6 9 11 11 8 10 6 7 12\n2\n35 2.5 Listen und Tabellen\nTabelle 2.1 (Fortsetzung). Geschlecht (M = m\u00e4nnlich, W = weiblich), Blutgruppe, Rhesusfaktor, Raucher, K\u00f6rpergr\u00f6\u00dfe in cm, K\u00f6rpergewicht in kg und die Anzahl richtig gel\u00f6ster Klausuraufgaben ID\nGeschlecht\nBlutgruppe\nRhesusfaktor\nRaucher\nGr\u00f6\u00dfe\nGewicht\nKlausur\n45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\nW W W W W W W W W W W W W W W W W W W W W W W W W W W\n0 A A 0 0 A A 0 B A 0 A AB 0 A A B 0 A B A 0 A B 0 A AB\n+ + + + + + + + \u2013 + + + + + \u2013 + + + + + + + + + \u2013 + +\nnein nein nein nein nein nein nein nein nein ja ja nein nein nein nein nein ja ja ja nein nein nein nein nein nein nein nein\n163 168 165 174 156 172 173 176 173 178 174 174 180 166 157 160 170 162 180 180 172 178 172 165 168 165 164\n57 79 60 . 48 55 74 80 63 70 63 60 65 54 49 50 75 56 72 79 60 55 54 54 70 77 50\n7 8 6 9 9 11 10 3 10 2 9 12 7 8 4 9 12 5 11 9 4 8 10 7 10 9 5\n3\nH\u00e4ufigkeiten 3.1\nH\u00e4ufigkeiten bei diskreten Merkmalen 39\n3.1.1\nAbsolute und relative H\u00e4ufigkeiten 39\n3.1.2\nGraphische Darstellungen 40\n3.2\nH\u00e4ufigkeiten bei stetigen Merkmalen 42\n3.2.1\nDas Prinzip der Klassenbildung 42\n3.2.2\nGraphische Darstellungen 44\n3.3\nDie empirische Verteilungsfunktion 46\n3.4\n2-dimensionale H\u00e4ufigkeiten 49\n3.4.1\nDie Kontingenztafel 49\n3.4.2\nDie Beschreibung einer Assoziation 50\n3.4.3\nAusblick auf die induktive Statistik 52\n3\n39 3.1 H\u00e4ufigkeiten bei diskreten Merkmalen\n3.1\nH\u00e4ufigkeiten bei diskreten Merkmalen\n3.1.1\nAbsolute und relative H\u00e4ufigkeiten\nUm sich einen \u00dcberblick bez\u00fcglich wesentlicher Eigenschaften eines Merkmals anzueignen, beginnt man mit der H\u00e4ufigkeitsverteilung. Diese Verteilung beschreibt, wie h\u00e4ufig die einzelnen Merkmalsauspr\u00e4gungen in der Stichprobe zu finden sind. H\u00e4ufigkeiten lassen sich f\u00fcr jedes Merkmal und jedes Skalenniveau ermitteln. In den Abschnitten 3.1 und 3.2 werden \u2013 getrennt f\u00fcr diskrete und stetige Merkmale \u2013 H\u00e4ufigkeitsbegriffe er\u00f6rtert und graphische Darstellungen vorgestellt. Zu den diskreten Merkmalen z\u00e4hlen alle qualitativen sowie die quantitativ-diskreten Merkmale. Die Anzahl der Auspr\u00e4gungen ist in der Regel wesentlich kleiner als der Stichprobenumfang und damit \u00fcberschaubar. So geh\u00f6ren beispielsweise zum qualitativen Merkmal \u201eBlutgruppe\u201c die vier Auspr\u00e4gungen 0, A, B und AB. Durch einfaches Abz\u00e4hlen l\u00e4sst sich ermitteln, wie h\u00e4ufig die einzelnen Auspr\u00e4gungen in der Stichprobe vertreten sind. Allgemein formuliert man diesen Sachverhalt folgenderma\u00dfen: Ein diskretes Merkmal A habe k verschiedene Auspr\u00e4gungen A1 ,..., Ak . Die absolute H\u00e4ufigkeit einer Auspr\u00e4gung Ai wird mit ni bezeichnet. Der Buchstabe i ist der so genannte Laufindex, der zwischen 1 und k variiert. Die Summe aller absoluten H\u00e4ufigkeiten ni entspricht der Anzahl der Beobachtungseinheiten in der Stichprobe \u2013 das ist der Stichprobenumfang n: k\n\u00a6n\ni\n=n\n(3.1)\ni =1\ni Bei dem Summen-Zeichen \u01b6 handelt es sich um den griechischen z Buchstaben Sigma. Damit werden Summen in verk\u00fcrzter Schreibweise k\ndargestellt. Der Ausdruck\n\u00a6n\ni\nentspricht der Summe n1 + n2 + ... + nk .\ni =1\nUnter der relativen H\u00e4ufigkeit hi einer Auspr\u00e4gung Ai versteht man den Quotienten \u00b4\nhi =\nni n\n(3.2)\n40\nKapitel 3 \u00b7 H\u00e4ufigkeiten\nAus dieser Definition folgt, dass 0 \u2264 hi \u2264 1, und dass sich die relativen H\u00e4ufigkeiten aller Auspr\u00e4gungen zu 1 aufaddieren: k\n\u00a6h\ni\ni =1\n3\n\u00a6n\ni\nk\n=\ni =1\nn\n=\nn =1 n\n(3.3)\nIn der Praxis gewinnt man die H\u00e4ufigkeiten am einfachsten durch das Erstellen einer Strichliste oder \u2013 weniger m\u00fchsam \u2013 mittels einer \u203a Beispiel 3.1). geeigneten Software (z Beispiel 3.1 Wir betrachten das qualitative Merkmal \u201eBlutgruppe\u201c mit den Daten der in Tabelle 2.1 aufgelisteten Stichprobe von n = 71 Beobachtungseinheiten. Es ergeben sich folgende H\u00e4ufigkeiten: Auspr\u00e4gung absolute H\u00e4ufigkeiten relative H\u00e4ufigkeiten n1 = 28 A1 =Blutgruppe 0 h1 = 39 % A2 =Blutgruppe A\nn2 = 31\nh2 = 44 %\nA3 =Blutgruppe B\nn3 = 9\nh3 = 13 %\nA4 =Blutgruppe AB\nn4 = 3\nh4 = 4 %\nSumme\nn = 71\n100%\n! Die relative H\u00e4ufigkeit wird oft in Prozentwerten angegeben. Da der z\nAusdruck Prozent \u201evon Hundert\u201c bedeutet, sind derlei Angaben nur bei einem hinreichend gro\u00dfen Stichprobenumfang sinnvoll. Wenn man bei kleineren Stichproben mit weniger als 50 Beobachtungseinheiten Prozente berechnet, t\u00e4uscht man eine h\u00f6here Genauigkeit vor als in Wirklichkeit vorhanden ist. In diesen F\u00e4llen sollte man anstelle der Prozentangaben einfache Quotienten bevorzugen \u2013 wie z. B.: Die relative H\u00e4ufigkeit der Blutgruppe A bei den m\u00e4nnlichen Studenten betr\u00e4gt 10/23.\n3.1.2\nGraphische Darstellungen\nGraphische Darstellungen bringen die oben beschriebenen Sachverhalte pr\u00e4gnant zum Ausdruck. \u2022 Kreisdiagramm. Bei dieser Darstellung geben die einzelnen Kreissektoren die H\u00e4ufigkeiten ni wieder. Anstelle der absoluten H\u00e4ufigkeiten ni lassen sich auch die relativen H\u00e4ufigkeiten hi darstellen; dabei \u00e4ndert sich nur der Ma\u00dfstab des Diagramms, nicht jedoch dessen Aussehen. Bei einem Kreisdiagramm kommt allerdings\n41\n3\n3.1 H\u00e4ufigkeiten bei diskreten Merkmalen\nnicht (zumindest nicht auf den ersten Blick) zur Geltung, welches die kleinste oder die gr\u00f6\u00dfte Auspr\u00e4gung ist \u2013 deshalb eignet sich \u203a diese Art der Darstellung nur f\u00fcr nominal skalierte Merkmale (z Abbildung 3.1). \u2022 Rechteckdiagramm (oder Blockdiagramm). Hier ist ein Rechteck entsprechend der einzelnen H\u00e4ufigkeiten unterteilt. Diese Darstellung eignet sich auch f\u00fcr ordinal skalierte Merkmale, da die kleinste und die gr\u00f6\u00dfte Auspr\u00e4gung zu erkennen sind. \u2022 Balkendiagramm. Diese Art von Diagrammen eignet sich f\u00fcr alle diskreten Merkmale. Die L\u00e4ngen der einzelnen Balken entsprechen \u203a Abbildung 3.2). Dabei sind zahlreiden H\u00e4ufigkeiten ni oder hi (z che Varianten denkbar. Die 2-dimensionalen Balken lassen sich durch 1-dimensionale Striche oder 3-dimensionale S\u00e4ulen ersetzen. Bei senkrechter Anordnung spricht man auch von einem S\u00e4ulendiagramm; wenn anstelle der S\u00e4ulen 1-dimensionale Striche verwendet werden, bezeichnet man dies als Stabdiagramm. Dar\u00fcber hinaus k\u00f6nnen die Balken horizontal anstatt vertikal angeordnet werden; bez\u00fcglich Farben, Mustern und Hintergr\u00fcnden sind \u2013 nicht zuletzt dank geeigneter Software- und Hardwareprodukte \u2013 der Phantasie keine Grenzen gesetzt. Man sollte jedoch bei solchen Darstellungen vor allem darauf achten, dass die wesentlichen Eigenschaften der H\u00e4ufigkeitsverteilung optimal zur Geltung kommen und nicht zugunsten optischer Effekte in den Hintergrund treten. Abb. 3.1 Kreisdiagramm; Darstellung der H\u00e4ufigkeiten des Merkmals \u201eBlutgruppe\u201c (Beispiel 3.1)\nAbb. 3.2 Balkendiagramm; Darstellung der H\u00e4ufigkeiten des Merkmals \u201eAnzahl richtig gel\u00f6ster Klausuraufgaben\u201c\n42\n3\nKapitel 3 \u00b7 H\u00e4ufigkeiten\n\u2022 Punktediagramm. Dies ist eine Darstellung einfachster Art f\u00fcr quantitative Merkmale. Die Stichprobenwerte werden entlang einer Achse (die waagrecht oder senkrecht angeordnet sein kann) als einzelne Punkte eingetragen. Diese Art der Darstellung eignet sich weniger zu Pr\u00e4sentationszwecken als vielmehr dazu, schnell und einfach einen \u00dcberblick \u00fcber die H\u00e4ufigkeitsverteilung zu gewinnen.\n3.2\nH\u00e4ufigkeiten bei stetigen Merkmalen\n3.2.1\nDas Prinzip der Klassenbildung\nBei der Erfassung eines stetigen Merkmals (z. B. der K\u00f6rpergr\u00f6\u00dfe) werden \u2013 bedingt durch die begrenzte Messgenauigkeit \u2013 die gemessenen Werte im Einzelfall auf- oder abgerundet. Im Vergleich zum Stichprobenumfang ergeben sich zahlreiche Auspr\u00e4gungen, deren H\u00e4ufigkeiten meist gering und daher wenig informativ sind. So schwankt beispielsweise die K\u00f6rpergr\u00f6\u00dfe der Studenten in Tabelle 2.1 zwischen 156 cm und 196 cm \u2013 dies sind 41 verschiedene Werte f\u00fcr 71 Beobachtungseinheiten. Davon haben 14 Auspr\u00e4gungen die H\u00e4ufigkeit 0, neun sind nur einmal vertreten. Es erweist sich in solchen F\u00e4llen als sinnvoll, mehrere nebeneinander liegende Auspr\u00e4gungen zusammenzufassen und Klassen zu bilden. Dies ist auch bei einem quantitativ-diskreten Merkmal mit extrem vielen, fein abgestuften Auspr\u00e4gungen gerechtfertigt (z. B. die Leukozytenanzahl). Ein solches Merkmal kann f\u00fcr praktische Analysen wie ein stetiges Merkmal behandelt werden. Damit verbindet sich die Frage, wie die Anzahl der Klassen und deren Breiten festzulegen sind. Bei sehr vielen, schmalen Klassen ist die Darstellung un\u00fcbersichtlich und der Verteilungstyp schwer erkennbar. Dagegen ist eine geringe Anzahl von breiten Klassen mit einem hohen Informationsverlust verbunden; charakteristische Eigenschaften der Verteilung werden eventuell verdeckt. Es gibt bez\u00fcglich der Klassenbildung zwar keine strengen Vorschriften, jedoch einige Faustregeln, die einen Kompromiss zwischen einer \u00fcbersichtlichen Darstellung einerseits und einem geringen Informationsverlust andererseits beinhalten:\n\u0177 Die Klassenanzahl k richtet sich nach dem Stichprobenumfang n.\nAls Anhaltspunkt gilt: k \u2248 n . F\u00fcr gr\u00f6\u00dfere Stichprobenumf\u00e4nge n \u2265 1000 verwendet man k \u2248 10 \u22c5 lg n (wobei lg der Zehnerlogarithmus bedeutet), damit die Klassenanzahl nicht zu gro\u00df wird.\n3\n43 3.2 H\u00e4ufigkeiten bei stetigen Merkmalen\n\u0177 Weniger als drei Klassen sind generell nicht sinnvoll. \u0177 Am \u00fcbersichtlichsten ist die Darstellung, wenn die Klassenbreiten gleich sind. Wenn jedoch Ausrei\u00dfer vorhanden sind, ist es eventuell sinnvoll, am jeweiligen Rand eine breite Klasse zu bilden. Klassen mit den Grenzen -\u221e oder +\u221e sind zu vermeiden. \u0177 Es muss eindeutig gekl\u00e4rt sein, welcher Klasse ein Datum zugeordnet wird, das auf eine Klassengrenze f\u00e4llt. Man umgeht dieses Problem, indem man die Grenzen so definiert, dass sie nicht mit Werten der Stichprobe zusammenfallen. Ansonsten muss man die Klassen als halboffene Intervalle festlegen (meist benutzt man Intervalle, die links offen und rechts abgeschlossen sind). Bei klassierten Daten ermittelt man die absolute H\u00e4ufigkeit oder die Besetzungszahl einer Klasse und bezeichnet diese als ni . Der Laufindex i kennzeichnet die Klassen in aufsteigender Reihenfolge ( i = 1 bezeichnet also die erste Klasse mit den kleinsten Messwerten, i = k die letzte Klasse mit den gr\u00f6\u00dften Werten). Basierend auf den absoluten H\u00e4ufigkeiten ni berechnet man die relativen Klassenh\u00e4ufigkeiten hi ebenso wie bei diskreten Merkmalen. Beispiel 3.2 Die Messwerte f\u00fcr die K\u00f6rpergr\u00f6\u00dfe der 71 Studenten in Tabelle 2.1 variieren zwischen 156 und 196 cm. Das Intervall (152,5 cm; 197,5 cm) wird in 9 Klassen der Klassenbreite 5 cm eingeteilt. Dadurch ist gew\u00e4hrleistet, dass kein Messwert auf eine Klassengrenze f\u00e4llt. relative absolute relative absolute Laufindex Klassengrenzen H\u00e4ufigkeit H\u00e4ufigkeit Summenh. Summenh. i in cm ni hi Ni Hi 1 2 3 4 5 6 7 8 9\n(152,5 ; 157,5) (157,5 ; 162,5) (162,5 ; 167,5) (167,5 ; 172,5) (172,5 ; 177,5) (177,5 ; 182,5) (182,5 ; 187,5) (187,5 ; 192,5) (192,5 ; 197,5)\n5 2 10 18 12 17 3 1 3\n0,07 0,03 0,14 0,25 0,17 0,24 0,04 0,01 0,04\n5 7 17 35 47 64 67 68 71\n0,07 0,10 0,24 0,49 0,66 0,90 0,94 0,96 1\nUm die H\u00e4ufigkeitsbegriffe zu verdeutlichen, betrachten wir die 4. Klasse. Die absolute und die relative H\u00e4ufigkeit n4 bzw. h4 bedeuten: 18 Studenten (das entspricht 25 %) haben eine K\u00f6rpergr\u00f6\u00dfe zwischen 167,5 cm und 172,5 cm. Die ab\u203a Abschnitt 3.3) N 4 bzw. H 4 besasolute und die relative Summenh\u00e4ufigkeit (z gen, dass 35 insgesamt Studenten bzw. 49 % kleiner als 172,5 cm sind.\n44\nKapitel 3 \u00b7 H\u00e4ufigkeiten\ni Wenn eine Intervallgrenze durch eine runde Klammer angegeben wird, z bedeutet dies, dass der Grenzwert nicht im Intervall enthalten ist. Eine eckige Klammer ([ oder ]) zeigt an, dass der Grenzwert zum Intervall geh\u00f6rt.\n! In fr\u00fcheren Zeiten \u2013 als man einen Mittelwert noch per Hand oder mit z\n3\neinem Taschenrechner ermittelte \u2013 erleichterte man sich bei umfangreichem Datenmaterial die Arbeit, indem man die Daten in eine \u00fcberschaubare Anzahl von Klassen zusammenfasste und den Mittelwert und andere Kenngr\u00f6\u00dfen aus den Klassenmitten ermittelte. Deshalb legte man Wert darauf, dass die Klassenmitten rechentechnisch g\u00fcnstige Werte waren. Heute \u2013 im Zeitalter benutzerfreundlicher Statistiksoftware \u2013 ist dieses Argument obsolet. Die Einteilung in Klassen wird haupts\u00e4chlich vorgenommen, um die Daten \u00fcbersichtlich graphisch darzustellen.\n3.2.2\nGraphische Darstellungen\n\u2022 Histogramm. Bei dieser Darstellung wird jede Klasse durch ein Rechteck repr\u00e4sentiert, dessen Fl\u00e4chen proportional zu den jeweiligen Klassenh\u00e4ufigkeiten sind. Am \u00fcbersichtlichsten ist ein \u203a Abbildung 3.3); dann Histogramm mit gleichen Klassenbreiten (z sind auch die H\u00f6hen der Rechtecke proportional zu den H\u00e4ufigkeiten. Falls Daten auf eine Klassengrenze fallen, muss gekennzeichnet werden, welcher Klasse diese Daten zugerechnet werden (\u00fcblicherweise w\u00e4hlt man die untere Klasse). Die mathematische Funktion, die ein Histogramm beschreibt, bezeichnet man als empirische Dichte. Sie ist definiert als: 0 f\u00fcr x \u2264 a0 \u00b0 \u00b0 hi f ( x) = \u00ae f\u00fcr ai \u22121 < x \u2264 ai (i = 1,..., k ) \u00b0 ai \u2212 ai \u22121 \u00b0\u00af0 f\u00fcr x > ak\n(3.4)\nDabei sind a i \u22121 und a i die untere bzw. die obere Grenze der i. Klasse, k ist die Klassenanzahl. Dieses Histogramm besteht aus k Rechtecken der Fl\u00e4che hi . Die Gesamtfl\u00e4che hat den Wert 1. \u2022 H\u00e4ufigkeitspolygon. Diese Darstellung erh\u00e4lt man, indem man senkrecht auf die Klassenmitten Strecken in H\u00f6he der entsprechenden H\u00e4ufigkeiten auftr\u00e4gt und deren Endpunkte miteinander ver\u203a Abbildung 3.4). bindet (z\n45\n3\n3.2 H\u00e4ufigkeiten bei stetigen Merkmalen\n\u2022 Stamm-und-Blatt-Diagramm. Hier werden die Daten zun\u00e4chst nach ihrer Gr\u00f6\u00dfe geordnet und dann von unten nach oben aufgetragen. Der Stamm besteht aus den ersten Stellen der Stichproben\u203a Abbildung werte, die Bl\u00e4tter stellen die folgenden Ziffern dar (z 3.5). Diese Darstellung benutzt man, um sich einen schnellen \u00dcberblick \u00fcber die H\u00e4ufigkeitsverteilung zu verschaffen. F\u00fcr Pr\u00e4sentationszwecke ist sie weniger geeignet. Eine graphische Darstellung liefert zwar auf einen Blick wesentliche Informationen; sie allein ist jedoch f\u00fcr eine statistische Datenanalyse unzureichend. Kenngr\u00f6\u00dfen, die die oben genannten Eigenschaften quantitativ beschreiben, sind Gegenstand des Kapitels 4.\nAbb. 3.3 Histogramm f\u00fcr das Merkmal \u201eK\u00f6rpergr\u00f6\u00dfe\u201c (Beispiel 3.2), Einteilung in 9 Klassen\nAbb. 3.4 H\u00e4ufigkeitspolygon f\u00fcr das Merkmal \u201eK\u00f6rpergr\u00f6\u00dfe\u201c (Beispiel 3.2)\nAbb. 3.5 Stamm- und Blattdiagramm; Darstellung der K\u00f6rpergewichte der m\u00e4nnlichen Studenten\n46\n3\nKapitel 3 \u00b7 H\u00e4ufigkeiten\nMerke Anhand eines Diagramms lassen sich bei quantitativen Merkmalen folgende Eigenschaften ablesen: \u0177 Lage: In welchem Bereich konzentrieren sich die Werte? Welches ist der gr\u00f6\u00dfte, welches der kleinste Wert? Welche Auspr\u00e4gungen sind h\u00e4ufig, welche selten oder gar nicht vertreten? \u0177 Streuung: Streuen die Werte weit um den Mittelwert? Gibt es Ausrei\u00dfer? \u0177 Form: Hat die Verteilung eine besondere Form? Ist sie symmetrisch oder schief? Wie viele Gipfel sind erkennbar?\n3.3\nDie empirische Verteilungsfunktion\nBei quantitativen oder ordinal skalierten Merkmalen mag es sinnvoll sein, die H\u00e4ufigkeiten beginnend bei der kleinsten Auspr\u00e4gung in aufsteigender Reihenfolge aufzuaddieren. Dadurch erh\u00e4lt man die Anzahl der Daten, die eine bestimmte obere Grenze nicht \u00fcberschreiten. Diese H\u00e4ufigkeiten nennt man kumulative oder Summenh\u00e4ufigkeiten. Unter der Annahme, dass die Auspr\u00e4gungen sortiert sind mit A1 < A2 < ...< Ak , gilt f\u00fcr die absoluten Summenh\u00e4ufigkeiten: i\nN i = \u00a6 n j (f\u00fcr i = 1,..., k )\n(3.5)\nj =1\nDie relativen Summenh\u00e4ufigkeiten sind entsprechend definiert als: i\nH i = \u00a6 h j (f\u00fcr i = 1,..., k )\n(3.6)\nj =1\nDie zu den einzelnen Auspr\u00e4gungen geh\u00f6renden relativen Summenh\u00e4ufigkeiten H i werden durch die empirische Verteilungsfunktion F (x ) mathematisch beschrieben: 0 f\u00fcr x < A1 \u00b0 F ( x ) = \u00ae H i f\u00fcr Ai \u2264 x < Ai +1 (i = 1,..., k \u2212 1) \u00b01 f\u00fcr x \u2265 A \u00af k\n(3.7)\n3\n47 3.3 Die empirische Verteilungsfunktion\nBeispiel 3.3 F\u00fcr die K\u00f6rpergr\u00f6\u00dfen der Studenten ergeben sich mit den Daten aus Tabelle 2.1 folgende Summenh\u00e4ufigkeiten, auf denen die empirische Verteilungsfunktion \u203a Abbildung 3.6). Angegeben sind die absoluten und relativen H\u00e4ufigbasiert (z keiten ni und hi sowie die Summenh\u00e4ufigkeiten N i und Hi . Auspr\u00e4gung K\u00f6rpergr\u00f6\u00dfe ni hi Ni Hi A1 A2 A3 A4 A5 A6 A7 A8 A9 A10 A11 A12 A13 A14 A15 A16 A17 A18 A19 A20 A21 A22 A23 A24 A25 A26 A27\n156 157 160 162 163 164 165 166 167 168 169 170 172 173 174 175 176 177 178 179 180 182 185 186 190 193 196\n3 2 1 1 2 2 4 1 1 6 2 4 6 3 3 2 3 1 5 3 8 1 1 2 1 2 1\n0,04 0,03 0,01 0,01 0,03 0,03 0,06 0,01 0,01 0,08 0,03 0,06 0,08 0,04 0,04 0,03 0,04 0,01 0,07 0,04 0,11 0,01 0,01 0,03 0,01 0,03 0,01\n3 5 6 7 9 11 15 16 17 23 25 29 35 38 41 43 46 47 52 55 63 64 65 67 68 70 71\n0,04 0,07 0,08 0,10 0,13 0,15 0,21 0,23 0,24 0,32 0,35 0,41 0,49 0,54 0,58 0,61 0,65 0,66 0,73 0,77 0,89 0,90 0,92 0,94 0,96 0,99 1\nF (x ) gibt die relativen H\u00e4ufigkeiten an, mit der in der Stichprobe Werte vorhanden sind, die gleich x oder kleiner als x sind. F\u00fcr das obige Beispiel 3.3 gilt etwa: F (172) = 0,49 . Das bedeutet: Knapp die H\u00e4lfte der Studenten ist 172 cm gro\u00df oder kleiner; 51 % sind gr\u00f6\u00dfer als 172 cm.\n48\n3\nKapitel 3 \u00b7 H\u00e4ufigkeiten\nAbb. 3.6 empirische Verteilungsfunktion F ( x ) f\u00fcr das Merkmal \u201eK\u00f6rpergr\u00f6\u00dfe\u201c (Beispiel 3.3)\nDie Abbildung 3.6 verdeutlicht wesentliche Eigenschaften der Verteilungsfunktion F (x) :\n\u0177 F (x) ist eine Treppenfunktion; \u0177 F ( x) = 0 f\u00fcr alle x, die kleiner als der kleinste Stichprobenwert x min sind;\n\u0177 F (x) w\u00e4chst ab x min monoton von 0 bis 1; \u0177 F ( x) = 1 ab dem gr\u00f6\u00dften Wert x max . i Eine Funktion hei\u00dft monoton wachsend, wenn f\u00fcr zwei x-Werte mit z x1 < x2 gilt: F ( x1 ) \u2264 F ( x2 ) . Falls sogar gilt: F ( x1 ) < F ( x2 ) f\u00fcr x1 < x2 , hei\u00dft die Funktion streng monoton wachsend. Die empirische Verteilungsfunktion F ( x ) ist demnach monoton, aber nicht streng monoton wachsend.\nBei fein abgestuften Auspr\u00e4gungen ist die Anzahl der Treppen zahlreich und die Stufen sind entsprechend niedrig; die Treppenfunktion n\u00e4hert sich einer glatten Kurve. In der Pharmakologie werden Verteilungsfunktionen zur Analyse der dosisabh\u00e4ngigen Wirksamkeit eines Pharmakons verwendet. Dabei beschreibt die empirische Funktion F (x) den relativen Anteil der Untersuchungseinheiten, bei denen ein Effekt der Dosis x erkennbar ist. Die graphische Darstellung von F (x) bezeichnet man als Dosiswirkungskurve. Auch in der Labormedizin arbeitet man h\u00e4ufig mit der Verteilungsfunktion. Wenn etwa f\u00fcr einen Cholesterinwert x gilt F ( x) = 0,98 , informiert diese Angabe dar\u00fcber, dass dieser Wert im oberen 2%-Bereich liegt.\n49\n3\n3.4 2-dimensionale H\u00e4ufigkeiten\n3.4\n2-dimensionale H\u00e4ufigkeiten\n3.4.1\nDie Kontingenztafel\nBisher wurde lediglich die H\u00e4ufigkeitsverteilung eines einzelnen Merkmals betrachtet. Bisweilen ist es interessant, den Zusammenhang zwischen zwei Merkmalen, die an den Beobachtungseinheiten erhoben wurden, n\u00e4her zu beleuchten. Wenn es sich dabei um zwei qualitative Merkmale handelt, spricht man von Assoziation oder Kontingenz. Wir betrachten im Folgenden zwei diskrete Merkmale mit den Auspr\u00e4gungen Ai ( i = 1,..., k ) und B j ( j = 1,..., A) . Dann betr\u00e4gt die Anzahl aller denkbaren Kombinationen k \u22c5 A . Die absoluten H\u00e4ufigkeiten nij bezeichnen die Anzahl der Beobachtungseinheiten, bei denen die Auspr\u00e4gungen Ai und B j gemeinsam auftreten. F\u00fcr die relativen H\u00e4ufigkeiten ergibt sich dann: hij =\nnij\nmit i = 1,..., k und j = 1,..., A\nn\n(3.8)\nDie hij erstrecken sich zwischen 0 und 1. Wenn man alle H\u00e4ufigkeiten aufaddiert, erh\u00e4lt man: k\nA\n\u00a6\u00a6 n\nij\n=n\n(3.9)\n=1\n(3.10)\ni =1 j =1 k\nA\n\u00a6\u00a6 h\nij\ni =1 j =1\nDie H\u00e4ufigkeiten, die sich nur auf die Auspr\u00e4gungen Ai oder B j beziehen, sind die so genannten Randh\u00e4ufigkeiten oder Randsummen. All diese H\u00e4ufigkeiten lassen sich \u00fcbersichtlich in einer Tabelle \u2013 der so genannten Kontingenztafel \u2013 darstellen. Im Kopf und in der Vorspalte sind die Auspr\u00e4gungen der beiden Merkmale aufgelistet. Im Innern enth\u00e4lt die Tabelle Felder mit den jeweiligen H\u00e4ufigkeiten. In der letzten Tabellenspalte oder der letzten Zeile k\u00f6nnen Randsummen eingetragen werden. In Beispiel 3.4 werden zwei Alternativmerkmale betrachtet; daher enth\u00e4lt die Tabelle im Innern nur vier Felder. Diese einfachste Form der Kontingenztafel nennt man auch Vierfeldertafel. Die dazu geh\u00f6renden absoluten H\u00e4ufigkeiten werden \u00fcblicherweise mit a, b, c und d bezeichnet. Au\u00dfer den absoluten H\u00e4ufigkeiten lassen sich bei\n50\nKapitel 3 \u00b7 H\u00e4ufigkeiten\nBedarf zus\u00e4tzlich die relativen H\u00e4ufigkeiten (die sich auf den gesamten Stichprobenumfang beziehen) sowie die relativen Reihenoder Spaltenh\u00e4ufigkeiten (die sich auf die Reihen- bzw. Spaltensummen beziehen) angeben.\n3\nBeispiel 3.4 F\u00fcr die Merkmale \u201eRauchen und Geschlecht\u201c ergeben sich aus den Daten der Tabelle 2.1 folgende Zusammenh\u00e4nge. Angegeben sind jeweils die absoluten H\u00e4ufigkeiten nij, die relativen H\u00e4ufigkeiten hij, die relativen Reihenh\u00e4ufigkeiten, die relativen Spaltenh\u00e4ufigkeiten. Raucher\nNichtraucher\na=4 b = 19 (0,06) (0,27) 23 m\u00e4nnlich (0,17) (0,83) (0,32) (0,31) (0,33) c=9 d = 39 (0,13) (0,55) 48 weiblich (0,19) (0,81) (0,68) (0,69) (0,67) 13 58 71 (0,18) (0,82) Daraus geht hervor, dass sich die Menge der 71 Studenten aus 13 Rauchern (das sind 18 %) und 58 Nichtrauchern (82 %) bzw. aus 23 M\u00e4nnern (32 %) und 48 Frauen (68 %) zusammensetzt. Die 19 nicht rauchenden M\u00e4nner stellen 27 % des Gesamtkollektivs dar. 17 % der M\u00e4nner und 19 % der Frauen rauchen. Die Raucher sind zu 31 % m\u00e4nnlich; die Nichtraucher zu 33 %. F\u00fcr \u203a Abschnitt 3.4.2) ergibt sich OR = (4 \u22c539) /(19 \u22c5 9) = 0,912 . die Odds Ratio (z\n3.4.2\nDie Beschreibung einer Assoziation\nDie Kontingenztafeln enthalten zwar genaue Informationen bez\u00fcglich der H\u00e4ufigkeiten; sie sind jedoch wenig geeignet, um den Grad eines Zusammenhangs zu erfassen. Zu diesem Zweck bedient man sich graphischer Darstellungen und geeigneter Assoziationsma\u00dfe. \u2022 Balkendiagramm. Die Zusammenh\u00e4nge zweier qualitativer Merkmale lassen sich mittels eines Balkendiagramms darstellen. Die L\u00e4ngen der Balken repr\u00e4sentieren die H\u00e4ufigkeiten der Auspr\u00e4gungen des ersten Merkmals. Au\u00dferdem ist jeder Balken entsprechend\n51\n3\n3.4 2-dimensionale H\u00e4ufigkeiten\nder H\u00e4ufigkeiten der Auspr\u00e4gungen des zweiten Merkmals unterteilt \u203a Abbildung 3.7). Eine andere M\u00f6glichkeit besteht darin, f\u00fcr jede (z Merkmalskombination einen 3-dimensionalen Balken zu erstellen, der die jeweilige H\u00e4ufigkeit nij repr\u00e4sentiert, und die k \u22c5 A Balken in \u203a Abbildung 3.8). r\u00e4umlicher Perspektive anzuordnen (z \u2022 Odds Ratio. Dies ist ein Assoziationsma\u00df, das den Grad eines Zu sammenhangs zwischen zwei Alternativmerkmalen quantifiziert. Es wird gebildet, indem man aus den H\u00e4ufigkeiten im Innern der Vierfeldertafel das Kreuzprodukt bildet: OR =\nad bc\n(3.11)\nDiese Ma\u00dfzahl ist der Quotient aus den beiden \u201eOdds\u201c a / c und b / d . Ein Odds ist das Verh\u00e4ltnis aus zwei zusammen geh\u00f6renden H\u00e4ufigkeiten. So stellt etwa der Quotient a / c die Anzahl der m\u00e4nnlichen Raucher im Verh\u00e4ltnis zu den weiblichen Rauchern dar. Eine Odds Ratio mit dem Wert 1 zeigt, dass kein Zusammenhang zwischen den beiden Merkmalen besteht. Die berechnete Odds Ratio von 0,912 in Beispiel 3.4 l\u00e4sst vermuten, dass bei den Studenten kein wirklicher Zusammenhang zwischen den Merkmalen \u201eRauchen\u201c und \u201eGeschlecht\u201c nachzuweisen ist. Abb. 3.7 Zusammenhang zwischen Rauchen und Geschlecht, 2-dimensionales Balkendiagramm (Beispiel 3.4)\nAbb. 3.8 Zusammenhang zwischen Rauchen und Geschlecht, 3-dimemsionales Balkendiagramm (Beispiel 3.4)\n52\nKapitel 3 \u00b7 H\u00e4ufigkeiten\n\u2022 Assoziationskoeffizient nach Yule (George Yule, 1871-1951, war ein Mitarbeiter von Karl Pearson). Dieses Ma\u00df wird berechnet nach: Q=\n3\nad \u2212 bc ad + bc\n(3.12)\nQ nimmt den Wert 0 an, falls ad = bc (vollkommene Unabh\u00e4ngigkeit). Ansonsten erstreckt sich Q zwischen -1 und +1. In Beispiel 3.4 nimmt Q den Wert -0,046 an. Weitere Assoziationsma\u00dfe f\u00fcr qualitative Merkmale sind Gegenstand des Abschnitts 12.2.4. Zusammenhangsma\u00dfe f\u00fcr quantitative Merkmale werden in Kapitel 5 er\u00f6rtert. 3.4.3\nAusblick auf die induktive Statistik\nIn diesem Kapitel wurden Methoden vorgestellt, die dazu dienen, eine H\u00e4ufigkeitsverteilung zu quantifizieren und optisch darzustellen. Die Beschreibung einer Stichprobe ist \u2013 f\u00fcr sich allein genommen \u2013 jedoch unbefriedigend. Bisher wurde die Frage ausgeklammert, inwieweit sich die Ergebnisse verallgemeinern lassen. Bei der Betrachtung des Beispiels 3.4 dr\u00e4ngen sich folgende Fragen auf:\n\u0177 Aus der Vierfeldertafel geht hervor, dass etwa 2/3 aller Medizinstudenten des 1. klinischen Semesters weiblich sind. Kann man daraus schlie\u00dfen (unter der Annahme, dass die beobachtete Stichprobe repr\u00e4sentativ f\u00fcr die Medizinstudenten des 1. klinischen Semesters in Deutschland ist), dass die Frauen die Mehrheit darstellen? Oder ist dieser Schluss zu gewagt? \u0177 17 % der M\u00e4nner rauchen, wohingegen dieser Anteil bei den Frauen 19 % betr\u00e4gt. Kann man daraus schlie\u00dfen, dass Frauen mehr rauchen, oder sind die unterschiedlichen Anteile nur zuf\u00e4llig bedingt und haben ansonsten keine tiefere Bedeutung? Auf derlei Fragen kann die deskriptive Statistik keine befriedigenden Antworten geben. Intuitiv w\u00fcrde man wohl annehmen, dass zum im WS 2006/07 tats\u00e4chlich mehr Frauen als M\u00e4nner Medizin studierten, und dass sich aus dem minimalen Unterschied zwischen den Raucheranteilen bei M\u00e4nnern und Frauen kein Hinweis darauf ergibt, dass die Rauchgewohnheiten vom Geschlecht abh\u00e4ngen. Dabei handelt es sich jedoch nur um Vermutungen, die nicht statistisch abgesichert sind. Zu diesem Zweck bedarf es Methoden der induktiven Statistik. In den Kapiteln 9 bis 12 werden wir auf darauf zur\u00fcckkommen.\n4\nDie Beschreibung eines Merkmals 4.1\nDie Methoden der univariaten Statistik 55\n4.2\nLagema\u00dfe 55\n4.2.1\nDas arithmetische Mittel 55\n4.2.2\nDer Median 57\n4.2.3\nQuartile und Quantile 60\n4.2.4\nDer Modus 62\n4.2.5\nMinimum und Maximum 63\n4.2.6\nDas geometrische Mittel 63\n4.2.7\nDas harmonische Mittel 64\n4.3\nStreuungsma\u00dfe 64\n4.3.1\nVarianz und Standardabweichung 65\n4.3.2\nDer Variationskoeffizient 66\n4.3.3\nDie Spannweite 67\n4.3.4\nWeitere Streuungsma\u00dfe 68\n4.4\nFormma\u00dfe 69\n4.4.1\nDie Schiefe 69\n4.4.2\nDie W\u00f6lbung 71\n4.5\nDer Vergleich mehrerer Stichproben 73\n4.5.1\nBeispiele f\u00fcr Gruppenvergleiche 73\n4.5.2\nGraphische Darstellungen 74\n4.5.3\nAnforderungen an die Stichproben 76\n4.5.4\nAusblick auf die induktive Statistik 76\n55\n4\n4.1 Die Methoden der univariaten Statistik\n4.1\nDie Methoden der univariaten Statistik\nIn diesem Kapitel werden Methoden vorgestellt, mit denen sich die charakteristischen Eigenschaften eines einzelnen Merkmals beschreiben lassen. Die geeigneten Methoden sind abh\u00e4ngig von der Art des jeweiligen Merkmals, insbesondere von dessen Skalenniveau. Zur quantitativen Analyse eines Merkmals bedarf es aussagekr\u00e4ftiger statistischer Kenngr\u00f6\u00dfen (oder Ma\u00dfzahlen). Man unterscheidet hierbei Lagema\u00dfe, Streuungsma\u00dfe und Formma\u00dfe. Diese werden in den Abschnitten 4.2 bis 4.4 besprochen. Abschlie\u00dfende Bemerkungen zu den Stichproben finden sich in Abschnitt 4.5. i Die Daten einer Stichprobe werden allgemein mit x ,..., x bezeichnet. z 1 n Diese Werte bilden die so genannte Urliste. Die tief gestellten Indizes geben normalerweise die Reihenfolge an, in der die Daten erhoben wurden; sie haben dar\u00fcber hinaus keine Bedeutung. Die Zahl n symbolisiert den Stichprobenumfang. Die Kenngr\u00f6\u00dfen werden aus den Daten der Stichprobe ermittelt und dienen als Sch\u00e4tzwerte f\u00fcr die entsprechenden Parameter der Grundgesamtheit. Man nennt sie deshalb empirische Gr\u00f6\u00dfen.\n4.2\nLagema\u00dfe\nDie Lagema\u00dfe (auch Lokalisationsma\u00dfe genannt) geben an, in welchem Bereich sich die Stichprobenwerte konzentrieren. 4.2.1\nDas arithmetische Mittel\nDas bekannteste Lagema\u00df ist der Mittelwert (das arithmetische Mittel oder der Durchschnitt). Er wird mit x (sprich: x quer) bezeichnet und nach folgender Formel berechnet: n\nx=\n\u00a6 xi i =1\nn\n(4.1)\nEs werden also alle Stichprobenwerte addiert und deren Summe durch den Stichprobenumfang n dividiert (zur Erkl\u00e4rung des \u01b6-Zei\u203a Abschnitt 3.1). chens: z\n56\nKapitel 4 \u00b7 Die Beschreibung eines Merkmals\nBeispiel 4.1 Von den Merkmalen der Tabelle 2.1 lassen sich Mittelwerte f\u00fcr die K\u00f6rpergr\u00f6\u00dfe, das K\u00f6rpergewicht und die Anzahl der richtig gel\u00f6sten Klausuraufgaben berechnen. F\u00fcr die mittlere K\u00f6rpergr\u00f6\u00dfe erh\u00e4lt man: xm = 181,22 cm (m\u00e4nnliche Studenten, n = 23 )\n4\nxw = 169,06 cm\n(weibliche Studenten, n = 48 )\nx ges = 173,00 cm\n(alle Studenten, n = 71 )\nEs f\u00e4llt auf, dass die weiblichen Studenten im Durchschnitt wesentlich kleiner sind als ihre m\u00e4nnlichen Kommilitonen. Ob dieser Unterschied nur zuf\u00e4llig bedingt ist oder ob er ein Hinweis darauf ist, dass weibliche Studenten generell kleiner sind, kann an dieser Stelle nicht beurteilt werden. Die induktive Statistik stellt Methoden zur Verf\u00fcgung, die eine Entscheidung diesbez\u00fcglich \u203a Kapitel 11). gestatten (z\nDer Mittelwert hat dieselbe Ma\u00dfeinheit wie die Daten der Stichprobe. Bei einem kleinen Stichprobenumfang bis n = 10 sollte er mit einer zus\u00e4tzlichen Kommastelle angegeben werden; bis n = 100 erscheinen zwei und erst ab n = 1000 drei zus\u00e4tzliche Stellen sinnvoll (auch wenn der Taschenrechner oder der PC wesentlich mehr Kommastellen angeben). Ansonsten t\u00e4uscht man eine h\u00f6here Messgenauigkeit vor als in Wirklichkeit gegeben ist. Der Mittelwert ist sicherlich die bekannteste Kenngr\u00f6\u00dfe der deskriptiven Statistik; allerdings wird seine Bedeutung h\u00e4ufig \u00fcbersch\u00e4tzt. Viele Anwender wissen nicht, dass dessen Berechnung nicht in jedem Fall sinnvoll ist und dass andere Lagema\u00dfe existieren, die sich zur Beschreibung einer H\u00e4ufigkeitsverteilung eventuell besser eignen. Ein Nachteil des Mittelwerts besteht darin, dass er von Ausrei\u00dfern stark beeinflusst wird und daher bei schiefen Verteilungen \u203a Beispiel 4.3). ein verzerrtes Bild der Verteilung wiedergibt (z Aus der mathematischen Herleitung geht hervor, dass der Mittelwert nur dann berechnet werden darf, wenn die Differenz zwischen zwei Auspr\u00e4gungen definiert ist. Dies setzt quantitative Merkmale voraus. Ein Mittelwert, der einem ordinalen oder gar einem nominalen Merkmal zugeordnet wird, ist nicht sinnvoll interpretier\u203a Beispiel 4.4). bar (z Ob ein Merkmal ann\u00e4hernd symmetrisch verteilt ist, kann anhand einer geeigneten graphischen Darstellung (z. B. Histogramm) \u203a Abschnitt 4.4.1) beurteilt werden. oder am Wert der Schiefe (z\n57\n4\n4.2 Lagema\u00dfe\nMerke Der Mittelwert\n\u0177 \u0177 \u0177\ndarf nur f\u00fcr quantitative Merkmale (nicht f\u00fcr ordinal skalierte) berechnet werden; ist vor allem bei symmetrischen, eingipfeligen Verteilungen sinnvoll; nutzt im Gegensatz zu anderen Lagema\u00dfen alle Informationen der Stichprobenwerte.\nMathematische Herleitung des Mittelwertes Vom Mittelwert x erwartet man, dass er die Lage der Werte xi optimal repr\u00e4sentiert; d. h. die Abweichungen der x i von x sollten m\u00f6glichst gering sein. Die Summe aller Abst\u00e4nde \u00a6 ( xi \u2212 x ) zu minimieren ist nicht sinnvoll, da sich positive und negative Abweichungen gegenseitig ausgleichen. Daher berechnet man x so, dass die Summe der Abstandsquadrate \u00a6 ( xi \u2212 x ) 2 minimal wird. Dieses Vorgehen bezeichnet man als die Methode der kleinsten Quadrate. Aus der Analysis ist bekannt, dass eine Funktion im Punkt x ein relatives Minimum hat, wenn gilt: f ' ( x ) = 0 und f ' ' ( x ) > 0 . Man berechnet also f\u00fcr die Funktion n\nn\nn\ni =1\ni =1\ni =1\nf ( x ) = \u00a6 ( xi \u2212 x )2 = \u00a6 xi 2 \u2212 2 x \u00a6 xi + n \u22c5 x 2 n\nf '( x ) = \u22122\u00a6 xi + 2nx = 0 und\nein x , f\u00fcr das gilt:\nf '' ( x ) = 2 n > 0 .\ni =1\nn\nOffensichtlich erf\u00fcllt der Wert x = \u00a6 xi / n diese Voraussetzungen. i =1\nDa mit diesem x die Summe der Abstandsquadrate minimiert ist, gilt: n\n\u00a6(x i =1\nn\ni\n\u2212 x )2 \u2264 \u00a6 ( xi \u2212 c )2 f\u00fcr alle reellen Zahlen c. i =1\nDiese Ungleichung beschreibt die so genannte Minimumeigenschaft des Mittelwertes.\n4.2.2\nDer Median\nDer empirische Median (oder Zentralwert) teilt die Stichprobenwerte in zwei H\u00e4lften: Die eine H\u00e4lfte der Daten ist h\u00f6chstens so gro\u00df wie der Median, die andere H\u00e4lfte ist mindestens so gro\u00df. Um diese Kenngr\u00f6\u00dfe, die \u00fcblicherweise mit x (sprich: x Schlange) bezeichnet wird, zu ermitteln, sind die Stichprobenwerte der Gr\u00f6\u00dfe nach zu sortieren. Die geordneten Werte werden mit tief gestellten, in Klammern gesetzten Indizes versehen, sodass gilt:\n58\nKapitel 4 \u00b7 Die Beschreibung eines Merkmals\nx(1) \u2264 x(2) \u2264 ... \u2264 x(n )\n4\nDemnach ist x (1) der kleinste Wert der Stichprobe, also das Minimum (er wird auch als xmin bezeichnet); x (n ) oder x max ist der gr\u00f6\u00dfte Wert, das Maximum. Die sortierten Stichprobenwerte nennt \u203a Tabelle 4.1). Das dazugeh\u00f6rende Merkmal muss man Rangliste (z mindestens ordinal skaliert sein, da f\u00fcr nominal skalierte Daten keine sinnvolle Reihenfolge angegeben werden kann. Der empirische Median x wird in Abh\u00e4ngigkeit vom Stichprobenumfang n nach folgender Formel ermittelt: x \u00a7 n +1 \u00b7 \u00b0 \u00a8\u00a9 2 \u00b8\u00b9 \u00b0 ~ x = \u00aex n + x n \u00b7 \u00a7 \u00b7 \u00a7 \u00a8 +1\u00b8 \u00b0 \u00a8\u00a9 2 \u00b8\u00b9 \u00a92 \u00b9 \u00b0 2 \u00af\nf\u00fcr n ungerade\n(4.2) f\u00fcr n gerade\nAus (4.2) folgt, dass x entweder ein Wert der Urliste ist (falls n ungerade) oder der Durchschnittswert der beiden mittleren Werte (falls n gerade). Deshalb hat der empirische Median dieselbe Ma\u00dfeinheit wie die xi -Werte und h\u00f6chstens eine Stelle mehr nach dem Dezimalkomma. Beispiel 4.2 Nach der Formel (4.2) ergeben sich f\u00fcr die K\u00f6rpergr\u00f6\u00dfe folgende Werte f\u00fcr \u203a Tabelle 4.1): die Mediane (z ~ xm = xm(12) = 180 cm (m\u00e4nnliche Studenten, n = 23 ) xw( 24) + xw( 25) ~ xw = = 169,5 cm 2 ~ x ges = x(36) = 173 cm\n(weibliche Studenten, n = 48 ) (alle Studenten, n = 71 )\nDa bei ordinal skalierten Daten die Berechnung des Mittelwerts nicht statthaft ist, wird stattdessen gerne der Median als Lagema\u00df benutzt. Ein weiterer Vorteil des Medians liegt darin, dass er gegen\u00fcber Ausrei\u00dfern robust ist. Ausrei\u00dfer bewirken, dass Mittelwert und Median stark voneinander abweichen \u2013 in diesen F\u00e4llen ist die Verteilung schief. Wenn Mittelwert und Median in etwa \u00fcbereinstimmen, ist dies ein Hinweis darauf, dass die Verteilung symmetrisch ist. Ein Vergleich der beiden Lagema\u00dfe liefert demnach Hinweise auf die Form der zugrunde liegenden Verteilung.\n59\n4\n4.2 Lagema\u00dfe\nBeispiel 4.3 Die postoperative Krankenhaus-Aufenthaltsdauer von vier Patienten nach einer Appendektomie betrug 4, 5, 5 und 6 Tage. Bei einem weiteren Patienten traten Komplikationen ein; er blieb 20 Tage im Krankenhaus. Aus diesen 5 Werten ergibt sich eine mittlere Aufenthaltsdauer von 8 Tagen; der Median betr\u00e4gt dagegen nur 5 Tage. Der Mittelwert wird wesentlich vom Ausrei\u00dfer bestimmt; er gibt die tats\u00e4chlichen Verh\u00e4ltnisse verzerrt wieder. Der Median ist dagegen von diesem Ausrei\u00dfer weitgehend unbeeinflusst. Beispiel 4.4 Wir betrachten das ordinal skalierte Merkmal \u201eTherapieerfolg\u201c mit den Auspr\u00e4gungen 0 (Patient verstorben), 1 (Zustand verschlechtert), 2 (keine Ver\u00e4nderung eingetreten), 3 (Zustand verbessert) und 4 (Patient vollst\u00e4ndig geheilt). Wenn jeweils die eine H\u00e4lfte der Patienten verstorben und die andere vollst\u00e4ndig geheilt ist, besagt der Median ~ x = 2 , dass bei der H\u00e4lfte der Patienten keine Ver\u00e4nderung oder ein schlechterer Zustand eingetreten ist, w\u00e4hrend bei der anderen H\u00e4lfte der Zustand unver\u00e4ndert geblieben ist oder sich gebessert hat. Es ist jedoch vollkommen sinnlos, aus den Codierungen einen Mittelwert von 2 zu berechnen und zu behaupten, \u201ekeine Ver\u00e4nderung\u201c sei der Durchschnitt zwischen \u201etot\u201c und \u201evollst\u00e4ndig geheilt\u201c.\nBei zensierten Daten (etwa bei \u00dcberlebenszeitanalysen) hat der Median den Vorteil, dass er bereits berechnet werden kann, nachdem die H\u00e4lfte der Studienteilnehmer verstorben ist. Um einen Mittelwert zu berechen, m\u00fcsste man den Tod aller Untersuchungseinheiten abwarten. Wenn es sich bei dem Merkmal um die verabreichte Dosis eines Pharmakons handelt, ist der Median die Dosis, die bei der H\u00e4lfte der Untersuchungseinheiten einen Effekt erkennen l\u00e4sst. Mathematische Beschreibung des Medians Der Median x ist der Wert, f\u00fcr den die Summe der Abweichungsbetr\u00e4ge n\n\u00a6x\ni\ni =1\n\u2212 x minimal ist; d. h.:\nn\n\u00a6x\ni\ni =1\nn\n\u2212 x \u2264 \u00a6 xi \u2212 c f\u00fcr alle reellen Zahlen c. i =1\nDiese Ungleichung beschreibt die Minimumeigenschaft des Medians. Diese Eigenschaft setzt metrisch skalierte Merkmale voraus, da Differenzen bei ordinal skalierten Merkmalen nicht definiert sind. F\u00fcr die Berechnung des Medians werden jedoch nicht alle Werte ben\u00f6tigt; nur deren Reihenfolge ist ma\u00dfgebend. Da diese Reihenfolge auch bei einer Ordinalskala definiert ist, ist die Berechnung des Medians auch bei diesen Merkmalen \u00fcblich.\n60\nKapitel 4 \u00b7 Die Beschreibung eines Merkmals\nMerke Die Angabe des Medians ist sinnvoll\n\u0177 \u0177 \u0177 \u0177\n4\nbei ordinal skalierten Daten; bei quantitativen Merkmalen, die schief verteilt sind; bei Verdacht auf Ausrei\u00dfer; bei zensierten Daten.\nWenn der Mittelwert und der Median stark voneinander abweichen, sollte dies bei der Pr\u00e4sentation der Ergebnisse und ihrer Interpretation ber\u00fccksichtigt werden.\n4.2.3\nQuartile und Quantile\nW\u00e4hrend der Median die Stichprobe in zwei H\u00e4lften einteilt, teilen die Quartile die Stichprobe in vier Viertel. \u2022 Unteres oder erstes Quartil Q1 . Dieses besagt, dass 25% der Stichprobenwerte kleiner als oder gleich Q1 sind, w\u00e4hrend dementsprechend 75% der Werte gr\u00f6\u00dfer als oder gleich Q1 sind. \u2022 Oberes oder drittes Quartil Q3 . Analog gilt, dass 75% der Werte maximal so gro\u00df wie Q3 und die Werte des restlichen Viertels mindestens so gro\u00df wie Q3 sind. \u2022 Mittleres oder zweites Quartil Q2 . Es entspricht dem Median x . Eine weitere Verfeinerung der H\u00e4ufigkeitsverteilung gestatten die Quantile (oder Fraktile) x\u03b1 , die f\u00fcr alle reellen Zahlen \u03b1 mit 0 < \u03b1 < 1 definiert sind. Ein \u03b1-Quantil wird folgenderma\u00dfen berechnet: Man ermittelt zun\u00e4chst den Wert \u03b1 \u22c5 n und davon abh\u00e4ngig eine Rangzahl k und das Quantil x\u03b1 nach folgenden Formeln:\n\u0177 Falls \u03b1 \u22c5 n keine ganze Zahl ist, sei k die direkt auf \u03b1 \u22c5 n folgende ganze Zahl und x\u03b1 = x( k ) \u0177 Falls \u03b1 \u22c5 n eine ganze Zahl ist, sei k = \u03b1 \u22c5 n und x( k ) + x( k +1 ) x\u03b1 = 2\n(4.3a) (4.3b)\nSpezielle Quantile sind der Median (\u03b1 = 0,50) sowie die beiden Quartile (\u03b1 = 0,25 bzw. \u03b1 = 0,75). Von Dezilen spricht man, falls \u03b1 = 0,1 , 0,2 ,..., 0,9 ; von Perzentilen bei 2-stelligen Kommazahlen \u03b1 = 0,01 , ..., 0,99 .\n4\n61 4.2 Lagema\u00dfe\nDie Angabe eines Perzentils kann sehr hilfreich sein, um einen Messwert gr\u00f6\u00dfenm\u00e4\u00dfig einzuordnen. So werden etwa in der Kinderheilkunde die individuellen Werte eines Kindes bez\u00fcglich Gr\u00f6\u00dfe, Gewicht oder Kopfumfang mit den altersgem\u00e4\u00dfen 5%- und 95%Perzentilen verglichen, um zu beurteilen, ob es Auff\u00e4lligkeiten in der Entwicklung gibt. Beispiel 4.5 Wir bestimmen mit Hilfe der Rangliste in Tabelle 4.1 einige Quantile bez\u00fcglich der K\u00f6rpergr\u00f6\u00dfe der weiblichen Studenten nach Formel 4.3b ( n = 48 ): 1. Quartil: \u03b1 \u22c5 n = 0,25 \u22c5 48 = 12 ; also k = 12 und Q1 = ( x(12) + x(13) ) / 2 = 165 cm \u03b1 \u22c5 n = 0,75 \u22c5 48 = 36 ; also k = 36 und\n3. Quartil:\nQ3 = ( x(36) + x(37) ) / 2 = 173,5 cm \u03b1 \u22c5 n = 0,90 \u22c5 48 = 43,2 ; also k = 44 und\n9. Dezil:\nx0,90 = x(44) = 178 cm\nDaraus folgt, dass eine 164 cm gro\u00dfe Studentin bez\u00fcglich ihrer K\u00f6rpergr\u00f6\u00dfe im unteren Viertel liegt, w\u00e4hrend eine 180 cm gro\u00dfe Dame den oberen 10% angeh\u00f6rt. Tabelle 4.1. Rangliste bez\u00fcglich des Merkmals \u201eK\u00f6rpergr\u00f6\u00dfe\u201c f\u00fcr weibliche Studenten mit Daten aus Tabelle 2.1. Angegeben sind der Rang, die K\u00f6rpergr\u00f6\u00dfe sowie die ID. Rang\nGr\u00f6\u00dfe\nID\nRang\nGr\u00f6\u00dfe\nID\nRang\nGr\u00f6\u00dfe\nID\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16\n156 156 156 157 157 160 162 163 163 164 164 165 165 165 166 167\n28 29 49 40 59 60 62 39 45 24 71 47 68 70 58 25\n17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32\n168 168 168 168 168 168 169 169 170 170 170 170 172 172 172 172\n30 32 36 43 46 69 35 41 26 33 44 61 31 42 50 65\n33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n172 173 173 173 174 174 174 175 176 176 178 178 179 180 180 180\n67 38 51 53 48 55 56 34 37 52 54 66 27 57 63 64\n62\nKapitel 4 \u00b7 Die Beschreibung eines Merkmals\nMerke Der Median, die Quartile und alle sonstigen Quantile lassen sich \u00fcber die empirische Verteilungsfunktion F (x) beschreiben und graphisch absch\u00e4tzen. Nach Definition ist n\u00e4mlich: F (x~\u03b1 ) = \u03b1 . F\u00fcr den Median und \u203a die Quartile gelten also: F ( ~x ) = 0,5 , F (Q1 ) = 0,25 und F (Q3 ) = 0,75 (z Abbildung 3.6). ! In der Literatur werden teilweise etwas andere Berechnungsarten vorgez\n4\nschlagen, die jedoch \u00e4hnliche Werte wie die Formeln (4.3a) und (4.3b) liefern. In jedem Fall ist zu beachten, dass derlei Angaben nur bei einem entsprechend hohen Stichprobenumfang sinnvoll sind.\n4.2.4\nDer Modus\nDer Modus (auch Modalwert oder Dichtemittel genannt) ist die Auspr\u00e4gung mit der gr\u00f6\u00dften H\u00e4ufigkeit. Er wird mit dem Buchstaben D (oder M) abgek\u00fcrzt und kann bei allen Skalenniveaus ermittelt werden. Bei Daten, die in Klassen eingeteilt sind, gibt man statt des Modalwertes gerne die modale Klasse an \u2013 das ist die Klasse mit der gr\u00f6\u00dften Besetzungszahl \u2013 und bezeichnet deren Mitte als Modus. Beispiel 4.6 \u203a Beispiel 3.1). Bei der Anzahl Der Modus des Merkmals \u201eBlutgruppe\u201c ist A (z \u203a Abbildung 3.2). Die richtig gel\u00f6ster Klausuraufgaben ist der Modus 9 (z modale Klasse bei der K\u00f6rpergr\u00f6\u00dfe der Studenten ist (167,5 cm; 172,5 cm) mit \u203a Beispiel 3.2). Dieser Gipfel ist der H\u00e4ufigkeit 18 und dem Modus 170 cm (z jedoch nur schwach ausgepr\u00e4gt. Die Klasse (177,5 cm; 182,5 cm) ist nahezu ebenso stark.\nAnhand der graphischen Darstellung ist erkennbar, ob die Verteilung eingipfelig (unimodal), zweigipfelig (bimodal) oder mehrgipfelig (multimodal) ist. Zwei- und mehrgipfelige Verteilungen beobachtet man in der Regel bei heterogenen Populationen, in denen sich mehrere Verteilungen \u00fcberlappen. So gibt es beispielsweise in der Abbildung 3.4 (H\u00e4ufigkeitspolygon der K\u00f6rpergr\u00f6\u00dfen) zwei Gipfel, wobei einer von M\u00e4nnern und einer von Frauen gebildet wird. Uf\u00f6rmige Verteilungen sind durch zwei Modalwerte an ihren R\u00e4ndern und einem Tiefpunkt in der Mitte charakterisiert. Der Mittelwert einer solchen Verteilung repr\u00e4sentiert einen atypischen Wert. Ein Beispiel ist das Merkmal \u201eIntensit\u00e4t der Einstellung zu einer alternativen Heilmethode\u201c. Es gibt viele Ablehnende (niedrige Intensit\u00e4t), viele Zustimmende (hohe Intensit\u00e4t), aber wenig Neutrale (mit Werten in der Mitte der Skala).\n4\n63 4.2 Lagema\u00dfe\nMerke Modalwerte werden haupts\u00e4chlich angegeben: \u0177 bei nominalen Merkmalen, da andere Lagema\u00dfe bei diesem Skalenniveau nicht zul\u00e4ssig sind; \u0177 bei ordinalen und quantitativen Merkmalen, wenn es sich um einen \u201eausgepr\u00e4gten Gipfel\u201c handelt (dies setzt in der Regel einen sehr hohen Stichprobenumfang voraus). \u0177 bei einer U-Verteilung. Die Angabe eines Modalwertes ist nicht empfehlenswert: \u0177 bei Alternativmerkmalen (etwa Geschlecht oder Rhesusfaktor); \u0177 wenn es keinen \u201eausgepr\u00e4gten Gipfel\u201c gibt.\n4.2.5\nMinimum und Maximum\nDies sind die beiden extremsten Werte eines ordinal oder metrisch skalierten Merkmals. Sie geben einen sehr groben \u00dcberblick \u00fcber die Streuung der Daten. Au\u00dferdem sind diese Ma\u00dfe hilfreich, um die Daten auf Plausibilit\u00e4t zu \u00fcberpr\u00fcfen: Fehler, die bei der Dateneingabe entstehen (wenn etwa das Dezimalkomma falsch gesetzt wird), werden am ehesten durch einen Blick auf das Minimum und das Maximum offensichtlich. 4.2.6\nDas geometrische Mittel\nDas geometrische Mittel wird bei relativen \u00c4nderungen verwendet, bei denen sich der Unterschied zweier Merkmalswerte sinnvoller durch einen Quotienten als durch eine Differenz beschreiben l\u00e4sst. Dies ist der Fall bei Verd\u00fcnnungsreihen (z. B. bei Antik\u00f6rpertitern in der Immunologie) oder bei Wachstumserscheinungen (z. B. die Zunahme der Unterhaltskosten einer Klinik). Wenn xi die relativen \u00c4nderungen bezeichnen (wobei xi > 0 und dimensionslos), berechnet es sich das geometrische Mittel als:\nxG = n x1\u22c5...\u22c5xn\n(4.4)\nBeispiel 4.7 Die Titer von f\u00fcnf Kaninchenseren sind: 1/100, 1/200, 1/400, 1/800 und 1/1000. Dann berechnet man f\u00fcr das geometrische Mittel: xG = 5\n1 1 1 1 1 1 \u22c5 \u22c5 \u22c5 \u22c5 \u2248 100 200 400 800 1000 364\n64\nKapitel 4 \u00b7 Die Beschreibung eines Merkmals\ni H\u00e4ufig wird das geometrische Mittel herangezogen, wenn die Stichz \u203a Abschnitt 4.4.1). probenwerte rechtsschief verteilt sind (z\n4.2.7\n4\nDas harmonische Mittel\nDas harmonische Mittel dient als Lagema\u00df, wenn die Beobachtungswerte xi Verh\u00e4ltniszahlen (also Quotienten) sind, die sich nur in ihren Nennern unterscheiden. Damit l\u00e4sst sich etwa eine Durchschnittsgeschwindigkeit oder eine durchschnittliche Dichte berechnen. Es ist definiert als: xH =\nn n\n1 \u00a6x i =1 i\n(4.5)\nBeispiel 4.8 Derselbe Weg s wird einmal mit der Geschwindigkeit v1 = 20 km/h und ein anderes Mal mit v2 = 30 km/h zur\u00fcckgelegt. Die Geschwindigkeiten sind definiert als Quotienten v1 = s / t1 bzw. v 2 = s / t2 (wobei t1 und t2 die ben\u00f6tigten Zeiten darstellen). Zur Berechnung der Durchschnittsgeschwindigkeit verwendet man das harmonische Mittel nach (4.5): 2 vH = = 24 1 1 + 20 30 i Ein Vorteil des harmonischen Mittels liegt darin, dass auch \u201eunendlich z lange\u201c Zeiten ber\u00fccksichtigt werden k\u00f6nnen. Falls am Ende einer Studie einige Probanden (oder Versuchstiere) noch leben, wird deren \u00dcberlebenszeit als unendlich angenommen. Der Kehrwert ist dann 0 und flie\u00dft als solcher in die Summe des Nenners ein. Damit kann das harmonische Mittel nach (4.5) berechnet werden.\n4.3\nStreuungsma\u00dfe\nWenn sich zwei Verteilungen hinsichtlich ihrer Lagema\u00dfe \u00e4hneln, k\u00f6nnen sie dennoch aufgrund ihrer Streuung sehr unterschiedlich sein. Die Streuungsma\u00dfe (oder Dispersionsma\u00dfe) geben Auskunft \u00fcber die Variabilit\u00e4t der Stichprobenwerte.\n4\n65 4.3 Streuungsma\u00dfe\n4.3.1\nVarianz und Standardabweichung\nBei quantitativen Merkmalen ist der Mittelwert das am h\u00e4ufigsten benutzte Lagema\u00df. Es liegt deshalb nahe, ein Streuungsma\u00df zu definieren, das die Abweichungen der Stichprobenwerte vom Mittelwert quantifiziert. Ein solches Ma\u00df ist die Varianz \u2013 das ist die mittlere quadratische Abweichung der Daten vom Mittelwert. Wenn man nun (wie es nahe liegend erscheint) die Varianz berechnet, indem man die Summe der Abstandsquadrate ( xi \u2212 x ) 2 durch n dividiert, erh\u00e4lt man die Varianz der Stichprobe. Allerdings ist diese Stichproben-Varianz im Durchschnitt etwas kleiner als die \u203a Abschnitt 9.2.3) geVarianz der Grundgesamtheit. Es wird sp\u00e4ter (z zeigt, dass man aus den Messwerten der Stichprobe einen optimalen Sch\u00e4tzwert f\u00fcr die Varianz der Grundgesamtheit erh\u00e4lt, wenn man die empirische Varianz nach folgender Formel ermittelt: n\nn\nVar =\n\u00a6 ( xi \u2212 x ) 2 \u00a6 xi2 \u2212 nx 2 i =1\nn \u22121\n=\ni =1\nn \u22121\n(4.6)\nWegen der quadratischen Dimension ist die Varianz schwer zu interpretieren. Um ein Streuungsma\u00df mit gleicher Dimension wie die der Stichprobendaten zu erhalten, zieht man die Wurzel aus der Varianz und erh\u00e4lt die Standardabweichung: s = Var\n(4.7)\nBeispiel 4.9 F\u00fcr die Standardabweichungen des Merkmals \u201eK\u00f6rpergr\u00f6\u00dfe\u201c berechnet man: sm = 7,12 cm (m\u00e4nnliche Studenten, n = 23 ) s w = 6,60 cm\n(weibliche Studenten, n = 48 )\ns ges = 8,83 cm\n(alle Studenten, n = 71 )\nDie \u201egemischte\u201c Gruppe ist also bzgl. der K\u00f6rpergr\u00f6\u00dfe wesentlich heterogener ist als die beiden Gruppen der m\u00e4nnlichen und der weiblichen Studenten.\nDie Standardabweichung stellt ein Ma\u00df f\u00fcr die Homogenit\u00e4t bzw. Heterogenit\u00e4t der Stichprobe dar. Sie ist wie der Mittelwert nur bei quantitativen Merkmalen sinnvoll. Im Allgemeinen ist diese Ma\u00dfzahl positiv; nur im Extremfall \u2013 wenn alle Werte identisch sind und die Stichprobe vollkommen homogen ist \u2013 nimmt sie den Wert 0 an.\n66\nKapitel 4 \u00b7 Die Beschreibung eines Merkmals\nEs ist \u00fcblich, quantitative, ann\u00e4hernd symmetrisch verteilte Daten durch den Mittelwert und die Standardabweichung in der Form x \u00b1 s unter Angabe des Stichprobenumfangs n zu charakterisieren, wie zum Beispiel f\u00fcr die K\u00f6rpergr\u00f6\u00dfe der m\u00e4nnlichen Studenten: x \u00b1 s = (181,22 \u00b1 7,12) cm ( n = 23 ). Die Standardabweichung erlaubt folgende Absch\u00e4tzungen:\n\u0177 Bei Normalverteilungen liegen etwa 2/3 aller Werte zwischen\n4\nx \u2212 s und x + s ; zwischen den Grenzen x \u2212 2s und x + 2 s lie\u203a Tabelle 8.1). gen ungef\u00e4hr 95% aller Werte (z \u0177 Bei symmetrischen, eingipfeligen Verteilungen liegen mindestens 8/9 aller Werte innerhalb der Grenzen x \u00b1 2 s und 95% im \u203a Formel 8.21). Bereich x \u00b1 3s (z \u0177 Generell findet man bei allen (also auch bei schiefen) Verteilungen mindestens 3/4 aller Werte im Intervall x \u00b1 2 s und 8/9 in \u203a Formel 8.19). x \u00b1 3s (z Mathematische Herleitung der Varianz Die Idee, anstelle des mittleren Abstandsquadrats einfach den mittleren Abstand der Messwerte vom Mittelwert zu berechnen, erweist sich als unsinnig, da sich positive und negative Abweichungen ausgleichen: n\n\u00a6(x\ni\ni =1\nn\n\u2212 x ) = \u00a6 xi \u2212 nx = nx \u2212 nx = 0 i =1\nDies erkl\u00e4rt, weshalb man bei der Berechnung der Varianz die Summe der Abstandsquadrate zugrunde legt. Wenn man im Z\u00e4hler von (4.6) die einzelnen Terme ausmultipliziert und addiert, erh\u00e4lt man: n\n\u00a6(x\ni\ni =1\nn\nn\nn\nn\ni =1\ni =1\ni =1\ni =1\n\u2212 x )2 = \u00a6 xi 2 \u2212 2 x \u00a6 xi +nx 2 = \u00a6 xi2 \u2212 2nx 2 + nx 2 = \u00a6 xi2 \u2212nx 2\nDie Division durch n \u2212 1 ist dadurch begr\u00fcndet, dass nur n \u2212 1 Summanden des Z\u00e4hlers eine Information beinhalten. Wenn n\u00e4mlich n \u2212 1 Stichprobenwerte und der Mittelwert bekannt sind, l\u00e4sst sich aus diesen Angaben der noch fehlende Summand ermitteln. Die Zahl f = n \u2212 1 wird auch als die Anzahl der Freiheitsgrade bezeichnet. Das bedeutet: Man hat die \u201eFreiheit\u201c, n \u2212 1 Werte nach Belieben zu ver\u00e4ndern und den letzten Wert entsprechend anzupassen, ohne dass sich dabei der Wert der Varianz \u00e4ndert.\n4.3.2\nDer Variationskoeffizient\nEine Standardabweichung von 7,12 cm \u2013 bezogen auf die K\u00f6rpergr\u00f6\u00dfe von m\u00e4nnlichen Studenten mit einem Durchschnittswert von 181,22 cm \u2013 wiegt wesentlich weniger als dieselbe Standardabweichung bezogen auf eine Gruppe von Kleinkindern mit einer mittle-\n4\n67 4.3 Streuungsma\u00dfe\nren Gr\u00f6\u00dfe von 90 cm. Dieser Sachverhalt l\u00e4sst sich durch den Variationskoeffizienten quantitativ beschreiben: V = s / x (falls x > 0 )\n(4.8)\nDieses Ma\u00df ist dimensionslos und nur f\u00fcr verh\u00e4ltnisskalierte Merkmale geeignet. Sein Maximum betr\u00e4gt n . Der relative Variationskoeffizient kann daher nur Werte zwischen 0 und 1 annehmen: Vr =\ns/ x n\n(4.9)\ni Ein relativer Variationskoeffizient bis zu 0,30 ist in den Biowissenschafz ten keine Seltenheit. Wenn er jedoch wesentlich h\u00f6her ist, ist dies ein Hinweis darauf, dass die Verteilung extrem schief ist, oder dass zwei inhomogene Gruppen gemeinsam untersucht werden. Dies sollte man nach M\u00f6glichkeit vermeiden.\nMathematische Herleitung des relativen Variationskoeffizienten Die Varianz ist minimal (d. h. gleich 0), wenn alle Werte der Stichprobe identisch sind. Dann ist auch der relative Variationskoeffizient 0. Die Varianz ist bei gegebenem Mittelwert x maximal, wenn eine Beobachtungseinheit den Wert n \u22c5 x annimmt, w\u00e4hrend die anderen n \u22121 Werte gleich 0 sind. F\u00fcr diesen Extremfall berechnet man: 1 \u22c5 ( nx \u2212 x ) 2 + ( n \u2212 1) \u22c5 (0 \u2212 x )2 ( n \u2212 1) 2 \u22c5 x 2 + ( n \u2212 1) \u22c5 x 2 s2 = = = n \u22c5 x2 n \u22121 n \u22121 Daraus folgt: 0 \u2264 V = s / x \u2264 n und 0 \u2264 Vr \u2264 1 .\n4.3.3\nDie Spannweite\nDas am einfachsten zu berechnende Streuungsma\u00df ist die Spannweite oder Variationsbreite:\nR = xmax \u2212 xmin = x( n ) \u2212 x(1)\n(4.10)\nEbenso wie die Standardabweichung ist die Spannweite nur dann gleich 0, wenn alle Stichprobenwerte identisch sind, und ansonsten positiv. Sie ist wesentlich leichter zu berechnen als die Standardabweichung; allerdings ber\u00fccksichtigt sie nur die beiden extremsten Werte und ist daher sehr stark von Ausrei\u00dfern beeinflusst. Deshalb wird diese Ma\u00dfzahl haupts\u00e4chlich bei diskreten Merkmalen mit wenigen Auspr\u00e4gungen verwendet.\n68\nKapitel 4 \u00b7 Die Beschreibung eines Merkmals\ni Die Spannweite ist streng genommen nur f\u00fcr quantitative Merkmale z geeignet, da bei niedrigeren Skalenniveaus Differenzen nicht sinnvoll sind. Vielfach wird R jedoch auch bei ordinal skalierten Merkmalen berechnet. Dies ist dann zu vertreten, wenn die Auspr\u00e4gungen mit nat\u00fcrlichen, aufeinander folgenden Zahlen codiert sind. Die Spannweite ist in diesem Fall nicht als Differenz, sondern als die Anzahl der Abstufungen zwischen dem gr\u00f6\u00dften und dem kleinsten Wert zu verstehen.\n4\n4.3.4\nWeitere Streuungsma\u00dfe\n\u2022 Dezilabstand. Ein Streuungsma\u00df, das weniger empfindlich ist als die Spannweite, erh\u00e4lt man, wenn man an beiden R\u00e4ndern der Verteilung jeweils 10 % abschneidet und die L\u00e4nge dieses so genannten Interdezilbereichs berechnet: I80 = x0,90 \u2212 x0,10\n(4.11)\n\u2022 Quartilsabstand. Dies ist die L\u00e4nge des Interquartilsbereichs Q1 ,Q3 , der die mittleren 50 % der Stichprobenwerte enth\u00e4lt: I50 = Q3 \u2212 Q1 = x0,75 \u2212 x0,25\n(4.12)\nBeispiel 4.10 F\u00fcr das Merkmal \u201eK\u00f6rpergr\u00f6\u00dfe\u201c (Daten aus Tabelle 2.1) berechnet man: I 50, m = 186 cm \u2212 178 cm = 8 cm (m\u00e4nnliche Studenten, n = 23 ) I 50, w = 173,5 cm \u2212 165 cm = 8,5 cm\n(weibliche Studenten, n = 48 )\nI 50 ges = 179 cm \u2212 168 cm = 11 cm\n(alle Studenten, n = 71 )\nAuch diese Zahlen zeigen, dass die Gruppe aller Studenten heterogener ist als die beiden anderen, geschlechtshomogenen Gruppen.\n\u2022 Mittlere Abweichung vom Median. Auch dieses Streuungsma\u00df wird \u2013 zusammen mit dem Median als Lagema\u00df \u2013 gelegentlich bei ordinal skalierten oder schief verteilten Daten verwendet: n\n\u00a6 x \u2212 x i\nMAx =\ni =1\nn\n(4.13)\n\u2022 Variation Ratio. Schlie\u00dflich gibt es sogar ein Streuungsma\u00df f\u00fcr nominal skalierte Merkmale: die Variation Ratio VR (ein deutscher Begriff hat sich daf\u00fcr noch nicht eingeb\u00fcrgert). Es handelt sich dabei\n4\n69 4.4 Formma\u00dfe\num die relative H\u00e4ufigkeit der Beobachtungen, die nicht in die modale Kategorie fallen: VR = 1 \u2212 hmodal\n(4.14)\n(wobei hmodal die relative H\u00e4ufigkeit des Modalwertes ist). VR nimmt den Wert 0 an, falls alle Beobachtungen identisch sind; ansonsten liegt VR zwischen 0 und 1. Je gr\u00f6\u00dfer die Anzahl der Merkmalsauspr\u00e4gungen und je weniger sich die H\u00e4ufigkeiten der einzelnen Kategorien unterscheiden, desto n\u00e4her liegt VR an 1. Beispiel 4.11 Aus Beispiel 3.1 geht hervor, dass die Blutgruppe A mit 44 % relativer H\u00e4ufigkeit der Modus ist. Demnach ist VR = 0,56 .\nMerke Lagema\u00dfe und Streuungsma\u00dfe m\u00fcssen zusammen passen wie z. B.: \u0177 Mittelwert und Standardabweichung bei symmetrisch verteilten Daten \u0177 Median und Quartilsabstand (Dezilabstand oder mittlere Abw. vom Median) bei schief verteilten Daten oder Verdacht auf Ausrei\u00dfer \u0177 Modus und Spannweite bei diskreten Merkmalen mit wenigen Auspr\u00e4gungen \u0177 Modus und Variation Ratio bei nominal skalierten Merkmalen\n4.4\nFormma\u00dfe\nEinige statistische Methoden setzen eine bestimmte Verteilungsform \u203a Abschnitt 8.2) voraus. Einen ersten Ein(z. B. Normalverteilung, z druck diesbez\u00fcglich liefern die graphischen Darstellungen. Sie lassen erkennen, ob eine Verteilung einen oder mehrere Gipfel hat, ob sie symmetrisch ist und ob sie stark oder eher schwach gew\u00f6lbt ist. Die dritte Art der Kenngr\u00f6\u00dfen \u2013 die Formma\u00dfe \u2013 dient dazu, die Verteilungsform quantitativ zu beschreiben. 4.4.1\nDie Schiefe\nDie Schiefe ist ein Formma\u00df, das die Symmetrie bzw. Asymmetrie einer Verteilung kennzeichnet. Sie ist definiert als:\n70\nKapitel 4 \u00b7 Die Beschreibung eines Merkmals\ng1 =\n4\n1 \u22c5 n\nn\n\u00a6 (x \u2212 x) i\ni =1\ns3\n3\n(4.15)\nDie Schiefe ist dimensionslos und kann sowohl positive als auch negative Werte annehmen. Gro\u00dfe Abweichungen der Werte vom Mittelwert werden der 3. Potenz wegen stark betont; kleinere Abweichungen fallen dagegen kaum ins Gewicht. Falls sich positive und negative Abweichungen ausgleichen, ergibt sich f\u00fcr die Schiefe der Wert 0. Die Verteilung ist dann symmet\u203a Abbildung 4.1a). Das bekannteste risch bez\u00fcglich des Mittelwerts (z Beispiel einer symmetrischen Verteilung ist wohl die Normalverteilung. Einige, aber bei weitem nicht alle Merkmale in der Medizin sind ann\u00e4hrend normalverteilt \u2013 etwa die K\u00f6rpergr\u00f6\u00dfe erwachsener M\u00e4nner oder erwachsener Frauen. Die eigentliche Bedeutung dieser Verteilung werden wir in Kapitel 8 kennen lernen. Viele medizinisch relevante Merkmale sind rechtsschief (linksgipfelig oder linkssteil) verteilt (z. B. das K\u00f6rpergewicht erwachsener M\u00e4nner). Die Dichtefunktion hat einen Gipfel an der linken Seite \u203a Abbildung 4.1b). Linksschiefe und einen langen Ausl\u00e4ufer rechts (z \u203a Abbildung 4.1c) (rechtsgipfelige oder rechtssteile) Verteilungen (z findet man in den Biowissenschaften eher selten; ein Beispiel ist die Tragezeit bei S\u00e4ugetieren. Diese Verteilungen haben einen Gipfel am rechten Rand. F\u00fcr eingipfelige Verteilungen gilt: \u0177 Bei symmetrischen Verteilungen ist g1 = 0 und x = ~x = D , \u0177 bei rechtsschiefen Verteilungen ist g1 > 0 und x > x > D , \u0177 bei linksschiefen Verteilungen ist g1 < 0 und x < x < D . Wesentlich einfachere, daf\u00fcr etwas grobere Absch\u00e4tzungen f\u00fcr die Schiefe unimodaler Verteilungen lassen sich nach den Formeln von Pearson ermitteln: g1 \u2248\n3 \u22c5 ( x \u2212 x ) s\n(4.16a)\ng1 \u2248\nx\u2212D s\n(4.16b)\nAuf eine schiefe Verteilung kann nur dann geschlossen werden, wenn das empirisch ermittelte g1 stark von 0 abweicht und der Stichprobenumfang hinreichend gro\u00df ist. Kleinere Abweichungen\n4\n71 4.4 Formma\u00dfe\nvon 0 k\u00f6nnen zufallsbedingt sein und sind insofern kein Hinweis auf eine schiefe Verteilung der Grundgesamtheit. Um eine \u201eechte\u201c Schiefe einigerma\u00dfen sinnvoll absch\u00e4tzen zu k\u00f6nnen, sollte ein Stichprobenumfang von mindestens n \u2265 100 vorliegen. 4.4.2\nDie W\u00f6lbung\nDie W\u00f6lbung (auch Kurtosis oder Exzess genannt) beschreibt die Massenanh\u00e4ufungen an den Enden bzw. um den Mittelwert der Verteilung. Sie ist definiert als:\ng2 =\n1 n \u22c5 \u00a6 ( xi \u2212 x ) 4 n i =1 s4\n\u22123\n(4.17)\nF\u00fcr symmetrische, eingipfelige Verteilungen gilt:\n\u0177 Falls g2 = 0 , sind die Daten normalverteilt. \u0177 Falls g2 > 0 , ist die Verteilung schmaler und steilgipfeliger als\ndie Glockenkurve der Normalverteilung mit gleicher Standardabweichung, das Maximum ist gr\u00f6\u00dfer (positiver Exzess, starke W\u00f6lbung). Die Werte h\u00e4ufen sich in der Umgebung des Mittel\u203a Abbildung 4.1d). werts und an den Ausl\u00e4ufern (z \u0177 Falls g2 < 0 , ist die Verteilung flacher als die Glockenkurve der Normalverteilung, und das Maximum ist kleiner (negativer Exzess, schwache W\u00f6lbung). Eine solche Verteilung hat \u201eausge\u203a Abbildung 4.1e). pr\u00e4gte Schulterpartien\u201c (z Beispiel 4.12 F\u00fcr die K\u00f6rpergr\u00f6\u00dfe der weiblichen Studenten ergibt sich g1 = \u22120,337 . Dieser Wert weicht nur geringf\u00fcgig von 0 ab; man darf deshalb annehmen, dass dieses Merkmal ann\u00e4hernd symmetrisch verteilt ist. Ein Vergleich der Lagema\u00dfe xw = 169,1 cm und ~ xw = 169,5 cm best\u00e4tigt dies. Der Wert der Kurtosis betr\u00e4gt g 2 = \u22120,416 . Dieser Wert nahe bei 0 ist ein Hinweis darauf, dass dieses Merkmal nicht nur symmetrisch, sondern ann\u00e4hernd normalverteilt ist.\nAuch bei der Kurtosis ist zu beachten: Nur gr\u00f6\u00dfere Abweichungen von 0 lassen den Schluss zu, dass die Daten nicht normalverteilt sind. Kleinere Abweichungen sind in der Regel zufallsbedingt und haben keine tiefere Bedeutung, insbesondere bei nicht allzu gro\u00dfen Stichproben.\n72\nKapitel 4 \u00b7 Die Beschreibung eines Merkmals\nAbb. 4.1 a-e: empirische Verteilungen mit unterschiedlicher Schiefe und unterschiedlicher W\u00f6lbung\n4 a. symmetrische Verteilung (Schiefe=0)\nb. rechtsschiefe Verteilung (Schiefe>0)\nc. linksschiefe Verteilung (Schiefe<0)\nd. symmetrische Verteilung (W\u00f6lbung>0)\ne. symmetrische Verteilung (W\u00f6lbung<0)\n4\n73 4.5 Der Vergleich mehrerer Stichproben\n\u00dcbersicht 2: Univariate Datenbeschreibung \u2013 geeignete Ma\u00dfzahlen und graphische Darstellungen Skala\nLagema\u00dfe\nStreuungsma\u00dfe\nFormma\u00dfe\ngraphische Darstellungen\nNominalskala\nModus\nVariation Ratio\n--\nKreisdiagr. Rechteckdiagr. Balkendiagr.\nOrdinalskala\nModus Median Quartile Quantile\nVariation Ratio Spannweite Quartilsabstand Interdezilabstand\n--\nRechteckdiagr. Balkendiagr.\nIntervallskala\nModus Median Quartile Quantile Mittelwert\nSpannweite Quartilsabstand Interdezilabstand Standardabw.\nSchiefe\nVerh\u00e4ltnisskala\ndiskrete Daten: Balkendiagr. symmetrische Punktediagr. Verteilungen: W\u00f6lbung\nSpannweite Quartilsabstand Interdezilabstand Standardabw. Variationskoeff.\n4.5\nDer Vergleich mehrerer Stichproben\n4.5.1\nBeispiele f\u00fcr Gruppenvergleiche\nstetige Daten: Histogramm, H\u00e4ufigkeitspolygon, Stamm-undBlatt-Diagr.\nIn diesem Kapitel wurden zahlreiche Methoden vorgestellt, mit denen sich die charakteristischen Eigenschaften eines einzelnen Merkmals graphisch darstellen und numerisch beschreiben lassen. Oft ist es erforderlich, zwei oder mehrere Stichproben zu untersuchen und diese miteinander zu vergleichen. Das Ziel der statistischen Analyse besteht in der Regel darin, einen Unterschied zwischen diesen Gruppen nachzuweisen. In der medizinischen Forschung finden sich daf\u00fcr vielf\u00e4ltige Anwendungsm\u00f6glichkeiten, wie die folgenden Beispiele zeigen:\n74\nKapitel 4 \u00b7 Die Beschreibung eines Merkmals\n\u0177 Mehrere Therapieformen (z. B. eine neue Therapie und eine\n4\n\u203a klinischStandardtherapie) werden miteinander verglichen (z kontrollierte Studie, Abschnitt 16.1); \u0177 eine Gruppe von erkrankten Patienten wird zur Kl\u00e4rung eines \u00e4tiologischen Faktors einer Gruppe von gesunden Personen ge\u203a Fall-Kontroll-Studie, Abschnitt 14.3); gen\u00fcbergestellt (z \u0177 Personen, die einem bestimmten Risiko ausgesetzt sind, und Personen, die diesem Risiko nicht ausgesetzt sind, werden eine \u203a Kohortenstudie, Abschnitt Zeitlang gemeinsam beobachtet (z 14.4). 4.5.2\nGraphische Darstellungen\nAuch bei diesen Fragestellungen liefern graphische Darstellungen erste Hinweise: Unterschiede bez\u00fcglich der H\u00e4ufigkeitsverteilung eines bestimmten Merkmals erkennt man daran, dass man f\u00fcr jede Stichprobe ein Diagramm anfertigt und diese gemeinsam betrachtet. Bei quantitativen Merkmalen eignen sich die so genannten Box-andWhiskers-Plots besonders gut. Dabei wird jede Stichprobe durch eine rechteckige Box repr\u00e4sentiert, die unten und oben (bzw. links und rechts) vom 1. und 3. Quartil begrenzt wird. Innerhalb der Box wird der Median gekennzeichnet; der Mittelwert kann ebenfalls eingezeichnet werden (er muss nicht notwendigerweise in der Box liegen). Die von der Box ausgehenden Striche (\u201ewhiskers\u201c ist die englische Bezeichnung f\u00fcr Schnurrhaare) zeigen die Lage des Mi\u203a nimums und des Maximums der jeweiligen Stichprobe an (z Abbildung 4.2). Die Plots liefern Hinweise zu Lagema\u00dfen (Mittelwerte, Mediane, Quartile, Maxima und Minima) und Streuungsma\u00dfen (Spannweite, Quartilsabstand). Sie enthalten sogar Informationen bez\u00fcglich der Schiefe: Je weiter der Mittelwert und der Median voneinander entfernt sind, desto schiefer ist die Verteilung. Als Darstellung eignet sich ferner ein abgewandeltes S\u00e4ulendiagramm, bei dem die H\u00f6he einer S\u00e4ule dem jeweiligen Mittelwert entspricht. Dabei kann die Standardabweichung als senkrechter Strich auf eine S\u00e4ule gesetzt \u203a Abbildungen 4.3a und 4.3b). werden (z i Die Striche bei einem Box-and-Whisker-Plot k\u00f6nnen sich auch zwischen z dem 10%- und dem 90%-Perzentil oder dem 1%- und dem 99%-Perzentil erstrecken. Damit vermeidet man, dass die Whiskers wegen eines Ausrei\u00dfers extrem in die L\u00e4nge gezogen werden.\n75 4.5 Der Vergleich mehrerer Stichproben\nAbb. 4.2 Box-and-Whisker-Plots bez\u00fcglich des Merkmals \u201eK\u00f6rpergr\u00f6\u00dfe\u201c (Daten aus Tabelle 2.1)\nAbb. 4.3a K\u00f6rpergr\u00f6\u00dfen m\u00e4nnlicher und weiblicher Studenten. Die y-Achse beginnt bei 0. Diese Darstellung vermittelt den Eindruck, der Unterschied zwischen den beiden Gruppen sei sehr gering.\nAbb. 4.3b Die y-Achse beginnt bei 160. Der Unterschied tritt wesentlich deutlicher hervor als in Abbildung 4.3a.\nMerke Eine graphische Darstellung sollte informieren und nicht manipulieren! Es gibt zahlreiche Tricks, harmlose Effekte durch geschickte Graphiken zu dramatisieren. Wertvolle Hinweise dazu finden sich in [3]. An dieser Stelle sei lediglich erw\u00e4hnt, dass der Wertebereich der Achsen dabei eine \u203a Abbildungen 4.3a und 4.3b). Es ist in jedem Fall wichtige Rolle spielt (z wichtig, sich als Leser nicht nur von Graphiken beeindrucken zu lassen, sondern zus\u00e4tzlich einen Blick auf die Daten zu werfen.\n4\n76 4.5.3\n4\nKapitel 4 \u00b7 Die Beschreibung eines Merkmals\nAnforderungen an die Stichproben\nDie H\u00e4ufigkeiten und die empirischen Kenngr\u00f6\u00dfen haben eine doppelte Funktion. Einerseits beschreiben sie die Charakteristika der Stichprobe; dar\u00fcber hinaus dienen sie als Sch\u00e4tzwerte f\u00fcr die entsprechenden Parameter der Grundgesamtheit. Man kann freilich nicht erwarten, dass die Kenngr\u00f6\u00dfen der Stichprobe und die der Grundgesamtheit identisch sind, oder dass die empirisch ermittelte Verteilungsfunktion mit der Verteilungsfunktion der Grundgesamtheit exakt \u00fcbereinstimmt. Man ist jedoch in jedem Fall daran interessiert, dass die Kenngr\u00f6\u00dfen der Stichproben in brauchbarer Weise die Eigenschaften der Grundgesamtheit beschreiben. Dazu muss die Stichprobe zwei Bedingungen erf\u00fcllen:\n\u0177 Sie muss repr\u00e4sentativ f\u00fcr die jeweilige Grundgesamtheit sein, \u0177 und der Stichprobenumfang muss hinreichend gro\u00df sein. Bei einer sehr kleinen Stichprobe kann es vorkommen, dass einem der Zufall einen Streich spielt und die empirischen Kenngr\u00f6\u00dfen wesentlich beeinflusst, sodass die Eigenschaften der Grundgesamtheit verzerrt wiedergegeben werden. Dies kann bei einer gr\u00f6\u00dferen Stichprobe nicht so leicht passieren; Ausrei\u00dfer werden eher ausgeglichen. Daher leuchtet ein, dass eine gro\u00dfe Stichprobe bessere Sch\u00e4tzungen erm\u00f6glicht als eine kleine. Andererseits bereitet eine umfangreiche Stichprobe in der Medizin oft erhebliche Probleme. Deshalb sollte der Stichprobenumfang nicht gr\u00f6\u00dfer sein als n\u00f6tig. Die optimale Stichprobengr\u00f6\u00dfe muss daher vor der Datenerhebung festgelegt werden. Sie h\u00e4ngt von zahlreichen Faktoren ab, u. a. von den Skalenniveaus der Merkmale, den Kenngr\u00f6\u00dfen, die gesch\u00e4tzt werden sollen und der erforderlichen Genauigkeit der Sch\u00e4tzung. 4.5.4\nAusblick auf die induktive Statistik\nEin Vergleich zwischen mehreren Stichproben wird nach folgendem Prinzip durchgef\u00fchrt: Zun\u00e4chst werden geeignete Kenngr\u00f6\u00dfen, die den interessierenden Effekt beschreiben (etwa relative H\u00e4ufigkeiten, Mittelwerte und Standardabweichungen), f\u00fcr jede Stichprobe getrennt berechnet. Diese Kenngr\u00f6\u00dfen und geeignete graphische Darstellungen erm\u00f6glichen einen direkten Vergleich. Dies ist allerdings nicht ausreichend, um einen Unterschied statistisch abzusichern. In einem zweiten Schritt wird deshalb mittels eines statistischen Tests \u00fcberpr\u00fcft, ob die Unterschiede nur zuf\u00e4llig bedingt oder ob sie \u201esignifikant\u201c sind. In den Kapiteln 10 bis 12 wird ausf\u00fchrlich auf dieses Thema eingegangen.\n5\nDie Beschreibung eines Zusammenhangs 5.1\nDie Methoden der bivariaten Statistik 79\n5.2\nDie Korrelationsanalyse 80\n5.2.1\nDie Punktwolke 80\n5.2.2\nDie Voraussetzungen der Korrelationsanalyse 82\n5.2.3\nDie Kovarianz 82\n5.2.4\nDer Korrelationskoeffizient nach Pearson 84\n5.2.5\nInterpretation eines Korrelationskoeffizienten 85\n5.3\nDie Regressionsanalyse 88\n5.3.1\nHerleitung der Regressionsgeraden 88\n5.3.2\nRegression 1. Art und 2. Art 91\n5.3.3\nDas Bestimmtheitsma\u00df 92\n5.3.4\nNicht-lineare Regression 94\n5.4\nWeitere Techniken 94\n5.4.1\nDer Korrelationskoeffizient nach Spearman 94\n5.4.2\nDer Zusammenhang zwischen einem quantitativen und einem Alternativmerkmal 97\n5.4.3\nDer Zusammenhang zwischen qualitativen Merkmalen 98\n5.4.4\nAusblick auf die induktive Statistik 98\n79\n5\n5.1 Die Methoden der bivariaten Statistik\n5.1\nDie Methoden der bivariaten Statistik\nBei den meisten medizinischen Studien werden mehrere Merkmale erfasst. In diesen F\u00e4llen ist es interessant und sinnvoll, nicht nur einzelne Merkmale zu beschreiben, sondern dar\u00fcber hinaus auch deren Zusammenhang zu untersuchen. Aus Erfahrung oder aufgrund theoretischer \u00dcberlegungen ist oft bekannt, ob ein solcher Zusammenhang besteht. So wei\u00df man beispielsweise, dass das K\u00f6rpergewicht eines Menschen von dessen Gr\u00f6\u00dfe mitbestimmt wird; das Auftreten bestimmter Krankheiten ist im Allgemeinen abh\u00e4ngig von diversen Risikofaktoren, viele auch vom Geschlecht der Patienten. Manche Zusammenh\u00e4nge sind besonders stark ausgepr\u00e4gt (z. B. zwischen dem Geschlecht einer Person und der Erkrankung an H\u00e4mophilie), andere dagegen eher schwach (z. B. zwischen der K\u00f6rpergr\u00f6\u00dfe und dem Gewicht). Aus der Mathematik und der Physik sind Zusammenh\u00e4nge zwischen zwei oder mehreren Gr\u00f6\u00dfen hinl\u00e4nglich bekannt. So besteht beispielsweise zwischen dem Umfang U und dem Radius r eines Kreises die lineare Beziehung U = 2\u03c0 \u22c5 r ; der Weg s, den ein aus dem Ruhezustand frei nach unten fallender K\u00f6rper nach der Zeit t zur\u00fcckgelegt hat, l\u00e4sst sich ausdr\u00fccken durch s = 1 / 2 \u22c5 gt 2 (wobei die Konstante g = 9,81 m / sec2 die Erdbeschleunigung bezeichnet). Diese Art von Zusammenh\u00e4ngen nennt man funktional: Eine Gr\u00f6\u00dfe kann aus einer anderen mittels einer mathematischen Gleichung exakt berechnet werden. Die Zusammenh\u00e4nge in der Medizin sind stochastisch, weil dabei bekanntlich auch der Zufall eine Rolle spielt. Es ist deshalb nicht m\u00f6glich, exakte Aussagen oder Vorhersagen zu treffen. Man kann jedoch angeben, welche Werte \u2013 bei bekannter Auspr\u00e4gung des einen Merkmals \u2013 das andere Merkmal mit gr\u00f6\u00dferer oder kleinerer Wahrscheinlichkeit annehmen wird. Wenn beispielsweise ein gesicherter Zusammenhang zwischen der Dosis eines Medikaments und dessen Wirkung besteht und die Art dieses Zusammenhangs bekannt ist, kann man aufgrund der Dosis einen Effekt absch\u00e4tzen, ehe dieser eingetreten ist. Wenn man von einem Patienten wei\u00df, dass mehrere Risikofaktoren vorliegen, die das Auftreten eines Herzinfarkts beg\u00fcnstigen, wird man eher auf entsprechende Symptome achten als bei Patienten, bei denen diese Risikofaktoren nicht vorhanden sind. So erlaubt die Kenntnis \u00fcber einen Zusammenhang, bereits im Vorfeld geeignete Ma\u00dfnahmen zu treffen und geschickt zu intervenieren.\n80\nKapitel 5 \u00b7 Die Beschreibung eines Zusammenhangs\nDie Aufgaben der bivariaten Statistik bestehen darin, den Zusammenhang zwischen zwei Merkmalen aufzuzeigen und zu beschreiben. Welche Methoden im Einzelfall geeignet sind, h\u00e4ngt von den Skalenniveaus der beiden Merkmale ab:\n\u0177 Der Zusammenhang zwischen zwei quantitativen Merkmalen wird mit Methoden der Korrelationsanalyse und der Regressi\u203a Abschnitte 5.2 und 5.3). onsanalyse untersucht (z \u0177 In Abschnitt 5.4 werden Techniken vorgestellt, die sich eignen, wenn nicht beide Merkmale quantitativ sind.\n5\n5.2\nDie Korrelationsanalyse\n5.2.1\nDie Punktwolke\nUm einen Zusammenhang zwischen zwei quantitativen Merkmalen zu untersuchen, sollte man \u2013 um einen ersten \u00dcberblick zu erhalten \u2013 eine graphische Darstellung anfertigen. Es bietet sich an, jeder Beobachtungseinheit ein Wertepaar ( xi , yi ) zuzuordnen und diese Punkte in ein rechtwinkeliges Koordinatensystem einzutragen. Auf diese Weise erh\u00e4lt man eine Punktwolke (oder Punkteschar). Es h\u00e4ngt weitgehend von sachlogischen \u00dcberlegungen ab, welches Merkmal mit x und welches mit y bezeichnet wird. Wie bei mathematischen Gleichungen \u00fcblich, sollte x das unabh\u00e4ngige und y das abh\u00e4ngige Merkmal sein. Wenn eine Entscheidung diesbez\u00fcglich nicht m\u00f6glich ist, dienen die Buchstaben x und y lediglich zur Unterscheidung der beiden Merkmale. Beispiel 5.1 Wir untersuchen den Zusammenhang zwischen K\u00f6rpergr\u00f6\u00dfe und Gewicht von 48 weiblichen Medizinstudenten anhand der Daten in Tabelle 2.1. Leider hat eine Studentin ihr Gewicht nicht angegeben, sodass nur 47 Wertepaare verf\u00fcgbar sind. Es erscheint sinnvoll, die K\u00f6rpergr\u00f6\u00dfe als das unabh\u00e4ngige und das Gewicht als das abh\u00e4ngige Merkmal aufzufassen. Das K\u00f6rpergewicht kann n\u00e4mlich in gewisser Weise beeinflusst werden, w\u00e4hrend die K\u00f6rpergr\u00f6\u00dfe bei jungen Erwachsenen quasi konstant ist. Somit repr\u00e4sentieren die Werte x i die K\u00f6rpergr\u00f6\u00dfe der Studentinnen und die Werte yi deren Gewicht.\n81\n5\n5.2 Die Korrelationsanalyse\nAbb. 5.1 Punktwolke resultierend aus den Daten der Merkmale K\u00f6rpergr\u00f6\u00dfe und K\u00f6rpergewicht von 47 weiblichen Studenten (Beispiele 5.1 und 5.2)\nAnhand der Punktwolke sind zwei charakteristische Eigenschaften eines Zusammenhangs auf einen Blick erkennbar:\n\u0177 Die St\u00e4rke des Zusammenhangs. Je dichter die Punkte beieinander liegen, desto st\u00e4rker ist der Zusammenhang. Die Punktwolke in Abbildung 5.1 macht deutlich, dass ein Zusammenhang zwischen Gr\u00f6\u00dfe und Gewicht zwar besteht, dass dieser jedoch von anderen Faktoren \u00fcberlagert wird. \u0177 Die Art des Zusammenhangs. Die Art wird durch eine mathematische Funktion angegeben, die den Zusammenhang optimal beschreibt. Es ist Aufgabe der Regressionsanalyse, diese Funktion zu finden. Vorausgesetzt werden metrische Skalenniveaus bei beiden Merkmalen. Wenn \u2013 wie in unserem Beispiel \u2013 der Zusammenhang durch eine Gerade charakterisiert werden kann, spricht man von einem linearen Zusammenhang; dieser wird \u203a Abschnitt 5.3). durch eine Regressionsgerade beschrieben (z Die positive Steigung der Regressionsgeraden besagt, dass zwischen K\u00f6rpergr\u00f6\u00dfe und K\u00f6rpergewicht ein gleichsinniger Zusammenhang besteht \u2013 das hei\u00dft, gro\u00dfe Studentinnen haben tendenziell ein h\u00f6heres Gewicht, w\u00e4hrend kleine Studentinnen eher weniger wiegen. Auch der Zusammenhang zwischen Pulsfrequenz und K\u00f6rpertemperatur ist gleichsinnig. Ein Beispiel f\u00fcr einen gegensinnigen Zusammenhang findet sich in der Anwendung volatiler An\u00e4sthetika. Je h\u00f6her die inspiratorische Konzentration des An\u00e4sthetikums (z. B. Isofluran) gew\u00e4hlt wird, desto niedriger wird der arterielle Blutdruck (und umgekehrt).\n82 5.2.2\nKapitel 5 \u00b7 Die Beschreibung eines Zusammenhangs\nDie Voraussetzungen der Korrelationsanalyse\nMittels der Korrelationsanalyse wird der Korrelationskoeffizient nach Pearson berechnet, der geeignet ist, die St\u00e4rke eines Zu\u203a Abschnitt 5.2.4). Meist schlie\u00dft sammenhangs zu quantifizieren (z \u203a Absich daran die Berechnung einer Regressionsgeraden an (z schnitt 5.3). Zun\u00e4chst sollte jedoch \u00fcberpr\u00fcft werden, ob die Voraussetzungen f\u00fcr diese Methoden erf\u00fcllt sind. Es muss gelten:\n\u0177 Beide Merkmale x und y sind quantitativ. \u0177 Der Zusammenhang ist ann\u00e4hernd linear. \u0177 Die Beobachtungseinheiten sind unabh\u00e4ngig voneinander.\n5\nOb der Zusammenhang als linear angesehen werden kann, sollte vorab durch sachlogische \u00dcberlegungen gekl\u00e4rt werden. Hilfreich \u203a Abzur Beurteilung dieser Frage ist au\u00dferdem die Punktwolke (z schnitt 5.2.1). Sie muss so geartet sein, dass sich mittendurch eine Gerade legen l\u00e4sst, um die die Punkte ellipsenf\u00f6rmig liegen. Die Unabh\u00e4ngigkeit der Beobachtungseinheiten kann ebenfalls durch logische \u00dcberlegungen \u00fcberpr\u00fcft werden. Bei Abh\u00e4ngigkeit der Merkmalspaare k\u00f6nnte ein st\u00e4rkerer Zusammenhang als tats\u00e4chlich vorhanden vorget\u00e4uscht werden. In unserem Beispiel ist diese Voraussetzung erf\u00fcllt. Die Daten w\u00e4ren jedoch nicht unabh\u00e4ngig, wenn sich unter den Studenten Geschwister bef\u00e4nden oder wenn die Daten einzelner Studenten mehrfach erfasst worden w\u00e4ren. Wenn die empirischen Ma\u00dfzahlen der Stichprobe als Sch\u00e4tzer f\u00fcr die entsprechenden Parameter der Grundgesamtheit dienen, m\u00fcssen weitere Voraussetzungen \u00fcberpr\u00fcft werden. Dazu sollten die \u203a Abschnitte 9.3.4 beiden Merkmale bivariat normalverteilt sein (z und 11.1.6). 5.2.3\nDie Kovarianz\nDer Korrelationskoeffizient und die Parameter der Regressionsgeraden bauen auf der so genannten Kovarianz auf. Sie wird mit sxy bezeichnet und \u2013 basierend auf den Mittelwerten x und y \u2013 folgenderma\u00dfen berechnet: n\nn\n\u00a6 ( xi \u2212 x ) \u22c5 ( yi \u2212 y )\ns xy =\ni =1\nn \u22121\n\u00a6 xi y i \u2212 n \u22c5 x \u22c5 y\n=\ni =1\nn \u22121\n(5.1)\n83\n5\n5.2 Die Korrelationsanalyse\nDie Formel (5.1) \u00e4hnelt der Formel (4.6), mit der die Varianz eines Merkmals berechnet wird. W\u00e4hrend die Varianz das durchschnittliche Abweichungsquadrat ( xi \u2212 x )2 quantifiziert, erfasst die Kovarianz das durchschnittliche Produkt der Abweichungen ( xi \u2212 x ) und ( yi \u2212 y ) . Die Division durch n \u2212 1 gew\u00e4hrleistet, dass man \u2013 analog zur Varianz \u2013 einen optimalen Sch\u00e4tzwert f\u00fcr die Kovarianz der Grundgesamtheit erh\u00e4lt. Die Kovarianz ist ein Ma\u00df f\u00fcr das \u201eMiteinander-Variieren\u201c zweier quantitativer Merkmale. Sie kann sowohl positive als auch negative Werte annehmen: \u2022 Eine positive Kovarianz sxy > 0 impliziert einen gleichsinnigen Zu sammenhang. Wenn beide Messwerte einer Beobachtungseinheit gr\u00f6\u00dfer oder beide kleiner sind als der jeweilige Mittelwert, haben die Terme ( xi \u2212 x ) und ( yi \u2212 y ) dasselbe Vorzeichen, sodass deren \u203a Abbildung 5.2a). Produkt positiv ist (z \u2022 Eine negative Kovarianz sxy < 0 ergibt sich, wenn sich die beiden Merkmale gegensinnig verhalten. Dann haben die Abweichungen ( xi \u2212 x ) und ( yi \u2212 y ) unterschiedliche Vorzeichen, sodass deren Pro\u203a Abbildung 5.2b). dukt negativ ist (z \u2022 Eine Kovarianz nahe bei 0 signalisiert, dass nahe beieinander lie gende x-Werte sowohl mit positiven als auch mit negativen Abweichungen ( yi \u2212 y ) korrelieren, sodass sich die Produkte ( xi \u2212 x ) \u22c5 ( yi \u2212 y ) ausgleichen und in ihrer Summe einen Wert nahe \u203a Abbildung 5.2c). Falls sxy \u2248 0 , bedeutet dies jebei 0 annehmen (z doch keineswegs, dass generell kein Zusammenhang besteht. Dies zeigt lediglich, dass kein linearer Zusammenhang nachzuweisen ist.\nAbb. 5.2a gleichsinniger Abb. 5.2b gegensinniger Zusammenhang, Zusammenhang, posinegative Kovarianz tive Kovarianz\nAbb. 5.2c kein linearer Zusammenhang, Kovarianz \u2248 0\n84\nKapitel 5 \u00b7 Die Beschreibung eines Zusammenhangs\nDie Einheit der Kovarianz ist das Produkt der Einheiten der beiden zugrunde liegenden Merkmale. Sowohl der Zahlenwert als auch die Einheit der Kovarianz sind abh\u00e4ngig von deren Ma\u00dfst\u00e4ben (die mitunter recht willk\u00fcrlich gew\u00e4hlt sind) und deshalb schwer zu interpretieren. Die Kovarianz ist \u2013 f\u00fcr sich allein betrachtet \u2013 wenig informativ zur Beurteilung der Frage, ob ein Zusammenhang besonders eng oder eher lose ist. Sie informiert lediglich anhand des Vorzeichens dar\u00fcber, ob der Zusammenhang gleichsinnig oder gegensinnig ist.\n5\n5.2.4\nDer Korrelationskoeffizient nach Pearson\nDer Pearson\u2019sche Korrelationskoeffizient (auch Produkt-MomentKorrelationskoeffizient genannt) stellt ein normiertes Ma\u00df zur Quantifizierung eines linearen Zusammenhangs dar. Man erh\u00e4lt diesen Koeffizienten, indem man die Kovarianz s xy durch die beiden Standardabweichungen sx und s y dividiert: r=\ns xy sx \u22c5 s y\n(5.2)\nDer Korrelationskoeffizient kann nur Werte zwischen -1 und +1 annehmen; er ist dimensionslos. Der Buchstabe r weist darauf hin, dass die Korrelations- und die Regressionsanalyse eng miteinander verbunden sind. Das Vorzeichen von r ist identisch mit dem Vorzeichen der Kovarianz sxy : Ein positives Vorzeichen steht demnach f\u00fcr einen gleichsinnigen, ein negatives Vorzeichen f\u00fcr einen gegensinnigen Zusammenhang. Beispiel 5.2 Aus den Daten der K\u00f6rpergr\u00f6\u00dfe und des K\u00f6rpergewichts von 47 Studentinnen ergibt sich eine Kovarianz von 36,856 cm \u00b7 kg. Wenn man nun durch die Standardabweichungen s x = 6,63 cm und s y = 9,16 kg dividiert, erh\u00e4lt man den Pearson\u2019schen Korrelationskoeffizienten r = 0,607 . Die St\u00e4rke des Zusammenhangs ist also mittelm\u00e4\u00dfig. Einerseits ist r deutlich gr\u00f6\u00dfer als 0 \u2013 daher besteht durchaus ein Zusammenhang zwischen den beiden Merkmalen. Andererseits ist r kleiner als 1 \u2013 weil das Gewicht nicht nur von der Gr\u00f6\u00dfe, sondern von zahlreichen weiteren Faktoren abh\u00e4ngt.\n5\n85 5.2 Die Korrelationsanalyse\nDer Betrag von r hat folgende Bedeutung:\n\u0177 Je n\u00e4her r bei 0 liegt, desto schw\u00e4cher ist der Zusammenhang und desto weiter streut die Punktwolke um die Gerade.\n\u0177 Je n\u00e4her der Betrag von r bei 1 liegt, desto st\u00e4rker ist der Zusammenhang und desto dichter liegen die Punkte ( xi , yi ) an der Regressionsgeraden. \u0177 Die Extremf\u00e4lle r = 1 und r = \u22121 ergeben sich bei einem funktionalen Zusammenhang, der durch eine lineare Gleichung der Form y = a + bx exakt beschrieben werden kann. Alle Punkte ( xi , yi ) liegen dann auf der Regressionsgeraden. Mathematische Herleitung des Korrelationskoeffizineten nach Pearson Es ist offenkundig, dass die Kovarianz sxy genau dann maximal wird, wenn der Zusammenhang funktional ist und durch eine lineare Gleichung y = a + bx exakt beschrieben werden kann. Dann erh\u00e4lt man nach den Definitionen der Kovarianz und der Varianz in (5.1) und (4.6): n\n\u00a6x y i\ni\n\u2212 nxy\ni =1\nn\n\u00a6 x (a + bx ) \u2212 nx (a + bx ) i\n= i =1 n \u22121 F\u00fcr die Varianz s y 2 ergibt sich: s xy =\nn\nsy2 =\n\u00a6( y\ni\n\u2212 y )2\nn\ni\nn \u22121\n=\nb( \u00a6 xi2 \u2212 nx 2 ) i =1\nn \u22121\n= bsx 2\nn\nb2 \u00a6 ( xi \u2212 x )2\n= i =1 = b2 sx 2 n \u22121 n \u22121 F\u00fcr positives b ist s y = bsx und s xy = bs x 2 = sx \u22c5 s y . F\u00fcr negatives b folgt anai =1\nlog: s y = \u2212 bsx und sxy = \u2212 sx \u22c5 s y . Da es sich hierbei um die beiden Extremf\u00e4lle handelt, folgt f\u00fcr die Kovarianz: \u2212 sx \u22c5 s y \u2264 sxy \u2264 sx \u22c5 s y . Daraus ergibt sich f\u00fcr sxy den Korrelationskoeffizienten r = : \u22121 \u2264 r \u2264 1 . sx \u22c5 s y\n5.2.5\nInterpretation eines Korrelationskoeffizienten\nH\u00e4ufig wird ein Korrelationskoeffizient falsch interpretiert, oder seine Bedeutung wird \u00fcbersch\u00e4tzt. Ein empirischer Koeffizient, dessen Betrag gr\u00f6\u00dfer als 0 ist, besagt lediglich, dass ein Zusammenhang aufgrund der Stichprobe nicht auszuschlie\u00dfen ist. Er besagt jedoch nichts dar\u00fcber, worauf dieser Zusammenhang zur\u00fcckzuf\u00fchren ist und welche Schlussfolgerungen gezogen werden k\u00f6nnen. Mittels einer geeigneten Statistiksoftware ist die Berechnung eines Korrelationskoeffizienten auch bei umfangreichem Datenmaterial problemlos m\u00f6glich. Die Software berechnet diese Ma\u00dfzahl je-\n86\nKapitel 5 \u00b7 Die Beschreibung eines Zusammenhangs\ndoch auch dann, wenn die Voraussetzungen nicht erf\u00fcllt sind; sie \u00fcberpr\u00fcft auch nicht, ob sachliche Gr\u00fcnde f\u00fcr den Zusammenhang sprechen. So kommt es, dass hin und wieder Zusammenh\u00e4nge beschrieben werden, die zwar formal korrekt, aber sachlogisch in keiner Weise nachvollziehbar sind. Es gibt zahlreiche Beispiele f\u00fcr derartige Schein- oder Nonsens-Korrelationen:\n5\n\u2022 Formale Korrelation. Sie entsteht beispielsweise dann, wenn zwei relative Anteile miteinander in Beziehung gesetzt werden, die sich zu 100 % addieren. Wenn etwa die Merkmale x und y die relativen Anteile von Eiwei\u00df und Fett in Nahrungsmitteln darstellen (so dass die Summe 100 % betr\u00e4gt), ergibt sich rein mathematisch ein funktionaler Zusammenhang mit einem Korrelationskoeffizienten von -1 (Abweichungen w\u00e4ren allein durch Messfehler zu erkl\u00e4ren). \u2022 Selektionskorrelation. In der Stichprobe muss die gesamte Vari ationsbreite der zu untersuchenden Merkmale repr\u00e4sentiert sein. Wenn man jedoch bei der Wahl der Beobachtungseinheiten selektiert, ergibt sich eine Korrelation, die nicht die Verh\u00e4ltnisse in der Grundgesamtheit widerspiegelt. Ein Beispiel hierf\u00fcr ist gegeben, wenn zur Beurteilung der Frage, ob das Geburtsgewicht in Beziehung zum Zigarettenkonsum der Mutter steht, nur Risikopatientinnen einer Spezialklinik herangezogen werden. Eine Selektion wird auch dann vorgenommen, wenn einzelne Werte aus der Stichprobe eliminiert werden, um einen vermeintlich starken Zusammenhang k\u00fcnstlich zu erzeugen (selbstverst\u00e4ndlich ist dieses Vorgehen h\u00f6chst unwissenschaftlich). \u2022 Korrelation durch Ausrei\u00dfer. Ein Ausrei\u00dfer \u2013 das ist ein Punkt, \u203a Abbildung 5.3a) der sehr weit vom Punkteschwarm entfernt liegt (z \u2013 kann mitunter einen betragsm\u00e4\u00dfig hohen Korrelationskoeffizienten verursachen. Die Punktwolke l\u00e4sst Ausrei\u00dfer auf einen Blick er\u203a Abschnitt 2.4). kennen (z \u2022 Inhomogenit\u00e4tskorrelation. Sie ergibt sich, wenn f\u00fcr zwei inho mogene Gruppen ein gemeinsamer Korrelationskoeffizient berechnet wird. Die graphische Darstellung besteht aus zwei Punktwolken, die \u203a Abbildung 5.3b), und die \u2013 sich nicht oder nur wenig \u00fcberlappen (z isoliert betrachtet \u2013 keinen Zusammenhang offenbaren. Wenn beispielsweise die Schuhgr\u00f6\u00dfen und die Geh\u00e4lter der Angestellten eines Klinikums miteinander verglichen werden, ist ein Korrelationskoeffizient zu erwarten, der deutlich gr\u00f6\u00dfer als 0 ist. Er kommt dadurch zustande, dass M\u00e4nner im Allgemeinen gr\u00f6\u00dfere F\u00fc\u00dfe als Frauen haben und gleichzeitig Positionen mit h\u00f6heren Einkommen innehaben.\n87\n5\n5.2 Die Korrelationsanalyse\nAbb. 5.3a Korrelation, die durch einen Ausrei\u00dfer verursacht ist\nAbb. 5.3b Inhomogenit\u00e4tsKorrelation\n\u2022 Gemeinsamkeitskorrelation. Wenn zwei Merkmale durch ein drittes beeinflusst werden, liegt eine Gemeinsamkeitskorrelation vor. So ergibt sich beispielsweise rechnerisch eine positive Korrelation, wenn man die Entwicklung des Storchenbestands in Deutschland mit der Entwicklung der Geburtenrate vergleicht \u2013 obwohl allgemein bekannt sein d\u00fcrfte, dass diese beiden Gr\u00f6\u00dfen nicht kausal zusammenh\u00e4ngen. Die Korrelation wird durch eine dritte Gr\u00f6\u00dfe \u2013 n\u00e4mlich die allgemeine zeitliche Tendenz \u2013 k\u00fcnstlich erzeugt. Sie beeinflusst gleicherma\u00dfen den Storchenbestand und die Geburtenrate und t\u00e4uscht somit eine typische Nonsens-Korrelation vor. Diese Ausf\u00fchrungen belegen, dass es in keinem Fall ausreichend ist, einen Korrelationskoeffizienten rechnerisch zu bestimmen und diesen Wert dann kritik- und kommentarlos als Ma\u00df f\u00fcr die St\u00e4rke eines Zusammenhangs anzugeben. Auf zwei weit verbreitete Fehlinterpretationen sei an dieser Stelle hingewiesen: ! Ein betragsm\u00e4\u00dfig hoher Korrelationskoeffizient allein ist kein Beleg f\u00fcr z\neine kausale Beziehung, sondern allenfalls als Hinweis zu werten. Er besagt jedoch nichts dar\u00fcber, welches der beiden Merkmale das andere kausal bedingt, ob die Merkmale wechselseitig aufeinander einwirken, oder ob m\u00f6glicherweise beide Merkmale durch ein drittes beeinflusst sind. ! Eine andere Fehlinterpretation wird vorgenommen, wenn beim Verz gleich zweier Messverfahren ein hoher Korrelationskoeffizient als Beweis daf\u00fcr gewertet wird, dass die Messwerte beider Verfahren \u00fcbereinstimmen. Um dies zu beurteilen, sollten zus\u00e4tzlich der Mittelwert der Differenzen und deren Standardabweichung untersucht werden (Bland-Altman-Analyse). Als graphische Darstellung eignet sich der Bland-AltmanPlot, bei dem die Mittelwerte der einzelnen Messungen ( xi + yi ) / 2 gegen die Differenzen ( xi \u2212 yi ) aufgetragen werden.\n88\n5\nKapitel 5 \u00b7 Die Beschreibung eines Zusammenhangs\nMerke Um Fehlinterpretationen zu vermeiden, empfiehlt sich bei der Berechnung eines Korrelationskoeffizienten folgendes Vorgehen: \u0177 Theoretische Herleitung. Man sollte zun\u00e4chst dar\u00fcber nachdenken, ob und wie der zu quantifizierende Zusammenhang begr\u00fcndet werden kann. Das Erarbeiten eines theoretischen Hintergrundes tr\u00e4gt wesentlich dazu bei, Nonsens-Korrelationen zu vermeiden. \u0177 Erstellen der Punktwolke. Die graphische Darstellung ist hilfreich bei der Beurteilung, ob der Zusammenhang linear ist. Au\u00dferdem deckt sie Ausrei\u00dfer und inhomogene Gruppen auf. \u0177 \u00dcberpr\u00fcfen der Voraussetzungen. Dies ist insbesondere dann wichtig, wenn der empirische Korrelationskoeffizient den Zusammenhang \u203a Abschnitte 9.3.4, 11.1.6). in der Grundgesamtheit sch\u00e4tzen soll (z \u0177 Interpretation. Nachdem ein Zusammenhang zwischen zwei Merkmalen x und y theoretisch hergeleitet und statistisch abgesichert ist, k\u00f6nnen vorsichtig Schlussfolgerungen gezogen werden. Dazu bedarf es \u00fcberwiegend medizinisch-fachlicher \u00dcberlegungen. Folgende M\u00f6glichkeiten sind zu pr\u00fcfen: x beeinflusst y. y beeinflusst x. x und y bedingen sich gegenseitig. Beide Merkmale werden durch eine dritte Gr\u00f6\u00dfe beeinflusst. Der Zusammenhang kam zuf\u00e4llig zustande.\n5.3\nDie Regressionsanalyse\n5.3.1\nHerleitung der Regressionsgeraden\nDie Regressionsanalyse ist ein flexibles und h\u00e4ufig eingesetztes Verfahren, das in der Medizin u. a. f\u00fcr Ursachen- und Wirkungsanalysen und Zeitreihenanalysen angewandt wird. Ihre Aufgabe besteht darin, eine mathematische Gleichung herzuleiten, welche die Art des Zusammenhangs zwischen zwei quantitativen Merkmalen optimal beschreibt. Anhand dieser Gleichung l\u00e4sst sich dann aus einem bekannten Wert f\u00fcr das x-Merkmal ein entsprechender Wert f\u00fcr das y-Merkmal prognostizieren. i Das Wort \u201eRegression\u201c geht zur\u00fcck auf den englischen Naturforscher z Francis Galton (1822-1911), ein Vetter von Charles Darwin, der die Beziehung zwischen den K\u00f6rpergr\u00f6\u00dfen von V\u00e4tern und ihren S\u00f6hnen untersuchte. Er fand heraus, dass die S\u00f6hne gro\u00dfer V\u00e4ter und die S\u00f6hne\n89\n5\n5.3 Die Regressionsanalyse\nkleiner V\u00e4ter eine K\u00f6rpergr\u00f6\u00dfe haben, die weniger vom Durchschnittswert abweicht als die Gr\u00f6\u00dfe der V\u00e4ter. Dieses Ph\u00e4nomen bezeichnete er als \u201eRegression\u201c (R\u00fcckschritt zum Mittelwert). Galtons Freund Karl Pearson hat in 1.078 Familien die Gr\u00f6\u00dfen von V\u00e4tern und S\u00f6hnen verglichen und seine Ergebnisse zusammen mit dem nach ihm benannten Korrelationskoeffizienten im Jahre 1903 ver\u00f6ffentlicht. Im Laufe der Zeit wurde der Begriff \u201eRegression\u201c allgemein verwendet, um den stochastischen Zusammenhang zwischen zwei oder mehr Merkmalen zu beschreiben.\nAufgrund sachlogischer \u00dcberlegungen sollte vorab gekl\u00e4rt werden, welches der beiden Merkmale sinnvollerweise als das unabh\u00e4ngige x-Merkmal bzw. als das abh\u00e4ngige y-Merkmal bezeichnet wird. F\u00fcr praktische Zwecke ist es nahe liegend, dasjenige Merkmal, das einfacher, billiger oder fr\u00fcher erfasst werden kann, als das x-Merkmal anzusehen. Wenn diesbez\u00fcglich keine Entscheidung m\u00f6glich ist, ist die Herleitung einer Regressionsgleichung nicht sinnvoll. Man sollte sich in diesem Fall darauf beschr\u00e4nken, den Zusammenhang durch einen Korrelationskoeffizienten zu beschreiben. Die einfachste Form der Regressionsanalyse ist die Beschreibung des Zusammenhangs durch eine Gerade. Dies ist erlaubt, nachdem man sich davon \u00fcberzeugt hat, dass der zu beschreibende Zusam\u203a menhang ann\u00e4hernd linear ist. Ein Blick auf den Punkteschwarm (z Abbildung 5.1) macht deutlich, dass es bei stochastischen Zusammenh\u00e4ngen keine Gerade geben kann, auf der alle Punkte liegen. Dies ist dadurch begr\u00fcndet, dass das y-Merkmal nicht nur vom xMerkmal, sondern auch von anderen Faktoren beeinflusst wird, die in der Geradengleichung nicht ber\u00fccksichtigt sind. Die Aufgabe der Regressionsanalyse besteht nun darin, eine Gerade zu finden, die die Punktwolke optimal repr\u00e4sentiert \u2013 die so genannte Regressionsgerade. Diese ist so konstruiert, dass das durchschnittliche Abstandsquadrat der Beobachtungspunkte von der Geraden minimal ist. Sie ist eindeutig bestimmt durch die Steigung b=\ns xy sx 2\n(5.3)\nund den y-Achsenabschnitt a = y \u2212 bx\n(5.4)\nDabei sind s xy die in Abschnitt 5.2.3 eingef\u00fchrte Kovarianz und s x 2 die Varianz der x-Werte. Der Parameter b wird als Regressionskoeffizient bezeichnet. Aus (5.3) geht hervor, dass sich der Variationsbe-\n90\nKapitel 5 \u00b7 Die Beschreibung eines Zusammenhangs\nreich von b generell zwischen -\u221e und +\u221e erstreckt. Ein Vergleich mit der Formel (5.2) auf Seite 84 zeigt, dass die Vorzeichen von b und dem Korrelationskoeffizienten r \u00fcbereinstimmen. Das bedeutet: Bei einem gleichsinnigen Zusammenhang ist die Steigung der Regressionsgeraden positiv, bei einem gegensinnigen Zusammenhang ist sie negativ. Mit den Parametern a und b l\u00e4sst sich bei Vorliegen eines Wertes xi nach folgender Formel ein Wert y\u02c6 i f\u00fcr das abh\u00e4ngige Merkmal prognostizieren: s xy\ny\u02c6 i = a + bxi = y +\n5\ns x2\n( xi \u2212 x )\n(5.5)\nMathematische Herleitung der Regressionsgeraden Von der Regressionsgeraden y = a + bx erwartet man, dass sie die y-Werte\noptimal prognostiziert; das hei\u00dft die Abweichungen ( yi \u2212 y\u02c6 i ) sollten m\u00f6glichst gering sein. Es gilt also, passende Werte f\u00fcr a und b zu finden, die eine Gerade mit dieser Eigenschaft definieren. Dazu minimiert man nach der Methode der kleinsten Quadrate die Summe der Abstandsquadrate: n\n\u00a6(y\nn\ni\ni =1\n\u2212 y\u02c6 i )2 = \u00a6 ( yi \u2212 a \u2212 bxi ) 2 = f ( a, b) . i =1\nDas Minimum dieser Funktion erh\u00e4lt man, indem man die Ableitungen (nach der Kettenregel der Differentialrechnung) bildet und gleich 0 setzt: n df = \u22122\u00a6 ( yi \u2212 a \u2212 bxi ) = \u22122n ( y \u2212 a \u2212 bx ) = 0 und da i =1 n n n df = \u22122\u00a6 xi ( yi \u2212 a \u2212 bxi ) = 2b\u00a6 xi 2 \u2212 2\u00a6 xi yi + 2anx = 0 db i =1 i =1 i =1 Aus der ersten Gleichung folgt: a = y \u2212 bx . Wenn man diesen Term in die zweite Gleichung einsetzt und nach b aufl\u00f6st, ergibt sich:\nn\n\u00a6x y i\nb=\ni =1 n\n\u00a6x\ni\ni =1\n2\ni\n\u2212 nxy = \u2212 nx 2\nsxy sx 2\n.\nn d2 f d2 f Da f\u00fcr die zweiten Ableitungen gilt: = 2\u00a6 xi 2 > 0 , = 2n > 0 und 2 2 da i =1 handelt es sich bei den berechneten Ausdr\u00fccken f\u00fcr a und db b um Minima der Funktion f(a,b) und damit um optimale Parameter f\u00fcr die Regressionsgerade. Mit einem statistischen Test l\u00e4sst sich \u00fcberpr\u00fcfen, ob der beschriebene Zusammenhang wirklich existiert und ob anzunehmen ist, dass er rein zuf\u00e4llig \u203a Abschnitt 11.1.6). zustande kam (z\n5\n91 5.3 Die Regressionsanalyse\nDer Mittelwert der berechneten y i -Werte ist gleich dem Mittelwert der beobachteten yi -Werte, also y . Der Punkt ( x , y ) liegt auf der Regressionsgeraden; er ist der Schwerpunkt der Punktwolke. Wenn der Zusammenhang funktional ist ( r = \u00b11 ), liegen alle Punkte auf der Regressionsgeraden. Beispiel 5.3 Bez\u00fcglich des Zusammenhangs zwischen K\u00f6rpergr\u00f6\u00dfe und Gewicht von 47 Studentinnen ergibt sich folgende Regressionsgerade: y\u02c6i = \u221281,111 + 0,839 xi . F\u00fcr eine 170 cm gro\u00dfe Studentin w\u00fcrde man ein Gewicht von 61,5 kg prognostizieren. Aus dieser Gleichung geht auch hervor, dass das Gewicht um durchschnittlich 0,839 kg pro cm K\u00f6rpergr\u00f6\u00dfe zunimmt. Der y-Achsenabschnitt -81,111 hat keine praktische Bedeutung. ! Es ist wichtig zu beachten, dass eine Extrapolation \u00fcber den Beobachz\ntungsbereich hinaus problematisch ist. In unserem Beispiel wurden bei der Berechnung der Regressionsgeraden x-Werte zwischen 156 cm und 180 cm zugrunde gelegt. Wenn man mit dieser Geraden das Gewicht eines 90 cm gro\u00dfen Kindes bestimmen w\u00fcrde, erhielte man -5,6 kg. Dies zeigt, dass eine Extrapolation unsinnige Werte liefern kann. Wenn man trotzdem extrapoliert, sollte man dies mit der gebotenen Vorsicht tun.\nWenn das y-Merkmal von mehreren x-Variablen bestimmt wird, verwendet man die multiple Regressionsanalyse. Die Regressionsgleichung enth\u00e4lt dann mehrere x-Variablen, die die y-Zielgr\u00f6\u00dfe beeinflussen, und entsprechend viele Regressionskoeffizienten. Ausf\u00fchrliche Informationen findet man in [2], [4] und [10]. 5.3.2\nRegression 1. Art und 2. Art\nBei der Regressionsanalyse unterscheidet man nach der Eigenschaft der x-Variablen zwischen Regression 1. Art und Regression 2. Art. Bei der Regression 1. Art sind die Auspr\u00e4gungen der x-Variablen explizit vorgeben. Zu jedem x-Wert existieren dann mehrere, zuf\u00e4llig bedingte y-Werte. Als Beispiel sei der Zusammenhang zwischen der Dosis eines Medikaments und dessen Wirkung genannt. Wenn \u2013 wie beim Zusammenhang zwischen K\u00f6rpergr\u00f6\u00dfe und Gewicht \u2013\n\u2022 \u2022 \u2022 \u2022\u2022 \u2022\n\u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022\nAbb. 5.4 Regression 1. Art\n\u2022 \u2022 \u2022\u2022 \u2022 \u2022 \u2022\n\u2022\u2022 \u2022 \u2022 \u2022 \u2022\n92\nKapitel 5 \u00b7 Die Beschreibung eines Zusammenhangs\nbeide Merkmale Zufallsvariable darstellen, spricht man von der Regression 2. Art. In beiden F\u00e4llen ist die Bestimmung der Regressionsgleichung n\u00fctzlich, um die Art des Zusammenhangs zu beschreiben. Der Korrelationskoeffizient nach Pearson als Ma\u00dfe der St\u00e4rke des Zusammenhangs ist allerdings nur sinnvoll bei der Regression 2. Art. 5.3.3\n5\nDas Bestimmtheitsma\u00df\nEin Problem der Regressionsanalyse liegt in der Verl\u00e4sslichkeit der Sch\u00e4tzung. Meistens wird der zu einem Messwert xi geh\u00f6rende Wert y i , der durch die Gleichung der Regressionsgeraden prognostiziert wird, vom Beobachtungswert yi abweichen. Ein einfaches Ma\u00df f\u00fcr diese Abweichung ist das Residuum: ei = yi \u2212 y\u02c6 i\n(5.6)\nUm die Sch\u00e4tzung durch die Regressionsgerade generell zu beurteilen, bedarf es eines Ma\u00dfes, das alle Residuen ber\u00fccksichtigt. Da sich die Residuen gegenseitig ausgleichen, sodass deren Summe gleich 0 ist, legt man die Summe der Abweichungsquadrate ei 2 zugrunde. Diese Summe ist ein Teil des Z\u00e4hlers der Varianz der yi -Werte, die sich aus zwei Komponenten zusammensetzt: n\nn\nn\ni =1\ni =1\ni =1\n\u00a6 ( yi \u2212 y ) 2 =\u00a6 ( yi \u2212 y\u02c6 i ) 2 +\u00a6 ( y\u02c6 i \u2212 y ) 2\n(5.7)\nDer Einfachheit halber sind in dieser Gleichung die Nenner ( n \u2212 1) weggelassen. Der Term auf der linken Seite des Gleichheitszeichens steht f\u00fcr die Gesamtvarianz der Beobachtungswerte yi . Der erste Summand rechts vom Gleichheitszeichen bezieht sich auf die Varianz der Residuen ei (mit dem Mittelwert 0), der zweite auf die Varianz der mit der Regressionsgleichung berechneten Werte y i . Der zweite Teil der Gesamtvarianz wird auch als die erkl\u00e4rte Varianz bezeichnet (diese l\u00e4sst sich durch die Gleichung der Regressionsgeraden erkl\u00e4ren). Der erste Summand, n\u00e4mlich die Residualvarianz, ist dagegen auf die Abweichung der Beobachtungswerte von der Regressionsgeraden zur\u00fcckzuf\u00fchren. Gleichung (5.7) l\u00e4sst sich also verbal folgenderma\u00dfen formulieren: Gesamtvarianz = Residualvarianz + erkl\u00e4rte Varianz\n5\n93 5.3 Die Regressionsanalyse\nEs ist offensichtlich, dass die Sch\u00e4tzung durch die Regressionsgerade dann besonders gut ist, wenn der Anteil der Residualvarianz m\u00f6glichst klein und die erkl\u00e4rte Varianz entsprechend gro\u00df ist. Andererseits gilt: Je kleiner die erkl\u00e4rte Varianz ist, desto schlechter k\u00f6nnen die y-Werte \u00fcber das Regressionsmodell gesch\u00e4tzt werden. Aus diesen \u00dcberlegungen ergibt sich, dass die erkl\u00e4rte Varianz im Verh\u00e4ltnis zur Gesamtvarianz ein geeignetes Ma\u00df f\u00fcr die G\u00fcte des Modells darstellt. Es l\u00e4sst sich nachweisen, dass dieser Quotient mit r 2 \u00fcbereinstimmt: n\nr2 =\ns y\u02c6\n2\nsy\n2\n=\n\u00a6 ( y\u02c6 i \u2212 y ) 2 i =1 n\nerkl\u00e4rte Varianz Gesamtvarianz\n=\n\u00a6 ( yi \u2212 y ) 2\n(5.8)\ni =1\nMan bezeichnet r 2 als das Bestimmtheitsma\u00df oder den Determinationskoeffizienten. Der Wertebereich des Bestimmtheitsma\u00dfes r 2 erstreckt sich zwischen 0 und 1. Im Extremfall r 2 = 1 ist die Residualvarianz gleich 0. Mathematische Herleitung des Bestimmtheitsma\u00dfes Die Gleichung (5.7) l\u00e4sst sich durch elementare Umformungen unter Zuhilfenahme der Gleichungen (5.3) bis (5.5) nachweisen. Ein geeignetes Ma\u00df f\u00fcr die G\u00fcte der Sch\u00e4tzung ist die Varianz der berechneten yi -Werte (das ist die durch das Regressionsmodell erkl\u00e4rte Varianz) dividiert durch die Gesamtvarianz. F\u00fcr die erkl\u00e4rte Varianz erhalten wir: n\ns 2y\u02c6 =\n\u00a6 ( y\u02c6 i =1\ni\nn\n\u2212 y )2\nn \u22121\n=\n\u00a6 (bx\ni\ni =1\n\u2212 bx ) 2 = b 2 sx2\nn \u22121\nDaraus folgt f\u00fcr die G\u00fcte der Sch\u00e4tzung: Mit b =\nsxy sx\n2\n(Formel 5.3) erhalten wir:\ns y 2 sy\ns y 2 sy\n2\n2\n=\n=\nb2sx 2 . sy 2 sxy 2\nsx 2 \u22c5 s y 2\n= r 2 (nach Formel 5.2).\nBeispiel 5.4 Aus r = 0,607 (Beispiel 5.2) ergibt sich f\u00fcr den Determinationskoeffizienten: r 2 = 0,368 . Diese Zahl besagt, dass 37 % der Varianz des Gewichts durch das Modell der Regressionsgeraden (also durch die K\u00f6rpergr\u00f6\u00dfe) bedingt sind. 63 % sind durch andere, nicht im Modell ber\u00fccksichtigte Einfl\u00fcsse verursacht.\n94 5.3.4\n5\nKapitel 5 \u00b7 Die Beschreibung eines Zusammenhangs\nNicht-lineare Regression\nNicht jeder Zusammenhang wird durch eine Gerade optimal beschrieben. Es gibt exponentielle Zusammenh\u00e4nge (die beispielsweise durch Wachstumsprozesse bedingt sind) oder Zusammenh\u00e4nge, die sich durch eine logarithmische Funktion beschreiben lassen. Diese nicht-linearen Beziehungen erfordern spezielle Methoden zur Regressionsanalyse. Ehe man einen nicht-linearen Zusammenhang genauer untersucht, sollte man dar\u00fcber nachdenken, ob es eine Theorie gibt, die diesen Trend erkl\u00e4rt. Danach versucht man, die Art des Zusammenhangs zu finden und eine allgemeine Regressionsgleichung mit Parametern a, b etc. aufzustellen. Diese Wahl ist oft recht schwierig und erfordert sehr viel Erfahrung sowie genaue Kenntnisse der theoretischen Hintergr\u00fcnde. Wertvolle Hinweise liefert auch hier die graphische Darstellung der Wertepaare als Punktwolke. Generell gibt es zwei M\u00f6glichkeiten, geeignete Werte f\u00fcr die Parameter a, b etc. zu finden:\n\u2022 Manchmal ist es m\u00f6glich, die nichtlineare Regressionsgleichung in eine lineare zu transformieren. Anstelle der Gleichung y = a \u22c5 ebx w\u00fcrde man die Funktion lny = lna + bx betrachten und nach der Methode der kleinsten Quadrate optimale Werte f\u00fcr lna (und damit auch f\u00fcr a) sowie f\u00fcr b erhalten. \u2022 Man verwendet \u2013 \u00e4hnlich wie bei der linearen Regression \u2013 die Methode der kleinsten Quadrate. So w\u00fcrde man etwa bei der Funktion f ( x ) = a \u22c5 ebx die Ableitungen von \u00a6 ( yi \u2212 a \u22c5 ebxi ) 2 nach a und b bilden und diese gleich 0 setzen. i Die G\u00fcte eines multiplen oder eines nicht-linearen Modells l\u00e4sst sich z ebenfalls mit dem Determinationskoeffizienten r 2 (der das Verh\u00e4ltnis der erkl\u00e4rten zur Gesamtvarianz wiedergibt) absch\u00e4tzen. Mit Hilfe dieses Koeffizienten lassen sich auch mehrere Modelle miteinander vergleichen.\n5.4\nWeitere Techniken\n5.4.1\nDer Korrelationskoeffizient nach Spearman\nDie Berechnung des Korrelationskoeffizienten nach Pearson ist an einige Bedingungen gekn\u00fcpft. Es muss sich um quantitative Merkmale handeln, und der Zusammenhang muss ann\u00e4hernd linear sein.\n95\n5\n5.4 Weitere Techniken\nAls Alternative bietet sich der Korrelationskoeffizient nach Spearman an (Charles Spearman, 1863-1945, war ein britischer Psychologe). Dies ist ein Ma\u00df f\u00fcr die St\u00e4rke eines monotonen Zusammenhangs. Es wird auch als Rangkorrelation bezeichnet, da es auf den Rangzahlen der Beobachtungswerte ( xi , yi ) basiert. i Spearman untersuchte den Zusammenhang zwischen intellektuellen Leisz tungen und einem allgemeinen Intelligenzfaktor. Er ver\u00f6ffentlichte seine Ergebnisse etwa zeitgleich mit Pearson im Jahr 1904. In dieser Publikation wurde die Rangkorrelation erstmals erw\u00e4hnt.\n\u2022\n\u2022\n\u2022 \u2022\u2022\u2022 \u2022 \u2022\u2022 \u2022 \u2022 \u2022\u2022 \u2022 \u2022\u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022\u2022 \u2022 \u2022 \u2022 \u2022 \u2022 \u2022\nAbb. 5.5 gleichsinniger, monotoner Zusammenhang; Rangkorrelation positiv\nUm diesen Koeffizienten zu berechnen, werden alle x-Werte sortiert und mit Rangzahlen versehen. Der kleinste Wert erh\u00e4lt den Rang 1, der gr\u00f6\u00dfte den Rang n. Falls mehrere Auspr\u00e4gungen \u00fcbereinstimmen (man spricht dann von verbundenen R\u00e4ngen), ermittelt man mittlere Rangzahlen, indem man die Rangzahlen der gleichen Auspr\u00e4gungen addiert und die Summe durch deren Anzahl dividiert. Mit den Daten des yMerkmals verf\u00e4hrt man ebenso.\nJeder Beobachtungseinheit wird also eine Rangzahl f\u00fcr das x-Merkmal und eine f\u00fcr das y-Merkmal zugeordnet. Die Differenz dieser beiden Rangzahlen sei di . Aus diesen Differenzen wird der Spearman\u2019sche Korrelationskoeffizient berechnet nach: n\nrs = 1 \u2212\n6 \u22c5 \u00a6 di 2 i =1\nn \u22c5 (n 2 \u2212 1)\n(5.9)\nEbenso wie der Korrelationskoeffizient nach Pearson erstreckt sich auch der Korrelationskoeffizient nach Spearman rs zwischen \u20131 und +1. rs nimmt den maximalen Betrag 1 an, wenn der Zusammenhang streng monoton ist (dies umfasst den Begriff \u201estreng linear\u201c). Ein positives Vorzeichen symbolisiert einen gleichsinnigen, ein negatives Vorzeichen einen gegensinnigen Zusammenhang. rs = 0 bedeutet, dass kein monotoner Zusammenhang nachweisbar ist.\n96\nKapitel 5 \u00b7 Die Beschreibung eines Zusammenhangs\n! Die Voraussetzungen, die zur Berechnung des Spearman\u2019schen Korrelatiz\nonskoeffizienten erf\u00fcllt sein m\u00fcssen, sind schw\u00e4cher als die Voraussetzungen, die der Berechnung des Pearson\u2019schen Koeffizienten zugrunde liegen. Wenn allerdings zus\u00e4tzlich eine Regressionsgleichung ermittelt werden soll, wird \u2013 wenn es statthaft erscheint \u2013 dem Korrelationskoeffizienten nach Pearson den Vorzug gegeben.\n5\nBeispiel 5.5 Bei 10 Frauen wird der BMI-Wert zu Beginn ihrer Schwangerschaft gemessen; sp\u00e4ter wird der Apgar-Wert des neugeborenen Kindes ermittelt. Zum Nachweis eines Zusammenhangs eignet sich der Korrelationskoeffizient nach Spearman, da es sich beim Apgar-Score um ein ordinal skaliertes Merkmal handelt. Es ergeben sich folgende Werte (wobei x i der Apgar-Score, yi der BMI, R( xi ) und R( yi ) die R\u00e4nge und d i = R( xi ) \u2212 R ( yi ) deren Differenzen bezeichnen): xi 4 5 6 6 7 8 8 8 9 10 yi 27,1 24,9 26,4 25,9 25,3 23,2 21,0 22,4 19,6 20,1 R ( xi ) 1 2 3,5 3,5 5 7 7 7 9 10 R ( yi ) 10 6 9 8 7 5 3 4 1 2 di -9 -4 -5,5 -4,5 -2 2 4 3 8 8 81 16 30,25 20,25 4 4 16 9 64 64 di 2 10\nDaraus berechnet man\n\u00a6d i =1\n2 i\n= 308,5 und rs = 1 \u2212\n6 \u22c5 308,5 = \u22120,87 . Bei der 990\nkleinen Stichprobe ist also ein gegensinniger Zusammenhang erkennbar: Je h\u00f6her der BMI-Wert der Mutter, desto geringer der Apgar-Score des Kindes. i Streng mathematisch gesehen setzt der Spearman-Koeffizient voraus, dass z zwei benachbarte Merkmalsauspr\u00e4gungen \u00e4quidistant sind (was bekanntlich bei ordinalen Merkmalen problematisch ist). Die Rang-Korrelation \u03c4 (griechischer Buchstabe tau) nach Kendall setzt dies nicht voraus; dabei werden ausschlie\u00dflich die ordinalen Informationen verwendet. Ausf\u00fchrlich beschrieben ist dieser Koeffizient in [5]. Der Spearman\u2019sche Korrelationskoeffizient ist bekannter und wird h\u00e4ufiger angewandt.\nMerke Die Rangkorrelation nach Spearman eignet sich f\u00fcr folgende Konstellationen: \u0177 Beide Merkmale sind ordinal skaliert. \u0177 Ein Merkmal ist metrisch, das andere ordinal skaliert. \u0177 Beide Merkmale sind quantitativ; der Zusammenhang ist monoton, aber nicht linear.\n5\n97 5.4 Weitere Techniken\nMathematische Herleitung des Korrelationskoeffizienten nach Spearman Dieser Koeffizient wird berechnet, indem man in die Formel zur Bestimmung des Pearson\u2019schen Korrelationskoeffizienten (5.2) anstelle der Messwerte x i und yi deren R\u00e4nge R( xi ) und R( yi ) und f\u00fcr x und y den mittleren Rang R einsetzt. Durch vollst\u00e4ndige Induktion l\u00e4sst sich nachweisen, dass n n n n n \u22c5 ( n + 1) n \u22c5 ( n + 1) \u22c5 (2n + 1) R( xi ) = \u00a6 i = und \u00a6 R 2 ( xi ) = \u00a6 i 2 = \u00a6 2 6 i =1 i =1 i =1 i =1 Daraus resultiert f\u00fcr den Mittelwert und die Summe der Abstandsquadrate: n n n \u22c5 ( n 2 \u2212 1) n +1 R= und \u00a6 ( R( xi ) \u2212R )2 = \u00a6 R 2 ( xi ) \u2212 nR 2 = 2 12 i =1 i =1\nAnaloges gilt f\u00fcr die R\u00e4nge des y-Merkmals; d. h. die Standardabweichungen von R( xi ) und R( yi ) sind gleich. Deren Produkt entspricht dem Nenner von Formel (5.2). F\u00fcr den Z\u00e4hler ergibt sich durch Umformen: n\n\u00a6 ( R( x ) \u2212 R ) \u22c5 ( R( y ) \u2212 R ) = i\ni\ni =1 n\n2\nn\n2\nn\n\u00a6 ( R( x ) \u2212 R ) + \u00a6 ( R( y ) \u2212 R ) \u2212 \u00a6 d i\nn\n2\n5.4.2\ni =1\ni =1\ni\n\u00a6d\n2\nn \u22c5 ( n \u2212 1) i =1 i = \u2212 . 2 12 2 Wenn man Z\u00e4hler und Nenner zusammenfasst, erh\u00e4lt man die Formel (5.9). i =1\ni\n2\nDer Zusammenhang zwischen einem quantitativen und einem Alternativmerkmal\nIn diesem Kapitel wurde der Frage nachgegangen, wie sich der Zusammenhang zwischen zwei quantitativen Merkmalen \u2013 etwa zwischen K\u00f6rpergr\u00f6\u00dfe und Gewicht \u2013 beschreiben l\u00e4sst. Nun h\u00e4ngt das Gewicht bekanntlich nicht nur von der Gr\u00f6\u00dfe, sondern auch vom Geschlecht einer Person ab. Um den Unterschied zwischen zwei Gruppen abzusichern, verwendet man \u00fcblicherweise einen statistischen Test wie etwa den t-Test f\u00fcr zwei unverbundene Stichproben \u203a Abschnitt 11.1.3). Ein solcher Test beinhaltet jedoch kein (z Assoziationsma\u00df, das die St\u00e4rke des Zusammenhangs quantifiziert. Die St\u00e4rke des Zusammenhangs zwischen einem quantitativen und einem Alternativmerkmal kann durch die punktbiseriale Korrelation rpb ausgedr\u00fcckt werden. Dabei werden f\u00fcr die Auspr\u00e4gungen des Alternativmerkmals die Werte 0 oder 1 eingesetzt; damit l\u00e4sst sich dann nach (5.2) ein Korrelationskoeffizient berechnen.\n98\nKapitel 5 \u00b7 Die Beschreibung eines Zusammenhangs\nBeispiel 5.6 Um die St\u00e4rke des Zusammenhangs zwischen Geschlecht und K\u00f6rpergewicht zu quantifizieren, codiert man das Geschlecht mit 0 (m\u00e4nnlich) und 1 (weiblich). Die x-Werte nehmen dann entweder den Wert 0 oder 1 an; die y-Werte sind die Messwerte f\u00fcr das Gewicht. Mit den Daten in Tabelle 2.1 erhalten wir einen biserialen Korrelationskoeffizienten rpb = \u22120,638 . Der Zusammenhang ist gegensinnig \u2013 d. h. M\u00e4nner (mit dem kleineren x-Wert 0 codiert) wiegen mehr als Frauen. Aus diesen Angaben folgt au\u00dferdem: rpb2 = 0,407 . Dies besagt, dass \u2013 bezogen auf alle Studenten \u2013 etwa 41 % des K\u00f6rpergewichts durch den Einfluss des Geschlechts erkl\u00e4rt werden k\u00f6nnen.\n5 5.4.3\nDer Zusammenhang zwischen qualitativen Merkmalen\nIn Abschnitt 3.4.2 wurden die Odds Ratio und der Assoziationskoeffizient nach Yule erw\u00e4hnt, die geeignet sind, den Zusammenhang zwischen zwei Alternativmerkmalen zu quantifizieren. In Abschnitt 12.2.4 werden Assoziationsma\u00dfe vorgestellt, mit denen sich der Zusammenhang zwischen zwei nominal skalierten Merkmalen beschreiben l\u00e4sst. Allgemein gilt: Je h\u00f6her das Skalenniveau der zugrunde liegenden Merkmale ist, desto pr\u00e4ziser lassen sich die St\u00e4rke und die Art eines Zusammenhangs beschreiben. 5.4.4\nAusblick auf die induktive Statistik\nZur sinnvollen Interpretation eines Korrelationskoeffizienten, einer Regressionsgleichung oder eines Assoziationskoeffizienten ist es wichtig, dass der Stichprobenumfang hinreichend gro\u00df ist. Allgemein gilt: Je n\u00e4her ein Korrelationskoeffizient bei 0 liegt und je kleiner der Stichprobenumfang ist, umso weniger kann auf einen real existierenden Zusammenhang geschlossen werden. In diesen F\u00e4llen muss man davon ausgehen, dass die empirisch ermittelte Korrelation zufallsbedingt ist. Um absch\u00e4tzen zu k\u00f6nnen, ob und inwieweit der anhand der Stichprobe ermittelte Zusammenhang auf die Grundgesamtheit \u00fcbertragbar ist, erscheint es sinnvoll, Vertrauensbereiche zu ermitteln und einen geeigneten statistischen Test durchzuf\u00fchren. Dies geschieht \u2013 in Abh\u00e4ngigkeit von den Skalenniveaus der beiden \u203a Abschnitte Merkmale \u2013 mit Methoden der induktiven Statistik (z 9.3.4, 11.1.6 und 12.2.4).\n6\nWahrscheinlichkeiten in der Medizin 6.1\nDie Aufgaben der Wahrscheinlichkeitsrechnung 101\n6.2\nDas Rechnen mit Wahrscheinlichkeiten 102\n6.2.1\nZufallsexperimente und deren Beschreibung 102\n6.2.2\nDas Ermitteln einer Wahrscheinlichkeit 103\n6.2.3\nDie Verkn\u00fcpfung zweier Ereignisse 105\n6.2.4\nDie Axiome von Kolmogoroff und deren Folgerungen 107\n6.2.5\nAbh\u00e4ngigkeit und bedingte Wahrscheinlichkeit 109\n6.2.6\nDas Bayes-Theorem 110\n6.3\nWahrscheinlichkeiten in der Epidemiologie 111\n6.4\nBev\u00f6lkerungsstatistiken 114\n6.4.1\nSpezielle Wahrscheinlichkeiten 114\n6.4.2\nSterbetafeln 115\n6.5\nDiagnostische Tests 118\n6.5.1\nDie G\u00fctekriterien eines diagnostischen Tests 118\n6.5.2\nVorhersagewerte 119\n6.1 Die Aufgaben der Wahrscheinlichkeitsrechnung\n6.1\n101\n6\nDie Aufgaben der Wahrscheinlichkeitsrechnung\nUnser Alltag ist bestimmt von unendlich vielen Zuf\u00e4lligkeiten und Irregularit\u00e4ten. Wir haben gelernt, Wahrscheinlichkeiten intuitiv abzusch\u00e4tzen, um unseren Alltag regeln zu k\u00f6nnen \u2013 ansonsten w\u00fcrden wir im \u00dcberangebot der auf uns einstr\u00f6menden Informationen zugrunde gehen. Wir verlassen uns beispielsweise darauf, dass wir sicher am Ziel ankommen, wenn wir ein Auto besteigen, und wir kalkulieren bei unseren Zukunftspl\u00e4nen keinen Lottogewinn ein. Ein Arzt vertraut darauf, dass die von ihm verordnete Therapie den gew\u00fcnschten Erfolg erzielt, oder dass ein Patient durch eine Impfung einer m\u00f6glichen Epidemie entgeht. Mit einem unwahrscheinlichen Ereignis befassen wir uns erst dann, wenn dieses \u2013 entgegen unseren Erwartungen \u2013 eingetreten ist. Wir orientieren uns also nicht nur nach Sicherheiten, sondern geben uns meistens notgedrungen mit Wahrscheinlichkeiten zufrieden. Der Begriff \u201ewahrscheinlich\u201c und davon abgeleitete Ausdr\u00fccke entstammen unserer Umgangssprache. Mit S\u00e4tzen wie \u201eMorgen scheint wahrscheinlich die Sonne\u201c oder \u201eEs ist unwahrscheinlich, dass nach einer Impfung dauerhafte Sch\u00e4den zur\u00fcckbleiben\u201c dr\u00fccken wir Vermutungen aus bez\u00fcglich Ereignissen, die wir nicht vorhersehen k\u00f6nnen. Dabei handelt es sich meist um subjektive Wahrscheinlichkeiten, die auf allt\u00e4glichen Erfahrungen basieren. Diese k\u00f6nnen wir nach unserem pers\u00f6nlichen Empfinden grob als hoch oder eher niedrig einstufen; es ist jedoch nicht m\u00f6glich, sie exakt zu quantifizieren. Manchmal sind derlei Einsch\u00e4tzungen allerdings v\u00f6llig unrealistisch, weil wir uns bei subjektiven Beurteilungen gerne von Wunschdenken oder anderen psychisch bedingten, intellektuell kaum nachvollziehbaren Einfl\u00fcssen t\u00e4uschen lassen. Auch die Prozesse und Entwicklungen in den Biowissenschaften unterliegen dem Zufall. Man bezeichnet sie als probabilistisch \u2013 im Gegensatz zu deterministischen Vorg\u00e4ngen, die sich exakt berechnen lassen. F\u00fcr wissenschaftliche Untersuchungen ist es notwendig, den Begriff der Wahrscheinlichkeit zu pr\u00e4zisieren und quantitativ zu beschreiben. Diese Zahlenangaben bezeichnet man als objektive Wahrscheinlichkeiten. Die Aufgaben der Wahrscheinlichkeitsrechnung und der induktiven Statistik bestehen darin, die Realit\u00e4t durch ein statistisches Modell hinreichend genau zu beschreiben und anhand dieses Modells Gesetzm\u00e4\u00dfigkeiten herzuleiten und Wahrscheinlichkeiten zu bestimmen. Dabei ist es unerheblich, ob die zu\n102\n6\nKapitel 6 \u00b7 Wahrscheinlichkeiten in der Medizin\nbeschreibenden Vorg\u00e4nge prinzipiell nicht erfassbar sind (wie z. B. der Zerfall eines radioaktiven Atoms), oder ob sie so komplex sind, dass sie sich einer deterministischen Beschreibung entziehen und deshalb als probabilistisch angesehen werden. Die mathematisch-theoretischen Aussagen, die in der Wahrscheinlichkeitsrechnung hergeleitet werden, bilden die Basis der induktiven Statistik. F\u00fcr den praktischen Anwender sind Kenntnisse aus der Wahrscheinlichkeitsrechnung hilfreich und notwendig, um die Methoden der induktiven Statistik zu verstehen und sinnvoll mit ihnen umgehen zu k\u00f6nnen. In diesem Kapitel werden zun\u00e4chst in Abschnitt 6.2 Grundlagen bez\u00fcglich des Rechnens mit Wahrscheinlichkeiten vermittelt. In den Abschnitten 6.3 bis 6.5 werden einige f\u00fcr die Medizin relevante Wahrscheinlichkeiten vorgestellt.\n6.2\nDas Rechnen mit Wahrscheinlichkeiten\n6.2.1\nZufallsexperimente und deren Beschreibung\nUm einen probabilistischen Vorgang zu untersuchen und relevante Wahrscheinlichkeiten herzuleiten, gen\u00fcgt es nicht, ihn ein einziges Mal durchzuf\u00fchren. Es erscheint vielmehr angebracht, diesen Vorgang mehrmals zu wiederholen, die Ergebnisse der einzelnen Experimente zu dokumentieren und auszuwerten. Diese Art von Untersuchungen bezeichnet man als Zufallsexperimente. Ein Zufallsexperiment ist durch die folgenden Eigenschaften charakterisiert:\n\u0177 \u0177 \u0177 \u0177\nEs wird nach einer bestimmten Vorschrift durchgef\u00fchrt, es ist (zumindest prinzipiell) beliebig oft wiederholbar, mehrere Ausg\u00e4nge oder Ergebnisse sind m\u00f6glich, und das Ergebnis eines einzelnen Experiments ist vorab ungewiss.\nSo stellen beispielsweise das W\u00fcrfeln oder das Werfen einer M\u00fcnze Zufallsexperimente dar. Beim W\u00fcrfeln gibt es sechs m\u00f6gliche Ausg\u00e4nge, beim M\u00fcnzwurf zwei. Auch das Erfassen der Blutgruppe oder des Rhesusfaktors einer Person l\u00e4sst sich als Zufallsexperiment auffassen mit den m\u00f6glichen Ergebnissen 0, A, B und AB bzw. \u201eRhesusfaktor positiv\u201c und \u201eRhesusfaktor negativ\u201c. Zur Beschreibung von Zufallsexperimenten bedient sich die Wahrscheinlichkeitsrechnung der Mengentheorie. Die Menge aller m\u00f6glichen Ergebnisse bildet den so genannten Ereignisraum. Diese\n6\n103 6.2 Das Rechnen mit Wahrscheinlichkeiten\nMenge wird mit dem griechischen Gro\u00dfbuchstaben \u2126 (Omega) bezeichnet. Teilmengen von \u2126 nennt man Ereignisse, 1-elementige Teilmengen Elementarereignisse. Ereignisse werden \u00fcblicherweise mit gro\u00dfen lateinischen Buchstaben A, B usw. angegeben. Spezielle Ereignisse sind der Ereignisraum \u2126 , der als das sichere Ereignis bezeichnet wird, und die leere Menge \u2205 , die dem unm\u00f6glichen Ereignis entspricht. Beispiel 6.1 Der Ereignisraum f\u00fcr das Zufallsexperiment \u201eW\u00fcrfeln\u201c ist die 6-elementige Menge \u2126 = {1,2,3,4,5,6} . Das Ereignis \u201egerade Zahl\u201c l\u00e4sst sich durch die Teilmenge A = {2,4,6} beschreiben. Man sagt: \u201eDas Ereignis A ist eingetreten\u201c, falls ein Elementarereignis aus der Menge A eingetreten ist.\nAn diesem Beispiel wird der Zusammenhang zwischen der Wahrscheinlichkeitsrechung und der deskriptiven Statistik deutlich. Das Analogon zum Ereignisraum ist die Auspr\u00e4gungsliste; einzelne Merkmalsauspr\u00e4gungen sind vergleichbar mit Elementarereignissen. Der grundlegende Unterschied ist folgender: Die deskriptive Statistik befasst sich mit Stichproben und Merkmalen; die Wahrscheinlichkeitsrechnung untersucht die mathematisch-theoretischen Eigenschaften von Grundgesamtheiten. 6.2.2\nDas Ermitteln einer Wahrscheinlichkeit\n\u2022 Theoretische Herleitung. Um eine Wahrscheinlichkeit quantita tiv anzugeben, ist es notwendig, diesen Begriff zu objektivieren. Eine erste Definition geht auf den franz\u00f6sischen Mathematiker Pierre Simon Marquis de Laplace zur\u00fcck, der sich f\u00fcr die Zufallsgesetze bei Gl\u00fccksspielen interessierte. Er definierte basierend auf dem Begriff des Zufallsexperiments die Wahrscheinlichkeit, dass ein bestimmtes Ereignis A eintritt, folgenderma\u00dfen: P( A ) =\nAnzahl der g\u00fcnstigen Ergebnisse Anzahl der m\u00f6glichen Ergebnisse\n(6.1a)\nMit der Mengenschreibweise l\u00e4sst sich die Formel (6.1a) auch darstellen als: P ( A) =\nAnzahl der Elemente von A Anzahl der Elemente von \u2126\n(6.1b)\n104\nKapitel 6 \u00b7 Wahrscheinlichkeiten in der Medizin\nDie Laplace\u2019sche Definition ordnet demnach jedem Ereignis eine Zahl zwischen 0 und 1 zu. Der Buchstabe P leitet sich ab vom englischen Ausdruck \u201eprobability\u201c. Die Wahrscheinlichkeit eines Ereignisses ist vergleichbar mit der relativen H\u00e4ufigkeit einer Merkmalsauspr\u00e4gung.\n6\nBeispiel 6.2 Mit der Definition von Laplace l\u00e4sst sich berechnen, wie gro\u00df die Chance ist, eine gerade Zahl zu w\u00fcrfeln. Unter sechs m\u00f6glichen Ergebnissen gibt es drei \u201eg\u00fcnstige\u201c (n\u00e4mlich die Augenzahlen 2, 4 und 6). Damit erh\u00e4lt man: P( A ) = 3 / 6 = 1 / 2 . F\u00fcr das unm\u00f6gliche Ereignis (beispielsweise die Zahl 7) ergibt sich P( \u2205 ) = 0 , da die Anzahl der g\u00fcnstigen Ereignisse gleich 0 betr\u00e4gt. F\u00fcr das sichere Ereignis (Augenzahl zwischen 1 und 6) erh\u00e4lt man P( \u2126 ) = 1 , da die Anzahl der g\u00fcnstigen der Anzahl der m\u00f6glichen Ereignisse entspricht.\nMit der Laplace\u2019schen Definition lassen sich auch kompliziertere Wahrscheinlichkeiten herleiten \u2013 so z. B. die Wahrscheinlichkeit, sechs Richtige im Lotto zu erzielen. Dennoch ist diese Definition nur eingeschr\u00e4nkt anwendbar: Sie setzt n\u00e4mlich voraus, dass alle Elementarereignisse mit gleicher Wahrscheinlichkeit eintreten. F\u00fcr das W\u00fcrfeln und den M\u00fcnzwurf trifft dies auch zu. So ist beispielsweise leicht nachvollziehbar, dass man bei einem idealen W\u00fcrfel jeder Augenzahl die Wahrscheinlichkeit 1/6 zuordnet, oder dass die Wahrscheinlichkeit, beim M\u00fcnzwurf \u201eWappen\u201c oder \u201eZahl\u201c zu erhalten, jeweils 1/2 betr\u00e4gt. F\u00fcr Ereignisse im medizinischen Bereich ist dieser Ansatz jedoch im Allgemeinen unbrauchbar. \u2022 Empirische Herleitung. Bei medizinisch-wissenschaftlichen Fragestellungen wird eine Wahrscheinlichkeit in der Regel empirisch ermittelt. Dazu wird eine hinreichend gro\u00dfe Stichprobe bez\u00fcglich eines Merkmals untersucht; der Wert der relativen H\u00e4ufigkeit einer Merkmalsauspr\u00e4gung wird dann als N\u00e4herungswert f\u00fcr die entsprechende Wahrscheinlichkeit zugrunde legt. Dieses Vorgehen \u203a Abl\u00e4sst sich durch das \u201eGesetz der gro\u00dfen Zahlen\u201c rechtfertigen (z schnitt 8.3.2). Beispiel 6.3 Aus den Daten aus Tabelle 2.1 von 71 Studenten ergeben sich folgende H\u00e4ufigkeiten: 28 (Blutgruppe 0), 31 (Blutgruppe A), 9 (Blutgruppe B) und 3 (Blutgruppe AB). 60 Studenten haben Rhesusfaktor positiv (R+), 11 Rhesusfaktor negativ (R\u2013). Damit lassen sich folgende Wahrscheinlichkeiten sch\u00e4tzen: P (0) = 39% , P ( A) = 44% , P ( B) = 13% und P ( AB) = 4% ; P ( R +) = 85% , P ( R \u2212) = 15% .\n105\n6\n6.2 Das Rechnen mit Wahrscheinlichkeiten\n\u2022 Computersimulation. Bei sehr komplexen Problemen, insbeson dere aus dem technisch-wissenschaftlichen Bereich, ist auch die empirische Vorgehensweise nicht brauchbar. Um beispielsweise die Wahrscheinlichkeit zu ermitteln, dass ein Flugzeug abst\u00fcrzt oder dass bei einem Atomkraftwerk ein GAU eintritt, kann man keine Zufallsexperimente durchf\u00fchren. In diesen F\u00e4llen ist es sinnvoll, das Problem im Computer zu simulieren und mit Hilfe dieses Modells die Wahrscheinlichkeit f\u00fcr das Auftreten eines bestimmten Ereignisses zu ermitteln. Die Computersimulation wird in den letzten Jahren \u2013 dank der Entwicklung hochleistungsf\u00e4higer Rechner und ad\u00e4quater Software \u2013 zunehmend auch f\u00fcr medizinische Fragestellungen angewandt. Im Rahmen dieses Buches kann jedoch nicht n\u00e4her auf diese Thematik eingegangen werden. 6.2.3\nDie Verkn\u00fcpfung zweier Ereignisse\nIm vorangegangenen Abschnitt wurden Methoden vorgestellt, mit denen sich die Wahrscheinlichkeit f\u00fcr das Auftreten eines bestimmten Ereignisses A ermitteln l\u00e4sst. Bei vielen Fragestellungen interessieren jedoch nicht nur einzelne Ereignisse, sondern bestimmte Ereigniskonstellationen. Fragen dieser Art lauten z. B.: Wie gro\u00df ist die Wahrscheinlichkeit,\n\u0177 dass eine Person eine andere Blutgruppe als 0 hat? \u0177 dass eine Person an zwei Krankheiten gleichzeitig erkrankt? \u0177 dass eine m\u00e4nnliche Person an H\u00e4mophilie erkrankt? Verbindungen zwischen zwei oder mehreren Ereignissen lassen sich durch mengentheoretische Operationen beschreiben. Zur graphischen Darstellung dieser Beziehungen eignen sich die so genannten VENN-Diagramme (benannt nach dem britischen Mathematiker John Venn, 1834-1923). So bezeichnen die Vereinigungsmenge A \u222a B : (sprich: A vereinigt B) die Schnittmenge A \u2229 B : (sprich: A Schnitt B) die Differenzmenge A \u2212 B : (sprich: A minus B)\ndas Ereignis, dass A allein oder B allein oder beide Ereignisse gemeinsam eintreten (Abb. 6.1a) das Ereignis, dass A und B gemeinsam eintreten (Abb. 6.1b) das Ereignis, dass A aber nicht B eintritt (Abb. 6.1c)\n106\nKapitel 6 \u00b7 Wahrscheinlichkeiten in der Medizin\nB\nA\n6\nAbb. 6.1a Vereinigung A \u222a B\nB\nB\nA Abb. 6.1b Schnitt A \u2229 B\nA Abb. 6.1c Differenz A \u2212 B\nBeispiel 6.4 Wenn A das Ereignis \u201eBlutgruppe A\u201c und R + das Ereignis \u201eRhesusfaktor positiv\u201c bezeichnet, dann bedeutet A \u222a R + das Ereignis, dass die Blutgruppe A oder der Rhesusfaktor positiv vorliegt. Das Wort \u201eoder\u201c wird dabei im nichtausschlie\u00dflichen Sinne verwendet: A \u222a R + beinhaltet, dass nur das Ereignis A (Blutgruppe A, Rhesusfaktor negativ) oder nur das Ereignis R+ (andere Blutgruppe als A, Rhesusfaktor positiv) eintritt oder beide Ereignisse gemeinsam (Blutgruppe A und Rhesusfaktor positiv) eintreten.\nZwei Ereignisse A und B, deren Durchschnitt die leere Menge bildet, hei\u00dfen disjunkt (oder unvereinbar). Als Beispiel seien \u201em\u00e4nnliches Geschlecht\u201c und \u201eschwanger\u201c genannt. Formal gilt f\u00fcr disjunkte Ereignisse: A \u2229 B = \u2205 . Zwei disjunkte Ereignisse, die sich zum Ereignisraum \u2126 erg\u00e4nzen, nennt man komplement\u00e4r. Das zu A komplement\u00e4re Ereignis wird \u00fcblicherweise mit A (sprich: A quer) bezeichnet. F\u00fcr A und A gelten:\n\u0177 A \u222a A = \u2126 (die Ereignisse erg\u00e4nzen sich) und \u0177 A \u2229 A = \u2205 (die Ereignisse sind disjunkt). Beispiele f\u00fcr komplement\u00e4re Ereignisse sind: gerade und ungerade Augenzahl beim W\u00fcrfeln, m\u00e4nnliches und weibliches Geschlecht, \u201eRhesusfaktor positiv\u201c und \u201eRhesusfaktor negativ\u201c oder \u201eBlutgruppe A\u201c und \u201eandere Blutgruppe als A\u201c.\n107\n6\n6.2 Das Rechnen mit Wahrscheinlichkeiten\n6.2.4\nDie Axiome von Kolmogoroff und deren Folgerungen\nUm mit Wahrscheinlichkeiten zu rechnen, ist es notwendig, deren mathematische Eigenschaften zu pr\u00e4zisieren. Der russische Mathematiker Andrej Kolmogoroff (1903-1987) hat im Jahre 1930 drei Axiome aufgestellt, die diese Eigenschaften definieren. Demnach hei\u00dft eine Funktion P(A), die einem Ereignis A eine reelle Zahl zuordnet, Wahrscheinlichkeit, falls die folgenden Axiome erf\u00fcllt sind: 1. 0 \u2264 P( A ) \u2264 1 2. P( \u2126 ) = 1 3. P( A \u222a B ) = P( A ) + P( B ) f\u00fcr disjunkte Ereignisse A und B i Axiome sind einfache mathematische Aussagen, die nicht beweisbar sind. z Sie werden aufgestellt, um einen Begriff zu definieren oder um eine Theorie aufzubauen. Mittels der Axiome lassen sich weitere Aussagen deduktiv herleiten.\nBeispiel 6.5 Wir betrachten die Funktion P, die den Blutgruppen folgende Wahrscheinlichkeiten zuordnet (Beispiel 6.3): P (0) = 0,39 , P ( A) = 0,44 , P( B ) = 0,13 und P ( AB) = 0,04 . Der Ereignisraum \u2126 ist die Menge {0, A, B, AB} . Man kann leicht nachpr\u00fcfen, dass die Axiome von Kolmogoroff erf\u00fcllt sind. Jeder Funktionswert liegt zwischen 0 und 1 (Axiom 1), au\u00dferdem gilt P( \u2126 ) = 1 \u2013 denn eine der vier Blutgruppen liegt mit Sicherheit vor (Axiom 2). Die Wahrscheinlichkeit, dass eine der Blutgruppen A oder B gegeben ist, ist: P ( A \u222a B) = P ( A) + P ( B) = 0,44 + 0,13 = 0,57 ; Analoges gilt f\u00fcr die anderen Ereignispaare (demnach ist Axiom 3 erf\u00fcllt). Somit handelt es sich bei der Funktion P um eine Wahrscheinlichkeit im Sinne von Kolmogoroff.\nDie Definition der Wahrscheinlichkeit nach Kolmogoroff schlie\u00dft die Definition von Laplace ein \u2013 sie ist jedoch wesentlich allgemeiner als diese. W\u00e4hrend Laplace davon ausgeht, dass alle Elementarereignisse mit gleicher Wahrscheinlichkeit eintreten, verlangt Kolmogoroff lediglich, dass die Wahrscheinlichkeit jedes Elementarereignisses eine Zahl zwischen 0 und 1 ist, und dass deren Summe 1 ergibt. Man kann leicht nachvollziehen, dass diese Eigenschaften auch f\u00fcr relative H\u00e4ufigkeiten und die daraus gesch\u00e4tzten Wahrscheinlichkeiten gelten. Aus den Axiomen von Kolmogoroff lassen sich mehrere Rechenregeln herleiten:\n\u2022 Wahrscheinlichkeit f\u00fcr das komplement\u00e4re Ereignis. Aus P( A) ergibt sich sehr einfach die Wahrscheinlichkeit f\u00fcr das Ereignis A :\n108\nKapitel 6 \u00b7 Wahrscheinlichkeiten in der Medizin\nP ( A ) = 1 \u2212 P ( A)\n(6.2)\nDaraus und aus Axiom 2 folgt f\u00fcr das unm\u00f6gliche Ereignis:\nP (\u2205 ) = 0\n(6.3)\nBeispiel 6.6 Die Wahrscheinlichkeit f\u00fcr die Blutgruppe 0 betr\u00e4gt P (0) = 0,39 . Damit berechnet sich die Wahrscheinlichkeit, dass eine andere Blutgruppe als 0 vorliegt, als P ( 0 ) = 1 \u2212 0,39 = 0,61 .\n\u2022 Satz von der totalen Wahrscheinlichkeit. Er besagt, dass ein Er eignis A entweder zusammen mit dem Ereignis B oder B auftritt:\n6\nP ( A) = P ( A \u2229 B ) + P ( A \u2229 B )\n(6.4)\nDas Ereignis A \u2229 B ist identisch mit der Differenzmenge A \u2212 B . Des\u203a Abbildung 6.1c): halb folgt aus der Formel (6.4) sofort (z P( A \u2212 B ) = P( A ) \u2212 P( A \u2229 B )\n(6.5)\n\u2022 Additionssatz. F\u00fcr die Vereinigung zweier Ereignisse A und B gilt allgemein: P( A \u222a B ) = P( A ) + P( B ) \u2212 P( A \u2229 B )\n(6.6)\nWenn die beiden Ereignisse A und B disjunkt sind, ist A \u2229 B = \u2205 . Dann hat der Additionssatz eine etwas einfachere Form: P( A \u222a B ) = P( A ) + P( B )\n(6.7)\nBeispiel 6.7 Seien A und R+ die Ereignisse \u201eBlutgruppe A\u201c bzw. \u201eRhesusfaktor positiv\u201c. Dann entspricht R- dem Ereignis \u201eRhesusfaktor negativ\u201c. Der Satz von der totalen Wahrscheinlichkeit (6.4) besagt, dass eine Person mit Blutgruppe A entweder \u201eRhesusfaktor positiv\u201c oder \u201eRhesusfaktor negativ\u201c hat. Die Wahrscheinlichkeit P ( A) = 0,44 ist die Summe aus P( A \u2229 R + ) = 0, 374 und P( A \u2229 R \u2212 ) = 0, 066 (die Wahrscheinlichkeiten der Schnittmengen werden im n\u00e4chsten Abschnitt hergeleitet). Die Wahrscheinlichkeit f\u00fcr Rhesusfaktor positiv oder Blutgruppe A betr\u00e4gt nach dem Additionssatz (6.6):\nP( A \u222a R + ) = P( A) + P ( R + ) \u2212 P ( A \u2229 R + ) = 0, 44 + 0,85 \u2212 0, 374 = 0, 916\n6\n109 6.2 Das Rechnen mit Wahrscheinlichkeiten\nMathematische Herleitung der Rechenregeln Alle genannten Rechenregeln lassen sich auf die drei Axiome von Kolmogoroff zur\u00fcckf\u00fchren. Aus den Axiomen 2 und 3 folgt sofort: 1 = P( \u2126 ) = P( A \u222a A ) = P( A ) + P( A ) Daraus ergibt sich Formel (6.2). Der Satz von der totalen Wahrscheinlichkeit (Formel 6.4) folgt ebenfalls direkt aus Axiom 3. Um den Additionssatz herzuleiten (Formel 6.6), zerlegt man die Menge A \u222a B in drei disjunkte Teilmengen: P( A \u222a B ) = P( A \u2229 B ) + P( A \u2229 B ) + P( A \u2229 B ) Nach dem Satz von der totalen Wahrscheinlichkeit ergibt die Summe der ersten beiden Summanden P( A ) ; f\u00fcr den dritten Summanden gilt: P( A \u2229 B ) = P( B ) \u2212 P( A \u2229 B ) . Demnach ist P( A \u222a B ) = P( A ) + P( B ) \u2212 P( A \u2229 B ) .\n6.2.5\nAbh\u00e4ngigkeit und bedingte Wahrscheinlichkeit\nIn gewissen Situationen ist es nicht zweckm\u00e4\u00dfig, Wahrscheinlichkeiten anzugeben, die sich auf die Grundgesamtheit beziehen. Viele Krankheiten stehen in Zusammenhang mit dem Geschlecht der Patienten (z. B. H\u00e4mophilie, Rot-Gr\u00fcn-Blindheit oder Brustkrebs) oder sind abh\u00e4ngig von bestimmten Risiken. In diesen F\u00e4llen ist es sinnvoll, die Wahrscheinlichkeiten f\u00fcr bestimmte Teilmengen der Grundgesamtheit getrennt zu berechnen \u2013 etwa f\u00fcr M\u00e4nner und f\u00fcr Frauen oder f\u00fcr Patienten mit und ohne Risikofaktor. Man spricht dann von einer bedingten Wahrscheinlichkeit und bezeichnet diese als P( A| B ) (sprich: \u201eP von A gegeben B\u201c oder \u201eP von A unter der Bedingung B\u201c). Sie ist folgenderma\u00dfen definiert: P( A| B ) =\nP( A \u2229 B ) P( B )\n(6.8)\nDiese Formel quantifiziert die Wahrscheinlichkeit f\u00fcr das Eintreten des Ereignisses A eingeschr\u00e4nkt auf die Menge, die dem Ereignis B entspricht. Beispiel 6.8 Die Wahrscheinlichkeit, an Diabetes mellitus zu erkranken, betr\u00e4gt f\u00fcr einen Mann P( D| M ) \u2248 0 ,07 und f\u00fcr eine Frau P( D|W ) \u2248 0 ,02 . Daraus geht hervor, dass das Risiko bei M\u00e4nnern wesentlich h\u00f6her ist als bei Frauen. Die Wahrscheinlichkeit P( D ) \u2248 0 ,045 , die sich auf die gesamte Population bezieht, ist weniger informativ.\n110\nKapitel 6 \u00b7 Wahrscheinlichkeiten in der Medizin\nDurch einfaches Umschreiben von (6.8) erh\u00e4lt man den Multiplikationssatz, mit dem sich die Wahrscheinlichkeit berechnen l\u00e4sst, dass zwei Ereignisse A und B gemeinsam eintreten: P( A \u2229 B ) = P( A| B ) \u22c5 P( B )\n(6.9)\nWenn A und B unabh\u00e4ngig sind, bedeutet dies, dass das Eintreten von B keinerlei Einfluss auf das Eintreten von A hat. Formal dr\u00fcckt man dies folgenderma\u00dfen aus: P( A| B ) = P( A ) . Damit erh\u00e4lt man den Multiplikationssatz und den Additionssatz f\u00fcr unabh\u00e4ngige Ereignisse als Spezialf\u00e4lle von (6.9) und (6.6):\n6\nP( A \u2229 B ) = P( A ) \u22c5 P( B )\n(6.10)\nP( A \u222a B ) = P( A ) + P( B ) \u2212 P( A ) \u22c5 P( B )\n(6.11)\nBeispiel 6.9 Die Ereignisse \u201eBlutgruppe A\u201c und \u201eRhesusfaktor positiv\u201c sind unabh\u00e4ngig mit den Wahrscheinlichkeiten P ( A) = 0,44 und P ( R +) = 0,85 . Die Wahrscheinlichkeit, dass eine Person Blutgruppe A und Rhesusfaktor positiv hat, ist dann (siehe auch Beispiel 6.7): P( A \u2229 R + ) = P( A) \u22c5 P ( R + ) = 0, 44 \u22c5 0,85 = 0, 374\n6.2.6\nDas Bayes-Theorem\nDas Bayes-Theorem geht zur\u00fcck auf den englischen Geistlichen Thomas Bayes (1702-1761), der sich u. a. mit Gl\u00fccksspielen befasste. Es erlaubt die Berechnung der bedingten Wahrscheinlichkeit P( A | B ) , wenn au\u00dfer der Wahrscheinlichkeit P ( A) auch die bedingten Wahrscheinlichkeiten P( B | A) und P ( B | A ) bekannt sind. Die Formel ist: P( A| B ) =\nP( A ) \u22c5 P( B| A ) P( A ) \u22c5 P( B| A ) + P( A ) \u22c5 P( B| A )\n(6.12)\nDas Bayes-Theorem erm\u00f6glicht also R\u00fcckschl\u00fcsse von der a-prioriWahrscheinlichkeit P( A ) auf die a-posteriori-Wahrscheinlichkeit P ( A | B ) . Diese Formel wird in der Medizin bei diagnostischen Tests benutzt: Wenn A das Ereignis \u201eVorliegen einer bestimmten Krankheit\u201c und B das Ereignis \u201eTestergebnis positiv\u201c symbolisieren, l\u00e4sst sich mit obiger Formel die Wahrscheinlichkeit P ( A | B ) berechnen, mit der ein Patient mit einem positiven Befund tats\u00e4chlich erkrankt \u203a Abschnitt 6.5.2). ist (falls die Pr\u00e4valenz P( A ) bekannt ist, z\n111\n6\n6.3 Wahrscheinlichkeiten in der Epidemiologie\n\u00dcbersicht 3: Rechenregeln f\u00fcr Wahrscheinlichkeiten Name des Satzes\nRechenregeln\nSatz f\u00fcr das komplement\u00e4re Ereignis A\nP( A ) = 1 \u2212 P( A )\nSatz von der totalen Wahrscheinlichkeit\nP ( A) = P ( A \u2229 B ) + P ( A \u2229 B )\nAdditionssatz\nP ( A \u222a B ) = P ( A) + P ( B ) \u2212 P ( A \u2229 B )\nA und B disjunkt P ( A \u222a B ) = P ( A) + P ( B ) A und B unabh\u00e4ngig P ( A \u222a B ) = P ( A) + P( B ) \u2212 P( A) \u22c5 P ( B )\nMultiplikationssatz\nP( A \u2229 B) = P( A | B) \u22c5 P( B)\nA und B disjunkt P ( A \u2229 B) = 0 A und B unabh\u00e4ngig P ( A \u2229 B ) = P ( A) \u22c5 P ( B )\nMathematische Herleitung des Bayes-Theorems Nach der Definition der bedingten Wahrscheinlichkeit in (6.8) ist P( A \u2229 B ) . P( A| B ) = P( B ) Der Z\u00e4hler dieses Quotienten l\u00e4sst sich \u2013 wenn man die Ereignisse A und B in der Formel (6.9) des Multiplikationssatzes vertauscht \u2013 schreiben als: P ( A \u2229 B) = P ( A) \u22c5 P ( B | A) . Analog leitet man her: P( A \u2229 B) = P( A ) \u22c5 P( B | A ) Mittels des Satzes von der totalen Wahrscheinlichkeit (6.4) ergibt sich dann f\u00fcr den Nenner des obigen Quotienten: P( B ) = P( A \u2229 B ) + P( A \u2229 B ) = P( A ) \u22c5 P( B| A ) + P( A ) \u22c5 P( B| A ) Mit diesen Ausdr\u00fccken erh\u00e4lt man f\u00fcr P( A| B ) die Formel (6.12).\n6.3\nWahrscheinlichkeiten in der Epidemiologie\nDie Epidemiologie befasst sich mit dem Auftreten von Krankheiten in einer gr\u00f6\u00dferen Population. Die Ziele der epidemiologischen Forschung sind: das Erkennen von Ursachen und Risikofaktoren von Krankheiten; das Bestimmen deren Verbreitung in der Bev\u00f6lkerung; die Untersuchung des nat\u00fcrlichen Verlaufs und relevanter prognostischer Faktoren; die Evaluation pr\u00e4ventiver und therapeutischer Ma\u00dfnahmen sowie das Schaffen von Grundlagen f\u00fcr politische Ent-\n112\nKapitel 6 \u00b7 Wahrscheinlichkeiten in der Medizin\nscheidungen. Zur Beschreibung demographischer Charakteristika werden folgende Wahrscheinlichkeiten verwendet:\n6\n\u2022 Pr\u00e4valenz (im engeren Sinne: Punktpr\u00e4valenz).. Dies ist der rela tive Krankenbestand zu einem bestimmten Zeitpunkt \u2013 also die Wahrscheinlichkeit P( K t ) f\u00fcr eine beliebige Person aus der Population, zum Zeitpunkt t erkrankt zu sein. Dieses Ma\u00df eignet sich f\u00fcr Krankheiten, die chronisch sind oder wiederholt auftreten; es wird \u00fcblicherweise im Rahmen einer Querschnittstudie bestimmt. Die Punktpr\u00e4valenz muss immer zusammen mit dem Zeitpunkt angegeben werden, auf den sie sich bezieht. Es handelt sich dabei nicht um einen Zeitpunkt im physikalischen Sinne, sondern meist um einen bestimmten Tag oder Monat. Die Kenntnis der Pr\u00e4valenz ist eine wertvolle Hilfe f\u00fcr die Bedarfsplanung im \u00d6ffentlichen Gesundheitswesen. \u2022 Periodenpr\u00e4valenz. Das Bestimmen einer Punktpr\u00e4valenz kann bei Krankheiten von sehr kurzer Dauer methodische Schwierigkeiten mit sich bringen. Dann mag es sinnvoll sein, anstelle der Punktpr\u00e4valenz eine Periodenpr\u00e4valenz zu bestimmen, die sich auf einen l\u00e4ngeren Zeitraum bezieht. Dabei werden alle Personen ber\u00fccksichtigt, die zu Beginn, w\u00e4hrend oder am Ende des Beobachtungszeitraums erkrankt waren (\u00fcblicherweise im Rahmen einer Kohortenstudie). Eine spezielle Form stellt die Lebenszeitpr\u00e4valenz dar; sie quantifiziert die Wahrscheinlichkeit einer Person, krank geboren zu werden oder einmal im Laufe des Lebens zu erkranken. \u2022 Inzidenz. Dies ist die Neuerkrankungsrate, also die Wahrschein lichkeit P ( K ) f\u00fcr eine beliebige Person, w\u00e4hrend einer Beobachtungszeit zu erkranken. Dabei geht man von einer Population aus, deren Mitglieder zu Beginn des Beobachtungszeitraumes nicht erkrankt sind. Die Inzidenz wird immer in Verbindung mit einem Zeitraum (z. B. ein bestimmtes Jahr oder die Dauer eines Klinikaufenthaltes) angegeben. Dieses Ma\u00df hat nur Aussagekraft bei Erkrankungen, die bei einer Person w\u00e4hrend der Beobachtungszeit maximal einmal auftreten. Bei l\u00e4nger andauernden Krankheiten l\u00e4sst sich die Pr\u00e4valenz aus der Inzidenz berechnen nach: Pr\u00e4valenz = Inzidenz \u00b7 durchschnittliche Dauer Diese Gleichung erkl\u00e4rt, weshalb viele chronische Krankheiten zwar eine geringe Inzidenz, aber dennoch eine hohe Pr\u00e4valenz aufweisen. W\u00e4hrend die Inzidenz angibt, wie gro\u00df das Erkrankungsrisiko f\u00fcr eine einzelne Person ist, informiert die Pr\u00e4valenz \u00fcber die Auswirkungen einer Krankheit auf die Gesamtpopulation.\n6\n113 6.3 Wahrscheinlichkeiten in der Epidemiologie\nBeispiel 6.10 Im Oktober 2003 lebten in Deutschland 39.000 HIV-positive Menschen; dies entspricht bei einer Gesamtbev\u00f6lkerung von 82 Millionen etwa 4,76 von 10.000 (Pr\u00e4valenz). Bei Asthma betr\u00e4gt die j\u00e4hrliche Inzidenz aller Kinder und Jugendlichen zwischen 6 und 16 Jahren 3/1.000; die durchschnittliche Dauer betr\u00e4gt etwa 11 Jahre. Dann l\u00e4sst sich nach obiger Formel ermitteln, dass 33 von 1.000 Personen in dieser Altersgruppe zu einem bestimmten Zeitpunkt an Asthma erkrankt sind (Pr\u00e4valenz).\n\u2022 Krankheitsspezifische Mortalit\u00e4t. Darunter versteht man die To desrate \u2013 also die Wahrscheinlichkeit P ( K \u2229 T ) , w\u00e4hrend der Beobachtungszeit an der Krankheit K zu erkranken und daran zu versterben. \u2022 Letalit\u00e4t. Die T\u00f6dlichkeitsrate der Erkrankten ist die bedingte Wahrscheinlichkeit P( T| K ) . Die Angabe der Letalit\u00e4t ist nur sinnvoll f\u00fcr Erkrankungen, deren Beginn und Ende innerhalb des Beobachtungszeitraums liegen. Nach dem Multiplikationssatz (6.9) gilt: P( K \u2229 T ) = P( K ) \u22c5 P( T | K )\n(6.13)\noder in Worten: Mortalit\u00e4t = Inzidenz \u00b7 Letalit\u00e4t Beispiel 6.11 Ignaz Semmelweis ermittelte f\u00fcr den April des Jahres 1846 in der \u00c4rzte-Abteilung des Wiener Geb\u00e4rhauses, dass 24 % der geb\u00e4renden Frauen w\u00e4hrend des Klinikaufenthaltes an Kindbettfieber erkrankten (Inzidenz) und von den Erkrankten 80 % verstarben (Letalit\u00e4t). Mit Formel (6.13) berechnet man daraus eine Mortalit\u00e4t von etwa 19 %.\n\u2022 Morbidit\u00e4t. Dieser Begriff ist in der Literatur unterschiedlich de finiert: Teilweise wird er synonym f\u00fcr Pr\u00e4valenz, teilweise synonym f\u00fcr Inzidenz verwendet. ! Die Pr\u00e4valenz, Inzidenz oder Mortalit\u00e4t sind keine absoluten H\u00e4ufigkeiz\nten, sondern Wahrscheinlichkeiten. Die Angabe der Bezugspopulation ist unbedingt erforderlich. Man stellt diese Gr\u00f6\u00dfen entweder als Prozentzahl dar oder \u2013 wenn diese sehr gering ist \u2013 als relative H\u00e4ufigkeit bezogen auf 1.000, 10.000 oder mehr Personen.\nBei Infektionskrankheiten sind au\u00dferdem folgende Wahrscheinlichkeiten interessant:\n114\nKapitel 6 \u00b7 Wahrscheinlichkeiten in der Medizin\n\u2022 Kontagionsindex. Dieser Index gibt die Wahrscheinlichkeit an, dass sich eine nicht immune Person, die mit dem Erreger in Kontakt kommt, infiziert. Er ist also ein Ma\u00df f\u00fcr die Ansteckungsf\u00e4higkeit. \u2022 Manifestationsindex. Dies ist die Wahrscheinlichkeit, mit der eine infizierte Person manifest erkrankt (die Krankheitsbereitschaft). Je kleiner dieser Index ist, desto mehr Infektionsf\u00e4lle verlaufen klinisch stumm. Beispiel 6.12 Bei Masern betr\u00e4gt der Kontagionsindex fast 100 %; der Manifestationsindex liegt bei etwa 95 %. Das hei\u00dft: Fast alle Personen, die mit dem Virus in Kontakt kommen, infizieren sich. Davon erkranken 95 % manifest, w\u00e4hrend 5 % der Infektionen klinisch stumm verlaufen.\n6\nSchlie\u00dflich sei noch angemerkt, dass all diese Ma\u00dfzahlen keineswegs Naturkonstanten sind, die \u2013 nachdem man sie einmal bestimmt hat \u2013 f\u00fcr alle Zeit ihren Wert behalten. Es handelt sich vielmehr um Gr\u00f6\u00dfen, die abh\u00e4ngig sind von den sozialen Rahmenbedingungen sowie den aktuellen diagnostischen und therapeutischen M\u00f6glichkeiten. Mit besseren diagnostischen Mitteln werden mehr Krankheitsf\u00e4lle erkannt \u2013 dadurch steigt die Inzidenz. Wenn f\u00fcr eine Krankheit eine bessere Therapie zur Verf\u00fcgung steht, werden mehr Personen \u00fcberleben \u2013 damit steigt bei chronischen Erkrankungen die Pr\u00e4valenz, w\u00e4hrend die Mortalit\u00e4t und die Letalit\u00e4t sinken. Weitere interessante Hinweise dazu findet man in [6].\n6.4\nBev\u00f6lkerungsstatistiken\n6.4.1\nSpezielle Wahrscheinlichkeiten\n\u2022 Natalit\u00e4t. Das ist die Geburtenrate (auch Geburtenziffer genannt), also der Anteil lebend geborener Kinder im Verh\u00e4ltnis zur Gesamtpopulation w\u00e4hrend eines Beobachtungszeitraums. Sie ist abh\u00e4ngig von der Altersstruktur der beobachteten Population. Ein hoher Altenanteil impliziert automatisch eine niedrige Geburtenrate. \u2022 Fertilit\u00e4tsziffer. Dieses Ma\u00df beschreibt die Fruchtbarkeitsrate (oder Fruchtbarkeitsziffer) \u2013 das ist die Wahrscheinlichkeit, dass eine Frau im geb\u00e4rf\u00e4higen Alter ein lebendes Kind zur Welt bringt (bezogen auf ein Jahr). Sie ist \u2013 im Gegensatz zur Geburtenziffer \u2013 unabh\u00e4ngig von der Altersstruktur der Population.\n6\n115 6.4 Bev\u00f6lkerungsstatistiken\n\u2022 Pearl-Index. Dies ist ein Risikoma\u00df bez\u00fcglich der Sicherheit einer Verh\u00fctungsmethode. Zu dessen Sch\u00e4tzung m\u00fcssen hinreichend viele Frauen, die eine bestimmte Verh\u00fctungsmethode anwenden, \u00fcber einen l\u00e4ngeren Zeitraum beobachtet werden. Der Index wird bestimmt, indem die Anzahl der ungewollten Schwangerschaften im Verh\u00e4ltnis zur Anzahl der beobachteten Zyklen mit dem Faktor 1.200 multipliziert wird. Er gibt somit an, wie viele von 100 Frauen in einem Jahr ungewollt schwanger werden (wobei davon ausgegangen wird, dass eine nicht-schwangere Frau zw\u00f6lf Zyklen pro Jahr hat). Dieses Ma\u00df ist im Gegensatz zur Fertilit\u00e4tsziffer keine Wahrscheinlichkeit! \u2022 Sterbeziffer. Dies ist die Gesamtmortalit\u00e4t \u2013 also der Anteil der im Beobachtungszeitraum Verstorbenen. Dar\u00fcber hinaus gibt es auch spezifische Sterbeziffern, wie Sterbeziffern f\u00fcr Neugeborene oder Sterbeziffern bezogen auf bestimmte Krankheiten. Beispiel 6.13 Im Jahre 2004 betrug die Geburtenziffer im EU-Durchschnitt 10,9 pro 1.000 Einwohner. In Deutschland wurden damals 8,5 Kinder pro 1.000 Einwohner geboren \u2013 das war eine der niedrigsten Geburtenziffern der L\u00e4nder der Europ\u00e4ischen Union. Wenn man bedenkt, dass die Sterbeziffer 10,4 Personen pro 1.000 Einwohner betrug, bedeutet das einen Bev\u00f6lkerungsr\u00fcckgang um 1,9 Personen je 1.000 Einwohner. Dieser R\u00fcckgang konnte durch Zuwanderungen teilweise ausgeglichen werden. Die Fertilit\u00e4tsrate lag bei 46 Geburten pro 1.000 Frauen im geb\u00e4rf\u00e4higen Alter.\n6.4.2\nSterbetafeln\nEine Sterbetafel beschreibt die Verteilung von Lebensdauern. Sie basiert auf folgenden H\u00e4ufigkeiten:\nA 0 : Anzahl von Lebendgeborenen innerhalb eines Beobachtungszeitraums (z. B. in einem bestimmten Jahr) A x : Anzahl der Personen, die ihren x-ten Geburtstag erleben und danach noch unbestimmte Zeit leben. Dann ist d x = A x \u2212 A x +1\n(6.14)\ndie Anzahl der Lebendgeborenen, die zwischen ihrem x-ten und (x+1)-ten Geburtstag sterben. Der Einfachheit halber wird die Lebensdauer als diskretes Merkmal aufgefasst mit den Auspr\u00e4gungen x (Anzahl der erreichten Lebensjahre) und den absoluten H\u00e4ufigkeiten dx .\n116\nKapitel 6 \u00b7 Wahrscheinlichkeiten in der Medizin\nDie Sterbeziffern sind die altersspezifischen Mortalit\u00e4tsraten qx = d x / A x ( x = 0,..., \u03c9 )\n(6.15)\nEin Wert q x dr\u00fcckt die Wahrscheinlichkeit aus, dass jemand, der seinen x-ten Geburtstag erlebt hat, vor seinem (x+1)-ten Geburtstag stirbt. Dabei ist \u03c9 das letzte in der Sterbetafel ber\u00fccksichtige Alter. Man nimmt also an: A \u03c9+1 = 0 (oft wird \u03c9 = 100 gesetzt). Die durchschnittliche Lebenszeit (oder Lebenserwartung) eines Neugeborenen l\u00e4sst sich sch\u00e4tzen als: e0 =\n6\n1 1 + 2 A0\n\u03c9\n\u00a6A\n(6.16)\nx\nx =1\nDie Lebenserwartung eines x-j\u00e4hrigen berechnet sich analog als:\nex =\n1 1 + 2 Ax\n\u03c9\n\u00a6A\n(6.17)\ny\ny = x +1\nDie Verteilungsfunktion F ( x ) gibt den relativen Anteil der Lebendgeborenen an, deren Sterbealter kleiner als x ist: F ( x) = 1 \u2212\nAx A0\nf\u00fcr 0 \u2264 x \u2264 \u03c9\n(6.18)\nMathematische Herleitung der Lebenserwartungen Die Anzahl der Personen, die x Jahre alt werden (und vor dem (x+1). Geburtstag sterben), betr\u00e4gt d x . Damit ist die mittlere Lebensdauer bei A 0 Lebendgebore\u03c9\nnen leicht herleitbar als: e0 = \u00a6 x \u22c5 d x / A 0 . x =0\nNach (6.14) und unter Ber\u00fccksichtigung von A \u03c9+1 = 0 ergibt sich daraus: \u03c9\nAx 0( A 0 \u2212 A1 ) + 1( A1 \u2212 A 2 ) + 2(A 2 \u2212 A 3 ) + ... + \u03c9(A \u03c9 \u2212 A \u03c9+1 ) \u00a6 = x =1 e0 = A0 A0\n\u00dcblicherweise wird zu e0 der Term \u00bd addiert, da man annimmt, dass die Lebensdauer eines Menschen, der im Jahr nach seinem x-ten Geburtstag stirbt, durchschnittlich x + 1 / 2 betr\u00e4gt. Der Anteil der Lebendgeborenen, die maximal das Alter x erreichen, ist\nx \u22121\n\u00a6d i =0\ni\n/ A 0 = ( A 0 \u2212 A x ) / A 0 = 1 \u2212 A x / A 0 . Daraus folgt (6.18).\n117\n6\n6.4 Bev\u00f6lkerungsstatistiken\nTabelle 6.1: Sterbetafel aus den Jahren 1901/10, entnommen aus dem Statistischen Jahrbuch der Bundesrepublik Deutschland. Die Tafel enth\u00e4lt folgende Angaben: Anzahl A x der Personen, die das Alter x erreichen, Sterbeziffern qx \u22c51000 und Lebenserwartung e x in Jahren.\nx 0 1 2 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90\nm\u00e4nnliche Bev\u00f6lkerung bezogen auf 100.000 lebend geborene Personen Ax qx \u22c51000 ex 100.000 202,34 44,82 79.766 39,88 55,12 76.585 14,92 56,39 74.211 5,28 55,15 72.827 2,44 51,16 72.007 2,77 46,71 70.647 5,04 42,56 68.881 5,13 38,59 67.092 5,56 34,55 65.104 6,97 30,53 62.598 9,22 26,64 59.405 12,44 22,94 55.340 16,93 19,43 50.186 23,57 16,16 43.807 32,60 13,14 36.079 47,06 10,40 27.136 69,36 7,99 17.586 106,40 5,97 8.987 157,87 4,38 3.212 231,60 3,18 683 320,02 2,35\nweibliche Bev\u00f6lkerung bezogen auf 100.000 lebend geborene Personen Ax qx \u22c51000 ex 100.000 170,48 48,33 82.952 38,47 57,20 79.761 14,63 58,47 77.334 5,31 57,27 75.845 2,56 53,35 74.887 3,02 49,00 73.564 4,22 44,84 71.849 5,37 40,84 69.848 5,97 36,94 67.679 6,86 33,04 65.283 7,71 29,16 62.717 8,54 25,25 59.812 11,26 21,35 55.984 16,19 17,64 50.780 24,73 14,17 43.540 39,60 11,09 34.078 62,06 8,45 23.006 98,31 6,30 12.348 146,50 4,65 4.752 217,39 3,40 1.131 295,66 2,59\nDie Sterbetafel in Tabelle 6.1 beinhaltet \u2013 getrennt f\u00fcr m\u00e4nnliche und weibliche Personen \u2013 die Lebenserwartungen zu Beginn des 20. Jahrhunderts im damaligen deutschen Reich. Bei neueren Sterbetafeln sind die Sterbeziffern und Lebenserwartungen nicht alle exakt (da einige Personen, deren Lebenserwartung aufgelistet ist, noch leben). Sie werden deshalb aufgrund von Erfahrungswerten aus vergangenen Jahren gesch\u00e4tzt.\n118\nKapitel 6 \u00b7 Wahrscheinlichkeiten in der Medizin\n6.5\nDiagnostische Tests\n6.5.1\nDie G\u00fctekriterien eines diagnostischen Tests\nDiagnostische Tests \u2013 wie z. B. der HIV-Test \u2013 werden benutzt, um gr\u00f6\u00dfere Sicherheit bez\u00fcglich des Krankheitsstatus eines Patienten zu gewinnen. Im einfachsten Fall sind nur zwei Testergebnisse m\u00f6glich. Von einem guten Test erwartet man:\n\u0177 ein positives Ergebnis bei einer erkrankten Person und \u0177 ein negatives Ergebnis bei einer nicht-erkrankten Person.\n6\nSeien nun T+ und T\u2212 die Ereignisse, dass das Testergebnis positiv bzw. negativ ist; K und K seien die Ereignisse, dass die zu untersuchende Krankheit vorliegt bzw. nicht vorliegt. Die G\u00fcte eines diagnostischen Tests wird quantifiziert durch:\n\u2022 Sensitivit\u00e4t. Dies ist die bedingte Wahrscheinlichkeit P (T+ | K ) , dass der Test bei einer kranken Person richtig (also positiv) reagiert. \u2022 Spezifit\u00e4t. Darunter versteht man die bedingte Wahrscheinlich keit P(T\u2212 | K ) , dass eine nicht-erkrankte Person ein richtiges (also negatives) Testergebnis erh\u00e4lt. Im Idealfall \u2013 wenn alle Testergebnisse richtig sind \u2013 nehmen beide Wahrscheinlichkeiten den Wert 1 an. In der Praxis muss man leider damit rechnen, dass sich hin und wieder ein falscher Befund ergibt. Wenn der Test die Krankheit eines Patienten \u00fcbersieht, erh\u00e4lt man ein falsch negatives Ergebnis. Die Wahrscheinlichkeit daf\u00fcr ergibt sich aus der Sensitivit\u00e4t. Da n\u00e4mlich T\u2212 und T+ komplement\u00e4re Ereignisse sind, berechnet man mit (6.2): P (T\u2212 | K ) = 1 \u2212 P (T+ | K )\n(6.19)\nIn analoger Weise l\u00e4sst sich aus der Spezifit\u00e4t die Wahrscheinlichkeit f\u00fcr ein falsch positives Ergebnis ermitteln:\nP(T+ | K ) = 1 \u2212 P(T\u2212 | K )\n(6.20)\n6\n119 6.5 Diagnostische Tests\nBeispiel 6.14 Ein HIV-Test habe eine Sensitivit\u00e4t von 99% und eine Spezifit\u00e4t von 99,5%. Dann werden 99% der infizierten und 99,5% der nicht-infizierten Personen richtig klassifiziert. Die Wahrscheinlichkeit, dass eine infizierte Person f\u00e4lschlicherweise ein negatives Ergebnis erh\u00e4lt, ist nach (6.19) 1%. Die Wahrscheinlichkeit, dass sich bei einer nicht-infizierten Person ein falsch positives Ergebnis ergibt, berechnet sich nach (6.20) als 0,5%. Wenn dieser Test bei einer Population von 100.000 homosexuellen M\u00e4nnern (Pr\u00e4valenz = 0,001) angewandt wird, erwartet man theoretisch folgende H\u00e4ufigkeiten: positiver Befund negativer Befund infiziert 99 1 100 nicht infiziert 500 99.400 99.900 599 99.401 100.000 Nur etwa 1/6 der positiven Ergebnisse ist auf eine Infektion zur\u00fcckzuf\u00fchren; der Rest ist falsch positiv. Die negativen Befunde sind dagegen fast alle richtig.\n6.5.2\nVorhersagewerte\nF\u00fcr den behandelnden Arzt und die betroffenen Patienten sind nicht so sehr die Sensitivit\u00e4t und die Spezifit\u00e4t als vielmehr die Vorhersagewerte (oder pr\u00e4diktiven Werte) interessant \u2013 das sind die Wahrscheinlichkeiten, dass das Testergebnis den richtigen Krankheitsstatus anzeigt. Unter dem positiven Vorhersagewert versteht man die bedingte Wahrscheinlichkeit P ( K | T+ ) ; der negative Vorhersagewert ist die bedingte Wahrscheinlichkeit P ( K | T\u2212 ) . Mit dem BayesTheorem (6.12) leitet man her: P( K|T+ ) =\nP( K ) \u22c5 P( T+| K ) P( K ) \u22c5 P( T+ | K ) + P( K ) \u22c5 P( T+ | K )\n(6.21)\nP( K |T\u2212 ) =\nP( K ) \u22c5 P( T\u2212| K ) P( K ) \u22c5 P( T\u2212 | K ) + P( K ) \u22c5 P( T\u2212 | K )\n(6.22)\nW\u00e4hrend die Pr\u00e4valenz P( K ) die Wahrscheinlichkeit bezeichnet, erkrankt zu sein, bevor das Testergebnis bekannt ist, ist der positive Vorhersagewert die Wahrscheinlichkeit, erkrankt zu sein, nachdem das positive Ergebnis vorliegt. Deshalb wird die Pr\u00e4valenz auch \u201eapriori-Wahrscheinlichkeit\u201c genannt, w\u00e4hrend der positive Vorhersagewert als \u201ea-posteriori-Wahrscheinlichkeit\u201c bezeichnet wird.\n120\n6\nKapitel 6 \u00b7 Wahrscheinlichkeiten in der Medizin\nBeispiel 6.15 Wir greifen zur\u00fcck auf den HIV-Test in Beispiel 6.14 (Sensitivit\u00e4t 99%, Spezifit\u00e4t 99,5%) und betrachten die Risikogruppe \u201ehomosexuelle M\u00e4nner\u201c (Pr\u00e4valenz 0,001). F\u00fcr den positiven Vorhersagewert berechnet man nach (6.21): 0,001 \u22c5 0,99 P ( K | T+ ) = = 0,165 0,001 \u22c5 0,99 + 0,999 \u22c5 0,005 Dieser Wert gibt die a-posteriori-Wahrscheinlichkeit an, dass eine Person mit einem positiven Testergebnis auch tats\u00e4chlich infiziert ist. F\u00fcr den negativen Vorhersagewert berechnet man nach (6.22): 0,999 \u22c5 0,995 P ( K | T\u2212 ) = = 0,99999 0,999 \u22c5 0,995 + 0,001 \u22c5 0,01 Das bedeutet, dass man bei einem negativen Testergebnis fast sicher sein kann, dass die betreffende Person nicht infiziert ist. Diese Werte entsprechen den relativen H\u00e4ufigkeiten, die sich in Beispiel 6.14 ergeben: 99 99.400 = 0,165 und P ( K | T\u2212 ) = = 0,99999 P ( K | T+ ) = 599 99.401\nDer geringe positive und der hohe negative Vorhersagewert in Beispiel 6.15 sind keine Besonderheit, sondern eher typisch f\u00fcr einen diagnostischen Test. Ein positiver Befund kann sich n\u00e4mlich auch bei gesunden Personen ergeben aufgrund von Einfl\u00fcssen, die in keinem Zusammenhang mit der relevanten Krankheit stehen. Deshalb ist bei niedriger Pr\u00e4valenz (wenn der Test bei weitaus mehr gesunden als bei kranken Personen durchgef\u00fchrt wird) oft nur ein kleiner Teil der positiven Befunde auf die zu diagnostizierende Krankheit zur\u00fcckzuf\u00fchren. Die negativen Befunde sind dagegen fast ausschlie\u00dflich gesunden Personen zuzuordnen; nur ein sehr kleiner Anteil ist falsch negativ. Beispiel 6.16 F\u00fcr den HIV-Test ergeben sich in Abh\u00e4ngigkeit von der Pr\u00e4valenz folgende Vorhersagewerte: positiver negativer Population Pr\u00e4valenz Vorhersagewert Vorhersagewert ohne Risiko 0,00001 0,00198 1,00000 (Rechenbeispiel) 0,0001 0,01942 1,00000 homosexuelle M\u00e4nner 0,001 0,16541 0,99999 Drogenabh\u00e4ngige 0,01 0,66667 0,99990 (Rechenbeispiel) 0,1 0,95652 0,99888\n121\n6\n6.5 Diagnostische Tests\nAn Beispiel 6.16 wird deutlich, dass die Vorhersagewerte von der Pr\u00e4valenz abh\u00e4ngen. Dies kann bei klinischen Anwendungen zu Problemen f\u00fchren, da ein exakter Wert f\u00fcr die Pr\u00e4valenz im Einzelfall oft gar nicht bekannt ist. Bei den meisten Krankheiten ist die Pr\u00e4valenz gl\u00fccklicherweise gering \u2013 was sich jedoch nachteilig auf den positiven Vorhersagewert auswirkt. Aus Beispiel 6.16 geht hervor, dass dieser insbesondere bei kleiner Pr\u00e4valenz extrem niedrig sein kann. Nur bei besonderen Risikogruppen oder in Spezialkliniken sind die Pr\u00e4valenz und damit auch die Aussagekraft eines diagnostischen Tests h\u00f6her. Die negativen Vorhersagewerte haben dagegen alle einen Wert, der nahe bei 1 liegt. W\u00e4hrend also bei einem negativen Ergebnis die Krankheit mit hoher Wahrscheinlichkeit ausgeschlossen werden kann, ist ein positiver Befund weitaus schwieriger zu bewerten. In jedem Fall muss der Arzt ihn ernst nehmen; er sollte sich jedoch h\u00fcten, voreilig falsche Schlussfolgerungen zu ziehen. Das Testergebnis ist lediglich ein Hinweis darauf, dass die Krankheit vorliegen k\u00f6nnte. Um eine sichere Diagnose zu erstellen, bedarf es weiterer Untersuchungen. Leider sind sich viele Anwender dar\u00fcber nicht im Klaren und interpretieren ein positives Testergebnis intuitiv so, als seien Zweifel an der Erkrankung eines Patienten quasi ausgeschlossen. Sie folgern naiv, dass \u2013 wenn mit 99%-iger Wahrscheinlichkeit aus der Bedingung \u201eKrankheit vorhanden\u201c die Aussage \u201eTestergebnis positiv\u201c folgt \u2013 auch der Umkehrschluss gilt: dass also aus einem positiven Ergebnis mit 99%-iger Sicherheit auf die Krankheit geschlossen werden kann. Dabei unterliegen sie jedoch einer kognitiven T\u00e4uschung \u2013 sei es aufgrund von Selbst\u00fcbersch\u00e4tzung, Bequemlichkeit oder einfach nur wegen mangelnder Erfahrung im Umgang mit Wahrscheinlichkeiten (siehe dazu [3] und [8]). Um ein Testergebnis zu beurteilen, bedarf es jedoch weniger Intuition als vielmehr fachlicher F\u00e4higkeiten und solider Statistik-Kenntnisse. Merke \u0177 Die Vorhersagewerte sind abh\u00e4ngig von der Pr\u00e4valenz. \u0177 Der positive Vorhersagewert kann bei geringer Pr\u00e4valenz sehr niedrig sein \u2013 auch dann, wenn die Sensitivit\u00e4t und Spezifit\u00e4t hoch sind. ! In einigen Publikationen taucht der Begriff \u201eaccuracy\u201c im Zusammenz\nhang mit diagnostischen Tests auf. Dies bezeichnet die Wahrscheinlichkeit, dass eine beliebige Person, die sich dem Test unterzieht, einen korrekten Befund erh\u00e4lt. Allerdings ist dieses Ma\u00df f\u00fcr praktische Anwendungen wenig geeignet, da es von der Pr\u00e4valenz abh\u00e4ngt und keine Information bez\u00fcglich der Vorhersagewerte beinhaltet.\n122\nKapitel 6 \u00b7 Wahrscheinlichkeiten in der Medizin\n\u00dcbersicht 4: Kenngr\u00f6\u00dfen diagnostischer Tests formelle Schreibweise\nTestergebnis richtig positiv Testergebnis falsch negativ Testergebnis richtig negativ\nBezeichnung der Wahrscheinlichkeit Pr\u00e4valenz (a-priori-Wahrscheinlichkeit) Sensitivit\u00e4t --Spezifit\u00e4t\nTestergebnis falsch positiv Krankheit liegt vor, falls Testergebnis positiv\n--positiver Vorhersagewert (a-posteriori-Wahrscheinl.)\nP( T+| K )\nKrankheit liegt nicht vor, falls Testergebnis negativ\nnegativer Vorhersagewert\nP( K |T\u2212 )\nEreignis Krankheit liegt vor\n6\nP( K ) P( T+ | K ) P( T\u2212| K ) P( T\u2212| K ) P( K|T+ )\n! Weitere Hinweise zu diagnostischen Tests finden sich in Kapitel 15. z\n7\nDiskrete Verteilungen 7.1\nDiskrete Zufallsvariable 125\n7.1.1\nDie Bedeutung einer Zufallsvariablen 125\n7.1.2\nWahrscheinlichkeiten 126\n7.1.3\nLageparameter 127\n7.1.4\nStreuungsparameter 128\n7.2\nDie Binomialverteilung 129\n7.2.1\nDas Bernoulli-Experiment 129\n7.2.2\nEigenschaften der Binomialverteilung 130\n7.2.3\nDie symmetrische Binomialverteilung 134\n7.3\nAndere diskrete Verteilungen 136\n7.3.1\nDie Poissonverteilung 136\n7.3.2\nDie Polynomialverteilung 138\n7.3.3\nDie negative Binomialverteilung 139\n7.3.4\nDie hypergeometrische Verteilung 140\n7.3.5\nDie diskrete Gleichverteilung 141\n125\n7\n7.1 Diskrete Zufallsvariable\nIn diesem und dem n\u00e4chsten Kapitel werden einige Verteilungen behandelt, die f\u00fcr die Biowissenschaften von Bedeutung sind. H\u00e4ufigkeitsverteilungen, die bei empirischen Studien beobachtet werden, lassen sich oft \u00fcber eine solche Verteilung approximieren und in ihren wesentlichen Eigenschaften beschreiben. Zun\u00e4chst wird in Abschnitt 7.1 der Begriff der Zufallsvariablen eingef\u00fchrt, und es wird erl\u00e4utert, wie eine Verteilung mittels statistischer Kenngr\u00f6\u00dfen beschrieben werden kann. Danach werden die Binomialverteilung und andere diskrete Verteilungen vorgestellt. Die Normalverteilung und weitere stetige Verteilungen werden in Kapitel 8 besprochen.\n7.1\nDiskrete Zufallsvariable\n7.1.1\nDie Bedeutung einer Zufallsvariablen\nDer Begriff des Merkmals ist fundamental f\u00fcr die deskriptive Statistik. Die Beschreibung einer Stichprobe beruht im Wesentlichen auf den H\u00e4ufigkeiten der Merkmalsauspr\u00e4gungen und auf statistischen Kenngr\u00f6\u00dfen wie etwa Mittelwert und Standardabweichung. In der Wahrscheinlichkeitsrechnung benutzt man anstelle des konkreten Begriffs \u201eMerkmal\u201c den abstrakten Begriff \u201eZufallsvariable\u201c. Theoretisch handelt es sich dabei um eine Funktion, die jedem m\u00f6glichen Ergebnis eines Zufallsexperiments eine reelle Zahl zuordnet. Diese Zahlenwerte entsprechen den Merkmalsauspr\u00e4gungen und werden mit Kleinbuchstaben vom Ende des Alphabets (z. B. xi ) symbolisiert. Die Zufallsvariable selbst bezeichnet man in der Regel mit dem passenden Gro\u00dfbuchstaben (z. B. X ). Es ist f\u00fcr das Verst\u00e4ndnis der Wahrscheinlichkeitsrechnung sehr hilfreich, sich die Analogie der Begriffe \u201eMerkmal\u201c und \u201eZufallsvariable\u201c immer wieder vor Augen zu halten. Die xi werden Realisationen (oder Realisierungen) der Zufallsvariablen X genannt. Bei quantitativen Merkmalen sind die xi die Mess- oder Z\u00e4hlwerte; bei qualitativen Merkmalen entsprechen die \u203a xi den numerischen Codierungen der einzelnen Auspr\u00e4gungen (z Beispiel 2.5). Ebenso wie ein Merkmal l\u00e4sst sich auch eine Zufallsvariable einem bestimmten Skalenniveau zuordnen; ferner lassen sich diskrete und stetige Zufallsvariablen unterscheiden. Dieses Kapitel 7 befasst sich mit diskreten Zufallsvariablen und deren Verteilungen.\n126\nKapitel 7 \u00b7 Diskrete Verteilungen\n7.1.2\nWahrscheinlichkeiten\nDiskrete Zufallsvariable ergeben sich bei der Beobachtung von Zufallsexperimenten, bei denen abz\u00e4hlbar viele Ergebnisse m\u00f6glich sind. So lassen sich beispielsweise die Merkmale \u201eM\u00fcnzwurf\u201c, \u201eBlutgruppe\u201c oder die Anzahl der Schwangerschaften einer Frau durch diskrete Zufallsvariablen beschreiben. Ein Elementarereignis A l\u00e4sst sich darstellen durch X = xi (das hei\u00dft: Die Zufallsvariable X nimmt den Wert xi an). F\u00fcr die Wahrscheinlichkeit P ( X = xi ) sind folgende Schreibweisen gebr\u00e4uchlich: P ( A) = P ( X = xi ) = P( xi ) = pi\n7\n(7.1)\nBeispiel 7.1 Beim M\u00fcnzwurf gibt es zwei M\u00f6glichkeiten: Wappen oder Zahl. A sei das Ereignis \u201eZahl\u201c. Dieses Merkmal l\u00e4sst sich durch eine diskrete Zufallsvariable X beschreiben, die die beiden Werte 0 (Wappen) oder 1 (Zahl) annehmen kann. Wenn man mehrmals nacheinander eine M\u00fcnze wirft, bedeutet xi = 1 , dass sich beim i-ten Wurf eine Zahl ergeben hat; das Ereignis \u201eWappen\u201c wird beschrieben durch xi = 0 . Dabei gilt: P( A) = P( X = 1) = 1/ 2 .\nDie Wahrscheinlichkeiten aller Elementarereignisse (deren Anzahl sei k) summieren sich \u2013 ebenso wie die relativen H\u00e4ufigkeiten \u2013 zu 1: k\nk\n\u00a6 p = \u00a6 f (x ) = 1 i\ni =1\ni\n(7.2)\ni =1\nDie Wahrscheinlichkeitsfunktion f ( x ) ordnet jedem Wert xi dessen Wahrscheinlichkeit pi zu; sie ist definiert als: p f\u00fcr x = xi (i = 1,...k ) f ( x) = \u00ae i \u00af0 sonst\n(7.3)\nDie Formel (7.2) entspricht dem 2. Axiom von Kolmogoroff, nach dem die Wahrscheinlichkeit des Ereignisraums gleich 1 ist. Die Verteilungsfunktion F ( x) = P ( X \u2264 x) einer diskreten Zufallsvariablen (die mindestens ordinal skaliert sein muss) gibt die Wahrscheinlichkeit an, dass die Zufallsvariable X einen Wert annimmt, der kleiner als x oder gleich x ist. Man erh\u00e4lt die Funktionswerte F ( x ) durch \u203a Beispiel 7.3). Aufaddieren der Wahrscheinlichkeiten pi (z\n7\n127 7.1 Diskrete Zufallsvariable\n7.1.3\nLageparameter\n\u2022 Erwartungswert. Das bekannteste Lagema\u00df einer Stichprobe ist der Mittelwert; das Analogon zur Charakterisierung einer Grundgesamtheit wird Erwartungswert genannt. W\u00e4hrend die Parameter einer Stichprobe gew\u00f6hnlich mit lateinischen Buchstaben dargestellt werden, werden die Parameter einer Grundgesamtheit mit griechischen Buchstaben bezeichnet. So wird der Erwartungswert mit \u00b5 (sprich: m\u00fc) symbolisiert; dies entspricht dem lateinischen m. Bei einer diskreten Zufallsvariablen mit k m\u00f6glichen Realisationen ist \u00b5 definiert als: k\n\u00b5 = \u00a6 xi \u22c5 pi\n(7.4)\ni =1\nDer Erwartungswert von X wird auch mit E( X ) , EX oder \u00b5 x bezeichnet. Diese Schreibweisen bevorzugt man, wenn der Variablenname X hervorgehoben werden soll. Zwei unmittelbar einleuchtende Rechenregeln seien an dieser Stelle genannt: E ( aX + b) = a \u22c5 EX + b\n(7.5)\nn\nE ( X 1 + ... + X n ) = \u00a6 EX i\n(7.6)\ni =1\nDie Gleichung (7.6) beschreibt die Additivit\u00e4t der Erwartungswerte. ! Der Begriff des Erwartungswertes wurde bereits im Jahr 1657 vom niez\nderl\u00e4ndischen Mathematiker Christiaan Huygens in dessen Buch \u201eDe Ratiociniis in Alea Ludo\u201c eingef\u00fchrt. Dieses Werk war das erste gedruckte Lehrbuch der Wahrscheinlichkeitsrechnung und hatte gro\u00dfen Einfluss auf die weitere Entwicklung dieses Gebietes.\nAbgesehen von den Begriffen \u201eMittelwert\u201c bzw. \u201eErwartungswert\u201c stimmen bei den anderen Parametern die Bezeichnungen f\u00fcr die Stichprobe und die Grundgesamtheit weitgehend \u00fcberein. ~ (sprich: m\u00fc Schlange) einer \u2022 Median und Quantile. Der Median \u00b5 Grundgesamtheit ist durch die Verteilungsfunktion bestimmt. Bei einer diskreten Zufallsvariablen ist der Median die kleinste Zahl ~ ) \u2265 0,5 . Analog dazu ist ein zwischen 0 und k, f\u00fcr die gilt: F (\u00b5 ~ beliebiges \u03b1-Quantil \u00b5 \u03b1 (mit 0 < \u03b1 < 1 ) definiert als die kleinste ~ ) \u2265 \u03b1 . So ist etwa der Median in Beispiel 7.3 gleich 2. Zahl mit F (\u00b5 \u03b1\n128\nKapitel 7 \u00b7 Diskrete Verteilungen\n\u00dcbersicht 5: Analoge Begriffe aus der deskriptiven Statistik und der Wahrscheinlichkeitsrechnung\n7\ndeskriptive Statistik\nWahrscheinlichkeitsrechnung\nMerkmal Auspr\u00e4gungsliste Merkmalsauspr\u00e4gung ermittelter Merkmalswert der Beobachtungseinheit i relative H\u00e4ufigkeit hi empirische Verteilungsfunktion F\u02c6 ( x) Mittelwert x\nZufallsvariable X Ereignisraum \u2126 Elementarereignis A Realisation xi der Zufallsvariablen Wahrscheinlichkeit pi Verteilungsfunktion F ( x) Erwartungswert \u00b5\n\u2022 Modus. Der Modus der Grundgesamtheit ist der Wert mit der gr\u00f6\u00dften Wahrscheinlichkeit. Bei bi- oder multimodalen Verteilungen existieren eventuell mehrere Modalwerte. 7.1.4\nStreuungsparameter\n\u2022 Varianz. In der deskriptiven Statistik ist die empirische Varianz definiert als die mittlere quadratische Abweichung der StichprobenDaten vom Mittelwert. Das Analogon in der Wahrscheinlichkeitsrechnung ist der Erwartungswert der quadratischen Abweichung der Zufallsvariablen X vom Erwartungswert \u00b5 : \u03c32 = E ( ( X \u2212 \u00b5 ) 2 ) = E ( X 2 ) \u2212 \u00b5 2\n(7.7)\nDas griechische \u03c3 (Sigma) entspricht dem lateinischen s. F\u00fcr diskrete Zufallsvariable ist die Varianz \u00e4quivalent zu: k\n\u03c32 = \u00a6 ( xi \u2212 \u00b5) 2 pi\n(7.8)\ni =1\nWegen der quadratischen Dimension einer Varianz gilt:\nVar( aX + b) = a 2 \u22c5 Var(X )\n(7.9)\nDaraus folgt sofort (f\u00fcr a = 0 ): Var(b) = 0 . Dies beinhaltet die triviale Feststellung: Eine Konstante hat keine Varianz. Analog zur deskriptiven Statistik erh\u00e4lt man die Standardabweichung \u0131 aus der Wurzel der Varianz. F\u00fcr verh\u00e4ltnisskalierte Zufallsvariable ist der\n7\n129 7.2 Die Binomialverteilung\nVariationskoeffizient definiert als der Quotient \u03c3 / \u00b5 . F\u00fcr die Summe zweier Zufallsvariablen gilt allgemein: Var( X + Y ) = Var( X ) + Var(Y ) + 2 \u22c5 Cov( X , Y )\n(7.10)\nDabei gilt f\u00fcr die Kovarianz: Cov( X , Y ) = E ( ( X \u2212 \u00b5 x ) \u22c5 (Y \u2212 \u00b5 y ) ) = E ( XY ) \u2212 \u00b5 x \u22c5 \u00b5 y\n(7.11)\nDie Kovarianz ist 0, wenn X und Y unabh\u00e4ngige Variable sind. F\u00fcr die Summe von mehreren unabh\u00e4ngigen Zufallsvariablen gilt: n\nn\ni =1\ni =1\nVar( \u00a6 X i ) = \u00a6 Var(X i )\n(7.12)\nMathematische Herleitung der Rechenregeln zur Varianz Aus der Definition der Varianz ergibt sich unter Ber\u00fccksichtigung der Rechenregeln (7.5) und (7.6) die Formel (7.7): \u03c32 = E (( X \u2212 \u00b5 )2 ) = E ( X 2 \u2212 2\u00b5 \u22c5 X + \u00b5 2 ) = E ( X 2 ) \u2212 2\u00b5 \u22c5 E ( X ) + \u00b5 2 = = E ( X 2 ) \u2212 2\u00b5 2 + \u00b5 2 = E ( X 2 ) \u2212 \u00b5 2\nDie Formel (7.8) folgt dann direkt aus (7.4), indem man xi durch ( xi \u2212 \u00b5) 2 ersetzt. F\u00fcr die Variable aX + b erh\u00e4lt man aus der Definition der Varianz in (7.7) die Formel (7.9): Var (aX + b) = E (aX + b \u2212 a\u00b5 \u2212 b) 2 = a 2 \u22c5 E ( X \u2212 \u00b5) 2 = a 2 \u22c5 Var ( X ) i Weitere Kenngr\u00f6\u00dfen zur Beschreibung einer Verteilung, n\u00e4mlich die z Formma\u00dfe, werden in Abschnitt 8.1.3 erl\u00e4utert.\n7.2\nDie Binomialverteilung\n7.2.1\nDas Bernoulli-Experiment\nDie Binomialverteilung basiert auf einem Zufallsexperiment einfachster Art, bei dem nur zwei Ausg\u00e4nge m\u00f6glich sind. Man bezeichnet dies als ein Bernoulli-Experiment, benannt nach dem Schweizer Mathematiker Jakob Bernoulli (1654-1705). Generell lassen sich alle Experimente, bei denen ein Alternativmerkmal beobachtet wird (z. B. der M\u00fcnzwurf oder die Bestimmung des Geschlechts einer Person) als ein Bernoulli-Experiment auffassen. Die-\n130\nKapitel 7 \u00b7 Diskrete Verteilungen\nses Modell ist anwendbar bei allen qualitativen und quantitativen Merkmalen, deren Auspr\u00e4gungen in zwei Gruppen oder Klassen eingeteilt sind (z. B. Blutgruppe A oder andere Blutgruppe, Laborwert normal oder pathologisch). Um ein Bernoulli-Experiment formal zu beschreiben, betrachten wir zwei komplement\u00e4re Ereignisse A und A . Wir f\u00fchren eine Zufallsvariable X ein, welche die Werte 1 (falls A eintritt) und 0 (falls \u203a Beispiel 7.1). Die dazugeh\u00f6renden A eintritt) annehmen kann (z Wahrscheinlichkeiten seien:\nP( A) = P( X = 1) = p P( A) = P( X = 0) = q Nach Formel (6.2) erhalten wir f\u00fcr die Wahrscheinlichkeit des komplement\u00e4ren Ereignisses A : q = 1\u2212 p\n7\n(7.13)\nDie Wahrscheinlichkeit p kann \u2013 wie bereits in Abschnitt 6.2.2 erw\u00e4hnt \u2013 empirisch gesch\u00e4tzt werden, indem man ein Bernoulli-Experiment hinreichend oft wiederholt und dann die relative H\u00e4ufigkeit des Ereignisses A als Sch\u00e4tzwert f\u00fcr p verwendet. \u203a Abschnitt 8.3.2) fini Diese Variante des Gesetzes der gro\u00dfen Zahlen (z z det sich bereits in Bernoullis Schrift \u201eArs conjectandi\u201c, die erst nach seinem Tod im Jahr 1713 ver\u00f6ffentlicht wurde. Das Neue und Besondere an diesem Werk ist die Idee, die Statistik auf wirtschaftliche und gesellschaftliche Probleme anzuwenden. 7.2.2\nEigenschaften der Binomialverteilung\nWenn ein Bernoulli-Experiment mehrfach wiederholt wird und diese Wiederholungen unabh\u00e4ngig voneinander sind, bezeichnet man dies als einen Bernoulli-Prozess. Wenn beispielsweise bei einer Wurfserie mit einem W\u00fcrfel die Anzahl der 6er gez\u00e4hlt wird, oder wenn eine bestimmte Anzahl von Personen danach untersucht wird, wie h\u00e4ufig \u201eRhesusfaktor positiv\u201c vorkommt, dann handelt es sich bei diesen Beobachtungsserien formal um Bernoulli-Prozesse. Ein solcher Prozess ist folgenderma\u00dfen charakterisiert:\n\u0177 Es werden n unabh\u00e4ngige Bernoulli-Experimente durchgef\u00fchrt,\ndie durch gleich verteilte Zufallsvariable X i ( i = 1,..., n ) beschrieben werden.\n7\n131 7.2 Die Binomialverteilung\n\u0177 Jedes X i nimmt mit der Wahrscheinlichkeit p den Wert 1 (bei\nEintreten des Ereignisses A) und mit der Wahrscheinlichkeit q = 1 \u2212 p den Wert 0 (bei Eintreten von A ) an. \u0177 Dann quantifiziert die Zufallsvariable X = X 1 + X 2 + ... + X n , wie h\u00e4ufig bei n Experimenten das Ereignis A eingetreten ist. X wird durch eine Binomialverteilung beschrieben. Eine binomialverteilte Zufallsvariable X ist durch die Parameter n und p eindeutig festgelegt und wird mit X ~ B (n, p ) angegeben. Der Erwartungswert und die Varianz sind berechenbar als: n\nE ( X ) = \u00a6 EX i = n \u22c5 p\n(7.14)\ni =1\nn\nVar( X ) = \u00a6 Var( X i ) = n \u22c5 p \u22c5 q\n(7.15)\ni =1\nBeispiel 7.2 Eine Klausur in Biomathematik bestehe aus 10 Aufgaben. Es sind jeweils f\u00fcnf Antworten vorgegeben, von denen genau eine richtig ist. Wenn ein Student mangels solider Statistik-Kenntnisse darauf angewiesen ist, die richtigen Antworten zu erraten, l\u00e4sst sich dieses Vorgehen formal ansehen als einen Prozess bestehend aus n = 10 Bernoulli-Experimenten mit den m\u00f6glichen Ereignissen A (richtig raten) und A (falsch raten). Die Wahrscheinlichkeiten sind: p = P ( A) = 1 / 5 = 0,2 und q = P (A ) = 4 / 5 = 0,8 . X ~ B (10;0,2) sei die Zufallsvariable, die die Anzahl der richtig gel\u00f6sten Aufgaben angibt. F\u00fcr den Erwartungswert und die Varianz ergeben sich: \u00b5 = 10 \u22c5 0, 2 = 2, 0 nach (7.14) \u03c32 = 10 \u22c5 0, 2 \u22c5 0, 8 = 1, 6\nnach (7.15)\nEtwas komplizierter ist die Berechnung der Wahrscheinlichkeiten. Die Zufallsvariable X ~ B (n, p ) kann theoretisch jede nat\u00fcrliche Zahl zwischen 0 und n annehmen. Diese Zahl gibt an, wie oft bei n Zufallsexperimenten das Ereignis A eingetreten ist. Die entsprechenden Wahrscheinlichkeiten berechnet man nach folgender Formel: \u00a7n\u00b7 P ( X = k ) = \u00a8 \u00b8 \u22c5 p k \u22c5 q n \u2212 k f\u00fcr k = 0,..., n \u00a9k \u00b9\n(7.16)\n132\nKapitel 7 \u00b7 Diskrete Verteilungen\n\u00a7n\u00b7 Der Ausdruck \u00a8\u00a8 \u00b8\u00b8 (sprich: n \u00fcber k) wird als Binomialkoeffizient \u00a9k \u00b9 bezeichnet. Er quantifiziert die Anzahl der M\u00f6glichkeiten, aus einer Menge von n Elementen genau k Elemente auszuw\u00e4hlen, und ist folgenderma\u00dfen definiert:\n\u00a7n\u00b7 n! 1 \u22c5 2 \u22c5 ... \u22c5 n = \u00a8k \u00b8 = \u00a9 \u00b9 k !\u22c5 ( n \u2212 k )! (1 \u22c5 ... \u22c5 k ) \u22c5 ((1 \u22c5 ... \u22c5 ( n \u2212 k ))\n(7.17)\nDer Z\u00e4hler dieses Ausdrucks n! (sprich: n Fakult\u00e4t) bezeichnet das Produkt, das aus allen nat\u00fcrlichen Zahlen von 1 bis n gebildet wird. Entsprechend werden k! und (n \u2212 k )! im Nenner berechnet.\n7\nMathematische Herleitung der Parameter der Binomialverteilung Wir betrachten den einfachsten Fall n = 1 , also ein einzelnes Bernoulliexperiment mit zwei m\u00f6glichen Ergebnissen A bzw. A und den Wahrscheinlichkeiten p bzw. q. Nach (7.4) und (7.8) berechnet man: \u00b5 = 1\u22c5 p + 0 \u22c5 q = p \u03c3 2 = (1 \u2212 p ) 2 \u22c5 p + (0 \u2212 p ) 2 \u22c5 q = q 2 \u22c5 p + p 2 \u22c5 q = pq \u22c5 (q + p ) = pq F\u00fcr die Summe X = X 1 + ... + X n gilt nach (7.6) und (7.12): EX = np und VarX = npq Bei n unabh\u00e4ngigen Wiederholungen dieses Experiments betr\u00e4gt die Wahrscheinlichkeit, dass bei den ersten k Experimenten das Ereignis A und bei den folgenden (n-k) Experimenten das Ereignis A eintritt, p k \u22c5 q n\u2212k . Diese Wahrscheinlichkeit ergibt bei jeder Kombination, bei der k-mal A und (n-k)mal A eintritt \u2013 egal in welcher Reihenfolge. Jetzt bleibt nur noch zu kl\u00e4ren, wie viele M\u00f6glichkeiten existieren, aus einer Menge von n Elementen eine Teilmenge von k Elementen auszuw\u00e4hlen. F\u00fcr das 1. Element gibt es n Auswahlm\u00f6glichkeiten, f\u00fcr das 2. verbleiben (n \u2212 1) und f\u00fcr das k. Element noch (n \u2212 k + 1) M\u00f6glichkeiten \u2013 dies ergibt insgesamt n! . n \u22c5 (n \u2212 1) \u22c5 ... \u22c5 (n \u2212 k + 1) = (n \u2212 k )! Da es k! M\u00f6glichkeiten gibt, diese k Elemente anzuordnen (und da die Reihenfolge keine Rolle spielt), m\u00fcssen wir diesen Quotienten durch k! dividieren und erhalten: \u00a7n\u00b7 \u00a7 n\u00b7 n! = \u00a8 \u00b8 und damit: P( X = k ) = \u00a8\u00a8 \u00b8\u00b8 \u22c5 p k \u22c5 q n\u2212k . (k!) \u22c5 (n \u2212 k )! \u00a8\u00a9 k \u00b8\u00b9 \u00a9k \u00b9\n7\n133 7.2 Die Binomialverteilung\nBeispiel 7.3 Wir greifen zur\u00fcck auf das Beispiel 7.2 (Biomathe-Klausur) und berechnen die Wahrscheinlichkeit daf\u00fcr, dass 3 von 10 Antworten richtig sind. Die Wahrscheinlichkeit, die ersten 3 Aufgaben richtig und die restlichen 7 falsch zu l\u00f6sen, ist: p 3 \u22c5 q 7 = 0, 23 \u22c5 0,87 \u2248 0, 0017 . Es gibt jedoch nicht nur eine, sondern\n\u00a7 10 \u00b7 insgesamt \u00a8 \u00b8 = 120 M\u00f6glichkeiten, von 10 Aufgaben genau 3 richtig zu \u00a93\u00b9 erraten. Demnach betr\u00e4gt die gesuchte Wahrscheinlichkeit nach (7.16): P ( X = 3) = 120 \u22c5 0,23 \u22c5 0,87 = 0,2013 . F\u00fcr die anderen Wahrscheinlichkeiten \u203a Abbildung 7.1): ergibt sich (z P( X = k )\nk 0\n0\n10\nF ( k ) = P( X \u2264 k )\n10\n1 \u22c5 0, 2 \u22c5 0, 8 = 0, 8 = 0,1074 1\n9\n0,1074\n1\n10 \u22c5 0, 2 \u22c5 0, 8 = 0, 2684\n0,3758\n2\n45 \u22c5 0, 22 \u22c5 0, 88 = 0, 3020\n0,6778\n3\n7\n3\n120 \u22c5 0, 2 \u22c5 0, 8 = 0, 2013\n0,8791\n4\n210 \u22c5 0,2 4 \u22c5 0,86 = 0,0881\n0,9672\n5\n5\n5\n252 \u22c5 0, 2 \u22c5 0, 8 = 0, 0264\n0,9936\n6\n210 \u22c5 0, 26 \u22c5 0, 84 = 0, 0055\n0,9991\n7\n3\n7\n120 \u22c5 0, 2 \u22c5 0, 8 = 0, 0008\n0,99992\n8\n45 \u22c5 0, 28 \u22c5 0, 82 = 7 \u22c5 10\u22125\n0,999996\n9\n10 \u22c5 0, 29 \u22c5 0, 81 = 4 \u22c5 10\u22126\n10\n10\n0\n10\n1 \u22c5 0, 2 \u22c5 0, 8 = 0, 2 = 10\n0,9999999 \u22127\n1\nDie Wahrscheinlichkeit, durch Raten weniger als 6 Punkte zu erreichen, betr\u00e4gt demnach P ( X \u2264 5) = 99,36% . Wenn 6 Punkte zum Bestehen der Klausur notwendig sind, hat man eine Chance von weniger als 1 %, ohne die geringste Ahnung von Biomathematik die Klausur zu bestehen.\nBez\u00fcglich der Formel (7.17) sind folgende Regeln zu beachten:\n\u0177 Jeder Binomialkoeffizient ist eine nat\u00fcrliche Zahl. \u0177 Einen Binomialkoeffizienten berechnet man am einfachsten als einen Bruch mit k nat\u00fcrlichen Zahlen im Z\u00e4hler (beginnend bei n in absteigender Reihenfolge) und k Zahlen im Nenner (beginnend bei 1 in aufsteigender Reihenfolge). So ist z. B. \u00a710 \u00b7 10 \u22c5 9 \u22c5 8 \u00a8\u00a8 \u00b8\u00b8 = = 120 . \u00a9 3 \u00b9 1\u22c5 2 \u22c5 3\n134\nKapitel 7 \u00b7 Diskrete Verteilungen\n\u0177 F\u00fcr alle p gilt generell: p 0 = 1 und p1 = p . \u00a7n\u00b7\n\u00a7 n \u00b7\n\u00a7 10 \u00b7\n\u00a7 10 \u00b7\n\u00b8\u00b8 ; z. B. \u00a8 \u00b8 = \u00a8 \u00b8 . \u0177 F\u00fcr alle k = 0,..., n gilt: \u00a8\u00a8 \u00b8\u00b8 = \u00a8\u00a8 \u00a93\u00b9 \u00a97\u00b9 \u00a9k \u00b9 \u00a9n \u2212 k \u00b9 \u00a7 n\u00b7\n\u00a7 n\u00b7\n\u00a9 \u00b9\n\u00a9 \u00b9\n\u0177 Per definitionem ist: \u00a8\u00a8 \u00b8\u00b8 = \u00a8\u00a8 \u00b8\u00b8 = 1 0 n 7.2.3\nDie symmetrische Binomialverteilung\nF\u00fcr die symmetrische Binomialverteilung ( p = q = 0,5 ) vereinfachen sich die obigen Formeln zu:\n7\nE ( X ) = 0,5 \u22c5 n\n(7.18)\nVar( X ) = 0, 25 \u22c5 n\n(7.19)\n\u00a7n\u00b7 P( X = k ) = P( X = n \u2212 k ) = \u00a8 \u00b8 \u22c5 0,5n \u00a9k \u00b9\n(7.20)\nBeispiel 7.4 Eine Familie habe vier Kinder, X sei die Anzahl der Jungen. Wir nehmen an, dass mit der Wahrscheinlichkeit von 0,5 ein Junge geboren wird. Nach (7.18) und (7.19) ergibt sich: E ( X ) = 2 und Var ( X ) = 1 . F\u00fcr die Wahrschein\u203a Abbildung 7.2): lichkeiten berechnet man nach (7.20) (z\nk\nP( X = k )\nP( X \u2264 k )\n0\n1 \u22c5 0,54 = 1 / 16 = 0,0625\n0,0625\n1\n4\n4 \u22c5 0,5 = 1 / 4 = 0,25 4\n0,3125\n2\n6 \u22c5 0,5 = 3 / 8 = 0,375\n0,6875\n3\n4 \u22c5 0,54 = 1 / 4 = 0,25\n0,9375\n4\n4\n1 \u22c5 0,5 = 1 / 16 = 0,0625\n1\ni Die Schiefe einer Binomialverteilung berechnet sich als \u03b31 = ( q \u2212 p ) / \u03c3 . z Also ist die Verteilung genau dann symmetrisch ist, wenn p = q .\n135 7.2 Die Binomialverteilung\n0,4\n0,3\n0,2\n0,1\n0 0 1 2 3 4 5 6 7 8 9 10 Abb. 7.1 Binomialverteilung mit n = 10 und p = 0,2 0,4\n0,3\n0,2\n0,1\n0 0 1 2 3 4 5 6 7 8 9 10 Abb. 7.2 Binomialverteilung mit n = 4 und p = 0,5 0,3\n0,2\n0,1\n0 0 1 2 3 4 5 6 Abb. 7.3 Poissonverteilung mit \u03bb = 2\n7\n8\n9\n10\n7\n136\n7\nKapitel 7 \u00b7 Diskrete Verteilungen\n7.3\nAndere diskrete Verteilungen\n7.3.1\nDie Poissonverteilung\nDer franz\u00f6sische Mathematiker Sim\u00e9on Denis Poisson (1781-1840) hat die Binomialverteilung f\u00fcr den speziellen Fall untersucht, dass die Anzahl der Wiederholungen n gro\u00df und die Wahrscheinlichkeit p f\u00fcr das Eintreten des Ereignisses A klein ist. Fragestellungen dieser Art treten in der Medizin h\u00e4ufig auf. So wird etwa bei epidemiologischen Untersuchungen eine umfangreiche Population beobachtet, wobei die Wahrscheinlichkeit, dass bei einem Individuum eine bestimmte Krankheit eintritt, sehr gering ist. Ein anderes Beispiel stellt der radioaktive Zerfall dar: In einer bestimmten Zeiteinheit zerf\u00e4llt nur ein minimaler Anteil von Millionen radioaktiver Isotope. Poisson hat nachgewiesen, dass f\u00fcr n \u2265 30 und p \u2264 0,1 die Binomialverteilung durch folgende Grenzverteilung approximiert werden kann:\nP( X = k ) =\n\u03bb k \u2212\u03bb \u22c5e k!\n(7.21)\nDer Buchstabe e symbolisiert die Euler\u2019sche Zahl, deren Wert ungef\u00e4hr 2,718 betr\u00e4gt. Die Formel (7.21) hat gegen\u00fcber (7.16) den Vorteil, dass sie f\u00fcr gro\u00dfe n und kleine k wesentlich leichter zu handhaben ist. Der griechische Buchstabe \u03bb (Lambda) repr\u00e4sentiert den Erwartungswert der Verteilung, f\u00fcr den nach (7.14) gilt: E( X ) = \u03bb = n \u22c5 p\n(7.22)\nNach (7.15) und (7.13) l\u00e4sst sich die Varianz approximieren durch:\nVar( X ) = n \u22c5 p \u22c5 q = n \u22c5\n\u03bb \u03bb \u22c5 (1 \u2212 ) \u2192 \u03bb n n n\u2192\u221e\n(7.23)\nDemnach stimmen bei der Poissonverteilung der Erwartungswert und die Varianz \u00fcberein. Durch den Parameter \u03bb ist eine Poissonverteilte Zufallsvariable eindeutig festgelegt; sie wird als X ~ P (\u03bb) angegeben. Wegen des kleinen Wertes f\u00fcr p bezeichnet man diese Verteilung auch als die \u201eVerteilung der seltenen Ereignisse\u201c. ! F\u00fcr die Berechnung einer Wahrscheinlichkeit nach (7.21) wird nur der z\nErwartungswert \u01ca ben\u00f6tigt. Weitere Angaben (der Parameter n oder die Wahrscheinlichkeit p f\u00fcr das Eintreten eines Ereignisses im Einzelfall)\n137\n7\n7.3 Andere diskrete Verteilungen\nsind nicht erforderlich. Daher kann die Poissonverteilung auch angewandt werden, wenn die Grundgesamtheit nicht konkret angegeben werden kann oder wenn die Wahrscheinlichkeit p nicht explizit quanti\u203a Beispiel 7.6). fizierbar ist (z Beispiel 7.5 In einer Geburtsklinik werden j\u00e4hrlich n = 2.000 Kinder geboren. Die Wahrscheinlichkeit, dass ein Neugeborenes mit einem Down-Syndrom zur Welt kommt, betr\u00e4gt p = 0,001 . Unter der Annahme, dass die Ereignisse unabh\u00e4ngig sind, l\u00e4sst sich die Anzahl der Neugeborenen mit Down-Syndrom durch eine Poisson-verteilte Zufallsvariable X beschreiben. F\u00fcr den charakteristischen Parameter gilt: \u03bb = n \u22c5 p = 2.000 \u22c5 0,001 = 2 . Mit (7.21) berechnet man:\nk\nP( X = k )\n0\n\u22122\ne\n= 0,135\nF ( k ) = P( X \u2264 k )\n0,135\n0,406 2 \u22c5 e \u22122 = 0,271 4 \u22122 \u22c5 e = 0, 271 2 0,677 2 8 \u22122 \u22c5 e = 0,180 3 0,857 6 16 \u22122 \u22c5 e = 0,090 4 0,947 24 32 \u22122 \u22c5 e = 0,036 5 0,983 120 64 \u22122 \u22c5 e = 0,012 6 0,995 720 Man erkennt, dass die Wahrscheinlichkeiten f\u00fcr wachsendes k sehr schnell \u203a Abbildung 7.3). Die Wahrscheinlichkeit, dass pro Jahr mehr als abnehmen (z 6 Kinder mit Down-Syndrom geboren werden, ist nahezu 0. 1\nBeispiel 7.6 Verd\u00fcnntes Blut wird in eine Z\u00e4hlkammer eingef\u00fcllt. Diese ist in zahlreiche Quadrate identischer Fl\u00e4che eingeteilt. Unter dem Mikroskop werden die Erythrozyten in 80 Quadraten gez\u00e4hlt. Man ermittelt durchschnittlich 5,9125 Erythrozyten pro Z\u00e4hlquadrat. Es stehen Millionen von Erythrozyten zur Verf\u00fcgung; die Wahrscheinlichkeit, dass ein bestimmter Erythrozyt in einem Z\u00e4hlquadrat gefunden wird, ist extrem gering. Dies rechtfertigt die Annahme, dass die Anzahl der Erythrozyten pro Quadrat einer Poissonverteilung folgt. Also kann man nach (7.21) mit \u03bb = 5,9125 Wahrscheinlichkeiten berechnen, \u203a Abohne dass die Parameter n und p explizit bekannt sind (siehe auch z schnitt 12.2.6, Beispiel 12.6).\n138\nKapitel 7 \u00b7 Diskrete Verteilungen\nMathematische Herleitung der Poissonverteilung Diese Verteilung ist ein Grenzfall der Binomialverteilung und kann aus dieser hergeleitet werden. Mit (7.16) und \u03bb = n \u22c5 p ergibt sich: n\n\u2212k\n\u00a7n\u00b7 1 n \u22c5 ( n \u2212 1) \u22c5 ... \u22c5 ( n \u2212 k + 1) k \u00a7 \u03bb\u00b7 \u00a7 \u03bb\u00b7 P( X = k ) = \u00a8 \u00b8 \u22c5 p k \u22c5 q n \u2212 k = \u22c5 \u22c5 \u03bb \u22c5 \u00a81 \u2212 \u00b8 \u00a81 \u2212 \u00b8 k k ! k n n\u00b9 n \u00a9 \u00b9 \u00a9 \u00a9 \u00b9 F\u00fcr gro\u00dfes n und vergleichsweise kleines k ist das Produkt der k Faktoren des\nZ\u00e4hlers ungef\u00e4hr n k . Aus der Analysis ist bekannt, dass gilt: n\n\u00a7 \u03bb\u00b7 \u00a7 \u03bb\u00b7 lim \u00a81 \u2212 \u00b8 = e \u2212 \u03bb . Au\u00dferdem ist lim \u00a8 1 \u2212 \u00b8 n \u2192\u221e n \u2192 \u221e\u00a9 n\u00b9 \u00a9 n\u00b9\n\u2212k\n=1.\nDamit erhalten wir f\u00fcr obige Formel: P ( X = k ) =\n\u03bb k \u2212\u03bb \u22c5e k!\ni Die Poissonverteilung ist immer rechtsschief (oder linksgipfelig), da f\u00fcr z die Schiefe gilt: \u03b31 = ( q \u2212 p ) / \u03c3 \u2192 (1 \u2212 0) / \u03bb = 1/ \u03bb > 0 . n \u2192\u221e\n7\n7.3.2\nDie Polynomialverteilung\nDie Polynomialverteilung (oder Multinomialverteilung) stellt eine Verallgemeinerung der Binomialverteilung dar. Sie beschreibt eine Serie von n Zufallsexperimenten, bei denen pro Beobachtung eines von k m\u00f6glichen Ereignissen A1 , A2 ,..., Ak mit den Wahrscheinlichkeiten p1 , p2 ,..., pk auftreten kann. Die Wahrscheinlichkeit, dass bei n Beobachtungen das Ereignis A1 mit der H\u00e4ufigkeit n1 , das Ereignis A2 mit der H\u00e4ufigkeit n2 usw. eintritt, berechnet sich nach: P ( n1 , n2 ,..., nk p1 , p2 ,..., pk ) = k\nDabei ist\n\u00a6p\ni\ni =1\n= 1 und\nk\n\u00a6n\ni\n( p1 ) n1 \u22c5 ... \u22c5 ( pk ) nk \u22c5 n! n1 !\u22c5 ... \u22c5 nk !\n(7.24)\n=n.\ni =1\nBeispiel 7.7 Die Wahrscheinlichkeiten f\u00fcr das Auftreten der Blutgruppen betragen: P (0) = p1 = 0,39 , P (A ) = p2 = 0,44 , P (B) = p3 = 0,13 , P (AB) = p4 = 0,04 . Dann ist die Wahrscheinlichkeit, dass unter n = 10 Personen je 4mal die Blutgruppen 0 und A und je 1mal B und AB vorkommen, nach (7.24):\nP(4,4,1,1 0,39;0,44;0,13;0,04 ) =\n0,394 \u22c5 0,444 \u22c5 0,131 \u22c5 0,041 \u22c510!= 0,0284 4! \u22c54! \u22c51! \u22c51!\n139\n7\n7.3 Andere diskrete Verteilungen\n7.3.3\nDie negative Binomialverteilung\nW\u00e4hrend die Binomialverteilung dar\u00fcber informiert, mit welcher Wahrscheinlichkeit das Ereignis A bei n unabh\u00e4ngigen Beobachtungen 0, 1, 2, ... oder n-mal gez\u00e4hlt wird, beschreibt die negative Binomialverteilung NB (r , p ) , mit welcher Wahrscheinlichkeit das Ereignis A gerade bei der j-ten Beobachtung zum r-ten Mal eintritt. Diese Verteilung wird h\u00e4ufig zur Analyse von Wartezeiten verwendet. Der einfachste Spezialfall ist die geometrische Verteilung NB (1, p) , die angibt, mit welcher Wahrscheinlichkeit das Ereignis A bei der j-ten Beobachtung erstmals eintritt. Sie l\u00e4sst sich leicht herleiten als: P ( X = j ) = q j \u22121 \u22c5 p\n(7.25)\nDabei wird zugrunde gelegt, dass bei den ersten j \u2212 1 Beobachtungen jeweils das Ereignis A (mit der Wahrscheinlichkeit q = 1 \u2212 p ) und bei der j. Beobachtung das Ereignis A (mit der Wahrscheinlichkeit p ) eintritt. Beispiel 7.8 Eine Blutbank ben\u00f6tigt Blut von 10 Personen mit dem Rhesusfaktor positiv. Wie gro\u00df ist die Wahrscheinlichkeit, dass man nach der Blutentnahme bei maximal 14 Personen 10 positive Konserven hat? Nach (7.26) berechnet man f\u00fcr X ~ NB(10;0,85) (also r = 10 und p = 0,85 ): \u00a79\u00b7 P ( X = 10) = \u00a8\u00a8 \u00b8\u00b8 \u22c5 0,8510 = 0,1969 \u00a99\u00b9 \u00a710 \u00b7 P( X = 11) = \u00a8\u00a8 \u00b8\u00b8 \u22c5 0,15 \u22c5 0,8510 = 0,2953 \u00a99\u00b9 \u00a711\u00b7 P( X = 12) = \u00a8\u00a8 \u00b8\u00b8 \u22c5 0,152 \u22c5 0,8510 = 0,2436 \u00a99\u00b9\n\u00a712 \u00b7 P( X = 13) = \u00a8\u00a8 \u00b8\u00b8 \u22c5 0,153 \u22c5 0,8510 = 0,1462 \u00a99\u00b9 \u00a713\u00b7 P ( X = 14) = \u00a8\u00a8 \u00b8\u00b8 \u22c5 0,154 \u22c5 0,8510 = 0,0713 \u00a99\u00b9 Durch Addition erh\u00e4lt man: P ( X \u2264 14) = 0,9533 . Das bedeutet, dass mit 95%iger Wahrscheinlichkeit 14 Entnahmen ausreichen werden, um 10 positive Reserven zu erhalten.\n140\nKapitel 7 \u00b7 Diskrete Verteilungen\nWie gro\u00df ist nun die Wahrscheinlichkeit, dass bei der j-ten Beobachtung das Ereignis A zum r-ten Mal eintritt? Dabei ist zu ber\u00fccksichtigen, dass unter den vorangegangenen ( j \u2212 1) Beobachtungen das Ereignis A genau (r \u2212 1) -mal gez\u00e4hlt worden ist. Also gilt f\u00fcr die negative Binomialverteilung allgemeiner Art:\n\u00a7 j \u2212 1\u00b7 j \u2212 r r \u00b8\u00b8 \u22c5 q P( X = j ) = \u00a8\u00a8 \u22c5 p f\u00fcr j \u2265 r \u00a9 r \u2212 1\u00b9 7.3.4\n7\n(7.26)\nDie hypergeometrische Verteilung\nDie hypergeometrische Verteilung beschreibt n Beobachtungen, bei denen jeweils alternativ die Ereignisse A und A eintreten k\u00f6nnen. Im Gegensatz zur Binomialverteilung sind diese Beobachtungen jedoch nicht unabh\u00e4ngig voneinander \u2013 das Auftreten eines bestimmten Ereignisses beeinflusst die Wahrscheinlichkeiten aller nachfolgenden Ereignisse. i Die Binomial- und die hypergeometrische Verteilung lassen sich durch z zwei unterschiedliche Urnenmodelle veranschaulichen. Gegeben sei eine Urne mit roten und wei\u00dfen Kugeln; der Anteil roter Kugeln betrage p. Wenn man aus dieser Urne nacheinander n Kugeln zieht, und nach jeder Ziehung die Kugel zur\u00fcck in die Urne legt, sind die Ziehungen unabh\u00e4ngig voneinander und die Wahrscheinlichkeit, eine rote Kugel zu ziehen, betr\u00e4gt bei jedem Zug p. Ein solcher Prozess l\u00e4sst sich durch eine Binomialverteilung beschreiben. Wenn man jedoch die gezogenen Kugeln nicht zur\u00fccklegt, \u00e4ndern sich bei jedem Zug die Wahrscheinlichkeiten. Die Ziehungen sind voneinander abh\u00e4ngig und werden durch eine hypergeometrische Verteilung charakterisiert.\nDer hypergeometrischen Verteilung liegen folgende Annahmen zugrunde:\n\u0177 Insgesamt stehen N Objekte (also endlich viele) zur Verf\u00fcgung,\nvon denen genau M die Eigenschaft A und ( N \u2212 M ) die Eigenschaft A aufweisen. \u0177 Von den N Objekten werden n zuf\u00e4llig ausgew\u00e4hlt. Die Zufallsvariable X ~ HG (n; N , M ) gibt an, wie h\u00e4ufig das Merkmal A bei n Beobachtungen auftritt. Die Wahrscheinlichkeiten f\u00fcr k = 0,..., n sind:\n141\n7\n7.3 Andere diskrete Verteilungen\n\u00a7M \u00b7 \u00a7N \u2212 M \u00b7 \u00a8 k \u00b8\u22c5\u00a8 n \u2212 k \u00b8 \u00b9 P( X = k ) = \u00a9 \u00b9 \u00a9 \u00a7N\u00b7 \u00a8n\u00b8 \u00a9 \u00b9\n(7.27)\nDer Quotient p = M / N wird auch als Anteilswert bezeichnet. Damit ist der Erwartungswert der hypergeometrischen Verteilung \u00e4hnlich wie bei der Binomialverteilung (Formel 7.14): E ( X ) = np = n \u22c5\nM N\n(7.28)\nF\u00fcr die Varianz gilt: Var( X ) =\nN \u2212n \u22c5 n \u22c5 p \u22c5 (1 \u2212 p ) N \u22121\n(7.29)\nDer Faktor ( N \u2212 n) /( N \u2212 1) in Formel (7.29) entspricht der Endlichkeitskorrektur. Falls N im Vergleich zu n sehr gro\u00df ist, kann die hypergeometrische Verteilung durch die Binomialverteilung approximiert werden. Beispiel 7.9 Von den 71 Studenten in Tabelle 2.1 sind 23 m\u00e4nnlich. Wie gro\u00df ist die Wahrscheinlichkeit, dass von 5 zuf\u00e4llig ausgew\u00e4hlten Studenten 2 m\u00e4nnlich sind? Nach (7.27) ergibt sich mit N = 71 , M = 23 , n = 5 und k = 2 : \u00a7 23\u00b7 \u00a7 48 \u00b7 \u00a8\u00a8 \u00b8\u00b8 \u22c5 \u00a8\u00a8 \u00b8\u00b8 2 3 253 \u22c517.296 = 0,336 P ( X = 2) = \u00a9 \u00b9 \u00a9 \u00b9 = 13.019.909 \u00a7 71\u00b7 \u00a8\u00a8 \u00b8\u00b8 \u00a95\u00b9\n7.3.5\nDie diskrete Gleichverteilung\nSchlie\u00dflich sei noch die diskrete Gleichverteilung DG (k ) erw\u00e4hnt. Sie beschreibt ein Zufallsexperiment, bei dem k Ereignisse A1 , A2 ,..., Ak mit jeweils derselben Wahrscheinlichkeit eintreten k\u00f6nnen. Ein bekanntes Beispiel ist der ideale W\u00fcrfel, bei dem jede Augenzahl mit der Wahrscheinlichkeit p = 1 / 6 erzielt wird. In der Statistik spielen diskrete Gleichverteilungen bei Zufallszahlen eine Rolle. Dies sind Ziffernfolgen, bei denen jede Ziffer mit derselben Wahrscheinlichkeit p = 0,1 auftritt. Zwei nebeneinander stehende\n142\nKapitel 7 \u00b7 Diskrete Verteilungen\nZiffern bilden dann eine 2-stellige Zufallszahl zwischen 0 und 99. Diese sind gleichverteilt mit p = 1 / 100 . \u00dcbersicht 6: Diskrete Verteilungen\n7\nName und Bezeichnung der Verteilung\nAbschnitt\nAnzahl und Art der m\u00f6gliche Beobachtungen Einzelereignisse\nBinomialverteilung B ( n, p )\n7.2\nn unabh\u00e4ngige\nA und A\nPoisson-Verteilung P (\u03bb)\n7.3.1\nn unabh\u00e4ngige n \u2265 30, p \u2264 0,1\nA und A\nPolynomial-Verteilung\n7.3.2\nn unabh\u00e4ngige\nA1 ,..., Ak\ngeometrische Verteilung NB(1, p)\n7.3.3\nbis A zum 1. Mal eintritt\nA und A\nnegative Binomialverteilung NB(r , p)\n7.3.3\nbis A zum r. Mal eintritt\nA und A\nhypergeometrische Verteilung HG (n; N , M )\n7.3.4\nn abh\u00e4ngige\nA und A\nGleichverteilung DG (k )\n7.3.5\n1\nA1 ,..., Ak\n8\nStetige Verteilungen 8.1\nStetige Zufallsvariable 145\n8.1.1\nFunktionen 145\n8.1.2\nLage- und Streuungsparameter 147\n8.1.3\nDie zentralen Momente 147\n8.2\nDie Normalverteilung 148\n8.2.1\nAllgemeine Eigenschaften 148\n8.2.2\nDie Standardnormalverteilung 149\n8.2.3\n\u03c3-Bereiche und Referenzbereiche 151\n8.2.4\nNormalisierende Transformationen 152\n8.3\nS\u00e4tze der Wahrscheinlichkeitsrechnung 155\n8.3.1\nDie Tschebyscheff\u2019sche Ungleichung 155\n8.3.2\nDas Gesetz der gro\u00dfen Zahlen 157\n8.3.3\nDer zentrale Grenzwertsatz 159\n8.3.4\nDie Bedeutung der Normalverteilung 161\n8.4\nDie Verteilung von \u00dcberlebenszeiten 162\n8.4.1\nEinige wichtige Begriffe 162\n8.4.2\nDie Exponentialverteilung 164\n8.4.3\nDie Weibull-Verteilung 165\n8.5\nPr\u00fcfverteilungen 166\n8.5.1\nDie t-Verteilung 167\n8.5.2\nDie Chi2-Verteilung 168\n8.5.3\nDie F-Verteilung 170\n145\n8\n8.1 Stetige Zufallsvariable\n8.1\nStetige Zufallsvariable\n8.1.1\nFunktionen\nEine stetige Zufallsvariable X (z. B. K\u00f6rpergewicht oder K\u00f6rpergr\u00f6\u00dfe) kann theoretisch alle Zahlenwerte innerhalb eines bestimmten Intervalls annehmen. Die Wahrscheinlichkeitsverteilung wird durch die Dichtefunktion (oder Dichte) beschrieben. Diese Funktion ordnet jedem Wert xi der Zufallsvariablen einen Funktionswert f ( xi ) > 0 zu. Die Gesamtfl\u00e4che unter der Kurve f (x ) ist gleich 1: +\u221e\n\u00b3 f ( x)dx = 1\n(8.1)\n\u2212\u221e\nDiese Gleichung dr\u00fcckt aus, dass die Zufallsvariable X mit Sicherheit (also der Wahrscheinlichkeit 1) einen Wert zwischen -\u221e und +\u221e annimmt. Sie ist vergleichbar mit (7.2); das \u03a3-Zeichen ist ersetzt durch das Integral. Die Verteilungsfunktion einer stetigen Zufallsvariablen ist das Integral \u00fcber der Dichte: x\nF ( x) = P( X \u2264 x) =\n\u00b3 f (t )dt\n(8.2)\n\u2212\u221e\nDaraus folgt f\u00fcr das komplement\u00e4re Ereignis X > x : +\u221e\nP( X > x) =\n\u00b3 f (t )dt = 1 \u2212 F ( x)\n(8.3)\nx\n! Die Dichte wird in den Gleichungen (8.2) und (8.3) mit f ( t ) bezeichnet, z\nweil x eine Grenze des Integrals darstellt, w\u00e4hrend sich die Variable t zwischen den Grenzen -\u221e und x bzw. zwischen x und +\u221e bewegt.\nAus den obigen Formeln lassen sich folgende allgemeine Eigenschaften der Verteilungsfunktion F ( x ) herleiten:\n\u0177 F ( x ) ist eine monoton wachsende Funktion, \u0177 F ( x ) hat die Grenzwerte F( \u2212\u221e ) = 0 und F( +\u221e ) = 1 , \u0177 die Dichte f ( x ) ist die Ableitung der Verteilungsfunktion; es gilt n\u00e4mlich: f ( x ) = F' ( x ) .\n146\nKapitel 8 \u00b7 Stetige Verteilungen\nDie Wahrscheinlichkeit, dass X einen Wert zwischen a und b annimmt, wird folgenderma\u00dfen berechnet:: b\nP ( a \u2264 X \u2264 b) =\n\u00b3 f ( x)dx = F (b) \u2212 F (a)\n(8.4)\na\nDieses Integral beschreibt eine Fl\u00e4che, die von der x-Achse, der Kurve f ( x ) und den Parallelen zur y-Achse x = a und x = b be\u203a Abbildung 8.1). Dies entspricht einem Teil der Gegrenzt wird (z samtfl\u00e4che unter der Dichtefunktion, deren Wert nach (8.1) 1 betr\u00e4gt. Infolgedessen hat das Integral in (8.4) immer einen Wert zwischen 0 und 1. F\u00fcr die Wahrscheinlichkeit, dass X einen bestimmten Wert a annimmt, berechnet man: P( X = a) = F (a) \u2212 F (a) = 0\n8\n(8.5)\nDieses Ergebnis mag manchen Leser \u00fcberraschen. Es sei an einem konkreten Beispiel erl\u00e4utert: Wir betrachten die Zufallsvariable X, die das Merkmal \u201eK\u00f6rpergr\u00f6\u00dfe\u201c symbolisiert. Dann ist es sinnlos, nach der Wahrscheinlichkeit zu fragen, mit der X einen Wert von beispielsweise 178 cm annimmt. Dieser scheinbare Widerspruch zur Realit\u00e4t wird dadurch erkl\u00e4rt, dass die gemessene K\u00f6rpergr\u00f6\u00dfe nicht exakt 178 cm betr\u00e4gt, sondern sich \u2013 bei einer Messgenauigkeit von 1 cm \u2013 zwischen 177,5 cm und 178,5 cm bewegt.\nAbb. 8.1 Dichte einer stetigen Zufallsvariablen. Die eingezeichnete Fl\u00e4che entspricht P ( a \u2264 X \u2264 b) .\nP(a \u2264 x \u2264 b)\na\nb\n147\n8\n8.1 Stetige Zufallsvariable\n8.1.2\nLage- und Streuungsparameter\nF\u00fcr den Erwartungswert einer stetigen Zufallsvariablen gilt: +\u221e\n\u00b5=\n\u00b3 x \u22c5 f ( x)dx\n(8.6)\n\u2212\u221e\nDer Median und die \u03b1-Quantile sind definiert als: F( \u00b5 ) = 0 ,5 bzw. F( \u00b5 \u03b1 ) = \u03b1 . Der Modus ist der Wert, an dem die Dichtefunktion f ( x ) ein Maximum aufweist (bei multimodalen Verteilungen gibt es mehrere relative Maxima). Die Varianz l\u00e4sst sich darstellen als: +\u221e 2\n\u03c3 =\n\u00b3 ( x \u2212 \u00b5)\n2\nf ( x)dx\n(8.7)\n\u2212\u221e\nAnsonsten gelten die in Abschnitt 7.1 dargelegten Rechenregeln analog. 8.1.3\nDie zentralen Momente\nWeitere Charakterisierungen einer quantitativen Zufallsvariablen gestatten die so genannten Momente EX k und die zentralen Momente E ( X \u2212 EX )k (wobei k eine nat\u00fcrliche Zahl ist). Das erste Moment EX haben wir bereits als den Erwartungswert \u00b5 kennen gelernt. Das zweite zentrale Moment E( X \u2212 EX )2 ist die Varianz. Aus dem 3. zentralen Moment l\u00e4sst sich die Schiefe \u03b31 (Gamma) herlei\u203a Formel 4.15): ten (z \u03b31 = E ( X \u2212 EX ) 3 \u03c3 3\n(8.8)\nDa sich wegen der 3. Potenz negative und positive Abweichungen der x-Werte vom Mittelwert ausgleichen, ergibt sich bei symmetrischen Verteilungen f\u00fcr die Schiefe der Wert 0. Bei rechtsschiefen Verteilungen ist \u03b31 > 0 , bei linksschiefen ist \u03b31 < 0 . Mit dem 4. zentralen Moment wird die W\u00f6lbung definiert als \u03b3 2 = E ( X \u2212 EX ) 4 \u03c3 4 \u2212 3\n(8.9)\n\u203a Formel 4.17). Das 4. Moment der Normalverteilung ist 3\u03c3 4 . Mit (z der Definition nach (8.9) erreicht man, dass die W\u00f6lbung einer normalverteilten Zufallsvariablen den Wert 0 annimmt.\n148\nKapitel 8 \u00b7 Stetige Verteilungen\n8.2\nDie Normalverteilung\n8.2.1\nAllgemeine Eigenschaften\nDie Normalverteilung ist f\u00fcr die Statistik und deren praktische Anwendung von grundlegender Bedeutung. Ihre Dichte wird durch die Gau\u00df\u2019sche Glockenkurve dargestellt (sie war ehemals zusammen mit dem Konterfei von Carl Friedrich Gau\u00df auf dem 10-Mark-Schein abgebildet). Die zugrunde liegende mathematische Funktion lautet: f ( x) =\n8\n1 2\u03c0 \u22c5 \u03c3\n\u2212( x \u2212\u00b5) 2\n\u22c5e\n2\u03c3 2\n(8.10)\nEine normalverteilte Zufallsvariable X ist durch den Erwartungswert \u00b5 und die Standardabweichung \u03c3 eindeutig charakterisiert. Sie wird deshalb allgemein als X ~ N (\u00b5, \u03c3 2 ) angegeben (so auch in diesem Buch); andere Autoren verwenden die Schreibweise X ~ N (\u00b5, \u03c3) . Aus (8.10) lassen sich folgende Eigenschaften der Normalverteilung herleiten:\n\u0177 Die Glockenkurve ist symmetrisch um den Erwartungswert \u00b5; es gilt also: f (\u00b5 + x) = f (\u00b5 \u2212 x) .\n\u0177 Sie hat zwei Wendepunkte bei x = \u00b5 \u2212 \u03c3 und x = \u00b5 + \u03c3 . \u0177 Ihr Maximum ist an der Stelle x = \u00b5 . \u0177 Der Erwartungswert, der Median und der Modalwert von X stimmen \u00fcberein.\n\u0177 Die Dichte f ( x) ist f\u00fcr jede reelle Zahl definiert und gr\u00f6\u00dfer als 0. F\u00fcr x \u2192 \u00b1\u221e n\u00e4hert sie sich asymptotisch der x-Achse.\nDer Ausdruck \u201easymptotisch\u201c bedeutet in diesem Zusammenhang, dass die Glockenkurve f\u00fcr hinreichend gro\u00dfe x-Betr\u00e4ge beliebig nahe an die x-Achse herankommt, ohne diese jedoch zu erreichen. Die spezielle Form der Glockenkurve h\u00e4ngt von der Standardabweichung \u03c3 ab: Bei kleinem \u03c3 ist sie schmal und hoch; bei gro\u00dfem \u03c3 ist \u203a Abbildung 8.2). In jedem Fall ist die sie dagegen breit und niedrig (z Gesamtfl\u00e4che unter der Kurve gem\u00e4\u00df Formel (8.1) gleich 1. Die Schiefe \u03b31 ist \u2013 wie bei jeder symmetrischen Verteilung \u2013 gleich 0. Auch die W\u00f6lbung \u03b3 2 ist nach (8.9) so definiert, dass sie bei einer Normalverteilung den Wert 0 annimmt. Die Wahrscheinlichkeit, dass eine normalverteilte Zufallsvariable X einen Wert zwischen zwei Grenzwerten a und b annimmt, berechnet man nach (8.4) \u00fcber die Verteilungsfunktion F ( x ) :\n149\n8\ndx = F (b) \u2212 F (a)\n(8.11)\n8.2 Die Normalverteilung\nP ( a \u2264 X \u2264 b) =\nb\n1 2\u03c0 \u22c5 \u03c3\n\u22c5\u00b3e\n\u2212 ( x \u2212\u00b5 ) 2 2\u03c3 2\na\nDiese Wahrscheinlichkeit entspricht der Fl\u00e4che, die von der Glockenkurve, der x-Achse und den Parallelen zur y-Achse x = a und \u203a Abbildung 8.1). Die Bestimmung eines solx = b begrenzt wird (z chen Intervalls ist allerdings problematisch: Es ist nicht m\u00f6glich, die Funktion F (x ) analytisch aufzul\u00f6sen, und ein Taschenrechner hilft hier im Allgemeinen auch nicht weiter. Man kann sich jedoch heutzutage \u2013 wenn man Zugang zu einem Rechner mit geeigneter Software hat \u2013 die gew\u00fcnschten Werte einfach und schnell berechnen lassen. Mathematische Betrachtung der Gau\u00df\u2019schen Glockenkurve F\u00fcr die Ableitungen von f (x) berechnet man mit der Kettenregel der Diffe\u00a7 ( x \u2212 \u00b5) 2 1 \u00b7 \u2212 2\u00b8. und f ' ' ( x) = f ( x) \u22c5 \u00a8 \u00a8 \u03c34 \u03c3 \u00b8\u00b9 \u03c3 \u00a9 Daraus folgt: Das Maximum (d. h. der Modalwert) ist bei x = \u00b5 ( f ' (\u00b5) = 0 , f ' ' (\u00b5) < 0 ); die Wendepunkte bei x = \u00b5 \u00b1 \u03c3 ( f ' ' (\u00b5 \u00b1 \u03c3) = 0 ). Der Nachweis, dass die gesamte Fl\u00e4che unter der Glockenkurve gleich 1 ist, erfordert die L\u00f6sung des bestimmten Integrals \u00fcber den Ausdruck in Formel (8.10).\nrentialrechnung: f ' ( x) = \u2212 f ( x) \u22c5\nx\u2212\u00b5 2\nUm nachzuweisen, dass es sich bei den Parametern \u00b5 und \u03c3 2 tats\u00e4chlich um den Erwartungswert bzw. die Varianz handelt, reichen schulmathematische Kenntnisse nicht aus. Deshalb wird an dieser Stelle auf den Beweis verzichtet.\n8.2.2\nDie Standardnormalverteilung\nUm eine bestimmte Wahrscheinlichkeit einer normalverteilten Zufallsvariablen auszurechnen, ist man ohne geeignete Statistik-Software auf Tabellen angewiesen, in denen die Funktionswerte der Verteilungsfunktion aufgelistet sind und die in jedem Statistik-Buch zu finden sind. Diesen Tabellen liegt generell die Standardnormalverteilung zugrunde \u2013 das ist eine spezielle Normalverteilung mit dem Erwartungswert 0 und der Varianz 1. Jede normalverteilte Zufallsvariable X ~ N (\u00b5, \u03c3 2 ) l\u00e4sst sich in die Standardnormalverteilung Z ~ N (0,1) transformieren durch:\nZ=\nX \u2212\u00b5 \u03c3\n(8.12)\n150\nKapitel 8 \u00b7 Stetige Verteilungen\nMit den Rechenregeln (7.5) und (7.9) l\u00e4sst sich nachweisen, dass EZ = 0 und VarZ = 1 . Durch die Transformation wird die Glockenkurve entlang der x-Achse so verschoben, dass der Erwartungswert 0 wird. Au\u00dferdem wird die Kurve aufgrund der Division durch \u0131 in ihrer Form so angepasst, dass die Standardabweichung den Wert 1 annimmt. F\u00fcr die Dichte und die Verteilungsfunktion der Standardnormalverteilung erh\u00e4lt man mit (8.10) und (8.2): \u03d5( z ) =\n1 2\u03c0\n\u2212z2 \u22c5e 2\n(8.13) z\n\u03a6( z ) = P(Z \u2264 z ) =\n\u00b3 \u03d5(t )dt =\n\u2212\u221e\n1 2\u03c0\nz\n\u00b3\n\u2212t 2 e 2\ndt\n(8.14)\n\u2212\u221e\nDie griechischen Buchstaben \u03d5 (klein Phi) und \u012d (gro\u00df Phi) entsprechen den lateinischen Buchstaben f bzw. F. In der Tabelle A im Anhang dieses Buches sind diverse z-Perzentile zusammen mit den Funktionswerten \u03d5(z ) und \u03a6 (z ) aufgelistet.\n8\nBeispiel 8.1 Die K\u00f6rpergr\u00f6\u00dfe einer Population von jungen M\u00e4nnern X sei normalverteilt mit \u00b5 = 180 cm und \u03c3 = 10 cm . Gesucht ist die Wahrscheinlichkeit P (170 cm \u2264 X \u2264 190 cm) . Nach (8.12) berechnet man f\u00fcr die entsprechenden Grenzen der standardisierten Variablen: 190 \u2212 180 170 \u2212 180 z1 = = \u22121 und z2 = = +1 . 10 10 Aus den z-Variablen geht hervor, dass die K\u00f6rpergr\u00f6\u00dfen 170 cm und 190 cm eine Standardabweichung unter bzw. \u00fcber dem Erwartungswert liegen. Nach (8.11) ist die gesuchte Wahrscheinlichkeit: P (-1 \u2264 Z \u2264 +1) = P ( Z \u2264 1) \u2212 P ( Z \u2264 \u22121) . Nun ist P ( Z \u2264 1) = \u03c6(1) . Wegen der Symmetrie der Glockenkurve gilt: P ( Z \u2264 \u22121) = P ( Z \u2265 1) = 1 \u2212 P ( Z \u2264 1) = 1 \u2212 \u03a6 (1) . Demnach ist P (-1 \u2264 Z \u2264 +1) = \u03a6 (1) \u2212 (1 \u2212 \u03a6 (1)) = 2\u03a6 (1) \u2212 1 Aus Tabelle A ist zu entnehmen: \u03a6 (1) = 0,84 . Daraus ergibt sich: P (170 cm \u2264 X \u2264 190 cm) = 2 \u22c5 0,84 - 1 = 0,68 . i Eine Tabelle mit Funktionswerten der Standardnormalverteilung wurde z erstmals 1812 von Laplace in \u201eTh\u00e9orie Analytique des Probabilit\u00e9s\u201c publiziert. Ihr Umgang erfordert einige \u00dcbung, da man die gesuchten Werte nicht immer direkt ablesen kann. Aus Platzgr\u00fcnden enthalten derlei Tabellen n\u00e4mlich im Allgemeinen nur Funktionswerte f\u00fcr z \u2265 0 . F\u00fcr negative -z gilt \u03a6 (\u2212 z ) = P ( Z \u2264 \u2212 z ) = P ( Z \u2265 z ) = 1 \u2212 \u03a6 ( z ) aufgrund der Symmet-\n8\n151 8.2 Die Normalverteilung\nrie der Glockenkurve. Heute lassen sich mit einer geeigneten Software derlei Wahrscheinlichkeiten f\u00fcr jede beliebige Normalverteilung leicht ermitteln. Dennoch mag die Berechnung der standardisierten z-Variablen sinnvoll sein: Sie informiert, um wie viele Standardabweichungen der \u203a Beispiel 8.1). entsprechende x-Wert vom Erwartungswert \u01cb abweicht (z\n8.2.3\n\u03c3-Bereiche und Referenzbereiche\nObwohl die Normalverteilung theoretisch f\u00fcr alle x zwischen \u2212\u221e und +\u221e definiert ist, konzentrieren sich die Werte in unmittelbarer Umgebung des Erwartungswertes \u00b5. Einige oft benutzte Intervalle und deren Wahrscheinlichkeiten lassen sich generell f\u00fcr jede Normalverteilung angeben. Aus Tabelle 8.1 geht hervor, dass etwa 2/3 \u203a Beispiel 8.2). aller Messwerte innerhalb der Grenzen \u00b5 \u00b1 \u03c3 liegen (z Die Wahrscheinlichkeit, einen Wert au\u00dferhalb des 3\u03c3 -Bereichs zu finden, betr\u00e4gt nahezu 0. Deshalb wird die Normalverteilung h\u00e4ufig verwendet, um quantitative, symmetrisch verteilte, eingipfelige Merkmale zu beschreiben \u2013 auch wenn der Wertebereich in der Praxis immer eine obere und eine untere Grenze aufweist. F\u00fcr medizinische Fragestellungen sind so genannte Normberei\u203a Abbildung 8.3) wichtig, die 95% oder che (oder Referenzbereiche, z 99% aller Werte enthalten. So legt man bei normalverteilten Daten zugrunde, dass ein Wert au\u00dferhalb eines bestimmten Referenzbereichs \u00fcberpr\u00fcft werden sollte (etwa auf Messfehler, pathologische Besonderheiten etc.). Allerdings muss darauf hingewiesen werden, dass anhand eines Normbereichs keine Entscheidung wie etwa \u201epathologisch / nicht pathologisch\u201c getroffen werden kann.\nAbb. 8.2 Normalverteilungen mit gleichem Erwartungswert \u00b5 = 0 und unterschiedlicher Streuung. Obere Kurve: \u03c3 = 0,6 , mittlere Kurve: \u03c3 = 1 , untere Kurve: \u03c3 = 2\n0,7\n0,6\n0,5\n0,4\n0,3\n0,2\n0,1\n0 -4\n-2\n0\n2\n4\n152\nKapitel 8 \u00b7 Stetige Verteilungen\nTabelle 8.1 Spezielle Intervalle und Wahrscheinlichkeiten der Normalverteilung\nX : N (\u00b5, \u03c3 2 )\nIntervallgrenzen f\u00fcr Z : N (0,1)\nBezeichnung des Intervalls\nWahrscheinlichkeit P\n\u00b5\u2212\u03c3 \u2264 X \u2264 \u00b5+\u03c3\n\u22121 \u2264 Z \u2264 1\n1\u03c3-Bereich\n0,6827\n\u00b5 \u2212 2\u03c3 \u2264 X \u2264 \u00b5 + 2\u03c3\n\u22122 \u2264 Z \u2264 2\n2\u03c3-Bereich\n0,9545\n\u00b5 \u2212 3\u03c3 \u2264 X \u2264 \u00b5 + 3\u03c3\n\u22123 \u2264 Z \u2264 3\n3\u03c3-Bereich\n0,9973\n\u00b5 \u2212 1,96\u03c3 \u2264 X \u2264 \u00b5 + 1,96\u03c3\n\u22121,96 \u2264 Z \u2264 1,96\n95%-Referenzbereich\n0,95\n\u00b5 \u2212 2,58\u03c3 \u2264 X \u2264 \u00b5 + 2,58\u03c3\n\u22122,58 \u2264 Z \u2264 2,58\n99%-Referenzbereich\n0,99\nIntervallgrenzen f\u00fcr\n8\nBeispiel 8.2 Die K\u00f6rpergr\u00f6\u00dfe einer m\u00e4nnlichen Population X sei normalverteilt mit \u00b5 = 180 cm und \u03c3 = 10 cm . Gesucht ist das Intervall um den Erwartungswert, in dem sich mit einer Wahrscheinlichkeit von 95% ein Messwert befindet. Der Tabelle 8.1 ist zu entnehmen, dass dieses Intervall durch \u00b5 \u00b1 1,96\u03c3 begrenzt ist. Damit berechnet man f\u00fcr die untere bzw. obere Grenze: x1 = \u00b5 \u2212 1,96\u03c3 = 160,4 cm und x2 = \u00b5 + 1,96\u03c3 = 199,6 cm . Also gilt: P (\u22121,96 \u2264 Z \u2264 +1,96) = P (160,4 cm \u2264 X \u2264 199,6 cm) = 0,95 . Diese Wahrscheinlichkeit l\u00e4sst sich graphisch darstellen als die Fl\u00e4che unter der Glockenkurve, bei der an beiden Seiten 2,5% \u201eabgeschnitten\u201c sind. Jeweils 2,5 % aller Studenten sind kleiner als 160,4 cm oder gr\u00f6\u00dfer als 199,6 cm; 95 % haben eine Gr\u00f6\u00dfe zwischen diesen beiden Werten.\n8.2.4\nNormalisierende Transformationen\nBei den Anwendern der Statistik ist die Normalverteilung aus verschiedenen Gr\u00fcnden recht beliebt. Zum einen lassen sich Referenzbereiche auch ohne Computer sehr leicht berechnen; zum anderen setzen \u2013 wie wir sp\u00e4ter sehen werden \u2013 viele Verfahren der induktiven Statistik normalverteilte Daten voraus. Leider sind jedoch etliche Merkmale in der Medizin rechtsschief verteilt. Das hei\u00dft: Die Dichtefunktion hat einen Gipfel am linken Rand und einen langen Auslauf an der rechten Seite. Bei empirischen Daten ist dies optisch erkennbar am Histogramm. Rechnerisch l\u00e4sst sich die Verteilungsform \u00fcber die empirische Schiefe nach Formel (4.15) nachpr\u00fcfen; sie ist bei einer rechtsschiefen Verteilung \u203a Abbildung 4.1b). gr\u00f6\u00dfer als 0 (z\n8\n153 8.2 Die Normalverteilung\nAbb. 8.3 95%-Referenzbereich einer Normalverteilung 95% 2,5 %\n2,5 %\nEine solche Verteilung entsteht dadurch, dass ein Merkmal nach unten eine nat\u00fcrliche Grenze aufweist, w\u00e4hrend im oberen Wertebereich die Einflussfaktoren multiplikativ zusammen wirken. Dadurch ist die Variabilit\u00e4t der Messwerte am unteren Rand eingeschr\u00e4nkt, wohingegen im oberen Bereich die Werte durch zuf\u00e4llige \u00c4nderungen wesentlich st\u00e4rker beeinflusst werden. Als Beispiele seien das K\u00f6rpergewicht der erwachsenen Bev\u00f6lkerung, der systolische und der diastolische Blutdruck oder die Senkungsgeschwindigkeit von Erythrozyten genannt (jeweils mit 0 als untere Grenze). In diesen F\u00e4llen ist es eventuell m\u00f6glich, durch eine logarithmische Transformation der Originaldaten eine angen\u00e4herte Normalverteilung zu erhalten. Man betrachtet also anstelle der X-Variablen die transfomierte Y-Variable Y = ln X\n(8.15)\nWenn Y = ln X normalverteilt ist, hei\u00dft X logarithmisch normalverteilt (oder lognormalverteilt). Dabei ist \u201eln\u201c der nat\u00fcrliche Logarithmus zur Basis e (Euler\u2019sche Zahl). Man schreibt abk\u00fcrzend X ~ LN (\u00b5, \u03c3 2 ) , wobei \u00b5 den Erwartungswert und \u03c3 2 die Varianz von Y bezeichnen. Eine lognormalverteilte Zufallsvariable X muss positiv sein, da andernfalls die Transformation X \u2192 ln X nicht m\u00f6glich ist. Auf diese Weise werden kleine x-Werte zwischen 0 und 1 in negative y-Werte abgebildet; gro\u00dfe x-Werte am rechten Rand der Verteilung werden gestaucht. Die R\u00fccktransformation erfolgt \u00fcber: X = eY\n(8.16)\nDie Umrechnungen (8.15) oder (8.16) sind m\u00fchelos mit einem Taschenrechner zu bew\u00e4ltigen. Da die e-Funktion streng monoton\n154\nKapitel 8 \u00b7 Stetige Verteilungen\nwachsend ist, gilt f\u00fcr jede Zahl c > 0 : Y \u2264 c ist gleichbedeutend mit X = eY \u2264 e c . Daraus folgt: P (Y \u2264 c) = P ( X \u2264 e c )\n(8.17)\nAus dieser Eigenschaft lassen sich folgende Aussagen herleiten:\n\u0177 Allgemein lassen sich aus den Quantilen von Y = ln X nach \u0177 \u0177\n\u0177\n8\n\u0177\nR\u00fccktransformation die entsprechenden Quantile von X bestimmen. Die zur\u00fccktransformierten Grenzen der Referenzbereiche von Y sind die Grenzen der Referenzbereiche von X . Der Median der transformierten Variablen Y ist gleich deren Erwartungswert \u00b5 (da Y normalverteilt ist). Dann ist der Median der log-normalen Verteilung X gleich e \u00b5 ; denn wegen (8.17) gilt: P ( X \u2264 e \u00b5 ) = P (Y \u2264 \u00b5) = 0,5 . Der Erwartungswert von X ist nicht einfach zu bestimmen; bei \u203a Abdieser Verteilung ist jedoch das geometrische Mittel (z schnitt 4.2.6) ohnedies das sinnvollere Lagema\u00df. Aus der Formel (4.4) l\u00e4sst sich mit elementaren Berechnungen herleiten: Das geometrische Mittel der x-Werte entspricht dem Median e \u00b5 .\nBeispiel 8.3 Die Konzentrationswerte von Serum-IgM bei Kindern seien log-normalverteilt mit Werten zwischen 0,1 und 2,8 g/l. Durch Logarithmieren erhalte man eine normalverteilte Zufallsvariable Y mit dem Erwartungswert \u00b5 y = \u22120,36 und der Standardabweichung s y = 0,51 . Dann ergibt sich f\u00fcr den Median und\n~ = e \u22120,36 = 0,70 g/l. das geometrische Mittel von X: \u00b5 x F\u00fcr den 95%-Referenzbereich von Y berechnet man folgende Grenzwerte: y1 = \u00b5 \u2212 1,96\u03c3 = \u22120,36 \u2212 1,96 \u22c5 0,51 = \u22121,36 und y2 = \u00b5 + 1,96\u03c3 = \u22120,36 + 1,96 \u22c5 0,51 = 0,64\nInnerhalb der Grenzen x1 = e \u22121,36 = 0,26 g/l und\nx2 = e0,64 = 1,90 g/l liegen\ndemnach 95% aller IgM-Werte. Nur 2,5% sind gr\u00f6\u00dfer als 1,90 g/l, und 2,5 % sind kleiner als 0,26 g/l. i Wenn sich die 0 oder negative Werte unter den Original-Daten befinden, z bietet sich eine Transformation der Form Y = ln( X + a) (wobei a eine konstante, positive Zahl ist) an. Bei sehr schiefen Verteilungen mit extrem gro\u00dfen Werten erreicht man eine Normalverteilung eventuell durch 2-faches Logarithmieren: Y = ln ln ( X ) . Die optimale Art der Transformation muss empirisch bestimmt werden.\n155\n8\n8.3 S\u00e4tze der Wahrscheinlichkeitsrechnung\nWeit seltener werden in den Biowissenschaften linksschiefe Verteilungen beobachtet. Sie zeichnen sich aus durch einen langen Anlauf \u203a Abbildung 4.1c). Ihre links und einen Gipfel am rechten Rand (z Schiefe ist kleiner als 0. Bei diesen Verteilungen finden sich viele Daten im unteren Wertebereich, w\u00e4hrend nach oben eine nat\u00fcrliche Grenze existiert. Beispiele sind die Schwangerschaftsdauer, die Tragezeit von S\u00e4ugetieren oder der Kopfumfang von Neugeborenen. Eine Normalisierung dieser Verteilungen erreicht man durch eine Potenztransformation wie z. B.: Y = X 1,5\n(8.18)\nDadurch wird der Gipfel am rechten Rand in die Breite gezogen. Bei besonders stark ausgepr\u00e4gter Rechtsgipfeligkeit potenziert man mit einem h\u00f6heren Wert.\n8.3\nS\u00e4tze der Wahrscheinlichkeitsrechnung\nUm die eigentliche Bedeutung der Normalverteilung ermessen zu k\u00f6nnen, ben\u00f6tigen wir einige bekannte S\u00e4tze aus der Wahrscheinlichkeitsrechnung, die in diesem Abschnitt vorgestellt werden. 8.3.1\nDie Tschebyscheff\u2019sche Ungleichung\nVon dem russischen Mathematiker Pafnutij Tschebyscheff (18211879) wurde im Jahr 1874 die nach ihm benannte Tschebyscheff\u2019sche Ungleichung hergeleitet. Sie erlaubt eine Absch\u00e4tzung der Wahrscheinlichkeit, mit der die Zufallsvariable X um mehr als eine feste Zahl vom Erwartungswert \u00b5 abweicht. Es gilt:\nP(| X \u2212 \u00b5 |> k\u03c3) \u2264\n1 k2\nf\u00fcr alle k > 0\n(8.19)\nDiese Ungleichung l\u00e4sst sich auch in einer anderen Form schreiben, indem man den Faktor k\u03c3 durch \u03b5 (Epsilon) ersetzt: P (| X \u2212 \u00b5 |> \u03b5) \u2264\n\u03c32 \u03b52\nf\u00fcr alle \u03b5 > 0\n(8.20)\nDie Tschebyscheff\u2019sche Ungleichung setzt keine besondere Verteilungsform voraus \u2013 sie gilt generell f\u00fcr alle, also f\u00fcr symmetrische\n156\nKapitel 8 \u00b7 Stetige Verteilungen\nund schiefe Verteilungen. Allerdings sind die daraus hergeleiteten Absch\u00e4tzungen recht grob. F\u00fcr k = 1 ergibt sich aus (8.19) lediglich die triviale Feststellung: P (| X \u2212 \u00b5 |> \u03c3) \u2264 1\nF\u00fcr k = 2 und k = 3 berechnet man: P (| X \u2212 \u00b5 |> 2\u03c3) \u2264\n1 4\nP (| X \u2212 \u00b5 |> 3\u03c3) \u2264\n1 9\nDemnach liegen bei jeder Verteilung mindestens 8/9 aller Werte innerhalb der Grenzen \u00b5\u00b13\u03c3. Wenn genauere Informationen bez\u00fcglich der Verteilungsform vorliegen, sind bessere Absch\u00e4tzungen m\u00f6glich. Gau\u00df hat bereits 1821 f\u00fcr symmetrische, eingipfelige Verteilungen eine sch\u00e4rfere Ungleichung nachgewiesen: P (| X \u2212 \u00b5 |> k\u03c3) \u2264\n8\n4 9k 2\nf\u00fcr alle k \u2265 2\n3 \u2248 1,155\n(8.21)\nF\u00fcr k = 2 oder k = 3 erh\u00e4lt man damit folgende Absch\u00e4tzungen:\n1 \u2248 0,111 9 4 P (| X \u2212 \u00b5 |> 3\u03c3) \u2264 \u2248 0,049 81\nP(| X \u2212 \u00b5 |> 2\u03c3) \u2264\nMathematische Herleitung der Tschebyscheff\u2019schen Ungleichung Zun\u00e4chst betrachten wir eine stetige Zufallsvariable X mit dem Erwartungswert \u00b5, die nur positive Werte annehmen kann. Dann gilt nach der Definition des Erwartungswertes in (8.6) und nach (8.3) f\u00fcr alle c > 0 : +\u221e\n\u00b5=\n\u00b30\nxf ( x)dx \u2265\n+\u221e\n\u00b3\n+\u221e\nxf ( x)dx \u2265 c\u00b5\nc\u00b5\n\u00b3 f ( x)dx = c\u00b5 \u22c5 P( X > c\u00b5)\nc\u00b5\nDaraus folgt: P ( X > c\u00b5) \u2264 1 / c . Wenn man nun anstelle von X die Variable ( X \u2212 \u00b5) 2 mit dem Erwartungswert \u03c3 2 betrachtet und f\u00fcr c eine Konstante k 2 einsetzt, erh\u00e4lt man:\n(\n)\nP ( EX \u2212 \u00b5) 2 > k 2\u03c3 2 \u2264 1 / k 2 .\nDa der Ausdruck in der Klammer gleichbedeutend ist mit: EX \u2212 \u00b5 > k\u03c3 , folgt daraus die Tschebyscheff\u2019sche Ungleichung in der Form (8.19).\n8\n157 8.3 S\u00e4tze der Wahrscheinlichkeitsrechnung\nBeispiel 8.4 Wir betrachten die K\u00f6rpergr\u00f6\u00dfe X einer Grundgesamtheit einer m\u00e4nnlichen Population mit \u00b5 x = 180 cm und \u03c3 x = 10 cm . X ist symmetrisch verteilt. Dann gilt nach der Ungleichung von Gau\u00df: 8/9=89% der Studenten haben eine K\u00f6rpergr\u00f6\u00dfe zwischen 160 cm und 200 cm.\n8.3.2\nDas Gesetz der gro\u00dfen Zahlen\nEs ist intuitiv klar, dass sich der Erwartungswert einer Grundgesamtheit durch einen Mittelwert umso genauer sch\u00e4tzen l\u00e4sst, je gr\u00f6\u00dfer der zugrunde liegende Stichprobenumfang ist. Das Gesetz der gro\u00dfen Zahlen ist die mathematisch pr\u00e4zise Formulierung dieses Sachverhalts. Vorab einige \u00dcberlegungen: Wir wissen, dass der Mittelwert aus n Werten berechnet wird, die zuf\u00e4llig in die Stichprobe gelangen. Wenn man aus derselben Grundgesamtheit eine andere Stichprobe des Umfangs n ziehen w\u00fcrde, erhielte man andere StichprobenWerte und damit auch einen anderen Mittelwert. Bei einer gro\u00dfen Grundgesamtheit sind eine enorme Vielzahl von Stichproben des Umfangs n und fast ebenso viele verschiedene Mittelwerte denkbar. Demzufolge ist jeder Mittelwert vom Zufall abh\u00e4ngig und l\u00e4sst sich insofern auffassen als die Realisation einer Zufallsvariablen: n\nX =\n\u00a6 Xi i =1\nn\nAlle Variablen X i haben den Erwartungswert \u00b5 und die Varianz \u03c3 2 . F\u00fcr die Funktional-Parameter von X leitet man her: E( X ) = \u00b5 Var( X ) = \u03c3x =\n\u03c3 n\n(8.22) 2\n\u03c3 n\n(8.23) (8.24)\nDiese Betrachtung der Zufallsvariablen X ist f\u00fcr jemanden, der sich zum ersten Mal mit Wahrscheinlichkeitsrechnung befasst, eine eigenartige Sichtweise. Normalerweise liegt eine konkrete Stichprobe vor, aus der ein einziger Mittelwert resultiert. Wieso spricht man nun von der Verteilung der Mittelwerte, und was bedeuten in\n158\n8\nKapitel 8 \u00b7 Stetige Verteilungen\ndiesem Zusammenhang der Erwartungswert und die Standardabweichung von X ? Man muss sich \u2013 um einen Mittelwert beurteilen zu k\u00f6nnen \u2013 dar\u00fcber im Klaren sein, dass dieser Wert zuf\u00e4llig zustande gekommen ist, und dass sich ebenso gut ein anderer aus einer immensen Vielzahl von M\u00f6glichkeiten h\u00e4tte ergeben k\u00f6nnen. Die Variabilit\u00e4t dieser m\u00f6glichen Mittelwerte wird durch die Standardabweichung \u03c3 x quantifiziert. Sie wird deshalb auch als der Standardfehler des Mittelwerts bezeichnet. Dieser ist umso geringer, je kleiner die Standardabweichung der Grundgesamtheit \u03c3 und je gr\u00f6\u00dfer der Stichprobenumfang n ist. Aus diesem Grund erm\u00f6glichen homogene Grundgesamtheiten mit kleinem \u03c3 bessere Sch\u00e4tzungen des Erwartungswerts als heterogene Populationen mit gro\u00dfem \u03c3 . Wir werden in Kapitel 9 bei der Behandlung von Sch\u00e4tzverfahren darauf zur\u00fcckkommen. Im n\u00e4chsten Abschnitt 8.3.3 wird gezeigt, dass die Verteilung der Mittelwerte einer Normalverteilung entspricht. Nach diesen theoretischen \u00dcberlegungen l\u00e4sst sich nun das so genannte schwache Gesetz der gro\u00dfen Zahlen herleiten. Es beinhaltet die Aussage, dass sich ein Mittelwert x mit wachsendem Stichprobenumfang dem Erwartungswert \u00b5 n\u00e4hert. Mathematisch formuliert man dies folgenderma\u00dfen:\nX =\n1 n \u00a6 Xi \u2192 \u00b5 n i =1 n \u2192\u221e\n(8.25)\nMan sagt auch: Der Mittelwert konvergiert gegen den Erwartungswert. Die sch\u00e4rfere Form \u2013 das starke Gesetz der gro\u00dfen Zahlen \u2013 besagt, dass diese Ann\u00e4herung mit einer Wahrscheinlichkeit von nahezu 1 erfolgt. Sei \u03b5 > 0 eine beliebige positive Zahl; dann gilt: P (| X \u2212 \u00b5 |< \u03b5 ) \u2192 1 n \u2192\u221e\n(8.26)\nVerbal formuliert bedeutet die Formel (8.26), dass die Differenz \u03b5 zwischen Mittelwert und Erwartungswert beliebig klein gehalten werden kann, wenn n entsprechend gro\u00df ist. Einerseits rechtfertigt dieses Gesetz einen hohen Stichprobenumfang. Andererseits besagt es auch, dass ab einer gewissen Gr\u00f6\u00dfe der Unterschied zwischen Mittelwert und Erwartungswert so gering ist, dass eine Erh\u00f6hung des Stichprobenumfangs nicht mehr sinnvoll ist.\n159\n8\n8.3 S\u00e4tze der Wahrscheinlichkeitsrechnung\nMathematische Herleitung des Gesetzes der gro\u00dfen Zahlen Zun\u00e4chst berechnen wir den Erwartungswert und die Varianz des Mittelwerts. Mit (7.5) und (7.6) leitet man her: n 1 n n \u22c5\u00b5 E ( X ) = E (\u00a6 X i / n) = \u00a6 E ( X i ) = =\u00b5 n n i =1 i =1 F\u00fcr die Varianz berechnet man mit (7.9) und (7.12): n\nVar ( X ) = Var(\n1\nn\nX i / n) = \u00a6 \u00a6 Var( X i ) = n i i 2\n=1\n=1\nn \u22c5 \u03c32 n2\n=\n\u03c32 n\nDann folgt mit der Tschebyscheff\u2019schen Ungleichung (8.20):\n(\n)\nP | X \u2212 \u00b5 |> \u03b5 \u2264\nVar( X )\n=\n\u03c32\n\u2192 0 \u03b52 n\u03b5 2 n \u2192 \u221e Wenn man nun die Wahrscheinlichkeit f\u00fcr das komplement\u00e4re Ereignis X \u2212 \u00b5 < \u03b5 betrachtet, ergibt sich das Gesetz der gro\u00dfen Zahlen nach (8.26).\n8.3.3\nDer zentrale Grenzwertsatz\nDer zentrale Grenzwertsatz sagt aus, dass \u2013 unter sehr allgemeinen Bedingungen \u2013 die Summe einer gro\u00dfen Anzahl von Zufallsvariablen normalverteilt ist. Mathematisch pr\u00e4zise formuliert lautet dieser Satz: Seien X i ( i = 1,..., n ) unabh\u00e4ngige, identisch verteilte Zufallsvariablen mit dem Erwartungswert \u00b5 und der Varianz \u03c3 2 . Dann ist die Summe der X i asymptotisch normalverteilt mit dem Erwartungswert n \u22c5 \u00b5 und der Varianz n \u22c5 \u03c3 2 . Das bedeutet wiederum, dass die Variable n\nZn =\n\u00a6X\ni\n\u2212 n \u22c5\u00b5\ni =1\nn \u22c5\u03c3\n=\nX \u2212\u00b5 \u03c3/ n\nasymptotisch standardnormalverteilt ist. Daraus ergeben sich unmittelbar einige wichtige Konsequenzen bez\u00fcglich der:\n\u2022 Verteilung von Zufallsvariablen. Dieser Satz rechtfertigt die An nahme, dass eine Zufallsvariable normalverteilt ist, wenn zahlreiche Einfl\u00fcsse additiv und unabh\u00e4ngig voneinander zusammenwirken. Aus diesem Grund sind beispielsweise Messfehler normalverteilt. Carl Friedrich Gau\u00df hat dies bereits im Jahre 1794 erkannt und beschrieben; deshalb wird die Normalverteilung ihm zu Ehren auch Gau\u00df-Verteilung genannt.\n160\nKapitel 8 \u00b7 Stetige Verteilungen\n\u2022 Verteilung von Mittelwerten. Aus dem Gesetz der gro\u00dfen Zahlen geht hervor, dass die Gesamtheit aller theoretisch denkbaren Mittelwerte, die aus Stichproben des Umfangs n derselben Grundgesamtheit berechnet werden, den Erwartungswert \u00b5 und die Varianz \u03c3 2 / n hat. Aus dem zentralen Grenzwertsatz folgt nun, dass \u2013 falls der Stichprobenumfang n hinreichend gro\u00df ist (etwa n \u2265 25 ) \u2013 diese Mittelwerte normalverteilt sind (auch wenn die Grundgesamtheit nicht normalverteilt ist). Diese Aussage hat weit reichende Fol\u203a Beispiel 8.5). gen f\u00fcr die Methoden der induktiven Statistik (z \u2022 Binomialverteilung. Eine binomialverteilte Zufallsvariable X ~ B (n, p ) l\u00e4sst sich n\u00e4mlich auffassen als die Summe von n identisch verteilten, unabh\u00e4ngigen Variablen X i , die jeweils die Werte 1 oder 0 (mit den Wahrscheinlichkeiten p bzw. q = 1 \u2212 p ) annehmen k\u00f6nnen. Nach dem zentralen Grenzwertsatz kann eine Binomialverteilung f\u00fcr hinreichend gro\u00dfes n durch eine Normalverteilung X mit \u203a Abdem Erwartungswert \u00b5 = np und der Varianz \u03c32 = npq (z schnitt 7.2.2) approximiert werden. Als Faustregel gilt, dass dazu die Ungleichung npq \u2265 9 erf\u00fcllt sein muss.\n8\nBeispiel 8.5 Das K\u00f6rpergewicht weiblicher Studenten habe einen Erwartungswert von \u00b5 = 61 kg und eine Standardabweichung von \u03c3 = 6,2 kg . Wir f\u00fchren nun folgendes Gedankenexperiment durch: Aus der Grundgesamtheit werden mehrere Stichproben vom Umfang n = 30 entnommen und jeweils der Mittelwert bestimmt. Nach dem zentralen Grenzwertsatz sind diese Mittelwerte normalverteilt mit einem Erwartungswert von \u00b5 x = 61 kg und einer Standardabweichung von \u03c3 x = 6,2 / 30 kg = 1,13 kg . Wegen der Normalverteilung der x definieren \u00b5 x \u00b1 1,96 \u22c5 \u03c3 x = (61 \u00b1 1,96 \u22c51,13) kg einen 95%-Referenzbereich, d. h. P(58,8 kg \u2264 x \u2264 63,2 kg) = 0,95 . Man wird also bei einer Stichprobe des Umfangs n = 30 mit 95%-iger Wahrscheinlichkeit einen Mittelwert zwischen 58,8 und 63,2 kg erhalten; die Wahrscheinlichkeiten, dass der Mittelwert kleiner ist als 58,8 kg oder gr\u00f6\u00dfer als 63,2 kg, betragen jeweils 2,5 %. i Der Zusammenhang zwischen Binomial- und Normalverteilung wurde z von dem franz\u00f6sischen Mathematiker Abraham de Moivre (1667-1754) im Jahre 1718 erkannt und in seinem Werk \u201eThe doctrine of chances\u201c beschrieben. De Moivre hat die Normalverteilung sozusagen \u201eentdeckt\u201c. Von Gau\u00df wurde sie einige Jahrzehnte sp\u00e4ter bei der Erarbeitung seiner Fehlertheorie wiederentdeckt. Es wurde schon fr\u00fch vermutet, dass die Aussage des zentralen Grenzwertsatzes gilt. Der Beweis f\u00fcr diesen Satz wurde jedoch erst im Jahre 1920 erbracht.\n161\n8\n8.3 S\u00e4tze der Wahrscheinlichkeitsrechnung\n8.3.4\nDie Bedeutung der Normalverteilung\nDie zentrale Bedeutung der Normalverteilung f\u00fcr die Statistik und deren Anwendung in den Biowissenschaften muss unter verschiedenen Aspekten beurteilt werden. Sie l\u00e4sst sich ansehen als:\n\u2022 Eine empirische Verteilung. Der belgische Astronom und Physi ker Adolphe Quetelet (1796-1874) gab ein fr\u00fches Beispiel f\u00fcr die Normalverteilung eines Merkmals menschlicher Individuen: Ihm war aufgefallen, dass die Daten des Brustumfangs von 5.738 schottischen Soldaten angen\u00e4hert normalverteilt sind. Der Name \u201eNormalverteilung\u201c wurde von Francis Galton im Jahr 1880 eingef\u00fchrt. Einige Wissenschaftler vertraten damals die Auffassung, dass die belebte Natur bei jedem Merkmal die Normalverteilung anstrebe. \u201eNormal\u201c wird dabei im Sinne von \u201eallgemein \u00fcblich\u201c oder \u201ephysiologisch\u201c verwendet. Wir wissen heute, dass dieser Ansatz nicht stimmt. Es gibt zwar einige medizinisch relevante Merkmale, die angen\u00e4hert normalverteilt sind (z. B. die K\u00f6rpergr\u00f6\u00dfe erwachsener M\u00e4nner). Andere wichtige Verteilungen in der Medizin sind jedoch \u203a Abschnitt 8.4). nicht symmetrisch (z. B. \u00dcberlebenszeiten, z \u2022 Eine approximative Verteilung. Schiefe Verteilungen lassen sich \u203a Abschnitt eventuell in eine Normalverteilung transformieren (z 8.2.4). Die Binomial- und auch die Poissonverteilung lassen sich unter gewissen Bedingungen durch die Normalverteilung approximie\u203a Abschnitt 8.3.3). ren (z \u2022 Eine Verteilung f\u00fcr statistische Kennwerte. Nach dem zentralen Grenzwertsatz sind die Mittelwerte aus Stichproben des Umfangs n beliebiger Verteilungen normalverteilt. Bei normalverteilten Grundgesamtheiten sind auch andere Kenngr\u00f6\u00dfen wie z. B. der Median, die Varianz etc. normalverteilt. Ansonsten k\u00f6nnen allerdings die Verteilungen statistischer Kennwerte \u2013 au\u00dfer der des Mittelwertes \u2013 erheblich von der Normalverteilung abweichen. \u2022 Eine Basisverteilung f\u00fcr Pr\u00fcfverteilungen. Die Normalverteilung bildet die Grundlage f\u00fcr die wichtigsten Pr\u00fcfverteilungen, die in der \u203a Abschnitt 8.5). induktiven Statistik Anwendung finden (z\n162\nKapitel 8 \u00b7 Stetige Verteilungen\n8.4\nDie Verteilung von \u00dcberlebenszeiten\n8.4.1\nEinige wichtige Begriffe\nIn diesem Abschnitt werden zwei wichtige Verteilungen vorgestellt, die in der medizinischen Forschung bei \u00dcberlebenszeitanalysen benutzt werden.\n8\n\u2022 \u00dcberlebenszeit. Das wesentliche Merkmal, das bei diesen Studien untersucht wird, ist die Dauer, die zwischen einem definierten Anfangsereignis und dem Eintritt eines zufallsbedingten Endereignisses vergeht. Diese Zeitspanne wird \u00dcberlebenszeit genannt. Die Anfangsereignisse sind beispielsweise die Geburt eines Individuums oder der Beginn einer therapeutischen Ma\u00dfnahme; bei den Endereignissen handelt es sich \u00fcblicherweise um den Tod eines Patienten, den eingetretenen Heilerfolg, das Ende der Beschwerdefreiheit, das Auftreten eines bestimmten Symptoms oder den Ausfall eines transplantierten Organs. Wenn ein Lebewesen vom Zeitpunkt der Geburt bis zu seinem Tod beobachtet wird, spricht man von Lebensdauer. Dieser Begriff wird auch in der Technik verwendet, wo er die Zeit zwischen dem Betriebsbeginn und dem Ausfall eines Objekts bezeichnet. Der Begriff \u201e\u00dcberlebenszeit\u201c ist also nicht unbedingt gleichbedeutend mit der Zeit, die bis zum Tod eines Individuums vergeht. Wenn wir im Folgenden dennoch das kritische Endereignis mit \u201eTod\u201c oder \u201eSterben\u201c gleichsetzen, dann geschieht dies deshalb, weil diese Begriffe anschaulicher und pr\u00e4gnanter sind als Formulierungen wie etwa \u201edas Eintreten des kritischen Endereignisses\u201c. \u2022 \u00dcberlebensfunktion. Sei T eine Zufallsvariable zur Beschreibung einer \u00dcberlebenszeit. T kann sinnigerweise nur positive Werte annehmen, die im Folgenden \u2013 da es sich um Zeiten handelt \u2013 mit dem Buchstaben t (vom lateinischen tempus) symbolisiert werden. Die dazugeh\u00f6rende Verteilungsfunktion F(t) gibt die Wahrscheinlichkeit an, mit der ein Individuum vor dem Zeitpunkt t stirbt. Daraus ergibt sich die \u00dcberlebenswahrscheinlichkeit oder \u00dcberlebensfunktion: S (t ) = P(T > t ) = 1 \u2212 F (t )\n(8.27)\nS (t ) ist also die Wahrscheinlichkeit, dass ein Individuum den Zeitpunkt t \u00fcberlebt. Der Buchstabe S ist abgeleitet vom englischen Ausdruck \u201esurvival function\u201c.\n163\n8\n8.4 Die Verteilung von \u00dcberlebenszeiten\n\u2022 Bedingte \u00dcberlebenswahrscheinlichkeit. Sie quantifiziert die Wahrscheinlichkeit f\u00fcr ein Individuum, das den Zeitpunkt t erreicht hat, eine weitere Zeitspanne der L\u00e4nge \u2206t (Delta t) zu \u00fcberleben. Sie l\u00e4sst sich nach Formel (6.8) berechnen als: P (T > t + \u2206t T > t ) =\nP (T > t + \u2206t ) P (T > t )\n(8.28)\n\u2022 Momentane Sterberate r (t ) (auch Hazard-Rate oder im techni schen Bereich Ausfallrate genannt). Sie ist durch folgende Beziehung charakterisiert: r (t ) =\nf (t ) S (t )\n(8.29)\nDabei ist f (t ) die Dichtefunktion der Variablen T. Die momentane Sterberate hat gegen\u00fcber der in Abschnitt 6.3 eingef\u00fchrten Mortalit\u00e4t den Vorteil, dass sie unabh\u00e4ngig vom Beobachtungszeitraum ist und f\u00fcr jeden Zeitpunkt t angegeben werden kann. Mathematische Herleitung der Sterberate Die Sterberate r (t ) basiert auf der bedingten Wahrscheinlichkeit, dass ein Individuum, nachdem es den Zeitpunkt t \u00fcberlebt hat, im darauf folgenden Zeitintervall der L\u00e4nge t + \u2206t stirbt. Diese Wahrscheinlichkeit ist wegen der Definition von F (t ) und S (t ) : P(t < T \u2264 t + \u2206t ) F (t + \u2206t ) \u2212 F (t ) = P (T > t ) S (t ) Unter der momentanen Sterberate versteht man nun diese Wahrscheinlichkeit bezogen auf ein infinitesimal kleines Zeitintervall der L\u00e4nge \u2206t : F (t + \u2206t ) \u2212 F (t ) 1 r (t ) = lim \u22c5 \u2206t \u2192 0 \u2206t S (t ) P (t < T \u2264 t + \u2206t | X > t ) =\nF\u00fcr den Differentialquotienten gilt: lim\n\u2206t \u2192 0\nDaraus ergibt sich: r (t ) =\nf (t ) . S (t )\nF (t + \u2206t ) \u2212 F (t ) dF (t ) = = f (t ) . \u2206t d (t )\n164 8.4.2\nKapitel 8 \u00b7 Stetige Verteilungen\nDie Exponentialverteilung\nIm einfachsten Fall l\u00e4sst sich die \u00dcberlebenswahrscheinlichkeit modellieren als (wobei \u03bb > 0 ): S (t ) = P(T > t ) = e \u2212\u03bbt\n(8.30)\n(\u03bb = griechischer Buchstabe lambda). Die Wahrscheinlichkeit, mit der ein Individuum vor dem Zeitpunkt t stirbt, ist demnach: F (t ) = 1 \u2212 S (t ) = P (T \u2264 t ) = 1 \u2212 e \u2212\u03bbt\n(8.31)\nEine Zufallsvariable T mit dieser Verteilungsfunktion nennt man exponentialverteilt T ~ Exp(\u03bb ) . F\u00fcr die Dichtefunktion ergibt sich: f (t ) = F ' (t ) = \u03bbe \u2212\u03bbt\n8\n(8.32)\nDie Exponentialverteilung hat einige bemerkenswerte Eigenschaften. F\u00fcr die bedingte \u00dcberlebenswahrscheinlichkeit folgt mit (8.28) und (8.30): P (T > t + \u2206t T > t ) =\ne \u2212 \u03bb (t + \u2206t ) e\n\u2212 \u03bbt\n= e \u2212\u03bb\u22c5\u2206t\n(8.33)\nDie Wahrscheinlichkeit, noch eine Zeitspanne der L\u00e4nge \u2206t zu leben, ist also unabh\u00e4ngig vom Alter. Deshalb wird die Exponentialverteilung auch ged\u00e4chtnislose Verteilung genannt. Wegen dieser Eigenschaft ist die Sterberate \u00fcber die Zeit konstant; mit (8.29), (8.32) und (8.30) berechnet man n\u00e4mlich: r (t ) =\nf (t ) \u03bbe \u2212 \u03bbt = \u2212 \u03bbt = \u03bb S (t ) e\n(8.34)\nDeshalb eignet sich die Exponentialverteilung zur Beschreibung von Lebensdauern nicht alternder Objekte oder von \u00dcberlebenszeiten bei Individuen, deren Tod unabh\u00e4ngig vom aktuellen Alter eintritt. Typische Beispiele sind die Lebensdauern radioaktiver Teilchen oder das \u00dcberleben nach einer schweren Erkrankung mit kurzer Lebenserwartung. Weitere wichtige Kenngr\u00f6\u00dfen sind der Median (der bei \u00dcberlebenszeitstudien auch mediane \u00dcberlebenszeit genannt wird), der Erwartungswert (auch mittlere Lebensdauer genannt) und die Varianz:\n165\n8\n8.4 Die Verteilung von \u00dcberlebenszeiten\n~ = 1 \u22c5 ln 2 \u00b5 \u03bb\n(8.35)\n1 \u03bb\n(8.36)\n\u00b5=\n\u03c32 =\n1\n(8.37)\n\u03bb2\nDiese Ma\u00dfzahlen sind also umso gr\u00f6\u00dfer, je kleiner die momentane Sterberate \u03bb ist. Die Schiefe betr\u00e4gt grunds\u00e4tzlich 2 \u2013 demnach ist die Exponentialverteilung ebenso wie die Lognormalverteilung rechtsschief. i Der Median l\u00e4sst sich relativ einfach berechnen, indem man die Funktion z ~ ) = 0,5 in (8.31) nach \u00b5 ~ aufl\u00f6st. Der Erwartungswert, die Varianz F (\u00b5 und die Schiefe ergeben sich durch aufwendige Integralrechnungen.\n8.4.3\nDie Weibull-Verteilung\nDie Weibull-Verteilung ist nach dem schwedischen Ingenieur Waloddi Weibull (1887-1979) benannt, der damit die Bruchfestigkeit von Werkzeugen beschrieb. Im medizinischen Umfeld wird sie haupts\u00e4chlich zur Analyse von \u00dcberlebenszeiten verwendet. Eine Zufallsvariable T hei\u00dft Weibull-verteilt mit den Parametern \u03bb > 0 und \u03b3 > 0 , wenn f\u00fcr ihre Verteilungsfunktion gilt:\nF (t ) = 1 \u2212 e \u2212 \u03bb\u22c5t\n\u03b3\nf\u00fcr t > 0\n(8.38)\nDurch die beiden Parameter \u03bb (lambda) und \u03b3 (gamma) ist die Verteilung eindeutig festgelegt; man schreibt: T ~ WB(\u03bb, \u03b3 ) . Im Vergleich mit (8.31) wird deutlich, dass die Weibull-Verteilung eine Verallgemeinerung der Exponentialverteilung darstellt. Durch den zus\u00e4tzlichen Parameter \u03b3 ist sie wesentlich flexibler; die Dichteund die \u00dcberlebensfunktion sowie die Parameter sind allerdings erheblich komplizierter zu berechnen. Aus der Verteilungsfunktion (8.38) leitet man her: S (t ) = P( X > t ) = 1 \u2212 F (t ) = e \u2212 \u03bb\u22c5t f (t ) = F '(t ) = \u03bb\u03b3 \u22c5 t ( \u03b3\u22121) \u22c5 e \u2212\u03bb\u22c5t\n\u03b3\n\u03b3\n(8.39) (8.40)\n166\nKapitel 8 \u00b7 Stetige Verteilungen\nDaraus ergibt sich f\u00fcr die momentane Sterberate: r (t ) =\nf (t ) = \u03bb\u03b3 \u22c5 t \u03b3 \u22121 S (t )\n(8.41)\nEs lassen sich nun drei F\u00e4lle unterscheiden:\n\u0177 Sterberate konstant ( \u03b3 = 1 ). Dieser Spezialfall ist die Exponentialverteilung.\n\u0177 Sterberate monoton wachsend ( \u03b3 > 1 ). Eine Weibullverteilung mit \u03b3 > 1 ist geeignet, ein \u00dcberleben mit Altern zu beschreiben.\n\u0177 Sterberate monoton fallend ( 0 < \u03b3 < 1 ). Diese Verteilung be-\nschreibt ein \u00dcberleben mit Regeneration, bei dem mit wachsendem Alter die Sterberate abnimmt.\nDen Median einer Weibullverteilung berechnet man, indem man die ~ ) = 0,5 aufl\u00f6st; aus (8.38) ergibt sich unter AnwenGleichung F (\u00b5 dung elementarer Rechenregeln: 1/ \u03b3\n~ = \u00a7\u00a8 ln 2 \u00b7\u00b8 \u00b5 \u00a9 \u03bb \u00b9\n8\n(8.42)\nDieser Parameter gibt an, nach welcher Zeit die H\u00e4lfte der Beobachtungseinheiten verstorben ist. i Die Berechnung anderer Parameter (Erwartungswert, Varianz) erfordert z die Kenntnis einer speziellen Funktion (n\u00e4mlich der so genannten Gamma-Funktion). Ausf\u00fchrliche Informationen zu diesem Thema findet man in [9].\n8.5\nPr\u00fcfverteilungen\nWir wissen, dass nicht nur einzelne Messwerte xi , sondern auch statistische Kennwerte wie etwa der Mittelwert x oder die empirische Standardabweichung s dem Zufall unterliegen und damit als Realisationen einer Zufallsvariablen X bzw. S aufgefasst werden k\u00f6nnen. Die Pr\u00fcfverteilungen dienen dazu, die Verteilung von statistischen Kenngr\u00f6\u00dfen zu beschreiben. Die Pr\u00fcfverteilungen sind die Grundlage f\u00fcr die Sch\u00e4tz- und Testmethoden der induktiven Statistik. Deren Anwendung setzt zwar nicht unbedingt spezielle Kenntnisse bez\u00fcglich der Pr\u00fcfverteilungen voraus. Mathematisch weniger interessierte Leser k\u00f6nnen\n167\n8\n8.5 Pr\u00fcfverteilungen\ndaher diesen Abschnitt 8.5 \u00fcberschlagen. Allerdings erscheinen die Verfahren der induktiven Statistik logischer und leichter nachvollziehbar, nachdem man sich mit dem theoretischen Hintergrund dieser Verteilungen etwas n\u00e4her befasst hat. 8.5.1\nDie t-Verteilung\nDiese Verteilung wurde im Jahre 1908 von dem Engl\u00e4nder William Sealy Gosset (1876-1937) ver\u00f6ffentlicht. Gosset befasste sich mit der Sch\u00e4tzung von Mittelwerten, deren Verteilung nach dem zentralen \u203a Abschnitt 8.3.3) durch die standardnormalverGrenzwertsatz (z teilte Zufallsvariable Z=\nX \u2212\u00b5 \u03c3/ n\nbeschrieben wird. In der Praxis ist jedoch der Parameter \u03c3 meist unbekannt. Deshalb ist die Verteilung von Z nur theoretisch interessant, aber f\u00fcr praktische Untersuchungen wenig aufschlussreich. Aus diesem Grund ersetzte Gosset das \u03c3 durch die empirische Standardabweichung s und betrachtete anstelle von Z die Variable T=\nX \u2212\u00b5 S/ n\n(8.43)\nDiese Verteilung ging als Student- oder t-Verteilung in die Literatur ein. Sie ist f\u00fcr alle n \u2265 2 (also auch f\u00fcr kleine Stichprobenumf\u00e4nge) definiert. Dabei muss allerdings vorausgesetzt werden, dass die Einzelbeobachtungen X i , aus denen X und S berechnet werden, normalverteilt sind mit dem Erwartungswert \u00b5 und der Varianz \u03c3 2 . Die t-Verteilung hat \u00e4hnliche Eigenschaften wie die Standardnormalverteilung:\n\u0177 Sie ist symmetrisch um 0, stetig und glockenf\u00f6rmig, \u0177 sie kann Werte zwischen \u2212\u221e und +\u221e annehmen, und \u0177 der Erwartungswert ist 0. Es gibt allerdings zwei wesentliche Unterschiede:\n\u0177 Sie ist nicht direkt abh\u00e4ngig von \u03c3 (sondern nur von s), \u0177 sie ist aber abh\u00e4ngig vom Parameter f, der die Anzahl der Frei-\nheitsgrade angibt. Die t-Verteilung nach (8.43) hat f = n \u2212 1 Freiheitsgrade. Diese Anzahl begr\u00fcndet sich dadurch, dass in die\n168\nKapitel 8 \u00b7 Stetige Verteilungen\nBerechnung der t -Gr\u00f6\u00dfe n Beobachtungen einflie\u00dfen, die einer einschr\u00e4nkenden Bedingung (durch die Vorgabe des Mittelwertes x ) unterliegen. Es existiert also f\u00fcr jeden Freiheitsgrad f eine spezielle t-Verteilung. Die Varianz betr\u00e4gt f /( f \u2212 2) f\u00fcr alle f \u2265 3 und ist damit gr\u00f6\u00dfer als 1. Demzufolge hat die t-Verteilung f\u00fcr kleine Freiheitsgrade einen flacheren Verlauf als die Standard-Normalverteilung. F\u00fcr gro\u00dfe Freiheitsgrade geht sie in die Normalverteilung \u00fcber. Die t-Verteilung spielt eine wichtige Rolle bei der Sch\u00e4tzung \u203a Kapitel 9 bis 11). Einige und dem Vergleich von Lagema\u00dfen (z Quantile, die f\u00fcr Sch\u00e4tz- und Testverfahren wichtig sind, sind in Tabelle B im Anhang aufgelistet. i Gosset war eigentlich als Chemiker bei der bekannten Bierbrauerei Guinz ness angestellt und betrieb Statistik als Hobby. Weil er als Angestellter seiner Firma nicht unter seinem Namen ver\u00f6ffentlichen wollte, benutzte er das Pseudonym \u201eStudent\u201c.\n8\n8.5.2\nDie Chi2-Verteilung\nDie Chi2-Verteilung (sprich: Chi-Quadrat, auch mit dem griechischen Buchstaben \u03c7 2 geschrieben) beschreibt in ihrer einfachsten Form die Verteilung des Quadrats einer standnormalverteilten Zufallsvariablen Z ~ N (0,1) . F\u00fcr den Erwartungswert von \u03c712 = Z 2 gilt: EZ 2 = VarZ + ( EZ ) 2 = 1\n(8.44)\nDie Gleichung (8.44) leitet man aus der Definition der Varianz nach (7.7) her, indem man X durch Z ersetzt. Falls nun mehrere Variablen Z1 ,..., Z n unabh\u00e4ngig voneinander nach N (0,1) verteilt sind, ist deren Quadratsumme\n\u00a6Z\n2 i\n\u03c7 2 -verteilt\nmit n Freiheitsgraden oder (anders ausgedr\u00fcckt): \u03c7 2n -verteilt. Wegen (8.44) ist der Erwartungswert dieser Zufallsvariablen gleich n, die Varianz betr\u00e4gt 2n und die Schiefe \u03b3 1 = 8 / n . Die \u03c7 2n \u203a Abbildung 8.4). Mit wachVerteilung ist also immer rechtsschief (z sendem n n\u00e4hert sie sich einer Normalverteilung. Wir betrachten nun n unabh\u00e4ngige, normalverteilte Variable X i ~ N (\u00b5, \u03c32 ) . Dann sind die ( X i \u2212 \u00b5) / \u03c3 standardnormalverteilt, und demnach gilt f\u00fcr deren Quadratsumme:\n169\n8\n8.5 Pr\u00fcfverteilungen\nAbb. 8.4 Dichtefunktionen von Chi2-Verteilungen mit unterschiedlichen Freiheitsgraden n\n2\n\u00a7 Xi \u2212 \u00b5 \u00b7 \u03c72n \u03c3 \u00b8\u00b9 i =1 n\n\u00a6 \u00a8\u00a9\n(8.45)\nWenn wir in diesem Ausdruck den Erwartungswert \u00b5 durch die Variable X ersetzen, erhalten wir eine \u03c7 2 -Verteilung mit n \u2212 1 Freiheitsgraden, da die X i wegen des Mittelwerts X einer einschr\u00e4nkenden Bedingung unterliegen. Daraus folgt: 2\n\u00a7 Xi \u2212 X \u00b7 ( n \u2212 1) \u22c5 S 2 \u03c72n \u22121 = \u00a6 \u00a8 \u00b8 \u03c3 \u00b9 \u03c32 i =1 \u00a9 n\n(8.46)\nDer Erwartungswert dieser Variablen ist n \u2212 1 , die Varianz betr\u00e4gt 2( n \u2212 1) . Diese Eigenschaften sind fundamental f\u00fcr die Sch\u00e4tzung der Varianz aus einer Stichprobe vom Umfang n . Zahlreiche statistische Tests (insbesondere Homogenit\u00e4ts- und Unabh\u00e4ngigkeitstests, \u203a Kapitel 12) basieren auf der \u03c7 2 -Verteilung. Wichtige Quantile z findet man im Anhang in Tabelle E. i Die Chi2-Verteilung verdanken wir Forschungen auf dem Gebiet der z Astronomie. Sie geht zur\u00fcck auf den Physiker und Astronomen Ernst Abbe (1840-1905), der sie erstmals 1863 erw\u00e4hnt. Abbe war Professor an der Universit\u00e4t in Jena und Direktor der dortigen Sternwarte. Unabh\u00e4ngig von Abbe wurde die Chi2-Verteilung von Friedrich Robert Helmert (1843-1917), der Astronom und Mathematiker war, entdeckt. Sie geriet dann in Vergessenheit, bis sie von Karl Pearson einige Jahre sp\u00e4ter wiederentdeckt wurde und seither vielf\u00e4ltige Anwendung bei den Verfahren der induktiven Statistik findet.\n170\nKapitel 8 \u00b7 Stetige Verteilungen\n8.5.3\nDie F-Verteilung\nAls dritte Pr\u00fcfverteilung sei die F-Verteilung erw\u00e4hnt (benannt nach Sir Ronald Aylmer Fisher). Seien S12 und S 22 die Varianzen zweier unabh\u00e4ngiger Stichproben aus zwei normalverteilten Grundgesamtheiten mit derselben Varianz \u03c32. Dann folgt die Variable Fm ,n =\nS12 S22\n(8.47)\neiner F-Verteilung mit m und n Freiheitsgraden im Z\u00e4hler bzw. im Nenner. Diese Zahlen entsprechen den um 1 reduzierten Stichprobenumf\u00e4ngen. Die F-Verteilung findet u. a. Anwendung bei der Varianzanalyse. Es lassen sich folgende Beziehungen nachweisen: F1,n = tn2\nFm ,n =\n8\n(8.48)\n\u03c7m2 n \u22c5 \u03c7 n2 m\n(8.49)\n\u00dcbersicht 7: Stetige Verteilungen Name und Bezeichnung der Verteilung\nAbschnitt\nX beschreibt\nBeispiele\nN (\u00b5, \u03c3 2 )\n8.2.1 8.2.3\nsymmetrisch verteilte Daten, Dichte glockenf\u00f6rmig\nMessfehler, K\u00f6rpergr\u00f6\u00dfe\nlogarithmische Normalverteilung\n8.2.4\nrechtsschief verteilte Daten\nK\u00f6rpergewicht, Blutdruck\nExponentialverteilung Exp(\u03bb)\n8.4.2\nLebensdauern mit konstanter Sterberate\nZerfall radioaktiver Teilchen\nWeibullverteilung WB(\u03bb, \u03b3 )\n8.4.3\nLebensdauern mit nicht konstanter Sterberate\n\u00dcberleben mit Altern, \u00dcberleben mit Regeneration\nNormalverteilung\n2\nLN (\u00b5, \u03c3 )\n9\nSch\u00e4tzverfahren 9.1\nGrundlagen 173\n9.2\nPunktsch\u00e4tzungen 173\n9.2.1\nDer Begriff der Punktsch\u00e4tzung 173\n9.2.2\nKriterien zur G\u00fcte einer Sch\u00e4tzung 174\n9.2.3\nSpezielle Sch\u00e4tzfunktionen 175\n9.3\nIntervallsch\u00e4tzungen 177\n9.3.1\nDie Bedeutung eines Konfidenzintervalls 177\n9.3.2\nKonfidenzintervalle f\u00fcr einen Erwartungswert 179\n9.3.3\nKonfidenzintervall f\u00fcr eine Wahrscheinlichkeit 182\n9.3.4\nKonfidenzintervalle f\u00fcr Zusammenhangsma\u00dfe 183\n9.4\nAbschlie\u00dfende Bemerkungen 184\n9.4.1\nDie Bedeutung des Stichprobenumfangs 184\n9.4.2\nZu den Voraussetzungen 186\n173\n9\n9.1 Grundlagen\n9.1\nGrundlagen\nWir haben in den vorangegangenen Kapiteln Zufallsvariablen X und deren Verteilungen kennen gelernt und durch charakteristische Parameter beschrieben. Diese Betrachtungen waren allerdings rein theoretischer Natur. Die Eigenschaften von X k\u00f6nnen in der Regel nicht exakt bestimmt werden, da man sich bei empirischen Untersuchungen normalerweise nur auf eine Stichprobe st\u00fctzen kann. Man ist also darauf angewiesen, anhand einzelner Stichprobenwerte Informationen bez\u00fcglich der Grundgesamtheit und der Zufallsvariablen X zu gewinnen. Dazu dienen die Methoden der induktiven Statistik (auch schlie\u00dfende, analytische oder beurteilende Statistik genannt). Bei diesen Verfahren muss grunds\u00e4tzlich vorausgesetzt werden, dass eine zuf\u00e4llige Stichprobe vorliegt, die repr\u00e4sentativ f\u00fcr ein \u00fcbergeordnetes Kollektiv (die Grundgesamtheit) ist. Oft sind gewisse Eigenschaften von X (etwa der Verteilungstyp) aus Erfahrung bekannt oder ergeben sich aus der Beschreibung der zugrunde liegenden Zufallsexperimente. Die charakteristischen Parameter sind dagegen meist unbekannt. So kann man beispielsweise leicht nachvollziehen, dass bei einer klinischen Studie mit einer bestimmten Anzahl von Patienten der Heilungserfolg eines Medikaments durch eine Binomialverteilung beschrieben werden kann, wobei die einzelnen Zufallsvariablen X i die Werte 1 (Heilung erfolgreich) oder 0 (Heilung nicht erfolgreich) annehmen k\u00f6nnen. Es liegt jedoch in der Natur der Sache, dass eine exakte Angabe der Erfolgswahrscheinlichkeit p a priori nicht m\u00f6glich ist. Man ist daher bem\u00fcht, anhand der Stichprobe den oder die unbekannten Parameter der Grundgesamtheit ann\u00e4hernd zu bestimmen. Bisher haben wir kaum Gedanken dar\u00fcber angestellt, welche Anforderungen an ein Sch\u00e4tzverfahren zu stellen sind und wie die G\u00fcte eines Sch\u00e4tzwertes zu beurteilen ist. Diesen Fragen werden wir in den folgenden Abschnitten nachgehen.\n9.2\nPunktsch\u00e4tzungen\n9.2.1\nDer Begriff der Punktsch\u00e4tzung\nEs liegt intuitiv nahe, die Funktionalparameter einer Grundgesamtheit durch die entsprechenden Kenngr\u00f6\u00dfen einer zuf\u00e4lligen Stichprobe zu sch\u00e4tzen. So erscheint der Mittelwert als Sch\u00e4tzwert f\u00fcr\n174\nKapitel 9 \u00b7 Sch\u00e4tzverfahren\nden Erwartungswert geeignet; eine Wahrscheinlichkeit wird durch eine relative H\u00e4ufigkeit gesch\u00e4tzt. Man nennt ein solches Verfahren, bei dem ein unbekannter Parameter durch einen einzigen Wert gesch\u00e4tzt wird, eine Punktsch\u00e4tzung. Die Sch\u00e4tzfunktion (oder der Sch\u00e4tzer) ist eine Vorschrift, nach der aus den Daten einer Stichprobe des Umfangs n ein angen\u00e4herter Wert f\u00fcr den unbekannten Parameter berechnet wird. So lautet z. B. die Sch\u00e4tzfunktion f\u00fcr den Erwartungswert: n\nX =\n\u00a6 Xi i =1\nn\n(9.1)\nDie Werte, die die Sch\u00e4tzfunktion in Abh\u00e4ngigkeit von der jeweiligen Stichprobe annimmt, nennt man Sch\u00e4tzwerte. 9.2.2\n9\nKriterien zur G\u00fcte einer Sch\u00e4tzung\nDie oben genannten Punktsch\u00e4tzungen sind nicht so selbstverst\u00e4ndlich, wie es auf den ersten Blick scheinen mag. Niemand bezweifelt zwar, dass der Erwartungswert durch den Mittelwert optimal gesch\u00e4tzt wird. Was aber spricht dagegen, bei symmetrischen Verteilungen den Erwartungswert durch den empirischen Median zu sch\u00e4tzen \u2013 zumal dies mit weniger Rechenaufwand verbunden w\u00e4re? Au\u00dferdem ist bisher nicht eindeutig gekl\u00e4rt, weshalb bei der empirischen Varianz oder bei der empirischen Kovarianz durch n \u2212 1 dividiert wird (und nicht durch den Stichprobenumfang n ). Um diese Fragen zu beantworten, bedarf es objektiver und nachpr\u00fcfbarer Eigenschaften, nach denen sich die G\u00fcte einer Sch\u00e4tzung beurteilen l\u00e4sst. Hierzu orientiert man sich an den folgenden vier Kriterien, die von Sir Ronald Aylmer Fisher aufgestellt wurden: \u2022 Erwartungstreue. Man kann nicht erwarten, dass eine einzelne Stichproben-Kenngr\u00f6\u00dfe den unbekannten Parameter exakt wiedergibt. Allerdings sollte die Sch\u00e4tz-Vorschrift nicht systematisch einen zu hohen oder zu niedrigen Wert liefern. Das Kriterium der Erwartungstreue fordert daher, dass der Durchschnitt (oder genauer: der Erwartungswert) aller theoretisch denkbaren Sch\u00e4tzwerte aus den Stichproben des Umfangs n mit dem unbekannten Parameter \u00fcbereinstimmt. Eine erwartungstreue Sch\u00e4tzung hei\u00dft unverzerrt. \u2022 Konsistenz. Es ist au\u00dferdem plausibel, von einem guten Sch\u00e4tzer Folgendes zu verlangen: Je gr\u00f6\u00dfer der Stichprobenumfang n, desto\n175\n9\n9.2 Punktsch\u00e4tzungen\ngenauer sollte die Sch\u00e4tzung sein. Ein Sch\u00e4tzer ist immer dann konsistent, wenn dessen Varianz f\u00fcr gro\u00dfe n gegen 0 geht. \u2022 Effizienz. Die Varianz des Sch\u00e4tzers sollte m\u00f6glichst gering sein. Je geringer sie ist, desto pr\u00e4ziser ist die Sch\u00e4tzung. Eine hohe Effizienz bedeutet, dass auch eine kleine Stichprobe einen brauchbaren Sch\u00e4tzwert liefert. Die Effizienz ist insbesondere dann wichtig, wenn zwei verschiedene Sch\u00e4tzverfahren f\u00fcr einen Parameter zu vergleichen sind. \u2022 Exhaustivit\u00e4t. Ein Sch\u00e4tzer ist exhaustiv (oder ersch\u00f6pfend), wenn er alle Informationen, die in den Daten einer Stichprobe enthalten sind, ber\u00fccksichtigt. Alle diese Forderungen scheinen plausibel und w\u00fcnschenswert zu sein; wir werden jedoch sehen, dass sie nicht unbedingt bei allen bekannten Sch\u00e4tzfunktionen erf\u00fcllt sind. 9.2.3\nSpezielle Sch\u00e4tzfunktionen\n\u2022 Erwartungswert. Wir wollen die oben genannten Kriterien zu n\u00e4chst an dem wohl bekanntesten Beispiel \u00fcberpr\u00fcfen und betrachten dazu den Mittelwert x einer Stichprobe, der den Erwartungswert \u00b5 der Grundgesamtheit sch\u00e4tzt. Wir wissen aus Abschnitt 8.3.2, dass gilt:\nE ( X ) = \u00b5 und\nVar ( X ) =\n\u03c32 \u2192 0 n n \u2192\u221e\nDemnach ist diese Sch\u00e4tzung erwartungstreu und konsistent. Die Konsistenz ergibt sich auch aus dem Gesetz der gro\u00dfen Zahlen.\n\u2022 Median. Etwas komplizierter liegen die Dinge beim empirischen Median. Man kann zeigen: Falls die Verteilung stetig und symmet~ ~ . In diesem Fall risch ist, ist X ein erwartungstreuer Sch\u00e4tzer f\u00fcr \u00b5 ~ ist ~ aber \u00b5 = \u00b5 ; deshalb ist etwa bei Normalverteilungen der Median X ein erwartungstreuer Sch\u00e4tzer f\u00fcr den Erwartungswert \u00b5 . F\u00fcr die Varianz des Medians gilt (dies sei ohne Beweis angef\u00fchrt): \u03c0 \u03c32 ~ Var( X ) = \u22c5 \u2192 0 (9.2) 2 n n \u2192\u221e ~ Somit ist X auch eine konsistente Sch\u00e4tzung. Allerdings ist die ~ Varianz von X gr\u00f6\u00dfer als die Varianz von X ; deshalb ist der\n176\nKapitel 9 \u00b7 Sch\u00e4tzverfahren\nMittelwert der effizientere Sch\u00e4tzer f\u00fcr \u00b5 . Der Median ist (im Gegensatz zum Mittelwert) nicht ersch\u00f6pfend, weil nicht alle Stichprobenwerte in dessen Berechnung einflie\u00dfen. Der Mittelwert hat also im Vergleich zum empirischen Median die g\u00fcnstigeren Sch\u00e4tzeigenschaften.\n\u2022 Varianz. Die daraus berechnete Standardabweichung ist bei quan titativen Merkmalen das am h\u00e4ufigsten benutzte Streuungsma\u00df. Die Varianz wird bekanntlich nach folgender Vorschrift gesch\u00e4tzt: n\nS2 =\n\u00a6 ( X i \u2212 X )2 i =1\nn \u22121\n(9.3)\nEs l\u00e4sst sich nachweisen, dass gilt: E (S 2 ) = \u03c3 2 Var( S 2 ) =\n9\n(9.4)\n2\u03c3 4 \u2192 0 n \u2212 1 n \u2192\u221e\n(9.5)\nDemnach ist diese Sch\u00e4tzung erwartungstreu und konsistent. Die Sch\u00e4tzung der Standardabweichung \u03c3 durch S ist zwar konsistent, aber merkw\u00fcrdigerweise nicht erwartungstreu.\n\u2022 Wahrscheinlichkeit. Die Wahrscheinlichkeit p wird \u00fcber eine relative H\u00e4ufigkeit gesch\u00e4tzt. Deren Erwartungswert ist p : n\nE (\u00a6 X i / n) = i =1\nn 1 np E (\u00a6 X i ) = =p n i =1 n\n(9.6)\nwobei Xi ~ B (1, p) . Die Sch\u00e4tzung ist also erwartungstreu. Die Konsistenz ergibt sich aus dem Gesetz der gro\u00dfen Zahlen.\n\u2022 Parameter der bivariaten Statistik. Man kann nachweisen, dass die Sch\u00e4tzung der Kovarianz erwartungstreu und konsistent ist, ebenso die Sch\u00e4tzung der Parameter der Regressionsgeraden. Die Sch\u00e4tzfunktion f\u00fcr den Pearson\u2019schen Korrelationskoeffizient nach Formel (5.2) ist dagegen nicht erwartungstreu, wohl aber konsistent.\n9\n177 9.3 Intervallsch\u00e4tzungen\nMathematische Herleitung der Eigenschaften der empirischen Varianz F\u00fcr den Erwartungswert gilt: \u00a7 n \u00b7 \u00a7 n \u00b7 E \u00a8 \u00a6 ( X i \u2212 X )2 \u00b8 E \u00a8 \u00a6 ( X i \u2212 \u00b5)2 \u2212 n( X \u2212 \u00b5)2 \u00b8 i i = = 1 1 \u00a9 \u00b9 \u00a9 \u00b9 = E(S 2 ) = n \u22121 n \u22121 Da nach der Definition der Varianz (Formel (7.7)) gilt: n\nE ( X i \u2212 \u00b5) 2 = Var ( X i ) = \u03c3 2 , folgt: E ( \u00a6 ( X i \u2212 \u00b5)2 ) = n \u22c5 \u03c32 . i =1\n2\n2\nAu\u00dferdem ist E ( X \u2212 \u00b5) = Var ( X ) = \u03c3 / n . Wenn man dies in die erste Gleichung einsetzt, erh\u00e4lt man: n\u03c3 2 \u2212 \u03c3 2 = \u03c3 2 (Formel (9.4)). n \u22121 Dies ist die formale Rechtfertigung daf\u00fcr, dass bei der empirischen Varianz E (S 2 ) =\ndurch (n \u2212 1) dividiert wird. Nach (8.46) ist die Gr\u00f6\u00dfe\n(n \u2212 1) S 2\nmit der Varianz 2(n \u2212 1) . Daraus leitet man mit (7.9) her: Var( S 2 ) =\n2(n \u2212 1) \u22c5 \u03c3 4 (n \u2212 1)\n2\n=\n\u03c32\n\u03c7 2 -verteilt\n2\u03c3 4 (Formel (9.5)). n \u22121\nWenn man in (7.7) die Variable X durch S und \u00b5 durch ES ersetzt, erh\u00e4lt man: Var( S ) = E( S 2 ) \u2212 ( ES ) 2 = \u03c3 2 \u2212 ( ES ) 2 . Daraus folgt: ( ES ) 2 = \u03c3 2 \u2212 Var( S ) und damit ES < \u03c3 . Die empirische Standardabweichung s sch\u00e4tzt also \u03c3 systematisch zu gering.\n9.3\nIntervallsch\u00e4tzungen\n9.3.1\nDie Bedeutung eines Konfidenzintervalls\nWir wissen, dass die g\u00e4ngigen Sch\u00e4tzverfahren g\u00fcnstige Eigenschaften haben und wenden sie an in der Hoffnung, einen brauchbaren Sch\u00e4tzwert zu erhalten. Dennoch sind diese Punktsch\u00e4tzungen in gewisser Weise unbefriedigend \u2013 ein einzelner Sch\u00e4tzwert enth\u00e4lt n\u00e4mlich keine Information dar\u00fcber, wie sehr er vom \u201ewahren\u201c Parameter der Grundgesamtheit abweicht. Prinzipiell kann man dar\u00fcber auch keine exakten Angaben treffen, da der gesuchte Parameter letztlich unbekannt ist. Wir d\u00fcrfen jedoch bei einem geeigneten Sch\u00e4tzverfahren vermuten, dass er sich in der n\u00e4heren Umge-\n178\n9\nKapitel 9 \u00b7 Sch\u00e4tzverfahren\nbung des Sch\u00e4tzwertes befindet. Es geht in diesem Abschnitt darum, diesen unscharfen Ausdruck \u201en\u00e4here Umgebung\u201c zu pr\u00e4zisieren. In Beispiel 4.1 wurde anhand der Daten von 23 m\u00e4nnlichen Medizinstudenten eine mittlere K\u00f6rpergr\u00f6\u00dfe von xm = 181,22 cm berechnet. Wenn wir diese Gruppe auffassen als eine Stichprobe, dann handelt es sich bei diesem Mittelwert um eine Sch\u00e4tzung f\u00fcr den Erwartungswert der Grundgesamtheit. Wir wissen, dass dieser Mittelwert zufallsbedingt ist \u2013 eine andere Stichprobe des Umfangs n = 23 w\u00fcrde andere Daten und einen anderen Mittelwert liefern. Die konkrete Frage, die sich nun stellt, lautet: Welcher Erwartungswert \u01cb k\u00f6nnte dem besagten Mittelwert zugrunde liegen? Es erscheint durchaus m\u00f6glich, dass er aus einer Grundgesamtheit mit \u00b5 = 180 cm oder mit \u00b5 = 183 cm resultiert. Wir glauben jedoch nicht, dass der wahre Parameter \u00b5 = 170 cm betr\u00e4gt \u2013 obwohl auch diese M\u00f6glichkeit nicht ganz ausgeschlossen werden kann. Um Anhaltspunkte bez\u00fcglich der Genauigkeit der Sch\u00e4tzung zu gewinnen, konstruiert man aus den Daten der Stichprobe ein so genanntes Konfidenzintervall (oder Vertrauensbereich). Man hofft, bei diesem Verfahren ein Intervall zu erhalten, das den gesuchten Parameter \u00fcberdeckt. Es ist allerdings m\u00f6glich, dass die Daten der Stichprobe ein Konfidenzintervall erzeugen, das \u201edaneben liegt\u201c und das den gesuchten Parameter nicht enth\u00e4lt. Diese Irrtumswahrscheinlichkeit wird vor der Bestimmung des Konfidenzintervalls festgelegt. Sie wird mit \u03b1 bezeichnet und betr\u00e4gt \u00fcblicherweise 5%, in besonderen F\u00e4llen auch 1% oder 0,1%. Generell gibt es bei der Konstruktion eines Konfidenzintervalls zwei M\u00f6glichkeiten:\n\u0177 Mit der Wahrscheinlichkeit 1 \u2212 \u03b1 erh\u00e4lt man ein Intervall, das\nden unbekannten Parameter enth\u00e4lt. Der Wert 1 \u2212 \u03b1 wird als Konfidenzwahrscheinlichkeit (oder Konfidenzniveau) bezeichnet. F\u00fcr die Irrtumswahrscheinlichkeit \u03b1 = 5% betr\u00e4gt die Konfidenzwahrscheinlichkeit 1 \u2212 \u03b1 = 95% . \u0177 Mit der Wahrscheinlichkeit \u03b1 erh\u00e4lt man ein Intervall, das den unbekannten Parameter nicht enth\u00e4lt. Das Konfidenzintervall selbst liefert leider keinen Anhaltspunkt daf\u00fcr, welche dieser beiden M\u00f6glichkeiten eingetreten ist. Es ist deshalb immer notwendig, die Irrtumswahrscheinlichkeit \u03b1 mit anzugeben. In den folgenden Abschnitten wird anhand mehrerer Beispiele das Konstruktionsprinzip eines Konfidenzintervalls erl\u00e4utert.\n179\n9\n9.3 Intervallsch\u00e4tzungen\n9.3.2\nKonfidenzintervalle f\u00fcr einen Erwartungswert\nDer Erwartungswert ist bei quantitativen Daten in der Regel der Parameter des wesentlichen Interesses. Er wird \u00fcber den Mittelwert x gesch\u00e4tzt. Ein Konfidenzintervall auf dem Niveau 1 \u2212 \u03b1 = 95% ist gegeben durch: \u00aa 1,96 \u22c5 \u03c3 1,96 \u22c5 \u03c3 \u00ba ;x + \u00abx \u2212 \u00bb n n \u00bc \u00ac\n(9.7)\nDie Wahrscheinlichkeit, dass ein Erwartungswert, der kleiner als die linke oder gr\u00f6\u00dfer als die rechte Intervallgrenze ist, zu x gef\u00fchrt hat, betr\u00e4gt jeweils 2,5% \u2013 also insgesamt \u03b1 = 5% . ! Die plausibel klingende Aussage \u201eDer Erwartungswert \u00b5 liegt mit einer z\nWahrscheinlichkeit von 95 % innerhalb des Konfidenzintervalls\u201c ist irref\u00fchrend. Der Erwartungswert ist zwar unbekannt \u2013 er ist jedoch eine feste Gr\u00f6\u00dfe und nicht vom Zufall abh\u00e4ngig. Dagegen ist das Konfidenzintervall abh\u00e4ngig von der Stichprobe und deshalb vom Zufall mitbestimmt. Eine korrekte Formulierung lautet: \u201eMan erh\u00e4lt mit einer Wahrscheinlichkeit von 95 % ein Konfidenzintervall, das den unbekannten Erwartungswert \u00b5 \u00fcberdeckt\u201c.\nBei einer Irrtumswahrscheinlichkeit von \u03b1 = 1% ist der Wert 1,96 in (9.7) durch 2,58 zu ersetzen. Theoretisch ist nat\u00fcrlich jede beliebige Irrtumswahrscheinlichkeit denkbar; die Quantile der Standard\u203a Tabelle A normalverteilung sind dementsprechend anzugleichen (z im Anhang). Wegen der Symmetrie dieser Verteilung unterscheiden sich die Quantile, die die beiden Intervallgrenzen bestimmen, nur bez\u00fcglich ihres Vorzeichens. Allgemein ist ein zweiseitiges Konfidenzintervall auf dem (1 \u2212 \u03b1) -Niveau definiert durch die Intervallmitte x und die Grenzen: \u00aa \u03c3 \u03c3 \u00ba ; x + z1\u2212 \u03b1 / 2 \u22c5 \u00ab x \u2212 z1\u2212\u03b1 / 2 \u22c5 \u00bb n n\u00bc \u00ac\n(9.8)\nDabei bezeichnet der Index 1 \u2212 \u03b1 / 2 das jeweilige Quantil der Standardnormalverteilung. F\u00fcr \u03b1 = 5% erh\u00e4lt man z1\u2212\u03b1 / 2 = z0,975 = 1,96 .\n180\nKapitel 9 \u00b7 Sch\u00e4tzverfahren\nMathematische Betrachtung des Konfidenzintervalls f\u00fcr den Erwartungswert Dessen Bestimmung liegt der zentrale Grenzwertsatz zugrunde. Demnach sind alle theoretisch denkbaren Mittelwerte aus Stichproben des Umfangs n normalverteilt (zumindest f\u00fcr n \u2265 25 ) mit dem Erwartungswert \u00b5 und der Standardabweichung \u03c3 / n . Deshalb gilt: X \u2212\u00b5 \u2264 1,96) = 0,95 \u03c3/ n Die Zahlenwerte sind die Grenzen, die den 95%-Referenzbereich der Standardnormalverteilung angeben (Tabelle 8.1). Durch Umformen dieser Ungleichung ergibt sich: 1,96 \u22c5 \u03c3 1,96 \u22c5 \u03c3 P(\u2212 \u2264 X \u2212\u00b5 \u2264 ) = 0,95 n n Das bedeutet, dass der Abstand zwischen dem Mittelwert und dem Erwartungswert betragsm\u00e4\u00dfig mit 95%-iger Wahrscheinlichkeit unterhalb von P (\u22121,96 \u2264\n1,96 \u22c5 \u03c3 / n liegt. Damit ergibt sich ein Konfidenzintervall nach (9.7).\n9\nBei diesen Formeln wurde stillschweigend vorausgesetzt, dass die Standardabweichung \u03c3 der Grundgesamtheit bekannt ist. Dies ist aber bei praktischen Untersuchungen fast niemals der Fall. Man k\u00f6nnte notgedrungen das \u03c3 durch die empirische Standardabweichung s ersetzen. Dies w\u00fcrde aber insbesondere bei kleinen Stichproben \u2013 die in den Biowissenschaften eher die Regel als die Ausnahme sind \u2013 zu einer weiteren Ungenauigkeit der Sch\u00e4tzung f\u00fchren. Vor diesem Problem stand Sealy Gosset, als er zu Beginn des 20. Jahrhunderts Mittelwerte f\u00fcr Bieringredenzien sch\u00e4tzen wollte und dabei nur auf kleine Stichproben zur\u00fcckgreifen konnte. Dies war die Ausgangssituation f\u00fcr die Entwicklung der t-Verteilung. Wenn die Zufallsvariable X normalverteilt ist, lassen sich die Quantile der Standardnormalverteilung in (9.8) ersetzen durch die entsprechenden t-Werte, und man erh\u00e4lt folgendes Konfidenzintervall: t \u22c5s\u00ba tn \u22121;1\u2212\u03b1 / 2 \u22c5 s \u00aa ; x + n \u22121;1\u2212\u03b1 / 2 \u00bb \u00abx \u2212 n n \u00bc \u00ac\n(9.9)\ni Der Ausdruck t n \u22121;1\u2212 \u03b1 / 2 ist f\u00fcr Anf\u00e4nger gew\u00f6hnungsbed\u00fcrftig. Die beiz den Angaben im Index sind notwendig, um den speziellen t-Wert exakt zu kennzeichnen. Der Index f = n \u2212 1 bezeichnet die Anzahl der Freiheitsgrade der jeweiligen t-Verteilung (es gibt n\u00e4mlich f\u00fcr jedes f eine spezielle t-Verteilung), 1 \u2212 \u03b1 / 2 gibt das Quantil an.\n9\n181 9.3 Intervallsch\u00e4tzungen\nOhne eine geeignete Software, die Konfidenzintervalle berechnet, m\u00fcssen die Quantile tn \u22121;1\u2212\u03b1 / 2 in Tabellen nachgeschlagen werden \u203a Tabelle B im Anhang). Der Faktor s / n in Formel (9.9) ist eine (z Sch\u00e4tzung f\u00fcr den Standardfehler des Mittelwerts \u03c3 / n . Theoretisch sind auch einseitige Konfidenzintervalle konstruierbar, die an einer Seite offen sind: ( \u2212\u221e; x +\ntn \u22121;1\u2212\u03b1 \u22c5 s n\n]\noder [ x \u2212\ntn \u22121;1\u2212\u03b1 \u22c5 s n\n;+\u221e)\n(9.10)\nAuf ein besonderes Problem sei an dieser Stelle hingewiesen: Bisher wurde vorausgesetzt, dass die Grundgesamtheit unendlich gro\u00df ist. Wird nun eine Stichprobe des Umfangs n aus einer endlichen Grundgesamtheit des Umfangs N gezogen, muss der Standardfehler korrigiert werden. Diese Endlichkeitskorrektur ergibt sich aus der \u203a Abschnitt 7.3.4). Die Varianz der hypergeometrischen Verteilung (z Grenzen des Konfidenzintervalls bei einer endlichen Grundgesamtheit sind demnach: x \u00b1 tn \u22121;1\u2212\u03b1 / 2 \u22c5 s \u22c5\nN \u2212n n \u22c5 ( N \u2212 1)\n(9.11)\nBei gro\u00dfen Grundgesamtheiten mit N / n \u2265 100 nimmt die Endlichkeitskorrektur einen Wert nahe bei 1 an und kann deshalb vernachl\u00e4ssigt werden. Beispiel 9.1 K\u00f6rpergr\u00f6\u00dfen m\u00e4nnlicher Studenten (n = 23): Aus xm \u00b1 sm = (181,22 \u00b1 7,12)cm ergibt sich f\u00fcr die Konfidenzintervalle: [178,14 cm ; 184,29 cm] ( \u03b1 = 0,05 ) mit t22;0,975 = 2,074 [177,04 cm ; 185,40 cm] ( \u03b1 = 0,01 ) mit t22;0,995 = 2,819 K\u00f6rpergr\u00f6\u00dfen weiblicher Studenten (n = 48): Aus xw \u00b1 sw = (169,06 \u00b1 6,60)cm berechnet man: [167,15 cm ; 170,98 cm] ( \u03b1 = 0,05 ) mit t47;0,975 = 2,012 [166,51 cm ; 171,62 cm] ( \u03b1 = 0,01 ) mit t47;0,995 = 2,685 Man erkennt: \u0177 Die Konfidenzintervalle der Frauen sind schmaler als die der M\u00e4nner. Das liegt zum einen am h\u00f6heren Stichprobenumfang, zum anderen an der geringeren Streuung der Daten. \u0177 Die 95%-Intervalle sind schmaler als die 99%-Intervalle. Das liegt an den t-Quantilen, die f\u00fcr \u03b1 = 0,05 kleiner sind als f\u00fcr \u03b1 = 0,01 .\n182\nKapitel 9 \u00b7 Sch\u00e4tzverfahren\n9.3.3\nKonfidenzintervall f\u00fcr eine Wahrscheinlichkeit\nAls Punktsch\u00e4tzer f\u00fcr eine Wahrscheinlichkeit p dient bekanntlich eine relative H\u00e4ufigkeit:\np\u02c6 =\nX n\n(9.12)\nDabei bezeichnet X die H\u00e4ufigkeit des Ereignisses A bei n Zufallsexperimenten. Die Grenzen eines Konfidenzintervalls f\u00fcr die unbekannte Wahrscheinlichkeit p lassen sich angeben als: \u00a7 1 p\u02c6 \u00b1 \u00a8 +z \u22c5 \u00a8 2n 1\u2212\u03b1 / 2 \u00a9\n9\np\u02c6 (1 \u2212 p\u02c6 ) \u00b7\u00b8 \u00b8 n \u00b9\n(9.13)\nDabei wird vorausgesetzt, dass np\u02c6 > 5 und n(1 \u2212 p\u02c6 ) > 5 . Das bedeutet: Der Stichprobenumfang darf nicht zu klein und die relativen H\u00e4ufigkeiten sollten nicht zu extrem sein. Das in (9.13) definierte Intervall ist vergleichbar mit dem Konfidenzintervall f\u00fcr den Erwartungswert nach (9.8): p\u02c6 entspricht dem Mittelwert, die Wurzel dem Standardfehler der Sch\u00e4tzung. Bei endlichen Grundgesamtheiten ist auch hier der Standardfehler mit dem Faktor ( N \u2212 n) /( N \u2212 1) zu multiplizieren. Der Faktor 1 / 2n in (9.13) ist die so genannte Stetigkeitskorrektur. Mathematische Betrachtung des Konfidenzintervalls f\u00fcr p Dieses Konfidenzintervall basiert auf dem zentralen Grenzwertsatz. F\u00fcr npq \u2265 9 ist die binomialverteilte Variable X normalverteilt mit \u00b5 = np und \u203a Binomialverteilung,, Abschnitt 7.2.2). Also gilt: \u03c3 2 = np(1 \u2212 p) (z P( \u2212 z1\u2212 \u03b1 / 2 \u2264\nX \u2212 np np(1 \u2212 p )\n\u2264 z1\u2212 \u03b1 / 2 ) = 1 \u2212 \u03b1\nDurch Umformen ergibt sich dann das Konfidenzintervall: p(1 \u2212 p) n Das unbekannte p unter der Wurzel wird durch den Sch\u00e4tzwert p\u02c6 ersetzt. Um das Intervall auch f\u00fcr kleinere Stichprobenumf\u00e4nge konstruieren zu k\u00f6nnen, wird die Stetigkeitskorrektur 1 / 2n hinzugef\u00fcgt (wodurch das Intervall um insgesamt den Faktor 1 / n verbreitert wird). Dadurch wird versucht, den Fehler auszugleichen, der beim \u00dcbergang von den relativen H\u00e4ufigkeiten p\u02c6 (diskrete Variable) zur Standardnormalverteilung entsteht. p\u02c6 \u00b1 z1\u2212 \u03b1 / 2 \u22c5\n183\n9\n9.3 Intervallsch\u00e4tzungen\nBeispiel 9.2 Der Anteil weiblicher Studenten wird anhand der Daten von Tabelle 2.1 mit p\u02c6 = 48 / 71 = 0,676 gesch\u00e4tzt. Kann man davon ausgehen, dass mehr als die H\u00e4lfte der Medizinstudenten weiblich sind \u2013 oder ist der h\u00f6here Anteil nur zuf\u00e4llig bedingt? F\u00fcr dass 95%-Konfidenzintervalls erhalten wir nach (9.13): 48 / 71 \u22c5 23 / 71 \u00b7\u00b8 48 \u00a7\u00a8 1 . Das Intervall ist also: [0,560 ; 0,792] . \u00b1 + 1,96 \u22c5 \u00b8 \u00a8 71 71 \u00a9 142 \u00b9 Aufgrund dieser Sch\u00e4tzung d\u00fcrfen wir mit gr\u00f6\u00dferem Vertrauen annehmen, dass der Anteil der Frauen tats\u00e4chlich mehr als 50% betr\u00e4gt. Worauf ist dies zur\u00fcckzuf\u00fchren? Dar\u00fcber schweigt sich das Konfidenzintervall aus.\n9.3.4\nKonfidenzintervalle f\u00fcr Zusammenhangsma\u00dfe\nDie Berechnung eines Konfidenzintervalls f\u00fcr den Korrelationskoeffizienten nach Pearson wird hier nicht im Detail beschrieben (zumal diese Berechnungen normalerweise nicht manuell durchgef\u00fchrt werden). Der Anwender muss lediglich wissen, dass X und Y bivariat (also 2-dimensional) normalverteilte Zufallsvariable sein sollten. Die Berechnung eines solchen Intervalls ist auch f\u00fcr den Korrelationskoeffizienten nach Spearman bei einem Stichprobenumfang n \u2265 10 m\u00f6glich. Beispiel 9.3 F\u00fcr den Zusammenhang zwischen K\u00f6rpergr\u00f6\u00dfe und Gewicht weiblicher Stu\u203a Beispiel 5.2). Mit einer Statistikdenten ermittelten wir r = 0,607 ( n = 47 , z software l\u00e4sst sich folgendes 95%-Konfidenzintervall bestimmen: (0,412 ; 0,803). Was besagt dieses? Da beide Intervallgrenzen deutlich gr\u00f6\u00dfer als 0 sind, k\u00f6nnen wir einigerma\u00dfen sicher sein, dass ein gleichsinniger Zusammenhang existiert. Allerdings wissen wir nicht, ob dieser schwach oder eher stark ist. F\u00fcr die m\u00e4nnlichen Studenten gilt r = 0,570 ( n = 23 ); das Konfidenzintervall ist (0,313 ; 0,827). Dieses ist breiter, weil der Stichprobenumfang geringer und damit die Sch\u00e4tzung ungenauer ist.\nAuch f\u00fcr die Steigung der Regressionsgeraden k\u00f6nnen Konfidenzintervalle berechnet werden. Spezielle Voraussetzungen gelten bei der Regression 1. Art, bei der die Auspr\u00e4gungen der x-Variablen nach Belieben festgelegt werden, sodass zu jedem x j mehrere Werte yij existieren:\n\u0177 Die Residuen yij \u2212 y j m\u00fcssen normalverteilt sein mit dem Erwartungswert 0 ( y j sei der Mittelwert der yij ).\n184\nKapitel 9 \u00b7 Sch\u00e4tzverfahren\n\u0177 Die Varianzen der zu den einzelnen x j -Werten geh\u00f6renden yij\nsollten gleich sein (diese Eigenschaft bezeichnet man als Homoskedastizit\u00e4t).\nEs erscheint zumindest bei hohen Stichprobenumf\u00e4ngen sinnvoll, in einem Koordinatensystem die Residuen gegen die Werte des xMerkmals aufzutragen. Wenn bei dieser Darstellung Muster erkennbar sind, ist dies ein Hinweis darauf, dass die oben genannten Voraussetzungen nicht erf\u00fcllt sind. Falls sie erf\u00fcllt sind, l\u00e4sst sich mit einer leistungsf\u00e4higen Software f\u00fcr einen fest vorgegebenen x-Wert ein 95%-Vorhersageintervall (Prognoseintervall) f\u00fcr den dazugeh\u00f6renden y-Wert angeben. Au\u00dferdem lassen sich Konfidenzintervalle f\u00fcr die Mittelwerte y j berechnen.\n9\n9.4\nAbschlie\u00dfende Bemerkungen\n9.4.1\nDie Bedeutung des Stichprobenumfangs\nDie Pr\u00e4zision einer Sch\u00e4tzung wird ausgedr\u00fcckt durch die Breite des Konfidenzintervalls. Je schmaler dieses Intervall ist, desto genauer ist die Sch\u00e4tzung. Ein sehr breites Konfidenzintervall ist dagegen f\u00fcr praktische Zwecke unbrauchbar. So betr\u00e4gt die Breite des nach (9.9) berechneten zweiseitigen Konfidenzintervalls f\u00fcr den Erwartungswert: BK =\n2 \u22c5 tn \u22121;1\u2212\u03b1 / 2 \u22c5 s n\n(9.14)\nGenerell sind also drei Faktoren f\u00fcr die Pr\u00e4zision der Sch\u00e4tzung von \u203a Beispiel 9.1): Bedeutung (z\n\u0177 Die Irrtumswahrscheinlichkeit \u03b1 . F\u00fcr \u03b1 = 5% ergibt sich ein\nschmaleres Intervall als f\u00fcr \u03b1 = 1% . Ein schmales Intervall l\u00e4sst sich also erreichen durch eine h\u00f6here Irrtumswahrscheinlichkeit und damit zu Lasten der Sicherheit. \u0177 Die Standardabweichung s. Je homogener die Grundgesamtheit, desto kleiner sind die Standardabweichung und die Breite des Konfidenzintervalls. \u0177 Der Stichprobenumfang n . Die Sch\u00e4tzung ist umso pr\u00e4ziser, je h\u00f6her der Stichprobenumfang ist.\n9\n185 9.4 Abschlie\u00dfende Bemerkungen\nDer Anwender hat also die M\u00f6glichkeit, \u00fcber die Irrtumswahrscheinlichkeit und den Stichprobenumfang die Breite eines Konfidenzintervalls zu beeinflussen. Aus (9.14) geht hervor, dass bei vorgegebener Breite der Mindeststichprobenumfang berechnet werden kann \u2013 allerdings nur theoretisch. In der Praxis ist die Standardabweichung \u03c3 nicht bekannt; der empirische Sch\u00e4tzwert s ergibt sich erst, nachdem die Daten der Stichprobe vorliegen. Au\u00dferdem kann der t-Wert (der von n abh\u00e4ngig ist) nicht explizit angegeben werden, sondern allenfalls grob gesch\u00e4tzt werden (er betr\u00e4gt f\u00fcr \u03b1 = 5% und n \u2265 10 ungef\u00e4hr 2). Aus (9.14) ist au\u00dferdem ersichtlich, dass bei gleicher Standardabweichung der vierfache Stichprobenumfang erforderlich ist, um die Breite des Intervalls zu halbieren (da der Stichprobenumfang nur mit n in den Nenner der Formel (9.14) eingeht). Schlie\u00dflich sei noch die Breite des Konfidenzintervalls f\u00fcr die Wahrscheinlichkeit p angegeben. Aus (9.13) ergibt sich: BK = 2 \u22c5 z1\u2212 \u03b1 / 2 \u22c5\np\u02c6 (1 \u2212 p\u02c6 ) 1 + n n\n(9.15)\nAuch diese Breite wird durch die Irrtumswahrscheinlichkeit und den Stichprobenumfang bestimmt. Um einen Mindestumfang festlegen zu k\u00f6nnen, ist zumindest eine grobe Absch\u00e4tzung der Wahrscheinlichkeit p erforderlich. Beispiel 9.4 Von 71 Studenten haben 60 (das sind ungef\u00e4hr 85 %) Rhesusfaktor \u201epositiv\u201c. Daraus berechnet sich nach (9.13) das Konfidenzintervall (mit \u03b1 = 0,05 ): 60 / 71 \u22c511 / 71 \u00b7\u00b8 60 \u00a7\u00a8 1 = [0,75;0,94] \u00b1 + 1,96 \u22c5 \u00b8 \u00a8 71 71 \u00a9 142 \u00b9\nWenn man nun den 4-fachen Stichprobenumfang zugrunde legen w\u00fcrde (also n = 284) und annehmen w\u00fcrde, dass 240 Personen \u201eRhesusfaktor positiv\u201c haben, erhielte man denselben Sch\u00e4tzwert p\u02c6 = 240 / 284 \u2248 85% . Das Konfidenzintervall w\u00e4re jedoch schmaler und die Sch\u00e4tzung w\u00e4re pr\u00e4ziser: 240 / 284 \u22c5 44 / 284 \u00b7\u00b8 240 \u00a7\u00a8 1 = [0,80;0,89] \u00b1 + 1,96 \u22c5 \u00a8 \u00b8 284 284 \u00a9 568 \u00b9\nAnaloge \u00dcberlegungen gelten f\u00fcr andere Parameter: In jedem Fall sind die Breite des Konfidenzintervalls und die Genauigkeit der Sch\u00e4tzung abh\u00e4ngig vom Stichprobenumfang n und von der Irrtumswahrscheinlichkeit \u012e.\n186 9.4.2\n9\nKapitel 9 \u00b7 Sch\u00e4tzverfahren\nZu den Voraussetzungen\nDie Beispiele in diesem Kapitel machen deutlich, dass die Angabe eines Konfidenzintervalls eine wesentlich bessere Beurteilung des Sch\u00e4tzwertes erlaubt als eine einfache Punktsch\u00e4tzung. W\u00e4hrend aber ein Punktsch\u00e4tzer auf einfache Weise aus den Daten der Stichprobe zu berechnen ist, kann die Bestimmung eines Konfidenzintervalls \u00e4u\u00dferst kompliziert sein. Sie setzt n\u00e4mlich voraus, dass die Verteilung der Stichproben-Kenngr\u00f6\u00dfen bekannt ist. So wird beispielsweise bei der Berechnung eines Konfidenzintervalls f\u00fcr den Erwartungswert zugrunde gelegt, dass die Zufallsvariable X normalverteilt ist. Falls die Verteilung der Kenngr\u00f6\u00dfe nicht explizit bekannt ist (z. B. bei der Schiefe oder W\u00f6lbung), kann man Monte-Carlo-Studien einsetzen. Dabei werden aus einer bekannten Grundgesamtheit zahlreiche Zufallsstichproben des Umfangs n gezogen und jeweils die interessierende Kenngr\u00f6\u00dfe berechnet. Aus all diesen Werten wird dann deren Verteilung simuliert. Mit der Monte-Carlo-Methode l\u00e4sst sich auch \u00fcberpr\u00fcfen, ob und inwieweit Verletzungen der Voraussetzungen tolerierbar sind. So kann man beispielsweise zeigen, dass die t-Verteilung einigerma\u00dfen robust ist gegen\u00fcber Abweichungen von der Normalverteilung. Es ist f\u00fcr den Anwender nicht notwendig, die mathematischen Hintergr\u00fcnde genau zu kennen, zumal die Intervalle in der Regel von einer Statistiksoftware ermittelt werden. Er sollte allerdings in der Lage sein, ein Konfidenzintervall sinnvoll zu interpretieren. H\u00e4ufig werden die Bedingungen zur Konstruktion eines Konfidenzintervalls nicht \u00fcberpr\u00fcft, sondern stillschweigend als erf\u00fcllt vorausgesetzt \u2013 sei es aus Bequemlichkeit oder Nichtwissen oder schlicht aus Not, weil keine anderen Sch\u00e4tzverfahren zur Verf\u00fcgung stehen. Nun bedeutet dieses laxe Vorgehen nicht unbedingt, dass die Sch\u00e4tzung insgesamt unbrauchbar ist \u2013 es kommt eben darauf an, wie das Sch\u00e4tzverfahren auf eine Verletzung der Voraussetzungen reagiert. Die Verfahren der induktiven Statistik sind insgesamt wesentlich komplexer als die Methoden der deskriptiven Statistik. Eine geeignete Software ist hierbei ein sinnvolles Mittel, ohne das manche Rechnungen gar nicht oder nur mit gr\u00f6\u00dfter M\u00fche zu bew\u00e4ltigen w\u00e4ren. Es darf jedoch keineswegs dazu f\u00fchren, dass man allzu sorglos die Voraussetzungen eines Verfahrens ignoriert. Man sollte in jedem Fall darauf achten, dass sie nicht in extremer Weise verletzt sind und die Ergebnisse mit der gebotenen Vorsicht interpretieren.\n10\nDas Prinzip eines statistischen Tests 10.1\nDie Durchf\u00fchrung eines Tests 189\n10.1.1\nDie Funktion eines statistischen Tests 189\n10.1.2\nDas Formulieren der Hypothesen 190\n10.1.3\nFehlerarten 192\n10.1.4\nDer Stichprobenumfang 194\n10.2\nTestentscheidung und Konsequenzen 195\n10.2.1\nDie Basis der Testentscheidung 195\n10.2.2\np-Wert und Konfidenzintervall 197\n10.2.3\nDie Interpretation eines signifikanten Ergebnisses 199\n10.2.4\nDie Interpretation eines nicht-signifikanten Ergebnisses 199\n10.2.5\nDie Manipulation des Testergebnisses 200\n10.2.6\nMultiples Testen 201\n10.3\nKlassifikation der Testmethoden 202\n189\n10\n10.1 Die Durchf\u00fchrung eines Tests\n10.1\nDie Durchf\u00fchrung eines Tests\n10.1.1 Die Funktion eines statistischen Tests Der Fortschritt in einer empirischen Wissenschaft wie der Medizin beruht im Wesentlichen auf Beobachtungen, die ein Arzt bei der Patientenbehandlung oder im Labor macht. M\u00f6glicherweise entwickelt er dabei eine Therapie, von der er glaubt, dass sie der herk\u00f6mmlichen Standardtherapie in irgendeiner Weise \u00fcberlegen sei, oder er gewinnt neue wissenschaftliche Erkenntnisse. Aus einer Vielzahl von Beobachtungen gepaart mit fachlich-theoretischen \u00dcberlegungen entsteht so eine Vermutung und \u2013 wenn diese pr\u00e4zise formuliert wird \u2013 eine Hypothese. In der Regel ist es nicht m\u00f6glich, derlei Hypothesen zu beweisen. Ein Forscher wird zwar meist von der Richtigkeit seiner Vermutung \u00fcberzeugt sein \u2013 dies allein kann jedoch kein objektives Kriterium darstellen. Die \u00dcberpr\u00fcfung einer Hypothese hat in zweifacher Hinsicht zu erfolgen:\n\u0177 Zun\u00e4chst sollte ein theoretischer Hintergrund erarbeitet werden, um die Hypothese mit sachlichen Argumenten zu untermauern. Dazu bedarf es \u00fcberwiegend medizinischer Fachkenntnisse und Erfahrungen \u2013 mit Statistik hat dies vorerst nichts zu tun. \u0177 Dar\u00fcber hinaus ist es erforderlich, die Hypothese statistisch abzusichern. Zu diesem Zweck m\u00fcssen relevante Daten erhoben und mit einer geeigneten Testmethode analysiert werden. In diesem Abschnitt 10.1 wird das Prinzip eines statistischen Tests anhand eines einfachen Beispiels erl\u00e4utert, wof\u00fcr der t-Test f\u00fcr eine Stichprobe herangezogen wird. Wir stellen uns dazu folgende Situation vor: Aus der Fachliteratur ist bekannt, dass das mittlere Geburtsgewicht gesunder Kinder nach einer unauff\u00e4llig verlaufenden Schwangerschaft 3.500 Gramm betr\u00e4gt. Ein Mediziner hat die Vermutung, dass Babys, deren M\u00fctter w\u00e4hrend der Schwangerschaft einem bestimmten Risiko ausgesetzt waren, im Durchschnitt weniger wiegen. Er beschlie\u00dft, das Geburtsgewicht von 20 solcher Risiko-Babys in seiner Klinik zu messen und den daraus resultierenden Mittelwert mit 3.500 Gramm zu vergleichen. Generell sind nun zwei M\u00f6glichkeiten bez\u00fcglich der (unbekannten) Ausgangssituation denkbar:\n190\nKapitel 10 \u00b7 Das Prinzip eines statistischen Tests\n\u0177 Es besteht kein Unterschied zwischen dem mittleren Geburtsgewicht der Risiko-Babys und dem aus der Literatur bekannten Wert von 3.500 Gramm. In diesem Fall w\u00fcrde man bei den 20 Babys ein Durchschnittsgewicht von 3.500 Gramm erwarten. Freilich wird man niemals einen Mittelwert von exakt 3.500 Gramm erhalten. Kleinere Abweichungen muss man tolerieren. \u0177 Es besteht ein Unterschied. Dann wiegen die Kinder durchschnittlich weniger (oder auch mehr) als 3.500 Gramm, wobei der Unterschied nicht nur zuf\u00e4llig bedingt ist.\n10\nDiese beiden Aussagen sind komplement\u00e4r: Sie erg\u00e4nzen sich und schlie\u00dfen sich gegenseitig aus. Genau eine davon muss also richtig sein. Eine Entscheidung aufgrund des Testergebnisses f\u00e4llt mitunter schwer. Wenn der Arzt ein mittleres Geburtsgewicht von 3.480 Gramm ermittelt, wird er kaum schlussfolgern, dass sich das Risiko negativ auf das Geburtsgewicht der Kinder auswirkt. Wenn er dagegen einen Mittelwert von weniger als 3.000 Gramm erh\u00e4lt, wird er seine Vermutung best\u00e4tigt finden. Wo aber ist die Grenze? Welche Abweichungen vom Sollwert 3.500 Gramm sind als zuf\u00e4llig bedingt einzustufen \u2013 und ab welchem Punkt muss man davon ausgehen, dass die Abweichung nicht allein durch den Zufall erkl\u00e4rt werden kann? Ein statistischer Test hilft in solchen Situationen weiter. Er funktioniert nach folgendem Prinzip: Man stellt zwei komplement\u00e4re Hypothesen auf (siehe oben), w\u00e4hlt einen f\u00fcr die Fragestellung passenden Test und berechnet dann aus den Daten einer (oder mehrerer) Stichprobe(n) nach einem bestimmten mathematischen Algorithmus eine so genannte Testgr\u00f6\u00dfe (oder Pr\u00fcfgr\u00f6\u00dfe). Diese Gr\u00f6\u00dfe erlaubt es, eine objektive und nachvollziehbare Entscheidung zugunsten von einer der beiden Hypothesen zu treffen. 10.1.2 Das Formulieren der Hypothesen Es ist wichtig, die beiden Hypothesen vor der Durchf\u00fchrung des Tests inhaltlich so pr\u00e4zise wie m\u00f6glich zu formulieren. Erst dadurch wird die konkrete Fragestellung klar definiert. Diejenige Hypothese, die eine innovative Aussage beinhaltet und Althergebrachtes in Frage stellt, bezeichnet man als Alternativhypothese. In unserem Beispiel lautet sie: \u201eDas mittlere Geburtsgewicht der 20 Risiko-Babys unterscheidet sich von 3.500 Gramm\u201c. Die dazu konkurrierende Aussage nennt man Nullhypothese: \u201eEs gibt keinen Unterschied\u201c.\n191\n10\n10.1 Die Durchf\u00fchrung eines Tests\nDie inhaltlichen Aussagen werden nun in statistische Hypothesen \u00fcbersetzt. In unserem Beispiel lauten sie: H0 :\n\u00b5 = 3.500\nH1 :\n\u00b5 \u2260 3.500\nDabei symbolisiert der Buchstabe \u01cb den Erwartungswert, der durch den Mittelwert der 20 Risiko-Babys gesch\u00e4tzt wird. Die Nullhypothese H 0 beinhaltet ein Gleichheitszeichen; sie ist also eindeutig formuliert. Die Alternativhypothese, die \u00fcblicherweise mit H1 (oder mit H A ) bezeichnet wird, ist dagegen sehr allgemein gehalten: Sie vereinigt in sich alle Hypothesen mit Ausnahme der Nullhypothese. Diese Art von Hypothesen, bei denen nichts \u00fcber die Richtung eines Unterschieds ausgesagt wird, nennt man zweiseitig (oder ungerichtet). Wenn aufgrund inhaltlicher \u00dcberlegungen oder Erfahrungen bereits Kenntnisse \u00fcber die Richtung eines m\u00f6glichen Unterschiedes vorliegen, ist es eventuell sinnvoll, einseitige (oder gerichtete) Hypothesen zu formulieren. Wenn der Arzt berechtigten Grund zur Annahme hat, dass die Babys auf keinen Fall mehr, sondern weniger wiegen als 3.500 Gramm, und dies statistisch absichern m\u00f6chte, wird er folgende Hypothesen aufstellen: H0 :\n\u00b5 = 3.500\nH1 :\n\u00b5 < 3.500\nEine Testentscheidung l\u00e4sst nur diese beiden Alternativen zu. Die M\u00f6glichkeit \u00b5 > 3.500 wird bei dieser Fragestellung gar nicht in Betracht gezogen. ! Oft wird die Nullhypothese bei einseitiger Fragestellung komplement\u00e4r z\nzur Alternativhypothese formuliert (also in unserem Beispiel: \u00b5 \u2265 3.500 ). Welche Formulierung das inhaltliche Problem besser beschreibt, bleibt dem Anwender \u00fcberlassen. F\u00fcr die Durchf\u00fchrung des Tests ist dies irrelevant: Die Berechnung der Pr\u00fcfgr\u00f6\u00dfe und die Testentscheidung basieren in jedem Fall auf einer eindeutig formulierten Nullhypothese.\nOb eine Fragestellung ein- oder zweiseitig formuliert wird, hat der Versuchsleiter vor der Durchf\u00fchrung des Tests festzulegen. Diese Entscheidung ist aufgrund von spezifisch-fachlichen \u00dcberlegungen zu treffen. Sie ist u. a. abh\u00e4ngig von den Konsequenzen einer Fehl\u203a n\u00e4chster Abschnitt). Falls der Versuchsleiter nicht entscheidung (z sicher ist, ob die Voraussetzungen f\u00fcr eine einseitige Fragestellung vorliegen, ist es zweckm\u00e4\u00dfig, die zweiseitige zu w\u00e4hlen.\n192\nKapitel 10 \u00b7 Das Prinzip eines statistischen Tests\n10.1.3 Fehlerarten Die Testentscheidung h\u00e4ngt von der Pr\u00fcfgr\u00f6\u00dfe ab; diese wiederum wird aus den Stichprobenwerten ermittelt. Es ist nicht ausgeschlossen, dass das Testverfahren im Einzelfall zu einer Fehlentscheidung f\u00fchrt. Wenn in Wirklichkeit die Nullhypothese richtig ist und man sich f\u00e4lschlicherweise f\u00fcr die Alternativhypothese entscheidet, liegt ein \u03b1-Fehler (oder Fehler 1. Art) vor. Auch dann, wenn sich die Risiko-Babys bez\u00fcglich ihres Geburtsgewichts von den anderen nicht unterscheiden w\u00fcrden (wenn also die Nullhypothese zutr\u00e4fe), k\u00f6nnten allein aufgrund des Zufalls nur leichtgewichtige Babys in die Stichprobe gelangen, deren durchschnittliches Gewicht weit unter 3.500 Gramm l\u00e4ge. Der Arzt w\u00fcrde dann annehmen, dass diese Kinder weniger wiegen und sich irrt\u00fcmlicherweise f\u00fcr die Alternativhypothese entscheiden. Damit w\u00fcrde er einen \u03b1-Fehler begehen (freilich ohne dies zun\u00e4chst zu merken). Ein \u03b1-Fehler ist nicht generell vermeidbar \u2013 aber er ist kontrollierbar. Dieser Fehler kann n\u00e4mlich nur bei G\u00fcltigkeit der Nullhypothese auftreten, und diese ist eindeutig formuliert. Deshalb ist es m\u00f6glich, die Wahrscheinlichkeitsverteilung der Pr\u00fcfgr\u00f6\u00dfe explizit anzugeben. Es ist bekannt, dass unter H 0 die Zufallsvariable\n10\nT=\nX \u2212 \u00b50 S/ n\n\u203a Abschnitt 8.5.1). Nach dieser Vorschrift berechnet t-verteilt ist (z man aus den Daten der Stichprobe die Pr\u00fcfgr\u00f6\u00dfe t: t=\nx \u2212 \u00b50\n(10.1)\ns/ n\nDiese Pr\u00fcfgr\u00f6\u00dfe kann Werte zwischen \u2212\u221e und +\u221e annehmen. Unter der Nullhypothese betragen die entsprechenden Wahrscheinlichkeiten (mit \u03b1 = 5% ): Bereich der Pr\u00fcfgr\u00f6\u00dfe t\nEntscheidung Wahrscheinlichf\u00fcr keit \u03b1 / 2 = 2,5% H1\nt < tn \u22121;\u03b1 / 2 < 0\nkritischer Bereich\ntn \u22121;\u03b1 / 2 \u2264 t \u2264 tn \u22121;1\u2212 \u03b1 / 2\nAnnahmebereich\nH0\n1 \u2212 \u03b1 = 95%\nt > tn \u22121;1\u2212 \u03b1 / 2 > 0\nkritischer Bereich\nH1\n\u03b1 / 2 = 2,5%\n10\n193 10.1 Die Durchf\u00fchrung eines Tests\nIm kritischen Bereich hat die Pr\u00fcfgr\u00f6\u00dfe einen Betrag t > tn \u22121;1\u2212 \u03b1 / 2 (wegen der Symmetrie der t-Verteilung ist t n \u22121;\u03b1 / 2 = \u2212t n \u22121;1\u2212\u03b1 / 2 ). Deshalb ist f\u00fcr diesen Test folgende Entscheidungsregel relevant:\n\u0177 Falls t \u2264 t n \u22121;1\u2212\u03b1 / 2 , beh\u00e4lt man die Nullhypothese bei; \u0177 falls t > t n \u22121;1\u2212\u03b1 / 2 , nimmt man die Alternativhypothese an. Die Werte \u00b1 tn \u22121;1\u2212\u03b1 / 2 trennen den Annahme- vom kritischen Bereich \u203a Abbildung und werden deshalb als kritische Werte bezeichnet (z 10.1). Bei einseitiger Fragestellung H1 :\n\u00b5 > \u00b50\nwird die Nullhypothese abgelehnt, falls t > t n \u22121;\u03b1 . Wenn man dagegen die Alternativhypothese formuliert als H1 :\n\u00b5 < \u00b50 ,\nmuss die Pr\u00fcfgr\u00f6\u00dfe t negativ und kleiner als t n \u22121;\u03b1 = \u2212t n \u22121;1\u2212\u03b1 sein, damit die Alternativhypothese angenommen werden kann. Der Ablehnungsbereich mit der Fl\u00e4che \u03b1 ist bei einseitigen Fragestellungen nur auf einer Seite der Dichtefunktion der t-Verteilung. Die kritischen Werte sind also abh\u00e4ngig von der Anzahl der Freiheitsgrade f = n \u2212 1 , der Irrtumswahrscheinlichkeit \u03b1 und davon, ob man ein- oder zweiseitig testet.\nAbb. 10.1 Annahme- und Ablehungsbereich beim t-Test (zweiseitige Fragestellung)\n1- \u03b1 \u03b1/2\n-tn \u20131;1\u2013 \u03b1/2\nAnnahmebereich\n\u03b1/2\ntn \u20131;1\u2013 \u03b1/2\n194\n10\nKapitel 10 \u00b7 Das Prinzip eines statistischen Tests\nDiese Vorgehensweise gew\u00e4hrleistet, dass \u2013 falls die Nullhypothese richtig ist \u2013 mit einer Wahrscheinlichkeit von mindestens 95% eine richtige Entscheidung getroffen wird. Das Risiko einer Fehlentscheidung (also der \u03b1-Fehler) betr\u00e4gt demnach maximal 5%. Theoretisch kann der Anwender eines statistischen Tests die maximale Gr\u00f6\u00dfe des \u03b1-Fehlers nach Belieben festlegen. Um jedoch eine Vergleichbarkeit statistisch abgesicherter Entscheidungen zu erm\u00f6glichen, hat sich in den Biowissenschaften ein Schwellenwert von 5 % eingeb\u00fcrgert. Diesen Wert bezeichnet man als das \u03b1-Niveau oder Signifikanzniveau. Bei besonderen Fragestellungen w\u00e4hlt man auch \u03b1 = 1% oder \u03b1 = 0,1% , hin und wieder auch \u03b1 = 10% . Die maximale Gr\u00f6\u00dfe des \u03b1-Fehlers sollte vor der Durchf\u00fchrung des Tests festgelegt werden. Daraus ergeben sich dann der Annahmebereich f\u00fcr die Nullhypothese sowie der kritische Bereich (oder Ablehnungsbereich f\u00fcr die Nullhypothese). Wenn die Pr\u00fcfgr\u00f6\u00dfe in den Annahmebereich f\u00e4llt, entscheidet man sich f\u00fcr die Nullhypothese, ansonsten f\u00fcr die Alternativhypothese. Nun ist auch umgekehrt m\u00f6glich, dass in Wirklichkeit die Alternativhypothese richtig ist und man f\u00e4lschlicherweise die Nullhypothese beibeh\u00e4lt. In diesem Fall begeht man einen \u03b2-Fehler oder Fehler 2. Art. Dieser l\u00e4sst sich im Gegensatz zum \u03b1-Fehler kaum absch\u00e4tzen, da die Alternativhypothese nicht explizit vorgegeben ist. Generell gilt: Je mehr sich der unbekannte Erwartungswert \u01cb und der Sollwert \u00b5 0 unterscheiden, desto eher l\u00e4sst sich die Alternativhypothese absichern und desto kleiner ist der \u03b2-Fehler. Man kann den \u03b2-Fehler durch die Wahl des \u03b1-Fehlers beeinflussen. Je gr\u00f6\u00dfer der Wert f\u00fcr \u03b1 angenommen wird, umso gr\u00f6\u00dfer ist der kritische Bereich und umso kleiner ist \u03b2. Ein kleiner \u03b1-Fehler bedeutet also einerseits, dass man seltener eine richtige Nullhypothese ablehnt. Andererseits geht man ein h\u00f6heres Risiko ein, die Nullhypothese auch dann beizubehalten, wenn in Wirklichkeit die Alternativhypothese richtig ist. 10.1.4 Der Stichprobenumfang Dem Stichprobenumfang ist besondere Beachtung beizumessen, da er das Testergebnis massiv beeinflusst. Je kleiner der Stichprobenumfang ist, desto eher wird die Nullhypothese beibehalten. Andererseits gibt ein extrem gro\u00dfer Stichprobenumfang der Nullhypothese keine Chance. Daraus folgt: Jede Alternativhypothese (die auch nur minimal von der Nullhypothese abweicht) l\u00e4sst sich statistisch absichern, wenn nur der Stichprobenumfang hinreichend gro\u00df ist.\n195\n10\n10.2 Testentscheidung und Konsequenzen\nDemnach k\u00f6nnte man meinen, dass die Testentscheidung bedeutungslos ist. Sie ist es jedoch nicht, wenn der Anwender (der ja in der Regel die Alternativhypothese annehmen m\u00f6chte) vorab dar\u00fcber nachdenkt, wie gro\u00df der Unterschied zwischen Null- und Alternativhypothese sein sollte, damit ihm eine praktische Bedeutung zukommt, und aufgrund dieser \u00dcberlegungen den Stichprobenumfang bestimmt. Damit kann man verhindern, dass ein Test nur aufgrund eines hohen Stichprobenumfangs kleinste Unterschiede erkennt, die in Wirklichkeit belanglos sind. Eine Besonderheit stellen sequenzielle Testverfahren dar, bei denen der Stichprobenumfang nicht vor dem Testen als fixe Gr\u00f6\u00dfe festgelegt, sondern als eine Zufallsvariable aufgefasst wird. Der zu pr\u00fcfende Parameter wird nicht nur unter der Nullhypothese, sondern auch unter der Alternativhypothese fixiert (dazu muss der Anwender wissen, welche Differenz zwischen Null- und Alternativhypothese klinisch bedeutsam ist). Au\u00dferdem werden sowohl \u012e als auch \u03b2 vorab bestimmt. Man f\u00fchrt den Test zun\u00e4chst mit einem minimalen Stichprobenumfang durch, erh\u00f6ht diesen um 1 und wiederholt diese Prozedur so lange, bis eine Testentscheidung m\u00f6glich ist. Dieses Verfahren gew\u00e4hrleistet, dass der Stichprobenumfang optimal ist (nicht zu hoch und nicht zu niedrig). Allerdings sind sequenzielle Verfahren in der Praxis nicht immer geeignet. N\u00e4heres dazu findet man in [5]. Merke Der optimale Stichprobenumfang h\u00e4ngt von mehreren Parametern ab: 1. vom \u012e-Fehler (\u00fcblich ist \u012e = 0,05), 2. vom \u03b2-Fehler (\u00fcblich ist \u03b2 = 0,20), 3. von der Art der Daten und deren Skalenniveau, 4. von der Streuung der Daten, 5. vom speziellen Test und 6. von der Gr\u00f6\u00dfe des nachzuweisenden Effekts.\n10.2\nTestentscheidung und Konsequenzen\n10.2.1 Die Basis der Testentscheidung Ein statistischer Test endet mit einer Entscheidung, die aufgrund des Testergebnisses getroffen wird. Generell gibt es zwei M\u00f6glichkeiten:\n196\nKapitel 10 \u00b7 Das Prinzip eines statistischen Tests\n\u0177 Wenn die Pr\u00fcfgr\u00f6\u00dfe im kritischen Bereich liegt, entscheidet man sich f\u00fcr die Alternativhypothese. Ein solches Ergebnis hei\u00dft in Abh\u00e4ngigkeit von \u03b1 schwach-signifikant ( \u03b1 = 10% ), signifikant ( \u03b1 = 5% ), hoch-signifikant ( \u03b1 = 1% ) oder h\u00f6chst-signifikant ( \u03b1 = 0,1% ). Theoretisch kann diese Entscheidung zwar falsch sein \u2013 n\u00e4mlich dann, wenn in Wirklichkeit die Nullhypothese richtig ist und man dennoch eine Pr\u00fcfgr\u00f6\u00dfe im kritischen Bereich erh\u00e4lt. Dieses Risiko wird jedoch durch den Wert von \u03b1 kontrolliert. Man formuliert die Entscheidung als: \u201eDie Nullhypothese wird verworfen\u201c oder \u201eDie Alternativhypothese wird angenommen\u201c. \u0177 Wenn die Pr\u00fcfgr\u00f6\u00dfe im Annahmebereich liegt, entscheidet man sich f\u00fcr die Nullhypothese. Diese Entscheidung ist richtig, wenn die Aussage der Nullhypothese in Wirklichkeit zutrifft. Ansonsten ist man einem \u03b2-Fehler erlegen. Dieser Fehler ist im Gegensatz zum \u03b1-Fehler nicht absch\u00e4tzbar; er kann \u2013 insbesondere bei kleinem Stichprobenumfang \u2013 sehr gro\u00df sein. Eine Pr\u00fcfgr\u00f6\u00dfe im Annahmebereich ist deshalb kein Beleg f\u00fcr die Richtigkeit der Nullhypothese, sondern lediglich ein Hinweis darauf, dass man anhand des vorhandenen Datenmaterials die Nullhypothese nicht ablehnen kann. Man formuliert deshalb sehr vorsichtig: \u201eDie Nullhypothese kann auf dem Signifikanzniveau \u03b1 nicht verworfen werden\u201c oder \u201eEs ergibt sich kein Widerspruch zur Nullhypothese\u201c.\n10\nDie Wahrscheinlichkeit eines Tests, eine richtige Alternativhypothese als solche zu erkennen, ist 1 \u2212 \u03b2 . Sie quantifiziert die so genannte G\u00fcte, Testst\u00e4rke, Trennsch\u00e4rfe oder Macht. Auch der englische Ausdruck Power wird h\u00e4ufig verwendet. ! Der Versuchsleiter wei\u00df bei Annahme der Alternativhypothese nie ganz z\ngenau, ob er eine richtige Entscheidung getroffen hat, oder ob er einem \u03b1-Fehler erlegen ist. Deshalb klingen S\u00e4tze \u201eMit 95%-iger Sicherheit trifft die Alternativhypothese zu\u201c oder \u201eMit einer Wahrscheinlichkeit von weniger als 5% ist die Alternativhypothese falsch\u201c plausibel. Diese Formulierungen sind zwar weit verbreitet, aber nicht korrekt. Sie w\u00fcrden ja implizieren, dass die vorab konkret formulierte Alternativhypothese meistens richtig, aber zuf\u00e4llig auch einmal falsch sein kann. Einer Hypothese haftet jedoch nichts Zuf\u00e4lliges an \u2013 sie ist entweder richtig oder falsch. Zuf\u00e4llig sind die Daten, die in die Stichprobe gelangen, damit auch die Testgr\u00f6\u00dfe und die davon abh\u00e4ngige Entscheidung.\n10\n197 10.2 Testentscheidung und Konsequenzen\nTabelle 10.1 Entscheidungen bei einem statistischen Test\nWirklichkeit Testentscheidung\nH 0 gilt\nH1 gilt\nf\u00fcr H 0\nrichtige Entscheidung\nFehler 2. Art\n1\u2212 \u03b1\n\u00df\nf\u00fcr H1\nFehler 1. Art\nrichtige Entscheidung\n\u03b1\n1\u2212 \u00df\nSumme\n1\n1\nAus diesen Ausf\u00fchrungen geht hervor: Die Nullhypothese ist in der Testtheorie die Basis, von der entschieden wird. Es ist wichtig, daf\u00fcr zu sorgen, dass sie nicht leichtfertig oder grundlos abgelehnt wird. Man ist deshalb vorsichtig und akzeptiert die Alternativhypothese nur dann, wenn die Testgr\u00f6\u00dfe in den kritischen Bereich f\u00e4llt \u2013 mit anderen Worten: wenn der Wert der Testgr\u00f6\u00dfe mit der Nullhypothese nur schwer zu vereinbaren ist. 10.2.2 p-Wert und Konfidenzintervall Vor noch nicht allzu langer Zeit war es \u00fcblich, eine Pr\u00fcfgr\u00f6\u00dfe per Hand oder mit einem Taschenrechner zu berechnen. Um zu beurteilen, ob das Ergebnis signifikant war, hatte man den berechneten Wert mit einem kritischen Wert zu vergleichen. In fast jedem Statistiklehrbuch findet man Tabellen, in denen kritische Werte aufge\u203a Anhang, Tabellen A \u2013 F). Wenn beispielsweise die listet sind (z Pr\u00fcfgr\u00f6\u00dfe, die aus einem t-Test f\u00fcr eine Stichprobe resultiert, betragsm\u00e4\u00dfig gr\u00f6\u00dfer ist als das Quantil tn \u22121;0,975 , kann man davon ausgehen, dass das Testergebnis signifikant ist auf dem Niveau \u03b1 = 0,05 . Wenn die Pr\u00fcfgr\u00f6\u00dfe sogar gr\u00f6\u00dfer ist als tn \u22121;0,995 , ist der Unterschied auf dem 1%-Niveau abgesichert (jeweils beim zweiseitigen Testen). Heutzutage ist es \u00fcblich, einen statistischen Test mit Hilfe einer geeigneten Software durchzuf\u00fchren. Diese berechnet in der Regel au\u00dfer der Pr\u00fcfgr\u00f6\u00dfe den so genannten p-Wert. Dieser Wert quantifiziert die Wahrscheinlichkeit, dass das gefundene Testergebnis (oder ein noch extremeres Ergebnis) zustande kommt, wenn in Wirklichkeit die Nullhypothese richtig ist. Wenn p kleiner ist als das zuvor festgelegte Signifikanzniveau \u012e, wird die Alternativhypothese angenommen. Etwas salopp ausgedr\u00fcckt ist der p-Wert die Wahrscheinlichkeit daf\u00fcr, dass das Testergebnis ein reiner Zufallsbefund ist. Grunds\u00e4tzlich ist Folgendes zu beachten:\n198\nKapitel 10 \u00b7 Das Prinzip eines statistischen Tests\n\u2022 Der p-Wert besagt lediglich, ob ein statistisch signifikanter Unterschied existiert. Er enth\u00e4lt jedoch keine Informationen \u00fcber die Gr\u00f6\u00dfe dieses Unterschieds. Deshalb ist es sinnvoll, zus\u00e4tzlich zum p-Wert ein Konfidenzintervall zu berechnen. \u2022 Grunds\u00e4tzlich sind alle Werte im Konfidenzintervall f\u00fcr die Gr\u00f6\u00dfe des Unterschieds in Betracht zu ziehen. Je schmaler dieses Intervall ist, desto pr\u00e4ziser ist die Sch\u00e4tzung und desto einfacher ist die Interpretation des Testergebnisses. Problematisch ist es, wenn ein kleiner Stichprobenumfang zu einem nicht-signifikanten Ergebnis und einem breiten Konfidenzintervall f\u00fchrt. In diesem Fall kann keine Aussage dar\u00fcber getroffen werden, ob es keinen praktisch relevanten Unterschied gibt oder ob dieser nur nicht nachgewiesen werden kann. Beispiel 10.1 Ein Arzt erh\u00e4lt bei einer Beobachtungsstudie mit 20 Babys von Risiko-Patientinnen f\u00fcr das Geburtsgewicht: x \u00b1 s = (3280 \u00b1 490) Gramm. Diese Werte sind zu vergleichen mit dem aus der Literatur bekannten Durchschnittswert von 3500 Gramm. Aus den Daten resultiert nach (10.1): t =\nx \u2212 \u00b50 3280 \u2212 3500 == = \u22122,0079 und s/ n 490 / 20\np = 0, 0509 . Der kritische Wert ist t19;0,975 = 2, 093 (zweiseitiger Test, Tabelle\n10\nB). Auf dem \u03b1 = 5% -Niveau m\u00fcsste man also die Nullhypothese beibehalten. F\u00fcr das einseitige Testen betr\u00e4gt der kritische Punkt jedoch t19;0,95 = 1, 729 ; der p-Wert halbiert sich auf 0,0255. Dieses Ergebnis ist signifikant. Das einseitige Konfidenzintervall f\u00fcr den Mittelwert ist nach Formel (9.10): (-; 3469). Dies zeigt zwar, dass die 20 Babys durchschnittlich weniger wiegen als 3500 Gramm, dass aber der Unterschied m\u00f6glicherweise nicht sehr gravierend ist. Bei diesem einseitigen Intervall ist nur die obere Grenze interessant. i Beim einseitigen t-Test entspricht der p-Wert dem Integral (also der Fl\u00e4z che) zwischen der nach (10.1) berechneten Pr\u00fcfgr\u00f6\u00dfe und dem Ende der Dichtefunktion; beim zweiseitigen t-Test verteilt sich diese Fl\u00e4che gleichm\u00e4\u00dfig auf beide Enden der Dichtefunktion. Falls das Ergebnis signifikant \u203a Abbilist mit p < \u03b1 , ist diese Fl\u00e4che ein Teil des kritischen Bereiches (z dung 10.1). Es ist in der Regel nicht m\u00f6glich, die p-Werte eines statistischen Tests manuell zu bestimmen. In den Beispielen der Kapitel 10 bis 12 wurden diese mit Hilfe der Statistiksoftware SAS ermittelt.\n199\n10\n10.2 Testentscheidung und Konsequenzen\n10.2.3 Die Interpretation eines signifikanten Ergebnisses Das Ziel eines statistischen Tests besteht meistens darin, die Alternativhypothese abzusichern. Ob das gelingt, h\u00e4ngt vom p-Wert ab. Ein p-Wert unter 0,05 ist h\u00e4ufig Anlass zu gro\u00dfer Freude! Viele Anwender unterliegen aber allzu menschlichen Schw\u00e4chen und \u201e\u00fcber\u201cinterpretieren ein Testergebnis subjektiv nach ihren eigenen Vorstellungen. Dies m\u00f6ge an den Beispielen dieses Kapitels verdeutlicht werden. Das Ergebnis von Beispiel 10.1 erh\u00e4rtet die These, dass das Geburtsgewicht der Risiko-Babys geringer ist als der allgemeine Durchschnitt. Das Ergebnis allein ist aber kein hieb- und stichfester Beweis (sondern lediglich ein Hinweis) f\u00fcr einen kausalen Zusammenhang. Um diese These zu erh\u00e4rten, sind weitere \u00dcberlegungen fachlicher Art notwendig. In Beispiel 11.1 wird die Wirkung einer Di\u00e4t an 10 Probanden getestet; der Unterschied bez\u00fcglich des durchschnittlichen K\u00f6rpergewichts vor und nach der Di\u00e4t ist statistisch signifikant. Dies hei\u00dft jedoch keineswegs, dass sich das K\u00f6rpergewicht allein wegen der Di\u00e4t verringert hat. Auch andere Ursachen sind in Betracht zu ziehen (m\u00f6glicherweise haben die Probanden generell ihren Lebensstil oder ihre Einstellung zu ihrer Gesundheit ver\u00e4ndert). In Beispiel 11.5 erh\u00e4lt man mit denselben Daten und einem anderen Testverfahren ein nicht-signifikantes Ergebnis. Hier w\u00e4re es allzu leichtfertig, das Ergebnis dahingehend zu interpretieren, als habe die Di\u00e4t keinen Einfluss auf das Gewicht. Das Ergebnis ist auch bedingt durch die geringe Power des Tests und den kleinen Stichprobenumfang. Generell gilt: Der p-Wert besagt nichts \u00fcber die Ursachen eines Unterschiedes oder \u00fcber die Konsequenzen, die sich daraus ergeben. Diese Fragen m\u00fcssen mit medizinischem Sachverstand gekl\u00e4rt werden; die Statistik hilft dabei nicht weiter. Der Anwender eines statistischen Tests sollte sich von einem kleinen p-Wert nicht blenden lassen. \u201eStatistische Signifikanz\u201c ist nicht gleichbedeutend mit \u201epraktischer Relevanz\u201c oder \u201ewissenschaftlicher Bedeutsamkeit\u201c. 10.2.4 Die Interpretation eines nicht-signifikanten Ergebnisses Ein nicht-signifikantes Testergebnis kann zweierlei bedeuten. 1: Es gibt keinen relevanten Unterschied, oder 2: Es gibt einen bedeutsamen Unterschied, der sich aber wegen eines zu geringen Stichprobenumfangs nicht nachweisen l\u00e4sst. Ein Konfidenzintervall ist hilf-\n200\n10\nKapitel 10 \u00b7 Das Prinzip eines statistischen Tests\nreich, um zu beurteilen, welche dieser beiden Alternativen eher zutrifft. Der Test in Beispiel 12.2 wurde durchgef\u00fchrt, um herauszufinden, ob ein Zusammenhang zwischen Rauchen und Geschlecht besteht. Das Ergebnis \u201enicht signifikant\u201c ist mit Vorsicht zu interpretieren. Abgesehen vom nicht allzu gro\u00dfen Stichprobenumfang ist zu bedenken, dass die Beobachtungseinheiten Medizinstudenten sind. Auf andere Populationen ist das Ergebnis nicht ohne weiteres \u00fcbertragbar. Wenn man keinen Unterschied erwartet hat, ist ein nichtsignifikantes Testergebnis nicht Aufsehen erregend. Ansonsten sollte man \u00fcberlegen, ob ein inhaltlicher Fehler vorliegt oder ob die statistische Analyse nicht optimal verlaufen ist. Nun gibt es auch Fragestellungen, bei denen die Beibehaltung der Nullhypothese erw\u00fcnscht ist. Dazu z\u00e4hlen Anpassungstest und \u00c4quivalenztests. Mit einem Anpassungstest soll nachgewiesen werden, dass eine empirische Verteilung mit einer theoretischen Ver\u203a Abschnitt 12.2.6). In diesen F\u00e4llen wird die teilung vereinbar ist (z Nullhypothese meist erst f\u00fcr p \u2265 0,10 angenommen. \u00c4quivalenztests werden u. a. bei Bioverf\u00fcgbarkeitsstudien angewandt, um die therapeutische Gleichwertigkeit zweier Behandlungen zu pr\u00fcfen. F\u00fcr den Nachweis, dass zwei Verfahren \u00fcbereinstimmend dieselben Ergebnisse liefern (abgesehen von zuf\u00e4llig bedingten Abweichungen, die f\u00fcr die Praxis unerheblich sind), stehen spezielle Methoden zur Verf\u00fcgung. F\u00fcr quantitative Messwerte eignet sich die \u203a Abschnitt 5.2.5). Bei qualitativen MerkBland-Altman-Analyse (z malen wird \u00fcblicherweise ein Kappa-Index berechnet, um den Grad \u203a Abschnitt 15.1.4). Weitere der \u00dcbereinstimung abzusch\u00e4tzen (z Informationen zu \u00c4quivalenztests findet man in [11]. 10.2.5 Die Manipulation des Testergebnisses Ein signifikantes Ergebnis l\u00e4sst sich leichter publizieren als ein nicht-signifikantes. Um dies zu erreichen, ist einigen Leuten jedes Mittel recht. Einige dieser \u201eTricks\u201c werden hier aufgez\u00e4hlt (wobei ausdr\u00fccklich betont wird, dass sie nicht zur Nachahmung empfohlen werden).\n\u2022 Auswahl des Tests. Bei vielen Fragestellungen kommen theore tisch mehrere Testmethoden mit unterschiedlichen Voraussetzungen in Frage. Die oben behandelte Frage, ob das mittlere Geburtsgewicht der 20 Babys mit dem Sollwert von 3.500 Gramm zu vereinbaren ist,\n201\n10\n10.2 Testentscheidung und Konsequenzen\nkann auch mit dem Wilcoxon-Test oder dem Vorzeichentest \u00fcber\u203a Abschnitte 11.2.1 und 11.3.1). Man k\u00f6nnte nun alle pr\u00fcft werden (z in Frage kommenden Tests durchprobieren und sich dann denjenigen ausw\u00e4hlen, dessen p-Wert am besten gef\u00e4llt (irgendeine Begr\u00fcndung bez\u00fcglich der Voraussetzungen l\u00e4sst sich sicherlich finden). Grunds\u00e4tzlich sollte man sich jedoch von vornherein aufgrund der Datenlage f\u00fcr ein bestimmtes Testverfahren entscheiden und dessen Ergebnis dann akzeptieren.\n\u2022 Ein- oder zweiseitiges Testen. Es mag verlockend sein, einseitig zu testen, nachdem man mit dem zweiseitigen Testen einen p-Wert zwischen 0,05 und 0,10 erhalten hat. Dann halbiert sich der p-Wert, und aus einem nicht-signifikanten Ergebnis wird ein signifikantes. Gegen eine einseitige Fragestellung ist nichts einzuwenden, falls sie sachlich begr\u00fcndet ist und falls die Richtung eines m\u00f6glichen Unterschiedes vor der Datenerhebung festgelegt wird. Es ist aber unehrlich, einseitig zu testen und die Richtung des Unterschieds erst festzulegen, nachdem die Daten vorliegen. Man testet einseitig, wenn man die Richtung eines eventuell vorhandenen Unterschiedes vorab kennt, oder wenn sich Konsequenzen nur bei einer bestimmten Abweichungsrichtung ergeben. Der Anwender sollte sich allerdings fragen, ob wirklich nur eine einzige Abweichungsrichtung interessant ist, oder ob er sich einen Unterschied in einer bestimmten Richtung erhofft und deshalb einseitig testet. Au\u00dferdem ist zu ber\u00fccksichtigen, dass einseitige Tests empfindlicher auf eine Verletzung ihrer Voraussetzungen reagieren als zweiseitige. Weitere Kniffe, mit denen sich Daten \u201efrisieren\u201c lassen und so zu sinnlosen oder irref\u00fchrenden Ergebnissen f\u00fchren, liest man auf unterhaltsame Weise in [3]. Man kann zwar mit derlei Tricks gewaltsam ein signifikantes Ergebnis herbeif\u00fchren und dieses mit etwas Gl\u00fcck sogar ver\u00f6ffentlichen. Die wissenschaftliche Arbeit ist damit aber wertlos. F\u00e4lschungen k\u00f6nnten bei sp\u00e4teren Verifikationen auffallen und sehr unangenehme Folgen f\u00fcr alle Beteiligten haben. Die beste Methode, zu einem signifikanten Testergebnis zu kommen und einen \u03b1-Fehler zu vermeiden, besteht immer noch darin, vor der Datenerhebung die Fragestellung theoretisch zu \u00fcberdenken und inhaltlich abzusichern. 10.2.6 Multiples Testen Im klinischen Alltag wird h\u00e4ufig eine gro\u00dfe Anzahl von Daten erhoben. Mit einer passenden Software und etwas EDV-Know-How\n202\n10\nKapitel 10 \u00b7 Das Prinzip eines statistischen Tests\nstellen deren Analyse kein nennenswertes Problem dar. So ist man oft geneigt, einen Test nach dem anderen durchzuf\u00fchren, in der Hoffnung, wenigstens ein einziges signifikantes Ergebnis zu erhalten. Aber: Bei mehrmaligem Testen steigt der \u03b1-Fehler enorm an. Bei einem einzelnen Test betr\u00e4gt die Wahrscheinlichkeit, unter der Nullhypothese richtig zu entscheiden, 1 \u2212 \u03b1 ; bei 10 unabh\u00e4ngig durchgef\u00fchrten Tests liegt diese Wahrscheinlichkeit nur noch bei (1 \u2212 \u03b1)10 . Bei \u03b1 = 5% sind dies etwa 60% \u2013 das hei\u00dft, der gesamte Fehler 1. Art liegt bei 40 %! Es l\u00e4sst sich mathematisch nachweisen, dass bei k Tests der \u03b1 -Fehler insgesamt etwa k\u03b1 betr\u00e4gt. Beim multiplen Testen wird daher h\u00e4ufig eine Korrektur benutzt. Nach der Bonferroni-Korrektur ist beispielsweise ein einzelnes Testergebnis erst dann signifikant, wenn der p-Wert kleiner als \u03b1 / k ist. Der Nachteil dieses Verfahrens liegt allerdings darin, dass sich dadurch der \u03b2-Fehler enorm erh\u00f6ht. Das Problem des multiplen Testens kann dadurch entsch\u00e4rft werden, dass man nicht wahllos jeden Test durchf\u00fchrt, der theoretisch denkbar ist, sondern dass man vorab die konkrete Fragestellung pr\u00e4zise formuliert und dann \u00fcberlegt, welche Tests dem inhaltlichen Problem angemessen sind. H\u00e4ufig ist es sinnvoll, anstatt mehrerer einfacher Tests ein komplexeres Verfahren zu verwenden (so z. B. eine Varianzanalyse statt mehrerer t-Tests), da dies eine effizientere Datenanalyse erm\u00f6glicht. Zum Schluss sei betont: Es ist selbstverst\u00e4ndlich legitim, ein signifikantes Ergebnis anzustreben und dieses auch zu ver\u00f6ffentlichen. Dies sollte aber nicht durch Manipulation der Daten oder unsachgem\u00e4\u00dfer Handhabung der Verfahren geschehen, sondern aufgrund einer ordentlichen Versuchsplanung. Die statistische Analyse ist dann nur noch das \u201eT\u00fcpfelchen auf dem i\u201c.\n10.3\nKlassifikation der Testmethoden\nEs gibt diverse Testverfahren f\u00fcr die unterschiedlichsten Fragestellungen. Diese lassen sich nach mehreren Aspekten einteilen:\n\u2022 Anzahl der Stichproben. Es gibt 1-Stichprobentests, 2-Stichpro ben- und Mehrstichprobentests. Bei den 1-Stichprobentests wird eine empirische Kenngr\u00f6\u00dfe (z. B. ein Mittelwert) mit einem vorgegebenen Sollwert verglichen. Mehrere Stichproben werden bez\u00fcglich eines bestimmten Parameters (z. B. dem Mittelwert) miteinander verglichen.\n203\n10\n10.3 Klassifikation der Testmethoden\n\u2022 Art der Stichproben. Zwei oder mehrere Stichproben k\u00f6nnen verbunden oder unverbunden sein. Verbundene (oder abh\u00e4ngige) Stichproben haben immer denselben Umfang; zwei verbundene Stichproben werden auch paarig genannt. Jeder Wert der einen Stichprobe bildet mit einem Wert der anderen Stichprobe inhaltlich ein Paar. Verbundene Stichproben werden untersucht, wenn ein bestimmtes Merkmal im Laufe einer Therapie an Patienten zu mehreren Zeitpunkten erfasst wird. Unverbundene (oder unabh\u00e4ngige) Stichproben sind bez\u00fcglich ihrer Beobachtungseinheiten unabh\u00e4ngig voneinander; ihre Umf\u00e4nge k\u00f6nnen unterschiedlich sein. Solche Stichproben treten bei klinischen Studien auf, in denen zwei oder mehr Therapien an unterschiedlichen Patientengruppen angewandt und verglichen werden. \u2022 Funktion des Tests. Diesbez\u00fcglich lassen sich Tests einteilen in:\n\u0177 Lagetests zum Vergleich von Lagema\u00dfen; \u0177 Wahrscheinlichkeitstests zum Vergleich \u0177 \u0177 \u0177 \u0177 \u0177\neiner relativen H\u00e4ufigkeit mit einer vorgegebenen Wahrscheinlichkeit; Homogenit\u00e4tstests zum Vergleich mehrerer Stichproben bez\u00fcglich einer H\u00e4ufigkeitsverteilung; Dispersionstests zur Pr\u00fcfung von Streuungsma\u00dfen; Unabh\u00e4ngigkeitstests, um die Unabh\u00e4ngigkeit zweier Merkmale zu \u00fcberpr\u00fcfen; Anpassungstests, bei denen eine empirische Verteilung mit einer theoretischen (z. B. Normalverteilung oder Poissonverteilung) verglichen wird; Tests zum Vergleich von \u00dcberlebenszeitkurven.\n\u2022 Pr\u00fcfgr\u00f6\u00dfen. Danach unterscheidet man u. a. t-Tests, Rang summentests, Vorzeichentests, Chi2-Tests und Binomialtests. In den beiden n\u00e4chsten Kapiteln werden Tests behandelt, die sich zum Nachweis einfacher Zusammenh\u00e4nge eignen. Diese Tests beinhalten das Basiswissen, das erforderlich ist, um komplexere Verfahren anwenden zu k\u00f6nnen. Dazu z\u00e4hlen Mehrstichprobentests und multiple Methoden, die den Zusammenhang zwischen einer Zielgr\u00f6\u00dfe und mehreren Einflussgr\u00f6\u00dfen untersuchen. Es w\u00fcrde den Rahmen dieses Buches sprengen, derlei Verfahren ausf\u00fchrlich zu behandeln. Interessierten Lesern seien die Werke [1,], [2], [4] und [10] empfohlen.\n204\nKapitel 10 \u00b7 Das Prinzip eines statistischen Tests\n\u00dcbersicht 8: Statistische Tests Funktion des Tests\nBezeichnung\nLagetest f\u00fcr eine Stichprobe\nt-Test Wilcoxon-Test Vorzeichentest\nLagetest f\u00fcr zwei verbundene Stichproben\nLagetest f\u00fcr zwei unverbundene Stichproben\n10\nTestgegenstand\nX normalverteilt X symmetrisch verteilt Variable X Differenz X \u2212 Y t-Test normalverteilt Differenz X \u2212 Y Wilcoxon-Test symmetrisch verteilt Vorzeichentest Differenz X \u2212 Y X und Y normalverteilt mit t-Test gleicher Varianz Welch-Test X und Y normalverteilt X und Y gleiche U-Test Verteilungsform Median-Test X und Y ordinal skaliert\nAbschn.\n11.1.1 11.2.1 11.3.1 11.1.2 11.2.2 11.3.2 11.1.3 11.1.4 11.2.3 12.2.2\nDispersionstest\nF-Test\n2 Varianzen\n11.1.5\nUnabh\u00e4ngigkeitstest\nt-Test\nKorrelationskoeffizient\n11.1.6\nWahrscheinlichkeitstest\nBinomialtest\nAlternativmerkmal\n12.1\nHomogenit\u00e4tstest f\u00fcr zwei unverbundene Stichproben, Unabh\u00e4ngigkeitstest Homogenit\u00e4tstest f\u00fcr zwei verbundene Stichproben\nVierfeldertest Chi2-Test Fisher\u2019s exakter Test\n2 Alternativmerkmale 2 qualitative Merkmale\n12.2.1 12.2.3\n2 qualitative Merkmale\n12.3\nMcNemar-Test\nAlternativmerkmal\n12.2.5\nAnpassungstest\nChi2Anpassungstest\nempirische Verteilung\n12.2.6\nVergleich von \u00dcberlebenszeiten\nLogrank-Test\n\u00dcberlebenszeitkurven\n12.2.7\n11\nLagetests 11.1\nt-Tests 207\n11.1.1 Der t-Test f\u00fcr eine Stichprobe 207 11.1.2 Der t-Test f\u00fcr zwei verbundene Stichproben 207 11.1.3 Der t-Test f\u00fcr zwei unverbundene Stichproben 209 11.1.4 Der Welch-Test 210 11.1.5 Die Voraussetzungen der t-Lagetests 212 11.1.6 Andere Anwendungen des t-Tests 214\n11.2\nRangsummentests 215\n11.2.1 Der Wilcoxon-Test f\u00fcr eine Stichprobe 215 11.2.2 Der Wilcoxon-Test f\u00fcr zwei verbundene Stichproben 216 11.2.3 Der U-Test von Mann und Whiney 218 11.2.4 Vergleich zwischen Rangsummentests und t-Tests 219\n11.3\nVorzeichentests 222\n11.3.1 Der Vorzeichentest f\u00fcr eine Stichprobe 222 11.3.2 Der Vorzeichentest f\u00fcr zwei verbundene Stichproben 223 11.3.3 Vergleich mit anderen Lagetests 223\n11.4\nAusblick auf komplexere Methoden 224\n11.4.1 Mehrstichprobentests 224 11.4.2 Multiple Methoden 225\n207\n11\n11.1 t-Tests\n11.1\nt-Tests\nDiese Tests setzen theoretisch normalverteilte Grundgesamtheiten voraus. Man bezeichnet sie als parametrische Tests, da bei bekannter Verteilung der Zufallsvariablen nur noch bestimmte Parameter (z. B. Erwartungswerte) \u00fcberpr\u00fcft werden. 11.1.1 Der t-Test f\u00fcr eine Stichprobe Dieser Test vergleicht den Mittelwert x einer Stichprobe mit einem vorgegeben Sollwert \u00b5 0 . Er setzt voraus, dass\n\u0177 die Stichprobenwerte xi Realisationen einer normalverteilten Zufallsvariablen X ~ N (\u00b5, \u03c3 2 ) sind.\nDieser Test wurde ausf\u00fchrlich in Abschnitt 10.1 behandelt. Die Pr\u00fcfgr\u00f6\u00dfe, nach der entschieden wird, berechnet sich nach (10.1) aufgrund des Mittelwerts und der Standardabweichung der Stichprobe als: t=\nx \u2212 \u00b50 s/ n\n11.1.2 Der t-Test f\u00fcr zwei verbundene Stichproben Dies ist ein Lagetest, der herangezogen wird, um die Gleichheit von zwei Erwartungswerten zu \u00fcberpr\u00fcfen. Er setzt formell voraus:\n\u0177 zwei verbundene Stichproben des Umfangs n mit Wertepaaren \u0177\n( xi , yi ) , die aus Grundgesamtheiten mit den Erwartungswerten \u00b51 und \u00b5 2 stammen; Differenzen d i = xi \u2212 yi , die Realisationen einer normalverteilten Zufallsvariablen D mit dem Erwartungswert \u012f (Delta) sind.\nDie Hypothesen lauten bei zweiseitiger Fragestellung: H0 :\n\u03b4=0\nH1 :\n\u03b4\u22600\nbzw. bei einseitiger Fragestellung: H1 :\n\u03b4>0\n(oder \u03b4 < 0 )\n208\nKapitel 11 \u00b7 Lagetests\nUnter der Nullhypothese erwartet man f\u00fcr die Differenzen d i den Mittelwert d = 0 . Die Pr\u00fcfgr\u00f6\u00dfe berechnet sich analog zu (10.1) als t=\nd sd / n\n(11.1)\nDabei bezeichnet s d die empirische Standardabweichung der Differenzen d i . Die Nullhypothese wird abgelehnt, falls t > t n \u22121;1\u2212 \u03b1 / 2 (bei zweiseitiger Fragestellung). Bei einseitiger Fragestellung wird die Nullhypothese abgelehnt, falls t > tn \u22121;1\u2212\u03b1 (f\u00fcr H1 : \u03b4 > 0 ) bzw. falls t < \u2212tn \u22121;1\u2212\u03b1 (f\u00fcr H1 : \u03b4 < 0 ). Auch bei diesem Test ist es sinnvoll, ein Konfidenzintervall zu bestimmen, um die Gr\u00f6\u00dfe des \u201ewahren\u201c \u203a Formel 9.9): Unterschieds abzusch\u00e4tzen (z t n \u22121;1\u2212\u03b1 / 2 \u22c5 s d t n \u22121;1\u2212\u03b1 / 2 \u22c5 s d \u00ba \u00aa ;d + \u00bb \u00abd \u2212 n n \u00bc \u00ac\nFalls einseitig getestet wird, benutzt man die Formeln nach (9.10), um ein halboffenes Intervall zu konstruieren.\n11\nBeispiel 11.1 In Beispiel 11.3 sind die K\u00f6rpergewichte von 10 Personen aufgelistet, die vor und nach einer Di\u00e4t gemessen wurden. Die Mittelwerte sind 93,9 kg (vorher) und 91,2 kg (nachher). Die mittlere Differenz ist (2,68 \u00b1 3,32) kg. Dies ergibt nach (11.1) die Pr\u00fcfgr\u00f6\u00dfe t = 2,55 . Aus Tabelle B entnimmt man t9;0,975 = 2,262 als kritischen Punkt (der p-Wert betr\u00e4gt 0,0312). Der Unterschied ist also signifikant auf dem Niveau \u03b1 = 0,05 . Das Konfidenzintervall f\u00fcr die Differenz ist: [0,302 ; 5,059]. Eventuell ist der durchschnittliche Unterschied mit 300 Gramm minimal; er k\u00f6nnte jedoch auch mehrere kg betragen. Das Testergebnis ist zwar signifikant \u2013 ein h\u00f6herer Stichprobenumfang w\u00fcrde aber zu einem kleineren Konfidenzintervall und zu einer genaueren Sch\u00e4tzung f\u00fchren. i Bei praktischen Anwendungen ist es nicht notwendig, die Pr\u00fcfgr\u00f6\u00dfe, den z kritischen Punkt oder das Konfidenzintervall manuell zu berechnen. Um zu beurteilen, ob ein Ergebnis signifikant ist, l\u00e4sst man den p-Wert und das Konfidenzintervall von einer Statistiksoftware ermitteln (die Pr\u00fcfgr\u00f6\u00dfe ist bei Publikationen von untergeordneter Bedeutung). Dennoch wird in den Beispielen der Kapitel 11 und 12 die Berechnung der jeweiligen Pr\u00fcfgr\u00f6\u00dfe aus didaktischen Gr\u00fcnden durchgef\u00fchrt.\n209\n11\n11.1 t-Tests\n11.1.3 Der t-Test f\u00fcr zwei unverbundene Stichproben Die Pr\u00e4missen dieses Tests sind folgende:\n\u0177 Es liegen zwei unverbundene Stichproben der Umf\u00e4nge n1 und n2 vor;\n\u0177 die Daten beider Stichproben entstammen normalverteilten Grundgesamtheiten mit derselben Varianz, also X ~ N (\u00b51, \u03c3 2 ) und Y ~ N (\u00b5 2 , \u03c3 2 ) .\nBeide Verteilungen sollten demnach dieselbe Form haben und sich h\u00f6chstens bez\u00fcglich ihrer Erwartungswerte unterscheiden. Die Nullhypothese lautet: H 0 : \u00b51 = \u00b5 2 . Die Pr\u00fcfgr\u00f6\u00dfe ist: x\u2212y\nt= s\u22c5\n(11.2)\n1 1 + n1 n2\nDa in diese Berechnung zwei unabh\u00e4ngige Mittelwerte einflie\u00dfen, betr\u00e4gt die Anzahl der Freiheitsgrade f = n1 + n2 \u2212 2 . Die Nullhypothese wird abgelehnt, falls t > t f ;1\u2212\u03b1 / 2 (bei zweiseitiger Fragestellung). Bei einseitiger Fragestellung ist +t f ;1\u2212\u03b1 bzw. t f ;\u03b1 = \u2212t f ;1\u2212\u03b1 der kritische Wert. Dabei ist s 2 die \u201emittlere\u201c Varianz, die sich aufgrund der Annahme gleicher Varianzen der Grundgesamtheiten durch eine gewichtete Mittelung aus den beiden empirischen Varianzen s12 und s 22 berechnen l\u00e4sst: s2 =\n( n1 \u2212 1) s12 + ( n2 \u2212 1) s22 n1 + n2 \u2212 2\n(11.3)\nDie Grenzen des zweiseitigen Konfidenzintervalls sind: x \u2212 y \u00b1 tn1 + n2 \u2212 2;1\u2212\u03b1 / 2 \u22c5 s \u22c5\n1 1 + n1 n2\nBei gleichen Stichprobenumf\u00e4ngen n = n1 = n2 vereinfachen sich die obigen Formeln zu: t=\nx\u2212y s\u22c5 2/n\n(11.4)\n210\nKapitel 11 \u00b7 Lagetests\ns2 =\ns12 + s22 2\n(11.5)\nMathematische Herleitung der Pr\u00fcfgr\u00f6\u00dfe beim t-Test f\u00fcr zwei unverbundene Stichproben Die Pr\u00fcfgr\u00f6\u00dfe beschreibt die Verteilung der Differenz X \u2212 Y , die aus den Mittelwerten der beiden Stichproben berechnet wird. Unter der Nullhypothese sind die Differenzen normalverteilt mit dem Erwartungswert 0. F\u00fcr deren Varianz gilt: Var ( X \u2212 Y ) = Var X + Var Y =\n\u03c32 \u03c32 + . n1 n2\nDie unbekannte Varianz \u03c3 2 wird gesch\u00e4tzt durch das gewichtete Mittel der beiden Stichproben-Varianzen nach Formel (11.3). Wenn man diese Terme in (8.43) einsetzt, erh\u00e4lt man eine Pr\u00fcfgr\u00f6\u00dfe nach (11.2).\n11\nBeispiel 11.2 F\u00fcr die K\u00f6rpergr\u00f6\u00dfen m\u00e4nnlicher und weiblicher Studenten ergeben sich Mittelwerte von xm = 181,22 cm bzw. xw = 169,06 cm . Ist dieser Unterschied nur zuf\u00e4llig bedingt oder kann man ihn als signifikant werten? Mit den Standardabweichungen sm = 7,12 cm bzw. sw = 6,60 cm und den Stichprobenumf\u00e4ngen n1 = 23 und n2 = 48 berechnet man nach (11.3): 22 \u22c5 7,12 2 + 47 \u22c5 6,60 2 s2 = cm 2 = 45,835 cm 2 69 Daraus ergibt sich f\u00fcr die Pr\u00fcfgr\u00f6\u00dfe nach (11.2): 181,22 \u2212 169,06 12,16 = = 7,083 t= 45,835 45,835 1,717 + 23 48 Die Anzahl der Freiheitsgrade betr\u00e4gt f = 23 + 48 \u2212 2 = 69 . Der kritische Wert t69;0,975 = 1,995 ist wesentlich kleiner als die Pr\u00fcfgr\u00f6\u00dfe. F\u00fcr den p-Wert gilt: p < 0,0001 ; das Ergebnis ist also hoch signifikant. F\u00fcr die mittlere Differenz ergibt sich folgendes Konfidenzintervall: [8,73 cm ; 15,58 cm].\n11.1.4 Der Welch-Test Der Welch-Test ist eine Alternative zum t-Test f\u00fcr zwei unverbundene Stichproben. Die Voraussetzungen sind dahingehend abgeschw\u00e4cht, dass die Gleichheit der Varianzen (die so genannte Homoskedazit\u00e4t) der beiden Grundgesamtheiten nicht vorausgesetzt wird.\n211\n11\n11.1 t-Tests i Die Problematik, Mittelwerte zu vergleichen, ohne dass gleiche Varianz zen der Grundgesamtheiten vorausgesetzt werden, wurde von B. L. Welch im Jahre 1937 beschrieben. Dieser Test ist auch unter dem Namen \u201et-Test nach Satterthwaite\u201c bekannt.\nDie empirischen Stichprobenvarianzen s12 und s 22 sind Sch\u00e4tzwerte f\u00fcr die Varianzen der Grundgesamtheiten. Die Pr\u00fcfgr\u00f6\u00dfe berechnet sich analog zu Formel (11.2) als: t=\nx\u2212y s12 s22 + n1 n2\n(11.6)\nDie Anzahl der Freiheitsgrade ermittelt man nach: f =\n( s12 / n1 + s22 / n2 ) 2 ( s12 / n1 ) 2 ( s22 / n2 ) 2 + n1 \u2212 1 n2 \u2212 1\n(11.7)\nMeist wird sich mit dieser Formel keine ganze Zahl ergeben; in diesem Fall rundet man auf die n\u00e4chst kleinere, ganze Zahl ab. In vielen Situationen stellt sich die Frage, ob der t-Test oder der Welch-Test geeigneter ist. Da beim Welch-Test weniger Voraussetzungen zu ber\u00fccksichtigen sind, k\u00f6nnte man geneigt sein, diesen zu bevorzugen (wenn etwa die Varianzen der Grundgesamtheit unbekannt sind oder die Gleichheit aus anderen Gr\u00fcnden nicht angenommen werden kann). Doch Vorsicht: Wenn die Bedingungen des t-Tests erf\u00fcllt sind, hat der Welch-Test eine geringere Power. Dann kann es passieren, dass der klassische t-Test ein Ergebnis zur Annahme der Alternativhypothese liefert, w\u00e4hrend der Welch-Test mit denselben Daten zur Beibehaltung der Nullhypothese f\u00fchrt. Au\u00dferdem sollte man sich Gedanken bez\u00fcglich der Interpretation des Testergebnisses machen. Beim Welch-Test werden ungleiche Varianzen und damit verschiedene Verteilungsformen angenommen. Ein Vergleich der dazugeh\u00f6renden Erwartungswerte erinnert an den ber\u00fchmten Vergleich zwischen Birnen und \u00c4pfeln. Eine sinnvollere Strategie besteht in der Regel darin, Fragestellungen zu behandeln, bei denen man ann\u00e4hernd gleichf\u00f6rmige Verteilungen (mit gleichen Varianzen) voraussetzen darf und den Welch-Test nur in begr\u00fcndeten Ausnahmef\u00e4llen zu verwenden.\n212\nKapitel 11 \u00b7 Lagetests\n11.1.5 Die Voraussetzungen der t-Lagetests\nt-Lagetests sind im Allgemeinen recht beliebt. Deren Grundvoraussetzung \u2013 n\u00e4mlich die Normalverteilung der Zufallsvariablen \u2013 wird dabei oft ignoriert. Leider sind jedoch viele Merkmale in der Medizin nicht normalverteilt; hin und wieder hat man es mit Merkmalen zu tun, deren Verteilung unbekannt ist. Wie l\u00e4sst sich nun die Normalverteilung \u00fcberpr\u00fcfen? Streng genommen gar nicht \u2013 denn die Forderung nach Normalverteilung bezieht sich auf die Grundgesamtheit, und diese ist in der Regel nicht konkret vorgegeben. Man kann lediglich anhand der Stichprobe \u00fcberpr\u00fcfen, ob gewisse Argumente f\u00fcr oder gegen die Normalverteilung sprechen. \u2022 Histogramm. Dieses informiert auf einen Blick, ob die Daten der Stichprobe symmetrisch oder eher schief verteilt sind. \u2022 Mittelwert und Median. Falls diese beiden Parameter stark voneinander abweichen, spricht dies f\u00fcr eine schiefe Verteilung. \u2022 Schiefe und Kurtosis. Beide Parameter m\u00fcssten \u2013 falls die Daten normalverteilt sind \u2013 Werte um 0 annehmen. \u2022 Anpassungstest. Hin und wieder wird empfohlen, \u201ezur Sicher heit\u201c die Normalverteilung mit einem Anpassungstest zu \u00fcberpr\u00fcfen. Der Nutzen dieses Vorgehens ist jedoch zweifelhaft. Wenn die mit einem Anpassungstest ermittelte Pr\u00fcfgr\u00f6\u00dfe in den Annahmebereich f\u00e4llt, ist damit die Normalverteilung keineswegs abgesichert, sondern lediglich nicht ausgeschlossen. Insbesondere bei kleinen Stichproben kann der \u03b2-Fehler so gro\u00df sein, dass ein solches Ergebnis als Best\u00e4tigung f\u00fcr die Normalverteilung h\u00f6chst unzuverl\u00e4ssig ist.\n11\nGl\u00fccklicherweise ist der t-Test jedoch robust (also unempfindlich) gegen\u00fcber Abweichungen von der Normalverteilung. Dies bedeutet: Trotz geringf\u00fcgiger Verletzungen seiner Voraussetzungen bleiben die Wahrscheinlichkeiten f\u00fcr Fehlentscheidungen (also der \u03b1-Fehler und der \u03b2-Fehler) nahezu konstant. Folgendes ist zu beachten: \u2022 t-Test f\u00fcr eine Stichprobe. Bei Stichproben des Umfangs n \u2265 10 gen\u00fcgt es, wenn die Daten ann\u00e4hernd symmetrisch verteilt sind. F\u00fcr n \u2265 25 kann man davon ausgehen, dass die Stichprobenmittelwerte nach dem zentralen Grenzwertsatz normalverteilt sind (auch wenn die Messwerte anders verteilt sind). Bei kleineren Stichproben sollte man allerdings, wenn keine Normalverteilung vorliegt, auf einen anderen Lagetest ausweichen \u2013 etwa auf den Wilcoxon-Test f\u00fcr eine \u203a Abschnitt 11.2.1) oder den Vorzeichentest (z \u203a AbStichprobe (z schnitt 11.3.1).\n213\n11\n11.1 t-Tests\n\u2022 t-Test f\u00fcr zwei verbundene Stichproben. F\u00fcr n \u2265 10 ist es ausrei chend, wenn die Differenzen d i ann\u00e4hernd symmetrisch verteilt sind. Diese Voraussetzung ist bereits erf\u00fcllt, wenn die Variablen X und Y ungef\u00e4hr die gleiche Verteilungsform haben. Asymmetrien werden durch die Bildung der Differenzen ausgeglichen. \u2022 t-Test f\u00fcr zwei unverbundene Stichproben. Dieser Test zum Ver gleich zweier Erwartungswerte ist au\u00dferordentlich beliebt, obwohl seine Voraussetzungen formal sehr streng sind. Manche Anwender umgehen dieses Problem, indem sie die einschr\u00e4nkenden Pr\u00e4missen schlicht missachten. Andere treffen umfangreiche Vorarbeiten, ehe sie den t-Test durchf\u00fchren, indem sie mit zwei \u201eVortests\u201c die Voraussetzungen (Gleichheit der Varianzen und Normalverteilung) \u00fcberpr\u00fcfen. Dass mit einem Anpassungstest die Normalverteilung nicht nachzuweisen ist, wurde bereits oben erw\u00e4hnt. \u00c4hnlich verh\u00e4lt es sich mit dem F-Test, der \u00fcblicherweise zur Pr\u00fcfung der Gleichheit zweier Varianzen herangezogen wird (dieser Test ist benannt nach Sir Ronald Fisher und basiert auf der in Abschnitt 8.5.3 genannten F-Verteilung). Bei einem kleinen Stichprobenumfang bedeutet die Beibehaltung der Nullhypothese mitnichten, dass die Varianzen \u00fcbereinstimmen. Andererseits wird ein hoher Stichprobenumfang fast immer zur Ablehnung der Nullhypothese f\u00fchren, da sich damit auch geringe Abweichungen der beiden Varianzen nachweisen lassen. Man sollte bei diesem t-Test darauf achten, dass\n\u0177 beide Stichprobenumf\u00e4nge mindestens 10 (bei nicht symmetrischen Verteilungen 20) betragen und \u00e4hnlich gro\u00df sind, und\n\u0177 die Zufallsvariablen X und Y ungef\u00e4hr denselben Verteilungstyp haben. Dies l\u00e4sst sich \u00fcber die empirischen Kenngr\u00f6\u00dfen oder eine graphische Darstellung \u00fcberpr\u00fcfen. Bei ungeplanten, wahllos durchgef\u00fchrten Datensammlungen mag dies schwierig sein \u2013 ein sorgf\u00e4ltiges Studiendesign kann jedoch Einiges dazu beitragen, dass diese Voraussetzungen erf\u00fcllt sind. Merke Um einen Unterschied mit einem t-Test abzusichern, sind g\u00fcnstig: \u0177 Ein hoher Stichprobenumfang, \u0177 ein gro\u00dfer Unterschied zwischen den Mittelwerten, \u0177 eine geringe Streuung der Daten. Dies geht aus den Berechnungen der Pr\u00fcfgr\u00f6\u00dfen hervor (Formeln 10.1, 11.1, 11.2 und 11.6). Je gr\u00f6\u00dfer der Betrag von t, umso eher wird die Alternativhypothese angenommen.\n214\nKapitel 11 \u00b7 Lagetests\nWas sollte man tun, wenn die Voraussetzungen nicht erf\u00fcllt sind? Hier bieten sich zwei M\u00f6glichkeiten an:\n\u0177 Man kann versuchen, nicht normalverteilte Daten in geeigneter\n\u203a Abschnitt 8.2.4). Wenn man rechtsWeise zu transformieren (z schiefe Daten logarithmiert, ist dies oft doppelt hilfreich: Die logarithmierten Daten sind eher normalverteilt und die Varianzen eher ann\u00e4hernd gleich. \u0177 Man kann auf einen Test mit schw\u00e4cheren Voraussetzungen aus\u203a Abschnitt 11.2.3). weichen (z. B. einen Rangsummentest, z 11.1.6 Andere Anwendungen des t-Tests Der t-Test ist keineswegs nur als Lagetest einsetzbar. Um zu testen, ob sich ein empirischer Korrelationskoeffizient nach Pearson signifikant von 0 unterscheidet, berechnet man folgende Pr\u00fcfgr\u00f6\u00dfe: t=\n11\nr 1\u2212 r2 n\u22122\n(11.8)\nDieses t hat n \u2212 2 Freiheitsgrade. Falls t > tn \u22122;1\u2212\u03b1 (bzw. t < \u2212tn \u2212 2;1\u2212\u03b1 ), entscheidet man sich f\u00fcr die Alternativhypothese. In diesen F\u00e4llen wird man in der Regel einseitig testen, da die Richtung eines Zusammenhangs (gleich- oder gegensinnig) vorab bekannt sein d\u00fcrfte. Dar\u00fcber hinaus ist es sinnvoll, ein Konfidenzintervall f\u00fcr ein empi\u203a Abschnitt 9.3.4). risch ermitteltes r anzugeben (z Aus Gleichung (11.8) geht hervor: Je gr\u00f6\u00dfer der Betrag des empirischen Korrelationskoeffizienten r und je gr\u00f6\u00dfer der Stichprobenumfang n, desto gr\u00f6\u00dfer ist der Betrag der Pr\u00fcfgr\u00f6\u00dfe t und desto eher wird die Alternativhypothese angenommen. Das nach (11.8) berechnete t dient \u00fcbrigens gleichzeitig zur \u00dcberpr\u00fcfung des Steigungskoeffizienten der Regressionsgeraden. Sowohl f\u00fcr r als auch f\u00fcr die Parameter der Regressionsgeraden lassen sich Konfidenzintervalle berechnen. Die Voraussetzungen \u203a Abschnitt 9.3.4). daf\u00fcr sind formal recht streng (z Der t-Test hat also mehrere Anwendungsm\u00f6glichkeiten und dabei einschr\u00e4nkende Voraussetzungen. Gl\u00fccklicherweise sind t-Tests robust: Mit Monte-Carlo-Studien wurde nachgewiesen, dass geringf\u00fcgige Verletzungen der Pr\u00e4missen (insbesondere der Normalverteilung) tolerierbar sind.\n215\n11\n11.2 Rangsummentests\n11.2\nRangsummentests\nDiese Tests werden alternativ zu den t-Lagetests verwendet. Sie haben weniger strenge Voraussetzungen: Es handelt sich um verteilungsfreie (oder nicht-parametrische) Tests, die keine bestimmte Verteilungsform voraussetzen. Die Pr\u00fcfgr\u00f6\u00dfen werden nicht aus den Original-Messwerten, sondern aus deren Rangzahlen berechnet. Daher lassen sich diese Tests unter Umst\u00e4nden auch f\u00fcr ordinal-skalierte Merkmale verwenden. Sie basieren auf einer Methode des Mathematikers Frank Wilcoxon (1892-1965). 11.2.1 Der Wilcoxon-Test f\u00fcr eine Stichprobe Dieser Test \u00fcberpr\u00fcft, ob und in welchem Ma\u00df die Werte einer ~ abweichen. Die Stichprobe von einem vorgegebenen Sollwert \u00b5 0 Nullhypothese lautet: H0 :\n~=\u00b5 ~ \u00b5 0\n~ der Median der Grundgesamtheit, zu der die Stichprobe Dabei ist \u00b5 geh\u00f6rt. Die Testdurchf\u00fchrung l\u00e4sst sich wie folgt beschreiben:\n\u0177 Zun\u00e4chst wird f\u00fcr jeden Stichprobenwert die Differenz zum Sollwert berechnet.\n\u0177 Stichprobenwerte, die mit dem Sollwert \u00fcbereinstimmen, wer\u0177\n\u0177 \u0177 \u0177 \u0177\nden eliminiert. Dadurch verringert sich eventuell der Stichprobenumfang. Die Differenzen werden nun nach der Gr\u00f6\u00dfe ihres Betrags in aufsteigender Reihenfolge sortiert und mit Rangzahlen versehen. Die betragsm\u00e4\u00dfig kleinste Differenz erh\u00e4lt die Rangzahl 1, die gr\u00f6\u00dfte die Rangzahl n. Wenn zwei oder mehr identische Differenzbetr\u00e4ge auftreten, \u203a Beiordnet man jeder Differenz eine mittlere Rangzahl zu (z spiel 11.3). Man spricht dabei von verbundenen R\u00e4ngen. Dann werden die Rangzahlen der negativen Differenzen und die Rangzahlen der positiven Differenzen aufaddiert. Diese beiden Rangsummen bezeichnet man mit R \u2212 bzw. R + . Die Pr\u00fcfgr\u00f6\u00dfe R ist die kleinere der beiden Rangsummen. \u203a Anhang) findet man kritische Werte in Abh\u00e4nIn Tabelle C (z gigkeit vom Stichprobenumfang n und der Irrtumswahrscheinlichkeit \u03b1. Die Nullhypothese wird abgelehnt, falls die Pr\u00fcfgr\u00f6\u00dfe gleich oder kleiner ist als der kritische Wert.\n216\nKapitel 11 \u00b7 Lagetests\nF\u00fcr Stichprobenumf\u00e4nge mit n > 25 ist die Pr\u00fcfgr\u00f6\u00dfe approximativ normalverteilt mit dem Erwartungswert n(n + 1) / 4 und der Varianz n(n + 1)(2n + 1) / 24 . Durch Transformation der Pr\u00fcfgr\u00f6\u00dfe in den Wert der Standardnormalverteilung l\u00e4sst sich absch\u00e4tzen, ob das Ergebnis signifikant ist. Bei der zweiseitigen Fragestellung betr\u00e4gt der \u203a Anhang, Tabelle A). kritische Wert 1,96 (f\u00fcr \u03b1 = 0,05 , z Der Wertebereich der Pr\u00fcfgr\u00f6\u00dfe R erstreckt sich zwischen 0 und n(n + 1) / 4 . Der Extremfall 0 besagt, dass sich die beiden Rangsummen maximal unterscheiden. Alle Stichprobenwerte sind dann kleiner (oder alle gr\u00f6\u00dfer) als der Sollwert. Unter der Nullhypothese erwartet man dagegen gleiche Rangsummen der Gr\u00f6\u00dfe n(n + 1) / 4 . Bei diesem Test weisen also (anders als beim t-Test) kleine Pr\u00fcfgr\u00f6\u00dfen auf gro\u00dfe Unterschiede hin. \u2022 Zu den Voraussetzungen. Dieser Test setzt zwar keine Normal verteilung voraus, wohl aber eine symmetrische Verteilung. Falls diese Voraussetzung grob verletzt ist, stellt der Vorzeichentest f\u00fcr \u203a Abschnitt 11.3.1). eine Stichprobe eine Alternative dar (z 11.2.2 Der Wilcoxon-Test f\u00fcr zwei verbundene Stichproben Dieser Test ist das Pendant zum t-Test f\u00fcr zwei verbundene Stichproben mit jeweils dem Umfang n. Es werden die beiden Mediane verglichen; die Nullhypothese lautet:\n11\n~ =\u00b5 ~ H0 : \u00b5 1 2\nDas Testverfahren funktioniert \u00e4hnlich wie beim 1-Stichprobentest:\n\u0177 F\u00fcr jedes Merkmalspaar werden aus den beiden Stichprobenwer\u0177 \u0177 \u0177 \u0177\nten die Differenzen d i = x i \u2212 y i gebildet. Der Test verlangt, dass diese Differenzen symmetrisch verteilt sind. Differenzen, die gleich 0 sind, werden eliminiert. Die Werte d i werden nach der Gr\u00f6\u00dfe ihres Betrags in aufsteigender Reihenfolge sortiert und mit Rangnummern versehen. Dann addiert man separat die Rangzahlen der positiven und die Rangzahlen der negativen Differenzen. Die kleinere Summe ist die Pr\u00fcfgr\u00f6\u00dfe. Die kritischen Werte fin\u203a Anhang); f\u00fcr n > 25 ist die Pr\u00fcfgr\u00f6\u00dfe det man in Tabelle C (z normalverteilt mit dem Erwartungswert n(n + 1) / 4 und der Varianz n(n + 1)(2n + 1) / 24 .\n11\n217 11.2 Rangsummentests\nWie beim Wilcoxon-Test f\u00fcr eine Stichprobe, schwankt auch dieses R zwischen 0 und n( n + 1) / 4 . R = n(n + 1) / 4 entsteht, wenn sich die R\u00e4nge vollkommen gleichm\u00e4\u00dfig zwischen den beiden Stichproben aufteilen. R = 0 bedeutet, dass jeder Wert der einen Stichprobe kleiner ist als jeder beliebige Wert der anderen Stichprobe. Beispiel 11.3 Zehn Personen nehmen sechs Monate lang eine Di\u00e4t zu sich. Die Werte bez\u00fcglich des K\u00f6rpergewichts vor und nach der Di\u00e4t sind in der folgenden Tabelle wiedergegeben. Mit dem Wilcoxon-Test f\u00fcr zwei verbundene Stichproben soll \u00fcberpr\u00fcft werden, ob sich das durchschnittliche Gewicht ge\u00e4ndert hat. Die Gewichte vor und nach der Di\u00e4t der i-ten Beobachtungseinheit seien xi bzw. yi (in kg). Rangzahlen Rangzahlen xi yi d i = xi \u2212 y i i f\u00fcr d i > 0 f\u00fcr d i < 0 1 2 3 4 5 6 7 8 9 10\n92,7 86,2 102,1 85,9 96,3 90,2 87,5 98,0 89,9 110,2\n85,8 83,4 98,3 83,6 91,1 92,7 88,6 98,7 87,1 102,9\n6,9 2,8 3,8 2,3 5,2 -2,5 -1,1 -0,7 2,8 7,3\n9 5,5 7 3 8 4 2 1 5,5 10\nR + = 48 R\u2212 = 7 + \u2212 Zur Rechenkontrolle bildet man die Summe aus R und R ; sie ergibt 55. Dies stimmt \u00fcberein mit der Summe der Zahlen 1 bis 10 (die sich allgemein als n(n + 1) / 2 berechnet). Weil die Differenzbetr\u00e4ge der Beobachtungseinheiten 2 und 9 \u00fcbereinstimmen, werden verbundene R\u00e4nge zugewiesen. Die Pr\u00fcfgr\u00f6\u00dfe ist R = 7 . F\u00fcr \u03b1 = 5% und n = 10 ermittelt man als kritischen Punkt \u203a Tabelle C). Da R kleiner ist als (bei zweiseitiger Fragestellung) den Wert 8 (z 8, wird die Alternativhypothese angenommen.\n\u2022 Zu den Voraussetzungen. Diese sind bei vielen praktischen An wendungen ann\u00e4hernd erf\u00fcllt. Bei zwei verbundenen Stichproben kann man n\u00e4mlich oft davon ausgehen, dass die Zufallsvariablen X und Y ann\u00e4hernd die gleiche Verteilungsform aufweisen. Dann sind auch die Differenzen d i symmetrisch verteilt. Falls mehrere Differenzen in ihrem Betrag \u00fcbereinstimmen, bildet man (wie oben beschrieben) verbundene R\u00e4nge.\n218\nKapitel 11 \u00b7 Lagetests\n11.2.3 Der U-Test von Mann und Whitney Dieser Test stellt eine Alternative zum t-Test f\u00fcr zwei unverbundene Stichproben dar. Dabei werden zwei Mediane miteinander vergli~ =\u00b5 ~ . Die Stichprobenumchen; die Nullhypothese lautet: H 0 : \u00b5 1 2 f\u00e4nge seien n1 und n2 ; diese m\u00fcssen nicht identisch sein. Der U-Test verlangt Zufallsvariable X und Y, die etwa die gleiche Verteilungsform haben. Symmetrie oder gar Normalverteilung werden nicht vorausgesetzt. Insofern basiert dieser Test auf wesentlich schw\u00e4cheren Voraussetzungen als der t-Test. Er wird folgenderma\u00dfen durchgef\u00fchrt:\n\u0177 Alle Werte aus beiden Stichproben werden in aufsteigender Reihenfolge sortiert und mit Rangzahlen versehen.\n\u0177 Danach addiert man f\u00fcr jede der beiden Stichproben die entsprechenden Rangzahlen und bezeichnet die Summen als R1 bzw. R2 . Daraus berechnet man: n1 (n1 + 1) \u2212 R1 2 n (n + 1) U 2 = n1 \u22c5 n2 + 2 2 \u2212 R2 2\nU 1 = n1 \u22c5 n2 +\n(11.9)\n\u0177 Es l\u00e4sst sich nachweisen, dass gilt: U1 + U 2 = n1 \u22c5 n2 . \u0177 Die Testgr\u00f6\u00dfe wird berechnet als U = min(U1 ,U 2 ) . \u0177 Wenn U kleiner ist als der kritische Wert oder gleich diesem (z\u203a Tabelle D, Anhang), wird die Nullhypothese abgelehnt.\n11\nF\u00fcr gr\u00f6\u00dfere Stichproben (mindestens 10 pro Gruppe) ist die Pr\u00fcfgr\u00f6\u00dfe normalverteilt mit dem Erwartungswert n1 ( n1 + n2 + 1) / 2 und der Varianz n1 n2 / 6 (wobei n1 den kleineren Umfang bezeichnet). Die Pr\u00fcfgr\u00f6\u00dfe U erstreckt sich zwischen 0 und n1 \u22c5 n2 / 2 . Je n\u00e4her U bei 0 liegt, umso mehr unterscheiden sich die beiden Stichproben und umso eher wird die Alternativhypothese angenommen. Verbundene R\u00e4nge sind unproblematisch, wenn sie innerhalb einer Stichprobe auftreten. Die Anzahl der verbundenen R\u00e4nge, die beide Stichproben betreffen, sollte ein gewisses Ma\u00df (h\u00f6chstens 20 %) nicht \u00fcberschreiten. Sie lassen sich bei einer hohen Messgenauigkeit vermeiden. i In manchen Publikationen wird dieser Test \u201eWilcoxon-test for 2 samples\u201c z genannt. Wilcoxon und die Statistiker Mann und Whitney haben ihre Tests nahezu zeitgleich ver\u00f6ffentlicht. Formal handelt es sich um dasselbe Verfahren.\n11\n219 11.2 Rangsummentests\nBeispiel 11.4 Es soll nachgewiesen werden, dass m\u00e4nnliche Studenten im Durchschnitt ein h\u00f6heres K\u00f6rpergewicht haben als weibliche. Dazu werden 10 Studenten und 12 Studentinnen aus dem in Tabelle 2.1 auflisteten Personenkreis zuf\u00e4llig ausgew\u00e4hlt. Da man beim Merkmal \u201eK\u00f6rpergewicht\u201c nicht unbedingt von einer Normalverteilung ausgehen kann, benutzt man den U-Test. Die Werte und R\u00e4nge der Daten sind in der folgenden Tabelle aufgelistet: Stichprobe 1 (M\u00e4nner, n1 = 10 ) Stichprobe 2 (Frauen, n2 = 12 ) Gewicht xi\nRang\nGewicht y j\n61 69 70 72 75 79 82 84 85 90\n8 11 12,5 14 16 18 19 20 21 22\n48 52 55 57 58 60 60 63 65 70 74 77\nR1 = 161,5\nRang 1 2 3 4 5 6,5 6,5 9 10 12,5 15 17 R2 = 91,5\nMit (11.9) ergibt sich: U1 = 13,5 und U 2 = 106,5 . Also ist U = 13,5 . Aus Tabelle D entnimmt man f\u00fcr den kritischen Wert 29 (zweiseitiger Test, \u03b1 = 5% ). Da die Pr\u00fcfgr\u00f6\u00dfe wesentlich kleiner ist, ist der Unterschied abgesichert. Der p-Wert betr\u00e4gt 0,0024. Wenn man mit denselben Daten einen t-Test durchf\u00fchrt, ergibt sich ein kleineres p von 0,0007.\n11.2.4 Vergleich zwischen Rangsummentests und t-Tests Die Rangsummentests haben schw\u00e4chere Voraussetzungen als die tTests und damit ein breiteres Anwendungsspektrum. Die R\u00e4nge haben n\u00e4mlich die g\u00fcnstige Eigenschaft, dass sie von Datenmanipulationen unber\u00fchrt bleiben, solange dabei die Reihenfolge der Daten nicht ver\u00e4ndert wird. Deshalb eignen sich auch Daten, die nur als Prozentangaben vorliegen, f\u00fcr Rangsummentests. Unter Umst\u00e4nden k\u00f6nnen derlei Tests auch f\u00fcr metrisch-diskrete und f\u00fcr ordinal-skalierte Merkmale verwendet werden.\n220\nKapitel 11 \u00b7 Lagetests\nMathematische Herleitung der Pr\u00fcfgr\u00f6\u00dfe U Zun\u00e4chst berechnen wir die Summe der Pr\u00fcfgr\u00f6\u00dfen. Aus (11.9) folgt: n (n + 1) + n2 (n2 + 1) U1 + U 2 = 2n1n2 + 1 1 \u2212 ( R1 + R2 ) 2 Da die Summe der Rangzahlen R1 und R2 der Summe aller Zahlen von 1 bis (n1 + n2 )(n1 + n2 + 1) . Wenn man diesen 2 Ausdruck in die obige Formel einsetzt, erh\u00e4lt man U1 + U 2 = n1 \u22c5 n2 .\nn1 + n2 entspricht, gilt: R1 + R2 =\nWelche Werte k\u00f6nnen U 1 und U 2 annehmen? Wir gehen zun\u00e4chst von folgendem Extremfall aus: Jedes Element xi der 1. Stichprobe ist kleiner als jedes beliebige Element y j der 2. Stichprobe. In diesem Fall unterscheiden sich die beiden Stichproben maximal. Dann haben die xi die R\u00e4nge 1 bis n1 und die y j die R\u00e4nge n1 + 1 bis n1 + n2 . Es gilt also: R1 = n1 \u22c5 (n1 + 1) / 2 und damit nach (11.9): U1 = n1 \u22c5 n2 , U 2 = 0 und U = min(U1 ,U 2 ) = 0 . Wenn die R\u00e4nge in den beiden Stichproben gleich verteilt sind, verhalten sich die Rangsummen wie die Stichprobenumf\u00e4nge, also n1 / n2 = R1 / R2 . In diesem Fall ist U = U1 = U 2 = n1 \u22c5 n2 / 2 .\nAllerdings sollte man nicht vollkommen bedenkenlos einen Rangsummentest gegen\u00fcber einem t-Test bevorzugen. t-Tests sind au\u00dferordentlich beliebt, und zwar aus mehreren Gr\u00fcnden:\n\u0177 Ein Rangsummentest wertet nur die Reihenfolge der Daten aus. Dies ist nicht f\u00fcr alle Fragestellungen sinnvoll.\n\u0177 Der t-Test nutzt dagegen die in den Daten enthaltenen Infor-\n11\nmationen vollst\u00e4ndig aus.\n\u0177 Mittels der t-Verteilung lassen sich nicht nur p-Werte ermitteln, sondern auch Konfidenzintervalle berechnen. Diese sind sehr hilfreich, um die Gr\u00f6\u00dfe eines Unterschiedes zu beurteilen. Bei den Rangsummentests ist die Berechnung dieser Konfidenzintervalle nicht m\u00f6glich. Grunds\u00e4tzlich gilt: Wenn Scores mit \u00e4quidistanten Werten 0, 1, 2 etc. zu analysieren sind, eignet sich ein Rangsummentest besser als ein t-Test. Wenn dagegen bei Messwerten berechtigter Grund zur Annahme besteht, dass die Daten einer Normalverteilung entstammen, sollte man den t-Test bevorzugen. Zwar sind auch Rangsummentests bei normalverteilten Daten durchaus legitim. Das Problem ist folgendes: Wenn man einen Rangsummentest verwendet (obwohl die Voraussetzungen des tTests erf\u00fcllt sind), bedeutet dies eine Verminderung der Power 1 \u2212 \u03b2 . So kann es vorkommen, dass man mit dem t-Test ein statis-\n221\n11\n11.2 Rangsummentests\ntisch signifikantes Ergebnis erh\u00e4lt, w\u00e4hrend der entsprechende Rangsummentest mit denselben Daten zur Beibehaltung der Nullhypothese f\u00fchrt. Dies ist h\u00f6chst \u00e4rgerlich f\u00fcr einen Forscher, der ja in der Regel etwas Neues etablieren und deshalb die Alternativhypothese absichern will. Einen Test, der zur Beibehaltung der Nullhypothese tendiert, nennt man konservativ. Wenn man dagegen einen Test anwendet, obwohl seine Voraussetzungen nicht erf\u00fcllt sind, nimmt man eventuell eine Erh\u00f6hung des \u03b1-Fehlers in Kauf. Das bedeutet: Der Test l\u00e4sst mehr Ergebnisse signifikant werden als dem festgelegten \u03b1-Niveau entspricht. Ein solches Testverhalten hei\u00dft progressiv. Ein signifikantes Ergebnis ist zwar meist erw\u00fcnscht \u2013 es k\u00f6nnte aber peinlich werden, wenn sich herausstellt, dass der vermeintliche Unterschied mit einer wissenschaftlich unsauberen Methode gewaltsam herbeigef\u00fchrt wurde. Die Auswahl eines geeigneten Tests muss also sehr differenziert erfolgen. Hierzu einige Anmerkungen: \u2022 1-Stichproben-Tests. Sie sind generell mit Vorsicht zu handha ben. Perfekt symmetrische Verteilungen (oder gar Normalverteilungen) gibt es in der Natur eigentlich nicht. Bei einem Stichprobenumfang von weniger als 10 sollte man \u2013 wenn man sich der Normalverteilung nicht sicher ist \u2013 den Wilcoxon-Test bevorzugen. F\u00fcr nicht symmetrische Verteilungen bietet sich der Vorzeichentest an \u203a Abschnitt 11.3.1). (z \u2022 Tests f\u00fcr zwei verbundene Stichproben. Beim Wilcoxon-Test m\u00fcssen nur die Differenzen symmetrisch verteilt sind. Diese Einschr\u00e4nkung ist nicht allzu stark. Bei sorgf\u00e4ltig geplanten Studien kann man zugrunde legen, dass die beiden Verteilungen bez\u00fcglich ihrer Form \u00e4hnlich sind. Dann sind auch die Differenzen symmetrisch. Falls der Stichprobenumfang 10 \u00fcbersteigt, kann man den tTest benutzen \u2013 er ist dann robust gegen\u00fcber Verletzungen seiner Voraussetzungen. F\u00fcr nicht symmetrische Verteilungen empfiehlt \u203a Abschnitt 11.3.2). sich auch hier der Vorzeichentest (z \u2022 Tests f\u00fcr zwei unverbundene Stichproben. Die Bedingungen des U-Tests sind im Vergleich zu denen des t-Tests schwach. \u00dcber den speziellen Verteilungstyp werden beim U-Test keine Angaben gemacht, w\u00e4hrend der t-Test Normalverteilung voraussetzt. Deshalb bietet der U-Test eine sinnvolle Alternative, wenn die Pr\u00e4missen des t-Tests nicht erf\u00fcllt sind. Ein weiterer Test f\u00fcr zwei unverbundene \u203a Abschnitt 12.2.2). Stichproben ist der Median-Test (z\n222\nKapitel 11 \u00b7 Lagetests\n11.3\nVorzeichentests\n11.3.1 Der Vorzeichentest f\u00fcr eine Stichprobe Die Nullhypothese ist dieselbe wie beim Wilcoxon-Test: Es wird untersucht, ob der Median einer Stichprobe mit einem vorgegebenen Sollwert vereinbar ist. Das Testverfahren ist einfach:\n\u0177 Man beurteilt jeden Stichprobenwert danach, ob er gr\u00f6\u00dfer oder kleiner als der Sollwert ist und ordnet ihm dementsprechend ein positives oder ein negatives Vorzeichen zu. \u0177 Werte, die mit dem Sollwert identisch sind, werden eliminiert. \u0177 Man z\u00e4hlt die Anzahl der positiven und der negativen Vorzeichen; die kleinere Zahl ist die Pr\u00fcfgr\u00f6\u00dfe k. Falls die Nullhypothese zutrifft, erwartet man, dass die Anzahl der positiven und die der negativen Vorzeichen \u00fcbereinstimmen. \u0177 Die Testentscheidung trifft man nach einem Vergleich mit dem kritischen Wert in Tabelle F im Anhang.\n11\nDie Bezeichnung Vorzeichentest ist darauf zur\u00fcckzuf\u00fchren, dass in die Berechnung der Pr\u00fcfgr\u00f6\u00dfe nur die Vorzeichen der Differenzen einflie\u00dfen. Es wird also nur die Richtung der Abweichungen vom Sollwert (nicht deren Betrag oder Rang wie beim t- bzw. WilcoxonTest) ber\u00fccksichtigt. Daher ist dieser Test auch bei ordinal skalierten Merkmalen anwendbar. Die Pr\u00fcfgr\u00f6\u00dfe ist unter der Nullhypothese binomialverteilt mit dem Erwartungswert n \u22c5 0,5 . Schranken f\u00fcr den Annahmebereich findet man in Tabelle F. Notfalls kann man mit einem Taschenrechner bei einem kleinen Stichprobenumfang den Annahmebereich ermitteln, indem man nach (7.20) die einzelnen Wahrscheinlichkeiten\n\u00a7n\u00b7 P( X = k ) = \u00a8\u00a8 \u00b8\u00b8 \u22c5 0,5 n \u00a9k \u00b9 berechnet und damit einen Annahmebereich f\u00fcr die Pr\u00fcfgr\u00f6\u00dfe k (also die Anzahl der positiven oder negativen Vorzeichen) konstruiert. Bei gr\u00f6\u00dferen Stichprobenumf\u00e4ngen ( n \u2265 36 ) l\u00e4sst sich die Binomialverteilung durch eine Normalverteilung mit dem Erwartungswert n \u22c5 0,5 und der Varianz n \u22c5 0, 25 approximieren. Die Schranken f\u00fcr den Annahmebereich sind dann: 0,5 \u22c5 n \u00b1 (1,96 \u22c5 0,25 \u22c5 n + 0,5)\n223\n11\n11.3 Vorzeichentests\n11.3.2 Der Vorzeichentest f\u00fcr zwei verbundene Stichproben Mit diesem Test werden Vergleiche einfachster Art durchgef\u00fchrt. Es wird lediglich vorausgesetzt, dass die Zufallsvariablen der beiden Stichproben in irgendeiner Weise vergleichbar sind (etwa: Der Zustand nach der Therapie ist besser als vor der Therapie) \u2013 ohne dass die Differenz exakt quantifiziert werden m\u00fcsste. Jedem Beobachtungspaar kann dann ein positives oder ein negatives Vorzeichen zugeordnet werden. Die Nullhypothese lautet: P ( X < Y ) = P( X > Y ) = 0,5\nUnter der Nullhypothese m\u00fcssten etwa gleich viele Beobachtungspaare ein negatives bzw. ein positives Vorzeichen erhalten. Das Testverfahren ist \u00e4hnlich wie beim Vorzeichentest f\u00fcr eine Stichprobe:\n\u0177 Man ordnet jedem Beobachtungspaar das passende Vorzeichen zu. Paare, deren Stichprobenwerte sich nicht unterscheiden, werden nicht ber\u00fccksichtigt. \u0177 Man z\u00e4hlt die Anzahl der positiven und der negativen Vorzeichen. Die kleinere Zahl ist die Pr\u00fcfgr\u00f6\u00dfe. \u0177 Die Testentscheidung trifft man nach einem Vergleich mit den kritischen Werten in Tabelle F. Beispiel 11.5 In den Beispielen 11.1 und 11.3 wurde das K\u00f6rpergewicht von n = 10 Personen vor und nach einer Di\u00e4t miteinander verglichen. Mit dem t-Test und dem Wilcoxon-Test f\u00fcr zwei verbundene Stichproben ergaben sich signifikante Testergebnisse. Wenn wir den Vorzeichentest anwenden, findet man mit Hilfe der Tabelle F als Annahmebereich das Intervall zwischen den Zahlen 2 und 8. Die Pr\u00fcfgr\u00f6\u00dfe k = 3 (es gibt 3 negative und 7 positive Vorzeichen bei den Differenzen) liegt also innerhalb des Annahmebereichs; demnach muss die Nullhypothese beibehalten werden.\n11.3.3 Vergleich mit anderen Lagetests Ein Vorzeichentest beinhaltet quasi keine Voraussetzungen. Allerdings nutzt er bei weitem nicht alle Informationen der Stichprobendaten aus. Aus diesem Grund hat der Vorzeichentest eine wesentlich geringere Power als der entsprechende t-Test oder Rangsummentest. Wegen seiner Rechen\u00f6konomie findet er h\u00e4ufig als \u201eSchnelltest\u201c Verwendung. Ein Wissenschaftler, dem es ja meist darum geht, die Alternativhypothese abzusichern, sollte den Vorzeichentest meiden\n224\nKapitel 11 \u00b7 Lagetests\nund statt dessen \u2013 sofern die Voraussetzungen erf\u00fcllt sind \u2013 den passenden t-Test oder Wilcoxon-Test anwenden. i Ein Vorzeichentest basiert auf der Analyse von H\u00e4ufigkeiten. Formal z handelt es sich dabei um einen Binomialtest, mit dem getestet wird, ob eine relative H\u00e4ufigkeit mit der Wahrscheinlichkeit p = 0,5 vereinbar ist \u203a Abschnitt 12.1). (z ! Als Lagetest f\u00fcr zwei unverbundene Stichproben eignet sich auch der auf z \u203a Abschnitt 12.2.2). der Chi2-Verteilung basierende Median-Test (z\n11.4\nAusblick auf komplexere Methoden\n11.4.1 Mehrstichprobentests Die t-Lagetests und die Rangsummentests sind auf eine oder zwei Stichproben beschr\u00e4nkt. In der medizinischen Forschung stellt sich hin und wieder das Problem, dass mehr als zwei Stichproben zu vergleichen sind (etwa wenn bei einer Therapiestudie zwei unterschiedliche Dosen eines Medikaments mit einem Placebo verglichen werden). Um mehr als zwei unverbundene Stichproben bez\u00fcglich einer quantitativen Zielgr\u00f6\u00dfe zu vergleichen, bieten sich an:\n11\n\u2022 1-faktorielle Varianzanalyse. Dies ist eine Erweiterung des t-Tests f\u00fcr mehr als zwei unverbundene Stichproben. Die Varianzanalyse setzt \u2013 ebenso wie der klassische t-Test \u2013 normalverteilte Grundgesamtheiten mit gleichen Varianzen voraus. Die Methode beruht auf dem Vergleich der Varianz der k Mittelwerte x i ( i = 1,..., k ) mit der Varianz der Abst\u00e4nde ( xij \u2212 xi ) (wobei k \u2265 2 die Anzahl der Stichproben bezeichnet). Der Quotient dieser Varianzen folgt einer F\u203a Abschnitt 8.5.3). Er nimmt den Wert 1 an, falls alle Verteilung (z Stichproben aus derselben Grundgesamtheit stammen. Je mehr die Mittelwerte streuen, desto gr\u00f6\u00dfer wird F und desto eher wird die Alternativhypothese angenommen. \u2022 Kruskal-Wallis-Test. Dieser Rangsummentest ist eine Erweite rung des U-Tests f\u00fcr mehr als zwei Stichproben. Diese Verfahren k\u00f6nnen nur globale Unterschiede nachweisen. Ein signifikantes Ergebnis zeigt lediglich an, dass nicht alle Erwartungswerte identisch sind. Aus dem p-Wert geht jedoch nicht hervor, wo die Unterschiede liegen. Freilich k\u00f6nnte man mit t-Tests (nach einer Varianzanalyse) oder U-Tests (nach einem Kruskal-Wallis-Test) beliebig viele 2-Stichproben-Vergleiche durchf\u00fchren. Diese Vergleiche\n225\n11\n11.4 Ausblick auf komplexere Methoden\nsind jedoch nicht ganz unproblematisch, weil es sich dabei um mul\u203a Abschnitt 10.2.6). Dennoch ist der Anwentiples Testen handelt (z der daran interessant, diese Unterschiede herauszufinden und nachzuweisen. Dazu bieten sich folgende M\u00f6glichkeiten an:\n\u0177 Man \u00fcberlegt sich vor der Testdurchf\u00fchrung, welche paarweisen Stichprobenvergleiche interessant sind und beschr\u00e4nkt die Anzahl dieser Vergleiche auf ein Mindestma\u00df. \u0177 Man verwendet die Bonferroni-Korrektur (z\u203a Abschnitt 10.2.6). Der Nachteil dieser Methode liegt darin, dass \u2013 insbesondere dann, wenn zahlreiche Tests durchgef\u00fchrt werden \u2013 die Power gering wird und sich Unterschiede kaum mehr nachweisen lassen. \u0177 F\u00fcr die Varianzanalyse wurden mehrere Verfahren f\u00fcr paarweise Mittelwert-Vergleiche entwickelt. Eine bekannte Methode ist der Scheff\u00e9-Test: Er vergleicht alle Stichproben paarweise miteinander und gew\u00e4hrleistet dabei dennoch, dass bei jedem Vergleich das \u012e-Signifikanzniveau eingehalten wird. Allerdings ist dieses Verfahren eher konservativ. F\u00fcr den Vergleich von mehr als zwei verbundenen Stichproben bez\u00fcglich eines quantitativen Merkmals eignen sich:\n\u2022 Varianzanalyse mit Messwiederholungen. W\u00e4hrend der t-Test f\u00fcr zwei verbundene Stichproben geeignet ist f\u00fcr einen einfachen Vorher-Nachher-Vergleich, k\u00f6nnen mit einer Varianzanalyse mehr als zwei Zeitpunkte verglichen werden. \u2022 Friedman-Test. Dieser Test basiert auf der Analyse von Rangsum men. Er ist eine Verallgemeinerung des Wilcoxon-Tests f\u00fcr mehr als zwei verbundene Stichproben. 11.4.2 Multiple Methoden Bei multiplen Methoden wird der Einfluss mehrerer Einflussgr\u00f6\u00dfen auf eine Zielgr\u00f6\u00dfe simultan untersucht. Diese Verfahren erm\u00f6glichen eine wesentlich effizientere Analyse als einfache Methoden, bei denen nur eine Einflussgr\u00f6\u00dfe ber\u00fccksichtigt wird.\n\u2022 Zwei- oder mehrfaktorielle Varianzanalyse. M\u00f6glicherweise h\u00e4ngt die Zielgr\u00f6\u00dfe nicht nur von einer Gruppierungsvariablen (z. B. der Therapieform), sondern dar\u00fcber hinaus von weiteren qualitativen Faktoren (Geschlecht, Diagnose, Schweregrad der Krankheit\n226\nKapitel 11 \u00b7 Lagetests\netc.) ab. F\u00fcr derlei Fragestellungen eignen sich mehrfaktorielle Varianzanalysen.\n\u2022 Varianzanalyse mit Messwiederholungen. Auch bei diesem Verfahren k\u00f6nnen mehrere Gruppierungs- und Messwiederholungsfaktoren involviert werden. \u2022 Multiple Regressionsanalyse. Diese Methode wird verwendet, wenn die quantitative Zielgr\u00f6\u00dfe von mehreren quantitativen Einflussgr\u00f6\u00dfen bestimmt wird. \u2022 Allgemeines lineares Modell. Damit ist es m\u00f6glich, den Einfluss mehrerer Faktoren, die sowohl quantitativ als auch qualitativ sein k\u00f6nnen, zu untersuchen. Am Ende wird eine lineare Gleichung erstellt, mit der ein Wert f\u00fcr die Zielgr\u00f6\u00dfe in Abh\u00e4ngigkeit der signifikanten Einflussfaktoren gesch\u00e4tzt werden kann. Diese Gleichung hat die Form: y = a0 + a1 x1 + a 2 x2 + ... + ak xk\n(11.10)\nBei diesem Ansatz werden qualitative Merkmale durch so genannte \u203a Beispiel 2.5); Alternativmerkmale lassen Dummy-Variable ersetzt (z sich einfach durch die Ziffern 0 und 1 codieren. Eine leistungsf\u00e4hige Software unterst\u00fctzt den Anwender bei der Wahl der Variablen, die in das Modell aufgenommen werden, und bei der Bestimmung der Regressionskoeffizienten. i Bei allen Varianz- und Regressionsanalysen ist das bereits erw\u00e4hnte z\n11\n\u203a Abschnitt 5.3.3) geeignet, um die G\u00fcte des Modells Bestimmtheitsma\u00df r 2 (z zu quantifizieren. Dieses Ma\u00df ist der prozentuale Anteil der durch das Modell erkl\u00e4rten Varianz bezogen auf die Gesamtvarianz der y-Werte. Je gr\u00f6\u00dfer da Bestimmtheitsma\u00df, desto besser ist das Modell.\nEs sei hinzugef\u00fcgt, dass die technische Anwendung dieser Verfahren mit einer geeigneten Software (z. B. mit SAS) kein nennenswertes Problem darstellt. Dennoch sollte der Anwender dieser Methoden \u00fcber den mathematischen Hintergrund und auch \u00fcber deren Grenzen zumindest in Grundz\u00fcgen Bescheid wissen, um sie sinnvoll anzuwenden und die Ergebnisse interpretieren zu k\u00f6nnen. Wer sich daf\u00fcr interessiert, m\u00f6ge auf geeignete Literatur zur\u00fcckgreifen ([2], [4] oder [10]).\n12\nTests zum Vergleich von H\u00e4ufigkeiten 12.1\nDer Binomialtest f\u00fcr eine Stichprobe 229\n12.2\nChi2-Tests 231\n12.2.1 Der Chi2-Vierfelder-Test 231 12.2.2 Der Median-Test 235 12.2.3 Der Chi2-Test f\u00fcr k \u22c5 A Felder 236 12.2.4 Assoziationsma\u00dfe f\u00fcr qualitative Merkmale 237 12.2.5 Der McNemar-Test 238 12.2.6 Der Chi2-Anpassungstest 240 12.2.7 Der Logranktest 242\n12.3\nDer exakte Test nach Fisher 243\n12.4\nAusblick auf die logistische Regression 245\n229\n12\n12.1 Der Binomialtest f\u00fcr eine Stichprobe\n12.1\nDer Binomialtest f\u00fcr eine Stichprobe\nDie Geschichte dieses Tests begann in den Jahren 1710-1712, als der englische Wissenschaftler John Arbuthnot beim Studium von Kirchenb\u00fcchern feststellte, dass bei 82 Jahrg\u00e4ngen Knabengeburten h\u00e4ufiger eingetragen waren als M\u00e4dchengeburten. Aufgrund des hohen Stichprobenumfangs kam er zu dem Schluss: Das kann kein Zufall sein! Der Binomialtest ist die geeignete Methode, um eine solche Vermutung objektiv zu \u00fcberpr\u00fcfen. Arbuthnot h\u00e4tte dazu folgende Hypothesen aufstellen m\u00fcssen: H0 : H1 :\nDie Wahrscheinlichkeit p f\u00fcr eine Knabengeburt ist gleich der Wahrscheinlichkeit f\u00fcr eine M\u00e4dchengeburt, oder formal: p = 1 / 2 Die Wahrscheinlichkeiten sind unterschiedlich. Es gilt also: p \u2260 1/ 2 .\nEin Binomialtest basiert auf sehr einfachen Annahmen:\n\u0177 Es liegt eine Stichprobe mit n Beobachtungseinheiten vor; \u0177 die Stichprobenwerte sind Auspr\u00e4gungen eines Alternativmerkmals. Der Test \u00fcberpr\u00fcft, ob die relative H\u00e4ufigkeit der Auspr\u00e4gung A mit einer vorgegebenen Wahrscheinlichkeit p0 vereinbar ist. Die Hypothesen lauten also: H0 : H1 :\np = p0 p \u2260 p0\n(bei zweiseitiger Fragestellung)\nZur Testentscheidung gelangt man folgenderma\u00dfen:\n\u0177 Zun\u00e4chst werden in der Stichprobe die Beobachtungseinheiten\nmit der Auspr\u00e4gung A gez\u00e4hlt; deren Anzahl sei X. Die relative H\u00e4ufigkeit p\u02c6 = X / n ist ein Sch\u00e4tzwert f\u00fcr die Wahrscheinlichkeit p der Grundgesamtheit. \u0177 Unter der Nullhypothese ist diese Anzahl X binomialverteilt mit dem Erwartungswert np0 . Mit der Formel (7.16) lassen sich nun die Wahrscheinlichkeiten P ( X = k ) berechnen. Damit l\u00e4sst sich dann ein Bereich konstruieren, in den X bei G\u00fcltigkeit der Nullhypothese mit einer Wahrscheinlichkeit von 1 \u2212 \u03b1 = 95% fallen w\u00fcrde. Bei einem nicht allzu hohen Stichprobenumfang gen\u00fcgt dazu ein Taschenrechner.\n230\nKapitel 12 \u00b7 Tests zum Vergleich von H\u00e4ufigkeiten\nFalls n hinreichend gro\u00df ist mit np0 (1 \u2212 p0 ) \u2265 9 , l\u00e4sst sich die Binomialverteilung von X durch eine Normalverteilung mit dem Erwartungswert np0 und der Varianz np0 (1 \u2212 p0 ) approximieren. Dann ist auch p\u02c6 = X / n normalverteilt mit dem Erwartungswert p0 und der Varianz p0 (1 \u2212 p0 ) / n . Daraus folgt, dass die Pr\u00fcfgr\u00f6\u00dfe Z=\np\u02c6 \u2212 p0 p0 (1 \u2212 p0 ) n\n(12.1)\neiner Standardnormalverteilung folgt. Der kritische Punkt ist 1,96 (f\u00fcr \u03b1 = 5% , zweiseitige Fragestellung). Bei einer anderen Irrtumswahrscheinlichkeit \u012e ist dieser Wert durch z1\u2212\u03b1 / 2 entsprechend anzupassen; bei einseitiger Fragestellung ist er durch \u00b1 z1\u2212\u03b1 zu erset\u203a Tabelle A, Anhang). zen (z Beispiel 12.1 Von n = 71 Studenten sind k = 48 weiblichen Geschlechts. Ist diese H\u00e4ufigkeit vereinbar mit der Hypothese, dass gleich viele M\u00e4nner und Frauen Medizin studieren? Die Nullhypothese lautet: p = 0,5 . Der Sch\u00e4tzwert ist p\u02c6 = 48 / 71 = 0,68 . Da np0 (1 \u2212 p0 ) = 71 \u22c5 0,5 \u22c5 0,5 = 17,75 \u2265 9 , kann man die Binomialverteilung von X durch eine Normalverteilung mit dem Erwartungswert \u00b5 = 71 \u22c5 0,5 = 35,5 und der Varianz 17,75 approximieren. F\u00fcr die Pr\u00fcfgr\u00f6\u00dfe nach (12.1) berechnet man mit p0 = 0,5 : 48 / 71 \u2212 0, 5 z= = 2, 9670 0, 25 / 71\n12\nDieser Wert ist gr\u00f6\u00dfer als 1,96 \u2013 also wird die Alternativhypothese angenommen. Der p-Wert ist 0,0030. W\u00e4hrend dieser p-Wert besagt, dass das Ergebnis \u203a Beispiel 9.2) darsignifikant ist, informiert das Konfidenzintervall f\u00fcr p\u02c6 (z \u00fcber, in welcher Gr\u00f6\u00dfenordnung der Anteil weiblicher Studenten angenommen werden kann.\nDer Binomialtest ist vielseitig anwendbar: Durch Reduktion des Skalenniveaus l\u00e4sst sich n\u00e4mlich jedes Merkmal als ein Alternativmerkmal auffassen.\n231 12.2 Chi2-Tests\n12.2\n12\nChi2-Tests\nChi2-Tests dienen zur Analyse von H\u00e4ufigkeitsunterschieden. Da sich H\u00e4ufigkeiten bei jeder Merkmalsart und jedem Skalenniveau ermitteln lassen, sind diese Tests sehr vielseitig anwendbar. 12.2.1 Der Chi2-Vierfelder-Test Im einfachsten Fall untersucht der Chi2-Test die Unabh\u00e4ngigkeit zweier Alternativmerkmale. Er wird deshalb auch als Chi2-Unabh\u00e4ngigkeitstest bezeichnet. Diesem Test liegt zugrunde\n\u0177 eine Stichprobe des Umfangs n und den H\u00e4ufigkeiten, die sich aus der Betrachtung zweier Alternativmerkmale ergeben. Die Auspr\u00e4gungen der beiden Merkmale seien A und A bzw. B und B . Insgesamt gibt es dann vier Kombinationsm\u00f6glichkeiten mit den H\u00e4ufigkeiten a , b , c und d , die sich anschaulich in einer \u203a Tabelle 12.1). Vierfeldertafel darstellen lassen (z Tabelle 12.1 Vierfeldertafel beim Chi2-Vierfelder-Test\nB B Randsummen\nA a\nA b\nRandsummen n1 = a + b\nc\nd\nn2 = c + d\na+c\nb+d\nn = a+b+c+d\nUnter der Nullhypothese sind die relevanten Ereignisse unabh\u00e4ngig voneinander; deshalb gilt nach dem Multiplikationssatz: H0 :\nP ( A | B ) = P ( A)\nUnter der Nullhypothese m\u00fcsste also ann\u00e4hernd gelten:\na a+c = a+b n\n(12.2)\nDagegen besagt die Alternativhypothese H1 , dass eine Abh\u00e4ngigkeit besteht. Die wesentliche Idee eines Chi2-Tests ist folgende: Die beobachteten H\u00e4ufigkeiten a , b , c und d werden verglichen mit den H\u00e4ufigkeiten, die unter der Nullhypothese zu erwarten sind. Dazu berechnet man f\u00fcr jede H\u00e4ufigkeit den Quotienten\n232\nKapitel 12 \u00b7 Tests zum Vergleich von H\u00e4ufigkeiten\n( beobachtete H\u00e4ufigkeit - erwartete H\u00e4ufigkeit) 2 ( B \u2212 E ) 2 = E erwartete H\u00e4ufigkeit\nDie Summe dieser vier Quotienten bildet die Pr\u00fcfgr\u00f6\u00dfe. Die unter H0 zu erwartende H\u00e4ufigkeit f\u00fcr a ergibt sich aus Formel (12.2) aus den Randsummen (a + b) , (a + c) und n; die anderen Erwartungsh\u00e4ufigkeiten leitet man analog her und erh\u00e4lt die H\u00e4ufigkeiten in Tabelle 12.2. Tabelle 12.2 Beobachtete und erwartete H\u00e4ufigkeiten beim Vierfelder-Test beobachtete H\u00e4ufigkeit B\nunter H0 erwartete H\u00e4ufigkeit E\n( B \u2212 E )2 / E\na\n(a + b)(a + c) / n\n( ad \u2212 bc ) 2 n \u22c5 ( a + b)( a + c)\nb\n(a + b)(b + d ) / n\n(ad \u2212 bc ) 2 n \u22c5 ( a + b)(b + d )\nc\n(c + d )(a + c) / n\n(ad \u2212 bc) 2 n \u22c5 (c + d )(a + c)\nd\n(c + d )(b + d ) / n\n(ad \u2212 bc ) 2 n \u22c5 ( c + d )(b + d )\nn\nn\n\u03c72\nSumme\nDie Pr\u00fcfgr\u00f6\u00dfe ist ann\u00e4hernd \u03c7 2 -verteilt mit einem Freiheitsgrad. Sie berechnet sich beim Vierfelder-Test als:\n12\n\u03c72 =\nn \u22c5 ( ad \u2212 bc ) 2 ( a + b)( a + c )( c + d )(b + d )\n(12.3)\nUnter der Nullhypothese erwartet man, dass alle beobachteten H\u00e4ufigkeiten mit den erwarteten \u00fcbereinstimmen; in diesem Extremfall w\u00e4re \u03c72 = 0. In der Praxis ist nat\u00fcrlich immer damit zu rechnen, dass \u03c72 > 0. Kleinere Abweichungen von 0 sind mit der Nullhypothese durchaus noch vereinbar; hohe Werte der Pr\u00fcfgr\u00f6\u00dfe sprechen gegen die Nullhypothese. Die Pr\u00fcfgr\u00f6\u00dfe ist umso gr\u00f6\u00dfer, je mehr die beobachteten von den erwarteten H\u00e4ufigkeiten abweichen. Das Testverfahren wird wie folgt durchgef\u00fchrt:\n\u0177 Aus den absoluten H\u00e4ufigkeiten wird nach (12.3) die Pr\u00fcfgr\u00f6\u00dfe \u03c72 berechnet.\n233 12.2 Chi2-Tests\n12\n\u0177 Falls der Wert der Pr\u00fcfgr\u00f6\u00dfe innerhalb des Intervalls [0, \u03c712;1\u2212\u03b1 ] liegt, wird die Nullhypothese auf dem \u03b1 -Niveau beibehalten. \u203a Tabelle E, Anhang). F\u00fcr \u03b1 = 5% ist \u03c712;0,95 = 3,841 (z\nBeispiel 12.2 Bei der Stichprobe unserer n = 71 Studenten betrachten wir die Alternativmerkmale Rauchen und Geschlecht. Es ergeben sich folgende Werte: beobachtete H\u00e4ufigkeiten erwartete H\u00e4ufigkeiten Raucher Nichtraucher Raucher Nichtraucher a=4 b = 19 M\u00e4nner 23 4,2 18,8 23 c=9 d = 39 Frauen 48 8,8 39,2 48 13 58 71 13 58 71 Es ist nicht erstaunlich, dass die erwarteten H\u00e4ufigkeiten keine ganzen Zahlen sind. Es handelt sich um theoretische H\u00e4ufigkeiten, die aus den Randsummen berechnet werden (Tabelle 12.2) und zum Vergleich mit den beobachteten H\u00e4ufigkeiten dienen. Von den M\u00e4nnern rauchen 17%, von den Frauen 19%. Ist der Unterschied nun so gravierend, dass man die Nullhypothese (\u201eEs besteht kein Zusammenhang zwischen Rauchen und Geschlecht\u201c) verwerfen kann? Die Pr\u00fcfgr\u00f6\u00dfe ist nach (12.3): 71 \u22c5 (4 \u22c5 39 \u2212 19 \u22c5 9) 2 \u03c72 = = 0,0192 23 \u22c513 \u22c5 48 \u22c5 58 Dieser Wert ist kleiner als der kritische Wert 3,841 \u2013 d. h. anhand der Stichprobe ist kein Zusammenhang zwischen den beiden Merkmalen nachzuweisen. Der p-Wert betr\u00e4gt 0,8898; das Konfidenzintervall f\u00fcr die Differenz (Anteil Frauen - Anteil M\u00e4nner) ist [-0,18 ; 0,20]. Der Raucheranteil der Frauen k\u00f6nnte also um 20 % \u00fcber dem der M\u00e4nner liegen; er k\u00f6nnte ebenso gut 18 % geringer sein.\nMan kann den Vierfelder-Test auch dahingehend interpretieren, dass er bei zwei unabh\u00e4ngigen Stichproben relative H\u00e4ufigkeiten vergleicht (er \u00fcberpr\u00fcft, ob ein bestimmtes Merkmal in den beiden Stichproben gleich verteilt ist). So l\u00e4sst sich etwa die Situation in Beispiel 12.2 auch so beschreiben: Es werden zwei unverbundene Stichproben (bestehend aus m\u00e4nnlichen bzw. weiblichen Studenten) hinsichtlich des Merkmals \u201eRauchgewohnheiten\u201c verglichen. Dies ist ein anderer Ansatz, der jedoch formal mit demselben Testverfahren untersucht wird. Man spricht in diesem Fall vom Chi2-Homogenit\u00e4tstest. \u2022 Einseitiges Testen. Bisher wurde stillschweigend vorausgesetzt, dass beim Vierfelder-Test zweiseitig gepr\u00fcft wird. Nun sind auch einseitige Fragestellungen denkbar wie etwa: \u201eRauchen mehr Frauen als M\u00e4nner (oder umgekehrt)?\u201c. Einseitige Testverfahren sind bei\n234\nKapitel 12 \u00b7 Tests zum Vergleich von H\u00e4ufigkeiten\nChi2-Tests allerdings problematisch, weil die Richtung eines Unterschieds durch das Quadrieren der Abst\u00e4nde (B\u2013E) eliminiert wird. Dennoch ist beim Vierfelder-Test eine einseitige Pr\u00fcfung m\u00f6glich, indem man als kritischen Wert \u03c712;1\u22122\u03b1 zugrunde legt. Man geht bei diesem Ansatz davon aus, dass \u2013 grob formuliert \u2013 bei die H\u00e4lfte der Werte, die die Pr\u00fcfgr\u00f6\u00dfe unter der Nullhypothese annehmen kann, die beobachtete H\u00e4ufigkeit a kleiner ist als die dazugeh\u00f6rende Erwartungsh\u00e4ufigkeit (und bei der anderen H\u00e4lfte gr\u00f6\u00dfer). Bei den Werten, die gr\u00f6\u00dfer sind als \u03c712;1\u22122\u03b1 , entspricht die H\u00e4lfte dem Wert \u03b1. Ein einseitiger Test ist allerdings nur dann statthaft, wenn man aufgrund von Vorkenntnissen die Richtung eines m\u00f6glichen Unterschiedes genau kennt \u2013 ansonsten hat man eine Irrtumswahrscheinlichkeit von 2\u03b1. Theoretisch ist der einseitige Vierfelder-Test interessant; praktisch sollte man ihn meiden. \u2022 Zu den Voraussetzungen. Beim Vierfelder-Test sollte jede der er warteten H\u00e4ufigkeit mindestens 5 betragen; keine der beobachteten H\u00e4ufigkeiten darf 0 sein. Falls diese Anforderungen nicht erf\u00fcllt \u203a sind, kann man als Alternative Fisher\u2019s exakten Test verwenden (z Abschnitt 12.3). Mathematische Betrachtung der Chi2-Pr\u00fcfgr\u00f6\u00dfe beim Vierfelder-Test Die Berechnung der Pr\u00fcfgr\u00f6\u00dfe aus der Summe aller ( B \u2212 E ) 2 / E erscheint plausibel. Je mehr eine beobachtete H\u00e4ufigkeit B von der erwarteten H\u00e4ufigkeit E abweicht, umso gr\u00f6\u00dfer wird dieser Quotient und damit auch die Pr\u00fcfgr\u00f6\u00dfe. Die Division durch E erfolgt, um der Tatsache Rechnung zu tragen, dass dieselbe Abweichung ( B \u2212 E ) umso schwerer wiegt, je kleiner die Erwartungsh\u00e4ufigkeit E ist. Mit elementaren Rechenregeln lassen sich dann die H\u00e4ufigkeiten und deren Summe in Tabelle 12.2 herleiten. Wieso ist unter der\n12\nNullhypothese die Summe der ( B \u2212 E ) 2 / E \u03c7 2 -verteilt? Dazu betrachten wir die H\u00e4ufigkeiten a und c . a ist unter H 0 binomialverteilt mit dem Erwartungswert n1 p und der Varianz n1 p(1 \u2212 p) . Auch c ist binomialverteilt mit dem Erwartungswert n2 p und der Varianz n2 p(1 \u2212 p) . Unter H 0 hat die Differenz D = a / n1 \u2212 c / n2 den Erwartungswert 0 und s D2 = p(1 \u2212 p)(1 / n1 + 1 / n2 ) als Varianz. Folglich ist D / sD standardnormalverteilt. Demnach folgt ( D / sD ) 2\n\u203a Abschnitt 8.5.2). Wenn man einer \u03c7 2 -Verteilung mit einem Freiheitsgrad (z in ( D / sD ) 2 einsetzt: p = (a + c) / n , n1 = a + b und n2 = c + d , erh\u00e4lt man nach einigen Umrechnungen die Pr\u00fcfgr\u00f6\u00dfe nach (12.3).\n12\n235 12.2 Chi2-Tests\n12.2.2 Der Median-Test Die Anwendung des Vierfelder-Tests ist nicht beschr\u00e4nkt auf Alternativmerkmale. Mit diesem Test lassen sich auch zwei unabh\u00e4ngige Stichproben bez\u00fcglich eines ordinal skalierten oder eines quantitativen Merkmals vergleichen. Die Nullhypothese lautet in diesem Fall: H0 :\n~ =\u00b5 ~ \u00b5 1 2\nDas Testverfahren l\u00e4sst sich wie folgt beschreiben:\n\u0177 Man bildet aus den Daten beider Stichproben den gemeinsamen\nx. empirischen Median ~ \u0177 Dann ermittelt man die H\u00e4ufigkeiten entsprechend der folgenden Vierfeldertafel (Tabelle 12.3). \u0177 Die Pr\u00fcfgr\u00f6\u00dfe berechnet man nach (12.3). \u0177 Falls der Wert der Pr\u00fcfgr\u00f6\u00dfe innerhalb [0, \u03c712;1\u2212\u03b1 ] liegt, wird die Nullhypothese beibehalten. Tabelle 12.3 Vierfeldertafel beim Median-Test\nStichprobe 1 Stichprobe 2\n\u2264~ x\n>~ x\na\nb\nn1 = a + b\nc\nd\nn2 = c + d\na+c\nb+d\nn = a+b+c+d\nBeispiel 12.3 Es soll getestet werden, ob sich die Klausurergebnisse von n1 = 23 m\u00e4nnlichen und n2 = 48 weiblichen Studenten unterscheiden (Daten in Tabelle 2.1). Von \u203a Abbildung 3.2). Unter allen n = 71 Werten ergibt sich der Median ~ x = 8 (z Ber\u00fccksichtigung des Geschlechts erh\u00e4lt man folgende Vierfeldertafel: \u01b6 \u2264~ x >~ x 11 23 M\u00e4nner 12 24 48 Frauen 24 35 71 \u01b6 36 Aus diesen H\u00e4ufigkeiten ergibt sich eine Pr\u00fcfgr\u00f6\u00dfe von 71 \u22c5 (12 \u22c5 24 \u2212 11 \u22c5 24) 2 = 0,029 23 \u22c5 48 \u22c5 36 \u22c5 35 Dieser Wert ist wesentlich kleiner als \u03c712;0,95 = 3,841 \u2013 ein Unterschied ist nicht nachzuweisen. Wer h\u00e4tte etwas Anderes erwartet? Der p-Wert ist 0,8639. \u00dcbrigens: Man k\u00f6nnte diese Fragestellung auch mit dem U-Test von Mann und Whitney \u00fcberpr\u00fcfen; damit ergibt sich p = 0,8770.\n\u03c72 =\n236\nKapitel 12 \u00b7 Tests zum Vergleich von H\u00e4ufigkeiten\nDer Median-Test hat gegen\u00fcber dem t-Test und dem U-Test den Vorteil, dass er gleiche Verteilungsformen der Zufallsvariablen nicht voraussetzt. Der Median-Test kann auch dann benutzt werden, wenn die Verteilungen der Stichproben ungleich oder unbekannt sind. Wenn jedoch die Voraussetzungen des t-Tests oder des U-Tests erf\u00fcllt sind, sollte man diese wegen der h\u00f6heren Power bevorzugen. 12.2.3 Der Chi2-Test f\u00fcr k \u22c5 A Felder Dies ist eine Verallgemeinerung des Vierfelder-Unabh\u00e4ngigkeitstests dahingehend, dass die beiden betrachteten Merkmale nicht nur jeweils zwei, sondern k Auspr\u00e4gungen A1 ,..., Ak bzw. A Auspr\u00e4gungen B1 ,..., BA aufweisen. Dann erh\u00e4lt man bei der Darstellung der H\u00e4ufigkeiten eine Kontingenztafel mit k \u22c5 A Feldern im Innern. Die Nullhypothese besagt, dass kein Zusammenhang zwischen den beiden Merkmalen besteht. Dieser Test funktioniert nach dem bereits beschriebenen Prinzip: Es werden die beobachteten mit den erwarteten H\u00e4ufigkeiten verglichen. Seien nij die Anzahl der Stichprobenelemente mit der Auspr\u00e4gungskombination Ai und B j und eij die unter H0 erwarteten H\u00e4ufigkeiten. Dann berechnet sich die Pr\u00fcfgr\u00f6\u00dfe als \u03c72 =\nk\nA\n\u00a6\u00a6 i =1 j =1\n12\n( nij \u2212 eij ) 2 eij\n(12.4)\nSie hat (k \u2212 1) \u22c5 (A \u2212 1) Freiheitsgrade (dies bedeutet, dass man im Innern der Kontingenztafel (k \u2212 1) \u22c5 (A \u2212 1) H\u00e4ufigkeiten unter Beibehaltung der Randsummen \u00e4ndern kann). Die erwarteten H\u00e4ufigkeiten eij berechnet man aus den Randsummen. Kritische Werte in Abh\u00e4ngigkeit der Anzahl der Freiheitsgrade findet man in Tabelle E \u203a Anhang). (z Dieser Test l\u00e4sst sich auch auffassen als ein Homogenit\u00e4tstest: Er \u00fcberpr\u00fcft, ob ein Merkmal mit A Auspr\u00e4gungen in k Stichproben homogen verteilt ist. In jedem Fall wird vorausgesetzt, dass die erwarteten H\u00e4ufigkeiten mindestens 5 betragen (oder dass zumindest der Anteil der erwarteten H\u00e4ufigkeiten, die kleiner als 5 sind, 20 % nicht \u00fcberschreitet). Wenn diese Bedingung nicht erf\u00fcllt ist, kann man versuchen, dies durch Zusammenlegen von mehreren Auspr\u00e4gungen oder Klassen zu erreichen. Ersatzweise kann man den exak\u203a Abschnitt 12.3). ten Test nach Fisher anwenden (z\n12\n237 12.2 Chi2-Tests\ni Es gibt eine Variante dieses Tests (Mantel-Haenszel-Test), die sich eignet, z \u203a [10]). wenn eines der beiden Merkmale ordinal skaliert ist (z\n12.2.4 Assoziationsma\u00dfe f\u00fcr qualitative Merkmale Mit dem Chi2-Unabh\u00e4ngigkeitstest l\u00e4sst sich die Existenz einer Assoziation zwischen zwei nominal skalierten Merkmalen nachweisen. \u00dcber dessen St\u00e4rke macht das Testergebnis jedoch keine Angaben. Es wurden mehrere Assoziationskoeffizienten entwickelt, um die St\u00e4rke eines solchen Zusammenhangs zu quantifizieren. \u2022 Phi-Koeffizient. Er eignet sich, um den Zusammenhang zwischen zwei Alternativmerkmalen zu beschreiben und ist definiert als: \u03c6=\n\u03c72 n\n(12.5)\nDieser Koeffizient ist 0 bei vollkommener Unabh\u00e4ngigkeit der Merkmale. Falls b = c = 0 , nimmt \u03c6 den Wert 1 an (wie sich leicht anhand der Formel (12.3) nachvollziehen l\u00e4sst). In diesem Fall kann man n\u00e4mlich aufgrund eines Merkmals das andere pr\u00e4zise vorhersagen. Ansonsten ist \u03c6 kleiner als 1. Der Phi-Koeffizient ist signifikant gr\u00f6\u00dfer als 0, falls das Ergebnis des Vierfeldertests signifikant ist. Beispiel 12.4 In einer klinisch-kontrollierten Studie werden jeweils 50 Patienten mit einem neuen Medikament bzw. mit dem herk\u00f6mmlichen Standardmedikament behandelt. Die Therapien sind in a = 35 (neu) bzw. c = 25 (Standard) F\u00e4llen erfolgreich und demnach in b = 15 bzw. d = 25 F\u00e4llen nicht erfolgreich. Mit einem Chi2-Test erh\u00e4lt man: \u03c7 2 = 4,1667 und p = 0, 0412 . Die St\u00e4rke des Zusammenhangs wird quantifiziert durch \u03c6 = 4,1667 /100 = 0,204 . Der \u203a Yule\u2019sche Assoziationskoeffizient betr\u00e4gt Q = 0,40 ; die Odds Ratio ist 2,33 (z Abschnitt 3.4.2). Der Zusammenhang ist zwar signifikant, aber eher schwach. Die Differenz der Erfolgsraten betr\u00e4gt 20 %; das 95%-Konfidenzintervall liegt zwischen 1,2 % und 38,8 %.\n\u2022 Cram\u00e9rs Index. Dieses Ma\u00df (vorgestellt im Jahre 1946) ist eine Verallgemeinerung von \u03c6 f\u00fcr k \u22c5 A -Kontingenztafeln: CI =\n\u03c72 n \u22c5 ( R \u2212 1)\n(12.6)\n238\nKapitel 12 \u00b7 Tests zum Vergleich von H\u00e4ufigkeiten\nwobei R = min(k , A) . Es ist leicht nachvollziehbar, dass dieser Index f\u00fcr R = 2 mit \u03c6 identisch ist. \u2022 Kontingenzkoeffizient von Pearson. Dieser im Jahre 1904 vorge stellte Koeffizient ist das \u00e4lteste und bekannteste Assoziationsma\u00df: CC =\n\u03c72\n(12.7)\nn + \u03c72\nEs l\u00e4sst sich nachweisen, dass der Maximalwert von CC gleich Cmax = ( R \u2212 1) / R ist. Ein Nachteil dieses Koeffizienten ist, dass er 1 nie erreichen kann und deshalb schwer zu interpretieren ist. 12.2.5 Der McNemar-Test Dies ist ein H\u00e4ufigkeitstest f\u00fcr zwei verbundene Stichproben, die hinsichtlich eines Alternativmerkmals zu vergleichen sind. Diese treten beispielsweise dann auf, wenn Patienten mit zwei verschiedenen Therapien nacheinander behandelt werden und das Merkmal \u201eTherapieerfolg\u201c mit den Auspr\u00e4gungen \u201eja\u201c und \u201enein\u201c untersucht wird. Der Stichprobenumfang n l\u00e4sst sich folgenderma\u00dfen aufteilen: Tabelle 12.4 Vierfeldertafel beim McNemar-Test\nStichprobe 2\n12\nA\nStichprobe 1 A A a b\nA\nc\nd\nDie Nullhypothese besagt: Die Stichproben stimmen bez\u00fcglich der H\u00e4ufigkeitsverteilung \u00fcberein. Das bedeutet, dass a + b = a + c oder einfacher: b = c . Die H\u00e4ufigkeiten, die f\u00fcr die Gleichheit der Stichproben sprechen, sind a und d. Die H\u00e4ufigkeiten b und c repr\u00e4sentieren Unterschiede. Je mehr diese vom Durchschnittswert (b + c) / 2 abweichen, desto mehr spricht f\u00fcr die Alternativhypothese. Der Test wird nach folgendem Prinzip durchgef\u00fchrt:\n\u0177 Zun\u00e4chst werden die H\u00e4ufigkeiten der Vierfeldertafel ermittelt. \u0177 Danach berechnet man die Pr\u00fcfgr\u00f6\u00dfe nach: \u03c72 =\n(b \u2212 c ) 2 b+c\n(12.8a)\n12\n239 12.2 Chi2-Tests\n\u0177 Falls der Wert der Pr\u00fcfgr\u00f6\u00dfe mehr als \u03c712;1\u2212\u03b1 betr\u00e4gt, wird die Alternativhypothese angenommen.\nDie Pr\u00fcfgr\u00f6\u00dfe nach (12.8a) wird f\u00fcr b + c \u2264 30 Stetigkeitskorrektur etwas verkleinert: \u03c72 =\ndurch eine\n( b \u2212 c \u2212 1) 2\n(12.8b)\nb+c\nIm \u00dcbrigen setzt auch dieser Test voraus, dass die erwartete H\u00e4ufigkeit (b + c ) / 2 mindestens 5 betr\u00e4gt. i Die Stetigkeitskorrektur ist erforderlich, weil die H\u00e4ufigkeiten b und c z diskrete Werte darstellen, w\u00e4hrend \u03c72 eine stetige Variable ist. In der Literatur werden unterschiedliche Stetigkeitskorrekturen vorgeschlagen. In jedem Fall wird dadurch die Pr\u00fcfgr\u00f6\u00dfe etwas verkleinert, um zu verhindern, dass man allzu leichtfertig die Nullhypothese ablehnt.\nBeispiel 12.5 Bei 20 Patienten wird ein schmerzstillendes Pr\u00e4parat (Verum) mit einem Placebo verglichen. Jeder Patient wird mit beiden Therapien behandelt, wobei zwischen den Behandlungsphasen eine l\u00e4ngere, therapiefreie Phase liegt. Die Patienten wissen nicht, wann sie mit dem Placebo bzw. dem Verum behandelt werden. Sie beurteilen die Wirkung folgenderma\u00dfen: Wirkung des Placebos schwach stark a=3 b=2 Wirkung schwach c = 11 d =4 des Verums stark Als Pr\u00fcfgr\u00f6\u00dfe berechnet man: \u03c7 2 =\n( 2 \u2212 11 \u2212 1) 2\n= 4,923 > 3,841 . 2 + 11 Der p-Wert ist 0,0265. Deshalb wird die Alternativhypothese angenommen. Das Verum zeigt in 15 von 20 F\u00e4llen eine starke Wirkung, das Placebo nur 6 Mal. Das Konfidenzintervall f\u00fcr diese Wirkungsdifferenz ist [0,17 ; 0,73].\nMathematische Herleitung der Chi2-Pr\u00fcfgr\u00f6\u00dfe beim McNemar-Test Unter der Nullhypothese wird f\u00fcr jede der beiden H\u00e4ufigkeiten b und c der Wert (b + c ) / 2 erwartet. Dann berechnet man die Pr\u00fcfgr\u00f6\u00dfe nach (12.3) als: 2\n2\nb+c\u00b7 \u00a7 b+c\u00b7 \u00a7 \u00b8 \u00b8 + \u00a8c \u2212 \u00a8b \u2212 2 \u00b9 \u00a9 2 \u00b9 2 \u00a9 \u03c7 = b+c 2 Nach Ausmultiplizieren und Addieren erh\u00e4lt man die Formel (12.8a).\n240\nKapitel 12 \u00b7 Tests zum Vergleich von H\u00e4ufigkeiten\nAbschlie\u00dfend noch einige Hinweise zum McNemar-Test:\n\u2022 Nullhypothese: Es wird nicht behauptet, dass es \u00fcberhaupt keine Unterschiede zwischen den Stichproben gibt (in diesem Fall w\u00e4re zu erwarten, dass die H\u00e4ufigkeiten b und c gleich 0 sind). Die Nullhypothese besagt lediglich, dass unterschiedliche Beurteilungen in beiden Richtungen (Verum besser bzw. Placebo besser) gleich h\u00e4ufig sind, sodass man unter der Nullhypothese b = c erwarten w\u00fcrde. \u2022 Stichprobenumfang: In die Berechnung der Pr\u00fcfgr\u00f6\u00dfe flie\u00dft nicht der volle Stichprobenumfang ein, sondern lediglich die H\u00e4ufigkeiten b und c. Allerdings kommt im Konfidenzintervall f\u00fcr die \u203a Beispiel 12.5) der gesamte Umfang n zur Geltung. Differenz (z \u2022 Verallgemeinerung auf qualitative Merkmale: Der McNemar Test setzt ein Alternativmerkmal voraus. Bei einem Merkmal mit mehr als zwei Auspr\u00e4gungen entsteht anstelle der Vierfeldertafel eine Matrix. Der Symmetrietest von Bowker [5] \u00fcberpr\u00fcft, ob diese Matrix symmetrisch ist. \u2022 Verallgemeinerung auf mehrere verbundene Stichproben: Wenn Patienten mehrfach nacheinander auf ein Alternativmerkmal hin untersucht werden, bietet sich der Q-Test von Cochran an [5]. 12.2.6 Der Chi2-Anpassungstest\n12\nMit einem Anpassungstest wird \u00fcberpr\u00fcft, ob die empirische Verteilung einer Stichprobe vereinbar ist mit einer vermuteten, theoretischen Verteilung. Dabei kann jede Verteilung, die dem inhaltlichen Problem angemessen ist, vorgegeben werden. Wie bei allen Chi2-Tests werden auch bei einem Anpassungstest die beobachteten mit den erwarteten H\u00e4ufigkeiten verglichen. Die erwarteten H\u00e4ufigkeiten werden berechnet, indem man \u2013 unter Annahme einer theoretischen Verteilung \u2013 f\u00fcr jede Auspr\u00e4gung (Klasse oder Gruppe) die entsprechende Wahrscheinlichkeit bestimmt und diesen Wert mit dem Stichprobenumfang multipliziert. Die Anzahl der Freiheitsgrade betr\u00e4gt f = k \u2212 1 \u2212 r . Dabei ist k die Anzahl der gegebenen Klassen. Diese Anzahl wird um 1 reduziert, weil generell eine Restriktion durch den Stichprobenumfang gegeben ist. Au\u00dferdem wird die Anzahl der Freiheitsgrade eingeschr\u00e4nkt durch die Anzahl r der Parameter, die zur Berechnung der erwarteten H\u00e4ufigkeiten erforderlich sind. Die Anzahl der Freiheitsgrade ist also auch abh\u00e4ngig von der Verteilung, die man unter der Nullhypothese zugrunde legt:\n241 12.2 Chi2-Tests\n12\nf = k \u22121 f = k \u22122 Hier wird ein Parameter \u2013 n\u00e4mlich der Erwartungswert \u03bb \u2013 \u00fcber den Mittelwert der Stichprobe gesch\u00e4tzt; daher ist r = 1 . Normalverteilung: f = k \u22123 Diese Verteilung ist durch r = 2 Parameter \u2013 n\u00e4mlich den Erwartungswert und die Varianz \u2013 charakterisiert.\n\u0177 Gleichverteilung: \u0177 Poissonverteilung: \u0177\nBeispiel 12.6 Wir greifen zur\u00fcck auf das Beispiel 7.6, in dem Erythrozyten unter dem Mikroskop gez\u00e4hlt werden. Bei 80 Versuchen werden zwischen 0 und 12 Erythrozyten pro Z\u00e4hlkammer gefunden. In der folgenden Tabelle sind f\u00fcr jede Anzahl k mit 0 \u2264 k \u2264 12 die beobachteten H\u00e4ufigkeiten angegeben. Es soll gepr\u00fcft werden, ob diese Werte mit der Annahme einer Poissonverteilung vereinbar sind. Zun\u00e4chst wird aus den gegebenen H\u00e4ufigkeiten ein Mittelwert berechnet, der als Sch\u00e4tzer f\u00fcr den Erwartungswert \u03bb = 5,9125 dient. Mit der Formel (7.21) lassen sich f\u00fcr alle k die theoretischen Wahrscheinlichkeiten berechnen. Daraus ergeben sich (indem man sie mit 80 multipliziert) die erwarteten H\u00e4ufigkeiten. Da diese mindestens 5 betragen m\u00fcssen, werden die drei ersten und die drei letzten Klassen zusammengefasst, so dass insgesamt 9 Klassen resultieren. Die Nullhypothese lautet: Die Anzahl der Erythrozyten in einer Z\u00e4hlkammer folgt einer Poisson-Verteilung.\nk 0\u20132 3 4 5 6 7 8 9 10 \u2013 11 Summe\nbeobachtete H\u00e4ufigkeit B 5 7 11 12 16 10 7 5 7 80\nerwartete H\u00e4ufigkeit E 5,28 7,46 11,02 13,03 12,84 10,85 8,02 5,27 5,61 79,37\n( B \u2212 E )2 / E\n0,01475 0,02785 0,00004 0,08167 0,77682 0,06607 0,12884 0,01346 0,34337\n\u03c7 2 = 1,45287\nDie Anzahl der Freiheitsgrade ist 9 \u2212 2 = 7 . Es gilt \u03c772;0,90 = 12,017 (Tab. E, Anhang). Da die berechnete Pr\u00fcfgr\u00f6\u00dfe kleiner ist, wird die Nullhypothese beibehalten. Der p-Wert betr\u00e4gt 0,99318.\nEin Anpassungstest wird in der Regel verwendet, um zu \u00fcberpr\u00fcfen, ob man eine bestimmte Verteilung annehmen darf. H\u00e4ufig wird ein solcher Test vor der Anwendung des t-Tests eingesetzt, um empirische Daten dahingehend zu \u00fcberpr\u00fcfen, ob sie aus einer normalverteilten Grundgesamtheit entstammen. In diesen besonderen F\u00e4llen ist man daran interessiert, die Nullhypothese beizubehalten. Also ist man bem\u00fcht, den \u03b2-Fehler m\u00f6glichst klein zu halten. Dieser ist je-\n242\nKapitel 12 \u00b7 Tests zum Vergleich von H\u00e4ufigkeiten\ndoch im Gegensatz zum \u03b1-Fehler schwer absch\u00e4tzbar. Eine M\u00f6glichkeit, indirekt Einfluss auf den \u03b2-Fehler zu nehmen, besteht darin, den \u03b1-Fehler zu vergr\u00f6\u00dfern. Deshalb ist es \u00fcblich, bei einem Anpassungstest \u03b1 = 0,10 festzulegen und die Alternativhypothese erst f\u00fcr p > 0,10 anzunehmen. Man muss sich immer wieder klar machen, dass das Testergebnis eines Anpassungstests auf Normalverteilung, das zur Beibehaltung der Nullhypothese f\u00fchrt, keinesfalls als Beweis zu werten ist, dass die Grundgesamtheit tats\u00e4chlich normalverteilt ist. Man sollte hier nur vorsichtige Formulierungen verwenden wie etwa: \u201eNichts spricht gegen die Normalverteilung der Grundgesamtheit\u201c. i Bei stetigen Verteilungen bietet sich als Alternative zum Chi2-Anpasz sungstest der Kolmogoroff-Smirnov-Test an. Er beruht auf dem Vergleich einer empirischen Verteilungsfunktion mit der Verteilungsfunktion einer theoretischen Verteilung (z. B. der Normalverteilung). F\u00fcr kleine Stichproben ist der Kolmogoroff-Smirnov-Test besser geeignet als der Chi2\u203a [10]). Anpassungstest (z\n12.2.7 Der Logranktest\n12\nSchlie\u00dflich sei noch der ebenfalls auf der Chi2-Verteilung basierende Logrank-Test erw\u00e4hnt, der zum Vergleich von \u00dcberlebenszeiten angewandt wird. Dabei werden die \u00dcberlebensfunktionen S1 (t ) und S2 (t ) zweier (oder mehrerer) unverbundener Stichproben verglichen. Das Besondere an diesem Test ist, dass auch zensierte Daten \u203a Abschnitt 2.4) an(die h\u00e4ufig bei \u00dcberlebenszeitstudien auftreten; z gemessen ber\u00fccksichtigt werden. Mit dem Logranktest wird beispielsweise \u00fcberpr\u00fcft, ob sich eine Therapie oder ein prognostischer Faktor auf die \u00dcberlebenszeit oder allgemein auf die Zeit bis zum Eintreten eines bestimmten Endereignisses auswirkt. Ein Beispiel f\u00fcr die Darstellung einer \u00dcberlebens\u203a Abbildung 16.1). Um zeitkurve findet man in Abschnitt 16.2.3 (z zwei Kurven zu vergleichen, ermittelt man zun\u00e4chst die Anzahl der aufgetretenen Endereignisse b1 und b2 in den Stichproben; au\u00dferdem berechnet man die Anzahl der Endereignisse e1 und e2 , die man erwarten w\u00fcrde, wenn die beiden Kurven identisch w\u00e4ren. Die Teststatistik f\u00fcr den Logranktest ist:\n\u03c72 =\n(b1 \u2212 e1 ) 2 (b2 \u2212 e2 ) 2 + e1 e2\n(12.9)\n243 12.3 Der exakte Test nach Fisher\n12\nDie H\u00e4ufigkeiten b1 und b2 werden durch einfaches Z\u00e4hlen ermittelt. Die Berechnung der Erwartungsh\u00e4ufigkeiten ist komplizierter. Dazu betrachtet man beide Stichproben gemeinsam und notiert die Zeitpunkte ti ( i = 1,..., k ), zu denen in einer der beiden Stichproben ein Endereignis stattfindet und die Anzahl der dazugeh\u00f6renden Ereignisse d i . Dann ist k\ne1 = \u00a6 d i \u22c5 i =1\nn1i n1i + n2i\nk\ne2 = \u00a6 d i \u22c5 i =1\nn 2i n1i + n2i\n(12.10)\nn1i und n2i sind die Beobachtungseinheiten der 1. bzw. der 2. Stichprobe, die zum Zeitpunkt ti noch leben. Die Quotienten n1i /( n1i + n2i ) und n2i /( n1i + n2i ) entsprechen den Anteilen in der jeweiligen Stichprobe. Der Logranktest ist auch anwendbar auf mehr als zwei \u00dcberlebenskurven. Detaillierte Erl\u00e4uterungen dazu findet man in [11].\n12.3\nDer exakte Test nach Fisher\nWenn die Voraussetzungen des Vierfelder-Tests oder auch des Chi2Tests f\u00fcr k \u22c5 A Felder nicht erf\u00fcllt sind (wenn die erwarteten H\u00e4ufigkeiten zu klein sind), kann man alternativ Fisher\u2019s exakten Test verwenden. Dieser Test hei\u00dft \u201eexakt\u201c, weil der p-Wert als Pr\u00fcfgr\u00f6\u00dfe direkt berechnet wird. Er funktioniert im Vierfelderfall nach folgendem Prinzip:\n\u0177 Man ordnet die Vierfeldertafel so an, dass die kleinste H\u00e4ufigkeit oben links steht (sie entspricht dann der H\u00e4ufigkeit a). Die Wahrscheinlichkeit f\u00fcr diese Situation berechnet sich nach: P=\n( a + b)!( c + d )!( a + c )!(b + d )! n !\u22c5 a !\u22c5 b !\u22c5 c !\u22c5 d !\n(12.11)\n\u0177 Falls diese Wahrscheinlichkeit gr\u00f6\u00dfer ist als \u03b1, ist der Test beendet \u2013 die Nullhypothese wird beibehalten.\n\u0177 Ansonsten bildet man f\u00fcr noch extremere Situationen weitere Vierfeldertafeln, indem man unter Beibehaltung der Randsummen die H\u00e4ufigkeit a schrittweise jeweils um 1 reduziert, bis man a = 0 erh\u00e4lt. F\u00fcr jede dieser Situationen berechnet sich die Einzelwahrscheinlichkeit nach (12.11).\n244\nKapitel 12 \u00b7 Tests zum Vergleich von H\u00e4ufigkeiten\n\u0177 Die so berechneten Einzelwahrscheinlichkeiten werden aufaddiert. Deren Summe gibt an, wie gro\u00df die Wahrscheinlichkeit ist, die Ausgangssituation oder eine noch extremere Situation zu erhalten. Bei der einseitigen Fragestellung entspricht dies dem pWert. \u0177 Bei einer zweiseitigen Fragestellung wird der p-Wert der einseitigen Fragestellung verdoppelt. Ein anderer Ansatz besteht darin, die Einzelwahrscheinlichkeiten f\u00fcr jede Tabelle, die theoretisch unter Beibehaltung der Randh\u00e4ufigkeiten m\u00f6glich ist, zu berechnen und dann alle Einzelwahrscheinlichkeiten, die maximal so gro\u00df sind wie die Wahrscheinlichkeit der gegebenen Tabelle, aufzuaddieren. \u0177 Falls der berechnete p-Wert kleiner ist als \u03b1, wird die Nullhypothese zugunsten der Alternativhypothese abgelehnt. Beispiel 12.7 Zwei Gruppen von Patienten werden bez\u00fcglich einer neuen Therapie verglichen. Es soll getestet werden, ob sich die Misserfolgsquoten der beiden Therapien unterscheiden (zweiseitige Fragestellung). Es ergeben sich folgende H\u00e4ufigkeiten: Misserfolg Erfolg a=0 b=8 Therapie 1 8 8!\u22c5 8!\u22c5 5!\u22c5 11! c=5 d =3 P( a = 0) = = 0,0128 Therapie 2 8 16!\u22c5 0!\u22c5 8!\u22c5 5!\u22c5 3! 16 5 11 Eine ebenso extreme Situation w\u00e4re gegeben, wenn a = 5 und c = 0 ; auch in diesem Fall w\u00e4re P( a = 5) = 0,0128 . Die Summe dieser beiden Wahrscheinlichkeiten ergibt 0,0256 < 0,05 . Also wird die Nullhypothese f\u00fcr \u03b1 = 5% abgelehnt.\n12\ni Bei der zweiseitigen Fragestellung kann man den p-Wert nach zwei z Ans\u00e4tzen ermitteln (siehe oben); diese Werte werden sich in aller Regel nur marginal unterscheiden.\nFisher\u2019s exakter Test kann nicht nur f\u00fcr Vierfeldertafeln, sondern theoretisch f\u00fcr beliebig gro\u00dfe k \u22c5 A -Kontingenztafeln angewandt werden. Allerdings ist er dann rechnerisch sehr aufwendig, sodass selbst ein leistungsstarkes Statistikprogramm mitunter lange Zeit ben\u00f6tigt, um den p-Wert zu ermitteln.\n245 12.4 Ausblick auf die logistische Regression\n12\nMathematische Herleitung der Wahrscheinlichkeiten bei Fisher\u2019s exaktem Test Es sind n Beobachtungseinheiten (z. B. Patienten) gegeben; davon haben a + c eine bestimmte Eigenschaft (z. B. Therapie nicht erfolgreich). Von n Patienten werden zuf\u00e4llig a + b (z. B. f\u00fcr Therapie 1) ausgew\u00e4hlt; davon haben a Patienten einen Misserfolg. Unter der Nullhypothese folgt a einer hypergeometrischen Verteilung HG ( a + b; n, a + c) . Mit (7.27) berechnet man: \u00a7 a + c\u00b7 \u00a7 n \u2212 a \u2212 c \u00b7 \u00a7 a + c\u00b7 \u00a7b + d \u00b7 \u00a8\u00a8 \u00b8\u22c5\u00a8 \u00b8 \u00a8 \u00b8\u22c5\u00a8 \u00b8 a \u00b8\u00b9 \u00a8\u00a9 a + b \u2212 a \u00b8\u00b9 \u00a8\u00a9 a \u00b8\u00b9 \u00a8\u00a9 b \u00b8\u00b9 P( X = a) = \u00a9 = \u00a7 n \u00b7 \u00a7 n \u00b7 \u00a8\u00a8 \u00b8\u00b8 \u00a8\u00a8 \u00b8\u00b8 a b + \u00a9 \u00b9 \u00a9 a + b\u00b9 Nach Einsetzen der Binomialkoeffizienten ergibt sich (12.11).\n12.4\nAusblick auf die logistische Regression\nIn Abschnitt 11.4.2 wurde das Allgemeine Lineare Modell vorgestellt, mit dem der Einfluss mehrerer qualitativer und quantitativer Merkmale auf eine quantitative Zielgr\u00f6\u00dfe untersucht werden kann. Bei derlei Zielgr\u00f6\u00dfen handelt es sich meist um Messwerte aus dem klinischen Alltag, aus dem Labor oder um Zeitmessungen. In der medizinischen Forschung hat man es h\u00e4ufig jedoch auch mit qualitativen, oft auch mit einfachen Alternativmerkmalen als Zielgr\u00f6\u00dfen zu tun. Dies betrifft Fragestellungen, die sich mit \u201eja\u201c oder \u201enein\u201c beantworten lassen, wie zum Beispiel \u201eTherapie erfolgreich\u201c, \u201eKrankheit bricht aus\u201c oder \u201ePatient \u00fcberlebt\u201c. Am Ende liegen zwei Gruppen vor, die zu vergleichen sind. Um diese Gruppen bez\u00fcglich eines qualitativen Merkmals zu testen, verwendet man in der Regel den in diesem Kapitel vorgestellten Chi2-Test oder Fisher\u2019s exakten Test; bei einem quantitativen Merkmal bietet sich der t-Test \u203a Kapitel 11). oder der U-Test an (z Mit diesen Tests lassen sich Unterschiede zwischen den Gruppen absichern; allerdings k\u00f6nnen damit keine Wahrscheinlichkeiten f\u00fcr ein bestimmtes Endereignis berechnet werden. Au\u00dferdem handelt es sich um einfache Tests, die nur den Einfluss eines einzigen Merkmals ber\u00fccksichtigen. Die logistische Regression ist ein multiples Verfahren, mit dem es m\u00f6glich ist, die Wahrscheinlichkeit f\u00fcr das Auftreten eines bestimmten Endereignisses basierend auf mehreren Einflussgr\u00f6\u00dfen zu modellieren. Diese Einflussgr\u00f6\u00dfen k\u00f6nnen sowohl qualitativ als auch\n246\nKapitel 12 \u00b7 Tests zum Vergleich von H\u00e4ufigkeiten\nquantitativ sein. Im einfachsten Fall ist die Zielgr\u00f6\u00dfe bin\u00e4r; es ist jedoch auch m\u00f6glich, ordinal oder nominal skalierte Zielgr\u00f6\u00dfen mit mehreren Auspr\u00e4gungen zu untersuchen. Bei diesem Verfahren wird eine mathematische Gleichung aufgestellt, mit der die Wahrscheinlichkeit f\u00fcr das Auftreten eines Ereignisses A (z. B. \u201eDie Therapie ist erfolgreich\u201c) in Abh\u00e4ngigkeit von mehreren signifikanten Einflussgr\u00f6\u00dfen f\u00fcr jeden Einzelfall gesch\u00e4tzt werden kann: P ( A) =\nexp(a0 + a1 x1 + ... + a k xk ) 1 + exp(a0 + a1 x1 + ... + ak xk )\n(12.12)\nDiese auf den ersten Blick seltsam scheinende Formel gew\u00e4hrleistet, dass in jedem Fall eine Wahrscheinlichkeit ermittelt wird, die zwischen 0 und 1 liegt. Nominal skalierte Merkmale lassen sich durch \u203a Beispiel 2.5). Die G\u00fcte des Modells Dummy-Variablen darstellen (z wird wesentlich bestimmt durch die in das Modell aufgenommen Variablen. Diese Wahl muss sowohl unter statistischen als auch unter medizinisch-fachlichen Aspekten erfolgen. Die Berechnung der Regressionskoeffizienten ai ist ohne eine leistungsstarke Statistiksoftware kaum durchf\u00fchrbar. Die logistische Regression ist in der medizinischen Forschung sehr vielseitig verwendbar. Ausf\u00fchrliche Informationen und weitere Hinweise zur Analyse von kategorialen Daten findet man in [1] und [2].\n12\n13\nEpidemiologische Studien 13.1\nAufgaben und Ziele der Epidemiologie 249\n13.2\nDer Inhalt epidemiologischer Studien 250\n13.3\nKlassifikation nach formalen Aspekten 251\n13.3.1 Deskriptiv versus analytisch 251 13.3.2 Transversal versus longitudinal 252 13.3.3 Retrospektiv versus prospektiv 252 13.3.4 Beobachtend versus experimentell 254 13.3.5 Monozentrisch versus multizentrisch 255\n13.4\nFehlerquellen 255\n13.4.1 Zuf\u00e4llige Fehler 255 13.4.2 Systematische Fehler 256\n13.5\nDie Studienplanung 258\n13.5.1 Die Bedeutung der Planung 258 13.5.2 Komponenten der Planung 259\n249\n13\n13.1 Aufgaben und Ziele der Epidemiologie\n13.1\nAufgaben und Ziele der Epidemiologie\nDie Epidemiologie ist die Lehre von der Entstehung und der \u203a Abschnitt Verbreitung von Krankheiten und deren Bek\u00e4mpfung (z 6.3). Dieser Begriff bezog sich urspr\u00fcnglich nur auf Infektionserkrankungen. Mittlerweile befasst sich die Epidemiologie generell mit allen Erkrankungen, die von allgemeinem Interesse sind (beispielsweise mit Diabetes mellitus oder Krebserkrankungen). Die Aufgaben und Ziele der Epidemiologie sind vielf\u00e4ltig. Sie umfassen:\n\u0177 das Untersuchen der Verbreitung von Krankheiten in einer Population;\n\u0177 das Erkennen der Ursachen und Risikofaktoren einer Krankheit; \u0177 das Untersuchen des nat\u00fcrlichen Verlaufs einer Krankheit und die Bestimmung relevanter prognostischer Faktoren;\n\u0177 die Evaluation pr\u00e4ventiver, diagnostischer und therapeutischer Ma\u00dfnahmen. Aufgrund der Erkenntnisse, die aus epidemiologischen Studien resultieren, werden Grundlagen f\u00fcr gesundheitspolitische Entscheidungen geschaffen. Im Gegensatz zu anderen medizinischen Disziplinen ist in der Epidemiologie nicht eine einzelne Person Gegenstand des Interesses, sondern eine gr\u00f6\u00dfere Population. Dennoch profitieren sowohl die \u00c4rzte als auch die Patienten von den Ergebnissen epidemiologischer Studien. Es geh\u00f6rt n\u00e4mlich zum Berufsbild jedes praktisch t\u00e4tigen Arztes, Risiken zu erkennen und die Patienten entsprechend zu beraten, Diagnosen zu stellen, geeignete Therapien anzuordnen, Pr\u00e4ventionsma\u00dfnahmen durchzuf\u00fchren und den Verlauf einer Krankheit zu prognostizieren. Um die Aussagen epidemiologischer Studien umsetzen zu k\u00f6nnen, ist es wichtig, dass jeder Mediziner deren Struktur, St\u00e4rken und Einschr\u00e4nkungen versteht. Nur so kann er sinnvolle und nachvollziehbare Entscheidungen treffen. ! Der Inhalt der Kapitel 13 bis 16 bezieht sich nicht nur auf gro\u00df angelegte z\nepidemiologische und klinische Studien, sondern ist f\u00fcr kleinere Forschungsvorhaben (etwa Doktorarbeiten) ebenso relevant.\n250\nKapitel 13 \u00b7 Epidemiologische Studien\n\u00dcbersicht 9: Studientypen Studientypus Risikostudie\nDiagnosestudie Pr\u00e4ventionsstudie Therapiestudie\nPrognosestudie\n13.2\nEinflussgr\u00f6\u00dfen Risikofaktoren (z. B. Umweltfaktoren, genetische oder verhaltensbedingte Faktoren) Krankheitsstatus pr\u00e4ventive Ma\u00dfnahme (Impfen oder Screening) Therapieform (Arznei, chirurg. Eingriff, Di\u00e4t)\nKrankheit oder andere prognostische Faktoren\nZielgr\u00f6\u00dfen\nAbschnitt\nKrankheit, Tod\nKap. 14\nErgebnis eines diagnostischen Tests\n15.1\nKrankheit\n15.2\nWirkung einer Therapie Endzustand (Heilung, Remission, Progression, Tod); Zeit bis zum Eintreten eines Ereignisses\n16.1\n16.2\nDer Inhalt epidemiologischer Studien\nEpidemiologische Studien werden in der Regel als beobachtende \u203a Abschnitt 13.3.4) an einer gr\u00f6\u00dferen Population durchgeStudien (z f\u00fchrt. Sie lassen sich nach inhaltlichen Aspekten in folgende Gruppen einteilen:\n13\n\u2022 Risikostudien. Diese Studien haben zum Ziel zu kl\u00e4ren, ob ein \u00e4tiologischer Faktor das Auftreten einer Krankheit beeinflusst. Sie k\u00f6nnen retrospektiv als Fall-Kontroll-Studie oder prospektiv als Kohortenstudie durchgef\u00fchrt werden. Risikostudien k\u00f6nnen aber auch als Querschnittstudie oder als Populationsstudie angelegt sein. In jedem Fall handelt es sich um Beobachtungsstudien. In Kapitel 14 wird ausf\u00fchrlich auf die verschiedenen Designs eingegangen. \u2022 Diagnosestudien. Der Gegenstand dieser Studien sind diagnosti sche Tests, die dazu dienen, erkrankte Personen von nicht erkrankten zu trennen. Ziel dieser Studien ist das Ermitteln der Sensitivit\u00e4t und Spezifit\u00e4t eines diagnostischen Verfahrens. In Abschnitt 15.1 wird dieser Studientypus vorgestellt.\n251\n13\n13.3 Klassifikation nach formalen Aspekten\n\u2022 Pr\u00e4ventionsstudien. Sie haben zum Ziel, den Nutzen einer pr\u00e4ventiven Ma\u00dfnahme (z. B. einer Impfung oder eines Fr\u00fcherkennungsprogramms) zu evaluieren. In Abschnitt 15.2 wird dieses Thema er\u00f6rtert. \u2022 Therapiestudien. Im weiteren Sinne z\u00e4hlen zu epidemiologischen Studien auch Therapiestudien, die allerdings meist nicht als beobachtende, sondern als randomisierte klinische Studien durchgef\u00fchrt werden. Dabei werden zwei oder mehr Patientengruppen, die unterschiedlich therapiert werden, miteinander verglichen. Diese Studien haben im Gegensatz zu den oben genannten Studientypen experimentellen Charakter. Detaillierte Erl\u00e4uterungen findet man in Abschnitt 16.1. \u2022 Prognosestudien. Auch diese Studien werden \u2013 ebenso wie Thera piestudien \u2013 an erkrankten Patienten durchgef\u00fchrt. Sie sind in der Regel als Beobachtungsstudien angelegt. H\u00e4ufig wird dabei der zeitliche Verlauf einer Krankheit bis zu einem bestimmten Endereignis (z. B. Tod oder Heilung eines Patienten) untersucht. Dieses Thema ist Gegenstand des Abschnitts 16.2.\n13.3\nKlassifikation nach formalen Aspekten\nEpidemiologische Studien lassen sich formal nach folgenden Aspekten klassifizieren: 13.3.1 Deskriptiv versus analytisch \u2022 Deskriptive Studien. Diese Studien sind rein beschreibend. Die zugrunde liegenden Daten werden ausgewertet, ohne dass ein zeitlicher oder kausaler Zusammenhang zwischen mehreren Merkmalen hergeleitet werden kann. Beispiele hierf\u00fcr sind Register (etwa Krebsregister, Geburten- oder Sterberegister). Au\u00dferdem z\u00e4hlen zu diesem Studientypus Fallberichte, Fallserien und Querschnittstudien \u203a Abschnitt 14.2). (z Deskriptive Studien k\u00f6nnen nur Hinweise auf Auff\u00e4lligkeiten und m\u00f6gliche Zusammenh\u00e4nge geben. Diese sollten dann im Rahmen einer analytischen Studie \u00fcberpr\u00fcft werden. \u2022 Analytische Studien. Wichtige Erkenntnisse der epidemiologi schen Forschung basieren auf analytischen Studien (z. B. Fall-Kon\u203a Abschnitte 14.3 und 14.4). In troll-Studien oder Kohortenstudien, z\n252\nKapitel 13 \u00b7 Epidemiologische Studien\nderlei Studien geht es darum, einen Zusammenhang zwischen einer Zielgr\u00f6\u00dfe und einer (oder mehreren) Einflussgr\u00f6\u00dfen inhaltlich herzuleiten und statistisch abzusichern. Die \u00dcberg\u00e4nge zwischen deskriptiven und analytischen Studien sind flie\u00dfend. Wenn verschiedene Register miteinander verkn\u00fcpft wer\u203a Abschnitt 14.2.4), kann die den (so genannte \u00f6kologische Studien, z deskriptive Studie in eine analytische \u00fcbergehen. H\u00e4ufig bilden die Erkenntnisse aus einer einfachen, deskriptiven Studie die Basis f\u00fcr eine nachfolgende, analytische Studie. 13.3.2 Transversal versus longitudinal \u2022 Transversale Studien. Eine transversale Studie (oder Querschnitt studie) ist eine Momentaufnahme einer Population, bei der eine oder mehrere Eigenschaften der Studienteilnehmer erfasst werden. Ein\u203a Abschnitt 14.2.2). fachste Transversalstudien sind etwa Fallserien (z Ein anderes Beispiel f\u00fcr diese Studienform ist eine Pr\u00e4valenzstu\u203a Abschnitt 14.2.3), bei der die Pr\u00e4valenz einer Krankheit zu die (z einem bestimmten Zeitpunkt festgestellt wird. M\u00f6glicherweise werden dabei noch weitere Merkmale erfasst (z. B. ob die Studienteilnehmer einem besonderen Risikofaktor ausgesetzt sind). Man kann dann zwar versuchen, einen statistischen Zusammenhang zwischen Krankheit und Risikofaktor herzuleiten; kausale oder zeitliche Zusammenh\u00e4nge k\u00f6nnen jedoch nicht nachgewiesen werden. Transversale Studien eignen sich f\u00fcr Zustandsbeschreibungen, jedoch nicht, um zeitliche Abl\u00e4ufe zu untersuchen. Sie sind \u00fcberwiegend deskriptiv.\n13\n\u2022 Longitudinale Studien. Diese Studien (auch L\u00e4ngsschnittstudien genannt) haben zum Ziel, einen zeitlichen Verlauf zu beschreiben oder einen zeitlichen Zusammenhang herzuleiten. Sie sind insofern analytisch. Dazu z\u00e4hlen Fall-Kontroll-Studien, Kohortenstudien und \u203a Abschnitte 14.3, 14.4 und 16.1). klinisch kontrollierte Studien (z Longitudinale Studien lassen sich au\u00dferdem danach unterscheiden, ob sie retrospektiv oder prospektiv ausgerichtet sind. 13.3.3 Retrospektiv versus prospektiv \u2022 Retrospektive Studien. Retrospektiv hei\u00dft \u201ezur\u00fcckblickend\u201c. Man ermittelt bei einer retrospektiven Studie zun\u00e4chst die Auspr\u00e4gungen einer bestimmten Zielgr\u00f6\u00dfe und versucht dann, die Auspr\u00e4gungen\n253\n13\n13.3 Klassifikation nach formalen Aspekten\neiner oder mehrerer Einflussgr\u00f6\u00dfen zu erfassen. Das Paradebeispiel sind Fall-Kontroll-Studien, bei denen eine Gruppe erkrankter Personen (F\u00e4lle) mit einer Gruppe nicht erkrankter (Kontrollen) dahingehend verglichen wird, ob und welchen Risikofaktoren die Teilneh\u203a Abschnitt 14.3). mer in der Vergangenheit ausgesetzt waren (z Bei retrospektiven Studien sind die relevanten Ereignisse zu einem Zeitpunkt geschehen, als die konkrete Fragestellung der Studie noch gar nicht vorlag. Die Daten sind entweder dokumentiert (etwa in Krankenakten) oder m\u00fcssen durch Befragungen (Interviews, Fragebogen) erhoben werden. Der Vorteil dieser Studienart liegt auf der Hand: Man braucht nicht auf das Eintreten der interessierenden Endereignisse zu warten, und kann deshalb relativ schnell Ergebnisse erhalten. Dem stehen jedoch mitunter gravierende Nachteile gegen\u00fcber, die in erster Linie die Datenqualit\u00e4t betreffen. Es besteht im Nachhinein keine M\u00f6glichkeit, auf die Auswahl der Beobachtungseinheiten und der zu erfassenden Merkmale sowie auf die Mess- und Dokumentationstechniken Einfluss zu nehmen. Unvollst\u00e4ndige oder falsche Angaben in Krankenbl\u00e4ttern (z. B. Arzneimittelanamnese, klinische Befunde) lassen sich in der Regel nicht erg\u00e4nzen oder korrigieren (oft bleiben sie g\u00e4nzlich unbemerkt). Wenn man Personen nach zur\u00fcckliegenden Ereignissen befragt, ist man auf deren Erinnerungsverm\u00f6gen angewiesen und kann keinesfalls sicher sein, korrekte und vollst\u00e4ndige Informationen zu erhalten. Retrospektive Studien (insbesondere Fall-Kontroll-Studien) k\u00f6nnen wertvolle Hinweise auf m\u00f6gliche Zusammenh\u00e4nge liefern. Gegebenenfalls sind sie der Anlass zu einer nachfolgenden prospektiven Studie. Sie lassen sich \u2013 sofern man sich auf vollst\u00e4ndig und richtig erfasste Daten st\u00fctzen kann \u2013 auch bei der Qualit\u00e4tskontrolle einsetzen (z. B. um den Erfolg einer therapeutischen Ma\u00dfnahme oder die H\u00e4ufigkeiten von Komplikationen zu ermitteln). \u2022 Prospektive Studien. Prospektiv bedeutet \u201evorausschauend\u201c. Bei diesen Studien ermittelt man zun\u00e4chst die Einflussgr\u00f6\u00dfen und wartet ab, bis das interessierende Endereignis eintritt. Die Untersuchungsrichtung ist somit logischer als bei retrospektiven Studien. Prospektive Studien sind \u00fcblicherweise so angelegt, dass sich die Daten \u00fcberwiegend nach Studienbeginn ergeben. Der Versuchsleiter hat dabei Kontrollm\u00f6glichkeiten bez\u00fcglich der Stichprobe, der zu erfassenden Merkmale, der Messmethoden und der Dokumentation. Dem Vorteil der hohen Datenqualit\u00e4t steht als Nachteil ein erh\u00f6hter Zeitbedarf gegen\u00fcber.\n254\nKapitel 13 \u00b7 Epidemiologische Studien\nKohortenstudien sind die bekanntesten prospektiven Studien. Risikound Prognosestudien werden h\u00e4ufig als Kohortenstudien durchge\u203a Abschnitte 14.4 und 16.2). Auch Experimente und randof\u00fchrt (z \u203a Abschnitt 16.1) sind promisierte Studien (z. B. Therapiestudien, z spektiv angelegt. ! Die Begriffe \u201eprospektiv\u201c und \u201eretrospektiv\u201c werden vielfach auch dazu z\nverwendet, die Art der Datenerhebung zu beschreiben. Eine prospektive Studie bezeichnet dabei ein Design, bei dem die Daten erst nach Studienbeginn erhoben werden, w\u00e4hrend bei einer retrospektiven Studie die Daten zu Studienbeginn bereits erfasst worden sind. Diese unterschiedlichen Bedeutungen sind manchmal etwas verwirrend \u2013 etwa bei der Be\u203a Abschnitt 14.4.5). Deren zeichnung \u201eretrospektive Kohortenstudie\u201c (z Untersuchungsrichtung ist prospektiv (da von den Einflussgr\u00f6\u00dfen auf die Zielgr\u00f6\u00dfe geschlossen wird), die Art der Datenerhebung ist jedoch retrospektiv.\n13.3.4 Beobachtend versus experimentell \u2022 Beobachtende Studie. Der Versuchsleiter nimmt in Bezug auf die interessierenden Eigenschaften der Untersuchungseinheiten eine passive Rolle ein \u2013 er beobachtet, dokumentiert und wertet die Daten aus. Er greift aber nicht aktiv in das Geschehen ein, und er versucht nicht, die Studienteilnehmer zu beeinflussen. Beobachtende Studien k\u00f6nnen sehr einfach und rein deskriptiv konzipiert sein (z. B. als Fallserie). Sie k\u00f6nnen jedoch auch als Longitudinalstudie angelegt sein und \u2013 wenn mehrere Merkmale erfasst und analysiert werden \u2013 wertvolle Hinweise auf m\u00f6gliche Zusammenh\u00e4nge geben und damit analytischen Charakter annehmen (z. B. Fall-KontrollStudie oder Kohortenstudie). Studien zu Risiken, Diagnose und \u203a Prognose sind in aller Regel als beobachtende Studien angelegt (z Kapitel 14, Abschnitte 15.1 und 16.2).\n13\n\u2022 Experimentelle Studie. Bei einem Experiment (oder einer Interventionsstudie) gibt der Versuchsleiter die Auspr\u00e4gungen der Einflussgr\u00f6\u00dfen zumindest teilweise vor. Im Mittelpunkt steht dabei meist eine nicht-menschliche Population (z. B. Tiere oder Zellkulturen). Experimentelle Studien sind in jedem Fall analytisch und prospektiv. Der Versuchsleiter hat optimale Einflussm\u00f6glichkeiten auf die Stichproben, die Datenerhebung und -auswertung. Experimente in der Humanmedizin sind ethisch nicht unproblematisch und werden deshalb selten durchgef\u00fchrt. Eine Ausnahme stellen randomisierte klinische Studien dar, bei denen die Art der \u203a Abschnitt 16.1). Therapie vom Versuchsleiter vorgegeben wird (z\n255\n13\n13.4 Fehlerquellen\n13.3.5 Monozentrisch versus multizentrisch \u2022 Monozentrische Studie. Bei monozentrischen Studien werden die Patienten oder Probanden aus einer einzigen Institution (z. B. einer Klinik) rekrutiert. \u2022 Multizentrische Studie. Bei seltenen Krankheiten mag es schwie rig sein, in einer einzigen Klinik eine ausreichende Zahl von Teilnehmern zu gewinnen. In diesen F\u00e4llen bieten sich multizentrische Studien an, bei denen Patienten aus mehreren Einrichtungen zusammengefasst und gemeinsam analysiert werden.\n13.4\nFehlerquellen\nSowohl zuf\u00e4llige als auch systematische Fehler k\u00f6nnen ein Ergebnis beeinflussen. Systematische Fehler werden auch Bias genannt. 13.4.1 Zuf\u00e4llige Fehler Zuf\u00e4llige Fehler sind durch die Variabilit\u00e4t der Studienteilnehmer bedingt:\n\u0177 Interindividuelle Variabilit\u00e4t. Bei mehreren Beobachtungseinheiten erh\u00e4lt man beim Messen eines bestimmten Parameters (z. B. des Blutdrucks) bekanntlich unterschiedliche Ergebnisse \u2013 auch dann, wenn die zu untersuchende Stichprobe eine weitgehend homogene Population darstellt. \u0177 Intraindividuelle Variabilit\u00e4t. Selbst bei einer einzigen Beobachtungseinheit ergeben sich beim Messen einer Gr\u00f6\u00dfe unter \u00e4hnlichen Bedingungen (etwa zu verschiedenen Zeitpunkten) unterschiedliche Werte. Da sich diese Variabilit\u00e4ten nicht eliminieren lassen, sind zuf\u00e4llige Fehler generell nicht vermeidbar. Sie lassen sich aber bei einer sorgf\u00e4ltigen Versuchsplanung kontrollieren und reduzieren. Bei der Behandlung der Sch\u00e4tzmethoden in Kapitel 9 wurde darauf hingewiesen, dass ein hoher Stichprobenumfang und eine geringe Streuung der Daten dazu beitragen, den zuf\u00e4lligen Fehler klein zu halten. Man sollte deshalb darauf achten, dass die Stichproben bez\u00fcglich wichtiger Einflussgr\u00f6\u00dfen homogen sind. Dies l\u00e4sst sich erreichen durch:\n256\nKapitel 13 \u00b7 Epidemiologische Studien\n\u2022 Selektion. Man w\u00e4hlt die Stichprobe nur aus einem bestimmten Teil der Grundgesamtheit aus. Die Ergebnisse sind dann allerdings nur eingeschr\u00e4nkt auf diese spezielle Population \u00fcbertragbar. \u2022 Stratifizierung (Schichten oder Blockbildung). Man fasst mehrere Beobachtungseinheiten, die sich bez\u00fcglich eines oder mehrerer Merkmale \u00e4hneln, in einer Schicht zusammen (etwa nach Geschlecht oder Alter). Innerhalb einer solchen homogenen Schicht ist der zuf\u00e4llige Fehler reduziert; Unterschiede in der Zielgr\u00f6\u00dfe sind dann klarer erkennbar. Der zuf\u00e4llige Fehler l\u00e4sst sich anhand eines Konfidenzintervalls kontrollieren. W\u00e4hrend der p-Wert die Irrtumswahrscheinlichkeit quantifiziert (also die Wahrscheinlichkeit daf\u00fcr, dass ein nachgewiesener Effekt nur zuf\u00e4llig zustande gekommen ist), informiert das Konfidenzintervall \u00fcber die Gr\u00f6\u00dfe dieses Effekts. Je heterogener die Stichprobe ist, desto ungenauer ist die Sch\u00e4tzung und desto breiter \u203a Abschnitt 9.4.1). Es ist g\u00fcnstig, wenn ist das Konfidenzintervall (z die Zielgr\u00f6\u00dfe exakt messbar ist und eine geringe Streuung aufweist. 13.4.2 Systematische Fehler W\u00e4hrend zuf\u00e4llige Fehler das Ergebnis einer Studie unsicher machen, verf\u00e4lschen systematische Fehler (Bias) ein Versuchsergebnis in eine bestimmte Richtung und verleiten zu fehlerhaften Schl\u00fcssen. Es gibt eine Vielzahl von Bias-Quellen. Die meisten davon lassen sich jedoch einer der folgenden Kategorien zuordnen: \u2022 Systematische Erfassungsfehler. Es versteht sich von selbst, dass die Messger\u00e4te einwandfrei funktionieren m\u00fcssen, die Messverfahren valide und die messende Person in der Lage sein sollte, mit dem Ger\u00e4t umzugehen.\n13\n\u2022 Selektionsbias. Dieser Bias tritt auf, wenn sich mehrere zu vergleichende Gruppen in wesentlichen Charakteristika unterscheiden, die relevant f\u00fcr das Studienergebnis sind. Dieser Fall liegt beispielsweise dann vor, wenn zwei Therapiegruppen verglichen werden, wobei die Patienten der einen Gruppe nur leicht erkrankt sind (z. B. ambulante Patienten), w\u00e4hrend die Patienten der anderen Gruppe schwer erkrankt sind (z. B. station\u00e4re Patienten). Da der Schweregrad der Krankheit eine wichtige Determinante f\u00fcr die Wirkung einer Therapie ist, k\u00f6nnte ein Vergleich der beiden Gruppen zu falschen Schlussfolgerungen verleiten.\n257\n13\n13.4 Fehlerquellen\nEin Vergleich ist nur dann sinnvoll, wenn die Gruppen zu Beginn der Studie strukturgleich sind. Bei Fall-Kontroll-Studien ist die paarweise Zuordnung (Matchen), bei klinisch kontrollierten Studien \u203a die Randomisation geeignet, strukturgleiche Gruppen zu erhalten (z Abschnitte 14.3.3 und 16.1.3). \u2022 Informationsbias. Dieser Bias liegt vor, wenn die Methoden zur Informationsgewinnung uneinheitlich sind. Er kann kontrolliert werden, indem auf Beobachtungsgleichheit geachtet wird: Alle Untersuchungseinheiten m\u00fcssen von denselben Personen, im selben Zeitraum und mit denselben Methoden beobachtet werden. Bei klinischen Studien ist die Blindung das Mittel der Wahl. Optimal ist eine doppelblinde Studie, bei der weder der untersuchende Arzt noch die Patienten \u00fcber die Therapie im Einzelfall in\u203a Abschnitt 16.1.4). Dadurch sollen autosuggestive formiert sind (z Einfl\u00fcsse auf beiden Seiten ausgeschaltet werden. Es ist ein Manko multizentrischer Studien, dass die Beobachtungsgleichheit nur eingeschr\u00e4nkt gew\u00e4hrleistet werden kann. \u2022 Bias durch Confounder. Confounder sind verzerrende St\u00f6rgr\u00f6\u00dfen, die den Zusammenhang zwischen der Einflussgr\u00f6\u00dfe und der Zielgr\u00f6\u00dfe verf\u00e4lschen und somit ad\u00e4quate Ma\u00dfnahmen verhindern oder fehlleiten k\u00f6nnen. Verzerrende St\u00f6rgr\u00f6\u00dfen stehen in Zusammenhang mit der Einflussgr\u00f6\u00dfe und wirken sich damit indirekt auch auf die Zielgr\u00f6\u00dfe aus. Ein einfaches Beispiel mag dies verdeutlichen: Innerhalb einer Patientenkohorte mit einer hohen Letalit\u00e4t sollen Faktoren evaluiert werden, die das Risiko zu sterben (Zielgr\u00f6\u00dfe) beeinflussen. Ziel der Studie ist es, Pr\u00e4ventionsma\u00dfnahmen zu formulieren. Das Risiko zu sterben ist bekanntlich auch vom Alter abh\u00e4ngig. Innerhalb einer Kohorte sterben jedoch auch mehr nicht-verheiratete Patienten als verheiratete. Da der Partnerstatus sowohl mit der Zielgr\u00f6\u00dfe \u201eTod\u201c als auch mit der Einflussgr\u00f6\u00dfe \u201eAlter\u201c assoziiert ist (Patienten im h\u00f6heren Alter sind eher verwitwet und sterben fr\u00fcher), handelt es sich um eine verzerrende St\u00f6rgr\u00f6\u00dfe. W\u00fcrde der Partnerstatus als eine kausale Einflussgr\u00f6\u00dfe falsch gedeutet werden, k\u00f6nnte eine fehlgeleitete Pr\u00e4ventionsma\u00dfnahme sein, bei Diagnose der Erkrankung zu heiraten bzw. sich wieder zu verheiraten. Systematische Fehler sind bei einer guten Versuchsplanung weitgehend vermeidbar. Insbesondere muss \u2013 wenn mehrere Gruppen zu vergleichen sind \u2013 unbedingt auf Struktur- und Beobachtungsgleichheit geachtet werden.\n258\n13.5\nKapitel 13 \u00b7 Epidemiologische Studien\nDie Studienplanung\n13.5.1 Die Bedeutung der Planung Studien in der epidemiologischen und klinischen Forschung sind in der Regel mit einem hohen organisatorischen, zeitlichen und finanziellen Aufwand verbunden. Dies trifft auch \u2013 wenngleich in geringerem Ma\u00dfe \u2013 f\u00fcr Doktorarbeiten zu. Die Ergebnisse dieser Studien werden in der Regel publiziert und dienen anschlie\u00dfend zahlreichen \u00c4rzten als Entscheidungshilfen bei der Behandlung ihrer Patienten. Es ist daher essenziell wichtig, dass die Ergebnisse valide sind. Die G\u00fcte und praktische Relevanz einer Studie lassen sich anhand von zwei Kriterien beurteilen: \u2022 Interne Validit\u00e4t. Eine Studie ist intern valide, wenn deren Ergebnisse und die daraus gezogenen Schlussfolgerungen f\u00fcr die Patienten, die an der Studie partizipierten, korrekt sind. Die interne Validit\u00e4t ist unbedingt notwendig, aber nicht hinreichend daf\u00fcr, dass die Studie sinnvoll ist.\n13\n\u2022 Externe Validit\u00e4t. Darunter versteht man die Generalisierbarkeit oder die Verallgemeinerbarkeit der Studienergebnisse. Ein Arzt, der die Ergebnisse einer Studie zur Kenntnis nimmt, m\u00f6chte nat\u00fcrlich wissen, ob und inwieweit diese auf seine Patienten \u00fcbertragbar sind. Eine Studie mit hoher interner Validit\u00e4t kann v\u00f6llig in die Irre f\u00fchren, wenn deren Ergebnisse auf die falschen Patienten \u00fcbertragen werden. Daher stellt sich die Frage: F\u00fcr welches Patientenkollektiv sind die Ergebnisse g\u00fcltig? Kann man von der untersuchten Stichprobe (z. B. Patienten mit Psoriasis in einer bestimmten Klinik) auf die interessierende Grundgesamtheit schlie\u00dfen, und wie ist diese beschaffen (etwa Psoriasis-Patienten in ganz Deutschland, Europa oder gar weltweit)? Bei solchen Schlussfolgerungen muss man sehr vorsichtig sein. Die interne und die externe Validit\u00e4t und damit die Anwendbarkeit einer Studie werden in hohem Ma\u00dfe von einer sorgf\u00e4ltigen und detaillierten Planung bestimmt. ! Der Imperativ einer guten Planung wird gerne vergessen, wenn es darum z\ngeht, schnell Ergebnisse f\u00fcr eine Dissertation oder eine attraktive wissenschaftliche Tagung zu bekommen. Es ist sicherlich einfach, eine bekannte Labormethode mechanisch an einer kleinen Stichprobe einzusetzen oder f\u00fcr eine so genannte \u201eklinische Doktorarbeit\u201c ohne wesentliche Vorbereitungen staubige Krankenakten zu ziehen. Bei derlei Vorgehen kom-\n259\n13\n13.5 Die Studienplanung\nmen jedoch zumeist nur schlechte Studien heraus. Auch spektakul\u00e4re Ergebnisse einer neuen Labormethode k\u00f6nnen nur kurz \u00fcber ein mangelhaftes Studiendesign hinwegt\u00e4uschen. Was nutzt es beispielsweise, Zytokinpolymorphismen zu untersuchen, wenn keine Klarheit \u00fcber die Repr\u00e4sentativit\u00e4t der gew\u00e4hlten Stichprobe besteht? Was nutzen Unmengen von aus Patientenakten entnommenen Daten, wenn keine Fragestellung vorgegeben ist oder sich die vorgegebene Fragestellung damit nicht beantworten l\u00e4sst?\n13.5.2 Komponenten der Planung Das Ziel einer Studie besteht im Allgemeinen darin, auswertbare Daten zu gewinnen, die dazu dienen, eine vorgegebene Fragestellung zu beantworten. Zu Beginn stehen folgende \u00dcberlegungen: \u2022 Ziel der Studie. Zun\u00e4chst ist zu kl\u00e4ren: Wie lautet die Hauptfragestellung? Keine Studie sollte begonnen werden, wenn die exakte Fragestellung nicht bekannt ist. Aufbauend auf eigenen oder fremden Vorstudien muss dann die Fragestellung als Hypothese formuliert werden und theoretisch abgesichert werden. \u2022 Ziel- und Einflussgr\u00f6\u00dfen. Die Ziel- und Einflussgr\u00f6\u00dfen ergeben sich inhaltlich aus der Fragestellung. Da die Einflussgr\u00f6\u00dfen in funktionalem Zusammenhang zur Zielgr\u00f6\u00dfe stehen, resultieren Erkenntnisse bez\u00fcglich der Zielgr\u00f6\u00dfe(n) aus den Einflussgr\u00f6\u00dfen. Wenn beispielsweise im Rahmen einer Kohortenstudie das Auftreten einer bestimmten Erkrankung als Zielgr\u00f6\u00dfe untersucht wird, ist es sinnvoll, relevante Risikofaktoren wie z. B. das Alter bei Eintritt in die Kohorte oder die Familienanamnese mit zu ber\u00fccksichtigen. Nat\u00fcrlich ist es unm\u00f6glich, alle denkbaren Einflussgr\u00f6\u00dfen zu erfassen. Bei deren Auswahl muss man abw\u00e4gen zwischen dem, was w\u00fcnschenswert ist und dem, was praktisch realisierbar erscheint. Je mehr Merkmale ber\u00fccksichtigt werden, desto aufwendiger wird die Studie, desto komplexer sind die Analysemethoden und desto schwieriger gestaltet sich die Interpretation der Ergebnisse. Es ist deshalb sinnvoll, sich zun\u00e4chst auf wenige Faktoren zu konzentrieren. Au\u00dferdem ist es wichtig, alle Ziel- und Einflussgr\u00f6\u00dfen und deren Eigenschaften (u. a. die Skalenniveaus) genau anzugeben. Antworten auf all diese Fragen sind nicht zuletzt abh\u00e4ngig davon, ob die Daten bereits vorliegen (wie bei retrospektiven Studien) oder erst nach Studienbeginn erhoben werden (wie bei den meisten prospektiven Studien).\n260\nKapitel 13 \u00b7 Epidemiologische Studien\n\u2022 Wahl eines statistischen Modells. Jede Analysemethode ist nur unter einschr\u00e4nkenden Voraussetzungen anwendbar; es werden also bestimmte Eigenschaften der zu untersuchenden Merkmale angenommen. Ein statistisches Modell kann die Wirklichkeit zwar niemals vollst\u00e4ndig widerspiegeln; es sollte sie aber unter bestm\u00f6glicher Ausnutzung aller zur Verf\u00fcgung stehenden Informationen optimal beschreiben. Der Anwender eines statistischen Verfahrens muss sich im Vorfeld \u00fcberlegen, ob dessen Voraussetzungen erf\u00fcllt sind und ob die Hypothesen der inhaltlichen Fragestellung angemessen sind. Ein multiples Modell, bei dem mehrere Einflussgr\u00f6\u00dfen simultan ausgewertet werden, erm\u00f6glicht eine effizientere Datenanalyse und liefert weit mehr Erkenntnisse als zahlreiche einfache Tests, die lediglich den Zusammenhang zwischen zwei Merkmalen \u00fcberpr\u00fcfen. Bei der technischen Umsetzung einer komplexen Methode ist ein leistungsstarkes Statistikprogramm notwendig und sinnvoll. Es empfiehlt sich, fr\u00fchzeitig den Rat eines Biomathematikers einzuholen. Bei der Datenanalyse und der Interpretation der Ergebnisse sind sowohl medizinische als auch biomathematische Fachkenntnisse gefragt. \u2022 Ethik. Nicht alles, was unter statistischen Gesichtspunkten sinn voll und machbar ist, ist auch ethisch vertretbar. Deshalb m\u00fcssen Studien, bei denen Patienten oder gesunde Probanden involviert sind (insbesondere randomisierte Therapiestudien), von einer Ethikkommission begutachtet werden.\n13\n\u2022 Logistische \u00dcberlegungen. Ist die Studie unter den vorgegebenen Bedingungen durchf\u00fchrbar? Stehen gen\u00fcgend Ressourcen an Zeit, Geld, Personal etc. zur Verf\u00fcgung? Kann die Anzahl der ben\u00f6tigten Patienten in absehbarer Zeit rekrutiert werden? Sind die notwendigen Messger\u00e4te vorhanden und funktionieren sie einwandfrei? Planungsfehler k\u00f6nnen zu einem sp\u00e4teren Zeitpunkt kaum noch korrigiert werden. Deshalb ist es extrem wichtig, die oben angesprochenen Fragen im Vorfeld zu beantworten. ! Diese Tipps m\u00f6gen sich bitte auch Doktoranden zu Herzen nehmen. Es z\nkommt leider immer wieder vor, dass Studenten mit gro\u00dfem Eifer eine Dissertation beginnen und dann nach etlichen Monaten oder sogar Jahren feststellen, dass die Arbeit so wie vorgesehen nicht durchzuf\u00fchren ist. Nur mit einer guten Versuchsplanung (und einem kompetenten Betreuer) l\u00e4sst sich ein solches Desaster vermeiden. Detaillierte und n\u00fctzliche Informationen zu diesem Thema findet man in [12].\n14\nRisikostudien 14.1\nEinleitung 263\n14.1.1 Die Bedeutung von Risikostudien 263 14.1.2 Wichtige Begriffe 264\n14.2\nDeskriptive Studien 264\n14.2.1 Fallberichte 264 14.2.2 Fallserien 265 14.2.3 Pr\u00e4valenzstudien 266 14.2.4 Populationsstudien 266\n14.3\nFall-Kontroll-Studien 267\n14.3.1 Grundlagen 267 14.3.2 Auswahl der F\u00e4lle und der Kontrollen 267 14.3.3 Matchen 268 14.3.4 Biasquellen 269 14.3.5 Die Odds Ratio 271 14.3.6 Anwendungen und Grenzen 272\n14.4\nKohortenstudien 272\n14.4.1 Grundlagen 272 14.4.2 Effektma\u00dfe 273 14.4.3 Inzidenzma\u00dfe 275 14.4.4 Biasquellen 276 14.4.5 Spezielle Kohortenstudien 276\n14.5\nDer Nachweis einer Kausalit\u00e4t 277\n263\n14\n14.1 Einleitung\n14.1\nEinleitung\n14.1.1 Die Bedeutung von Risikostudien Viele Menschen haben ein gro\u00dfes Interesse daran zu erfahren, welchen potentiellen Risikofaktoren sie ausgesetzt sind und wie hoch gegebenenfalls ihr pers\u00f6nliches Risiko ist, eine bestimmte Krankheit zu entwickeln. F\u00fcr den Arzt kann die Kenntnis m\u00f6glicher Risikofaktoren eines Patienten in mehrfacher Weise von Nutzen sein:\n\u0177 Vorhersage. Falls ein gesicherter Zusammenhang zwischen einer Krankheit und einem \u00e4tiologischen Faktor besteht, l\u00e4sst sich im Einzelfall die Wahrscheinlichkeit f\u00fcr das Eintreten einer Krankheit absch\u00e4tzen. \u0177 Pr\u00e4vention. Sollte es sich um ein vermeidbares Risiko handeln (z. B. Rauchen), kann der Arzt dem Patienten raten, seine Lebensweise zu \u00e4ndern. Andernfalls (z. B. bei einem genetisch bedingten Faktor) kann er Vorsorgema\u00dfnahmen treffen, um dessen Auswirkungen zu kontrollieren oder abzuschw\u00e4chen. \u0177 Diagnose. Die Kenntnis, welcher Risikogruppe ein Patient ange\u203a h\u00f6rt, kann in einem diagnostischen Prozess sehr wichtig sein (z Beispiel 6.16). Das Wissen um Faktoren, die mit einer Krankheit assoziiert sind, ist nicht zuletzt von gesundheitspolitischem Interesse. Falls eine gr\u00f6\u00dfere Population einem Risikofaktor ausgesetzt ist, kann dessen Beseitigung ma\u00dfgeblich dazu beitragen, das Auftreten neuer Krankheitsf\u00e4lle zu verhindern. Ignaz Philipp Semmelweis gelang es beispielsweise um die Mitte des 19. Jahrhunderts, durch hygienische Ma\u00dfnahmen (das Personal musste sich mit Chlorkalk die H\u00e4nde desinfizieren) die durch Kindbettfieber verursachte Mortalit\u00e4t drastisch zu senken. John Snow sorgte um das Jahr 1850 durch die Schlie\u00dfung eines Brunnens daf\u00fcr, dass die Bewohner eines Londoner Bezirks nicht mehr an Cholera erkrankten. Der Zusammenhang zwischen einer Erkrankung und einem Risikofaktor ist jedoch meist nicht so klar und eindeutig. Viele Krankheiten haben multiple Ursachen, und ein einzelner Faktor (z. B. Rauchen) beg\u00fcnstigt nicht nur das Auftreten einer, sondern diverser Krankheiten. Andere Gr\u00fcnde liegen in der langen Latenzzeit vieler Krankheiten (z. B. Krebs) oder deren geringer Inzidenz. Ein praktisch t\u00e4tiger Arzt ist daher auf Studien angewiesen, in denen der Einfluss eines Risikofaktors untersucht und beschrieben wird.\n264\nKapitel 14 \u00b7 Risikostudien\n14.1.2 Wichtige Begriffe Zun\u00e4chst soll die Bedeutung einiger h\u00e4ufig verwendeter Begriffe dargelegt werden. \u2022 Risiko. Darunter versteht man die Wahrscheinlichkeit eines unerw\u00fcnschten Ereignisses. H\u00e4ufig benutzte Risiken in der Medizin \u203a Abschnitt 6.3). sind die Inzidenz und die Mortalit\u00e4t (z \u2022 Risikofaktoren oder \u00e4tiologische Faktoren. Dies sind Merkmale, die mit einem erh\u00f6hten Erkrankungsrisiko assoziiert sind. Risikofaktoren k\u00f6nnen erblich sein oder aus dem Umfeld stammen (etwa Erreger von Infektionskrankheiten oder Umweltgifte). Andere sind sozial gepr\u00e4gt (z. B. psychische Belastungen) oder verhaltensbedingt (z. B. Rauchen, Alkoholkonsum). \u2022 Exposition. Eine Person gilt als exponiert, wenn sie mit einem Risikofaktor in Kontakt gekommen ist oder mit ihm behaftet ist. Die Exposition kann zu einem einzelnen Zeitpunkt stattfinden (z. B. Kontakt mit einem Infektionserreger); sie kann sich aber auch \u00fcber einen l\u00e4ngeren Zeitraum oder die gesamte Lebenszeit eines Menschen erstrecken. Beispiele hierf\u00fcr sind Jahre langer Zigarettenkonsum oder die Expression eines Gens, die das Auftreten einer bestimmten Krankheit beg\u00fcnstigt. Im Folgenden werden diverse Studientypen vorgestellt, mit denen sich Zusammenh\u00e4nge zwischen Risikofaktoren und Krankheitsbildern nachweisen lassen \u2013 angefangen bei Fallberichten einfachster Art bis hin zu gro\u00df angelegten, aufwendigen Kohortenstudien.\n14.2\nDeskriptive Studien\n14.2.1 Fallberichte\n14\nEin Fallbericht ist eine ausf\u00fchrliche Beschreibung eines interessanten Einzelfalls oder einiger weniger F\u00e4lle. Er eignet sich:\n\u0177 um Krankheitsbilder, die erstmals beobachtet werden, einer akademischen \u00d6ffentlichkeit vorzustellen,\n\u0177 um einen Hinweis auf einen m\u00f6glichen Risikofaktor der beschriebenen Erkrankung zu geben,\n\u0177 um ungew\u00f6hnliche oder typische Manifestationen einer Krankheit zu beschreiben.\n265 14.2 Deskriptive Studien\n14\nFallberichte beinhalten bedingt durch die niedrige Patientenanzahl keine statistische Analyse. Dem Leser eines solchen Berichts f\u00e4llt es mitunter schwer zu beurteilen, ob hier eine relevante Neuentdeckung (etwa ein bislang unbekannter Zusammenhang zwischen einem \u00e4tiologischen Faktor und einer Krankheit) oder nur ein zuf\u00e4lliges Zusammentreffen mehrerer seltener Ereignisse beschrieben wird. Diverse Krankheitsbilder wurden aufgrund eines Fallberichts bekannt. So gab es in den 1980er Jahren aufgrund eines Berichtes \u00fcber das Auftreten von Kaposisarkomen bei jungen m\u00e4nnlichen Homosexuellen in New York erste Hinweise auf eine neue Infektion. Demnach k\u00f6nnen Fallberichte Anhaltspunkte auf m\u00f6gliche Zusammenh\u00e4nge zwischen einem Krankheitsbild und einem potentiellen Risikofaktor liefern \u2013 insbesondere dann, wenn aufgrund eines solchen Berichts weitere, \u00e4hnlich gelagerte F\u00e4lle bekannt werden. Der vermutete Zusammenhang muss dann im Rahmen einer gr\u00f6\u00dferen, nachfolgenden Studie \u00fcberpr\u00fcft werden. 14.2.2 Fallserien Eine Fallserie unterscheidet sich von einem Fallbericht durch die Anzahl der involvierten Patienten. Es handelt sich um eine einfache deskriptive Studie an einer gr\u00f6\u00dferen Gruppe von Personen, die an einer bestimmten Krankheit leiden und dar\u00fcber hinaus einige Besonderheiten aufweisen. So hat beispielsweise im Jahre 1941 ein Chirurg aus New Orleans namens Alton Ochsner (1896-1981) eine Fallserie ver\u00f6ffentlicht, in der er nachwies, dass fast alle in den USA an Lungenkrebs operierten Patienten Raucher waren. Er stellte daraufhin die Hypothese auf, dass Rauchen mit Lungenkrebs assoziiert sei. Dies war damals eine umstrittene Hypothese, die mittlerweile aufgrund weiterer Studien eindrucksvoll best\u00e4tigt wurde. Das Beispiel zeigt, dass Fallserien durchaus in der Lage sind, Hypothesen zu generieren. Es ist auch m\u00f6glich, einfache statistische Ma\u00dfzahlen zu ermitteln. Das gro\u00dfe Manko von Fallserien ist das Fehlen einer Vergleichsgruppe. Ochsner konnte nur aufgrund der ihm bekannten Tatsache, dass andere Leute weit weniger rauchen als die von ihm beschriebenen Patienten, seine Hypothese aufstellen. Allerdings reichen zu deren Best\u00e4tigung Fallserien nicht aus.\n266\nKapitel 14 \u00b7 Risikostudien\n14.2.3 Pr\u00e4valenzstudien Eine Pr\u00e4valenzstudie ist eine Querschnittstudie, in der bei jedem Teilnehmer erfasst wird, ob er an einer bestimmten Erkrankung leidet und ob er exponiert ist. Ein Beispiel best\u00fcnde darin, die Mitglieder einer Population danach zu untersuchen, ob sie eine koronare Herzkrankheit haben und ob gleichzeitig ihr Blutdruck erh\u00f6ht ist. Der Anteil der Erkrankten entspricht der Pr\u00e4valenz. Man kann mit einer geeigneten Analysemethode (z. B. einem Chi2-Test) untersuchen, ob ein statistischer Zusammenhang zwischen der Exposition und der Krankheit besteht und diesen mittels eines Assoziations\u203a Abschnitt 3.4.2). Wenn ma\u00dfes wie der Odds Ratio quantifizieren (z eine Assoziation nachgewiesen wird, sollte dieses Ergebnis jedoch vorsichtig interpretiert werden:\n\u0177 Die Pr\u00e4valenz ist kein Ma\u00df f\u00fcr das Risiko, die Krankheit zu entwickeln.\n\u0177 Es werden nur Personen erfasst, die die Krankheit \u00fcberlebt haben. Todesf\u00e4lle bleiben unber\u00fccksichtigt. F\u00e4lle, bei denen ein schneller Heilerfolg eintritt, sind meist unterrepr\u00e4sentiert. \u0177 Mit dieser Studienform l\u00e4sst sich nicht direkt nachweisen, dass die Exposition der Krankheit vorausging. Pr\u00e4valenzstudien sind \u00fcberwiegend deskriptiv. Sie sind keineswegs ausreichend, zeitliche oder kausale Zusammenh\u00e4nge abzusichern; sie k\u00f6nnen allenfalls Hinweise liefern. In erster Linie eignen sie sich zur Erfassung von chronischen Krankheiten. 14.2.4 Populationsstudien\n14\nPopulationsstudien unterscheiden sich von anderen Risikostudien dadurch, dass nicht Individuen untersucht, sondern Gruppen oder L\u00e4nder zugrunde gelegt werden. Andere Bezeichnungen sind aggregative, \u00f6kologische oder Korrelationsstudien. Ein Beispiel stellt eine Studie dar, in der nachgewiesen wurde, dass eine gegensinnige Korrelation zwischen dem Weinkonsum eines Landes und der kardialen Mortalit\u00e4t besteht. In Italien und in Frankreich, wo traditionsgem\u00e4\u00df viel Wein getrunken wird, ist diese Mortalit\u00e4t wesentlich niedriger als etwa in Australien und den USA, wo der Weinkonsum deutlich geringer ist. Populationsstudien k\u00f6nnen Hinweise auf m\u00f6gliche Zusammenh\u00e4nge geben. Es ist jedoch problematisch, dass ein Bias durch Confounding nicht ausgeschlossen werden kann.\n267 14.3 Fall-Kontroll-Studien\n14.3\n14\nFall-Kontroll-Studien\n14.3.1 Grundlagen Bei diesem Studientypus werden F\u00e4lle (Patienten, die an einer bestimmten Krankheit leiden) und Kontrollen (Personen, die von dieser Krankheit nicht betroffen sind) bez\u00fcglich eines oder mehrerer \u00e4tiologischer Faktoren miteinander verglichen. Fall-Kontroll-Studien sind retrospektiv und analytisch. Die Untersucher eruieren durch Befragungen, anhand von Patientenakten oder dokumentierten Laborbefunden f\u00fcr jeden Fall und f\u00fcr jede Kontrolle, ob die betreffende Person in der Vergangenheit exponiert war. Es bietet sich an, nicht nur einen, sondern mehrere potentielle Risikofaktoren zu untersuchen. 14.3.2 Auswahl der F\u00e4lle und der Kontrollen Die F\u00e4lle werden meist aus Kliniken oder aus Arztpraxen rekrutiert. Es ist sinnvoll, neu diagnostizierte F\u00e4lle in die Studie aufzunehmen (Inzidenzf\u00e4lle). Wenn die Patienten bereits seit l\u00e4ngerer Zeit erkrankt sind (Pr\u00e4valenzf\u00e4lle), besteht die Gefahr, dass \u00fcberwiegend Langzeit\u00fcberlebende ber\u00fccksichtigt werden. Es ist ferner wichtig, dar\u00fcber nachzudenken, f\u00fcr welche Population die Fallgruppe repr\u00e4sentativ ist. Die Auswahl der Kontrollen ist weitaus schwieriger. Einerseits sollten die Kontrollen den F\u00e4llen \u00e4hneln, damit Vergleiche zwischen den Gruppen sinnvoll erscheinen. Andererseits sollte die Kontrollgruppe repr\u00e4sentativ f\u00fcr alle nicht erkrankten Personen der Population sein, um R\u00fcckschl\u00fcsse zu erm\u00f6glichen. Selbstverst\u00e4ndlich darf unter den Kontrollen niemand an der zu untersuchenden Krankheit leiden. Es wurden mehrere Strategien entwickelt, um Kontrollen zu rekrutieren:\n\u0177 Populationsbasierter Ansatz. Die Kontrollen w\u00e4hlt man aus der Allgemeinbev\u00f6lkerung. Im Idealfall geschieht dies in Form einer Zufallsstichprobe, etwa anhand zuf\u00e4llig ausgew\u00e4hlter Telefonnummern. Problematisch ist jedoch, dass diese Personen im Allgemeinen wenig Interesse an der Studie haben und daher h\u00e4ufig nicht kooperativ sind. Ferner ist zu bedenken, dass diese Kontrollen zwar repr\u00e4sentativ f\u00fcr die Allgemeinbev\u00f6lkerung sein m\u00f6gen, dass sie aber nicht ohne weiteres mit den F\u00e4llen vergleichbar sind.\n268\nKapitel 14 \u00b7 Risikostudien\n\u0177 Krankenhausbasierter Ansatz. Diese Form bietet sich an, wenn es sich bei den F\u00e4llen um Patienten eines Krankenhauses handelt. Die Kontrollen werden in der Regel nicht zuf\u00e4llig aus den Krankenhaus-Patienten ausgew\u00e4hlt. Man versucht vielmehr \u203a Abschnitt 14.3.3) zu erreichen, dass sich die durch Matchen (z Gruppen der F\u00e4lle und der Kontrollen bez\u00fcglich wichtiger Einflussfaktoren \u00e4hneln. Bei diesem Ansatz ist darauf zu achten, dass die Diagnose der Kontrollen mit dem zu untersuchenden Risikofaktor nicht assoziiert sein sollte. Wenn etwa ein Zusammenhang zwischen einer Krebsart und Rauchen nachgewiesen werden soll und als Kontrollgruppe Patienten mit koronarer Herzkrankheit gew\u00e4hlt w\u00fcrden, k\u00f6nnten sich unter den Kontrollen (ebenso wie unter den F\u00e4llen) \u00fcberdurchschnittlich viele Raucher befinden. Es w\u00e4re dann schwierig, den interessierenden Zusammenhang abzusichern. Allerdings stellt sich beim Krankenhaus-basierten Ansatz das Problem, dass die Kontrollen nicht unbedingt repr\u00e4sentativ f\u00fcr die Allgemeinbev\u00f6lkerung sind. Eine weitere Schwierigkeit entsteht mitunter dadurch, dass nicht alle Krankenhaus\u00e4rzte motiviert sind, ihre Patienten als Kontrollen zur Verf\u00fcgung zu stellen und die Kontrollen selbst ebenfalls nicht immer gro\u00dfes Interesse an der Studie haben. \u0177 Kontrollen aus dem Umfeld der F\u00e4lle. Manchmal ist es sinnvoll, zu jedem Fall den Partner, ein Geschwister oder einen Freund als Kontrollperson heranzuziehen. Es ist anzunehmen, dass diese Kontrollen in vielen Eigenschaften mit dem passenden Fall \u203a paarweises Matching, Abschnitt 14.3.3). \u00fcbereinstimmen (z \u0177 Mehrere Kontrollgruppen. Eine andere Strategie besteht darin, mehrere Kontrollgruppen unterschiedlicher Herkunft zu w\u00e4hlen und diese Kontrollen miteinander zu vergleichen. Systematische Fehler aufgrund der Auswahl der Kontrollen sind dann eher erkennbar. Diese Vorgehensweise ist freilich entsprechend aufwendig.\n14\n14.3.3 Matchen Eine potentielle Schwierigkeit bei Fall-Kontroll-Studien ist gegeben, wenn sich die beiden Gruppen \u2013 F\u00e4lle und Kontrollen \u2013 au\u00dfer bez\u00fcglich der zu untersuchenden Risikofaktoren in anderen wichtigen Eigenschaften unterscheiden. Wenn beispielsweise die F\u00e4lle im Durchschnitt wesentlich \u00e4lter sind als die Kontrollen und au\u00dferdem mehr F\u00e4lle einer Exposition ausgesetzt waren, l\u00e4sst sich nicht zweifelsfrei erkennen, ob die Krankheit durch die Exposition oder durch\n269 14.3 Fall-Kontroll-Studien\n14\ndas h\u00f6here Alter verursacht wurde. Dieses Problem kann dadurch gel\u00f6st werden, dass nach wichtigen Kriterien (z. B. dem Alter) gematcht wird. Man unterscheidet: \u2022 Paarweises (individuelles) Matching. Dabei wird f\u00fcr jeden Einzelfall eine passende Kontrolle gesucht, die mit dem Fall in einigen relevanten Merkmalen \u00fcbereinstimmt. Auf diese Weise erh\u00e4lt man strukturgleiche Gruppen bez\u00fcglich der gematchten Merkmale. Diese Methode wird \u00fcblicherweise angewandt, wenn die Kontrollen aus Krankenhauspatienten ausgew\u00e4hlt werden. H\u00e4ufig erfolgt die paarweise Zuordnung nach Geschlecht und Alter. Wenn Geschwister als Kontrollen herangezogen werden, wird automatisch nach genetischen Faktoren gematcht. Bei Partnern als Kontrollen wird nach sozio-\u00f6konomischen Status gematcht. \u2022 Gruppen-Matching. Bei diesem Ansatz wird die Kontrollgruppe so zusammengestellt, dass die H\u00e4ufigkeitsverteilungen eines bestimmten Merkmals bei den F\u00e4llen und den Kontrollen ann\u00e4hernd identisch sind. Wenn beispielsweise die Gruppe der F\u00e4lle aus 70 % M\u00e4nnern besteht, versucht man, eine Kontrollgruppe zu rekrutieren, bei denen der Anteil der M\u00e4nner ebenso hoch ist. Die Faktoren, nach denen sinnvollerweise gematcht wird, sind abh\u00e4ngig von der Fragestellung. Folgendes ist zu beachten:\n\u0177 Praktische Probleme entstehen, wenn nach zu vielen Faktoren gematcht werden soll. Es ist dann schwierig oder gar vollkommen unm\u00f6glich, passende Kontrollen zu rekrutieren. \u0177 Konzeptionelle Probleme ergeben sich dadurch, dass ein Merkmal, nach dem gematcht wurde, nicht mehr als potentieller Risikofaktor evaluiert werden kann. Wenn beispielsweise in der Fall- und der Kontrollgruppe die Altersverteilung identisch ist, kann nicht mehr \u00fcberpr\u00fcft werden, ob das Alter in Zusammenhang mit der Krankheit steht. Deshalb sollte nur nach bereits bekannten Risikofaktoren gematcht werden. 14.3.4 Biasquellen Fall-Kontroll-Studien sind anf\u00e4llig f\u00fcr diverse systematische Fehler:\n\u0177 Selektionsbias. Dieser Fehler tritt auf, wenn sich die Fall- und die Kontrollgruppe in wesentlichen Eigenschaften (au\u00dfer der zu untersuchenden Krankheit) unterscheiden. Dies k\u00f6nnte das Endresultat der Studie entscheidend beeinflussen. Matching ist\n270\nKapitel 14 \u00b7 Risikostudien\neine Methode, diesem Bias zu begegnen. Falls dies nicht m\u00f6glich ist, sollte man versuchen, diesen Bias durch eine geschickte statistische Analyse (z. B. eine logistische Regression) aufzudecken. \u0177 Informations-Bias 1. Eine Fall-Kontroll-Studie birgt in sich die Gefahr eines Recall-Bias, eine besondere Form des Informationsbias. F\u00e4lle, die von der Krankheit unmittelbar betroffen sind, k\u00f6nnen sich an zur\u00fcckliegende Ereignisse oft besser erinnern als Kontrollen. Eine Mutter, die ein krankes Kind zur Welt gebracht \u203a Beispiel 14.2), wird sich an au\u00dfergew\u00f6hnliche Ereignisse hat (z zu Beginn ihrer Schwangerschaft wesentlich besser entsinnen als eine Mutter mit einem gesunden Baby, die derlei Vorkommnisse m\u00f6glicherweise l\u00e4ngst vergessen hat. Dies k\u00f6nnte zu einer \u00dcbersch\u00e4tzung eines Risikofaktors f\u00fchren und zu falschen Schlussfolgerungen verleiten. \u0177 Informations-Bias 2. Eine andere Art von Informationsbias liegt vor, wenn Partner oder Freunde als Kontrollen fungieren oder anstelle der F\u00e4lle (z. B. nach deren Tod) befragt werden. Sie tendieren h\u00e4ufig dazu, negative Eigenschaften \u201eihres Falles\u201c zu verschweigen oder zu verharmlosen. Auch betroffene F\u00e4lle geben nicht immer uneingeschr\u00e4nkt die Wahrheit preis \u2013 etwa wenn ihnen Fragen gestellt werden, die sie als peinlich empfinden. \u0177 Bias durch Confounder. Diese Gefahr ist bei Fall-Kontroll-Studien besonders gro\u00df. Wenn ein statistischer Zusammenhang zwischen einer Krankheit und einem \u00e4tiologischen Faktor nachgewiesen wird, folgt daraus nicht notwendigerweise, dass dieser Zusammenhang kausal ist. Es k\u00f6nnte sich auch um einen Confounder handeln. Ein solcher Einflussfaktor wird auch als Risikoindikator bezeichnet. Er weist auf ein erh\u00f6htes Risiko hin, ist aber selbst nicht f\u00fcr das Entstehen einer Krankheit verantwortlich.\n14\nBeispiel 14.1 Alkohol ist als Risikofaktor f\u00fcr das Auftreten einer Psoriasis (Schuppenflechte) identifiziert. Ein mit dem Alkoholkonsum assoziierter Faktor ist der Nikotinkonsum. Wenn in einer Fall-Kontroll-Studie nachgewiesen wird, dass Nikotinkonsum in Zusammenhang mit Psoriasis steht, mag es nahe liegend erscheinen, diese Assoziation als kausal anzusehen. In Wirklichkeit ist das Rauchen jedoch ein Confounder oder Risikoindikator. Pr\u00e4ventionsma\u00dfnahmen, die auf eine Verringerung des Nikotinkonsums ausgelegt w\u00e4ren, w\u00fcrden nicht zu einer Reduktion der Neuerkrankungen an Psoriasis f\u00fchren.\n271 14.3 Fall-Kontroll-Studien\n14\n14.3.5 Die Odds Ratio \u2022 Statistische Analyse. Im einfachsten Fall untersucht man den Zu \u203a Beispiel 14.2). sammenhang zwischen zwei Alternativmerkmalen (z Geeignete Methoden, um einen solchen Zusammenhang abzusi\u203a Abchern, sind der Chi2-Vierfeldertest oder Fisher\u2019s exakter Test (z schnitte 12.2.1 und 12.3). Bei Fall-Kontroll-Studien ist es \u00fcblich, zus\u00e4tzlich die Odds Ratio als Ann\u00e4herung f\u00fcr das relative Risiko angegeben. Diese Ma\u00dfzahl berechnet sich basierend auf den H\u00e4ufig\u203a Abschnitt 3.4.2): keiten der Vierfeldertafel als (z OR =\nad bc\nDie Odds Ratio ist 1, falls kein Zusammenhang zwischen der Erkrankung und der Exposition besteht. Sie ist gr\u00f6\u00dfer als 1, wenn mehr F\u00e4lle als Kontrollen exponiert sind. Um beurteilen zu k\u00f6nnen, ob der Zusammenhang signifikant ist, sollte zus\u00e4tzlich ein Konfidenzintervall angeben werden. Beispiel 14.2 Wir betrachten eine (hypothetische) Studie, in der 50 Frauen, die ein missgebildetes Baby zur Welt gebracht hatten (F\u00e4lle), befragt wurden, ob sie zu Beginn ihrer Schwangerschaft ein bestimmtes Medikament eingenommen hatten. Ihnen wurden 50 Frauen gegen\u00fcbergestellt, die ein gesundes Baby geboren hatten (Kontrollen) und ebenfalls befragt. Es ergab sich folgendes Bild: Daraus berechnet man: OR = 9,333 . Medikament F\u00e4lle Kontrollen Dies impliziert, dass Frauen, die dem genommen Risikofaktor ausgesetzt waren, ein ja a = 35 b = 10 9,3-fach erh\u00f6htes Risiko hatten. nein c = 15 d = 40 Das Konfidenzintervall erstreckt sich zwischen 3,72 und 23,42. Mit dem Chi2Vierfeldertest erh\u00e4lt man p < 0,0001 . Damit ist der Zusammenhang zumindest statistisch abgesichert. i Die Odds Ratio quantifiziert das Verh\u00e4ltnis zwischen zwei Odds. Der z englische Begriff \u201eOdds\u201c hat die Bedeutung von Gewinnchancen bei Wetteins\u00e4tzen. Die \u201eChance\u201c der Fallgruppe, einem Risiko ausgesetzt gewesen zu sein, ist a / c ; bei den Kontrollen ist diese \u201eChance\u201c b / d . Der Quotient dieser beiden Odds ist die Odds Ratio.\nBei paarweisem Matchen verwendet man anstelle des Vierfeldertests \u203a Abschnitt 12.2.5). Die Odds Ratio wird in den McNemar-Test (z diesem Fall als der Quotient b / c bestimmt (wobei b die Anzahl der Paare, bei denen der Fall exponiert und die Kontrolle nicht expo-\n272\nKapitel 14 \u00b7 Risikostudien\nniert ist und c die Anzahl der Paare, bei denen es umgekehrt ist). Wenn mehr als ein potentieller Risikofaktor zu analysieren ist, bietet sich die Logistische Regression an. Diese multiple Methode ist insbesondere bei Fall-Kontroll-Studien sehr m\u00e4chtig:\n\u0177 Mehrere Einflussgr\u00f6\u00dfen (qualitative und auch quantitative wie etwa das Alter) k\u00f6nnen simultan analysiert werden;\n\u0177 die Wirkung einer Einflussgr\u00f6\u00dfe l\u00e4sst sich adjustieren (so k\u00f6nnen m\u00f6gliche Confounder erkannt werden);\n\u0177 f\u00fcr jede Einflussgr\u00f6\u00dfe l\u00e4sst sich die dazugeh\u00f6rende Odds Ratio mit Konfidenzintervall berechnen. 14.3.6 Anwendungen und Grenzen Fall-Kontroll-Studien sind unverzichtbar f\u00fcr die Erforschung von Risikofaktoren. Ein immenser Vorteil liegt darin, dass man nicht Jahre oder Jahrzehnte lang warten muss, bis man gen\u00fcgend \u201eF\u00e4lle\u201c rekrutiert hat, sondern auf bereits erkrankte Personen zur\u00fcckgreifen kann. Ergebnisse liegen deshalb relativ schnell vor. Dies ist besonders wichtig bei Krankheiten mit langer Latenzzeit oder geringer Inzidenz. Die Nachteile liegen wie bei allen retrospektiven Studien in der eventuell mangelhaften Datenqualit\u00e4t. Au\u00dferdem sind FallKontroll-Studien sehr anf\u00e4llig f\u00fcr Bias verschiedener Art. Einschr\u00e4nkend ist hinzuzuf\u00fcgen, dass absolute Risiken (etwa Inzidenzen) f\u00fcr Exponierte oder Nicht-Exponierte nicht ermittelt werden k\u00f6nnen; lediglich das Odds Ratio kann bestimmt werden. Dieses Ma\u00df ist eine Ann\u00e4herung f\u00fcr das relative Risiko \u2013 allerdings nur dann, wenn die Inzidenz der Erkrankung gering ist (maximal 1 %). Diese Bedingung ist gl\u00fccklicherweise bei vielen Krankheiten, die mit Fall-Kontroll-Studien untersucht werden, erf\u00fcllt.\n14.4\n14\nKohortenstudien\n14.4.1 Grundlagen Eine Kohortenstudie ist eine prospektive, longitudinale Studie (auch Follow-Up-Studie genannt), bei der gro\u00dfe Gruppe (Kohorte) von Personen, die in unterschiedlicher Weise exponiert und nicht erkrankt sind, eine Zeit lang beobachtet werden.\n273 14.4 Kohortenstudien\n14\nBeispiel 14.3 Ein bekanntes Beispiel ist die so genannte Framingham-Studie bez\u00fcglich kardiovaskul\u00e4rer Krankheiten. Sie wurde im Jahr 1948 in der Stadt Framingham (USA) begonnen und umfasste etwa 5.100 Einwohner, die zu Beginn der Studie zwischen 30 und 60 Jahre alt waren und keine kardiovaskul\u00e4ren Krankheiten hatten. Die Studie dauerte mehr als 30 Jahre; die Studienteilnehmer wurden regelm\u00e4\u00dfig alle zwei Jahre bis zum Auftreten einer kardiovaskul\u00e4ren Erkrankung, Tod des Teilnehmers bzw. Studienende untersucht. Dabei wurden mehrere potentielle Einflussfaktoren studiert: Rauchen, Adipositas, Bluthochdruck, erh\u00f6hte Cholesterinwerte, Alter u. a. Es wurde nachgewiesen, dass das Risiko, eine koronare Herzkrankheit zu entwickeln, mit zunehmendem Alter, erh\u00f6htem Blutdruck, erh\u00f6htem Cholesterinspiegel, Zigaretten- und Alkoholabusus sowie \u00dcbergewicht assoziiert ist.\n\u2022 Vorteile. Anhand des Beispiels 14.3 werden die Vorteile einer Ko hortenstudie unmittelbar deutlich: \u0177 Man kann die Inzidenzen f\u00fcr exponierte und nicht-exponierte Personen direkt ermitteln und vergleichen. Deshalb werden diese Studien auch als Inzidenzstudien bezeichnet. \u0177 Die Studie folgt derselben Logik wie die klinische Fragestellung: Man geht von den Einflussgr\u00f6\u00dfen aus, wartet ab und analysiert schlie\u00dflich, bei welchen Personen und zu welchem Zeitpunkt die Krankheit eintritt. \u0177 Die Studienteilnehmer werden kontinuierlich beobachtet. Die Gefahr eines Recall-Bias aufgrund mangelnden Erinnerungsverm\u00f6gens der Teilnehmer (wie bei Fall-Kontroll-Studien) besteht daher nicht. \u2022 Nachteile. Im Vergleich zu Fall-Kontroll-Studien gibt es auch deutliche Nachteile: \u0177 Es dauert unter Umst\u00e4nden sehr lange, bis hinreichend viele Krankheitsf\u00e4lle eingetreten sind. Dies gilt insbesondere bei Krankheiten mit langer Latenzzeit. \u0177 Die Studie erfordert \u2013 speziell bei Krankheiten mit geringer Inzidenz \u2013 extrem viele Teilnehmer. \u0177 Sie kann daher sehr aufwendig und teuer sein, da oft Tausende von Personen etliche Jahre lang in regelm\u00e4\u00dfigen Abst\u00e4nden untersucht werden m\u00fcssen. 14.4.2 Effektma\u00dfe Um zu eruieren, ob ein bestimmter Faktor tats\u00e4chlich mit einem erh\u00f6hten Erkrankungsrisiko assoziiert ist, erscheint es sinnvoll, die\n274\nKapitel 14 \u00b7 Risikostudien\nGruppen der Exponierten und der Nicht-Exponierten miteinander zu vergleichen. Das Erkrankungsrisiko bei Vorliegen eines Faktors R entspricht der Wahrscheinlichkeit P( K | R ) . P( K | R ) ist also die Wahrscheinlichkeit, dass bei Nicht-Vorhandensein des Faktors R die Krankheit entsteht. Es lassen sich folgende Effektma\u00dfe berechnen:\n\u0177 Absolute Risikoreduktion (zuschreibbares oder attributables Risiko). Dies ist die Differenz\nARR = P( K | R) \u2212 P( K | R )\n(14.1)\nDie ARR gibt an, in welchem Ma\u00df die Erkrankungswahrscheinlichkeit durch den Risikofaktor erh\u00f6ht wird.\n\u0177 Number Needed to Treat (NNT). Diese Anzahl wird sehr einfach berechnet nach: NNT = 1 / ARR\n(14.2)\nDie NNT wurde urspr\u00fcnglich f\u00fcr Therapiestudien entwickelt, um darzustellen, wie viele Personen durchschnittlich behandelt werden m\u00fcssen, damit eine von der Behandlung profitiert. Bei Risikostudien quantifiziert die NNT die Anzahl der Personen, die vom Risikofaktor befreit werden m\u00fcssen, damit eine profitiert.\n\u0177 Relatives Risiko. Darunter versteht man den Quotienten RR =\nP( K | R) P( K | R )\n(14.3)\nWenn es sich bei R tats\u00e4chlich um einen Risikofaktor handelt, ist das relative Risiko gr\u00f6\u00dfer als 1. Um dies beurteilen zu k\u00f6nnen, ist die Angabe eines Konfidenzintervalls sinnvoll.\n\u0177 Relative Risikoreduktion. Dieses Ma\u00df ist definiert als:\n14\nRRR =\nP( K | R) \u2212 P( K | R ) P( K | R)\n(14.4)\n! Bei der Interpretation eines relativen Risikos ist zu beachten, dass durch z\ndie Quotientenbildung die absoluten Risiken nicht mehr erkennbar sind. Die relativen Risiken in Beispiel 14.4 sind sehr hoch. Sie verschweigen jedoch, dass das Risiko an Lungenkrebs zu erkranken generell gering ist (auch f\u00fcr Raucher).\n275 14.4 Kohortenstudien\n14\nBeispiel 14.4 In der Kohortenstudie von Doll und Hill (Doll, R.; Hill, A.B.: Mortality in relation to smoking: ten years\u2019 observations of British doctors. Brit. Med. J. 1964; 1: 1399 \u2013 1410) wurde bei 40.000 britischen \u00c4rzten die Auswirkung des Faktors \u201eRauchen\u201c auf die Mortalit\u00e4tsrate bei Lungenkrebs untersucht. Seien R das Ereignis, dass eine Person mindestens 25 Zigaretten pro Tag raucht und T das Ereignis, innerhalb eines Jahres an Lungenkrebs zu sterben. Die Autoren ermittelten P(T | R) = 2,27 \u2030 f\u00fcr Raucher und P(T | R ) = 0,07 \u2030, f\u00fcr Nichtraucher. Demnach betr\u00e4gt das zuschreibbare Risiko ARR = 2,2 \u2030. Die Mortalit\u00e4t setzt sich zusammen aus dem Anteil 2,20\u2030, der dem Rauchen zuzurechnen ist, und dem kleineren Anteil 0,07\u2030, der auf andere Ursachen zur\u00fcckzuf\u00fchren ist. Daraus ergibt sich: NNT = 1 / 0,0022 \u2248 455 . Wenn 455 starke Raucher das Rauchen aufgeben w\u00fcrden, w\u00fcrde durchschnittlich einer pro Jahr weniger an Lungenkrebs sterben. Das relative Risiko berechnet sich nach (14.3) als 32. Also ist f\u00fcr einen Raucher das Risiko, innerhalb eines Jahres an Lungenkrebs zu sterben, etwa 32mal so gro\u00df wie f\u00fcr einen Nichtraucher. Die relative Risikoreduktion nach (14.4) betr\u00e4gt 97%. Das Risiko, an Lungenkrebs zu sterben, kann demnach um 97 % gesenkt werden, falls das Rauchen aufgeben wird. Oder anders formuliert: Wenn ein Mensch an Lungenkrebs stirbt, dann ist dies zu 97 % auf das Rauchen zur\u00fcckzuf\u00fchren.\nDie Wahrscheinlichkeit des Auftretens einer Krankheit kann durch die Logistische Regression ermittelt werden. Dieses multiple Verfahren erm\u00f6glicht es, mehrere Faktoren zu ber\u00fccksichtigen und deren komplexe Wechselwirkungen zu untersuchen. Anhand der Merkmale, die einen statistisch signifikanten Einfluss auf die Zielgr\u00f6\u00dfe haben, l\u00e4sst sich dann im Einzelfall die Wahrscheinlichkeit berechnen, dass die Krankheit eintritt. 14.4.3 Inzidenzma\u00dfe Die im vorigen Abschnitt erw\u00e4hnte Wahrscheinlichkeit P( K | R) wird als \u201ekumulative Inzidenz\u201c bezeichnet (weil sich die neuen F\u00e4lle \u00fcber die Zeit kumulieren). Deren Bestimmung erfordert eine gewisse Stabilit\u00e4t der beobachteten Population. Normalerweise ist jedoch davon auszugehen, dass die Population dynamischen Prozessen unterliegt. Nicht jedes Individuum kann \u00fcber denselben Zeitraum beobachtet werden. Au\u00dferdem muss quasi bei jeder prospektiven Studie einkalkuliert werden, dass einige Teilnehmer vorzeitig ausscheiden (so genannte Studienabbrecher oder Drop Outs). Dann mag die Inzidenzdichte eine Alternative darstellen: Der Z\u00e4hler dieses Ma\u00dfes enth\u00e4lt die Anzahl aller w\u00e4hrend der Beobachtungszeit neu aufgetretenen Krankheitsf\u00e4lle. Den Nenner bildet die\n276\nKapitel 14 \u00b7 Risikostudien\nso genannte Personenzeit \u2013 das ist die Summe der Beobachtungszeiten aller Individuen. Jedes Individuum wird so lange beobachtet, bis das interessierende Endereignis (Krankheit oder Tod) festgestellt wird. Falls dieses Ereignis nicht eintritt, endet die Beobachtungszeit am Ende der Studie bzw. zu dem Zeitpunkt, an dem die betreffende Person vorzeitig ausscheidet. Die Inzidenzdichte ist \u2013 im Gegensatz zur kumulativen Inzidenz \u2013 keine Wahrscheinlichkeit. Sie gibt an, wie viele Neuerkrankungen in einer bestimmten Zeiteinheit eintreten und ist insofern vergleichbar mit einer Erkrankungs-Geschwindigkeit oder mit der Hazard\u203a Abschnitt 8.4.1). Dabei spielt die Zeit eine besondere Rolle. Rate (z F\u00fcr derlei Fragestellungen stehen spezielle Auswertemechanismen \u203a Abschnitt 16.2.3). zur Verf\u00fcgung (z 14.4.4 Biasquellen\n14\nStudienabbrecher (Drop Outs) k\u00f6nnen zu einem Selektionsbias f\u00fchren, wenn die Gr\u00fcnde des Ausscheidens mit der Zielgr\u00f6\u00dfe in Zusammenhang stehen. Ferner kann es passieren, dass Teilnehmer ihre Gewohnheiten im Laufe der Zeit \u00e4ndern (wenn etwa aus einem ehemals starken Raucher ein Nichtraucher wird). Dies sollte bei der Auswertung unbedingt ber\u00fccksichtigt werden. Eine besondere Art von Informationsbias tritt auf, wenn Studienteilnehmer, die stark exponiert sind, h\u00e4ufiger oder gr\u00fcndlicher untersucht werden als andere Personen, bei denen das Eintreten einer Krankheit weniger erwartet wird. Dies kann zu verzerrten Ergebnissen f\u00fchren. Probleme k\u00f6nnen auch dadurch entstehen, dass sich die Diagnosetechniken im Laufe der Zeit \u00e4ndern oder dass die urspr\u00fcngliche Fragestellung an Relevanz verliert. Ein letzter Hinweis: Nicht jede Kohortenstudie muss Jahrzehnte dauern, ehe Ergebnisse vorliegen. Wenn die Zeitspanne zwischen Exposition und dem Auftreten einer Erkrankung kurz ist (z. B. Erkrankung eines Neugeborenen infolge einer m\u00fctterlichen Infektion w\u00e4hrend der Schwangerschaft), kann die Studie nach wenigen Monaten beendet sein. Dennoch bleibt festzuhalten, dass der zeitliche Aufwand wesentlich h\u00f6her ist als bei einer Fall-Kontroll-Studie. 14.4.5 Spezielle Kohortenstudien Die Population, die bei Kohortenstudien untersucht wird, wird meist in der Gegenwart zusammengestellt und dann \u00fcber einen l\u00e4ngeren Zeitraum beobachtet (\u201ebegleitende Kohortenstudie\u201c). Auf die damit\n277 14.5 Der Nachweis einer Kausalit\u00e4t\n14\nverbundenen Problematiken (die insbesondere bei Krankheiten mit langer Latenzzeit und geringer Inzidenz auftreten) wurde bereits hingewiesen. Bei Studien, die auf eine sehr lange Zeit geplant sind, wei\u00df der Versuchsleiter h\u00e4ufig nicht, ob er das Ende der Studie \u00fcberhaupt erleben wird. Es ist aber auch denkbar, Kohortenstudien \u201emit Versp\u00e4tung\u201c durchzuf\u00fchren: Man startet in der Vergangenheit und greift zur Erfassung der Exposition und der Zielgr\u00f6\u00dfe auf bereits dokumentierte Daten zur\u00fcck. Diese wertet man dann prospektiv aus (die Art der Datenerfassung ist jedoch retrospektiv). Dieses Design nennt man historische Kohortenstudie. Andere Bezeichnungen sind retrospektive oder konkurrierende Kohortenstudie oder Kohortenstudie mit zur\u00fcckverlegtem Ausgangspunkt. Dieser Studientyp wird gerne in der Arbeitsmedizin verwendet (wenn z. B. Bergwerksarbeiter und B\u00fcroangestellte auf das Vorhandensein einer Silikoselunge untersucht werden). Der Vorteil besteht darin, dass die Zeit zwischen der Exposition und dem Auftreten der Krankheit nicht abgewartet werden muss. Andererseits ist auf die Qualit\u00e4t der Daten nicht immer Verlass. Eine weitere Besonderheit stellen die so genannten eingebetteten (nested) Fall-Kontroll-Studien dar. Ein solche Studie beginnt wie eine Kohortenstudie in der Gegenwart. Zu Beginn werden von allen Studienteilnehmern Daten erhoben, Blut- oder Urinproben entnommen und in geeigneter Weise aufbewahrt. Wenn nach einiger Zeit gen\u00fcgend Krankheitsf\u00e4lle aufgetreten sind, werden diese zu einer \u201eFallgruppe\u201c zusammengefasst; aus den nicht erkrankten Teilnehmern wird eine \u00fcberschaubare Kontrollgruppe gebildet. Erst wenn diese beiden Gruppen definiert sind, werden deren Daten und Laborproben analysiert. Dieses Studiendesign ist wesentlich weniger aufwendig als eine begleitende Kohortenstudie, bei der alle Teilnehmer untersucht werden. Au\u00dferdem ist die Datenqualit\u00e4t besser als bei Fall-Kontroll-Studien, da die Daten erhoben und die Proben entnommen werden, ehe die Krankheit eingetreten ist.\n14.5\nDer Nachweis einer Kausalit\u00e4t\nEine kausale Beziehung zwischen einem Risikofaktor und einer Krankheit kann am ehesten durch ein Experiment nachgewiesen werden, bei dem die H\u00e4lfte der Teilnehmer nach Randomisation einem Risiko ausgesetzt wird und die andere H\u00e4lfte nicht. Aus ethischen Gr\u00fcnden ist dies jedoch nicht vertretbar. Laborexperimente\n278\nKapitel 14 \u00b7 Risikostudien\n(z. B. mit Ratten) k\u00f6nnen hier, obwohl sie in einem anderen biologischen System arbeiten, Hinweise zur Kausalit\u00e4t geben. Ansonsten ist man auf Beobachtungsstudien angewiesen. Den h\u00f6chsten Level nach den Richtlinien der Evidenzbasierten Medizin haben dabei Kohortenstudien. Diese sind \u2013 wenn sie sorgf\u00e4ltig geplant und durchgef\u00fchrt werden \u2013 am wenigsten anf\u00e4llig f\u00fcr systematische Fehler (Bias) und lassen am ehesten Schlussfolgerungen bez\u00fcglich Kausalit\u00e4ten zu. Das bedeutet jedoch nicht, dass die anderen Studienformen \u00fcberfl\u00fcssig oder generell minderwertig w\u00e4ren. Kohortenstudien sind in der Regel sehr aufwendig. Sie werden deshalb erst dann durchgef\u00fchrt, wenn \u2013 etwa aufgrund von Fall-Kontroll-Studien \u2013 gesicherte Hinweise auf eine Assoziation zwischen einer Krankheit und einer Exposition vorliegen. Im Jahre 1939 brachte der bereits erw\u00e4hnte Alton Ochsner eine Lawine ins Rollen, als er einen Fallbericht ver\u00f6ffentlichte, in dem er einen Zusammenhang zwischen Lungenkrebs und Rauchen vermutete und zwei Jahre sp\u00e4ter eine Fallserie zum selben Thema publizierte. Dies war der Anlass f\u00fcr Doll und Hill, eine Fall-Kontroll-Studie durchzuf\u00fchren (1952 publiziert). Diese wiederum war die Basis f\u00fcr eine extrem aufwendige Kohorten\u203a Beispiel 14.4, erstmals 1964 publiziert). studie (z Man kann zwar mit Beobachtungsstudien nicht zweifelsfrei eine Kausalit\u00e4t nachweisen. Es gibt jedoch Argumente, die f\u00fcr einen kausalen Zusammenhang sprechen und Richtlinien, an denen man sich orientieren kann:\n\u0177 Die Exposition muss der Krankheit zeitlich vorausgehen. \u0177 Je st\u00e4rker ein statistischer Zusammenhang ist, desto mehr spricht f\u00fcr eine kausale Beziehung.\n\u0177 Eine Dosis-Wirkungs-Beziehung ist ebenfalls ein Hinweis auf eine Kausalit\u00e4t.\n\u0177 Die Ergebnisse der Studie m\u00fcssen wiederholbar sein (auch in anderen Populationen).\n14\n\u0177 Der Zusammenhang muss biologisch plausibel sein. \u0177 Das Risiko einer Erkrankung sinkt, wenn die Exposition entf\u00e4llt. Bei einfachen deskriptiven Studien mag die \u00dcberpr\u00fcfung dieser Richtlinien schwierig sein. Bei Fall-Kontroll- und insbesondere bei Kohortenstudien sind sie jedoch sehr n\u00fctzlich bei der Beurteilung, ob ein Faktor kausal f\u00fcr eine Krankheit verantwortlich ist oder ob es sich allem Anschein nach um einen Confounder handelt. i Ausf\u00fchrliche Informationen zu Risikostudien findet man in [6]. z\n15\nStudien zu Diagnostik und Pr\u00e4vention 15.1\nDiagnosestudien 281\n15.1.1 Einleitende Bemerkungen\n281\n15.1.2 Die Validit\u00e4t eines diagnostischen Tests 281 15.1.3 Die ROC-Analyse 282 15.1.4 Reproduzierbarkeit 285 15.1.5 Die Anwendung eines diagnostischen Tests in der Praxis 287\n15.2\nPr\u00e4ventionsstudien 288\n15.2.1 Formen der Pr\u00e4vention 288 15.2.2 Evaluation des Nutzens 289 15.2.3 Biasquellen 291\n281\n15\n15.1 Diagnosestudien\n15.1\nDiagnosestudien\n15.1.1 Einleitende Bemerkungen Die Diagnosestellung geh\u00f6rt zu den wichtigsten Aufgaben eines Arztes. Dazu bedient er sich au\u00dfer seiner Fachkenntnisse und seiner pers\u00f6nlichen Erfahrung eines oder mehrerer diagnostischer Testverfahren. Dies kann ein technisch aufwendiger Labortest sein; es kann sich jedoch auch um eine klinische Untersuchung, ein bildgebendes Verfahren, um Informationen aus der Anamnese oder aus einem Gespr\u00e4ch mit dem Patienten handeln. Diagnosestudien sind f\u00fcr die epidemiologische Forschung und die medizinische Praxis sehr wichtig. Letzten Endes basieren die Ergebnisse fast aller Studien auf diagnostischen Verfahren, da diese ja die Voraussetzung f\u00fcr das Erkennen einer Krankheit sind. Zu den G\u00fctekriterien eines diagnostischen Verfahrens z\u00e4hlen die Validit\u00e4t und die Reliabilit\u00e4t. Die Validit\u00e4t ist die F\u00e4higkeit, zwi\u203a Abschnitt schen Kranken und Gesunden zu unterscheiden (z 15.1.2). Die Reliabilit\u00e4t ist ein Ma\u00df f\u00fcr die Reproduzierbarkeit der \u203a Abschnitt 15.1.4). Testergebnisse unter \u00e4hnlichen Bedingungen (z 15.1.2 Die Validit\u00e4t eines diagnostischen Tests Die Validit\u00e4t eines diagnostischen Tests wird durch die Sensitivit\u00e4t \u203a Abschnitt 6.5.1). Es ist das Ziel einer und die Spezifit\u00e4t bestimmt (z Diagnosestudie, diese Komponenten zu quantifizieren. In der Regel ist ein aufwendiges, teures oder kompliziertes Verfahren (z. B. eine Biopsie) notwendig, um Gewissheit bez\u00fcglich des Krankheitsstatus einer Person zu erhalten. Ein solches Verfahren nennt man Goldstandard. Im medizinischen Alltag ist man \u00f6fter bem\u00fcht, Ersatzverfahren zu benutzen \u2013 wohl wissend, dass diese weniger genau, daf\u00fcr aber einfacher in der Anwendung und mitunter weniger riskant sind als der Goldsstandard. Bei einer Diagnosestudie ist ein Goldstandard notwendig, um den wahren Krankheitsstatus der Testpersonen feststellen zu k\u00f6nnen. Um die Sensitivit\u00e4t und die Spezifit\u00e4t zu ermitteln, m\u00fcssen hinreichend viele kranke und nicht-erkrankte Personen durch den zu evaluierenden Test diagnostiziert werden. Der Arzt, der die Befunde interpretiert, sollte verblindet sein. Das hei\u00dft: Er darf den wahren Krankheitsstatus und andere klinische Informationen der Testteilnehmer nicht kennen. Nur dann ist gew\u00e4hrleistet, dass die\n282\nKapitel 15 \u00b7 Studien zu Diagnostik und Pr\u00e4vention\nBefunde unvoreingenommen und objektiv beurteilt werden. Beide Kenngr\u00f6\u00dfen \u2013 Sensitivit\u00e4t und Spezifit\u00e4t \u2013 sollten zusammen mit einem Konfidenzintervall angegeben werden, damit die Genauigkeit der Sch\u00e4tzungen beurteilt werden kann. Manchmal werden auch Likelihood-Quotienten benutzt, um die G\u00fcte eines diagnostischen Tests zu beschreiben. Der positive Likelihood-Quotient ist die Wahrscheinlichkeit, dass eine kranke Person einen positiven Befund erh\u00e4lt, dividiert durch die Wahrscheinlichkeit, dass sich dieser Befund bei einer gesunden Person ergibt: LH + =\nP(T+ K ) P(T+ K )\n=\nSensitivit\u00e4t 1 \u2212 Spezifit\u00e4t\n(15.1)\nAnalog ist der negative Likelihood-Quotient definiert als: LH \u2212 =\nP(T\u2212 K ) P(T\u2212 K )\n=\n1 \u2212 Sensitivit\u00e4t Spezifit\u00e4t\n(15.2)\nWenn ein Likelihood-Quotient einen Wert nahe bei 1 annimmt, ist der Test unbrauchbar. Je gr\u00f6\u00dfer der positive Likelihood-Quotient und je kleiner der negative, desto leistungsf\u00e4higer ist der Test. Bei einem Likelihood-Quotienten sind die Sensitivit\u00e4t und die Spezifit\u00e4t in einer Kenngr\u00f6\u00dfe zusammengefasst. Daher eignen sich diese Quotienten, um die G\u00fcte mehrerer Tests miteinander zu vergleichen. 15.1.3 Die ROC-Analyse\n15\nDie meisten Testergebnisse beruhen auf physikalischen Messungen im Labor. Bei solchen Gr\u00f6\u00dfen handelt es sich in der Regel um stetige Merkmale \u2013 und nicht, wie bisher angenommen wurde, um Alternativmerkmale mit den Auspr\u00e4gungen \u201epositiv\u201c und \u201enegativ\u201c. Um eine bin\u00e4re Testentscheidung zu erm\u00f6glichen, wird eine Trenngr\u00f6\u00dfe \u03c4 (griechischer Buchstabe tau) festlegt \u2013 das ist ein Schwellenwert, der den pathologischen vom physiologischen Bereich trennt. Der Messwert einer Person, die sich dem Test unterzieht, wird mit diesem Schwellenwert verglichen. Ist er gr\u00f6\u00dfer als \u03c4, spricht man von einem positiven, ansonsten von einem negativen Befund. Der Wert von \u03c4 beeinflusst die Sensitivit\u00e4t, die Spezifit\u00e4t und damit auch die Vorhersagewerte.\n283\n15\n15.1 Diagnosestudien\nJedem Schwellenwert sind eindeutige Werte f\u00fcr die Sensitivit\u00e4t und die Spezifit\u00e4t zugeordnet. Wenn man nun f\u00fcr jeden Schwellenwert den Anteil der falsch positiven (also die Differenz \u201e1 \u2013 Spezifit\u00e4t\u201c) gegen den Anteil der richtig positiven (also die Sensitivit\u00e4t) in ein Koordinatensystem eintr\u00e4gt und diese Punkte miteinander verbin\u203a Abbildung 15.1). ROC ist die det, entsteht die ROC-Kurve (z Abk\u00fcrzung f\u00fcr \u201eReceiver Operating Characteristic\u201c. Dieser Begriff stammt aus der Nachrichtentechnik und bedeutet Signalerkennung. Aus dem Beispiel 15.1 und der ROC-Kurve in Abbildung 15.1 geht hervor: Je h\u00f6her die Sensitivit\u00e4t, desto geringer ist die Spezifit\u00e4t. Dies ist leicht nachvollziehbar. Bei einem geringen Schwellenwert erhalten zahlreiche Personen ein positives Testergebnis. Dadurch werden einerseits viele Kranke (richtig) positiv und andererseits zahlreiche Gesunde (falsch) positiv klassifiziert. Dies ist gleichbedeutend mit einer hohen Sensitivit\u00e4t und einer hohen Wahrscheinlichkeit f\u00fcr falsch positive Ergebnisse, was wiederum mit einer niedrigen Spezifit\u00e4t einhergeht. Ein hoher Schwellenwert ergibt dagegen f\u00fcr die meisten gesunden und f\u00fcr relativ viele kranke Personen einen negativen Befund (hohe Spezifit\u00e4t, hohe Wahrscheinlichkeit f\u00fcr falsch negative Ergebnisse und geringe Sensitivit\u00e4t). Schwellenwerte, die gut zwischen Kranken und Gesunden diskriminieren, findet man in der oberen linken Ecke der ROC-Kurve. Die Frage nach dem optimalen Schwellenwert l\u00e4sst sich nicht allgemein beantworten. Er ist abh\u00e4ngig von den Konsequenzen, die sich aus falschen Testbefunden ergeben. Ein falsch negativer Befund kann fatale Folgen f\u00fcr den Patienten haben (dieser w\u00e4hnt sich zun\u00e4chst gesund und wird m\u00f6glicherweise zu sp\u00e4t oder gar nicht therapiert). Falsch positive Befunde belasten zun\u00e4chst die betreffenden Personen und f\u00fchren zu nachfolgenden Behandlungen, die unn\u00f6tig, teuer und mitunter gef\u00e4hrlich sind. Auf eine hohe Sensitivit\u00e4t legt man Wert, wenn \u0177 es sich um eine Krankheit mit schweren (oder gar lebensbedrohlichen) Folgen f\u00fcr den Patienten handelt, \u0177 eine Erfolg versprechende Therapie zur Verf\u00fcgung steht, \u0177 falsch positive Befunde mit vertretbarem Aufwand und ohne allzu gro\u00dfe Belastungen f\u00fcr die betreffende Person gekl\u00e4rt werden k\u00f6nnen. Eine hohe Spezifit\u00e4t ist anzustreben, wenn\n\u0177 keine Therapie mit Aussicht auf Besserung bekannt ist, \u0177 die Therapie zu unverh\u00e4ltnism\u00e4\u00dfig hohen finanziellen Belastungen f\u00fcr den Patienten oder das Gesundheitswesen f\u00fchrt,\n284\nKapitel 15 \u00b7 Studien zu Diagnostik und Pr\u00e4vention\n\u0177 die Therapie mit schweren Nebenwirkungen behaftet ist, \u0177 die Nachfolgeuntersuchungen mit erheblichen Risiken oder psychischen Belastungen f\u00fcr den Patienten verbunden sind. Ein optimaler Schwellenwert beruht also nicht nur auf wahrscheinlichkeitstheoretischen, sondern auch auf medizinischen, \u00f6konomischen und ethischen \u00dcberlegungen. Ein Arzt muss bei der Interpretation eines Testbefundes in jedem Fall ber\u00fccksichtigen, dass dieses unter Umst\u00e4nden auch von einem mehr oder weniger willk\u00fcrlich festgelegten Schwellenwert abh\u00e4ngt. Die Gesamtgenauigkeit eines Tests l\u00e4sst sich durch die Fl\u00e4che unter der ROC-Kurve (im englischen Sprachgebrauch als AUC = \u201earea under the curve\u201c bezeichnet) quantifizieren. Nur bei einem Test, bei dem falsche Befunde ausgeschlossen sind, ist diese Fl\u00e4che gleich 1. Eine Fl\u00e4che der AUC von 0,5 besagt, dass der diagnostische Test nicht besser ist als zuf\u00e4llige Zuweisungen \u201ekrank\u201c oder \u201egesund\u201c. In diesem Fall entspricht die ROC-Kurve der Diagonalen, die sich von der linken unteren bis zur rechten oberen Ecke erstreckt.\n15\nBeispiel 15.1 Ist der Kreatininkinase-Wert zur Diagnose eines akuten Myokardinfarkts geeignet? In einer Studie ergaben sich bei Infarkt-Patienten Werte zwischen 90 und 10280, w\u00e4hrend Patienten mit anderen Herzbeschwerden Werte zwischen 25 und 370 aufwiesen. Die Sensitivit\u00e4t und die Spezifit\u00e4t sind abh\u00e4ngig von unterschiedlichen Schwellenwerten: Sensitivit\u00e4t Spezifizit\u00e4t Summe \u03c4 in % in % Wenn man die 100 48 80 148 Sensitivit\u00e4t und 100 57 90 157 die Spezifit\u00e4t als 96 62 100 158 gleich wichtig er96 75 120 171 achtet, w\u00e4re 96 84 \u03c4 = 300 der opti150 180 93 91 200 184 male Schwellen93 94 250 187 wert. Die Fl\u00e4che 93 97 unter der ROC300 190 85 98 320 183 Kurve (AUC) 70 99 350 169 betr\u00e4gt 0,94 \u203a Abb. 15.1). (z 63 100 380 163 55 100 400 155\n285\n15\n15.1 Diagnosestudien\nAbb. 15.1 ROC-Kurve f\u00fcr einen Test zur Diagnose eines Myokardinfarkts (Beispiel 15.1). Eingezeichnet sind (1\u2013Spezifit\u00e4t) auf der x\u2013Achse und die Sensitivit\u00e4t auf der y\u2013Achse f\u00fcr unterschiedliche Schwellenwerte.\nMerke Die ROC-Kurve kann genutzt werden,\n\u0177 \u0177\num einen optimalen Schwellenwert zu finden. Falls Sensitivit\u00e4t und Spezifit\u00e4t als gleich wichtig erachtet werden, ist dies der Schwellenwert, der am n\u00e4chsten am Punkt (0|1) des Koordinatensystems liegt. um konkurrierende Tests miteinander zu vergleichen. Je gr\u00f6\u00dfer die AUC, desto besser ist der Test.\n15.1.4 Reproduzierbarkeit Ein weiterer Aspekt bei der Bewertung eines diagnostischen Tests betrifft die Reproduzierbarkeit (Reliabilit\u00e4t) \u2013 also die Frage: Inwieweit ist der Test zuverl\u00e4ssig und wiederholbar? Viele Testbefunde sind durch subjektive Einsch\u00e4tzungen des jeweiligen Untersuchers gepr\u00e4gt oder h\u00e4ngen von anderen Rahmenbedingungen ab. Beispiele hierf\u00fcr stellen klinische Schweregradscores wie etwa der PASI (Psoriasis Area and Severity Index) dar. Es ist keineswegs selbstverst\u00e4ndlich, dass wiederholte Beurteilungen desselben Zustands durch unterschiedliche Beobachter jeweils zum selben Ergebnis f\u00fchren. Es ist auch nicht garantiert, dass derselbe Beobachter, der einen Patienten zu verschiedenen Zeitpunkten untersucht, jedes Mal denselben Befund erh\u00e4lt. Der \u03ba-Koeffizient nach Cohen (\u01c9: griechischer Buchstabe Kappa) findet Verwendung, um \u2013 wie in Beispiel 15.2 \u2013 den Grad der \u00dcbereinstimmung zwischen zwei verschiedenen Beobachtern (interindividuelle Variabilit\u00e4t) zu quantifizieren. Er kann auch verwendet werden, um den Grad der \u00dcbereinstimmung der Beurteilungen desselben Beobachters zu zwei verschiedenen Zeitpunkten (intraindividuelle Variabilit\u00e4t) zu messen. Er ist folgenderma\u00dfen definiert:\n286\nKapitel 15 \u00b7 Studien zu Diagnostik und Pr\u00e4vention\n\u03ba=\np o \u2212 pe 1 \u2212 pe\n(15.3)\nDabei sind po und pe die Anteile der \u00fcbereinstimmenden Urteile, die man beobachtet hat bzw. die man rein zuf\u00e4llig erwarten w\u00fcrde (o und e stehen f\u00fcr \u201eobserved\u201c bzw. \u201eexpected\u201c). Dieser Koeffizient quantifiziert demnach den Anteil von \u00dcbereinstimmungen, der \u00fcber das hinausgeht, was man unter dem Zufall erwarten w\u00fcrde. Wenn zwei Beobachter in allen Urteilen \u00fcbereinstimmen, ist \u03ba = 1 . Falls die Anzahl der \u00dcbereinstimmungen der Zufallserwartung entspricht, ist \u03ba = 0 . Theoretisch kann \u03ba auch negative Werte annehmen (dieser Fall ist aber praktisch bedeutungslos). \u03ba > 0,60 zeigt eine gute, \u03ba > 0,80 eine exzellente \u00dcbereinstimmung jenseits des Zufalls an. Beispiel 15.2 100 R\u00f6ntgenbilder werden von zwei Radiologen unabh\u00e4ngig voneinander bewertet. Es ergeben sich folgende Beurteilungen (in Klammer die H\u00e4ufigkeiten, die rein zuf\u00e4llig zu erwarten sind): Beobachter A erwartete H\u00e4ufigkeiten Beobachter B normal pathologisch \u03a3 40 (30) 10 (20) 50 normal e11 = e21 = 50 \u22c5 60 / 100 = 30 e12 = e22 = 50 \u22c5 40 / 100 = 20 30 (20) 50 pathologisch 20 (30) 60 \u03a3 Daraus ergibt sich:\n40\n100\npo = (40 + 30) / 100 = 0,70 , pe = (30 + 20) / 100 = 0,50 . Die\nUntersucher haben also in 70 % der F\u00e4lle \u00fcbereinstimmend geurteilt; der Anteil der rein zuf\u00e4llig zu erwartenden \u00dcbereinstimmungen betr\u00e4gt 50 %. 0,70 \u2212 0,50 Daraus resultiert nach Formel (15.3) \u03ba = = 0, 40 . Der Grad der 1 \u2212 0,50 \u00dcbereinstimmung ist also recht schwach.\nEs gibt au\u00dferdem einen erweiterten \u01c9-Koeffizienten, der sich eignet, um mehr als zwei Beobachter zu vergleichen. Au\u00dferdem wurde ein gewichteter \u03ba-Koeffizient entwickelt, mit dem Abweichungen je nach ihrem Schweregrad unterschiedlich gewichtet werden k\u00f6nnen.\n15\ni Diese Ma\u00dfzahlen sind ausf\u00fchrlich in [5] beschrieben. Zur weiteren Lekz t\u00fcre sei das Handbuch [6] empfohlen.\n287\n15\n15.1 Diagnosestudien\n15.1.5 Die Anwendung eines diagnostischen Tests in der Praxis Die Sensitivit\u00e4t und die Spezifit\u00e4t beschreiben die G\u00fcte eines diagnostischen Verfahrens aus der Sicht des Forschers, der den Test entwickelt. Mitunter erweist sich ein diagnostisches Verfahren in der Praxis als ungeeignet \u2013 trotz hoher Werte f\u00fcr Sensitivit\u00e4t und Spezifit\u00e4t. Dies kann vielf\u00e4ltige Gr\u00fcnde haben:\n\u0177 Interpretation des Testbefundes. Es ist bekannt, dass ein Testbefund nicht immer den korrekten Krankheitsstatus anzeigt. Die Vorhersagewerte informieren dar\u00fcber, inwieweit man sich auf \u203a Abschnitt 6.5.2). Wenn die Pr\u00e4einen Befund verlassen kann (z valenz gering ist, kann der positive Vorhersagewert \u2013 trotz hoher Werte f\u00fcr Sensitivit\u00e4t und Spezifit\u00e4t \u2013 extrem gering sein \u203a Beispiel 6.16). Ohne die Kenntnis, ob der Patient einer (z Risikogruppe angeh\u00f6rt und wie hoch deren Pr\u00e4valenz ist, ist ein Testbefund kaum zu interpretieren. \u0177 Patientenspektrum. Die Sensitivit\u00e4t und die Spezifit\u00e4t sind unabh\u00e4ngig von der Pr\u00e4valenz. Andererseits bleibt festzuhalten, dass die Beurteilung der Testbefunde teilweise subjektiven Einfl\u00fcssen der behandelnden \u00c4rzte unterliegt, und dass die Patienten, bei denen ein diagnostisches Verfahren in der Praxis eingesetzt wird, andere Charakteristika aufweisen als Personen, die an einer diagnostischen Studie teilnehmen. Dies gilt sowohl f\u00fcr die Patienten, die an der Krankheit leiden, als auch f\u00fcr nichterkrankte Personen. Davon werden wiederum die Sensitivit\u00e4t, die Spezifit\u00e4t und damit auch die Vorhersagewerte beeinflusst. \u0177 Informationsbias. Wenn ein Arzt aufgrund einer klinischen Untersuchung den Eindruck gewinnt, dass der Patient erkrankt ist, wird er versuchen, diesen Eindruck anhand des Testbefundes zu best\u00e4tigen. Umgekehrt wird er, wenn er glaubt der Patient sei nicht erkrankt, den Testbefund eventuell weniger aufmerksam begutachten. Aus diesen Gr\u00fcnden sollten die Beurteiler bei einer \u203a Abschnitt 15.1.2). diagnostischen Studie verblindet sein (z Diese \u00dcberlegungen zeigen, dass ein einzelnes Testergebnis normalerweise nicht ausreicht, um sich auf eine Diagnose festzulegen. Um den Diagnoseprozess effizienter zu gestalten, werden in der Praxis h\u00e4ufig mehrere Tests durchgef\u00fchrt (multiples Testen). Dabei sind grunds\u00e4tzlich zwei Vorgehensweisen denkbar:\n288\nKapitel 15 \u00b7 Studien zu Diagnostik und Pr\u00e4vention\n\u2022 Parallele Tests. Im klinischen Bereich oder bei Notfallpatienten werden oft mehrere Tests gleichzeitig (genauer: innerhalb einer kurzen Zeitspanne) angewandt. Ein Patient gilt als testpositiv, wenn bereits ein einziger Test einen positiven Befund ergibt. Dies f\u00fchrt zu einer hohen Sensitivit\u00e4t. Die Wahrscheinlichkeit, eine Krankheit zu \u00fcbersehen, ist bei diesem Prozedere gering. Allerdings ergeben sich dabei auch einige falsch positive Befunde. \u2022 Sequenzielle (oder serielle) Tests. Diese Strategie wird verwendet, wenn eine schnelle Diagnosestellung nicht erforderlich ist. Man beginnt mit einem einfachen, leicht anwendbaren Test. Nur wenn dessen Ergebnis positiv ist, f\u00fchrt man einen weiteren, aufwendigeren Test durch. Wenn das zweite Ergebnis negativ ist, gilt der Patient als testnegativ. Ansonsten wird eventuell ein zus\u00e4tzlicher Test herangezogen. Dieses Prozedere ist zeitintensiver als das parallele Testen; andererseits beansprucht es weniger Laborkapazit\u00e4t. Es f\u00fchrt zu einer gr\u00f6\u00dferen Spezifit\u00e4t und zu einer geringeren Sensitivit\u00e4t. Schlie\u00dflich sollte ein Arzt bei seiner Entscheidungsfindung sich nicht ausschlie\u00dflich auf die Ergebnisse diagnostischer Tests verlassen, sondern auch seine individuelle Erfahrung, sein pers\u00f6nliches Urteilsverm\u00f6gen sowie seine fachspezifischen Kenntnisse mit ein\u203a Abschnitt 16.3). flie\u00dfen lassen (z\n15.2\nPr\u00e4ventionsstudien\n15.2.1 Formen der Pr\u00e4vention Im allgemeinen Sprachgebrauch versteht man unter Pr\u00e4vention eine Ma\u00dfnahme, die einer unerw\u00fcnschten Entwicklung zuvorkommen soll. In diesem Sinne ist nahezu jede T\u00e4tigkeit eines Arztes als Pr\u00e4vention aufzufassen. In einem engeren Sinne werden unter diesem Begriff \u00e4rztliche oder gesundheitspolitische Ma\u00dfnahmen zusammengefasst, die der Verh\u00fctung oder Fr\u00fcherkennung von Krankheiten dienen. Man unterscheidet drei Ebenen der Pr\u00e4vention:\n15\n\u0177 Prim\u00e4re Pr\u00e4vention. Mit diesen Ma\u00dfnahmen soll das Auftreten einer Krankheit durch das Ausschalten der Ursachen verhindert werden. Ein Arzt betreibt beispielsweise prim\u00e4re Pr\u00e4vention, wenn er einen Patienten ermahnt, auf eine gesunde Lebensweise zu achten, oder wenn er jemanden gegen eine Krankheit impft. Ein Beispiel stellt die Impfung eines jungen M\u00e4dchens gegen\n289\n15\n15.2 Pr\u00e4ventionsstudien\nHPV 16 oder 18 dar mit dem Ziel, das Auftreten von Geb\u00e4rmutterhalskrebs zu verhindern. Auch kommunale Einrichtungen leisten prim\u00e4re Pr\u00e4vention, etwa wenn sie f\u00fcr sauberes Trinkwasser oder hygienisch einwandfreie Lebensmittel sorgen. Aufkl\u00e4rungskampagnen, die Menschen zum verantwortungsbewussten Umgang mit Genussmitteln sensibilisieren sollen, fallen ebenfalls unter diese Kategorie. \u0177 Sekund\u00e4re Pr\u00e4vention. Diese Form der Pr\u00e4vention hat zum Ziel, eine Entwicklungsst\u00f6rung oder eine Krankheit im Fr\u00fchstadium zu erkennen, sodass rechtzeitig interveniert werden kann, um die Progression oder den Tod zu verhindern. Dazu werden Screening-Untersuchungen durchgef\u00fchrt, meist in Arztpraxen oder anderen medizinischen Institutionen. Anders als bei der prim\u00e4ren Pr\u00e4vention wird jeder Teilnehmer gezielt auf das Vorhandensein einer Krankheit oder einer St\u00f6rung untersucht. Beispiele sind Krebsfr\u00fcherkennungsuntersuchungen wie etwa die Mammographie oder der PAP-Abstrich, durch den Vorstufen des Geb\u00e4rmutterhalskrebses erkannt werden sollen. Auch Fr\u00fcherkennungsuntersuchungen, die bei Kindern durchgef\u00fchrt werden, sind eine Form der sekund\u00e4ren Pr\u00e4vention. \u0177 Terti\u00e4re Pr\u00e4vention. Dieser Begriff bezieht sich auf manifest gewordene Krankheiten. Er umfasst Ma\u00dfnahmen, mit denen deren Folgeerscheinungen begrenzt werden sollen. Wichtig ist dies vor allem bei letalen Krankheiten wie Krebs oder AIDS. Der Tod kann durch diese Form der Pr\u00e4vention in aller Regel zwar nicht verhindert werden. Durch eine ad\u00e4quate medizinische Betreuung k\u00f6nnen jedoch die Lebensqualit\u00e4t verbessert und eventuell der Todeszeitpunkt hinausgez\u00f6gert werden. 15.2.2 Evaluation des Nutzens Im Allgemeinen wird die Notwendigkeit pr\u00e4ventiver Ma\u00dfnahmen kaum in Frage gestellt. Dies betrifft insbesondere die Formen der prim\u00e4ren Pr\u00e4vention, die im Laufe der vergangenen Jahre und Jahrzehnte dazu gef\u00fchrt haben, dass viele Krankheiten nunmehr ausgerottet sind oder zumindest r\u00fcckl\u00e4ufige Fallzahlen aufweisen. Ebenso wenig wird \u00fcber terti\u00e4re Pr\u00e4vention diskutiert. Niemand bestreitet, dass die bestm\u00f6gliche Unterst\u00fctzung manifest erkrankter Menschen ethisch geboten erscheint. Studien, die den Nutzen prim\u00e4rer oder terti\u00e4rer Pr\u00e4ventionsma\u00dfnahmen untersuchen sollen, erscheinen vor diesem Hintergrund nicht notwendig.\n290\nKapitel 15 \u00b7 Studien zu Diagnostik und Pr\u00e4vention\nAuch bei sekund\u00e4ren Pr\u00e4ventionsma\u00dfnahmen, insbesondere bei Screening-Untersuchungen, wird weithin die Meinung vertreten, dass sie in keinem Fall schaden k\u00f6nnen. Die zugrunde liegende Idee ist einleuchtend: Krankheiten sollen bereits in der pr\u00e4klinischen Phase entdeckt werden, ehe der Patient die ersten klinischen Symptome bemerkt. Zu diesem Zeitpunkt kann durch eine therapeutische Intervention eventuell verhindert werden, dass die Krankheit sich weiter ausbreitet und in ein Stadium gelangt, in dem eine Heilung nicht mehr m\u00f6glich ist. Dies klingt so \u00fcberzeugend, dass eine genaue \u00dcberpr\u00fcfung der Effizienz eines Screenings \u00fcberfl\u00fcssig erscheint. Andererseits haben Screening-Untersuchungen offensichtliche Nachteile: Man denke nur an falsch positive oder falsch negative \u203a Abschnitt 6.5), an die mit Befunde und deren Konsequenzen (z manchen Untersuchungen verbundenen Risiken, Unannehmlichkeiten oder an die Kosten. Aus diesen Gr\u00fcnden erscheinen Studien, die durchgef\u00fchrt werden, um die Validit\u00e4t und die Effizienz einer Screening-Ma\u00dfnahme objektiv zu beurteilen, geboten.\n15\nBeispiel 15.3 Die Bedeutung der Ma\u00dfzahlen in Abschnitt 14.4.2 in Zusammenhang mit Screening-Methoden sei an folgendem Beispiel verdeutlicht. Zugrunde liegen die Ergebnisse von 10 randomisierten Studien, die durchgef\u00fchrt wurden, um zu ermitteln, ob die regelm\u00e4\u00dfige Teilnahme am Mammographie-Screening das Risiko verringert, an Brustkrebs zu sterben (Kerlikowske K: Efficacy of screening mammography among women aged 40 to 49 years and 50 to 59 years: Comparision of relative and absolute benefit, Journal of the National Cancer Institute Monographs, 22, 79-86, 1997). Insgesamt hatten 500.000 Frauen in Europa und Nord-Amerika teilgenommen. Das Risiko, innerhalb des Beobachtungszeitraums von 10 Jahren an Brustkrebs zu versterben, betrug 3,6 / 1000 (ohne Screening) bzw. 2,9 / 1000. Daraus ergibt sich: ARR = 0,0007 ; NNT = 1.429 ; RR = 1,24 und RRR = 0,19 . Welches Ma\u00df eignet sich zur Darstellung des Nutzens? Die ARR macht deutlich, dass das Risiko durch Screening nur minimal gesenkt werden kann. Noch pr\u00e4gnanter kommt dies in der NNT zum Ausdruck: Wenn sich 1.429 Frauen regelm\u00e4\u00dfig screenen lassen, wird durchschnittlich eine profitieren und vom Tod durch Brustkrebs bewahrt bleiben. Das RR zeigt, dass dieses Risiko f\u00fcr Frauen ohne Screening etwa 1,24 mal so hoch ist wie f\u00fcr Frauen in der Screening-Gruppe \u2013 allerdings kommt nicht zum Ausdruck, dass diese Risiken generell sehr gering sind. G\u00e4nzlich irref\u00fchrend ist die RRR. Sie suggeriert, dass 19 % aller Frauen vom Screenen profitieren \u2013 in Wirklichkeit beziehen sich die 19 % nur auf die Frauen, die ohne Screening an Brustkrebs sterben.\n291\n15\n15.2 Pr\u00e4ventionsstudien\nDie Validit\u00e4t eines Screenings wird durch die Sensitivit\u00e4t und die \u203a Abschnitt 6.5.1). In der Praxis sind jedoch Spezifit\u00e4t beschrieben (z die Vorhersagewerte die Parameter des wesentlichen Interesses: Sie geben an, inwieweit man sich auf einen Testbefund verlassen kann. Dabei ist zu bedenken, dass die Pr\u00e4valenz der untersuchten Population in der Regel sehr gering ist. Daher ist der positive Vorhersagewert sehr klein, was wiederum problematisch bei der Interpretation eines Befundes ist. Die Effizienz l\u00e4sst sich beschreiben, indem man die Effektma\u00dfe aus Abschnitt 14.4.2 berechnet. An Beispiel 15.3 wird deutlich, dass der Nutzen oft kleiner ist als vielfach angenommen wird. Weitere Beispiele zu diesem Thema findet man in [7]. ! Die NNT (Number Needed to Treat) wird bei Screeningprogrammen auch z\nals NNS (Number Needed to Screen) bezeichnet.\n15.2.3 Biasquellen Bei Studien zu Pr\u00e4ventionsma\u00dfnahmen gibt es eine Reihe spezifischer, systematischer Fehler (Bias): \u2022 Freiwilligenbias. Dies ist eine besondere Form des Selektionsbias. Er kann auftreten, wenn ein Vergleich durchgef\u00fchrt wird zwischen Personen, die sich freiwillig einer Impfung oder einer Fr\u00fcherkennungsma\u00dfnahme unterziehen, und einer Gruppe von Personen, die dies nicht tun. Die Individuen der beiden Gruppen unterscheiden sich m\u00f6glicherweise \u2013 sei es bez\u00fcglich ihres Lebensstils oder des famili\u00e4ren Risikos oder aus anderen Gr\u00fcnden. Verzerrte Ergebnisse w\u00e4ren dabei vorprogrammiert. Um diesen Bias zu vermeiden, sollte der Nutzen einer pr\u00e4ventiven Ma\u00dfnahme im Rahmen einer randomisierten Studie evaluiert wer\u203a Abschnitt 16.1.3). Bei diesem Studiendesign entscheidet alden (z lein der Zufall, ob ein Teilnehmer an einem Fr\u00fcherkennungspro\u203a Beispiel 15.3). Reine Beobachtungsgramm teilnimmt oder nicht (z studien k\u00f6nnten zu unzul\u00e4ssigen Schlussfolgerungen f\u00fchren. \u2022 Lead Time Bias. Bei Patienten mit nicht heilbaren Tumoren, die sich einem Screening-Test unterziehen, werden die Tumore eher entdeckt als bei anderen Patienten. Die Diagnose wird also vorverlegt. Die \u00dcberlebenszeit hat sich aufgrund des Screenings nicht verl\u00e4ngert, wohl aber die Zeit zwischen Diagnose und Tod. Dies darf aber in keinem Fall als Verl\u00e4ngerung der Lebenszeit interpretiert\n292\nKapitel 15 \u00b7 Studien zu Diagnostik und Pr\u00e4vention\nwerden. In Wirklichkeit hat das Screening eher geschadet, da dadurch ein Teil unbeschwerter Lebenszeit verloren gegangen ist. \u2022 Length Time Bias. Durch Screening-Untersuchungen werden vor allem langsam wachsende, wenig aggressive Tumore mit langer pr\u00e4klinischer Phase und guten Chancen auf Heilung aufgesp\u00fcrt. Aggressive Tumore mit schlechter Prognose werden dagegen h\u00e4ufig von den Patienten selbst entdeckt. Dies k\u00f6nnte zu der falschen Schlussfolgerung verleiten, die h\u00f6here Erfolgsrate bei den langsam wachsenden Tumoren sei dem Screening zu verdanken. \u2022 Bias durch \u00dcberdiagnose. Dies ist eine extreme Form des Length Time Bias. Er entsteht dadurch, dass Erkrankungen bekannt werden, die ohne Screening niemals diagnostiziert worden w\u00e4ren. Dieser Fall kann eintreten, wenn Karzinome erkannt werden, die zu Lebzeiten des Patienten gar nicht symptomatisch werden w\u00fcrden (weil der Patient vorher an einer anderen Ursache stirbt) oder wenn Tumore erfasst werden, die sich ohne Screening zur\u00fcckbilden w\u00fcrden. Zusammenfassend ist festzuhalten: Der Nutzen eines Screenings ist abh\u00e4ngig von der Pr\u00e4valenz und der Art der Erkrankung sowie von den zur Verf\u00fcgung stehenden gesundheits\u00f6konomischen Ressourcen. Dar\u00fcber hinaus spielen Kriterien wie Sicherheit, Kosten, einfache Anwendung und Akzeptanz eine wichtige Rolle. Leider ist die Durchf\u00fchrung von randomisierten Studien, die den Nutzen belegen k\u00f6nnten, aus verschiedenen Gr\u00fcnden problematisch: Diese Studien m\u00fcssten sehr viele Teilnehmer umfassen und etliche Jahre dauern, um verl\u00e4ssliche Ergebnisse zu erhalten. Nicht jeder Proband wird gerne den Zufall entscheiden lassen, ob er regelm\u00e4\u00dfig gescreent werden soll oder nicht. Da die N\u00fctzlichkeit eines Screenings von den meisten potentiellen Teilnehmern kaum in Zweifel gezogen wird, mag es schwierig sein, sie von der Notwendigkeit solcher Studien zu \u00fcberzeugen.\n15\n16\nStudien zu Therapie und Prognose 16.1\nTherapiestudien 295\n16.1.1 Einleitende Bemerkungen 295 16.1.2 Die Phasen einer Arzneimittelstudie 296 16.1.3 Randomisation 296 16.1.4 Verblindung 298 16.1.5 Vergleichsgruppen 300 16.1.6 Das Studienprotokoll 300 16.1.7 Protokollverletzungen 301 16.1.8 Die statistische Analyse 303 16.1.9 Studien zur Nicht-Unterlegenheit 304 16.1.10 Alternative Designs 304\n16.2\nPrognosestudien 306\n16.2.1 Einleitende Bemerkungen 306 16.2.2 Die Beschreibung einer Prognose 307 16.2.3 Die Kaplan-Meier-Methode 307 16.2.4 Die Evaluierung prognostischer Faktoren 309\n16.3\nEvidenzbasierte Medizin 310\n16.3.1 Grundlagen 310 16.3.2 Evidenzbasierte Fallberichte 311 16.3.3 Die Cochrane Collaboration 313 16.3.4 Die Zukunft der evidenzbasierten Medizin 314\n295\n16\n16.1 Therapiestudien\n16.1\nTherapiestudien\n16.1.1 Einleitende Bemerkungen Wenn bei einem Patienten eine Krankheit diagnostiziert wird, stellt sich fast immer die Frage nach einer wirksamen und sicheren Therapie. Dies ist eine Ma\u00dfnahme, die den Gesundheitszustand des Patienten verbessern soll: ein Medikament, ein chirurgischer Eingriff oder eine Di\u00e4t. Bei der Verordnung einer Therapie st\u00fctzt sich der Arzt zumeist auf die Ergebnisse von Studien, in denen deren Nutzen nachgewiesen wurde. Manche Therapien wurden entwickelt aufgrund von theoretischen \u00dcberlegungen zu den Krankheitsmechanismen, andere Therapien basieren auf zuf\u00e4lligen Beobachtungen oder langj\u00e4hrigen Erfahrungen eines Arztes. In jedem Fall m\u00fcssen die Wirksamkeit und die Sicherheit einer formalen Pr\u00fcfung unterzogen und mittels einer Therapiestudie untersucht werden. Wenn eine neue Therapie an Menschen getestet wird, kann dies mit Risiken verbunden sein \u2013 insbesondere dann, wenn nicht gen\u00fcgend Erfahrungen \u00fcber Wirkung und Nebenwirkungen vorliegen. Andererseits ist es nicht weniger problematisch, unter dem Deckmantel der Ethik Patienten Arzneimittel zukommen zu lassen, deren Wirksamkeit und Sicherheit nicht vorher untersucht worden sind. Die Voraussetzungen zur Durchf\u00fchrung einer Therapiestudie sind daher sehr streng und in mehreren Gesetzesvorlagen verankert, u. a. im Arzneimittelgesetz (AMG). In die neusten Fassungen des AMG sind die Leitlinien zur Durchf\u00fchrung von Therapiestudien nach der \u201eGood Clinical Practice\u201c (GCP) mit aufgenommen worden. Damit m\u00fcssen diese international anerkannten Qualit\u00e4tsanforderungen bei der Durchf\u00fchrung von Therapiestudien zur Anwendung kommen. In jedem Fall muss eine Therapiestudie (egal ob es sich um ein Arzneimittel oder ein Medizinprodukt handelt) vor Beginn von einer Ethikkommission begutachtet werden. Studien, die eine Zulassung eines Arzneimittels beinhalten, m\u00fcssen zudem der zust\u00e4ndigen Landesbeh\u00f6rde (Regierungspr\u00e4sidium) und dem Bundesinstitut f\u00fcr Arzneimittel und Medizinprodukte (BfArM) gemeldet werden. Das Wohl der Patienten und der Probanden hat dabei immer Priorit\u00e4t. Der verantwortliche Arzt oder Versuchsleiter ist verpflichtet, jeden Teilnehmer \u00fcber das Ziel der Studie aufzukl\u00e4ren und vor Studienbeginn dessen Einverst\u00e4ndnis einzuholen. Niemand darf gegen seinen Willen gezwungen werden, an einer solchen Studie\n296\nKapitel 16 \u00b7 Studien zu Therapie und Prognose\nteilzunehmen. Jeder Patient hat auch das Recht, nach Studienbeginn ohne Angabe von Gr\u00fcnden sein Einverst\u00e4ndnis zur\u00fcckzuziehen. 16.1.2 Die Phasen einer Arzneimittelstudie Bei der Entwicklung eines Arzneimittels sind mehrere Phasen zu durchlaufen:\n\u0177 Pr\u00e4klinische Phase. Im Tierversuch werden Hinweise auf den \u0177 \u0177\n\u0177\n\u0177\nWirkmechanismus ermittelt und Informationen bez\u00fcglich Akutund Langzeittoxikologie erhoben. Phase I. Gesunde Probanden werden mit dem neuen Arzneimittel behandelt, um Fragen zur Pharmakokinetik, zur Vertr\u00e4glichkeit, zur Wirkung und zu Nebenwirkungen zu kl\u00e4ren. Phase II. Danach wird das Arzneimittel an einzelnen Patienten eingesetzt. Ziel dieser Phase ist es, Informationen zur Wirksamkeit (u. a. von verschiedenen Dosierungen) und Nebenwirkungen bei kranken Personen zu erhalten. Phase III. In dieser Phase wird eine gr\u00f6\u00dfere Patientengruppe, die die neue Therapie erh\u00e4lt, mit einer Kontrollgruppe verglichen. Wenn alle Phasen I bis III erfolgreich abgeschlossen sind, kann die Zulassung des Arzneimittels beantragt werden. Phase IV. Sie beginnt mit der Zulassung und besteht, solange die Therapie auf dem Markt ist. Sie dient der Dokumentation seltener Nebenwirkungen und der Abgrenzung der Indikation. Es ist die Aufgabe der Pharmakoepidemiologie, diese Nebenwirkungen zu erfassen und zu analysieren.\nDie Phasen I und II werden als prospektive Beobachtungsstudien durchgef\u00fchrt. Auch die Erkenntnisse, die in Phase IV gewonnen werden, basieren auf Beobachtungen. Bei der Phase III handelt es sich dagegen um eine klinisch kontrollierte Studie mit experimentellem Design (auch Interventionsstudie genannt). 16.1.3 Randomisation\n16\nKlinisch kontrollierte Studien sind quasi auf Patientenpopulationen beruhende Experimente, deren Ziel darin besteht, die Wirksamkeit oder die Sicherheit einer neuen Therapie durch einen direkten Vergleich (z. B. mit der bisherigen Standardtherapie oder einem Placebo) nachzuweisen. Diese Studien sind analytisch, longitudinal und prospektiv. Die zu vergleichenden Gruppen werden nach einem Zufallsverfahren gebildet, sodass ausschlie\u00dflich der Zufall (z. B. ein\n297\n16\n16.1 Therapiestudien\nZufallszahlengenerator) in jedem Einzelfall entscheidet, welcher Behandlungsgruppe der Patient zugewiesen wird. Dieses Verfahren bezeichnet man als Randomisation. Damit soll erreicht werden, dass die Gruppen strukturgleich sind \u2013 und zwar nicht nur bez\u00fcglich bekannter, sondern auch bez\u00fcglich unbekannter Einflussfaktoren. Hierin liegt ein wesentlicher Unterschied zu einer Kohortenstudie, bei der die Zuordnung zu einer Gruppe von bestimmten Eigenschaften des individuellen Patienten abh\u00e4ngig ist (z. B. ob er Raucher oder Nichtraucher ist) und nicht von einem Zufallsverfahren bei Studienbeginn. Die Randomisation bietet den Vorteil, dass ein Selektionsbias vermieden wird. Dieser k\u00f6nnte leicht entstehen, wenn Patienten durch den behandelnden Arzt bewusst oder unbewusst \u2013 etwa aufgrund ihrer Prognose \u2013 einer bestimmten Therapiegruppe zugeordnet werden w\u00fcrden. Dar\u00fcber hinaus gew\u00e4hrleistet die Randomisation eine hohe interne Validit\u00e4t: Bei strukturgleichen Gruppen zu Beginn der Studie ist klar, dass Unterschiede zwischen den Gruppen, die am Ende der Studie nachgewiesen werden, tats\u00e4chlich durch die Therapien bedingt sind. Folgendes ist zu jedoch bedenken:\n\u0177 Randomisation f\u00fchrt nicht automatisch zu gleich gro\u00dfen Gruppen. Dies kann insbesondere bei kleinen Studien problematisch werden. \u0177 Es ist keineswegs garantiert, dass die zu vergleichenden Gruppen bez\u00fcglich aller Einflussfaktoren strukturgleich sind. Es gibt einige Sonderformen, um dem entgegenwirken: \u2022 Blockbildung. Dabei werden die Patienten in kleine Bl\u00f6cke einer fixen Gr\u00f6\u00dfe eingeteilt \u2013 und zwar so, dass innerhalb jedes Blocks gleich viele Patienten auf die einzelnen Therapiegruppen verteilt sind. Wenn etwa die beiden Therapien A und B zu vergleichen sind, kann man mit 6er-Bl\u00f6cken arbeiten, in denen jeweils 3 Patienten einer der beiden Therapien zugeordnet werden. Jeder Block wird vorab zuf\u00e4llig ausgew\u00e4hlt (z. B. BAABBA). Durch die Blockbildung erreicht man, dass die beiden Therapiegruppen am Ende der Studie den gleichen Umfang haben. Au\u00dferdem werden Zwischenauswertungen erleichtert. \u2022 Stratifizierung. Bei der stratifizierten Randomisation werden die Patienten zun\u00e4chst in homogene Schichten (oder Strata) eingeteilt. Eine Schicht besteht aus Patienten, die sich bez\u00fcglich wichtiger Einflussfaktoren gleichen oder zumindest \u00e4hneln. Bei klinischen Studien ist es oft angebracht, Schichten nach der speziellen Diag-\n298\nKapitel 16 \u00b7 Studien zu Therapie und Prognose\nnose, dem Alter oder dem Geschlecht zu bilden. Dann wird innerhalb jeder Schicht blockweise randomisiert. Dadurch erreicht man, dass die Therapiegruppen weitgehend homogen sind bez\u00fcglich der Merkmale, nach denen stratifiziert wurde. Es ist sinnvoll, die Datenanalyse f\u00fcr jede Schicht getrennt durchzuf\u00fchren und danach zu vergleichen. Dieses Verfahren wird h\u00e4ufig bei multizentrischen Studien angewandt, wobei die Strata mit den einzelnen Zentren identisch sind. \u2022 Minimisation. Diese Methode eignet sich eher f\u00fcr kleine Studien. Die Zuweisung erfolgt nur beim ersten Patienten rein zufallsbedingt. Jeder nachfolgende Patient wird dann so zugeordnet, dass die Gruppen bestm\u00f6glich hinsichtlich vorab festgelegter Merkmale ausbalanciert werden. Um dem Zufall weiterhin eine Chance zu geben, wird hin und wieder die gewichtete Randomisation verwendet: Dabei wird jeder Patient mit einer vorab festgelegten Wahrscheinlichkeit (die gr\u00f6\u00dfer ist als 0,5) der Gruppe mit der gr\u00f6\u00dften Imbalance zugeordnet. Details zu diesem Design findet man in [11]. Randomisierte Studien sind f\u00fcr wissenschaftliche Fragestellungen sehr wichtig und beobachtenden Studien \u00fcberlegen. Nur dieser Studientypus ist geeignet, um die Frage nach kausalen Zusammenh\u00e4ngen zuverl\u00e4ssig zu beantworten. Englische Bezeichnungen f\u00fcr diesen Studientypus sind \u201erandomized clinical trial\u201c oder auch \u201erandomized controlled trial\u201c mit der Abk\u00fcrzung RCT. i Die erste randomisierte, doppelblinde Studie wurde 1948 in England z durchgef\u00fchrt. Dabei wurden die beiden Therapien \u201eStreptomycin\u201c und \u201eBettruhe\u201c zur Behandlung der Lungentuberkulose miteinander verglichen. Diese Studie ist eng mit dem Namen des englischen Epidemiologen Sir Austin Bradford Hill (1897-1991) verbunden. Hill hatte die Randomisation als Basiselement des Therapievergleichs als erster erkannt.\n16.1.4 Verblindung\n16\nEin Arzt, der eine bestimmte Therapie favorisiert, hat eine Erwartungshaltung und k\u00f6nnte deshalb \u2013 wenn auch unbewusst \u2013 die Zielgr\u00f6\u00dfen manipulieren, wenn er die Therapieform im Einzelfall kennt. Ebenso ist ein Patient in seiner Wertung m\u00f6glicherweise beeinflusst, wenn er wei\u00df, wie er therapiert wird. Um derartige Fehlerquellen zu vermeiden, sollte \u2013 wann immer dies m\u00f6glich ist \u2013 die Studie verblindet werden. Idealerweise kennen weder der Patient noch der behandelnde Arzt die Therapie, die im Einzelfall verwendet wird. Ein solches Design hei\u00dft doppelblind.\n299\n16\n16.1 Therapiestudien\nDiese Vorgehensweise gew\u00e4hrt eine objektive und unvoreingenommene Beurteilung einer Therapie und tr\u00e4gt damit zur Beobachtungsgleichheit bei. Dies bedeutet: Jeder Patient wird in gleicher Weise behandelt und beobachtet (abgesehen von den unterschiedlichen Therapieformen). Gelegentlich wird eine Studie sogar dreifachblind durchgef\u00fchrt. Dann hat auch die mit der Datenanalyse befasste Person keine Kenntnis bzgl. der einzelnen Therapieformen. Leider sind manche Studien schwer oder gar nicht doppelblind durchf\u00fchrbar \u2013 z. B. wenn ein chirurgischer Eingriff mit einer konservativen Therapie verglichen wird. Studien, bei denen nur der Arzt (aber nicht der Patient) die Therapieform kennt, hei\u00dfen einfachblind. Einfachblind kann auch bedeuten, dass der Patient (aber nicht der Arzt) \u00fcber die Behandlungsform informiert ist. Dieser Fall mag eintreten, wenn verschiedene Di\u00e4ten verglichen werden. Eine Studie, bei der sowohl der behandelnde Arzt als auch die Patienten wissen, welche Therapieform angewandt wird, hei\u00dft offen. Der Versuchsleiter sollte sich bem\u00fchen, eine Therapiestudie doppelblind zu planen, wann immer dies realisierbar erscheint \u2013 auch wenn eine blinde Studie organisatorisch wesentlich schwieriger durchzuf\u00fchren ist als eine offene Studie. Die so genannte DoubleDummy-Technik erm\u00f6glicht ein doppelblindes Design auch dann, wenn zwei Medikamente in unterschiedlicher Applikation (z. B. oral und subkutan) gegeben werden: Dann wird in jeder Gruppe eines der beiden Medikamente als Placebo verabreicht. Bei einer doppelblinden Studie muss sichergestellt sein, dass sich der behandelnde Arzt im Notfall umgehend \u00fcber die spezielle Therapie eines Patienten informieren kann. Daf\u00fcr wird ein versiegelter Notfallumschlag mit dem Namen des Patienten und Informationen \u00fcber dessen Therapie bereitgelegt. Einschr\u00e4nkend muss hinzugef\u00fcgt werden, dass eine vollst\u00e4ndige Verblindung bis zum Ende der Studie nicht immer realisierbar ist. H\u00e4ufig treten im Laufe einer Studie Therapieeffekte oder Nebenwirkungen auf, die beim Arzt oder beim Patienten zu einem Verdacht f\u00fchren k\u00f6nnen. Dennoch sollten eine Verblindung und eine objektive Auswertung der erhobenen Daten angestrebt werden. Notfalls sollte wenigstens ein verblindeter Beobachter eingeschaltet werden, um den Therapieerfolg am Ende der Studie zu beurteilen.\n300\nKapitel 16 \u00b7 Studien zu Therapie und Prognose\n16.1.5 Vergleichsgruppen Wenn sich nach einer therapeutischen Ma\u00dfnahme der Zustand eines Patienten verbessert hat, ist dies nicht unbedingt allein auf den Einfluss der Therapie zur\u00fcckzuf\u00fchren. Auch unspezifische Effekte k\u00f6nnten daf\u00fcr ma\u00dfgebend sein: etwa der nat\u00fcrliche Krankheitsverlauf oder der Hawthorne-Effekt, der dadurch entsteht, dass sich die Patienten besser f\u00fchlen, wenn ihnen Aufmerksamkeit geschenkt wird. Nicht zuletzt kann der Placebo-Effekt wesentlich zur Verbesserung des Befindens beitragen. Der Nutzen einer Therapie kann daher nur im direkten Vergleich ermessen werden. Die Qualit\u00e4t einer Studie wird nicht zuletzt durch die Vergleichsgruppe bestimmt. Theoretisch sind denkbar:\n\u0177 Standardtherapie. Falls eine Standardtherapie bereits etabliert ist, sind andere Vergleichsgruppen wissenschaftlich und ethisch nicht vertretbar. \u0177 Placebo. Ein Placebo (Scheinmedikament, das sich im Aussehen, Geschmack und Geruch nicht von der wirksamen Substanz unterscheidet) als Vergleich sollte nur dann verwendet werden, wenn dies ethisch zu vertreten ist und keine Standardtherapie zur Verf\u00fcgung steht. \u0177 Historische Kontrolle. Auf eine historische Kontrolle (also eine Gruppe, die in der Vergangenheit behandelt wurde) greift man zur\u00fcck, wenn keine Standardtherapie existiert und ein Placebovergleich ethisch nicht zu rechtfertigen ist. Diese Vorgehensweise ist angebracht bei Krankheiten, die ohne Behandlung unweigerlich zum Tod oder zu einer dramatischen Verschlechterung des Zustands der betroffenen Patienten f\u00fchren w\u00fcrden. Historische Kontrollen sind jedoch problematisch, vor allem dann, wenn sich auch andere Faktoren im Laufe der Zeit \u00e4ndern (z. B. durch verfeinerte Diagnostik oder verbesserte Begleittherapien). Beobachtungsgleichheit ist dann nicht mehr gegeben. Historische Kontrollen tendieren dazu, den Wirkungseffekt der neuen Therapie zu \u00fcbersch\u00e4tzen. 16.1.6 Das Studienprotokoll\n16\nWegen der hohen Qualit\u00e4tsanspr\u00fcche und der strengen Voraussetzungen sollte ein ausf\u00fchrliches Studienprotokoll mit folgendem Inhalt angefertigt werden:\n301\n16\n16.1 Therapiestudien\n\u0177 Name und Ziel der Studie \u0177 Studiendesign (z. B. Angaben zu Randomisation und Verblindung sowie beteiligte Kliniken oder Institutionen)\n\u0177 Zeitplan (Beginn, Rekrutierungs- und Untersuchungszeitraum sowie geplantes Ende der Studie)\n\u0177 Behandlung. Die zu evaluierende Therapie und die Vergleichs\u0177 \u0177\n\u0177\n\u0177\n\u0177 \u0177 \u0177\nbehandlung m\u00fcssen vollst\u00e4ndig beschrieben werden. Dazu z\u00e4hlen auch die Dauer und Dosierung der Anwendungen. Einschlusskriterien. Sie legen fest, unter welchen Voraussetzungen Patienten in die Studie aufgenommen werden. Es ist ferner wichtig, deren Einverst\u00e4ndnis zur Teilnahme zu dokumentieren. Ausschlusskriterien. Sie beziehen sich auf Patienten, die zwar alle Einschlusskriterien erf\u00fcllen, aber dennoch von der Studie ausgeschlossen werden m\u00fcssen (etwa weil ein erh\u00f6htes Risiko besteht oder eine weitere Krankheit vorliegt). Abbruchkriterien. Sie geben an, unter welchen Bedingungen einzelne Patienten von der laufenden Studie ausgeschlossen werden oder die Studie vorzeitig abgebrochen wird. Dieser Fall k\u00f6nnte eintreten, wenn unerwartete, gravierende Nebenwirkungen beobachtet werden. Angaben zur Biometrie. Diese beinhalten die prim\u00e4ren und sekund\u00e4ren Zielgr\u00f6\u00dfen, die zu \u00fcberpr\u00fcfende Hypothese, Angaben zu den Stichproben, die statistischen Analysemethoden sowie die ben\u00f6tigte Anzahl von Patienten oder Probanden. M\u00f6gliche M\u00e4ngel der Studie. Falls nicht alle Qualit\u00e4tskriterien optimal erf\u00fcllt sind (z. B. Doppelblindheit), muss dies dokumentiert und begr\u00fcndet werden. Besondere Angaben (etwa Kostentr\u00e4ger oder Auftraggeber) Angaben zur ethischen und rechtlichen Basis. Dazu z\u00e4hlen die Stellungnahme der Ethikkommission sowie die Beschreibung, in welcher Weise die Patienten oder Probanden \u00fcber die Studie informiert wurden und welche Versicherungen abgeschlossen werden.\nDie Festlegung der Ein- und Ausschlusskriterien soll die interindividuelle Variabilit\u00e4t der Patienten verringern. Anhand dieser Kriterien l\u00e4sst sich beurteilen, auf welchen Personenkreis die Ergebnisse der \u203a externe Validit\u00e4t, Abschnitt 13.5.1). Studie \u00fcbertragbar sind (z 16.1.7 Protokollverletzungen Die Randomisation wird durchgef\u00fchrt, um strukturgleiche Gruppen zu erhalten. Idealerweise bleiben die Patienten bis zum Studienende\n302\nKapitel 16 \u00b7 Studien zu Therapie und Prognose\nin der ihnen anfangs zugewiesenen Gruppe, werden wie vorgesehen therapiert und stehen bis zur letzten Untersuchung zur Verf\u00fcgung. Die Realit\u00e4t sieht jedoch h\u00e4ufig anders aus. Es ist keineswegs sichergestellt, dass die Studie mit den anfangs erstellten, strukturgleichen Gruppen protokollgem\u00e4\u00df zu Ende gef\u00fchrt werden kann. So kann es passieren, dass Patienten vorzeitig ausscheiden (Drop Outs). Dies ist nicht allzu problematisch, wenn deren Anzahl gering ist und der Grund daf\u00fcr in keinem Zusammenhang mit dem interessierenden Endereignis steht. Ein weit gr\u00f6\u00dferes Problem ergibt sich, wenn Patienten ausscheiden oder die Therapiegruppe wechseln aus Gr\u00fcnden, die mit der anfangs zugeteilten Therapie assoziiert sind: Wegen vermeintlicher Wirkungslosigkeit, unangenehmer Nebenwirkungen oder auf Anraten ihres Arztes. Es wurden mehrere Analysemethoden entwickelt, um diese Protokollverletzungen zu handhaben:\n\u0177 Intention to Treat (ITT). Bei diesem Verfahren werden alle Patienten in die Analyse einbezogen, und zwar in der Gruppe, zu der sie anfangs randomisiert worden sind. Dies setzt voraus, dass auch die Studienabbrecher wenigstens zur Enduntersuchung erscheinen. \u0177 As Treated (AT). Dieser Ansatz wertet die Patienten danach aus, welche Therapie sie \u2013 eventuell nach einem Wechsel \u2013 zuletzt erhalten haben. Studienabbrecher werden dabei nicht ber\u00fccksichtigt. \u0177 Per Protocol (PP). Dieses Prinzip verlangt, dass alle nicht protokollgem\u00e4\u00df behandelten Patienten (also Abbrecher und Wechsler) von der Analyse ausgeschlossen werden.\n16\nDer Vorteil der ITT-Analyse besteht darin, dass die Strukturgleichheit der Gruppen bis zum Ende der Studie gewahrt bleibt. Nachteilig ist jedoch, dass Unterschiede zwischen den Therapien verw\u00e4ssert werden. Allerdings ist zu bedenken, dass sich normalerweise nicht alle Patienten an die Therapieempfehlungen halten, wodurch die durchschnittliche Wirksamkeit abgeschw\u00e4cht wird. Insofern beschreibt die ITT-Analyse einen Effekt, der in der Praxis zu erwarten ist (im Englischen wird dies \u201eeffectiveness of treatment\u201c genannt). Mit den AT- und PP-Analysen treten Unterschiede zwischen den Gruppen deutlicher in Erscheinung. Diese Strategien beschreiben eher die biologische Wirksamkeit (englisch: clinical efficacy). Allerdings ist bei diesen Ans\u00e4tzen die durch die Randomisation erzielte Strukturgleichheit am Ende der Studie nicht mehr gegeben. Es kann daher keineswegs geschlussfolgert werden, dass ein nachgewiesener Unterschied allein durch die Therapie bedingt ist.\n303\n16\n16.1 Therapiestudien\nMan sollte versuchen, durch sorgf\u00e4ltige Studienplanung Protokollverletzungen weitestgehend zu vermeiden. Es ist dar\u00fcber hinaus empfehlenswert, w\u00e4hrend der Studie einen intensiven Kontakt zu den Patienten zu pflegen, um eine gute Compliance (Art, wie die Patienten den \u00e4rztlichen Anweisungen folgen) zu erzielen. 16.1.8 Die statistische Analyse Die Voraussetzungen f\u00fcr die statistische Analyse sind optimal, wenn strukturgleiche Gruppen vorliegen, die sich lediglich bez\u00fcglich der Therapie unterscheiden. Geeignete Analysemethoden sind abh\u00e4ngig von der Zielgr\u00f6\u00dfe. Bei einer quantitativen Zielgr\u00f6\u00dfe eignet sich eventuell ein t-Test f\u00fcr zwei unverbundene Stichproben bzw. eine einfaktorielle Varianzanalyse, wenn mehr als zwei Therapiegruppen vorliegen. Bei einer bin\u00e4ren Zielgr\u00f6\u00dfe bietet sich ein Chi2-Test an; au\u00dferdem k\u00f6nnen die in Abschnitt 14.4.2 vorgestellten Effektma\u00dfe (NNT u. a.) bestimmt werden. Um den Einfluss weiterer Merkmale zu untersuchen und eventuell vorhandene Unterschiede zwischen den Gruppen auszugleichen (die auch nach der Randomisation auftreten k\u00f6nnten), eignet sich ein multiples Verfahren an (Allgemeines lineares Modell oder logistische Regression). Wenn eine Zeitdauer als Zielgr\u00f6\u00dfe untersucht wird (z. B. die Zeit zwischen Beginn der Therapie und Heilung), eignen sich die Kaplan-Meier-Methode und der Logranktest. Damit lassen sich mehrere Gruppen (z. B. unterschiedliche Therapieformen) miteinander vergleichen. Als multiple Methode bietet sich das Cox-Regressions\u203a Abschnitte 16.2.3 und 16.2.4). modell an (z Bei klinisch kontrollierten Studien werden h\u00e4ufig Surrogatmerk\u203a Abschnitt 2.4) untermale anstelle von klinischen Endzust\u00e4nden (z sucht, um Studien schneller abschlie\u00dfen und publizieren zu k\u00f6nnen. Surrogatmerkmale werden hin und wieder auch dann verwendet, wenn die Analyse der prim\u00e4ren klinischen Zielgr\u00f6\u00dfe den Erwartungen nicht gerecht wird. Der kritische Leser einer Publikation sollte sich fragen, ob die Verwendung eines Surrogatmerkmals gerechtfertigt ist und ob die Schlussfolgerungen statthaft sind. ! Wenn bei einer neuen Therapie mit schweren Nebenwirkungen zu rechz\nnen ist, kann \u2013 analog zur NNT \u2013 die so genannte NNH (Number Needed to Harm) berechnet werden. Sie gibt an, wie viele Patienten zu behandeln sind, damit durchschnittlich einer aufgrund der neuen Therapie Schaden erleidet. Die NNT sollte m\u00f6glichst gering, die NNH dagegen hoch sein.\n304\nKapitel 16 \u00b7 Studien zu Therapie und Prognose\n16.1.9 Studien zur Nicht-Unterlegenheit Beim Vergleich zweier Therapien geht es nicht immer darum, einen signifikanten Unterschied nachzuweisen. Wenn beispielsweise bekannt ist, dass eine neue Therapie weniger Nebenwirkungen hat, einfacher zu applizieren oder preiswerter ist als eine Vergleichstherapie, oder dass eine bessere Compliance zu erwarten ist, muss nicht zus\u00e4tzlich gefordert werden, dass sie auch in ihrer Wirksamkeit \u00fcberlegen ist. Bei derlei Fragestellungen w\u00fcrde der Nachweis gen\u00fcgen, dass die neue Therapie mindestens genauso wirksam ist wie die Standardtherapie. Ein signifikantes Testergebnis wird demnach nicht unbedingt angestrebt. Es ist andererseits nicht statthaft, ein nicht-signifikantes Testergebnis dahingehend zu interpretieren, dass die zu vergleichenden Therapien \u00e4quivalent seien. Der Nicht-UnterlegenheitsNachweis basiert auf der Konstruktion eines Konfidenzintervalls f\u00fcr \u203a Abschnitt 10.2.2). die Wirkungsdifferenz der beiden Therapien (z Man muss sich vorab \u00fcberlegen, ab welcher Gr\u00f6\u00dfe ein Unterschied als klinisch bedeutsam angesehen wird. Ausf\u00fchrliche Hinweise findet man in [11]. 16.1.10 Alternative Designs Randomisierte klinische Studien sind sehr aufwendig und unterliegen strengen Vorschriften. Sie sind zwar wegen der Strukturgleichheit der Gruppen intern valide; wegen der strengen Ein- und Ausschlusskriterien mangelt es ihnen aber h\u00e4ufig an externer Validit\u00e4t \u2013 das hei\u00dft, es ist mitunter problematisch, die Ergebnisse auf andere Patientengruppen zu \u00fcbertragen. Ferner ist zu bedenken, dass die Randomisation nicht immer praktisch umsetzbar ist. Manche Patienten verweigern sie, weil sie w\u00fcnschen, dass ihr Arzt \u00fcber die Therapie entscheidet. Bei Notfallpatienten ist eine Randomisation (verbunden mit der Aufkl\u00e4rung und der Einwilligung des Patienten) nicht m\u00f6glich. Aus diesen Gr\u00fcnden ist es sinnvoll, Alternativen zu diskutieren.\n16\n\u2022 Studien ohne direkte Vergleichsgruppe. Das denkbar einfachste Design, um die Wirkung einer Therapie zu \u00fcberpr\u00fcfen, besteht darin, einen einfachen Vorher-Nachher-Vergleich durchzuf\u00fchren. Vereinzelt wird in Fallberichten oder Fallserien \u00fcber zumeist erfolgreiche therapeutische Interventionen berichtet. Allerdings ist die Aussagekraft solcher Studien gering: Wegen der fehlenden Vergleichsgruppe kann schwer beurteilt werden, worauf eine Verbesse-\n305\n16\n16.1 Therapiestudien\nrung des Zustands zur\u00fcckzuf\u00fchren ist. Ersatzweise kann man eine historische Kontrolle oder eine Vergleichsgruppe aus der Literatur heranziehen. Diese Designs sind jedoch wegen der mangelhaften Beobachtungsgleichheit problematisch und sollten nur in begr\u00fcndeten Ausnahmef\u00e4llen verwendet werden (etwa wenn ein direkter Vergleich aus ethischen Gr\u00fcnden nicht akzeptabel ist). \u2022 Retrospektive Studien. Falls die Daten f\u00fcr zwei Therapiegruppen bereits vorliegen, ist auch ein Vergleich denkbar, der retrospektiv durchgef\u00fchrt wird. Allerdings ist anhand der Dokumentationen in der Regel nicht erkennbar, welche Beweggr\u00fcnde in die Therapieentscheidung des behandelnden Arztes eingeflossen sind. Deshalb sind die Ergebnisse dieser Studien mit Vorsicht zu bewerten. \u2022 Kohortenstudien. Sie sind im Vergleich zu randomisierten, doppelblinden Studien organisatorisch einfacher in der Planung und Durchf\u00fchrung. Falls neben der Therapie weitere Faktoren evaluiert werden, lassen sich diese Studien auch auffassen als Prognosestudien, bei denen die Therapie als ein potentieller Einflussfaktor analysiert wird. Bei diesen Studien entscheidet meist der behandelnde Arzt \u00fcber die Therapie im Einzelfall. Dieses Vorgehen birgt jedoch die Gefahr eines Selektionsbias in sich (etwa wenn die Therapie eines Patienten vom Schweregrad der Krankheit abh\u00e4ngt). Mit einem multiplen Test lassen sich Unterschiede zwischen den Vergleichsgruppen ausbalancieren (allerdings nur f\u00fcr bekannte Einflussfaktoren). \u2022 Cross-Over-Design. Bei diesem Design wird jeder Patient mit zwei unterschiedlichen Therapien behandelt. Die Therapien k\u00f6nnen gleichzeitig (Blockversuche; z. B. bei paarigen Organen) oder zeitlich versetzt durchgef\u00fchrt werden. Jeder Patient stellt also seine eigene Kontrolle dar. Idealerweise sollte die Zuordnung der Therapien randomisiert erfolgen. Wenn die Therapien nacheinander verabreicht werden, ist auf eine therapiefreie \u00dcbergangsphase zu achten, um \u00dcberhangeffekte zu vermeiden. Dieses Studiendesign erfordert statistische Auswertemethoden f\u00fcr verbundene Stichproben. Zur Analyse eines quantitativen Merkmals bietet sich der t-Test oder der \u203a Abschnitte 11.1.2 Wilcoxon-Test f\u00fcr verbundene Stichproben an (z und 11.2.2); bei einem Alternativmerkmal eignet sich der McNemar\u203a Abschnitt 12.2.5). Test (z Bei einer Cross-Over-Studie werden weit weniger Patienten als bei einer zweiarmigen Studie ben\u00f6tigt. Dieses Design ist allerdings ungeeignet bei progredienten Erkrankungen und bei Krankheiten,\n306\nKapitel 16 \u00b7 Studien zu Therapie und Prognose\nbei denen eine der beiden Therapien zur Heilung oder zur nachhaltigen Besserung des Gesamtzustands f\u00fchrt. Anwendungsm\u00f6glichkeiten sind gegeben bei chronischen Krankheiten wie z. B. rheumatischen Erkrankungen oder bei chronischen Hauterkrankungen wie etwa Neurodermitis, wo lediglich eine Milderung der Symptome zu erwarten ist.\n16.2\nPrognosestudien\n16.2.1 Einleitende Bemerkungen\n16\nViele akute Krankheiten haben, vor allem wenn sie gut therapierbar sind, einen zeitlich begrenzten Verlauf. Chronische Krankheiten k\u00f6nnen hingegen das Leben eines Patienten nachhaltig beeinflussen (insbesondere wenn sie mit einer hohen Mortalit\u00e4t oder einer starken Beeintr\u00e4chtigung der Lebensqualit\u00e4t einhergehen). In diesen F\u00e4llen ist es f\u00fcr den Patienten wichtig, Informationen bez\u00fcglich seiner Prognose zu erhalten. Der Begriff klinischer Verlauf bezeichnet die Prognose, wenn eine ad\u00e4quate Behandlung erfolgt. Dagegen versteht man unter dem nat\u00fcrlichen Verlauf die Prognose ohne medizinische Intervention. Prognosestudien werden in Angriff genommen, um einerseits eine Prognose \u00fcber eine geeignete Ma\u00dfzahl quantifizieren zu k\u00f6nnen und andererseits, um Prognosefaktoren zu finden, die den Verlauf einer Krankheit beeinflussen. Bei Kenntnis wichtiger Prognosefaktoren ist es eventuell m\u00f6glich, Vorhersagen im Einzelfall zu treffen. Es ist \u00fcblich, derlei Studien als Kohortenstudien durchzuf\u00fchren. Dabei wird eine Gruppe von Personen, die an einer bestimmten Krankheit leiden, prospektiv beobachtet, und zwar solange, bis ein definiertes Endereignis eintritt. Dies kann der Tod des Patienten sein; es kann sich jedoch auch um ein anderes, f\u00fcr den Patienten wichtiges Ereignis handeln. Bei Studien in der Onkologie wird beispielsweise h\u00e4ufig die Zeit bis zum Auftreten eines Rezidivs oder bis zum Eintreten einer Remission analysiert. Hin und wieder werden auch zusammengesetzte Endpunkte untersucht (z. B. Tod oder Auftreten eines Rezidivs). Der Startzeitpunkt, ab dem ein Patient beobachtet wird, muss ebenfalls klar definiert sein (etwa der Zeitpunkt der Diagnose oder des Behandlungsbeginns).\n307\n16\n16.2 Prognosestudien\n16.2.2 Die Beschreibung einer Prognose H\u00e4ufig wird die Prognose mittels einer Rate ausgedr\u00fcckt, wie etwa der 5-Jahres-\u00dcberlebensrate, der Letalit\u00e4t, der Mortalit\u00e4t, der Remissions- oder der Rezidivrate. Eine andere Form der Darstellung ist die mediane \u00dcberlebenszeit, die die Zeitspanne angibt, die die H\u00e4lfte der Kohorte \u00fcberlebt. Sie hat den Vorteil, dass sie \u2013 im Gegensatz zur mittleren \u00dcberlebenszeit \u2013 bereits dann berechnet werden kann, nachdem die H\u00e4lfte der Studienteilnehmer verstorben ist. All diese Ma\u00dfzahlen sind leicht einpr\u00e4gsam. Andererseits sind sie wenig informativ. So ist beispielsweise aus der 5-Jahres-\u00dcberlebensrate nicht ersichtlich, wie gro\u00df die Wahrscheinlichkeit ist, eine andere Zeitspanne zu \u00fcberleben. Detaillierte Analysemethoden werden in den folgenden Abschnitten vorgestellt. 16.2.3 Die Kaplan-Meier-Methode Um das \u00dcberleben einer Kohorte f\u00fcr jeden Zeitpunkt bis zum Ende der Studie zu beschreiben, m\u00fcsste man die Kohorte solange beobachten, bis der letzte Patient verstorben ist. Dies ist in den meisten F\u00e4llen aber nicht m\u00f6glich, da man bei derlei Studien mit Studienabbrechern (Drop Outs) rechnen muss. Au\u00dferdem ist anzunehmen, dass zum Zeitpunkt der Datenanalyse nicht bei jedem Patienten das \u203a zensierte Daten, Abschnitt 2.4). Es Endereignis eingetreten ist (z w\u00fcrde das Studienergebnis verzerren, wenn alle Patienten mit zensierten Zeiten bei der Analyse nicht ber\u00fccksichtigt werden w\u00fcrden Zwei Biostatistiker \u2013 Edward M. Kaplan und Paul Meier \u2013 haben im Jahre 1958 die nach ihnen benannte Kaplan-Meier-Methode entwickelt, welche die Informationen aller Patienten (also auch die unvollst\u00e4ndigen Angaben) so weit wie m\u00f6glich ber\u00fccksichtigt. Diese Methode wird h\u00e4ufig bei \u00dcberlebenszeitanalysen angewandt. Der Begriff \u201e\u00dcberlebenszeitanalyse\u201c wird dabei ganz allgemein verwendet, um die Zeit zwischen einem definierten Anfangs- und einem bestimmten Endereignis zu untersuchen. Die Kaplan-Meier-Methode l\u00e4sst sich wie folgt beschreiben:\n\u0177 Die Studie startet mit n Patienten. Diese Anzahl reduziert sich im Laufe der Zeit, da Patienten ausscheiden (weil das kritische Endereignis eintritt oder auch aus anderen Gr\u00fcnden). \u0177 Die Zeiten, zu denen Endereignisse stattfinden, werden ermittelt und mit t1 < t 2 < ... < t k bezeichnet. Die Anzahl der Patienten, die zu diesen Zeitpunkten ausscheiden, sei d1 , d 2 etc.\n308\nKapitel 16 \u00b7 Studien zu Therapie und Prognose\n\u0177 Die Anzahl der Patienten, die unmittelbar vor einem Zeitpunkt ti noch in der Studie involviert sind, sei ni .\n\u0177 Die \u00dcberlebensfunktionen S (ti ) = P(t > ti ) werden f\u00fcr jeden Zeitpunkt ti ( i = 1,..., k ) gesch\u00e4tzt nach: n \u2212 di n \u2212 d n \u2212 d2 S\u02c6 (ti ) = 1 1 \u22c5 2 \u22c5 ... \u22c5 i n1 n2 ni\n(16.1)\nWenn es keine zensierten Daten gibt, ist ni +1 = ni \u2212 d i . Dann l\u00e4sst sich der Bruch in (16.1) k\u00fcrzen und man erh\u00e4lt S\u02c6 (ti ) = ni +1 / n (mit n = n1 ). Dies ist also die Zahl derer, die den Zeitpunkt ti \u00fcberlebt haben, im Verh\u00e4ltnis zu der Gesamtzahl der Patienten, die zu Beginn an der Studie teilnehmen. In dieser Form ist die Sch\u00e4tzung einfach und unmittelbar einleuchtend. Beispiel 16.1 Nach einer Organtransplantation wurden bei 10 Patienten die \u00dcberlebenszeiten in Tagen ermittelt. Nach 160 Tagen wurde die Studie beendet. Bei 7 Patienten konnte der Zeitpunkt des Endereignisses ermittelt werden (nach 20, 35, 62, 91, 91, 128 und 148 Tagen). Ein Patient brach nach 98 Tagen die Studie ab; zwei Patienten lebten am Ende der Studie noch. Mit diesen Angaben erh\u00e4lt man (unter Ber\u00fccksichtigung des zensierten Wertes nach 98 Tagen) folgende Sch\u00e4tzwerte f\u00fcr S (ti ) :\n16\nS\u02c6 (ti )\nZeiten\nni\ndi\nni \u2212 d i\nt1 = 20\n10\n1\n9\n9 / 10 = 0,9\nt2 = 35\n9\n1\n8\n0,9 \u22c5 8 / 9 = 0,8\nt3 = 62\n8\n1\n7\n0,8 \u22c5 7 / 8 = 0,7\nt4 = 91\n7\n2\n5\n0,7 \u22c5 5 / 7 = 0,5\nt5 = 128\n4\n1\n3\n0,5 \u22c5 3 / 4 = 0,375\nt6 = 148\n3\n1\n2\n0,375 \u22c5 2 / 3 = 0,25\nWenn \u2013 wie in Beispiel 16.1 \u2013 bei einigen Patienten das Endereignis am Ende der Studie noch nicht eingetreten ist, kann die \u00dcberlebensfunktion nur bis zum Zeitpunkt der letzten zensierten Beobachtung gesch\u00e4tzt werden. Die graphische Darstellung der Wahrscheinlichkeiten S (ti ) in Abh\u00e4ngigkeit der Zeitpunkte ti ergibt die \u203a Abbildung 16.1). Es leuchtet ein, dass die \u00dcberlebenskurve (z Sch\u00e4tzung nach Formel (16.1) mit wachsendem t schlechter wird, da zu jedem neuen Beobachtungszeitpunkt ti weniger Patienten zur Verf\u00fcgung stehen.\n16\n309\nAbb. 16.1 empirische \u00dcberlebenskurve (Beispiel 16.1). Zensierte Daten sind durch einen Punkt dargestellt.\n\u00dcberlebenswahrscheinlichkeit\n16.2 Prognosestudien\n1,0 0,9 0,8 0,7 0,6 0,5 0,4 0,3 0,2 0,1 0\n* ** 0\n20\n40 60 80 100 120 140 160 \u00dcberlebenszeit in Tagen\nMathematische Herleitung der \u00dcberlebenszeiten Unmittelbar vor dem Zeitpunkt t1 stehen n1 Beobachtungseinheiten zur Verf\u00fcgung, zum Zeitpunkt t1 sterben d1 Patienten. Die Wahrscheinlichkeit, t1 zu \u00fcberleben, wird gesch\u00e4tzt als: n \u2212d S\u02c6 (t1 ) = 1 1 n1 Die Wahrscheinlichkeit, den Zeitpunkt t2 zu \u00fcberleben, ist nach (6.9): S (t2 ) = P(t > t2 ) = P (t > t1 ) \u22c5 P (t > t2 | t > t1 )\nDer erste Faktor wird gesch\u00e4tzt \u00fcber S\u02c6 (t1 ) (siehe oben); den zweiten sch\u00e4tzt n \u2212 d n \u2212 d2 man analog. So ergibt sich: S\u02c6 (t 2 ) = 1 1 \u22c5 2 . n1 n2\nDurch sukzessives Wiederholen erh\u00e4lt man schlie\u00dflich die Formel (16.1).\n16.2.4 Die Evaluierung prognostischer Faktoren In den vorangegangenen Abschnitten wurde beschrieben, wie eine \u203a einzelne Kohorte untersucht werden kann. Mit dem Logranktest (z Abschnitt 12.2.7) k\u00f6nnen zwei oder mehrere Gruppen, die sich bez\u00fcglich einer Einflussgr\u00f6\u00dfe (z. B. der Therapieform oder des Krankheitsstadiums) unterscheiden, verglichen werden. Dieser Test ist geeignet, um Unterschiede zwischen den \u00dcberlebenskurven zu erkennen. Ein signifikanter Unterschied weist darauf hin, dass die Gruppierungsvariable prognostisch relevant sein k\u00f6nnte. Im Jahre 1972 wurde von dem britischen Statistiker David Cox (geboren 1924) eine multiple Methode vorgestellt, die es erm\u00f6glicht, eine Kombination von prognostischen Faktoren ausfindig zu machen, die den Endzustand eines Patienten in optimaler Weise vorhersagt. Mit diesem Cox-Proportional-Hazards-Modell wird die in\n310\nKapitel 16 \u00b7 Studien zu Therapie und Prognose\nFormel (8.29) definierte Hazard-Rate in Abh\u00e4ngigkeit von einer oder mehreren Einflussgr\u00f6\u00dfen als Hazard-Funktion modelliert. Dies entspricht der momentanen Sterberate. F\u00fcr zwei Patienten oder Populationen kann dann der Quotient der jeweiligen Hazard-Funktionen bestimmt werden. Diese so genannte Hazard-Ratio ist ein Ma\u00df f\u00fcr das relative Risiko. Die Hazard-Ratio kann f\u00fcr jeden Zeitpunkt berechnet werden und erm\u00f6glicht dadurch \u2013 im Gegensatz zu einfachen Ma\u00dfzahlen wie der 5-Jahres-\u00dcberlebensrate \u2013 Prognosen f\u00fcr jeden einzelnen Zeitpunkt. Die Kaplan-Meier-Methode und das Cox-Regressionsmodell erm\u00f6glichen \u00dcberlebenszeitanalysen auch dann, wenn zensierte Daten vorliegen. Bei der Planung einer \u00dcberlebenszeitstudie ist generell zu beachten:\n\u0177 Anfang und Ende des Beobachtungszeitraums sollten m\u00f6glichst exakt definiert sein.\n\u0177 Bei der Planung des Stichprobenumfangs muss einkalkuliert werden, dass einige Daten m\u00f6glicherweise zensiert werden.\n\u0177 Die Beobachtungszeit sollte ausreichend lang bemessen sein, damit bei m\u00f6glichst vielen Patienten das interessierende Endereignis eintritt. \u0177 Wenn Patienten vorzeitig aus der Studie ausscheiden, sollten die Gr\u00fcnde daf\u00fcr in keinem Zusammenhang mit der Prognose stehen. Ansonsten k\u00f6nnten die Drop Outs zu fehlerhaften Schlussfolgerungen f\u00fchren. i F\u00fcr weitere Informationen bez\u00fcglich der Analyse von Ereigniszeiten sei z auf [6] und [11] verwiesen.\n16.3\nEvidenzbasierte Medizin\n16.3.1 Grundlagen\n16\nWarum geh\u00f6rt ein Abschnitt zu Evidenzbasierter Medizin (EBM) in ein Lehrbuch f\u00fcr Biomathematik und Epidemiologie? EBM ist mit den Methoden der Klinischen Epidemiologie und der Biomathematik eng verbunden. Ohne Kenntnisse dieser Methoden k\u00f6nnen wissenschaftliche Arbeiten nicht kritisch interpretiert werden \u2013 und diese Evaluierung stellt eine Grundlage der EBM dar. Evidenzbasierte Medizin (Evidence Based Medicine) ist eine Medizin, die sich nicht nur an Intuition, unsystematischen individuellen Erfahrungen eines Arztes (auch nicht eines Chefarztes) oder im\n311\n16\n16.3 Evidenzbasierte Medizin\nbesten Fall an veralteten Lehrb\u00fcchern orientiert, sondern versucht, \u00e4rztliche Entscheidungen auf wissenschaftliche und objektive Belege (und so ist das englische Wort \u201eevidence\u201c zu verstehen) zu gr\u00fcnden. Nach dem britischen Epidemiologen David Sackett (geboren 1934) ist EBM der gewissenhafte, ausdr\u00fcckliche und vern\u00fcnftige Gebrauch der gegenw\u00e4rtig besten externen, wissenschaftlichen Evidenz in der medizinischen Versorgung individueller Patienten. Systematische \u00dcbersichtsarbeiten mit Metaanalysen und einzelne randomisierte, klinische Therapiestudien sind die Basis f\u00fcr eine solche Vorgehensweise, und es erscheint sinnvoll, dass ein Arzt bei der Patientenbehandlung sich an den Ergebnissen aller ihm zur Verf\u00fcgung stehenden, relevanten Studien von guter Qualit\u00e4t orientiert. Dies h\u00f6rt sich selbstverst\u00e4ndlich an, ist aber in der Realit\u00e4t nicht einfach umzusetzen. Die Ergebnisse aus der medizinischen Forschung und die daraus hervorgehenden Publikationen vermehren sich rasant. In der knapp bemessenen Lesezeit ist dies von einem einzelnen Arzt nicht mehr zu bew\u00e4ltigen. EBM bietet durch ein strukturiertes Vorgehen Hilfe bei der \u00e4rztlichen Entscheidungsfin\u203a Abschnitt 16.3.3). Dabei muss der behandelnde Arzt nicht dung (z in jedem Einzelfall die Originalliteratur analysieren. H\u00e4ufig kann er mittlerweile auf gute Sekund\u00e4rliteratur zur\u00fcckgreifen, in der Kollegen die gesamte, verf\u00fcgbare Literatur zu einer bestimmten Fragestellung (z. B. \u201eWie behandle ich die Psoriasis am besten?\u201c) nach den Gesichtspunkten der EBM gesichtet und analysiert haben. Dar\u00fcber hinaus stellt die evidenzbasierte Bewertung medizinischer Literatur einen wichtigen Beitrag zur Qualit\u00e4tsverbesserung und Qualit\u00e4tssicherung in der Klinik und in der Gesundheitsversorgung dar. Aus diesen Gr\u00fcnden hat die EBM in den letzten Jahren an Bedeutung gewonnen und findet sowohl in der klinischen Praxis als auch im Bereich der Leitlinienentwicklung zunehmend Einzug. Leitlinien der h\u00f6chsten Stufe (S3) setzen eine nach evidenzbasierten Gesichtspunkten durchgef\u00fchrte Evaluation der Literatur voraus (http://www.awmf-online.de/). 16.3.2 Evidenzbasierte Fallberichte EBM fokusiert sich auf den individuellen Patienten, f\u00fcr den es gilt, die bestm\u00f6gliche Diagnostik bzw. Therapie auszuw\u00e4hlen. Aufbauend auf dem Konzept von David Sackett erfolgt ein mehrstufiges Vorgehen. An erster Stelle steht die Formulierung einer klinischen Fragestellung. Die weiteren Schritte geben den weitgehend standardisierten Prozess der Entscheidungsfindung an. Diese basiert auf der kri-\n312\nKapitel 16 \u00b7 Studien zu Therapie und Prognose\ntischen Bewertung der gefunden Literatur; dabei werden die Ressourcen der Cochrane Collaboration, jedoch auch anderer medizinischer Datenbanken genutzt. Am Schluss steht die \u00dcberpr\u00fcfung der getroffenen Entscheidung. Dies soll an einem Beispiel verdeutlicht werden: Ein Patient, der unter verst\u00e4rktem Schwitzen im Bereich der Achseln leidet (Hyperhidrose), stellt sich in der Praxis eines Dermatologen vor. Damit ergibt sich die Fragestellung: Wie kann dieser Patient am wirksamsten und nebenwirkungs\u00e4rmsten behandelt werden? Ein Arzt, der diese Entscheidung nur auf seinen eigenen, individuellen Erfahrungen aufbaut, wird dem Patienten eine Therapie empfehlen, die er selbst schon mehrfach erfolgreich angewandt hat, ohne \u00fcber Alternativen nachzudenken. Ein Arzt aus einer operativen Klinik wird dem Patienten eher eine operative Therapie (z. B. Schwei\u00dfdr\u00fcsenexzision) empfehlen als ein Arzt, der in einer eher konservativ orientierten Klinik t\u00e4tig ist. Ein Arzt, der hingegen versucht, eine evidenzbasierte Therapieentscheidung zu treffen, wird vor seiner Entscheidung auf eine systematische \u00dcbersichtsarbeit zur Behandlung des verst\u00e4rkten Schwitzens zur\u00fcckgreifen wollen. Falls eine solche Arbeit nicht existiert, muss Originalliteratur herangezogen werden. In erster Linie wird man sich dabei auf randomisierte klinische Studien st\u00fctzen, die man z. B. der Cochrane- oder der Medline-Datenbank entnehmen kann. Tabelle 16.1 Struktur eines evidenzbasierten Fallberichtes\n16\n1.\nFragestellung\nWie behandle ich diesen Patienten am besten (Ziel der Aktion, sinnvolle Handlungsoption und Alternativen)?\n2.\nSuchstrategie (Literaturrecherche)\nWelche Datenbanken durchsuche ich? Welche Suchbegriffe verwende ich? Wie kombiniere ich diese Suchbegriffe?\n3.\nKritische Evaluierung der Wie gut sind diese Grundlagen gefundenen Arbeiten (interne Validit\u00e4t, klinische Relevanz?\n4.\nTherapieentscheidung\nBasierend auf individueller Erfahrung des Arztes (interne Evidenz) und aktueller Literatur (externe Evidenz) in Anbetracht der Anwendung im konkreten Fall\n5.\nBegr\u00fcndung und Diskussion\nWar die Entscheidung richtig? Welche Konsequenzen ergeben sich daraus?\n313\n16\n16.3 Evidenzbasierte Medizin\nDie Therapieentscheidung bei einem individuellen Patienten wird sich auf die Ergebnisse dieser Literaturrecherche st\u00fctzen, jedoch auch individuelle Faktoren in Betracht ziehen. Man wird etwa eine Therapie, die anfangs dreimal pro Woche in der Klinik durchgef\u00fchrt werden muss (wie die Iontophoresebehandlung bei Hyperhidrose), keinem Patienten anbieten, der 100 km entfernt wohnt. Am Ende steht dann die Reflexion des behandelnden Arztes, ob er die Therapieentscheidung basierend auf EBM-Kriterien gef\u00e4llt hat, oder ob er sich von anderen Faktoren hat beeinflussen lassen. 16.3.3 Die Cochrane Collaboration Die Cochrane Collaboration (CC, http://www.cochrane.de) hilft, dem Arzt die bestm\u00f6gliche Evidenz f\u00fcr eine Therapieentscheidung zur Verf\u00fcgung zu stellen. Die CC ist eine internationale Organisation, deren Ziel die Erstellung, Verbreitung und regelm\u00e4\u00dfige Aktualisierung systematischer \u00dcbersichtsarbeiten zu diagnostischen und therapeutischen Fragestellungen ist. Systematische \u00dcbersichtsarbeiten, die nach den Kriterien der CC erstellt werden, werden im Gegensatz zu den klassischen \u00dcbersichtsarbeiten, die u. a. durch individuelle Erfahrungen und Netzwerke gepr\u00e4gt sind, strukturiert erstellt. Ziel der Strukturierung durch Richtlinien und Kontrollinstanzen ist es, die Ergebnisse der \u00dcbersichtsarbeit so objektiv und so nachvollziehbar wie m\u00f6glich zu gestalten. Sind gen\u00fcgend vergleichbare Arbeiten zu einer Fragestellung vorhanden, steht am Ende eine Metaanalyse. Dies ist eine besondere Form der statistischen Auswertung, die vergleichbare Arbeiten zusammenfasst. Die Anzahl der von der CC erstellten systematischen \u00dcbersichtsarbeiten w\u00e4chst zunehmend. \u203a Im Logo der CC ist eine Metaanalyse grafisch dargestellt (z Abbildung 16.2). Die kleine Raute im linken, unteren Teil des Kreises zeigt die gemeinsame Sch\u00e4tzung resultierend aus der Synthese aller vergleichbaren Studien zu einem bestimmten Thema, die in der Metaanalyse ber\u00fccksichtigt werden. Die Arbeiten der Cochrane Collaboration bedeuten im Kontext der EBM einen wichtigen Beitrag, um fundierte, wissenschaftlich hochwertige Antworten zu Fragen aus der klinischen Praxis mit hoher Validit\u00e4t und minimaler Verzerrung (Bias) zu erhalten.\n314\nKapitel 16 \u00b7 Studien zu Therapie und Prognose\n16.3.4 Die Zukunft der evidenzbasierten Medizin Evidenzbasierte Medizin wird in naher Zukunft nicht mehr wegzudenken sein. Sie wird gef\u00f6rdert durch das Bestreben nach Qualit\u00e4tssicherung und die Notwendigkeit der Verwaltung eingeschr\u00e4nkter Ressourcen. Sie erfordert klinisch interessierte Mediziner, die sich nicht scheuen, kritische Fragen zu stellen und an alten und neuen Dogmen (z. B. \u201eSchokolade verschlechtert eine Akne\u201c oder \u201eKartoffel-Reis-Di\u00e4t hilft bei einer physikalischen Urtikaria\u201c) zu r\u00fctteln und auch ihre Zeit opfern, um diese Fragen zu beantworten. Durch die Identifikation von Forschungsdefiziten werden neue Fragen auftauchen, die in sorgf\u00e4ltig geplanten, analytischen epidemiologischen Studien \u00fcberpr\u00fcft werden m\u00fcssen. Die EBM soll den Arzt bei seinen Entscheidungen unterst\u00fctzen. Nach Sackett ist sie zu verstehen als eine Kunst, bei der Behandlung eines individuellen Patienten die richtigen Fragen zu stellen und diese durch eine strukturierte Zusammenfassung der neuesten Erkenntnisse aus der medizinischen Forschung zu beantworten. Jedoch sollten immer bei der Umsetzung die eigene klinische Erfahrung des Arztes wie auch das Patientenverst\u00e4ndnis mit ber\u00fccksichtigt werden. Wenn z. B. der Arzt die Krankheit nicht richtig diagnostiziert, hilft die beste Literaturrecherche nicht weiter. Wenn der Arzt eine Therapieentscheidung f\u00e4llt, die nicht zum Verst\u00e4ndnis des Patienten von seiner Krankheit passt, wird diese Entscheidung vom Patienten nicht akzeptiert werden und wegen mangelnder Compliance nicht zum gew\u00fcnschten Erfolg f\u00fchren. Zusammenfassend l\u00e4sst sich schlussfolgern, dass die \u00e4rztliche Entscheidungsfindung auf drei S\u00e4ulen beruht:\n\u0177 Auf dem erworbenen Wissen und der klinischen Erfahrung des behandelnden Arztes (interne Evidenz);\n\u0177 auf den Bed\u00fcrfnissen des Patienten; \u0177 auf dem aktuellen Stand der Forschung (externe Evidenz). i Als Einf\u00fchrung in die Methoden der EBM sei [8] empfohlen. z\n16\nAbb. 16.2 Logo der Cochrane Collaboration\nAnhang\nAnhang Tabelle A: Dichte- und Verteilungsfunktion der Standardnormalverteilung 317 Tabelle B: Quantile der t-Verteilung 318 Tabelle C: Kritische Werte f\u00fcr den Wilcoxon-Test 319 Tabelle D: Kritische Werte f\u00fcr den U-Test 320 Tabelle E: Quantile der Chi2-Verteilung 322 Tabelle F: Kritische Werte f\u00fcr den VorzeichenTest 323 Glossar Englisch - Deutsch 324 Abk\u00fcrzungen \u2013 Abbreviations 327 Weiterf\u00fchrende Literatur 328\nTabelle A: Dichte- und Verteilungsfunktion der Standardnormalverteilung\nAnhang\n317\nTabelle A: Dichte- und Verteilungsfunktion der Standardnormalverteilung z 0,0 0,1 0,2 0,3 0,4 0,5 0,6 0,674 0,7 0,8 0,9 1,0 1,1 1,2 1,3 1,4 1,5\nEs gilt: Beispiel:\n\u03d5 (z ) 0,399 0,397 0,391 0,381 0,368 0,352 0,333 0,318 0,312 0,290 0,266 0,242 0,218 0,194 0,171 0,150 0,129\n\u03a6 (z ) 0,50 0,540 0,579 0,618 0,655 0,691 0,726 0,75 0,758 0,788 0,816 0,841 0,864 0,885 0,903 0,919 0,933\nz 1,6 1,645 1,7 1,8 1,9 1,96 2,0 2,1 2,2 2,3 2,4 2,5 2,58 2,7 2,8 2,9 3,0\n\u03d5 (z ) 0,111 0,103 0,094 0,079 0,066 0,058 0,054 0,044 0,035 0,028 0,022 0,018 0,014 0,010 0,008 0,006 0,004\n\u03d5( z ) = \u03d5(\u2212 z ) und \u03a6 ( z ) = 1 \u2212 \u03a6 (\u2212 z ) \u03d5(1) = \u03d5( \u22121) = 0,242 \u03a6 (1,0) = 0,841 \u03a6 (\u22121,0) = 1 \u2212 0,841 = 0,159\n\u03a6 (z ) 0,945 0,95 0,955 0,964 0,971 0,975 0,977 0,982 0,986 0,989 0,992 0,994 0,995 0,9965 0,9974 0,9981 0,9987\n318\nAnhang \u00b7 Tabelle B:\nQuantile der t-Verteilung\nTabelle B: Quantile der t-Verteilung f 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 40 50 60 70 80 90 100\nt f ;0,90\nt f ;0,95\nt f ;0,975\nt f ;0,99\nt f ;0,995\n3,078 1,886 1,638 1,533 1,476 1,440 1,415 1,397 1,383 1,372 1,363 1,356 1,350 1,345 1,341 1,337 1,333 1,330 1,328 1,325 1,323 1,321 1,319 1,318 1,316 1,315 1,314 1,313 1,311 1,310 1,303 1,299 1,296 1,294 1,292 1,291 1,290\n6,314 2,920 2,353 2,132 2,015 1,943 1,895 1,860 1,833 1,812 1,796 1,782 1,771 1,76l 1,753 1,746 1,740 1,734 1,729 1,725 1,721 1,717 1,714 1,711 1,708 1,706 1,703 1,701 1,699 1,697 1,684 1,676 1,671 1,667 1,664 1,662 1,660\n12,706 4,303 3,182 2,776 2,571 2,447 2,365 2,306 2,262 2,228 2,201 2,179 2,160 2,145 2,131 2,120 2,110 2,101 2,093 2,086 2,080 2,074 2,069 2,064 2,060 2,056 2,052 2,048 2,045 2,042 2,021 2,009 2,000 1,994 1,990 1,987 l,984\n31,821 6,965 4,541 3,747 3,365 3,143 2,998 2,896 2,821 2,764 2,718 2,681 2,650 2,624 2,602 2,583 2,567 2,552 2,539 2,528 2,518 2,508 2,500 2,492 2,485 2,479 2,473 2,467 2,462 2,457 2,423 2,403 2,390 2,381 2,374 2,368 2,364\n63,657 9,925 5,841 4,604 4,032 3,707 3,499 3,355 3,250 3,169 3,106 3,055 3,012 2,977 2,947 2,921 2,898 2,878 2,861 2,845 2,831 2,819 2,807 2,797 2,787 2,779 2,771 2,763 2,756 2,750 2,704 2,678 2,660 2,648 2,639 2,632 2,626\nf = Anzahl der Freiheitsgrade\nTabelle C: Kritische Werte f\u00fcr den WilcoxonTest\n319\nAnhang\nTabelle C: Kritische Werte f\u00fcr den Wilcoxon-Test n 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 n\nIrrtumswahrscheinlichkeit \u03b1 bei 2-seitiger Fragestellung 0,10 0 2 3 5 8 10 13 17 21 25 30 35 41 47 53 60 67 75 83 91 100 110 119 130 140 151 0,05\n0,05 \u2212 0 2 3 5 8 10 13 17 21 25 29 34 40 46 52 58 65 73 81 89 98 107 116 126 137 0,025\n0,02 \u2212 \u2212 0 1 3 5 7 9 12 15 19 23 27 32 37 43 49 55 62 69 76 84 92 101 110 120 0,01\n0,01 \u2212 \u2212 \u2212 0 1 3 5 7 9 12 15 19 23 27 32 37 42 48 54 61 68 75 83 91 100 109 0,005\nIrrtumswahrscheinlichkeit \u03b1 bei 1-seitiger Fragestellung\nDie Nullhypothese wird abgelehnt, wenn die Pr\u00fcfgr\u00f6\u00dfe gleich dem kritischen Wert oder kleiner als dieser ist.\n320\nAnhang \u00b7 Tabelle D:\nTabelle D: 1 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40\n0 0\nKritische Werte f\u00fcr den U-Test\nKritische Werte f\u00fcr den U-Test (2-seitige Fragestellung, \u03b1 = 0,05 ) 2\n3\n0 0 0 0 1 1 1 1 1 2 2 2 2 3 3 3 3 3 4 4 4 4 5 5 5 5 5 6 6 6 6 7 7\n0 1 1 2 2 3 3 4 4 5 5 6 6 7 7 8 8 9 9 10 10 11 11 12 13 13 14 14 15 15 16 16 17 17 18 18\n4 0 1 2 3 4 4 5 6 7 8 9 10 11 11 12 13 14 15 16 17 17 18 19 20 21 22 23 24 24 25 26 27 28 29 30 31 31\n5\n6\n7\n8\n9\n10\n2 3 5 6 7 8 9 11 12 13 14 15 17 18 19 20 22 23 24 25 27 28 29 30 32 33 34 35 37 38 39 40 41 43 44 45\n5 6 8 10 11 13 14 16 17 19 21 22 24 25 27 29 30 32 33 35 37 38 40 42 43 45 46 48 50 51 53 55 56 58 59\n8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46 48 50 52 54 56 58 60 62 64 66 68 70 72 74\n13 15 17 19 22 24 26 29 31 34 36 38 41 43 45 48 50 53 55 57 60 62 65 67 69 72 74 77 79 81 84 86 89\n17 20 23 26 28 31 34 37 39 42 45 48 50 53 56 59 62 64 67 70 73 76 78 81 84 87 89 92 95 98 101 103\n23 26 29 33 36 39 42 45 48 52 55 58 61 64 67 71 74 77 80 83 87 90 93 96 99 103 106 109 112 115 119\nDie Zahlen in der Vorspalte und der Kopfzeile bezeichnen die Umf\u00e4nge der beiden Stichproben.\nAnhang\n321 Tabelle D: Kritische Werte f\u00fcr den U-Test\nTabelle D:\n4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40\nKritische Werte f\u00fcr den U-Test (2-seitige Fragestellung, \u03b1 = 0,05 )\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n30 33 37 40 44 47 51 55 58 62 65 69 73 76 80 83 87 90 94 98 101 105 108 112 116 119 123 127 130 134\n37 41 45 49 53 57 61 65 69 73 77 81 85 89 93 97 101 105 109 113 117 121 125 129 133 137 141 145 149\n45 50 54 59 63 67 72 76 80 85 89 94 98 102 107 111 116 120 125 129 133 138 142 147 151 156 160 165\n55 59 64 69 74 78 83 88 93 98 102 107 112 117 122 127 131 136 141 146 151 156 161 165 170 175 180\n64 70 75 80 85 90 96 101 106 111 117 122 127 132 138 143 148 153 159 164 169 174 180 185 190 196\n75 81 86 92 98 103 109 115 120 126 132 137 143 149 154 160 166 171 177 183 188 194 200 206 211\n87 93 99 105 111 117 123 129 135 141 147 154 160 166 172 178 184 190 196 202 209 215 221 227\n99 106 112 119 125 132 138 145 151 158 164 171 177 184 190 197 203 210 216 223 230 236 243\n113 119 126 133 140 147 154 161 168 175 182 189 196 203 210 217 224 231 238 245 252 258\n127 134 141 149 156 163 171 178 186 193 200 208 215 222 230 237 245 252 259 267 274\nDie Nullhypothese wird abgelehnt, wenn die Pr\u00fcfgr\u00f6\u00dfe gleich dem kritischen Wert oder kleiner als dieser ist.\n322\nAnhang \u00b7 Tabelle E:\nQuantile der Chi2-Verteilung\nTabelle E: Quantile der Chi2-Verteilung f\n\u03c7 2f ;0,90\n\u03c7 2f ;0,95\n\u03c7 2f ;0,975\n\u03c7 2f ;0,99\n\u03c7 2f ;0,995\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 40 50 60 70 80 90 100\n2,706 4,605 6,251 7,779 9,236 10,645 12,017 13,362 14,684 15,987 17,275 18,549 19,812 21,064 22,307 23,542 24,769 25,989 27,204 28,412 29,615 30,813 32,007 33,196 34,382 35,563 36,741 37,916 39,087 40,256 51,805 63,167 74,397 85,527 96,578 107,565 118,498\n3,841 5,991 7,815 9,488 11,070 12,592 14,067 15,507 16,919 18,307 19,675 21,026 22,362 23,685 24,996 26,296 27,587 28,869 30,144 31,410 32,671 33,924 35,172 36,415 37,652 38,885 40,113 41,337 42,557 43,773 55,759 67,505 79,082 90,531 101,879 113,145 124,342\n5,024 7,378 9,348 11,143 12,833 14,449 16,013 17,535 19,023 20,483 21,920 23,337 24,736 26,119 27,488 28,845 30,191 31,526 32,852 34,170 35,479 36,781 38,076 39,364 40,647 41,923 43,194 44,461 45,722 46,979 59,342 71,420 83,298 95,023 106,629 118,136 129,561\n6,635 9,210 11,345 13,277 15,086 16,812 18,475 20,090 21,666 23,209 24,725 26,217 27,688 29,141 30,578 32,000 33,409 34,805 36,191 37,566 38,932 40,289 41,638 42,980 44,314 45,642 45,963 48,278 49,588 50,892 63,691 76,154 88,379 100,425 112,329 124,116 135,807\n7,879 10,597 12,838 14,860 16,750 18,548 20,278 21,955 23,589 25,188 26,757 28,300 29,819 31,319 32,801 34,267 35,719 37,156 38,582 39,997 41,401 42,796 44,181 45,559 46,928 48,290 49,645 50,993 52,336 53,672 66,766 79,490 91,952 104,215 116,321 128,299 140,169\nf = Anzahl der Freiheitsgrade\nAnhang\n323\nTabelle F: Kritische Werte f\u00fcr den VorzeichenTest\nTabelle F: Kritische Werte f\u00fcr den Vorzeichen-Test n 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30\nn\nIrrtumswahrscheinlichkeit \u03b1 bei 2-seitiger Fragestellung 0,05 1 1 1 2 2 2 3 3 3 4 4 5 5 5 6 6 6 7 7 8 8 8 9 9 10\n5 6 7 7 8 9 9 10 11 11 12 12 13 14 14 15 16 16 17 17 18 19 19 20 20 0,025\n0,02 0 1 1 1 1 2 2 2 3 3 3 4 4 5 5 5 6 6 6 7 7 8 8 8 9\n0,01 6 6 7 8 9 9 10 11 11 12 13 13 14 14 15 16 16 17 18 18 19 19 20 21 21\n0,01\n0 0 1 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 7 7 7 8 8\n6 7 7 8 9 10 10 11 12 12 13 14 14 15 16 16 17 18 18 19 19 20 21 21 22 0,005\nIrrtumswahrscheinlichkeit \u03b1 bei 1-seitiger Fragestellung\nDie Nullhypothese wird abgelehnt, wenn die Pr\u00fcfgr\u00f6\u00dfe au\u00dferhalb der angegebenen Schranken liegt.\n324\nAnhang \u00b7 Glossar Englisch - Deutsch\nGlossar Englisch - Deutsch 2 by 2 table 2-tailed (2-sided) hypothesis accuracy adjusted alternative hypothesis analysis of variance arbitrary attributable risk average bar chart bias bimodal biostatistics carry over effect case control study case report case report form case series censored data coefficient of determination coefficient of variation characteristic cohort study compliance composite endpoint conditional probability confidence interval confounder contingency table correlation coefficient cross over cross-over-design cumulative frequency curvilinear regression cutoff point / value degree of freedom density function dependent variable distribution drop out effectiveness (of treatment) (clinical) efficacy\nVierfeldertafel 2-seitige Fragestellung Genauigkeit, Richtigkeit adjustiert Alternativhypothese Varianzanalyse willk\u00fcrlich zuschreibbares Risiko Durchschnitt Balken-, Stabdiagramm systematischer Fehler zweigipfelig Biostatistik nachhaltige Wirkung einer Therapie Fall-Kontroll-Studie Fallbericht Patientenerhebungsbogen Fallserien zensierte Daten Bestimmtheitsma\u00df Variationskoeffizient Merkmal Kohortenstudie Akzeptanz der Behandlung kombinierter Endpunkt bedingte Wahrscheinlichkeit Konfidenzintervall verzerrende St\u00f6rgr\u00f6\u00dfe Kontingenztafel Korrelationskoeffizient Therapiewechsler \u00dcberkreuzungsstudie Summenh\u00e4ufigkeit nichtlineare Regression Schwellenwert Freiheitsgrad Dichtefunktion abh\u00e4ngige Variable Verteilung Abbrecher, Ausfall Wirkung einer Behandlungsstrategie (biologische) Wirksamkeit\n325 Glossar Englisch - Deutsch\neligible endpoint estimator event evidence evidence based case report experimental study false positive / negative follow up follow up study frequency Gaussian distribution general linear model goodness (of fit) Hazard rate incidence independent variable inferential statistics informed consent insignificant intercept interquartile range least-square-method level of significance life table life table analysis longitudinal study (individual) matching mean median follow up period mode mortality rate noising factor non-inferiority null hypothesis observation observational study odds ratio origin outcome outlier p-value pie chart population\ndie Einschlusskriterien erf\u00fcllend Zielgr\u00f6\u00dfe Sch\u00e4tzer Ereignis Nachweis, Beleg EBM-basierte Fallbericht Experiment falsch positiv / negativ Nachbeobachtungszeit Verlaufsuntersuchung H\u00e4ufigkeit Normalverteilung allgemeines lineares Modell G\u00fcte (der Anpassung) Ausfallrate Inzidenz unabh\u00e4ngige Variable Inferenzstatistik Einverst\u00e4ndniserkl\u00e4rung nicht signifikant Achsenabschnitt, Basiswert Interquartilsabstand Methode der kleinsten Quadrate Signifikanzniveau Sterbetafel \u00dcberlebenszeitanalyse longitudinale Studie (paarweise) Zuordnung Mittelwert, Erwartungswert mediane Nachuntersuchungszeit Modalwert, Modus Mortalit\u00e4t, Sterblichkeit(srate) unverzerrende St\u00f6rgr\u00f6\u00dfe Nichtunterlegenheit Nullhypothese Beobachtung Beobachtungsstudie Chancenverh\u00e4ltnis Nullpunkt Zielgr\u00f6\u00dfe, Therapieergebnis Ausrei\u00dfer p-Wert Kreisdiagramm Grundgesamtheit, Population\nAnhang\n326\nAnhang \u00b7 Glossar Englisch - Deutsch\npower precision prediction predictive value prevalence probability random experiment random sample random variable randomisation randomized clinical trial randomized controlled trial range rank ratio recurrence rate reference interval regression line reliability research residual variance risk safety sample sample size sampling method scatter plot sensitivity significance level skewed distribution slope specificity stem-and-leaf-diagram standard deviation standard error of the mean statistical inference steering committee stratification student\u2019s test study subject survey survival analysis survival probability\nTrennsch\u00e4rfe, Testst\u00e4rke Genauigkeit, Pr\u00e4zision Vorhersage Vorhersagewert Pr\u00e4valenz Wahrscheinlichkeit Zufallsexperiment Zufallsstichprobe Zufallsvariable Randomisation, Zufallszuteilung randomisierte klinische Studie randomisierte kontrollierte Studie Spannweite rang, Rangzahl Verh\u00e4ltnis Rezidivrate Referenzbereich Regressionsgerade Zuverl\u00e4ssigkeit, Reproduzierbarkeit Forschung Restvarianz (nicht erkl\u00e4rte) Risiko, Risikofaktor Sicherheit Stichprobe Stichprobenumfang Stichprobenverfahren Punktwolke Sensitivit\u00e4t Signifikanzniveau schiefe Verteilung Steigung (einer Geraden) Spezifit\u00e4t Stamm-und-Blatt-Diagramm Standardabweichung Standardfehler des Mittelwerts statistische Schlussweise Studienbegleitkommission Stratifizierung t-Test Studie, Untersuchung Proband, Testperson, Objekt Erhebung \u00dcberlebenszeitanalyse \u00dcberlebenswahrscheinlichkeit\n327\nAnhang\nGlossar Englisch - Deutsch\nsurvival rate threshold ties transversal study treatment treatment lag trial true positive / negative type I / II error unbiased uncorrelated unimodal validity value variability variance vital statistics washout period withdrawal\n\u00dcberlebensrate Schwellenwert verbundene R\u00e4nge Querschnittstudie Behandlung Wirkungsverz\u00f6gerung Untersuchung, Studie richtig positiv / negativ Fehler 1. / 2. Art unverzerrt (frei von system. Fehler) unkorreliert, ohne Zusammenhang eingipfelig Richtigkeit, Validit\u00e4t Wert Variabilit\u00e4t Varianz Bev\u00f6lkerungsstatistik therapiefreie Zwischenphase Studienabbruch, Abbrecher\nAbk\u00fcrzungen - Abbreviations ANOVA ANCOVA AT AUC CRF CI CV EBM ITT MANOVA NNH NNS NNT NS OR PP RCT SD SEM\nanalysis of variance analysis of covariance as treated Area Under the Curve case report form confidence interval coefficient of variation evidence based medicine intention to treat multivariate analysis of variance Number Needed to Harm Number Needed to Screen Number Needed to Treat not significant odds ratio per protocol randomized clinical (controlled) trial standard deviation standard error of the mean\n328\nAnhang \u00b7 Weiterf\u00fchrende Literatur\nWeiterf\u00fchrende Literatur 1. Andre\u00df HJ, Hagenaars JA, K\u00fchnel S: Analyse von Tabellen und kategorialen Daten. Springer-Verlag Berlin, Heidelberg, New York, 1997 2. Backhaus K, Erichson B, Plinke W, Weiber R: Multivariate Analysemethoden, 11. Auflage. Springer-Verlag Berlin, Heidelberg, New York, 2004 3. Beck-Bornholdt HP, Dubben HH: Der Hund, der Eier legt. Erkennen von Fehlinformation durch Querdenken. Rowohlt Taschenbuch Verlag, Reinbek bei Hamburg, 2006 4. Bortz J: Statistik f\u00fcr Sozialwissenschaftler, 6. Auflage. SpringerVerlag Berlin, Heidelberg, New York, 2004 5. Bortz J, Lienert GA: Kurzgefasste Statistik f\u00fcr die klinische Forschung, 2. Auflage. Springer-Verlag Berlin, Heidelberg, New York, 2003 6. Fletcher RH, Fletcher SW: Klinische Epidemiologie. Grundlagen und Anwendung. 2. Auflage, Verlag Hans Huber, Bern, Schweiz, 2002 7. Gigerenzer G: Das Einmaleins der Skepsis. \u00dcber den richtigen Umgang mit Zahlen und Risiken. Berliner Taschenbuch Verlag, 2004 8. Greenhalgh T: Einf\u00fchrung in die Evidence-Based Medicine. Kritische Beurteilung klinischer Studien als Basis einer rationalen Medizin. Verlag Hans Huber Bern, 2002 9. Hartung J, Elpelt B, Kl\u00f6sener KJ: Statistik. Lehr- und Handbuch der angewandten Statistik, 14. Auflage. Oldenbourg-Verlag M\u00fcnchen, Wien, 2005 10. Sachs L, Hedderich J: Angewandte Statistik, 12. Auflage. Springer-Verlag Berlin, Heidelberg, New York, 2006 11. Schumacher M, Schulgen G: Methodik klinischer Studien. Methodische Grundlagen der Planung, Durchf\u00fchrung und Auswertung. 2. Auflage, Springer-Verlag Heidelberg, 2006 12. Wei\u00df C, Bauer AW: Promotion. Die medizinische Doktorarbeit von der Themensuche bis zur Dissertation, 3. Auflage. ThiemeVerlag Stuttgart, 2007\n329\nIndex\nSach- und Personenregister\nSach- und Personenregister \u012e-Fehler 192, 195, 201 f a-posteriori-Wahrscheinlichkeit 110, 119 a-priori-Wahrscheinlichkeit 110, 119 Abbe, Ernst 169 Abbruchkriterien 301 Abstandsskala siehe Intervallskala Additionssatz 108-111 Allgemeines lineares Modell 226 Alternativhypothese 190 f, 196 Alternativmerkmale 23, 97, 231, 237 Annahmebereich 192-194 Anpassungstest 203, 212 f, 240 Apgar-Score 29 \u00c4quivalenztest 200 Arbuthnot, John 5, 229 Area under the curve 284 arithmetisches Mittel 55 Arzneimittelgesetz 295 Arzneimittelstudie 296 As treated 302 Assoziation 49 f Assoziationskoeffizient nach Yule 52, 237 Assoziationsma\u00dfe 50, 98, 237 Ausfallrate 163 Auspr\u00e4gungsliste 28, 103 Ausrei\u00dfer 30, 43, 58 f, 67, 86 Ausschlusskriterien 301 Axiome von Kolmogoroff 107 \u00df-Fehler 194-195 Bacon, Francis 8 Balkendiagramm 41, 50 Bayes, Thomas 110 Bayes-Theorem 110 f Begleitmerkmal 22 Beobachtungseinheit 21 f Beobachtungsgleichheit 257, 299 f Beobachtungsstudie 254, 278, 296 Bernoulli, Jakob 129\nBernoulli-Experiment 129 f Bernoulli-Prozess 130 Bestimmtheitsma\u00df 92 f, 226 Bev\u00f6lkerungsstatistik 5, 114 f Bias 256 f, 278 - Diagnosestudien 287 - Fall-Kontroll-Studien 269 f - Kohortenstudien 276 - Pr\u00e4ventionsstudien 291 f Binomialkoeffizient 132 f Binomialtest 229 f Binomialverteilung 129-134, 160 f - negative 139 - symmetrische 134 Biomathematik 11 f Biometrie 11 f Biostatistik 11 Bland-Altman-Analyse 87, 200 Blockbildung 256, 297 Blockdiagramm 41 Blockversuche 305 Bonferroni-Korrektur 202, 225 Box-and-Whisker-Plot 74 f\nChadwick, Edwin 8 Chi2-Anpassungstest 240 Chi2-Homogenit\u00e4tstest 233, 236 Chi2-Tests 231-243, 266 Chi2-Unabh\u00e4ngigkeitstest 231, 236 Chi2-Verteilung 168 f, 232 Chi2-Vierfeldertest 231-234, 271 Cochrane Collaboration 312-314 Compliance 303 f Computersimulation 105 Confounder 23, 257, 266, 270, 278 Cox, David 309 Cox-Regressionsmodell 303, 309 f Cram\u00e9rs Index 237 Cross-Over-Design 305 Deduktive Methode 13 Demographie 5\n330\nSach- und Personenregister\nDeterminationskoeffizient 93 Dezile 60 Dezilabstand 68 Diagnosestudie 250, 281-288 Diagnostische Tests 118-122, 281288 - parallele 288 - serielle 288 - sequenzielle 288 Diagramm 20, 46 Dichte(funktion) 145 - empirische 44 - Exponentialverteilung 164 - Normalverteilung 148 - Weibullverteilung 165 Dichtemittel siehe Modus Differenzmenge 105 Dispersionsma\u00dfe siehe\nStreuungsma\u00dfe Dispersionstest 203 Dissertation 258, 260 Doktorarbeit 249 Dosiswirkungskurve 48 Double-Dummy-Technik 299 Drop Outs 275, 302, 307, 310 Dummy-Variable 29, 226, 246 Durchschnitt 55\nEffektma\u00dfe 273 f Effizienz einer Sch\u00e4tzung 175 Einflussgr\u00f6\u00dfe 22, 257 Einschlusskriterien 301 Einzelfalldarstellung 15 Elementarereignis 103 Endlichkeitskorrektur 141, 181 Endpunkt 306 Epidemiologie 111-114, 249 f Ereignisraum 102 Ereignisse 103 - disjunkte 106-108 - komplement\u00e4re 106 f - sichere 103 - unabh\u00e4ngige 110 - unm\u00f6gliche 103 Erfassungsfehler 256 erkl\u00e4rte Varianz 92 Erwartungstreue 174\nErwartungswert 127 f, 147, 175, 179 - Binomialverteilung 131 - Chi2-Verteilung 168 - Exponentialverteilung 164 f - hypergeometrische Verteilung 141 - Normalverteilung 148 - Poissonverteilung 136 - t-Verteilung 167 Ethikkommission 295, 301 Euler\u2019sche Zahl 136 Evidenz 312, 314 Evidenzbasierte Medizin 278, 310314 evidenzbasierter Fallbericht 311 f Exhaustivit\u00e4t 175 Experiment 14, 254, 296 Exponentialverteilung 164 f Exposition 264, 266, 271, 276-278 Extrapolation 91 Exzess siehe W\u00f6lbung\nF-Test 213 F-Verteilung 170, 213, 224 Faktor 22 - \u00e4tiologischer 250 - prognostischer siehe\nPrognosefaktor Fall-Kontroll-Studie 250-254, 267273 - eingebettete 277 Fallbericht 251, 264 f, 304 F\u00e4lle 267 Fallserie 251, 265, 304 falsch negativer Befund 118, 283, 290 falsch positiver Befund 118, 283, 290 fehlende Daten 33 Fehlentscheidung 4 Fehler - 1. Art siehe \u03b1-Fehler - 2. Art siehe \u00df-Fehler - systematischer 256 f - zuf\u00e4lliger 255 f Fertilit\u00e4tsziffer 114 Fisher, Ronald Aylmer 6, 9, 170, 174, 213\n331\nIndex\nSach- und Personenregister\nFisher\u2019s exakter Test 243 f, 271 Follow-Up-Studie 272 formale Korrelation 86 Formma\u00dfe 69-73 Fraktile 60 Freiheitsgrade - Chi2-Verteilung 236, 240 - t-Verteilung 167 f, 180, 209, 214 - Varianz 66 Freiwilligenbias 291 Friedmantest 225\nGalen aus Pergamon 7 Galilei, Galileo 6 f Galton, Francis 88, 161 Gau\u00df, Carl Friedrich 6, 148, 159 f Gau\u00df\u2019sche Glockenkurve 148 f Geburtenziffer siehe Fertilit\u00e4tsziffer Gemeinsamkeitskorrelation 87 geometrisches Mittel 63, 154 Geschichte der med. Statistik 4-11 Gesetz der gro\u00dfen Zahlen 104, 130, 157 f Gleichverteilung, diskrete 141, 241 Goldstandard 281 Good clinical practice 295 Gosset, Sealy 6, 167, 180 graphische Darstellungen 40 f, 44 f, 50 f, 74 f Graunt, John 5 Grundgesamtheit 19 f, 76, 173 Gruppen-Matching 269 G\u00fcte - diagnostischer Test 118, 281-288 - Sch\u00e4tzung 174 f - statistisches Modell 93, 226, 246 - statistischer Test siehe Power\nharmonisches Mittel 64 H\u00e4ufigkeiten - absolute 39 f - kumulative 46 - relative 39 f - zweidimensionale 49 f H\u00e4ufigkeitspolygon 44\nH\u00e4ufigkeitsverteilung 39, 45 f, 125 Hawthorne-Effekt 300 Hazard-Rate 163, 276, 310 Hazard-Ratio 310 Helmert, Friedrich Robert 169 Hill, Austin 275, 278, 298 Hippokrates von Kos 7 Histogramm 44, 56, 212 Homogenit\u00e4tstest 203, 233, 236 Homoskedastizit\u00e4t 184, 210 Huygens, Christiaan 6, 127 Hypothese 13, 19, 190 f, 259 - einseitige 191, 201, 233 - zweiseitige 191, 201\nIdentifikation 32 Induktive Methode 14 Informationsbias 257, 270, 276, 287 Inhomogenit\u00e4tskorrelation 86 Intention to treat 302 Interdezilbereich 68 Interquartilsbereich 68 Intervallsch\u00e4tzung 177-186 Intervallskala 24, 26, 73 Interventionsstudie 254, 296 Inzidenz 112, 264, 272 f - kumulative 275 Inzidenzdichte 275 Inzidenzf\u00e4lle 267 Inzidenzstudie 273 Irrtumswahrscheinlichkeit 178, 184, 193 Jenner, Edward 8 Kaplan-Meier-Methode 303, 307 Kappa-Koeffizient 200, 285 f Karnofsky-Skala 30 Kenngr\u00f6\u00dfen 20, 55\nsiehe Ma\u00dfzahlen Klassenanzahl 42 f Klassenbildung 42 f Klassenbreite 43 Kontrolle, historische 300, 305 Kohortenstudie 250 f, 272-277, 305 f - begleitende 276 - historische 277\n332\nSach- und Personenregister\nKolmogoroff, Andrej 107 Kolmogoroff-Smirnov-Test 242 Konfidenzintervall 177-184, 197 f, 208 f, 220, 256, 304 - Erwartungswert 179-181 - Korrelationskoeffizient 183 - Wahrscheinlichkeit 182 Konfidenzwahrscheinlichkeit 178 Konsistenz 174 Kontagionsindex 114 Kontingenz 49 Kontingenzkoeffizient 238 Kontingenztafel 49, 236, 244 Kontrollen 267 f Kontrollgruppe 267 f Korrelationsanalyse 80-88 Korrelationskoeffizient - nach Pearson 82, 84-88, 183, 214 - nach Spearman 94-97, 183 Kovarianz 82 f, 129 176 Krankenbestand siehe Pr\u00e4valenz Kreisdiagramm 40 f kritischer Bereich 192-194 kritischer Wert 193 Kruskal-Wallis-Test 224 Kurtosis siehe W\u00f6lbung\nLaborexperiment 277 Lagema\u00dfe 55-64, 69, 73 Lageparameter 127 f, 147 Lagetest 203, 207-226 L\u00e4ngsschnittstudie 252 Laplace, Pierre Simon de 6, 103, 150 Latenzzeit 272 f Lead Time Bias 291 Lebensdauer 162 Lebenserwartung 116 f Lebenszeitpr\u00e4valenz 112 Length Time Bias 292 Letalit\u00e4t 113 Likelihood-Quotient 282 Linder, Arthur 11 Liste 32 Lognormalverteilung 153 f, 165 Logranktest 242, 303, 309 Louis, Pierre Charles Alexandre 9\nManifestationsindex 114 Mantel-Haenszel-Test 237 Martini, Paul 11 Ma\u00dfzahlen - bivariate Datenbeschr. 82-98 - epidemiologische 112 f - univariate Datenbeschr. 55-73 Matchen 257, 268 f Maximum 63 McNemar-Test 238 f, 271, 305 Median 57 f, 127, 147, 175 Median-Test 235 f mediane \u00dcberlebenszeit 164 f Mehrstichprobentests 203, 224 f Mendel, Gregor Johann 10 Merkmale 21-29, 125 - abh\u00e4ngige 89 f - bin\u00e4re 23 - dichotome 23 - diskrete 25, 39 f, 67, 219 - kategoriale 24 - qualitative 24 - quantitative 25, 56 f, 46, 74 - stetige 25, 42 f - unabh\u00e4ngige 89 Merkmalsauspr\u00e4gungen 22, 28 f Merkmalstr\u00e4ger 21 Messniveau 23 Metaanalyse 311, 313 Methode der kleinsten Quadrate 57, 90 metrische Skala 25 Minimisation 298 Minimum 63 Mittelwert 55 f, 157, 175 mittlere Abw. vom Median 68 modale Klasse 62 Modalwert siehe Modus Modus 62, 128, 147 Moivre, de Abraham 160 Momente 147 Monte-Carlo-Studie 186, 214 Morbidit\u00e4t 113 Mortalit\u00e4t 113, 264 Multinomialverteilung 138 multiple Methode 11, 203, 225 f, 245, 260, 303\n333 Sach- und Personenregister\nmultiple Regressionsanalyse 91, 226 multiples Testen - diagnostisch 287 - statistisch 201 f Multiplikationssatz 110 f\nNatalit\u00e4t 114 Naturwissenschaften 3, 7, 14 Neuerkrankungsrate siehe Inzidenz Nichtunterlegenheit 304 NNH 303 NNS 291 NNT 274, 291, 303 Nominalskala 23, 26, 73 Nonsenskorrelation 86 Normalverteilung 66, 70, 148-152, 161, 212, 230, 241 Normbereich siehe Referenzbereich Nullhypothese 190 f, 196 Number needed to harm siehe NNH Number needed to screen siehe NNS Number needed to treat siehe NNT Ochsner, Alton 265, 278 Odds ratio 51, 237, 271 f Ordinalskala 23, 26, 73\np-Wert 197-202, 208, 220, 256 paarweise Zuordnung siehe\nMatchen Pascal, Blaise 6 Pearl-Index 115 Pearson, Karl 6, 89, 169 Per Protocol 302 Periodenpr\u00e4valenz 112 Perzentile 60 Pharmakoepidemiologie 296 Phi-Koeffizient 237 Placebo 300 Poisson, Sim\u00e9on Denis 136 Poissonverteilung 136 f, 161, 241 Polynomialverteilung 138 Populationsstudie 250, 266 Power 196, 211, 220 pr\u00e4diktiver Wert siehe\nVorhersagewert Pr\u00e4valenz 112, 119-122, 266, 291\nPr\u00e4valenzf\u00e4lle 267 Pr\u00e4valenzstudie 252, 266 Pr\u00e4vention 288 f Pr\u00e4ventionsstudie 250 f, 288-292 Prognosefaktor 242, 306 Prognosestudie 250 f, 306-314 Protokollverletzung 301 f Prozentangaben 40 Pr\u00fcfgr\u00f6\u00dfe 190 f, 203 Pr\u00fcfverteilungen 161, 166-170 punktbiseriale Korrelation 97 Punktediagramm 42 Punktpr\u00e4valenz 112 Punktsch\u00e4tzung 173-176 Punktwolke 80-82, 85 f\nQ-Test von Cochran 240 Quantile 60, 127, 147 - der t-Verteilung 180, 197 Quartile 60 Quartilsabstand 68 Querschnittstudie 250-252, 266 Quetelet, Adolphe 161 Randomisation 257, 296-298, 304 Rangkorrelation 95 f Rangliste 58 Rangskala siehe Ordinalskala Rangsummentest 215-221 Ratioskala siehe Verh\u00e4ltnisskala Recall-Bias 270, 273 Rechteckdiagramm 41 Referenzbereich 151 Register 19, 251 f Regression - 1. Art 91 - 2. Art 91 - lineare 89 - logistische 245 f, 270, 272, 275 - nicht-lineare 94 Regressionsanalyse 88-94, 226 Regressionsgerade 81 f, 88-91 Regressionskoeffizient 89 Relevanz 199, 312 Reliabilit\u00e4t 285 f Reproduzierbarkeit 285 f Residualvarianz 92\nIndex\n334\nSach- und Personenregister\nResiduen 92, 183, Risiko 264 - relatives 271 f, 274 f - zuschreibbares 274 Risikofaktor 263 f, 268 f, 274, 277 Risikoindikator 270 Risikoreduktion 274 Risikostudie 250, 263-278 ROC-Analyse 282-285 ROC-Kurve 283-285\n\u0131-Bereich 151 Sackett, David 311, 314 Satz von der totalen Wahrscheinlichkeit 108, 111 S\u00e4ulendiagramm 41, 74 Sch\u00e4tzfunktion 174 Sch\u00e4tzwert 174 Scheff\u00e9-Test 225 Scheinkorrelation 86 Schichten 256, 297 f Schiefe 69 f, 147, 152, 155, 212 - Binomialverteilung 134 - Chi2-Verteilung 168 - Exponentialverteilung 165 - Normalverteilung 148 - Poissonverteilung 138 Schnittmenge 105 Schwellenwert 282 f Scores, klinische 24, 29 f Screening 289-292 Selektion 256 Selektionsbias 256, 269, 276, 291, 297 Selektionskorrelation 86 Semmelweis, Ignaz Philipp 9 f, 263 Sensitivit\u00e4t 118-122, 281-283 sequentielles Testverfahren 195 Signifikanzniveau 194 Skalenniveau 23 f, 195 Skalentransformation 25 f Snow, John 9, 263 Spannweite 67 Spearman, Charles 95 Spezifit\u00e4t 118-122, 281-284 Staatsbeschreibung 5 Stabdiagramm 41\nStamm- und Blatt-Diagramm 45 Standardabweichung 65, 128, 176, 184 - Normalverteilung 148 Standardfehler des Mittelwerts 158, 181 Standardnormalverteilung 149 f Standardtherapie 300 Statistik - bivariate 79-98, 176 - deskriptive 5, 12, 20 f, 103 - explorative 12 - induktive 6, 12, 21, 102, 173-246 - medizinische 11 - univariate 55-76 Statistisches Jahrbuch 5, 117 Sterberate 163, 166 Sterbetafel 115-117 Sterbeziffer 116 f Stetigkeitskorrektur 182, 239 Stichproben 19 f, 73 f, 202 - abh\u00e4ngige siehe verbundene - paarige siehe verbundene - repr\u00e4sentative 19, 76, 173 - unabh\u00e4ngige siehe\nunverbundene - unverbundene 203, 209, 218, 221 - verbundene 203, 207, 216, 221 Stichprobenumfang 22, 39, 42, 56, 76, 158, 174 f, 184, 194 f, 255 Stochastik 11 f St\u00f6rgr\u00f6\u00dfe 22 - nicht-verzerrende 23 - verzerrende 23, 257 Strata 297 f Stratifizierung 256, 297 Streuungsma\u00dfe 64-69, 73 Streuungsparameter 128, 147 Strichliste 40 Strukturgleichheit 257, 269, 297 Student-Verteilung siehe t-\nVerteilung Studie - analytische 251 - beobachtende siehe\nBeobachtungsstudie - deskriptive 251, 264-266\n335\nIndex\nSach- und Personenregister\n- diagnostische siehe\nDiagnosestudie - doppelblinde 257, 298 - dreifachblinde 299 - einfachblinde 299 - epidemiologische 249 f - experimentelle siehe Experiment - klinisch kontrollierte 252, 296 - longitudinale 252, 254 - monozentrische 255 - multizentrische 255, 257, 298 - offene 299 - \u00f6kologische 266 - prospektive 14, 253 f - randomisierte 254, 291 f, 311 - retrospektive 14, 252-254, 305 - transversale 252 Studienabbrecher siehe Drop Outs Studiendesign 301 Studienplanung 258-260 Studienprotokoll 300 f Summenh\u00e4ufigkeiten 46 f Summenzeichen 39 Surrogatmerkmal 31, 303 S\u00fc\u00dfmilch, Johann Peter 5 Symmetrietest von Bowker 240\nt-Test 207-214, 219 f - f\u00fcr eine Stichprobe 189-193, 207, 212, 221 - f\u00fcr 2 unverbundene Stichproben 209 f, 213, 221 - f\u00fcr 2 verbundene Stichproben 207, 213, 221, 305 - nach Welch 210 - zur Pr\u00fcfung eines Korrelationskoeffizienten 214 t-Verteilung 167 f Tabelle 20, 32 Test - diagnostischer 118-122, 281-288 - konservativer 221 - parametrischer 207 - progressiver 221 - sequenzieller 195 - statistischer 189-204 - verteilungsfreier 215\nTestentscheidung 195 f Testergebnis - nicht signifikantes 198-200 - signifikantes 196, 199 Testgr\u00f6\u00dfe siehe Pr\u00fcfgr\u00f6\u00dfe Testst\u00e4rke siehe Power Therapiestudie 250 f, 295-306 Totalerhebung 19 Transformationen 152, 161, 214 Trennsch\u00e4rfe siehe Power Tschebyscheff, Pafnutij 155 Tschebyscheff\u2019sche Ungleichung 155 f\nU-Test von Mann und Whitney 218, 221 \u00dcberlebensfunktion 162 f, 242, 308 \u00dcberlebensrate 307 \u00dcberlebenszeit 162, 164, 242, 307 \u00dcberlebenszeitanalyse 31, 307, 310 \u00dcbersichtsarbeit 313 Unabh\u00e4ngigkeitstest 203, 231, 236 f Untersuchungseinheit 21 Urliste 55\nValidit\u00e4t - eines Screenings 291 - eines diagnostischen Tests 281 f - externe 258, 301, 304 - interne 258, 312 Variabilit\u00e4t - interindividuelle 255, 285, 301 - intraindividuelle 255, 285 Variable 21 Varianz 65, 128, 147,, 176 f - Binomialverteilung 131 - Chi2-Verteilung 168 - Exponentialverteilung 164 f - hypergeometrische Verteilung 141 - Normalverteilung 148 - Poissonverteilung 136 - t-Verteilung 168 Varianzanalyse 224 f Variation Ratio 68 Variationsbreite 67 Variationskoeffizient 66, 129\n336\nSach- und Personenregister\n- relativer 67 Venn, John 105 Venn-Diagramm 105 Verblindung 298 f verbundene R\u00e4nge 215, 217 f Vereinigungsmenge 105 Vergleichsgruppe 265, 300, 304 Verh\u00e4ltnisskala 24, 26, 73 Verteilung - diskrete 125-142 - eingipfelige 57, 62, 66, 71 - ged\u00e4chtnislose 164 - geometrische 139 - hypergeometrische 140, 181 - linksschiefe 70, 147, 155 - mehrgipfelige 62 - rechtsschiefe 70, 147, 152 f, 214 - schiefe 56, 58, 70, 161 - symmetrische 56 f , 66, 70, 147 - U-f\u00f6rmige 62 - von Mittelwerten 158, 160 - von \u00dcberlebenszeiten 162-166 Verteilungsfunktion 126 f, 145 - diskrete Verteilung 126 f - empirische 46 f, 62 - Exponentialverteilung 164 - Normalverteilung 148 f - Standardnormalverteilung 150 - stetige Verteilung 145 f - Weibull-Verteilung 165 Vertrauensbereich siehe\nKonfidenzintervall Vierfeldertafel 49, 231, 244 Vierfeldertest 231-234, 271 Visuelle Analogskala 30 Vollerhebung 19 Vorhersagewert 119-122, 282 - negativer 119 f - positiver 119 f, 287, 291 Vorzeichentest - f\u00fcr eine Stichprobe 221-223 - f\u00fcr 2 verbundene Stichproben 221, 223\nWahrscheinlichkeit 101-105, 126, 176, 182 - bedingte 109 f\n- nach Kolmogoroff 107 - nach Laplace 103, 107 - objektive 101 - subjektive 101 Wahrscheinlichkeitsfunktion 126 Wahrscheinlichkeitsrechnung 6, 12, 101-111, 155-161 Wahrscheinlichkeitstest 203 Weber, Erna 11 Weibull, Waloddi 165 Weibull-Verteilung 165 f Welch-Test 210 Wilcoxon, Frank 215 Wilcoxon-Test - eine Stichprobe 215, 221 - 2 verbundene Stichproben 216 f, 221, 305 W\u00f6lbung 71, 147, 212 - Normalverteilung 148\nYule, George 52 z-Transformation 149 zensierte Daten 32, 59 f, 242, 307 f zentrale Momente 147 zentraler Grenzwertsatz 159-161 Zentralwert siehe Median Zielgr\u00f6\u00dfe 22, 256 f Zufall 3 f, 14, 101 Zufallsexperiment 102 Zufallsstichprobe 267 Zufallsvariable 21, 173 - diskrete 125 f - stetige 145 f Zufallszahlen 141 Zusammenhang - funktionaler 79 - gegensinniger 81, 83, 90, 95 - gleichsinniger 81, 83, 90, 95 - kausaler 87, 270, 277, 298 - linearer 81-85, 89 - monotoner 95 - nicht-linearer 94 - stochastischer 79", "language": null, "image": "https://epdf.tips/assets/img/epdf_logo.png", "pagetype": "website", "links": ["https://epdf.tips/", "https://epdf.tips/", null, null, "https://epdf.tips/register", "https://epdf.tips/", "https://epdf.tips/basiswissen-medizinische-statistik-springer-lehrbuch.html", "https://epdf.tips/author/Christel+Wei%C3%9F", null, "https://epdf.tips/dmca-form/basiswissen-medizinische-statistik-springer-lehrbuch", "https://epdf.tips/download/basiswissen-medizinische-statistik-springer-lehrbuch.html", "https://www.facebook.com/sharer.php?u=https://epdf.tips/basiswissen-medizinische-statistik-springer-lehrbuch.html", "http://www.linkedin.com/shareArticle?mini=true&url=https://epdf.tips/basiswissen-medizinische-statistik-springer-lehrbuch.html", "/cdn-cgi/l/email-protection", "/cdn-cgi/l/email-protection", "https://epdf.tips/basiswissen-medizinische-statistik-4-auflage.html", "https://epdf.tips/basiswissen-medizinische-statistik-4-auflage.html", "https://epdf.tips/basiswissen-medizinische-statistik-3-auflage.html", "https://epdf.tips/basiswissen-medizinische-statistik-3-auflage.html", "https://epdf.tips/basiswissen-medizinische-statistik-5-auflage.html", "https://epdf.tips/basiswissen-medizinische-statistik-5-auflage.html", "https://epdf.tips/basiswissen-medizinische-mikrobiologie-und-infektiologiecb557c293cf2b553efbce853b913473078064.html", "https://epdf.tips/basiswissen-medizinische-mikrobiologie-und-infektiologiecb557c293cf2b553efbce853b913473078064.html", "https://epdf.tips/basiswissen-medizinische-mikrobiologie-und-infektiologie.html", "https://epdf.tips/basiswissen-medizinische-mikrobiologie-und-infektiologie.html", "https://epdf.tips/statistikd011f50035f91bdc2dad17830191503973982.html", "https://epdf.tips/statistikd011f50035f91bdc2dad17830191503973982.html", "https://epdf.tips/medizinische-physik-3-medizinische-laserphysik.html", "https://epdf.tips/medizinische-physik-3-medizinische-laserphysik.html", "https://epdf.tips/basiswissen-statistik-kompaktkurs-fur-anwender-aus-wirtschaft-informatik-und-tec.html", "https://epdf.tips/basiswissen-statistik-kompaktkurs-fur-anwender-aus-wirtschaft-informatik-und-tec.html", "https://epdf.tips/einfhrung-in-die-medizinische-statistik-statistik-und-ihre-anwendungen-2-auflage.html", "https://epdf.tips/einfhrung-in-die-medizinische-statistik-statistik-und-ihre-anwendungen-2-auflage.html", "https://epdf.tips/statistik.html", "https://epdf.tips/statistik.html", "https://epdf.tips/medizinische-physikb6e14443750acfcaf9f6680103387e3178910.html", "https://epdf.tips/medizinische-physikb6e14443750acfcaf9f6680103387e3178910.html", "https://epdf.tips/medizinische-mikrobiologiee5703e50ec1cbace00f24ef6020aabca86635.html", "https://epdf.tips/medizinische-mikrobiologiee5703e50ec1cbace00f24ef6020aabca86635.html", "https://epdf.tips/medizinische-physik.html", "https://epdf.tips/medizinische-physik.html", "https://epdf.tips/medizinische-mikrobiologie.html", "https://epdf.tips/medizinische-mikrobiologie.html", "https://epdf.tips/medizinische-terminologie.html", "https://epdf.tips/medizinische-terminologie.html", "https://epdf.tips/basiswissen-rechtsmedizin.html", "https://epdf.tips/basiswissen-rechtsmedizin.html", "https://epdf.tips/basiswissen-beschaffung07b376256062981ec74c9ee314bc331c48648.html", "https://epdf.tips/basiswissen-beschaffung07b376256062981ec74c9ee314bc331c48648.html", "https://epdf.tips/medizinische-mikrobiologie37083fd48621c1e2cf52f019714bed1899563.html", "https://epdf.tips/medizinische-mikrobiologie37083fd48621c1e2cf52f019714bed1899563.html", "https://epdf.tips/basiswissen-urologie4e93b9c1d525d079b30d77d73d45bbaf93588.html", "https://epdf.tips/basiswissen-urologie4e93b9c1d525d079b30d77d73d45bbaf93588.html", "https://epdf.tips/schnelleinstieg-statistik.html", "https://epdf.tips/schnelleinstieg-statistik.html", "https://epdf.tips/basiswissen-palliativmedizin.html", "https://epdf.tips/basiswissen-palliativmedizin.html", "https://epdf.tips/statistik-bungen-beschreibende-statistik-wahrscheinlichkeitsrechnung-schlieende-0dfa5ab77f2ef3c43a5646e3f63aa0dc99713.html", "https://epdf.tips/statistik-bungen-beschreibende-statistik-wahrscheinlichkeitsrechnung-schlieende-0dfa5ab77f2ef3c43a5646e3f63aa0dc99713.html", "https://epdf.tips/arbeitsbuch-statistik.html", "https://epdf.tips/arbeitsbuch-statistik.html", "https://epdf.tips/basiswissen-chirurgie.html", "https://epdf.tips/basiswissen-chirurgie.html", "https://epdf.tips/basiswissen-urologie029d749a4b152f423436375c06f36dda54878.html", "https://epdf.tips/basiswissen-urologie029d749a4b152f423436375c06f36dda54878.html", "https://epdf.tips/basiswissen-urologie.html", "https://epdf.tips/basiswissen-urologie.html", "https://epdf.tips/basiswissen-beschaffung.html", "https://epdf.tips/basiswissen-beschaffung.html", "https://epdf.tips/basiswissen-elektrotechnik.html", "https://epdf.tips/basiswissen-elektrotechnik.html", "https://epdf.tips/statistik-bungen-beschreibende-statistik-wahrscheinlichkeitsrechnung-schlieende-.html", "https://epdf.tips/statistik-bungen-beschreibende-statistik-wahrscheinlichkeitsrechnung-schlieende-.html", "https://epdf.tips/mathematische-statistik-reihe-statistik-und-ihre-anwendungen.html", "https://epdf.tips/mathematische-statistik-reihe-statistik-und-ihre-anwendungen.html", "https://epdf.tips/basiswissen-medizinische-statistik-4-auflage.html", "https://epdf.tips/basiswissen-medizinische-statistik-4-auflage.html", "https://epdf.tips/basiswissen-medizinische-statistik-3-auflage.html", "https://epdf.tips/basiswissen-medizinische-statistik-3-auflage.html", "https://epdf.tips/basiswissen-medizinische-statistik-5-auflage.html", "https://epdf.tips/basiswissen-medizinische-statistik-5-auflage.html", "https://epdf.tips/basiswissen-medizinische-mikrobiologie-und-infektiologiecb557c293cf2b553efbce853b913473078064.html", "https://epdf.tips/basiswissen-medizinische-mikrobiologie-und-infektiologiecb557c293cf2b553efbce853b913473078064.html", "https://epdf.tips/basiswissen-medizinische-mikrobiologie-und-infektiologie.html", "https://epdf.tips/basiswissen-medizinische-mikrobiologie-und-infektiologie.html", "https://epdf.tips/statistikd011f50035f91bdc2dad17830191503973982.html", "https://epdf.tips/statistikd011f50035f91bdc2dad17830191503973982.html", "https://epdf.tips/medizinische-physik-3-medizinische-laserphysik.html", "https://epdf.tips/medizinische-physik-3-medizinische-laserphysik.html", "https://epdf.tips/basiswissen-statistik-kompaktkurs-fur-anwender-aus-wirtschaft-informatik-und-tec.html", "https://epdf.tips/basiswissen-statistik-kompaktkurs-fur-anwender-aus-wirtschaft-informatik-und-tec.html", "https://epdf.tips/einfhrung-in-die-medizinische-statistik-statistik-und-ihre-anwendungen-2-auflage.html", "https://epdf.tips/einfhrung-in-die-medizinische-statistik-statistik-und-ihre-anwendungen-2-auflage.html", "https://epdf.tips/statistik.html", "https://epdf.tips/statistik.html", "https://epdf.tips/about", "https://epdf.tips/privacy", "https://epdf.tips/term", "https://epdf.tips/copyright", "https://epdf.tips/dmca", "https://epdf.tips/contact", "https://epdf.tips/cookie_policy", "https://epdf.tips/forgot", "https://epdf.tips/login/facebook", "https://epdf.tips/cookie_policy", "#"]}