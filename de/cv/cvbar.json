{"title": "PDF", "author": "PDF", "url": "vdivde-it.de/sites/default/files/document/festschrift-40-jahre-fuer-innovation-und-technik-2018.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "id": "PDF", "license": "PDF", "body": "PDF", "comments": "PDF", "commentsbody": "PDF", "raw_text": "PDF", "text": "Inhaltsverzeichnis\nEinleitung  3\nIntegrierte Forschung f\u00fcr\n \nsoziotechnische Innovationen\n 8\nAusflug ins Universum von Blockchain \n \nund Smart Contracts\n 14\nImpfen \u2013 kleiner Pieks, gr\no\u00dfe Wirkung\n 22\nBiobanken \u2013 eine sicher\ne Investition in  \ndie Gesundheit?\n 29\nKommunikation immer und \u00fcberall\n 36\nW\nie ver\u00e4ndert Crowdsourcing die  \nGesellschaft?\n \n41\nVon Erbsen zu Designerbabies?\n 46\nW\nas machen wir blo\u00df mit den  \nSozialen Innovationen?\n 53\nT\nransformation der Energieversorgung\n 58\nDie Evidenzbasierte Medizin \u2013 ein \n \nkritischer Denkansatz erobert die Welt\n 68\nInnovation und radikale Innovation \u2013 \n \nworum handelt es sich und wie  \nplanbar sind sie? \n 74\nDigitale Hochschule\n \n77Wie Brot und Sprengstoff aus  der Luft die Welt ver\u00e4nderten:  Das Haber-Bosch-Verfahren\n 83 \nInnovationen im Spiegel der \n \nlangfristigen Aktienkursentwicklung\n 91\nInnovation f\u00fcr schnelle Pr\nozessoren\n 104\nW\nohlstand durch Materialeffizienz\n 112\nDie Innovation vor Augen\n 118\nV\non der Schallplatte bis zum online\nMusikstreaming\n \n125\nAntibiotika\n \n134\nDas Smartphone\n 141\nMeta-Innovationen oder die Innovationdes Innovationssystems selbst\n 149\nX-Strahlen: W\nie die Entdeckung  \nWilhelm Conrad R\u00f6ntgens die  moderne Medizin pr\u00e4gte\n 158\nDer neue Pflegebed\u00fcrftigkeitsbegri\nff\n 166\nAutorinnen und Autor\nen\n 174\nImpr\nessum\n \n183Einleitung \u00a7 3\nEinleitung\nAlfons Botthof\nVon dem r\u00f6mischen Architekten Vitruv1 ist \n\u00fcberliefert, dass Archimedes nach einem Geis-\ntesblitz in seiner Badewanne pudelnackt aus dem Haus und auf die Stra\u00dfe gelaufen sei, laut \u03b5\u1f55\u03c1\u03b7\u03ba\u03b1  (Heureka: \u201eIch habe gefunden\u201c) \nschreiend. Die Entdeckung des statischen Auf-triebs eines K\u00f6rpers in einem Medium, nach dem dieser so gro\u00df ist wie das Gewicht des von diesem K\u00f6rper verdr\u00e4ngten Mediums, wird nach seinem Entdecker Archimedisches Prinzip genannt. Dieser Geistesblitz, diese Idee f\u00fcr die L\u00f6sung des ihm vom Tyrannen von Syrakus ge-stellten Problems, den Goldgehalt seiner Krone zu bestimmen ohne diese zu zerst\u00f6ren, war noch weit weg von einer Innovation. \n\u201eDoch um daraus eine Innovation werden zu \nlassen, h\u00e4tte Archimedes bis zum Marktplatz rennen m\u00fcssen ...\u201c.\n2\nWird aus einer Idee, einer Invention, kein wirt-schaftlicher oder gesellschaftlicher Nutzen  \nabgeleitet, diese also im wahrsten Sinne des Wortes \u201ezu Markte getragen\u201c, sprechen wir noch nicht von einer Innovation. Allein diese \u00fcberlieferte Anekdote zeigt zwei Facetten f\u00fcr Triebkr\u00e4fte, die erfolgreiche Innovationspro-  \nzesse beg\u00fcnstigen: das Vorhandensein eines  \ngenialen Geistes und das \u201eMotiv\u201c, eine Problem-  \nbzw. Aufgabenstellung zu l\u00f6sen. Gelegentlich war es auch schon einmal der Zufall. Auch wenn  \ndieser heute eher selten eine entscheidende Rolle spielt, hei\u00dft dies aber nicht, dass Inno-vationen durch und durch planbar und damit  \nvorhersagbar w\u00e4ren. \nLassen sich in der Technikgeschichte zahlreiche \nBeispiele von Inventionen gro\u00dfer, aber \u201eein-samer\u201c Geister nachzeichnen, die als \u201eGame  Changer\u201c gelten und Innovationen hervorge-rufen haben, so zeigt sich heute Innovation als Resultat eines in der Regel komplexen Prozesses.\nNationale oder sektorale Innovationssysteme \nbeschreiben heute den Rahmen, innerhalb des-sen Aushandlungsprozesse zur Unterst\u00fctzung und Beschleunigung von Produkt-, Prozess-, Dienstleistungs- und sozialen Innovationen stattfinden. Betrachtet man aus heutiger Per -\nspektive historische Beispiele, kann man auch in diesen zahlreiche den Erfolg und Misserfolg beeinflussende Faktoren, die von einem dama-ligen \u201eInnovationssystem\u201c beeinflusst wurden, erkennen. Hierin liegt die Idee f\u00fcr diese Fest-schrift.\nThematik der Festschrift zum Jubil\u00e4um\nAusgangspunkt f\u00fcr die in dieser Publikation ausgef\u00fchrten Beispiele f\u00fcr Innovationen ist der Begriff der Game Changing Ereignisse \u2013 um-w\u00e4lzende Ereignisse, die durch technologische, aber auch durch gesellschaftliche, wirtschaftli-che oder soziale Umbr\u00fcche ausgel\u00f6st bzw. be-feuert werden k\u00f6nnen und wiederum auf die Gesellschaft erhebliche Auswirkungen haben. Anhand von interessanten Blitzlichtern soll das Verst\u00e4ndnis der VDI/VDE-IT von Innovationen und Innovationsprozessen verdeutlicht werden. Kolleginnen und Kollegen aus allen Fachbe-reichen des Unternehmens charakterisieren in Beispielen die unterschiedlichsten Facetten des Innovationsgeschehens.\nIm Zentrum dieser Ver\u00f6ffentlichung stehen also \ndisruptive Innovationen.\n3 Als radikal oder dis-\nruptiv werden Innovationen charakterisiert, die v\u00f6llig Neues schaffen. Einschl\u00e4gige Beispiele f\u00fcr solche Innovationen wie das Rad, die Dampf-\n40 Jahre4 \nmaschine, das Smartphone sind bekannt. In der \nFolge solcher technischen Innovationen entstan-den Dienstleistungen wie Paket- und Briefzu-stellung oder allgemein die Logistik, Call-a-Bike oder auch Reparatur und Fernwartungsservices. H\u00e4ufig sind diese auch \u00fcberschrieben mit dem Begriff der Gesch\u00e4ftsmodellinnovation.\nAls gesellschaftliche Innovationen wiederum \ngelten beispielsweise die Einf\u00fchrung der So-zialversicherungsleistungen wie die Kranken- oder auch die gesetzliche Rentenversicherung ab 1883 durch Otto von Bismarck, genossen-schaftliche Vereinigungen wie Raiffeisen zum Einkauf oder Vertrieb landwirtschaftlicher G\u00fcter und B\u00fcrgerenergiegenossenschaften oder auch der Kindergarten als Reaktion auf die dramati-schen \u00c4nderungen der famili\u00e4ren und sozialen Umst\u00e4nde im 19. Jahrhundert.\nAuf Basis solcher Entwicklungen, die gerne \nauch als \u201eGame Changer\u201c bezeichnet werden, erfolgen wiederum eine Reihe inkrementeller Innovationen, die sich in neuen Leistungs-merkmalen oder auch technischen und organi-satorischen Anpassungen zeigen. Auch wenn unser Haus mit seiner Namensgebung \u201eInno-vation + Technik\u201c die Dominanz technologisch basierter Innovationen unterstreicht, wird doch l\u00e4ngst in der Innovationswissenschaft ein erweiterter Innovationsbegriff diskutiert und gerade auch von unserem Hause \u201emit Leben gef\u00fcllt\u201c. \nUnter anderem am Beispiel der Mikrosystem-\ntechnik, f\u00fcr die die VDI/VDE-IT viele Jahre als Pro-jekttr\u00e4ger und in der Innovationsunterst\u00fctzung im Auftrag des BMFT\n4, sp\u00e4ter BMBF verant-\nwortlich t\u00e4tig war, l\u00e4sst sich zeigen, dass Innova-tionsf\u00f6rderung weit \u00fcber eine ausschlie\u00dflich auf die F\u00f6rderung technologischer Entwicklungen ausgerichtete Programmatik hinausgeht. Die mit der damaligen Programmatik stimulierten und vom Projekttr\u00e4ger VDI/VDE-IT begleiteten Prozesse der Aushandlung von Interessen, des Agendasettings, der umf\u00e4nglichen Innovations-unterst\u00fctzung und die Reichweite der damit er -\nzielten Wirkungen zeigen die sozio-technischen und sozio-\u00f6konomischen Dimensionen der da-maligen Umsetzung der Mikrosystemf\u00f6rderung. \nIn vielen Auspr\u00e4gungen der von der VDI/VDE-IT \ngestern und heute betreuten Projekttr\u00e4ger -\nschaften zeigt sich das damit zum Ausdruck kommende \u201eRollenverst\u00e4ndnis\u201c. So werden Programme von uns mitkonzipiert und um-gesetzt, die Produkt-/Service-Innovationen, Verfahrens-/Organisations-Innovationen bis hin zu Gesch\u00e4fts- und sozialen Innovationen intendieren und die daf\u00fcr notwendigen, f\u00f6r -\ndernden Rahmenbedingungen beispielsweise zur Kompetenzentwicklung, zur Innovations-finanzierung oder zur Rechtssicherheit adres-sieren. Innovationsunterst\u00fctzende Ma\u00dfnah-men \u2013 ein Begriff, den unser Haus ma\u00dfgeblich gepr\u00e4gt hat \u2013 sorgen neben der Finanzierung und Begleitung von Projekten daf\u00fcr, dass ge-f\u00f6rderte Vorhaben den erw\u00fcnschten volks-wirtschaftlichen oder / und gesellschaftlichen Erfolg zeitigen. \nVoraussetzung hierf\u00fcr ist ein umfassendes ana-\nlytisches, wissenschaftlich jederzeit anschlussf\u00e4-higes Verst\u00e4ndnis des Innovationssystems und der Innovationstriebkr\u00e4fte und -hemmnisse. Es erfordert die Kenntnis der wirtschaftlichen, ge-sellschaftlichen und technologischen Entwick-lungen und der Wechselwirkungsmechanismen zwischen Wissenschaft, Wirtschaft, Politik und Gesellschaft.\n5 \nMit Beispielen von Innovationen disruptiven Charakters aus j\u00fcngster bis weit zur\u00fcckliegen-der Zeit wollen wir in unserer Festschrift zum 40. Jahr unserer Unternehmensgeschichte die Bandbreite dieses Innovationsverst\u00e4ndnisses aufzeigen.\nDie auf den folgenden Seiten aufgef\u00fchrten \nzahlreichen Beispiele aus zur\u00fcckliegenden Zei-ten lassen deutlich werden, dass Rahmenbe-dingungen eine nicht unerhebliche Rolle dabei Einleitung \u00a7 5\nspielen, dass Produkt-, Prozess- oder Dienst-\nleistungsinnovationen letztlich auch auf dem Marktplatz ankommen und sich am Markt  \nrespektive in der Gesellschaft erfolgreich zeigen.\nDie Gestaltung dieses Rahmens und die Steu-\nerbarkeit von Innovationsprozessen setzen voraus, deren Wesen zu kennen. Die VDI/VDE Innovation + Technik GmbH, fr\u00fcher noch fir -\nmierend unter VDI Technologiezentrum bzw.  \nVDI/VDE Technologiezentrum Informationstech-nik GmbH, hat in unterschiedlichen Rollen bis heute Ausschnitte solcher Innovationsprozesse begleitet, sei es als Projekttr\u00e4ger, als Evaluator oder als Analyst technischer und nichttech-nischer Innovationsbarrieren. Im Auftrag und durch Unterst\u00fctzung der \u00f6ffentlichen Hand hat die VDI/VDE-IT durch F\u00f6rdermittel der Ministe-rien oder andere unterst\u00fctzende Ma\u00dfnahmen zum Abbau von Barrieren und zur Beschleuni-gung solcher Prozesse, zur Innovationskultur und zum verantwortungsvollen Diskurs \u00fcber die Rolle von technologieinduziertem Wandel in Gesellschaft und Wirtschaft beigetragen.\nDie VDI/VDE-IT versteht sich als ein Akteur in \nAushandlungsprozessen, der sich dabei \u2013 in aller Bescheidenheit und im Bewusstsein sei-ner eingeschr\u00e4nkten Wirkm\u00e4chtigkeit \u2013 einer \u00f6konomischen, \u00f6kologischen und sozialen Nachhaltigkeit verpflichtet sieht. Um unsere selbstauferlegte oder von uns erwartete Rolle in Innovationsprozessen bestm\u00f6glich wahr -\nnehmen zu k\u00f6nnen, betrachten wir alle Di-mensionen von Innovation: die Dimension des Wandels von Wissenschaft und Technologie, die einzel- und betriebswirtschaftliche Dimen-sion, die gesamt- und volkswirtschaftliche oder sektorale Entwicklung wie auch soziale und kulturelle Implikationen. Damit ersch\u00f6pft sich unser Handeln nicht allein in der Unter -\nst\u00fctzung der Technologieentwicklung und [\u2026] Entscheidend ist, dass dieses \u201eAgenda-Setting\u201c nicht blo\u00df ein kognitiver und pro-grammatischer Vorgang war. Dadurch, dass Akteure sich an der Agenda orientiert haben, haben sie sich n\u00e4mlich nicht nur je einzeln zu der vielversprechenden Technologie positi-oniert, sondern auch neue Realit\u00e4ten geschaffen. Forscher, Unternehmen, Institute und andere setzten sich zueinander in Beziehung, indem sie ihre jeweils spezifischen, mit der Mikrosystemtechnologie verbundenen Erwartungen zu bestimmten kollektiven Zukunfts-perspektiven verkn\u00fcpft haben. [\u2026] Einschl\u00e4gige Lehrst\u00fchle wurden eingerichtet und Curri-cula f\u00fcr die Schulung von Ingenieuren und Naturwissenschaftlern sind entwickelt worden.  \nEntsprechend orientierte Firmen sind entstanden und Infrastrukturen der Beratung und anderer auf Mikrosystemtechnologie bezogener Dienstleistungen wurden aufge-baut. Man hat einen Ausbildungsgang f\u00fcr den Beruf Mikrotechnologe/-in definiert, den  \ninzwischen mehr als tausend Menschen absolviert haben.\nUnd es wurden neue Mikrosysteme und Technologien entwickelt, die in ihrer Gesamtheit \ngleichsam empirisch illustriert haben, was Mikrosystemtechnologie als technologisches Genre ist. Es entstanden also Konfigurationen von Technologien, Kompetenzen und Ak-teuren mit aufeinander bezogenen Interessen und diese f\u00fcgten sich zu einem Arrange-ment, das die Grenzen zwischen etablierten techno-\u00f6konomischen Feldern \u00fcberspannt. In seiner Gesamtheit macht dieses Gef\u00fcge das aus, was hier soziotechnische MST-Welt genannt wird. [\u2026]\n66 \n-diffusion sondern zielt auch darauf ab, (Teil-)\nAufgaben in der Transformation von Systemen in Organisationen, Wirtschaft und Gesellschaft zu \u00fcbernehmen.\nDiese Vielfalt findet sich auch in den nachfol-\ngenden Beitr\u00e4gen wieder, in denen einige Au-torinnen und Autoren tief in die Vergangenheit eintauchen und andere den Bogen teilweise bis weit in die Zukunft schlagen, in denen soziale, \u00f6konomische und technische Innovationen un-terschiedlichster Art beschrieben werden und in denen wir die Innovationsprozesse manchmal in der Gesamtheit \u2013 quasi aus der Vogelpers-pektive \u2013 betrachten und manchmal ganz nah herangehen. \n\u201e40 Jahre VDI/VDE-IT\u201c haben wir zum Anlass \ngenommen, in dieser Form \u201eInnovation\u201c als zentrales Thema des Unternehmens in einer Festschrift zu adressieren. Mitarbeiterinnen und Mitarbeiter reflektieren Innovationen und Inno-vationsprozesse. Wichtig war uns,  einerseits der Kreativit\u00e4t der Autorinnen und Autoren gro\u00dfen Spielraum zu lassen und andererseits dennoch wesentliche Aspekte des Themas zu erreichen. \nInnovation findet sich \u00fcberall dort, wo Men-\nschen leben und arbeiten und stellt sich damit als ein buntes Kaleidoskop von Ergebnissen menschlichen Denkens und Handelns dar. So m\u00f6chten wir Ihnen auch die Inhalte in unserem Buch pr\u00e4sentieren. Wir haben daher bewusst darauf verzichtet, die einzelnen Beitr\u00e4ge einem mehr oder weniger logisch begr\u00fcndbaren Cluster zuzuordnen. Die Reihenfolge im Buch wird durch deren Eingang bei der Redaktion bestimmt. Jede Autorin, jeder Autor und jedes Autorenteam hat ihren bzw. seinen Artikel im Zuge der Erstellung hausintern fachlich disku-tiert und einem Peer-Review unterzogen. Die Autorinnen und Autoren werden im Anhang kurz vorgestellt.Was k\u00f6nnen Sie  \nerwarten?\nBeispiele f\u00fcr Innovationen in der Biologie und  \nGesundheitswirtschaft in dieser Ver\u00f6ffent-\nlichung reichen von Entdeckungen wie die R\u00f6ntgenstrahlung, Antibiotika und Impfstof-fen \u00fcber die evidenzbasierte Medizin und die \u201eGen-Schere\u201c bis hin zu Biodatenbanken und digital unterst\u00fctzter Pflege. In diese Reihe f\u00e4llt auch die Betrachtung der Innovation \u201eSehhil-fe\u201c \u00fcber die Jahrhunderte. An diesen und be-sonders am Beispiel des \u201eHuman Genome Pro-jects\u201c wird deutlich, weshalb sozio-technische Innovationen eines integrativen Forschungsan-satzes bed\u00fcrfen und was unter \u201everantwor -\ntungsvoller Forschung\u201c zu verstehen ist. \nInnovationen im Zeitalter der Digitalisierung fin-\nden sich in der Wirtschaft zum Beispiel in Smart Contracts auf Basis der Blockchain-Technologie, in der Musikindustrie und der Energieversor -\ngung, aber auch in Bildungseinrichtungen wie den Hochschulen. Die Entwicklung des Ha-ber-Bosch-Verfahrens hin zu seiner industriellen Nutzung durch BASF zeigt die Bedeutung des effektiven Zusammenspiels verschiedener Diszi-plinen \u2013 hier in der chemischen Gro\u00dfindustrie \u2013  \nf\u00fcr Innovationsprozesse. \nDie ehemals von der VDI/VDE-IT verantwor -\ntete Materialeffizienzagentur zeigt, wie ein  \nGame-Changer-Paradigma wie Nachhaltigkeit \nauch mit \u201eschlichten Ans\u00e4tzen, die gro\u00dfe Ver -\nbesserungen bewirken\u201c verfolgt werden kann. Das Beispiel EUV-Lithographie verweist auf die strategische Bedeutung von Innovationen in der Halbleiterindustrie f\u00fcr Europa. Am Beispiel technischer Entwicklungen wie dem Smart-  \nphone wird der Einfluss von Innovationen auf Kommunikationsprozesse in unserer Lebens- und Arbeitswelt betrachtet.Einleitung \u00a7 7\nEher grunds\u00e4tzliche Betrachtungen finden sich \nin Artikeln zu sozialen Innovationen, der \u201eNatur\u201c von Innovationen, der Bedeutung integrierter Forschung zu Innovationsprozessen, der Crowd als Innovationsmotor oder auch zu Innovatio-nen im Innovationssystem selbst. Ein \u201eeinzig-artiger\u201c Beitrag betrachtet Innovationen im  \nSpiegel langfristiger Aktienkursentwicklungen.Nun w\u00fcnschen wir Ihnen beim entspannten  \nLesen interessante Einblicke in Prozess-, Produkt-  \nund Dienstleistungsinnovationen und den ein  \noder anderen Aha- und Wiedererkennungs-  \neffekt.\n\u00b9 Archimedis vero cum multa miranda inventa et varia fuerint, [\u2026] clamabat \u03b5\u03c5\u03c1\u03b7\u03ba\u03b1 \u03b5\u03c5\u03c1\u03b7\u03ba\u03b1.\n2 Stephan A. Jansen (2009): Vom Heureka! zum Hurra! In: brandeins, 2009.  www.brandeins.de/magazine/brand-eins-wirtschaftsmagazin/2009/\n identi fikation/vom-heureka-zum-hurra  [Zugriff am 13.3.2018].\n\u00b3 Begrif flichkeit erstmalig verwendet von C.M. Christensen in: Joseph L. B ower, Clayton M. Christensen (1995): Disruptive Technologies. C atching\n the Wave. In: Harvard Business Review, Bd. 69 (1995), S. 19\u201345. H\u00e4ufig synonym verwendet werden das Adjektiv \u201eradikal\u201c oder die Begrifflich-\n \nkeit \u201eSprunginnovation\u201c.\n4 zun\u00e4chst BMFT (Bundesministerium f\u00fcr Forschung und Technologie), danach BMBF\n5  Hier orientieren wir uns am Triple-Helix-Modell. Siehe hierzu: Loet Leydesdorff, Henry Etzkowitz (1998): T he Triple Helix as a model for innovation\nstudies. Conference Report in: Science and Public Policy, volume 25, number 3, June 1998, pages 195-203, Beech Tree Publishing, 10 Watford\n Close, Guildford, Surrey GU1 2EP , England. www.oni.uerj.br/media/dow nloads/195.full.pdf [Zugriff am 13.3.2018). \n6 Gerd Bender (2006): Technologieentwicklung als Institutionalisierungsprozess: Zur Entstehung einer soziotechnischen Welt. Edition Sigma, S . 79-8 0.8 \nIntegrierte Forschung f\u00fcr  \nsoziotechnische Innovationen\nDr. Julian Stubbe  Christine Wei\u00df\nGame Changer: Human Genome Project \n(1990 \u2013 2003)\nDas  von den USA koordinierte und in weltwei-\nter Kooperation durchgef\u00fchrte Forschungs-projekt \u201eHuman Genome Project\u201c (HGP) hatte zum Ziel, das menschliche Genom vollst\u00e4ndig zu entschl\u00fcsseln. An diese Sequenzierung war die Hoffnung gekn\u00fcpft,  das Verst\u00e4ndnis elementarer biologischer Prozesse ebenso zu befl\u00fcgeln wie die Erforschung von Erbkrank-heiten und Krebserkrankungen. Neben der wissenschaftlichmedizinischen Forschung soll-ten in dem Projekt auch Therapiem\u00f6glichkeiten sowie Grundlagen industrieller Anwendungen mitentwickelt werden. Diese Verwertungsam-bitionen brachten jedoch eine zunehmend kontroverse gesellschaftspolitische Diskussion mit sich. Im Kern wurde die Frage aufgewor -\nfen, inwiefern die M\u00f6glichkeit menschliche Gene zu analysieren die Diskriminierung spezi-fischer Gruppen durch Versicherungsunterneh-men und Arbeitgeber zur Folge hat. Immerhin, so der Vorwurf, k\u00f6nnen Genanalysen dazu genutzt werden, die Wahrscheinlichkeit von Erkrankungen einzelner Menschen zu bestim-men, um sie daraufhin als \u201ePersonen zweiter Klasse\u201c zu behandeln. Die US-Regierung ver -\nabschiedete 1996 im Rahmen eines Versiche-rungsgesetzes, dass Patienten die Weitergabe und Analyse ihrer Daten autorisieren m\u00fcssen. Mit dem Anspruch, zuk\u00fcnftig \u00e4hnliche Span-nungslagen zu vermeiden, entschied die Pro-jektkoordination des HGP eine umfangreiche Integration ethischer, rechtlicher und sozialer Implikationen (ELSI) der Genforschung in das Gesamtprojekt, gef\u00f6rdert mit 5 Prozent des j\u00e4hrlichen Gesamtbudgets. In Europa entstanden parallel F\u00f6rderprogram-me zur Genforschung, wie etwa die 2002 lancierte Netherlands Genomics Initiative, die ebenfalls 5 Prozent ihres Budgets der ELSI-For -\nschung widmete. In diesem Programm wurden auch Projekte mit eigenst\u00e4ndigen Forschungs-zielen gef\u00f6rdert, bis hin zur Gr\u00fcndung des Centre for Society and Genomics. Diese F\u00f6r -\nderstruktur gab der Entwicklung von ELSI als eigenst\u00e4ndiger Forschungsansatz Raum: weg von einer begleitenden Evaluation, hin zu einer integrierten Forschungsgestaltung.\nTechnik f\u00fcr den demografischen Wandel: \nGut gemeint ist nicht immer gut gemacht\nDer Bedarf f\u00fcr eine verantwortungsvolle For -\nschung zeigte sich auch bald in der technolo-\ngischen Forschung. Als Reaktion auf den im Jahr 2000 erschienenen 3. Altenbericht der Bundesregierung entwickelte das BMBF einen neuen Forschungs- und F\u00f6rderschwerpunkt zur Bew\u00e4ltigung der Herausforderungen des demografischen Wandels. Ziel war die bedarfs-gerechte Unterst\u00fctzung und Verbesserung der Lebensqualit\u00e4t und Selbstst\u00e4ndigkeit \u00e4lterer Menschen mit Hilfe von intelligenten techni-schen Assistenzsystemen. Dabei wurden die Grenzen zwischen technischen und sozialen Innovationen immer st\u00e4rker aufgehoben. Ent-sprechend musste sichergestellt werden, dass gut gemeinte Ideen auch tats\u00e4chlich zu gut ge-machten L\u00f6sungen f\u00fchren.\nEin Meilenstein war die Entwicklung eines \u201eMo-\ndells zur Ethischen Evaluation Sozio-Techni-scher Arrangements \u2013 MEESTAR\u201c\n1. Das Modell \nliefert einen strukturierten Ansatz zur Reflexion \n40 JahreIntegrierte Forschung f\u00fcr soziotechnische Innovationen \u00a7  9\nund Evaluation ethischer Fragen und ihrer an-\ngemessenen Ber\u00fccksichtigung im Forschungs-, Entwicklungs- und Anwendungsbereich. Der Ansatz zielt weniger auf ein abschlie\u00dfendes me-thodologisches Paradigma, sondern vielmehr auf einen praktischen Methodenkoffer, mit dem Perspektiven er\u00f6ffnet werden (\u201eGebrauchs-  \nethik\u201c). MEESTAR basiert auf der begr\u00fcndeten Annahme, dass nur die gemeinsame Betrach-tung von technischen und sozialen Faktoren eine angemessene Einsch\u00e4tzung erlaubt. Erst im konkreten Zusammenspiel von Menschen und ihren Rollen, zum Beispiel der unterst\u00fct-zungsbed\u00fcrftigen Person, der Nachbarschaft, den Angeh\u00f6rigen, dem \u00e4rztlichen und pflege-rischen Personal, den sozialen, rechtlichen und institutionellen Rahmenbedingungen sowie den  \ntechnischen Ger\u00e4ten in ihrer aktuellen oder potenziellen Vernetzung lassen sich die \u201eerns-ten moralischen Fragen\u201c erkennen, evaluieren und Entscheidungen treffen \u00fcber den Umfang und die Gestalt eines technischen Einsatzes. Die leitenden Fragen bei der Anwendung von  \nMEESTAR lauten: \n    Welche spezifisch ethischen Herausforderun-\ngen ergeben sich durch den Einsatz eines oder mehrerer altersgerechter Assistenzsysteme?\n     Ist der Einsatz eines Assistenzsystems ethisch \nbedenklich oder unbedenklich? Gibt es hier -\nbei so gravierende Momente, dass sie die \nNichtnutzung des Systems nahelegen?\n     Lassen sich ethische Pr obleme, die sich beim \nEinsatz von altersgerechten Assistenzsys-\ntemen ergeben, abmildern oder gar ganz aufl\u00f6sen? Wenn ja, wie sehen potenzielle L\u00f6sungsans\u00e4tze aus?\n    Haben sich bei der Nutzung des Systems neue,  \nunerwartete ethische Problempunkte ergeben, die vorher \u2013 bei Forschung und Entwicklung des Systems \u2013 noch nicht absehbar waren?\nAbb. 1: MEESTAR zeigt auf der x-Achse die Dimensionen der ethischen Bewertung, auf der y-Achse die Stufen der ethischen \nBewertung und auf der z-Achse die Ebenen der ethischen Bewertung. Quelle: Manzeschke et al. (2013): Ergebnisse der Studie \u201eEthische Fragen im Bereich Altersgerechter Assistenzsysteme\u201c. Berlin.\n10 \n    Auf welche Aspekte und Funktionalit\u00e4ten \ndes untersuchten altersger\nechten Assistenz-\nsystems muss aus ethischer Sicht besonders geachtet werden?\nAuf Basis dieser Methode entwickelte sich der Ansatz der integrierten Forschung, der Inge-nieurs- und Natur- sowie Sozial-, Rechts- und Geisteswissenschaften zusammenf\u00fchrt. Bei der Entwicklung und dem Einsatz von tech-nologischen L\u00f6sungen werden ELSI-Gesichts-punkte von Beginn an bedacht und ber\u00fcck-sichtigt. Dies ist insbesondere dann der Fall, wenn Technologien neuartige Assistenzfunk-tionen f\u00fcr den Menschen \u00fcbernehmen und dabei einen tiefen Einblick in die Privatsph\u00e4re erm\u00f6glichen.\nDamit wurde die Integrierte Forschung zu ei-\nnem Forschungs- und Gestaltungsansatz, der den Menschen in den Mittelpunkt technischer Entwicklungen r\u00fcckt. Sie fordert eine ganzheit-liche Forschungsperspektive, die die Interaktion zwischen Mensch und Technik nicht allein als technische Problemstellung begreift, sondern vielmehr als eine M\u00f6glichkeit, gesellschaftli-chen Herausforderungen zu begegnen. Integ-rierte Forschung ist daher interdisziplin\u00e4r und methodisch vielf\u00e4ltig und erm\u00f6glicht so eine ganzheitliche und lebenswelt\u00fcbergreifende Technikentwicklung. Mit empirisch angeleiteter integrierter Forschung k\u00f6nnen ethische, recht-liche und soziale Aspekte identifiziert werden, die spezifischer f\u00fcr eine bestimmte Technologie sind als die eher generellen Themen, die in \u00f6f-fentlichen Ethikdiskursen aufgegriffen werden. Dadurch werden nicht-technische Aspekte greifbarer und f\u00fcr die Technikentwicklung an-schlussf\u00e4higer. \nELSI im internationalen Vergleich\nDie Integrierte Forschung und ELSI sind nicht die einzigen Forschungsans\u00e4tze, die gesell-schaftliche Fragestellungen und Werte in die Technikentwicklung integrieren. Mit Blick auf die Wissenschaft l\u00e4sst sich sogar von einer gewissen Tradition sprechen, in der gefordert wird, dass sich Geistes- und Sozialwissenschaf-\nAbb. 2: Einsatz eines Body-Scanners\nIntegrierte Forschung f\u00fcr soziotechnische Innovationen \u00a7  11\nten aktiv an der Gestaltung von Innovationen \nbeteiligen. Der historische Entwicklungspfad dieser Forderung umspannt philosophische Programmatiken, den Ansatz der Bioethik so-wie des Technology Assessments und Ans\u00e4tze, die sich im Zuge der zunehmenden Verschr\u00e4n-kung von Wissenschaft, Industrie und Gesell-schaft auf verschiedenen Innovationsfeldern entwickelten. Einige dieser Ans\u00e4tze wurden von \u00f6ffentlichen Institutionen zur Innovationsf\u00f6rde-rung aufgegriffen und in entsprechende F\u00f6r -\nderprogramme implementiert. Dies geschieht  \nK\u00f6rperscanner an deutschen Flugh\u00e4fen: Ein R\u00fcckblick\nK\u00f6rperscanner, auch Ganzk\u00f6rperscanner oder Bodyscanner genannt, sind Ger\u00e4te, mit denen vor allem Waffen und Sprengstoffe als Gegenst\u00e4nde unter der Kleidung erkannt und visualisiert werden k\u00f6nnen, ohne dass die Personen mit der Hand abgetastet werden m\u00fcssen. Die erste Generation der K\u00f6rperscanner lieferte Bilder, die k\u00f6rperliche Details wie k\u00fcnstliche Darmausg\u00e4nge, Prothesen oder Intimpiercings f\u00fcr alle sichtbar machten. Dies brachte den Ger\u00e4ten auch die Bezeichnung \u201eNacktscanner\u201c ein und stellt nach Einsch\u00e4tzungen von Vertretern aus Politik, Kirche und Gewerkschaften eine erheb-liche Verletzung der Privatsph\u00e4re und Menschenw\u00fcrde dar. In Deutschland hatte das Bundesinnenministerium im Oktober 2008 den Einsatz solcher Scanner ausgeschlossen. Der damalige Bundesinnenminister Wolfgang Sch\u00e4uble hatte sich f\u00fcr eine Weiterent-wicklung der Ger\u00e4te ausgesprochen, aber die Darstellung der Bilder kritisiert: \u201eDiesen Unfug machen wir nicht mit\u201c\n3. Das Bundesforschungsministerium brachte als Reaktion \ndas interdisziplin\u00e4re Forschungsprojekt \u201eKRETA - K\u00f6rperscanner: Reflexionen auf Technik und Anwendungskontexte\u201c (2011 bis 2013) auf den Weg. Das Internationale Zentrum f\u00fcr Ethik in den Wissenschaften an der Universit\u00e4t T\u00fcbingen hatte zur Aufgabe, die K\u00f6r-perscannertechnologie sowohl aus theoretisch-ethischer als auch aus empirischer Sicht unter sozialen Gesichtspunkten zu beleuchten und die Ergebnisse sowohl in Technikent-wicklung als auch in Anwendungskontexte zur\u00fcckzuspiegeln.\nDie vehemente gesellschaftliche Ablehnung und neue Ans\u00e4tze der Integrierten For-\nschung f\u00fchrten zum Umdenken bei der Visualisierung der Scandaten. Die zweite Generation der K\u00f6rperscanner zeigte nur noch standardisierte, menschliche Umrisse, bei denen die potenziell gef\u00e4hrlichen Gegenst\u00e4nde als Markierung dargestellt wurden. Anatomische oder andere private Details waren nicht mehr zu erkennen. Allerdings hat-ten die verwendeten Scankabinen den Nachteil, Fluchtwege im Sicherheitsschleusenbe-reich zu verstellen und Menschen mit Klaustrophobie zu benachteiligen. Die dritte und aktuelle Generation der K\u00f6rperscanner besteht nur noch aus zwei senkrecht stehenden Scanw\u00e4nden, durch die Passagiere hindurchlaufen, kurz stehenbleiben und in zwei Scanvorg\u00e4ngen, die jeweils 16 Millisekunden dauern, von vorn und hinten gescannt werden. Diese Scanner sind u. a. an den Flugh\u00e4fen Hannover, K\u00f6ln-Bonn und Stuttgart im Einsatz.\nAus heutiger Sicht w\u00e4re eine zwingende sozio-technische Auseinandersetzung von Be-\nginn an notwendig gewesen, bei der die Verletzung der Privatheit auf gleicher Augen-h\u00f6he mit dem technisch Machbaren diskutiert h\u00e4tte werden m\u00fcssen.i12 \n entweder themenspezifisch wie im Fall der Bio-\nethik oder auch themen\u00fcbergreifend, indem verl\u00e4ssliche Rahmenbedingungen f\u00fcr die wis-senschaftlich-technische Entwicklung formu-liert werden.\nSeit den 2010er Jahren hat ELSI auf Ebene \nder Europ\u00e4ischen Forschungsf\u00f6rderung mit dem Ansatz der Responsible Research and In-novation (RRI) ein programmatisches Pendant erhalten, welches insbesondere im Rahmen-programm Horizon 2020 themen\u00fcbergreifend implementiert wurde. RRI entwickelte sich wie auch ELSI aus dem Anspruch heraus, die ge-sellschaftliche Akzeptabilit\u00e4t (anstelle der gern angef\u00fchrten Akzeptanz, die oftmals nicht mehr meint als einen Anstieg der Hinnahmebereit-schaft) von Innovationen zu erh\u00f6hen und ge-sellschaftliche Werte in die Entwicklung neuer Technologien zu integrieren, anstatt auf etwa-ige negative Folgen lediglich reagieren zu k\u00f6n-nen. Sechs Kernthemen wurden dabei in den Fokus ger\u00fcckt: \u00d6ffentliches Engagement, Gen-der-Gerechtigkeit, wissenschaftliche Bildung, Open Access-Prinzip, Ethik und Governance.\nDie Entwicklung der RRI-Kernthemen fand im \nwissenschaftlichen Diskurs statt und wurde in abgewandelter Form als F\u00f6rderansatz imple-mentiert. Eine zentrale wissenschaftliche Refe-renz bildet der Rahmen f\u00fcr Responsible Inno-vation.\n2 Die Autoren gehen davon aus, dass \nsich die Governance nicht auf Produkte und ihre Risiken konzentrieren sollte, sondern auf die Prozesse, in denen Innovationen hergestellt werden. Sie unterscheiden vier Aspekte verant-wortungsbewusster Forschung: Antizipation, Reflexivit\u00e4t, Inklusion und Reaktivit\u00e4t im Sinne der F\u00e4higkeit, Impulse, die unter Umst\u00e4nden st\u00f6rend sind, konstruktiv aufzunehmen. \nELSI und RRI sind beides Forschungsans\u00e4tze, \ndie \u201etop-down\u201c \u00fcber F\u00f6rderprogramme die Art und Weise, wie Forschung stattfindet, beein-flussen sollen. In diesem Sinne sind sie Gover -\nnance-Instrumente der Innovationsf\u00f6rderung. Beide Ans\u00e4tze sind in Verbindung zu sozial- und geisteswissenschaftlichen Debatten entwickelt worden. Diese Diskurse entwickelten Grunds\u00e4t-ze sowie Methoden einer Forschung, die ihrer gesellschaftlichen Verantwortung Rechnung tr\u00e4gt. Hinsichtlich der Implementierung die-ser Grunds\u00e4tze und Methoden unterscheiden ELSI und RRI sich graduell: W\u00e4hrend ELSI me-thodisch nicht weiter konkretisiert ist, verf\u00fcgt RRI \u00fcber spezifischere methodische Leitmoti-ve, wie beispielsweise \u00f6ffentliche Partizipation oder Gender-Gerechtigkeit. In dieser Hinsicht ist ELSI offener. Die methodische Konkretisierung ethisch und sozial sensibilisierter Forschung fin-det in konkreten Forschungsprojekten statt, wo durch integrierte Forschung relevante Dimen-sionen von Ethik und Gesellschaft identifiziert werden m\u00fcssen.\nDie Entwicklung geht weiter\nDie integrierte Forschung ist heute zu einem ge-nerellen Forschungs- und F\u00f6rderansatz gewor -\nden und die Weiterentwicklung des Ansatzes steht auch in Zukunft nicht still. Insbesondere im Bereich der interdisziplin\u00e4ren Zusammenarbeit ist die Governance gefragt, um die Anschluss-f\u00e4higkeit der verschiedenen Wissensbereiche weiter auszubauen. Projekte mit unterschiedli-chen Partnern ben\u00f6tigen Konzepte, mit denen ihre Zusammenarbeit strukturiert wird und die Kompetenzen und Potenziale der verschiede-nen Perspektiven optimal zum Tragen kommen. Hierf\u00fcr sollte etwa der Koordination von Projek-ten mehr Aufmerksamkeit geschenkt werden und auch der gemeinsamen Weiterbildung zu forschungsethischen Grundsatzfragen. Folgen-de Themen werden zuk\u00fcnftig noch st\u00e4rker ad-ressiert:\n    Public Science  beinhaltet sowohl die Parti-\nzipation der (Laien-)\u00d6ffentlichkeit in Entwick-lungsprojekte als auch die Durchf\u00fchrung der Forschungspraxis im \u00f6ffentlichen Raum. Im Zuge des zunehmenden Legitimierungsdru-ckes, dass Wissenschaft nicht allein im \u201eEl-fenbeinturm\u201c stattfinden darf, sondern sich erkl\u00e4ren und an gesellschaftlichen Realit\u00e4ten und Bedarfen orientieren muss, wird die  Integrierte Forschung f\u00fcr soziotechnische Innovationen \u00a7  13\n1 Manzeschk e, Arne; Weber, Karsten; Rother, Elisabeth; Fangerau, Heiner (2013): Ergebnisse der Studie \u201eEthische Fragen im Bereich Altersgerechter\n Assistenzsysteme\u201c.\n Berlin.\n2 Stilgoe , Jack; Owen, Richard; Macnaghten, Phil (2013): Developing a framework for responsible innovation. In: Research Policy 42 (9),S.1568\u20131580.\n3 tagesschau.de (2008): Diesen Unfug machen wir nicht mit.  Bundesregierung lehnt \u201eNackt-Scanner\u201c ab. Hg. v. Norddeutscher Rundfunk. \n Hamburg.\n www.tagesschau.de/inland/sicherheitschecks104.html [Zugriff am 23.3.2018].Integration gesellschaftlicher Akteure und \nsozialer Lebenswelten zunehmend relevant. Dabei darf die in Artikel 3 des Grundgesetzes garantierte Freiheit der Forschung nat\u00fcrlich nicht eingeschr\u00e4nkt werden. \n    Datensouver\u00e4nit\u00e4t  l\u00f6st den Datenschutz \nals neues Paradigma des Umgangs mit per -\ns\u00f6nlichen Daten ab. Nicht l\u00e4nger soll restriktiv die Datenverarbeitung reguliert werden, son- dern vielmehr sollen die Kompetenzen der Nutzenden gest\u00e4rkt werden, damit sie sou-  \nver\u00e4n und selbstbestimmt ihre Daten zur Weiterverarbeitung freigeben (oder auch nicht) und daf\u00fcr Bedingungen festlegen. Hierf\u00fcr ist es n\u00f6tig, vormals technische Themen  \nder Datensicherheit zum Gegenstand sozial-wissenschaftlicher Forschung zu machen und \u00fcber interdisziplin\u00e4re Konzepte die Daten-souver\u00e4nit\u00e4t der Menschen zu st\u00e4rken.     For esight ist methodisch angeleitete Hoch-\nrechnung zuk\u00fcnftiger Entwicklungen. F\u00fcr eine konstruktive Integrierte Forschung d\u00fcr -\nfen sozial- und geisteswissenschaftliche F\u00e4-cher nicht den technischen Entwicklungen hinterherhinken, sondern sollten ihnen einen Schritt voraus sein. Erst wenn die Zukunft nicht allein aus technischen Visionen besteht, sondern auch gesellschaftliche Szenarien beinhaltet, k\u00f6nnen soziale, rechtliche und ethische Implikationen neuer Technologien vorausschauend modelliert und adressiert werden.\nIn Zukunft wird die Integrierte Forschung zu-nehmend gefragt sein. Sie hat Potenzial, bei dr\u00e4ngenden innovationspolitischen Herausfor -\nderungen Gesellschaft und Wissenschaft, For -\nschung und Anwendung zusammenzubringen. Dabei er\u00f6ffnet sie auch neue Themenbereiche.14 \nAusflug ins Universum von Blockchain \nund Smart Contracts\nDr. Patrick Schweitzer  D\u00e9sir\u00e9e Tillack\nWie n\u00e4hert man sich dem komplexen Thema \nBlockchain (BC)? Wir versuchen es mit einem Selbsttest, bei dem im Online-Casino die Kryp-tow\u00e4hrung Ether verwettet werden soll. Wir betrachten die besonderen Eigenschaften die-ser Technologie \u2013 und stimmen uns ein mit ei-nem Besuch im Bitcoin-Caf\u00e9.\nBerlin Kreuzberg, ein Freitagabend im M\u00e4rz. \nDas Etablissement \u201eRoom 77\u201c verspricht mit seinen abgewetzten Ohrensesseln zwar op-tisch eher eine Zeitreise in eine Kaschemme der 1980er-Jahre, doch hier kann man mit Bitcoins zahlen \u2013 ein guter Startpunkt f\u00fcr die Recherche und Treffpunkt, um zusammen im Online-Casi-no zu spielen. Au\u00dferdem gibt es exzellente Bur -\nger, beispielsweise mit flambiertem Rum oder Erdnussbutter. Allerdings hapert es mit dem Besuch im Online-Casino: Daf\u00fcr braucht man nicht nur WLAN und gen\u00fcgend Akku, sondern auch Speicherplatz auf dem PC. F\u00fcr das Spielen und Wetten gibt es zwei Varianten: Beim ers-ten Versuch \u00fcber die Software \u201eMist\u201c soll man eine BC komplett herunterladen, was zu einer Prognose von 340 GB Downloadvolumen und einer gesch\u00e4tzten Dauer von einem Tag f\u00fchrt.\n1  \nDer Ausflug ins Online-Casino wird kurzerhand verschoben. Er ist schlie\u00dflich erfolgreich, aber dazu sp\u00e4ter. Weil wir es eilig haben, bezahlen wir die Burger nicht einmal mit Bitcoins. Wir m\u00fcssten vor Ort zehn bis 15 Minuten warten, bis die Best\u00e4tigung der Transaktion eingetrof-fen ist. Obwohl wir f\u00fcr diesen Abend extra Kryptow\u00e4hrung gekauft hatten (s. Abschnitt \u201eDie Blockchain im Reality-Check\u201c), holen wir also den guten alten Euro aus der Tasche und zahlen bar auf die Hand. Auf dem Weg zur S-Bahn fragen wir uns, woher der Hype eigent-lich kommt, wenn die Anwendung so schwie-rig zu sein scheint.\nWarum ist die Blockchain \nso innovativ?\nZahlreiche Expertinnen und Experten prognos-\ntizieren, dass die Technologie der BC das gesell-schaftliche Leben und die Landschaft einzelner Industrien ver\u00e4ndern wird.\n2 Schon vor einigen \nJahren begann der Hype um dieses Thema, die momentan bekannteste Anwendung der Tech-nologie ist die Kryptow\u00e4hrung Bitcoin. Laut einer Umfrage des Branchenverbandes Bitkom kennen rund zwei Drittel aller Deutschen Bit-coins.\n3 Sp\u00e4testens seit dem H\u00f6henflug der Bit-\ncoins um den Jahreswechsel 2017/2018 ist die BC-Technologie im Mainstream angekommen. Doch die BC kann noch viel mehr als Kryp-tow\u00e4hrung.\nZun\u00e4chst ist eine BC nichts weiter als eine \nDatenbank \u2013 sie grenzt sich von anderen Da-tenbanken jedoch mittels einiger besonderer Eigenschaften ab: Innovativ ist die Tatsache, dass diese Datenbank verteilt ist. Das hei\u00dft, dass alle an der BC Beteiligten die Daten an-schauen, sie aber nicht r\u00fcckwirkend \u00e4ndern k\u00f6nnen, da jeder eine identische Kopie der Datenbank besitzt und \u00c4nderungen zus\u00e4tzlich kryptographisch verhindert werden. Wie in je-der anderen Datenbank m\u00fcssen auch bei BCs Lese- und Schreibrechte festgelegt werden (s. Infokasten).\n4 Ein gro\u00dfer Unterschied zu klassi-\n40 JahreAusflug ins Universum von Blockchain und Smart Contracts \u00a7  15\nschen Datenbanken ist aber, dass die BC keinen \nzentralen Inhaber ben\u00f6tigt.\nDas Modell der Akteure mit unterschiedlichen \nRechten und Regeln l\u00e4sst sich f\u00fcr unseren Fall vereinfacht mit einem Fu\u00dfballturnier verglei-chen: \u00c4hnlich wie bei der Weltmeisterschaft gibt es im Stadion des BC-Universums Spieler, die sich an die Regeln halten m\u00fcssen, um teil-nehmen zu k\u00f6nnen. Dann gibt es Fans vor Ort, die von den R\u00e4ngen aus auf das Geschehen bli-cken und beteiligt sind, indem sie jubeln, zum Beispiel wir Autoren als Gamer im Casino, die eine Transaktion t\u00e4tigen. Und schlie\u00dflich gibt es noch die Zuschauer vor den Fernsehern, die zwar nicht eingreifen, jedoch alles \u00fcberblicken, etwa die Leser, die am Schluss unsere Transakti-on \u00f6ffentlich in der BC einsehen k\u00f6nnen. \nEine andere innovative Eigenschaft der BC ist, \ndass sie als Werkzeug dazu dienen kann, die Integrit\u00e4t (Korrektheit) sich \u00e4ndernder Daten zu erreichen und aufrecht zu erhalten. Es kann also beispielsweise der Status von Daten zu einem gewissen Zeitpunkt dauerhaft und un-ver\u00e4nderbar festgehalten werden. Dieses Prin-zip funktioniert im betrachteten Fall der Kryp-tow\u00e4hrungen umso besser, je mehr sich an der BC beteiligen. Damit m\u00f6glichst viele Beteiligte die vorherigen Daten pr\u00fcfen und best\u00e4tigen, also die Integrit\u00e4t der Daten gew\u00e4hrleisten, bedarf es eines Anreizsystems. Teil des Anreiz-systems sind ein Konsensalgorithmus und eine Kryptow\u00e4hrung.\n5 \nEine weitere Innovation der BC ist schlie\u00dflich, dass die Anzahl von Vermittlern reduziert wird oder diese vollst\u00e4ndig \u00fcberfl\u00fcssig gemacht wer -\nden. Durch eine BC wird sichergestellt, dass alle die gleichen Prozessregeln verwenden und die Datenabgleichsprozesse (\u201eReconciliation\u201c) aus-geschaltet werden. Ein Beispiel: Der Transfer von Kryptow\u00e4hrung ist m\u00f6glich, ohne dass da-bei Banken, Paypal oder \u00e4hnliche Dienstleister in der Funktion von Mittlern notwendig sind. Es muss kein Geld gedruckt oder physisch \u00fcber -\ngeben werden, und auch die Infrastruktur wird von den Transferierenden selbst bereitgestellt anstatt von einem Dienstleister. Man spricht hierbei von Disintermediation. Die BC kann also deutlich g\u00fcnstiger sein als herk\u00f6mmliche L\u00f6sungen. Zus\u00e4tzlich ersetzt sie die Vertrauens-funktion, die zuvor die Vermittler \u00fcbernommen haben. Der Nutzen der BC ist besonders gro\u00df, wenn die Akteure ein gr\u00f6\u00dferes Vertrauen in die BC-Technologie haben als in die bisherigen Mittler.\nUns wird klar: Je tiefer wir in das Thema BC ein-\nsteigen, desto mehr Fragen ergeben sich. Wir wollen wissen, wie einerseits eine BC funktio-niert, wie also Daten in einer BC abgespeichert werden und andererseits, welche Daten eigent-lich abgespeichert werden.\nVier Arten von BCs \n \u00a1BC mit Lese- und Schr\neibrecht f\u00fcr alle (englisch: public, permissionless) \u2013 wird z.\n B. \neingesetzt f\u00fcr Bitcoin, Ether\n, andere Kryptow\u00e4hrungen\n \u00a1BC mit Leser\necht f\u00fcr alle, aber begrenztem Schreibrecht (englisch: public, permissi-\noned)\u00a0\u2013 wird z.\n B. eingesetzt f\u00fcr ein staatliches Register\n \u00a1BC mit begr\nenztem Leserecht, aber Schreibrecht f\u00fcr alle (englisch: private, permissi-\nonless) \u2013 ist f\u00fcr Anwendungen aktuell eher un\u00fcblich\n \u00a1BC mit begr\nenztem Lese- und Schreibrecht (englisch: private, permissioned) \u2013 wird \nmomentan vor allem in/von Unternehmen eingesetzti16 \nWie funktioniert eine \nBlockchain?\nMan stelle sich die BC wie ein Buch vor, zu dem \nam Ende Seiten hinzugef\u00fcgt werden, aus dem aber niemals bestehende Seiten entfernt wer -\nden k\u00f6nnen. Das Buch ist in diesem Bild die BC und jede Seite ist ein \u201eBlock der Chain\u201c, be-stehend aus Informationen. Mit kryptographi-schen Techniken\n6 wird sichergestellt, dass die \nneuen Informationen in den Bl\u00f6cken bestimmte Regeln einhalten.\n7 Wer einen neuen Block er -\nzeugt, ist ein \u201eMiner\u201c, d. h. er \u201esch\u00fcrft\u201c die Kryptow\u00e4hrung f\u00fcr sich selber, w\u00e4hrend er die Informationen f\u00fcr alle sichert. Jeder Block enth\u00e4lt unter anderem Informatio-nen \u00fcber die Blocknummer, die im Block ent-haltenen Transaktionen und einen Verweis auf einen vorangegangenen Block (s. Abbildung 1). Durch den Verweis auf einen vorherigen Block wird dessen Inhalt best\u00e4tigt. Nicht-re-gelkonforme Bl\u00f6cke werden zwar in die BC aufgenommen, sp\u00e4ter aber beim \u201eR\u00fcckw\u00e4rts-lesen\u201c \u00fcbersprungen, da das Anreizsystem daf\u00fcr sorgt, dass auf den letzten vorherigen regelkonformen Block verwiesen wird. Hier kommt auch ein Nachteil der Technologie zum Tragen, der uns bei der Bezahlung der Burger ausgebremst hat: Ob ein Block tats\u00e4chlich re-gelkonform ist und auf lange Sicht ber\u00fccksich-tigt wird, kann nicht unmittelbar, sondern erst nach einer Weile entschieden werden \u2013 n\u00e4m-\nAbb. 1: Ansicht einer BC im Explorer auf https://etherscan.io: Oben im blauen Block erscheinen die Informationen zur gesamten \nBC (wie Gesamtsumme der Ether und Gesamtanzahl der Transaktionen), darunter die Auflistung der letzten Bl\u00f6cke in grauen K\u00e4sten mit erg\u00e4nzenden Angaben (wie enthaltene Transaktionen und Dauer zum Erstellen des Blocks). In der rechten Spalte erscheint \u2013 f\u00fcr alle einsehbar \u2013 die Historie der Transaktionen.Block Nr. \n5691428Anzahl der im Block  erhaltenen TransaktionenDauer zum Erstellen des BlocksAusflug ins Universum von Blockchain und Smart Contracts \u00a7  17\nlich dann, wenn eine Kette von Bl\u00f6cken auf \nden fraglichen verweist.8\nUm eine Information, also einen \u201eInhalt\u201c egal welcher Art, in die BC zu schreiben, sucht man eine Schnittstelle (einen Zugangsknoten) auf, teilt diesem den eigenen Inhalt mit und gibt an, wieviel man bereit ist zu zahlen, damit der In-halt in die BC aufgenommen wird. Hierbei geht es um eine Transaktionsgeb\u00fchr (\u201etransaction fee\u201c), die mit der Gr\u00f6\u00dfe des Inhalts steigt. Der Zugangsknoten \u00fcberpr\u00fcft zun\u00e4chst, ob der ge-w\u00fcnschte Inhalt den Regeln der BC entspricht. Ist dies der Fall, wird der Inhalt akzeptiert und in den sogenannten Miningpool weitergeleitet. Aus dem Miningpool fischen die Miner den Inhalt heraus und h\u00e4ngen ihn dann in einem  Block an die bisherige Kette von Bl\u00f6cken \u2013 wenn sie sich als berechtigt erwiesen haben. Auf Basis der Transaktionsgeb\u00fchr k\u00f6nnen die Miner die lukrativsten Inhalte zuerst ausw\u00e4hlen.\n9\nDie Blockchain im Reality-Check\nZur\u00fcck zum Test des Online-Casinos, f\u00fcr den wir im ersten Schritt eine Kryptow\u00e4hrung ben\u00f6tigen. Wer diese ergattern will, braucht zuerst eine  \ndigitale Geldb\u00f6rse (\u201eonline wallet\u201c).\n10 Diese  \nbesteht aus einer ziemlich langen \u00f6ffentlichen und einer ebenso langen privaten Zeichen- und Nummernfolge (\u201eSchl\u00fcssel\u201c). Die \u00f6ffentliche Zeichenfolge, auch \u00f6ffentliche Adresse genannt, ist vergleichbar mit einer E-Mail- oder Paypal-  \nAdresse, an die Geld gesendet wird. Die private Zeichenfolge ist einem Passwort \u00e4hnlich. Beim \nAbb. 2: Weg einer Transaktion und Prozess des \u201eMinens\u201c am Beispiel von MyEtherWallet  \nQuelle: MyEtherWallet, eigene \u00dcbersetzung \n \n TXTXTX\nTXTXTXTX\nTXTXTX TXTX TX\nTXTX\nTXTXTXTXTX\nNew block \non the kid\nTXTXTX\nTXTXTXTXTXTX\nTXTXTXTXTXTX\nTXTXTXTXTXTX\nTXTXTXTXTXTX\nTXTXTXTXTXTX\nTXTXTXTXTXTX\nTXTXTXMEWSLIDE\u2018OFUN1.  Transaktion (TX) wird  \nunterschrieben\n \n2.  \nTransaktion wird  \nan MyEtherWallet (MEW) gesendetTX TX TX MyEtherWallet3. Transaktion geht an einen Knotenpunkt von MyEtherWallet\n\u00dcber der Linie sind die Schritte, f\u00fcr die MyEtherWallet verantwortlich ist, \ndarunter diejenigen, die die Funktionsweise der Blockchain verdeutlichen.\nTX: Transaktion4. \n V\nom Knotenpunkt aus wird die Transaktion \nin einen Transaktions-Pool geleitet\nDie Transaktion ist permanent, sobald sie in der Blockchain ist. 5. \n Die Miner fischen \nT\nransaktionen aus \ndem Pool heraus.\n6. \n Die Miner setzen \n \ndie Transaktion in  einen Block und  f\u00fcgen ihn der  Kette hinzu.DDOS  \nShield18 \nErstellen des wallets lautet die Warnung auf \nder Startseite: \u201ePlease take some time to under -\nstand this for your own safety [frown-icon]. Your funds will be stolen if you do not heed these warnings.\u201d Es folgt eine Vielzahl weiterer Sicher -\nheitshinweise. Wer die digitale W\u00e4hrung wirklich sicher lagern will, soll sich seine digitale Geldb\u00f6r -\nse ausdrucken \u2013 auf Papier! Und nicht nur die Papierl\u00f6sung wird empfohlen: F\u00fcr ca. 60 bis 80 Euro kann man sogar kleine K\u00e4sten zum kom-plett vom Internet getrennten Speichern von den privaten Schl\u00fcsseln erwerben. Wir schieben Bedenken aber gro\u00dfz\u00fcgig beiseite und nach zwei Tagen besitzt das Autorenteam statt rund 90 Euro ca. 0,184 Ether (ETH)\n11 und steht in den \nStartschuhen f\u00fcr das Wetten im Online-Casino.\nIm zweiten Anlauf \u2013 zu Hause mit einer Tasse \nKaffee neben dem Laptop \u2013 testen wir einen alternativen Weg in die Online-Spielh\u00f6lle, ohne die BC herunterladen zu m\u00fcssen.\n12 Wir werden \naufgefordert, mindestens 0,1 Ether einzuset-zen. Wir erkl\u00e4ren uns einverstanden und schlie-\u00dfen mit dem digitalen \u201eeinarmigen Banditen\u201c einen Vertrag ab. Das Spielen funktioniert so: Man setzt auf eine Zahl zwischen 1 und 100. Wenn der einarmige Bandit eine niedrigere Zahl ausspuckt, hat man gewonnen, liegt die Zahl dar\u00fcber, hat man verloren. Je niedriger die gew\u00e4hlte Zahl, umso geringer die Chance und umso h\u00f6her der ausgezahlte Gewinn. Das Spiel ist direkt mit dem online-wallet verkn\u00fcpft, so-dass Gewinne und Verluste sofort abgerechnet und angezeigt werden.\nAus technischer Sicht funktioniert das Spiel \nnach folgendem Prinzip, das einen einfachen Vertrag verdeutlicht: \u201eWenn wir einen Betrag von 0,1 ETH setzen, dann wird uns im Gewinn-fall ein Betrag von 0,1 plus x ETH ausgezahlt.\u201c Wenn wir verlieren, bekommen wir nur einen Kleinstbetrag zur\u00fcck\u00fcberwiesen (siehe Info-kasten). So wissen wir sowohl im Fall des Ge-winns als auch im Fall des Verlustes, dass der geschlossene Vertrag tats\u00e4chlich ausgef\u00fchrt wurde. Wie bei Computerprogrammen \u00fcblich, k\u00f6nnen die Spieler die Gewinnchance und die Gewinnh\u00f6he ver\u00e4ndern.\n13\nEin Smart Contract bei Etheroll   \nExemplarische Code-Ausz\u00fcge aus dem Smart Contract von Etheroll (angepasste Darstellung): Im Programmcode existiert jeweils eine Funktion f\u00fcr den Fall, dass der Spieler gewonnen hat und eine Funktion f\u00fcr den Fall, dass der Spieler verloren hat (Wenn-Dann-Bedingung).i\n* win;* pay winner* update contract balance to calculate new max bet; send reward* if send of reward fails save value to playerPendingWithdrawalsif(playerDieResult[myid] < playerNumber[myid]){\n \u2026 }\n* no win;* send 1 wei to a losing bet* update contract balance to calculate new max betif(playerDieResult[myid] >= playerNumber[myid]){\n \u2026 }https://etherscan.io/\ntx/0x6247108a2d-95c6a76\n9b92df291ef63b-\nbd25ffa673fc7b-c9a6a60bb8\ndfb6a7f5ehttps://etherscan.io/\ntx/0xe5aa09c78de-90ba7663be1e-a06e82cf-7ce5768701c-1434c51d-d4a362e3f5ddbcAusflug ins Universum von Blockchain und Smart Contracts \u00a7  19\nDer \u201eInhalt\u201c der BC ist im Fall des Gl\u00fccksspiels \nunser intelligenter Vertrag (\u201eSmart Contract\u201c) \u00fcber Verlust oder Gewinn. Er besagt, dass eine gewisse Summe der Kryptow\u00e4hrung von einer Adresse zu einer anderen Adresse \u00fcbertragen wird.\n Genauer gesagt ist ein \u201eSmart Contract\u201c \nein Softwarecode in einer Programmiersprache, die von der BC verstanden wird.\n14 Der Code \nfolgt einem Wenn-Dann-Muster und bildet da-bei vertragliche Regelungen ab. \nEndlich kann es losgehen mit der Spielerei: \nWir gehen erst einmal m\u00f6glichst auf Nummer sicher und setzen auf die Zahl 94. Wir klicken \u201eroll\u201c und nach ca. einer Minute, die sich ge-f\u00fchlt unendlich lang zieht, erscheint auf dem Bildschirm eine gro\u00dfe gelbe 14 als Ergebnis. Wir haben also gewonnen! Sofort erscheint im Online-Wallet statt 0,184 ETH die geringf\u00fcgig h\u00f6here Gesamtsumme von rund 0,19 ETH. Der schnelle Erfolg und das einfache Prinzip ma-chen s\u00fcchtig: Beim zweiten Mal sind wir schon etwas risikofreudiger und setzen auf die 85. Als Ergebnis erscheint eine 58 \u2013 und der Ge-winn bringt das Ether-Konto umgehend auf rund 0,2 ETH. Um uns selber davon abzuhal-ten, die ganze Nacht weiterzuspielen und alles Gewonnene wieder auf den Kopf zu hauen, klappen wir ganz schnell den Rechner zu. Die-se beiden Transaktionen sind nun unver\u00e4nder -\nbar und f\u00fcr alle einsehbar in der BC sichtbar:  \nBlockchain kann mehr als Online-Casino\nBei BC geht es allerdings um viel mehr als das Gewinnen oder Verlieren, das f\u00fcr diesen Beitrag als eine Beispiel-Anwendung gew\u00e4hlt wurde. Wie bereits eingangs geschildert, k\u00f6nnten vor allem diejenigen Branchen, in denen Mittler oder Treuh\u00e4nder eingesetzt werden, revolutio-niert werden. Darunter fallen beispielsweise Fi-nanzdienstleistungen, das Versicherungswesen, Beh\u00f6rden, notarielle Dienstleistungen, Steuer- systeme, Wahlen, das Bildungs- und das Ge-sundheitswesen, Management von Lieferketten,  \nInternet der Dinge, intelligente Energiesysteme oder die Musikindustrie.\n15\nDiesen Anwendungen zugrunde liegt die Ei-genschaft der BC, gewisse Informationen zu einem gewissen Zeitpunkt festzustellen und ab-zusichern (\u201eproof\u201c). Beispielsweise k\u00f6nnen im Fall von Steuern die Inhaberschaft und der Wert von Papieren zu einem gewissen Zeitpunkt fest-geschrieben werden. Zahlreiche weitere An-wendungen sind denkbar (s. Infokasten S. 20).\nWie geht es weiter mit \nder Blockchain?\nOb der Einsatz von BCs sinnvoll ist, steht und \nf\u00e4llt mit dem jeweiligen Anwendungsfall. F\u00fcr zahlreiche Herausforderungen, bei denen aktu-ell schnell nach BCs gerufen wird, kann auch eine herk\u00f6mmliche Datenbank die beste L\u00f6-sung sein. In diesem Beitrag wurden lediglich zwei Beispielanwendungen (Bezahlen und Spie-len) aufgegriffen, um die Innovation und die Funktionsweise der Technologie darzulegen. Die BC- und die Distributed-Ledger-Technologie stehen noch ziemlich am Anfang. Auch die fol-genden geschilderten Anwendungen k\u00f6nnen nur schlaglichtartig m\u00f6gliche weitere Entwick-lungen aufzeigen.\nUnter den Akteuren, die das Potenzial der \nBC-Technologie f\u00fcr sich erkannt haben, ist vor allem die Finanzbranche: In der Schweiz gibt es bereits 24 Bitcoin-Automaten, die f\u00fcr Kundin-nen und Kunden das e-Geld, also die \u00f6ffent-liche Adresse und den privaten Schl\u00fcssel, auf Papier ausdrucken.\n16 Nach einem zweij\u00e4hrigen \nFeldtest plant die australische B\u00f6rse noch in die-sem Jahr auf Distributed-Ledger-Technologien umzusteigen, um das bisherige Abwicklungs-system f\u00fcr Transaktionen zu ersetzen.\n17 Dies \nzieht so weite Kreise, dass berichtet wird, dass sich Konkurrenten dar\u00fcber informieren wol-20 \nlen.18 Dar\u00fcber hinaus zielt beispielsweise das \nProjekt \u201eBitPesa\u201c darauf ab, Liquidit\u00e4ts- und \nW\u00e4hrungsprobleme in Afrika zu reduzieren, sodass Gesch\u00e4fte in ganz Afrika unabh\u00e4ngig von den jeweiligen Landesw\u00e4hrungen get\u00e4tigt werden k\u00f6nnen.\n19 Und die auf BC basierende \nWahlsoftware \u201eFollow my vote\u201c steckt noch in den Kinderschuhen, hat aber das Potenzial, f\u00fcr transparente Wahlen zu sorgen.\n20 Auch Smart \nContracts werden bereits eingesetzt, beispiels-weise f\u00fcr Treuhandgesch\u00e4fte, Mikropayments, flexible Stromrechnungen, M\u00fcnzwechselproto-kolle, Initial Coin Offerings (also Kryptow\u00e4hrun-gen, die neu auf den Markt gebracht werden) oder Mehrspieler-Lotterien.\n21  \nSoweit der potenzielle Nutzen, nun zu den Ri-siken. Die Elimination von Mittlern klingt zwar verlockend, doch diese erf\u00fcllen neben der ei-gentlichen Vermittlungst\u00e4tigkeit h\u00e4ufig auch andere Aufgaben, darunter Beratungst\u00e4tigkei-ten, oder sie \u00fcbernehmen Garantien, f\u00fcr den Fall, dass es zu Problemen bei Transaktionen kommt. Andere Nachteile der BC sind oft auch noch aufkommende zeitliche Verz\u00f6gerungen\n22 \noder ein f\u00fcr die Datenverarbeitung immenser Energieverbrauch beim derzeit \u00fcblichsten Kon-sensalgorithmus \u201eproof of work\u201c (beispiels-weise im Fall von Bitcoins). Nicht nur der Ener -\ngieverbrauch, auch die Rechenleistung kann Probleme mit sich bringen: Wenn ein Gro\u00dfteil dieser Rechenleistung n\u00e4mlich in der Hand von wenigen liegt, k\u00f6nnen diese wenigen bestim-men, was aus ihrer Sicht korrekt ist. Das System funktioniert nur so lange, wie gew\u00e4hrleistet ist, dass die Mehrheit der Beteiligten sich an die Re-geln h\u00e4lt.\nUnd es gibt weitere Risiken, die noch nicht aus-\nreichend betrachtet worden sind, wie beispiels-weise die Tatsache, dass illegale Inhalte in BC geschrieben werden, aber nicht gel\u00f6scht wer -\nden k\u00f6nnen. Somit k\u00f6nnen auch illegale Ver -\ntr\u00e4ge abgeschlossen und best\u00e4tigt werden. Eine besondere Herausforderung bei dezentralen Systemen liegt also im Bereich der Regulierung und Rechtssicherheit. Und schlie\u00dflich entstehen durch BCs enorme Datenmengen, von denen \nEinsatzm\u00f6glichkeiten von BCs\n23\n \u00a1Pr oof of existence: Registrierung von Artikeln, die eindeutig sein sollen, wie  \nMarkennamen, Patente, Lizenzcodes und Internet- oder E-Mail-Adressen\n \u00a1Pr\noof of nonexistence: Beschwerden, Geldbu\u00dfen, Verurteilungen\n \u00a1Pr\noof of time: Zeitstempelfunktionen f\u00fcr Ereignisse wie Zustellung oder Benach-\nrichtigungsverfolgung, Verfolgung von Zahlungen, Verwaltung von Vorhersagen\n \u00a1Pr\noof of order: Verfolgung von Anwendungsprozessen, \u00dcberwachung \u00f6ffentlicher \nBieterverfahren und Treuhanddienste sowie Nachweise, dass ein Ereignis das erste oder das letzte seiner Art war, z. B. Antr\u00e4ge von Universit\u00e4ten, Patentanmeldungen oder Urheberrechtsanspr\u00fcche\n \u00a1Pr\noof of identity: digitale Ausweisdokumente f\u00fcr Menschen, Tiere oder G\u00fcter\n \u00a1Pr\noof of authorship: elektronisches Publizieren, Verfolgen von Inhalts\u00e4nderungen \nin Dokumenten, Inhaltsbereitstellung, kollaboratives Bearbeiten und Sch\u00fctzen von Urheberrechten\n \u00a1Pr\noof of ownership: Anwendungen mit diesem Nutzungsmuster sind  \nbeispielsweise Systeme zur Verwaltung des Eigentums an Immobilien, Autos,  Unternehmensanteilen, Anleihen, kryptografischen W\u00e4hrungeniAusflug ins Universum von Blockchain und Smart Contracts \u00a7  21\nam Ende nur noch ein geringer Anteil relevant \nist. F\u00fcr wen ist beispielsweise letztendlich auf Dauer interessant, dass wir 0,02 ETH im Casino gewonnen haben?\nIn welchem Ausma\u00df und in welchen Anwen-\ndungsf\u00e4llen sich die BC-Technologie durchset-zen kann, erscheint dem Autorenteam noch wie ein Blick in die Kristallkugel. Wie auch im-mer sich die Technologie entwickelt \u2013  falls nach weiteren Casino-Besuchen in unserem Wallet noch ein paar Zehntel Ether \u00fcbrig sind, planen wir eine Fortsetzung der Geschichte, bei der wir die gewonnene Kryptow\u00e4hrung in Avatare investieren, die im Ether-quest-Rollenspiel ihre Abenteuer erleben.\n24\n1 Durch K omprimierungstechniken wird das tats\u00e4chliche Downloadvolumen auf 60 GB reduziert und der Download dauert ca. sechs Stunden.\n2 Dies gilt ebenfalls f\u00fcr die \u00fcbergeordnete Distributed-Ledger -Technologie (DLT), wof\u00fcr BC nur eine m\u00f6gliche Umsetzung ist. In diesem Beitrag\n werden jedoch nur BCs betr\nachtet.\n3 https://www .bitkom.org/Presse/Presseinformation/Inzwischen-kennen-zwei-Drittel-der-Bundesbuerger-Bitcoin.html [Zugriff am 26.3.2018].\n4 Da f\u00fcr diesen Beitr ag das Beispiel Kryptow\u00e4hrung gew\u00e4hlt wurde, wird im Folgenden der Fall einer BC mit Lese- und Schreibrechten f\u00fcr alle\n (public,\n permissionless) betrachtet.\n5 Der K onsensalgorithmus wird im Entstehungsprozess der BC festgelegt. Der g\u00e4ngigste Algorithmus w\u00e4hlt aus einer m\u00f6glichst gro\u00dfen Gruppe\n zuf\u00e4llig eine P\nerson aus, die die BC ein St\u00fcck verl\u00e4ngert und gleichzeitig die Korrektheit der bisher geschriebenen Inhalte best\u00e4tigt. Die Auswahl\n basiert dar\nauf, welcher Computer ein komplexes mathematisches Problem am schnellsten gel\u00f6st hat. Bezeichnet wird dies als \u201eproof of work\u201c \u2013\n hergeleitet von der ben\u00f6tigten Rechenleistung,\n die eingesetzt werden muss, um das mathematische Problem zu l\u00f6sen.\n6 V or allem werden hier asymmetrische Verschl\u00fcsselung und Hashes (kryptografische Komprimierungstechniken) eingesetzt.\n7 Der Beginn einer BC mit einem P ersonenkreis, der die Regeln definiert, findet beispielsweise \u00fcber ein Konsortium statt, das gemeinsam eine\n Kryptow\n\u00e4hrung zum Initial Coin Offering und damit auf den Markt bringt.\n8 Die L\u00e4nge der auf den Block verweisenden K ette wird im Fachjargon als Anzahl der confirmations (Best\u00e4tigungen) bezeichnet.\n9  Neben dem \u201eInhalt\u201c werden noch weitere Informationen in den Block aufgenommen,  die man zum Erf\u00fcllen der Sicherheitseigenschaften der BC\n ben\u00f6tigt.\n Diese erm\u00f6glichen beispielsweise das Ermitteln des vorangegangenen Blocks, der Schwierigkeit des Konsensalgorithmus sowie der\n L\u00f6sung des vom K\nonsensalgorithmus vorgegebenen mathematischen Problems. Dar\u00fcber hinaus d\u00fcrfen die Miner noch einen besonderen Inhalt\n selbst schreiben.\n Durch diesen k\u00f6nnen sie einer beliebigen Adresse ein Entgelt zuweisen, ohne definieren zu m\u00fcssen, wo das Entgelt herkommt\n (Sch\u00fcrfen der Kryptow\n\u00e4hrung).\n10 Wir haben uns f\u00fcr ein Online-P ortemonnaie bei \u201eMyEtherWallet\u201c entschieden.\n11 Kauf am fr\u00fchen Morgen des 16.3.2018.\n12 Wir nutzen Chrome mit dem Add-On \u201eMetaMask\u201c und geben den privaten Schl\u00fcssel am Eingang zum Online-Casino Etheroll ein. Bei MetaMask\n m\u00fcssen wir k\neine BC herrunterladen, da MetaMask diese online bereitstellt.\n13 W er unsere Interaktion mit dem Smart Contract direkt nachvollziehen m\u00f6chte, kann sich das in die BC geschriebene Computerprogramm unter\n https://etherscan.io/address/0xddf0d0b9914d530e0b743808249d9af901f1bd01#code ansehen [Zugriff am 26.3.2018].\n14 Im F all des Ethereum-Netzwerks ist dies die Programmiersprache \u201eSolidity\u201c.\n15 W alport, M. 2016. \u201eDistributed Ledger Technology: Beyond Blockchain. Uk Government Office for Science\u201c, Tech. Rep und Blockchain for Dummies: \n https://public.dhe\n.ibm.com/common/ssi/ecm/xi/en/xim12354usen/XIM12354USEN.PDF [Zugriff am 26.3.2018].\n16 https://coinatmr adar.com/country/206/bitcoin-atm-switzerland/ [Zugriff am 26.3.2018].\n17 https://de .reuters.com/article/m-rkte-australien-idDEKBN1E11SL [Zugriff am 26.3.2018].\n18 https://cointelegraph.com/news/hong-kong-stock-exchange-seeks-dialogue-with-australian-counterpart-for-blockchain-advice \n [Zugriff am 26.3.2018].\n19 www .bitpesa.co [Zugriff am 26.3.2018].\n20 W eitere derzeit umgesetzte Beispiele unter www.nasdaq.com/article/7-most-interesting-uses-of-blockchain-cm875394 [Zugriff am 26.3.2018].\n21 Zu Smart Contr acts siehe www.kaspersky.de/blog/ethereum-ico/14993 (Einsatz bei ICOs), www.it-finanzmagazin.de/gar-kein-\n mysterium-blockchain-verstaendlich-erklaert-27960,\n https://futurezone.at/digital-life/blockchain-was-sind-eigentlich-smart-\n contr\nacts/293.031.908, www.dev-insider.de/was-ist-ein-smart-contract-a-585679 [Zugriff jeweils am 26.3.2018].\n22 Bei Bitcoins wird ein Block durchschnittlich alle 10 Minuten geschrieben,  bei der Ethereum BC dagegen alle ca. 15 Sekunden.\n23 Beim Selbsttest dieses Beitr ags bewegen wir uns im Ethereum-Netzwerk mit public permissionless BCs, bei unserem Smart Contract haben wir\n mit der \u201eproof of ownership\u201c-Eigenschaft der BC inter\nagiert. Einige der Eigenschaften k\u00f6nnen besser / nur durch private oder permissioned BCs\n umgesetzt werden.\n24 https://ether -quest.com [Zugriff am 26.3.2018].22 \nImpfen \u2013 kleiner Pieks, gro\u00dfe Wirkung\nDr. Anne Endmann\nInfektionskrankheiten sind in den letzten Jahr -\nzehnten insbesondere in Industrienationen \ndurch den routinem\u00e4\u00dfigen Einsatz von Impfun-gen, einen h\u00f6heren Lebensstandard und ver -\nbesserte Hygiene sowie durch den Einsatz von Arzneimitteln als Todesursache weit zur\u00fcckge-dr\u00e4ngt worden.\n1\nBis ins fr\u00fche 20. Jahrhundert haben schwere Seuchen auch Mitteleuropa heimgesucht. Auf-grund der Gewalt, mit der sie \u00fcber die Bev\u00f6l-kerung hereinbrachen, wurden sie als schick-salhaftes oder g\u00f6ttliches Ereignis erachtet. Die Pocken, gef\u00fcrchtet durch hohe Infekti\u00f6sit\u00e4t und Sterblichkeitsraten sowie h\u00e4ufig schwe-re Sp\u00e4tfolgen bei den \u00dcberlebenden, waren \u00fcber Jahrhunderte in Europa verbreitet und wurden durch die Kolonialisierung in alle Tei-le der Welt verschleppt. Auf dem H\u00f6hepunkt der Pockenepidemien im 18. Jahrhundert fielen j\u00e4hrlich etwa 400.000 Menschen der Krankheit zum Opfer.\n2\nAuch wenn die Ausl\u00f6ser von Infektionskrank-heiten bis ins 19. Jahrhundert nicht bekannt waren, haben die Menschen bereits vor Tau-senden Jahren beobachtet, dass ein \u00dcberste-hen der Erkrankung vor einer erneuten Anste-ckung sch\u00fctzen kann. Aus dieser Beobachtung heraus wurden in China, Indien und der T\u00fcrkei Verfahren der sogenannten Variolation (abge-leitet vom lateinischen Fachbegriff der Pocken, Variola) entwickelt. Hierbei wurde Material aus Pockenbl\u00e4schen mild Erkrankter auf Gesunde \u00fcbertragen, was in einer zumeist schw\u00e4cher verlaufenden Infektion und darauf folgender Immunit\u00e4t resultierte.\n3 Damit wurde das Prinzip \nder Impfung entdeckt. Mithilfe weiterentwi-ckelter Impftechnologien, immer zahlreicherer Impfstoffe und ihrem breiten Einsatz gelang es, viele der einst so gef\u00fcrchteten Erreger und Erkrankungen deutlich einzud\u00e4mmen oder, wie im Fall der Pocken, sogar g\u00e4nzlich auszurotten.\nGeschichte des Impfens\nDie oben beschriebene Variolation war eine durchaus erfolgreiche und anerkannte Be-handlung, die sich im fr\u00fchen 18. Jahrhundert zun\u00e4chst in England und dann zunehmend auf dem europ\u00e4ischen Festland verbreitete. Die Schwierigkeit des Verfahrens bestand al-lerdings darin, dass eine behandelte Person zwar nur leicht erkrankte, aber dennoch hoch-gradig ansteckend war und daher von ande-ren Menschen isoliert werden musste. Noch schwerwiegender waren allerdings die damit verbundenen Risiken \u2013 die Pathogenit\u00e4t des Le-bendimpfstoffs war nicht zu kontrollieren, wo-durch etwa ein bis zwei Prozent der Geimpften starben\n5, ein f\u00fcr heutige Impfstoffe vollkom-\nmen inakzeptables Sicherheitsprofil.\nAuf der Suche nach Alternativen f\u00fcr die Va-\nriolation wurde das Wissen genutzt, dass eine Infektion mit Kuhpocken \u2013 einer f\u00fcr den Men-schen harmlosen Erkrankung \u2013 Schutz vor den gef\u00e4hrlichen Pocken bot.\n6 So wurde die Imp-\nfung mit Kuhpocken von der Landbev\u00f6lke-rung in Deutschland und England gelegentlich empirisch betrieben. Doch erst der englische Landarzt Edward Jenner (1749 bis 1823) un-tersuchte die Methode vom wissenschaftlichen Standpunkt aus und belegte ihre Schutzwir -\nkung, gleichwohl durch einen aus heutiger Sicht ethisch bedenklichen Menschenversuch. Er \u00fcbertrug das Pustelsekret einer an Kuhpo-cken erkrankten Magd \u00fcber einen Schnitt im Oberarm auf den achtj\u00e4hrigen Sohn seines G\u00e4rtners James Phipps. Die Methode wurde sp\u00e4ter als Vakzinierung (nach lateinisch vacca, Kuh) bekannt. Ihre Nebenwirkungen waren leichtes Fieber und Narben durch die Pustel-\n40 JahreImpfen \u2013 kleiner Pieks, gro\u00dfe Wirkung \u00a7  23\nbildung an den Impfstellen. Sechs Wochen \nsp\u00e4ter \u00fcberpr\u00fcfte Jenner den Erfolg seines Ex-periments, indem er Phipps mit echten Pocken infizierte. Der Junge blieb gesund, Jenner hat-te bewiesen, dass die Impfung mit Kuhpocken einen wirksamen Schutz gegen die echten Po-cken verlieh. Aufgrund dieser Wirksamkeit und der gemessen an den Folgen der Variolation geringen Nebenwirkungen verdr\u00e4ngte die Vak-zinierung die Variolation in Europa bald v\u00f6llig. Als Impfstoff wurde das Pustelsekret erkrankter K\u00fche oder geimpfter Kinder verwendet. \nNach der Gr\u00fcndung erster Impfanstalten An-\nfang des 19. Jahrhunderts in Deutschland ver -\nbreitete sich die Pockenimpfung allm\u00e4hlich in der Bev\u00f6lkerung. Eine umfassende Durchimp-fung konnte durch das 1874 verabschiedete Impfgesetz erreicht werden, welches eine ver -\npflichtende Erst- und Wiederholungsimpfung aller gesunden Kinder vorsah. Mittlerweile wur -\nde das Impfvirus systematischer unter Verwen-dung k\u00fcnstlich infizierter K\u00e4lber hergestellt und auf eine definierte Konzentration eingestellt. Gegen Ende des 19. Jahrhunderts bestand in fast jedem Staat Europas eine Impfpflicht ge-gen Pocken. In der Folge nahm die Zahl der Erkrankten erheblich ab, so dass bis auf ver -\neinzelte F\u00e4lle die Pocken in der westlichen Welt in den 1950er Jahren ausgerottet waren. Die Weltgesundheitsorganisation startete 1967 ein konsequentes, weltweites Impf- und Bek\u00e4mp-\nWirkweise und Arten von Impfstoffen\nDas Prinzip der Immunisierung liegt in einer Imitierung der nat\u00fcrlichen Infektion, so dass ein immunologisches Ged\u00e4chtnis, aber keine Krankheit ausgel\u00f6st wird. Diese Nachahmung wird traditionell durch die Verwendung inaktivierter oder abgeschw\u00e4chter Erreger als Impfstoffe erreicht, nicht selten aber auch durch Einzelbestandteile davon.\n4 \nDie Erreger oder deren Bestandteile enthalten als Antigene bezeichnete molekulare Komponenten, die nicht vom eigenen K\u00f6rper gebildet werden. Auf diese Weise wird dem Immunsystem eine Infektion mit gef\u00e4hrlichen Viren oder Bakterien vorget\u00e4uscht und es zu Abwehrma\u00dfnahmen angeregt, die bei einer sp\u00e4teren realen Infektion durch die Bildung von Ged\u00e4chtniszellen eine rasche Reaktion erm\u00f6glichen. Lebendimpfstoffe enthalten gew\u00f6hnlich abgeschw\u00e4chte Viren, die noch in menschliche Zellen eindrin-gen, aber sich darin nicht mehr vermehren k\u00f6nnen. Beispiele hierf\u00fcr sind der Masern-, R\u00f6teln-, Mumps-, und Pockenimpfstoff oder die fr\u00fcher auf einem Zuckerw\u00fcrfel verab-reichte Schluckimpfung gegen Kinderl\u00e4hmung. Diese Impfstoffe bewirken zwar einen lebenslangen Schutz, k\u00f6nnen aber in sehr seltenen F\u00e4llen durch Mutationen ihre Viru-lenz wiedererlangen und die volle Erkrankung verursachen, vor der sie sch\u00fctzen sollen. Inaktivierte Erreger, die nicht mehr \u00fcber die F\u00e4higkeit zur Replikation verf\u00fcgen, werden bei der saisonalen Grippeimpfung und bei der derzeit routinem\u00e4\u00dfigen Impfung gegen Kinderl\u00e4hmung eingesetzt. Sogenannte \u201eSubunit\u201c-Impfstoffe wie gegen Hepatitis B oder Keuchhusten enthalten nur Bestandteile der Mikroben, die dem Immunsystem als fremdes Antigen pr\u00e4sentiert werden, um eine Antwort zu provozieren. Einige Bakterien setzen bei Infektionen gef\u00e4hrliche Toxine frei, die die Krankheitssymptome verursachen. F\u00fcr die Toxoidimpfstoffe gegen Wundstarrkrampf und Diphterie werden diese Toxine so inaktiviert, dass die antigene Wirkung erhalten bleibt und das Immunsystem zur Bildung von Antik\u00f6rpern angeregt wird, die im Ernstfall einer Infektion die Toxine neutralisieren k\u00f6nnen.i24 \nfungsprogramm. In diesem Jahr wurden \u00fcber \n200.000 Erkrankungsf\u00e4lle in 31 L\u00e4ndern regis-triert, in denen die Pocken noch verbreitet wa-ren.\n7 F\u00fcr die n\u00f6tigen Massenimpfungen wur -\nden gefriergetrocknete, hitzestabile Impfstoffe eingesetzt. Durch einen hohen Durchimpfungs-grad der Bev\u00f6lkerung von \u00fcber 95 Prozent sowie dichte \u00dcberwachung und Eind\u00e4mmung von lokalen Ausbr\u00fcchen konnte die Infektkette dauerhaft unterbrochen werden. Die weltweit letzte nat\u00fcrliche Pockeninfektion wurde am 26. Oktober 1977 in Somalia detektiert und am 8. Mai 1980 verk\u00fcndete die WHO offiziell die voll-st\u00e4ndige Ausrottung der Pocken.\n8 \nNicht nur durch die Fortschritte bei der Be-k\u00e4mpfung der Pocken war das 19. Jahrhun-dert bahnbrechend f\u00fcr die Erfolgsgeschichte der Impfung. Basierend auf den Erkenntnissen von Forschern wie Louis Pasteur, Robert Koch, Emil von Behring und Paul Ehrlich sowie be-feuert durch die \u201eKeimtheorie der Krankheits-entstehung\u201c wurden Impfstoffe gegen weite-re Infektionskrankheiten entwickelt. So fand Louis Pasteur 1881 einen Impfstoff gegen den Milzbrand.\n9 Kurz darauf entwickelte Emil von \nBehring das erste Serum gegen Diphtherie und etwas sp\u00e4ter eine Impfung gegen Diphtherie. Die Diphtherie-Schutzimpfung geh\u00f6rt heute zu den Standardimpfungen f\u00fcr S\u00e4uglinge und tr\u00e4gt dazu bei, dass die Diphtherie, fr\u00fcher die Kinderkrankheit mit der h\u00f6chsten Sterblich-keitsrate, heute in den entwickelten L\u00e4ndern keine Rolle mehr spielt. Bis zur Mitte des 20. Jahrhunderts folgten weitere heute routinem\u00e4-\u00dfig eingesetzte Impfstoffe, unter anderem ge-gen Wundstarrkrampf, Keuchhusten, Influenza, Kinderl\u00e4hmung, Masern, Mumps und R\u00f6teln.\nParallel zum wissenschaftlichen Fortschritt bei \nder Entwicklung neuer Impfstoffe wurden um-fangreiche und bis heute immer komplexer wer -\ndende nationale und internationale Regelungen zur \u00dcberpr\u00fcfung der Sicherheit und Wirksam-keit selbiger erlassen.\n10 Diese Regelungen ent-\nstanden urspr\u00fcnglich als Reaktion auf schwere Komplikationen oder gar Todesf\u00e4lle nach der Anwendung von Impfstoffen. So wurde in den USA 1902 der sogenannte \u201eBiologics Control Act\u201c beschlossen, nachdem mehrere Kinder an Wundstarrkrampf durch einen kontaminierten Impfstoff gegen Diphterie gestorben waren.\n11   \nDas Gesetz verlangte eine Zulassung und j\u00e4hrli-che Inspektionen f\u00fcr Hersteller von Impfstoffen und kann als Ausgangspunkt f\u00fcr die Regulie-rung von Arzneimitteln durch die amerikani-sche Zulassungsbeh\u00f6rde FDA angesehen wer -\nden. Als Antwort auf die schwankende Qualit\u00e4t des von Emil von Behring entwickelten Serums gegen Diphterie wurde 1896 in Deutschland das Paul-Ehrlich-Institut (PEI) gegr\u00fcndet, um Regelungen zur staatlichen Arzneimittelkont-rolle zu entwickeln.\n12 Seit 1972 pr\u00fcft das PEI als \nBundesoberbeh\u00f6rde Daten von Herstellern zur Qualit\u00e4t, Wirksamkeit und Unbedenklichkeit f\u00fcr die Zulassung von Impfstoffen. Im gleichen Jahr wurde auch die St\u00e4ndige Impfkommission (STIKO) ins Leben gerufen, welche Empfehlun-gen zur Durchf\u00fchrung von Schutzimpfungen in Deutschland erarbeitet und regelm\u00e4\u00dfig pr\u00fcft sowie aktualisiert.\nAbb. 1: Impfung des achtj\u00e4hrigen James Phipps mit Kuhpo-\ncken durch den Arzt Edward Jenner (14. Mai 1796) Impfen \u2013 kleiner Pieks, gro\u00dfe Wirkung \u00a7  25\nBedeutung von Impfungen\nImpfungen z\u00e4hlen zu den effektivsten und \nkosteng\u00fcnstigsten pr\u00e4ventiven Ma\u00dfnahmen der modernen Medizin.\n13 Sie kosten sehr we-\nnig, sind aber mit gro\u00dfem Nutzen f\u00fcr die Ge-sundheit der Bev\u00f6lkerung verbunden. Zum drastischen R\u00fcckgang zahlreicher Infektions-krankheiten und insbesondere der Kindersterb-lichkeit im letzten Jahrhundert trugen \u2013 neben der allgemeinen Verbesserung der sozio\u00f6kono-mischen und hygienischen Bedingungen und der zunehmenden Verf\u00fcgbarkeit von Antibio-tika \u2013 Schutzimpfungen in hohem Ma\u00dfe bei. Nur der Zugang zu sauberem Trinkwasser hat global einen gr\u00f6\u00dferen Beitrag zur Bek\u00e4mpfung von Infektionskrankheiten geleistet.\n14 Impfun-\ngen retten nicht nur das Leben von weltweit gesch\u00e4tzt etwa 2,5 Millionen Menschen j\u00e4hr -\nlich\n15, sie sch\u00fctzen auch weitere Millionen vor \nKrankheit und Behinderung. Damit verbunden sind weltweite Einsparungen in Gr\u00f6\u00dfenordnun-gen von zweistelligen Milliardenbetr\u00e4gen durch eingesparte Behandlungskosten und Erhalt der F\u00e4higkeit zur Bildung und Erwerbst\u00e4tigkeit.\n16\nEin historischer Vergleich f\u00fcr die USA vor und nach der Einf\u00fchrung von nationalen Impfpro-grammen zeigt beispielhaft den Nutzen der Impfung (Abbildung 2). F\u00fcr Deutschland fehlen  \ninsbesondere f\u00fcr die alten Bundesl\u00e4nder ver -\nl\u00e4ssliche Daten vor Einf\u00fchrung der Melde-pflicht durch das Infektionsschutzgesetz 2001, aber die in der DDR bzw. in den neuen Bun-desl\u00e4ndern erfassten Daten belegen den R\u00fcck-gang von Erkrankungszahlen und Sterbef\u00e4llen bei impfpr\u00e4ventablen Erkrankungen.\n17 Eine \nStudie aus den Niederlanden belegt den wich-tigen Einfluss von Impfstoffen auch vor dem Hintergrund der allgemein zur\u00fcckgehenden Sterblichkeit.\n18\nAbb. 2: J\u00e4hrliche Fallzahlen ausgew\u00e4hlter Infektionskrankheiten in den USA vor und nach der Einf\u00fchrung eines Impfprogram-\nmes. Die historischen Zahlen (in Lila) wurden f\u00fcr eine bestimmte Zeitspanne vor der Einf\u00fchrung einer entsprechenden Impfung bestimmt und gemittelt\n19, die aktuellen Daten (in Orange) beruhen auf den f\u00fcr 2013 gemeldeten Zahlen der amerikanischen \nSeuchenbeh\u00f6rde.20Masern\n530.217\n187\n28.639\n584900261\nKeuchhusten\n200.752\nMumps\n162.344R\u00f6teln\n47.745Pocken\n29.005Diphterie\n21.053Haemophilus influenzae\n20.00031Kinderl\u00e4hmung\n16.316Wundstarr -\nkrampf\n58026 \nMit Schutzimpfungen soll der Einzelne vor ei-\nner Infektionskrankheit oder damit assoziier -\nten Komplikationen gesch\u00fctzt werden. Diese individuelle Wirksamkeit (\u201evaccine efficacy\u201c) wird in klinischen Studien belegt. Die meisten Impfungen verfolgen aber noch ein weiteres Ziel: den Schutz der Bev\u00f6lkerung vor Epidemi-en durch Reduzierung oder Verhinderung der Erreger\u00fcbertragung.\n21 Durch dieses als Herden-  \nimmunit\u00e4t bekannte Prinzip sollen insbesondere Personen gesch\u00fctzt werden, bei denen aus medi-zinischen Gr\u00fcnden eine Impfung nicht durchge-f\u00fchrt werden kann, wie beispielsweise S\u00e4uglinge oder immungeschw\u00e4chte Personen, oder solche, die keinen ausreichenden Impfschutz aufbauen wie \u00e4ltere Menschen. Ein Gemeinschaftsnutzen setzt allerdings erst bei hohen Impfraten ein. Die Herdenimmunit\u00e4t hat auch Auswirkungen auf den Erfolg eines Impfprogrammes (\u201evacci-ne effectiveness\u201c). Epidemiologische Beobach-tungsstudien erfassen diese Wirksamkeit von Impfstoffen im realen Leben, die nur bei ausrei-chender Akzeptanz gew\u00e4hrleistet ist. \nBei hohen Durchimpfungsraten der Bev\u00f6lke-\nrung k\u00f6nnen Krankheitserreger gar regional eli-miniert werden oder weltweit ausgerottet wer -\nden, wenn der Mensch der einzige Tr\u00e4ger ist. So konnte die Kinderl\u00e4hmung dank weltweiter Impfkampagnen deutlich einged\u00e4mmt werden und manche Regionen wie Europa komplett davon befreit werden.\n22 Die WHO hat bereits \n1988 das Ziel erkl\u00e4rt, den Erreger der Kinderl\u00e4h-mung (Poliovirus) bis ins Jahr 2000 auszurotten, die Frist konnte allerdings nicht eingehalten werden. Derzeit gibt es noch drei L\u00e4nder (Af-ghanistan, Nigeria und Pakistan), in denen das Virus zirkuliert und vereinzelte F\u00e4lle auftreten. Vor diesem Hintergrund ist es bedeutsam, die Impfbereitschaft in der Bev\u00f6lkerung in erreger -\nfreien L\u00e4ndern zu sichern, damit im Falle einer Einschleppung die Verbreitung verhindert wird.\nImpfungen leisten aber nicht nur einen direkten \nBeitrag zur Bek\u00e4mpfung von Infektionskrank-heiten. Impfstoffe gegen Hepatitis B und gegen Humane Papillomaviren k\u00f6nnen der Entstehung der assoziierten Krebserkrankungen Leberkrebs und Geb\u00e4rmutterhalskrebs vorbeugen.\n23 Durch \nVerringerung des Bedarfs an Antibiotika k\u00f6n-nen Impfstoffe gegen bakterielle Erreger au\u00dfer -\ndem helfen, der Entstehung und Verbreitung von Antibiotikaresistenzen vorzubeugen.\nAktuelle und zuk\u00fcnftige \nHerausforderungen der Impfung\nGleichzeitig hat sich der Erfolg der Impfung je-\ndoch als ihr gr\u00f6\u00dfter Feind herausgestellt: Fr\u00fc-her als bedrohlich erlebte Krankheiten verloren ihren Schrecken, viele Menschen haben dank wirksamer Impfprogramme die verheerenden Auswirkungen der durch Impfung vermeid-baren Krankheiten nicht mehr erlebt. Zudem  \nwerden die im Vergleich zu den h\u00e4ufig beste-henden Erkrankungskomplikationen seltenen Nebenwirkungen nach Impfungen deutlicher wahrgenommen, insbesondere da diese bei Gesunden erfolgen. Dies mindert die Akzep-tanz von Impfungen und folglich gehen die Impfraten in der Bev\u00f6lkerung zur\u00fcck. Perso-nen mit impfkritischen Einstellungen erreichen in (sozialen) Medien, im Internet und der \u00d6f-fentlichkeit eine hohe und auch nachhaltige Aufmerksamkeit, w\u00e4hrend Berichterstattungen \u00fcber drohende Grippeepidemien oder andere Krankheitsausbr\u00fcche die Impfraten nur vor\u00fc-bergehend steigern.\n24  \nEin Beispiel aus der j\u00fcngeren Vergangenheit ist der Einbruch der Durchimpfung gegen Masern, Mumps und R\u00f6teln (MMR) um etwa 20 Prozent in England nach der Ver\u00f6ffentlichung einer Stu-die im Jahr 1998, die vermeintlich einen Zusam-menhang zwischen dem MMR-Impfstoff und Autismus belegte.\n25 Die Studie wurde erst 2010 \nnach umfangreicher \u00dcberpr\u00fcfung durch Wis-senschaftler und Kommissionen zur\u00fcckgezo-gen, da sich Teile der Studie als fehlerhaft und sp\u00e4ter auch als manipuliert herausstellten.\n26   \nEin Zusammenhang zwischen der MMR-Imp-Impfen \u2013 kleiner Pieks, gro\u00dfe Wirkung \u00a7  27\nfung und Autismus konnte nie nachgewiesen \nwerden.27 Das Misstrauen gegen\u00fcber dem \nImpfstoff war allerdings lange pr\u00e4sent, so dass die Impfraten erst heute wieder auf dem f\u00fcr das Erreichen einer Herdenimmunit\u00e4t ben\u00f6tigtem Niveau liegen.\nTats\u00e4chlich ist die Kritik an Impfungen keine \nErscheinung der letzten Jahre oder Jahrzehnte. Impfgegner oder -skeptiker gibt es beispiels-weise in Deutschland schon seit der Einf\u00fchrung der Impfpflicht gegen Pocken.\n28 Als Argumente \nwurden bereits damals die angeblich fehlende Wirksamkeit von Impfstoffen und beobachte-te Nebenwirkungen genannt, zudem spielten religi\u00f6se Beweggr\u00fcnde eine Rolle. Heute sind sch\u00e4tzungsweise 3 bis 5 Prozent der deutschen Bev\u00f6lkerung aus \u00e4hnlichen Gr\u00fcnden gegen Impfungen eingestellt. Impfungen werden als \u00fcberfl\u00fcssig, sch\u00e4dlich und interessengeleitet durch die Pharmaindustrie angesehen. Teilweise wird auch die Existenz von Krankheitserregern zur\u00fcckgewiesen oder angezweifelt. Das Robert Koch-Institut und das PEI nehmen im Internet ausf\u00fchrlich Stellung zu den 20 h\u00e4ufigsten Ein-w\u00e4nden gegen das Impfen\n29, um entsprechen-\nden Sorgen zu begegnen und Informationsdefi-zite zu verringern. F\u00fcr eine effektive Aufkl\u00e4rung und zur Weiterentwicklung der Impfprogram-me werden valide Daten zu H\u00e4ufigkeiten impf-pr\u00e4ventabler Krankheiten und zu Impfneben-wirkungen erhoben und der \u00d6ffentlichkeit zur Verf\u00fcgung gestellt.\n30 Die Impfquoten sind \nin Deutschland zwar insgesamt hoch und seit Jahren steigend, aber eben teilweise niedriger als die von der WHO angestrebten Ziele.\n31 Da \nimpfkritische Einstellungen Impfprogramme ernsthaft gef\u00e4hrden k\u00f6nnen, ist es eine Her -\nausforderung f\u00fcr die verschiedenen Akteure im Gesundheitswesen, diesen mit geeigneten Kommunikationsstrategien zu begegnen, um die Akzeptanz von Impfungen zu erh\u00f6hen.\nDie WHO versucht seit 1974 durch das \u201eExpan-\nded Programme on Immunization (EPI)\u201c global den Zugang zu Impfstoffen insbesondere f\u00fcr Kinder zu verbessern. Seit Einf\u00fchrung dieses erfolgreichen Programmes ist die Abdeckung von Routineimmunisierungen gegen Diphterie, Wundstarrkrampf, Keuchhusten, Kinderl\u00e4h-mung und Masern weltweit von weniger als 5 Prozent auf \u00fcber 85 Prozent gestiegen, und die Quote ist in vielen Entwicklungsl\u00e4ndern genau-so hoch wie in den Industriestaaten.\n32 Gleich-\nwohl werden immer noch etwa 20 Millionen Kinder weltweit j\u00e4hrlich nicht geimpft, daher ist es neben der Ausrottung von Kinderl\u00e4hmung erkl\u00e4rtes Ziel der WHO, auch diese L\u00fccken zu schlie\u00dfen.\n33 Seit Einf\u00fchrung des EPI-Program-\nmes sind auch eine Reihe weiterer Impfstoffe wie gegen Hepatitis B, Haemophilus influenzae type B, Rotavirus oder HPV in nationale Impfpro-gramme vieler L\u00e4nder aufgenommen worden. Neu entwickelte Impfstoffe gilt es m\u00f6glichst schnell auch in Entwicklungsl\u00e4ndern einzuf\u00fch-ren, da sie hier vermutlich den gr\u00f6\u00dften Impact haben. F\u00fcr diese L\u00e4nder wird es eine Heraus-forderung sein, die damit verbundenen Kosten zu schultern, trotz substanzieller Unterst\u00fctzung durch die internationale GAVI Impfallianz.\n34  \nEs bleibt festzuhalten, dass die Entdeckung, Entwicklung und Einf\u00fchrung von Impfstoffen einen enormen Beitrag zur globalen Gesund-heit geleistet hat und weiter leisten wird. Welt-weit verursachen Infektionskrankheiten aber immer noch etwa 16 Prozent aller j\u00e4hrlichen To-desf\u00e4lle. Ein Gro\u00dfteil sind auf AIDS, Tuberkulose und Malaria zur\u00fcckzuf\u00fchren. Trotz vielverspre-chender Fortschritte gibt es bisher keine wirksa-men und sicheren Impfstoffe gegen die Erreger dieser Krankheiten.\n35 Die Entwicklung neuer \noder verbesserter Impfstoffe gegen diese und andere bisher nicht durch Impfung vermeidbare und auch neu auftretende Infektionskrankhei-ten ist ein wichtiges Ziel f\u00fcr die Zukunft. Hier -\nf\u00fcr k\u00f6nnen unter anderem neue Erkenntnisse in der Entstehung von Immunantworten, bes-sere Methoden zur Identifizierung sch\u00fctzender Antigene sowie neuartige Darreichungsformen genutzt werden.\n36 Zuk\u00fcnftig sind aber auch \nAnwendungen von Impfstoffen \u00fcber die Vor -\nbeugung von Infektionskrankheiten hinaus zu erwarten: Das Feld der Immuntherapien macht Hoffnung f\u00fcr die Behandlung von Krebs, Alz-heimer oder Diabetes.28 \n1 W orld Health Organization (2018): Disease burden and mortality estimates 2000-2015 (Global summary estimates), World Health Organization\n www\n.who.int/healthinfo/global_burden_disease/estimates/en/index1.html [Zugriff am 23.3.2018].\n2 Behbehani , A. M. (1983): The smallpox story: life and death of an old disease. Microbiol. Rev., 47 (4), 455\u2013509.\n3 Gelderblom,  H. (1996): Die Ausrottung der Pocken. Spektrum der Wissenschaft (6), 36\u201344.\n4 Ada,  G. (2001): Vaccines and Vaccination. N Engl J Med (345), 1042\u20131053.\n5 Hajj Hussein,  I. et al. (2015): Vaccines Through Centuries. Major Cornerstones of Global Health. Frontiers in Public Health, 3 (1), 1\u201316. \n6 Gelderblom, H. (1996): Die Ausrottung der Pocken. Spektrum der Wissenschaft (6), 36\u201344.\n7 Hajj Hussein, I. et al. (2015): Vaccines Through Centuries. Major Cornerstones of Global Health. Frontiers in Public Health, 3 (1), 1\u201316.\n8 Fenner, Frank, Henderson, Donald A, Arita, Isao, Jezek, Zdenek, Ladnyi, Ivan Danilovich. et al. (1988): Smallpox and its eradication. World Health\n Organization: History of international public health (6),\n 1371\u20131409.\n9 Hajj Hussein,  I. et al. (2015): Vaccines Through Centuries. Major Cornerstones of Global Health. Frontiers in Public Health, 3 (1), 1\u201316. \n10 Schw anig, M. (2002): Die Zulassung von Impfstoffen. Regelungen und Prozesse auf europ\u00e4ischer Ebene. Bundesgesundheitsblatt (45), 338\u2013343.\n European Medicines \nAgency \u2013 Multidisciplinary \u2013 Multidisciplinary: vaccines. www.ema.europa.eu/ema/index.jsp?curl=pages/regulation/general/\n gener\nal_content_000407.jsp&mid=WC0b01ac058002958b [Zugriff am 26.3.2018].\n11 Bren, L. (2006): The Road to the Biotech Revolution. Highlights of 100 Years of Biologics Regulation. FDA Consumer magazine (40), 50\u201357.\n12 www.pei.de/DE/institut/geschichte/geschichte-node.html [Zugriff am 26.3.2018].\n13 Ereth, J. (2003): The global value of vaccination. Vaccine, 21 (7-8), 596\u2013600.\n14 Pollard, A. J. (2007): Childhood immunisation: what is the future? Arch Dis Child, 92 (5), 426\u2013433.\n15 W orld Health Organisation (2012): Global vaccine action plan 2011 - 2020. www.who.int/immunization/global_vaccine_action_plan/GVAP_\n doc_2011_2020/en/ [Zugriff am 26.3.2018].\n16 Ereth, J. (2003): The global value of vaccination. Vaccine, 21 (7-8), 596\u2013600.\n17 Meyer, C. et al. (2002): \u00dcber die Bedeutung von Schutzimpfungen. Epidemiologie,Durchimpfungsraten, Programme. Bundesgesundheitsblatt \n (45),\n 323\u2013331.\n18 Van Wijhe, M. et al. (2016): Effect of vaccination programmes on mortality burden among children and young adults in the Netherlands during\n the 20th century.\n A historical analysis. The Lancet Infectious Diseases, 16 (5), 592\u2013598. \n19 Roush, S. W. & Murphy, T. V . (2007): Historical comparisons of morbidity and mortality for vaccine-preventable diseases in the United States.\n JAMA,\n 298 (18), 2155\u20132163. \n20 CDC (2017): Global Routine Vaccination Coverage, 2016. www.cdc.gov/mmwr/volumes/66/wr/mm6645a3.htm#suggestedcitation \n [Zugriff am 26.3.2018].\n21 Pfleiderer, M. & Wichmann, O. (2015): Von der Zulassung von Impfstoffen zur Empfehlung durch die St\u00e4ndige Impfkommission in Deutschland\n Kriterien zur objektiven Bewertung von Nutzen und Risik\nen. Bundesgesundheitsblatt, 58 (3), 263\u2013273. \n22 Willyard, C. (2014): Polio. The eradication endgame. Nature, 507 (7490), S14-S15. \n23 Andre, F . E. et al. (2008): Vaccination greatly reduces disease, disability, death and inequity worldwide. Bulletin of the World Health Organization,\n 86 (2),\n 140\u2013146. \n24 Meyer, C. & Reiter, S. (2004): Impfgegner und Impfskeptiker. Geschichte, Hintergr\u00fcnde, Thesen, Umgang. Bundesgesundheitsblatt, 47 (12),1182\u20131188. \n25 Wakefield, A. J. et al. (1998): RETRACTED. Ileal-lymphoid-nodular hyperplasia, non-specific colitis, and pervasive developmental disorder in\n children.\n The Lancet, 351 (9103), 637\u2013641. \n26 Deer, B. (2011): How the case against the MMR vaccine was fixed. BMJ (Clinical research ed.), 342, c5347. \n27 Demicheli, V . et al. (2012): Vaccines for measles, mumps and rubella in children. The Cochrane database of systematic reviews (2), CD004407. \n28 Meyer, C. & Reiter, S. (2004): Impfgegner und Impfskeptiker. Geschichte, Hintergr\u00fcnde, Thesen, Umgang. Bundesgesundheitsblatt, 47 (12),1182\u20131188.\n29 RKI \u2013 Bedeutung von Impfungen \u2013 Antworten des Robert Koch-Instituts und des Paul-Ehrlich-Instituts zu den 20 h\u00e4ufigsten Einw\u00e4nden gegen das\n Impfen.\n www.rki.de/DE/Content/Infekt/Impfen/Bedeutung/Schutzimpfungen_20_Einwaende.html [Zugriff am 26.3.2018].\n30 RKI \u2013 Nebenwirkungen/Komplikationen. www.rki.de/DE/Content/Infekt/Impfen/Nebenwirkungen/nebenwirkungen_node.html \n [Zugriff am 26.3.2018].\n31 Robert Koch-Institut. (2018): Epidemiologisches Bulletin des Robert Koch-Instituts (1).\n32 CDC. (2017): Global Routine Vaccination Coverage, 2016. www.cdc.gov/mmwr/volumes/66/wr/mm6645a3.htm#suggestedcitation \n [Zugriff am 26.3.2018].\n \n33 W orld Health Organisation (2012): Global vaccine action plan 2011 - 2020. www.who.int/immunization/global_vaccine_action_plan/GVAP_\n doc_2011_2020/en/ [Zugriff am 26.3.2018].\n34 Gavi, the Vaccine Alliance. www.gavi.org/ [Zugriff am 26.3.2018].\n35 Bourzac, K. (2014): Infectious disease. Beating the big three. Nature, 507 (7490), S4-S7. \n36 Greenwood, B. (2014): The contribution of vaccination to global health. Past, present and future. Philosophical transactions of the Royal Society\n of London.\n Series B, Biological sciences, 369 (1645), 20130433. Biobanken \u2013 eine sichere Investition in die Gesundheit? \u00a7  29\nBiobanken \u2013 eine sichere Investition \nin die Gesundheit?\nDr. Lisette Leonhardt\nMedizinische Forschung und der damit verbun-\ndene Erkenntnisgewinn sind ohne den Zugang zu geeignetem Probenmaterial und den daraus resultierenden Daten nicht m\u00f6glich. Die Samm-lung, Konservierung und Langzeitlagerung von menschlichem K\u00f6rpermaterial sowie die Ver -\nkn\u00fcpfung mit den dazugeh\u00f6rigen Daten wird als Biobanking bezeichnet. Diese Informatio-nen umfassen probenbeschreibende, klinische und auch sozio\u00f6konomische Daten, die mitein-ander verkn\u00fcpft werden k\u00f6nnen. Dabei besteht eine Biobank aus drei wesentlichen Komponen-ten: dem biologischen Material und dessen La-gerung, den dazugeh\u00f6rigen Daten und deren Speicherung sowie der Expertise der beteiligten Mitarbeiterinnen und Mitarbeiter.\n1  \nBiobanken bilden die Grundlage f\u00fcr die klini-sche Forschung und damit f\u00fcr die Entwicklung innovativer Prognose-, Diagnose- und The-rapiem\u00f6glichkeiten von Krankheiten. Neben den Forschungszwecken finden die Proben Anwendung in der klinischen Versorgung, wo sie unter anderem zur Prognose von konkreten Krankheitsverl\u00e4ufen eingesetzt werden. Neben klinischen Biobanken, die Proben von Patienten aus Krankenh\u00e4usern einlagern, bieten popula-tionsbasierte (epidemiologische) Biobanken mit Proben ohne spezifischen Krankheitsbezug die M\u00f6glichkeit, systematische Analysen zur Ent-wicklung von Pr\u00e4ventionsans\u00e4tzen durchzuf\u00fch-ren.\n2 Sie haben daher auch f\u00fcr das \u00f6ffentliche \nGesundheitswesen eine gro\u00dfe Bedeutung.\nObwohl sie mittlerweile eine unverzichtbare \nRolle in der medizinischen Forschung einneh-men, r\u00fccken Biobanken nur langsam in die \u00f6ffentliche Wahrnehmung. Zahlreiche Publi-kationen in den letzten Jahren verdeutlichen die wachsende Bedeutung dieses Instruments, insbesondere f\u00fcr die personalisierte Medizin.\n3  \nWas als Ausstellungsst\u00fcck in einigen medizin-historischen Museen und den Gefrierschr\u00e4nken einzelner Forscher an den Universit\u00e4ten be-gann, hat sich mittlerweile zu zentralisierten, datenbankbasierten Forschungsinfrastrukturen entwickelt.\nVernetzung und Quali-\nt\u00e4tssicherung als gro\u00dfe Herausforderungen f\u00fcr die Nutzbarkeit von  Biobanken\nDie Vernetzung und Qualit\u00e4tssicherung dieser \nBiobanken, die \u00fcber den gesamten Globus ver -\nteilt sind, stellen gro\u00dfe Herausforderungen dar und sind gleichzeitig eine absolute Notwendig-keit f\u00fcr deren uneingeschr\u00e4nkte Nutzung. So-genannte virtuelle Biobanken bieten Forschen-den aus Industrie und Akademia mittlerweile die M\u00f6glichkeit, spezifisch nach bestimmten Proben zu suchen und sich auszutauschen.\n4 \nDabei besteht auch die M\u00f6glichkeit, Daten be-stimmter Proben, beispielsweise digitalisierte Gewebeschnitte, auszutauschen, ohne dabei die Probe selbst zur Verf\u00fcgung zu stellen.\nHumane Proben werden seit \u00fcber 100 Jahren \ngesammelt und gelagert.\n5  Die Lagerung erfolgt \n40 Jahre30 \ndabei in der Regel bei sehr niedrigen Tempera-\nturen. Auf diese Weise sind Proben jahrzehnte-lang konservierbar. Es kann sich dabei um Ge-webeproben, Haare, Abstriche, Stuhl oder auch K\u00f6rperfl\u00fcssigkeiten wie Liquor, Sputum, Urin und Blut in Form von Plasma oder Serum han-deln. Isolierte Komponenten wie beispielsweise Proteine oder Nukleins\u00e4uren werden ebenfalls aufbewahrt.\nSo heterogen die Proben sind, so unterschied-\nlich sind die M\u00f6glichkeiten, um diese f\u00fcr die entsprechenden biochemischen oder histologi-schen Analysen vorzubereiten. Der Zeitabschnitt zwischen Probennahme und Analytik, die so-genannte pr\u00e4-analytische Phase, stellt neben der eigentlichen Lagerung f\u00fcr die Qualit\u00e4t der Probe einen wichtigen Faktor dar. Verschiedene Variablen wie etwa die Handhabung w\u00e4hrend der Sammlung, die Temperatur, die Art des Pro-bengef\u00e4\u00dfes und die Zentrifugationsgeschwin-digkeit beeinflussen die chemische Zusammen-setzung der Probe.\n6 Da pr\u00e4analytische Faktoren \nund der Umgang mit der Probe im Allgemeinen einen wesentlichen Einfluss auf deren Qualit\u00e4t haben, ist es notwendig, dass diese Informatio-nen Teil der Metadaten zur Probe sind.\n7 Die meisten Proben wurden in der Vergangen-heit zu Diagnose- und Therapiezwecken ge-sammelt. Diese sind nur beschr\u00e4nkt f\u00fcr die For -\nschung verwendbar, da sie in den allermeisten F\u00e4llen nicht standardisiert entnommen wurden und dementsprechend Daten bez\u00fcglich Verar -\nbeitung, Lagerung und m\u00f6glicher Auftauzyk-len fehlen. Das Qualit\u00e4tsmanagement ist da-her einer der wichtigsten Faktoren, wenn die generierten Daten valide und reproduzierbar sein sollen. Reproduzierbarkeit ist eine funda-mentale Voraussetzung f\u00fcr belastbare wis-senschaftliche Ergebnisse. Eine ausreichende Anzahl an Proben mit vergleichbarer Qualit\u00e4t und der Verkn\u00fcpfung der relevanten klinischen Daten ist n\u00f6tig, um statistisch valide Aussagen treffen zu k\u00f6nnen. Aus diesen Gr\u00fcnden ist eine Standardisierung in allen Aspekten des Bioban-king notwendig. Die im Jahr 2000 gegr\u00fcndete International Society of Biological and Environ-mental Repositories (ISBER) besch\u00e4ftigt sich un-ter anderem mit der Etablierung gemeinsamer Standards und ver\u00f6ffentlicht in regelm\u00e4\u00dfigen Abst\u00e4nden Hinweise zu \u201eBest Practice\u201c f\u00fcr den Umgang mit Proben und den dazugeh\u00f6rigen Daten.\n8 Diese Gemeinschaft stellt ein globales \nForum dar, das sich mit wissenschaftlichen, \nBiobanken \u2013 eine sichere Investition in die Gesundheit? \u00a7  31\ntechnischen, ethischen und juristischen Aspek-\nten des Biobanking besch\u00e4ftigt und verf\u00fcgt \u00fcber ein eigenes Journal. Die Einf\u00fchrung eines Qualit\u00e4tsmanagementsystems bietet eine M\u00f6glichkeit der Zertifizierung und wird von verschiedenen Biobanken bereits angewandt.\n9  \nDie Welt der Biobanken ist vielschichtig und heterogen. Sie sind \u00fcber den gesamten Globus verteilt und haben sich dementsprechend auch unabh\u00e4ngig voneinander entwickelt. Derzeit existieren nach Angaben des Deutschen Bio-bankenregisters allein in Deutschland 128 Bio-banken.\n10 Neben unterschiedlichen Betreibern \ngibt es auch verschiedene Zwecke, die Bio-banken erf\u00fcllen sollen. Es gibt Biobanken, die an Universit\u00e4ten und Universit\u00e4tskliniken oder Institute angegliedert sind und kommerzielle Biobanken pharmazeutischer oder biotechno-logischer Unternehmen. Es existieren beispiel-weise Biobanken, die sich auf die Einlagerung von Molek\u00fclen spezialisiert haben, die geneti-sche Informationen speichern oder solche, die sich mit einer ganz konkreten Krankheit be-sch\u00e4ftigen. Populationsbasierte Biobanken sind bereits in vielen L\u00e4ndern etabliert. Darunter fallen Schweden, D\u00e4nemark, Gro\u00dfbritannien, Island, Lettland, Estland, USA, Kanada, Japan, Singapur und S\u00fcdkorea. Auch in Deutschland werden seit 2014 im Rahmen der Nationalen Kohorte Proben und Daten von 200.000 Men-schen gesammelt.\n11 Je mehr Daten einer Probe \nzugeordnet werden k\u00f6nnen, desto umfangrei-cher sind die Analysem\u00f6glichkeiten, auch wenn dies nicht notwendigerweise automatisch zu mehr Erkenntnissen f\u00fchrt. Auf IT-Ebene gehen die gro\u00dfen Datenmengen mit einer ansteigen-den Komplexit\u00e4t einher und erfordern ein um-fassendes Datenmanagement.\nDie Erkenntnis, dass der eigentliche Schatz in \nder Vernetzung und damit der Durchsuchbarkeit dieser Datenbanken liegt, hat zu deutlichen An-strengungen auf nationaler und internationaler Ebene gef\u00fchrt, diese Datenbanken miteinander zu verkn\u00fcpfen und soweit wie m\u00f6glich einheitli-che Standards zu schaffen. Dieses Ziel wird mit-tels unterschiedlicher Strategien verfolgt.\n12  Auf deutscher Ebene ist hier die zentrale Koope-rationsplattform German Biobank Node zu nen-nen, welche die Interessen der deutschen Bio-banken im europ\u00e4ischen Biobankennetzwerk BBMRI-ERIC (Biobanking and BioMolecular Resources Research Infrastructure \u2013 European Research Infrastructure Consortium) vertritt.\n13 \nDas BBMRI-ERIC, das mittlerweile aus 19 Mit-gliedsstaaten und einer internationalen Orga-nisation (International Agency for Research on Cancer \u2013 IARC) besteht, ist eine paneurop\u00e4ische Infrastruktur nationaler Biobanknetzwerke, die von den beteiligten Mitgliedsstaaten getragen wird.\n14 Beispielsweise wurde in dem EU-Projekt \n\u201eEuropean Prospective Investigation into Can-cer and Nutrition (EPIC)\u201c der Zusammenhang zwischen Lebensstil, Umweltfaktoren sowie Er -\nn\u00e4hrung und der H\u00e4ufigkeit von auftretenden Krebserkrankungen erforscht. Daran nahmen 23 Zentren aus 10 L\u00e4ndern teil und sammelten dabei Proben und Daten von \u00fcber einer halben Million Menschen.\n15 Im globalen Kontext agie-\nren die bedeutenden Forschungsinfrastrukturen International Society of Biological and Environ-mental Repositories (ISBER), das Public Populati-on Project in Genomics and Society (P\n3G)16 und \ndie European, Middle Eastern & African Society for Biopreservation and Biobanking (ESBB).\n17  \nEine zentrale Lagerung aller Proben an einem Ort ist nicht m\u00f6glich, da diese beispielswei-se noch f\u00fcr diagnostische Zwecke gebraucht werden. Virtuelle Datenbanken spielen in der Vernetzung daher eine Schl\u00fcsselrolle, da sie Forschern \u00fcber eine Vielzahl von Biobanken ge-zielte Abfragen erm\u00f6glichen. Damit eine virtu-elle Datenbank ihren Zweck erf\u00fcllt, m\u00fcssen die Merkmale, die den Proben und dem Spender zugeordnet sind, im System auffindbar sein. Zu-gang erh\u00e4lt man \u00fcber spezielle Software oder Webportale. Bez\u00fcglich des abfragbaren Infor -\nmationsgehalts gibt es Unterschiede. Es existie-ren  Biobanken, die lediglich aggregierte Daten, zum Beispiel \u00fcber die Anzahl der Proben eines bestimmten Materialtyps zur Verf\u00fcgung stellen oder solche, die Informationen auf Proben- ebene erm\u00f6glichen.\n18  32 \nDie Einrichtung von virtuellen Datenbanken ist \neine komplexe Herausforderung und zudem ein enormer Kostenfaktor. Zur Etablierung eines einheitlichen Datenbanksystems ist die Erf\u00fcl-lung gemeinsamer Standards Voraussetzung. Dies umfasst ein gemeinsames, \u00fcbergreifendes Datenmodell und entsprechende Transformati-onsregeln f\u00fcr die angebundenen Datenbanken. Es gibt verschiedene Strategien zur IT-techni-schen Umsetzung der Vernetzung von Bioban-ken, die verschiedene Kriterien wie Granularit\u00e4t der Daten, Speicherort oder Automatisierungs-grad unterscheiden.\n19 Eine H\u00fcrde ist dabei die \nsemantische Heterogenit\u00e4t der probenbeschrei-benden Daten. Hinzu kommen regulatorische Angelegenheiten und datenschutzrechtliche Belange, die intranational, national und inter -\nnational unterschiedlich geregelt sind. \nEthische und juristische \nAspekte\nSobald Patienten oder Probanden Proben ent-\nnommen und medizinische Daten gespeichert werden, stellen sich ethische Fragen, die es zu beachten gilt. Im deutschen Recht hat je-der Mensch ein Recht auf (informationelle) Selbstbestimmung, Leben und k\u00f6rperliche Un-versehrtheit. Damit geht einher, dass f\u00fcr jede Probennahme, unabh\u00e4ngig davon, ob diese zur Diagnostik, zur Forschung oder aber f\u00fcr bei-des genutzt werden soll, zuvor eine informier -\nte Einwilligung (\u201eInform Consent\u201c) eingeholt werden muss. Diese kann jederzeit widerrufen werden. Dabei kann der Spender entscheiden, ob er \u00fcber Ergebnisse, die relevant f\u00fcr seine Gesundheit sind, informiert werden m\u00f6chte oder nicht. Die pers\u00f6nlichen Informationen, die in einer normalen Blutprobe stecken, sind un-ter Umst\u00e4nden nicht weniger sensibel als die, welche sich in der Patientenakte eines Men-schen finden lassen, und k\u00f6nnen sogar dar\u00fc-ber hinausgehen. So besteht die M\u00f6glichkeit, durch Messung bestimmter Stoffwechselzwi-schenprodukte nachzuweisen, ob bestimmte Medikamente eingenommen wurden oder ob ein Risiko f\u00fcr spezifische Krankheiten vorliegt. Folglich sind Besonderheiten des Stoffwechsels eines Menschen erkennbar. \nAuch die Tatsache, dass bei der Diagnose von \nErbkrankheiten durch genetische Analysen neben dem Spender auch die Familienange-h\u00f6rigen unmittelbar betroffen sein k\u00f6nnen, verkompliziert das ethische und juristische Ge-flecht. Der Datenschutz spielt demnach in die-sem Zusammenhang eine besondere Rolle, da es sich hierbei um sehr sensible Informationen handelt, die vor Missbrauch gesch\u00fctzt werden m\u00fcssen. Sorge um den Schutz der Daten und einer damit verbundenen M\u00f6glichkeit zur Dis-kriminierung oder Stigmatisierung k\u00f6nnen ein Grund f\u00fcr Verunsicherung oder Misstrauen ge-gen\u00fcber Biobanken sein.\n20 \nSo gibt es eingelagerte Proben, die beispiels-weise der eigenen Verlaufskontrolle und Thera-pieempfehlung von Krankheiten dienen sollen, jedoch besteht bei der Sammlung von Proben zu reinen Forschungszwecken in der Regel kein direkter Nutzen f\u00fcr den Spender. Das Interes-se und das Verst\u00e4ndnis f\u00fcr die Notwendigkeit der Unterst\u00fctzung von Biobanken f\u00fcr die me-dizinische Forschung sollten daher sowohl im Sinne der Forschungsgemeinschaft als auch der Gesellschaft sein. Die geschilderten  ethischen und juristischen Aspekte haben dazu gef\u00fchrt, dass sich auf nationaler Ebene verschiedene Institutionen wie der Deutsche Ethikrat\n21, der \nDeutsche Bundestag22, der Bundesrat23 oder die \nBundes\u00e4rztekammer24 mit dem Thema ausein-\nandergesetzt haben. Ein Gesetz f\u00fcr Biobanken existiert noch nicht, jedoch wird der Bedarf ei-nes solchen Gesetzes auf verschiedenen Ebe-nen seit einiger Zeit diskutiert. Im Jahr 2015 hat eine Gruppe von Rechtswissenschaftlern den Augsburg-M\u00fcnchner-Entwurf eines Biobanken-gesetzes vorgelegt. Dieser Gesetzentwurf, f\u00fcr dessen Regelungen eine Bundeskompetenz be-steht, schl\u00e4gt einen einheitlichen Rechtsrahmen im Umgang mit Biobanken vor.\n25 Aufgrund der \nHeterogenit\u00e4t in Bezug auf Betrieb und Nut-Biobanken \u2013 eine sichere Investition in die Gesundheit? \u00a7  33\nzung ergibt sich zwangsl\u00e4ufig eine komplexe \nRechtslage, bei der auch geltendes EU-Recht beachtet werden muss. \nIm Hinblick auf die Spendenbereitschaft eines \njeden Einzelnen, welche eine Grundlage f\u00fcr das Betreiben und den Nutzen von Biobanken und damit f\u00fcr den medizinischen Fortschritt dar -\nstellt, spielen die Aufkl\u00e4rung der \u00d6ffentlichkeit sowie Transparenz eine essenzielle Rolle.\n26 Die-\nser Umstand und die Tatsache, dass der Gro\u00df-teil der Publikationen in diesem Bereich f\u00fcr den Wissenschaftsbetrieb und f\u00fcr Biobankenbetrei-ber verfasst wurde, hat die deutsche Bundes\u00e4rz-tekammer als Anlass genommen, 2017 eine Be-kanntmachung durch ihren wissenschaftlichen Beirat erstellen zu lassen.\n27 Diese soll in der Kli-\nnik t\u00e4tige \u00c4rzte in der direkten Kommunikation mit den Patienten unterst\u00fctzen. Sie informiert \u00fcber wesentliche Aspekte wie Nutzen und Risi-ken sowie ethische und juristische Aspekte. Die-ses Papier wurde vom interdisziplin\u00e4r besetzten Arbeitskreis \u201eBiobanken\u201c erstellt und zeigt ein weiteres Mal, dass die Vernetzung und Zusam-menarbeit der verschiedenen Disziplinen in Klinik und Forschung absolut notwendig ist. \nAnwendungsbeispiele  \nf\u00fcr die Nutzbarkeit von  \nBiobanken\nBiobanken finden Anwendung in der Grund-\nlagenforschung, der personalisierten Medizin, den Lebenswissenschaften, der Biomarker-  so-wie der Medikamentenentwicklung. Sie sind daher gleichsam ein zentraler Faktor f\u00fcr das \u00f6ffentliche Gesundheitswesen. Das Potenzial der Forschung geht dabei weit \u00fcber die Opti-onen hinaus, die im Rahmen einzelner Projekte beantwortet werden k\u00f6nnen. Die M\u00f6glichkeit, Zusammenh\u00e4nge zwischen genomischen und metabolischen Ver\u00e4nderungen bei Erkrankun-gen und Umweltbedingungen sowie Ern\u00e4h-rungs- und Lebensweisen herzustellen, ist die Grundlage f\u00fcr die personalisierte Medizin. Die-se zielt darauf ab, f\u00fcr jeden einzelnen Patienten die nach den vorhandenen individuellen Gege-benheiten optimale Pr\u00e4vention oder Therapie zur Verf\u00fcgung zu stellen. In der Pharmakoge-netik werden f\u00fcr die Vorhersage der Wirkung von Medikamenten genetische Daten genutzt.\nGro\u00dfe Bedeutung hat diese Vorgehensweise \nin der Onkologie. Beispielsweise differenzieren sich verschiedene Krebsarten wie Lungenkrebs oder Pankreaskrebs auf molekularbiologischer Ebene in eine Vielzahl von Subtypen, die einer unterschiedlichen Therapie bed\u00fcrfen. Die Pati-entenkollektive der einzelnen Subtypen verklei-nern sich entsprechend, so dass f\u00fcr klinische Studien die Vernetzung unter den Zentren es-senziell ist, um entsprechend gro\u00dfe Gruppen f\u00fcr statistisch valide Analysen zu erhalten. Dies ist auch f\u00fcr Patienten mit seltenen Erkrankun-gen von Relevanz. Nicht zuletzt bei der Medi-kamentenrepositionierung, bei der f\u00fcr bereits bekannte Wirkstoffe neue Anwendungen iden-tifiziert werden, spielt die systematische Analy-se der Prozesse auf verschiedenen Ebenen eine wichtige Rolle, um die Wirkung besser zu ver -\nstehen.  \nEin weiterer Forschungszweig, der von Bioban-\nken stark profitiert, ist die Systembiologie. Mit-tels der sogenannten \u201eOmics-Technologien\u201c  \nwerden auf verschiedenen Ebenen (Gene,  \nProteine, Metaboliten) Daten erhoben, um die molekularen und chemischen Vorg\u00e4nge in ihrer komplexen Gesamtheit zu verstehen. Die Inte-gration dieser Daten erm\u00f6glicht es besser zu verstehen, wie sich biochemische Prozesse ge-genseitig regulieren und miteinander in Wech-selwirkung stehen. Davon profitieren insbeson-dere multifaktorielle Krankheiten.\nDie Epidemiologie, die sich populations\u00fcber -\ngreifend mit gesundheitsbezogenen Zust\u00e4n-\nden befasst, profitiert ebenfalls von der gro\u00dfen Anzahl verf\u00fcgbarer Proben und deren Daten. Durch die Konservierung der Proben ist es so-gar m\u00f6glich, den Verlauf von Krankheiten ge-nerationen\u00fcbergreifend zu untersuchen. Der 34 \ntechnische Fortschritt k\u00f6nnte in Zukunft Ana-\nlysen erm\u00f6glichen, die zum Zeitpunkt der Ein-lagerung noch nicht zur Verf\u00fcgung standen. So kann der Spender gegebenenfalls auch Jahre nach der Abgabe der Probe am medizinischen Fortschritt teilhaben beziehungsweise diesen unterst\u00fctzen. \nBiobanken als Grundlage \nf\u00fcr die Gesundheits-  \nforschung\nDas Wissen \u00fcber molekulare und umweltbe-\ndingte Grundlagen menschlicher Erkrankungen auszubauen, um Diagnose und Behandlung zu verbessern, ist sowohl f\u00fcr die medizinische For -\nschung als auch f\u00fcr die Gesellschaft essenziell. Biobanken stellen daf\u00fcr heute und in Zukunft eine wichtige Grundlage dar. Die komplexe Infrastruktur der Biobanken und die damit ver -\nbundenen Anforderungen bed\u00fcrfen einer inter -\ndisziplin\u00e4ren Zusammenarbeit. Da Proben und Daten von Spendern die Basis f\u00fcr den Betrieb von Biobanken bilden, kommt es hier zu direk-ten Ber\u00fchrungspunkten von Forschung und Ge-sellschaft. Die F\u00f6rderung des individuellen und kollektiven Vertrauens in solche wissenschaftli-chen Infrastrukturen ist daher von fundamen-taler Bedeutung. Die Umsetzung m\u00f6glicher Re-gelungen wird auf politischer, wirtschaftlicher, technischer und sozialer Ebene diskutiert. Die im Zuge der Einlagerung erhobenen patien-tenbezogenen Daten und die damit verbunde-nen ethischen und juristischen Aspekte werfen Fragen bez\u00fcglich der Risiken auf. Biobanken finden sich daher im Spannungsfeld zwischen Medizin, Informationstechnologie und Ethik wieder und sind ein Beispiel daf\u00fcr, dass die enge, internationale Verzahnung zwischen den einzelnen Disziplinen unerl\u00e4sslich f\u00fcr Innovation und Fortschritt sind. Biobanken \u2013 eine sichere Investition in die Gesundheit? \u00a7  35\n1 P . Holub, M. Swertz, R. Reihs, D. van Enckevort, H. M\u00fcller und J.-E. Litton (2016): BBMRI-ERIC Directory: 515 Biobanks with over 60 Million\n Biological Samples\n. In: Biopreservation and Biobanking, 2016, pp. 559\u2013562, 6.11.2016.\n2 M.  Hummel, C. Rufenach (2015): Biomaterialbanken als Grundlage f\u00fcr die Entwicklung genetisch basierter Pr\u00e4ventionskonzepte. In: \n Bundesgesundheitsblatt Gesundheitsforschung Gesundheitsschutz,\n 2015, pp. 127\u2013130.\n3 J . Kinkorov\u00e1 (2016: Biobanks in the era of personalized medicine: objectives, challenges, and innovation. In: EPMA Journal, 22.2.2016.\n4 Y . De Souza und J. Greenspan (2013): Biobanking Past, Present, Future: Responsibilities and Benefits. In: AIDS, 2013, pp. 303\u2013312, 28.1.2013.\n5 Y . De Souza und J. Greenspan (2013): Biobanking Past, Present, Future: Responsibilities and Benefits. In: AIDS, 2013, pp. 303\u2013312, 28.1.2013.\n6 F . Betsou, R. Barnes, T. Burke, D. Coppola, Y . DeSouza, J. Eliason, B. Glazer, D. Horsfall, C. Kleeberger, S. Lehmann, A. Prasad, A. Skubitz, S. \n Somiari- und E.\n Gunter (2009): Human Biospecimen Research: Experimental Protocol and Quality Control Tools. In: Cancer Epidemiol Biomarkers\n Prev\n, 2009, pp. 1017\u20131025, 4.2009.\n7 H.  Moore, A. Kelly, S. Jewell, L. McShane, D. Clark und R. Greenspan, \u201eBiospecimen Reporting for improves study quality,\u201c Biopreserv Biobank,\n 2011,\n pp. 9:57\u201370, 2011.\n8 ISBER.  www.isber.org/?page=BPR&hhSearchTerms=%22best+and+practice%22.\n9 D . E., K. Hampson, C. Bray, K. Dixon, W. Ollier und M. Yuille (2012): Selection and Implementation of the ISO9001 Standard to Support \n Biobanking Research Infr\nastructure Development. In: Biopreservation and Biobanking, 2012, pp. 132\u2013167, 7.2.2012.\n10 www.biobanken.de. \n11 H.-E.  Wichmann, R. Kaaks, W. Hoffmann, K.-H. J\u00f6ckel, K. H. Greiser und J. Linseisen (2012): Die Nationale Kohorte. In: \n Bundesgesundheitsblatt,\n 2012, 1.6.2012.\n12 K.  Lablans, D. Kadioglu, S. Mate, I. Leb, H.-U. Prokosch und F . \u00dcckert (2016): Strategien zur Vernetzung von Biobanken. In: \n Bundesgesundheitsblatt,\n 2016, pp. 373\u2013378, 16.1.2016.\n13 www.GBN.de. \n14 www.bbmri-eric.eu. \n15 http://epic.iarc.fr/. \n16 http://www.p3g.org/. \n17 https://esbb.org/. \n18 K.  Lablans, D. Kadioglu, S. Mate, I. Leb, H.-U. Prokosch und F . \u00dcckert (2016): Strategien zur Vernetzung von Biobanken. In: \n Bundesgesundheitsblatt,\n 2016, pp. 373\u2013378, 16.1.2016.\n19 Ebd.  K. Lablans et al. (2016)\n20 Nationaler Ethikr at (2004): Biobanken f\u00fcr die Forschung \u2013 Stellungnahme. Berlin: Saladruck.\n21 Deutscher Ethikr at (2010): Humanbiobanken f\u00fcr die Forschung \u2013 Stellungnahme. Berlin.\n22 Deutscher Bundestag (2006): Drucksache 16/5374,  TA-Projekt: Biobanken f\u00fcr die humanmedizinische Forschung und Anwendung. Berlin.\n23 Bundesr at (2009): Beschluss des Bundesrates vom 15.5.2009, Drucksache 374/09.\n24 F . Montgomery, P . Scriba, M. Dietel und B.-M. Kurth (2017): Medizinische, ethische und rechtliche Aspekte von Biobanken. In: Deutsches \n \u00c4rzteblatt,\n 2017, 15.12.2017.\n25 U . Gassner, J. Kersten, M. Lindemann, J. F . Lindner, H. Rosenau, B. Schmidt am Busch, U. Schroth und F . Wollenschl\u00e4ger (2015): \n Biobankgesetz \nAusburg-M\u00fcnchner-Entwurf (AME-BiobankG). T\u00fcbingen: Mohr Siebeck, 2015.\n26 Ebd. F . Montgomery et al. (2017) \n27 Ebd. F . Montgomery et al. (2017)36 \nKommunikation immer und \u00fcberall\nDr. Jan Wessels\nVon Bahnfahrern sind h\u00e4ufig drei Standard-\nklagen zu h\u00f6ren. Zumeist wird \u00fcber die schon chronische Unp\u00fcnktlichkeit der Bahn lamen-tiert, oft gefolgt vom einem heftigen Kopf-sch\u00fctteln dar\u00fcber, dass Waggons wohl nie eine angenehme Reisetemperatur erreichen, sondern entweder im Sommer auf tropische 38 Grad aufgeheizt oder im Winter aufgrund ausgefallener Heizungen auf 15 Grad und k\u00e4l-ter heruntergek\u00fchlt sind. Und schlie\u00dflich folgt die lautstarke Klage dar\u00fcber, dass Mitreisen-de, kaum an ihren Pl\u00e4tzen angekommen, den Daheimgebliebenen eben diese unglaubliche Wendung ihres Schicksals telefonisch mitteilen m\u00fcssen. Und nicht selten in einer Lautst\u00e4rke, dass das gesamte Gro\u00dfraumabteil diese Erfah-rungen teilen darf. Erlebbar ist dies seit gut 25 Jahren \u2013 dank der Segnungen der fernm\u00fcndli-chen Kommunikation, der Fortschritte der mo-dernen Informationstechnologie mit den ersten mobilen Telefonen und nat\u00fcrlich dank der neu-esten Entwicklungen in Sachen Smartphone. \nInnovationen sind heute in aller Munde. Und \nvieles, was neu ist, wird sogleich als Innovati-on gesehen. Innovation gilt als Voraussetzung f\u00fcr Wachstum und Wohlstand, f\u00fcr die L\u00f6sung gesellschaftlicher Herausforderungen und f\u00fcr ein leichteres, besseres Leben. So sah es der \u00f6s-terreichische National\u00f6konomen Joseph Alois Schumpeter, der den Begriff der Innovation aus der Wirtschaftswissenschaft heraus einem brei-teren Publikum bekannt machte. F\u00fcr ihn waren Innovationen das Neue, das sich im Markt ge-gen das Alte durchsetzt und dabei m\u00f6glicher -\nweise auch zerst\u00f6rerische Wirkung entfalten kann. Das Neue muss dabei nicht unbedingt das objektiv Bessere sein, Neuigkeit kann auch f\u00fcr sich genommen schon ein Grund f\u00fcr Markt- erfolg sein, wenn das Alte, Hergebrachte seinen  \nReiz verloren hat. Dies zeigt sich gerade im  Konsumg\u00fcterbereich und in der Lebensmittel- industrie, wo viele Innovationen oder neue Pro-dukte nicht wirklich besser als die alten sind, sondern ganz einfach anders \u2013 und damit neu. Zumeist aber ist tats\u00e4chlich das Bessere der Feind des Guten; Produkte mit anderen, vermeintlich neuen Eigenschaften werden eher gekauft als die alten. Ob diese neuen Eigenschaften dann tats\u00e4chlich einen Zusatznutzen f\u00fcr den K\u00e4ufer oder die K\u00e4uferin darstellen, liegt im Auge der jeweiligen Betrachter.\nVor einiger Zeit h\u00e4tte man mit Blick auf diese \nEntwicklung aber nicht unbedingt von Inno-vationen gesprochen, sondern von Fortschritt. Der technische Fortschritt war der Motor, der die Menschheit voran brachte. Diesem Ver -\nst\u00e4ndnis lag auch ein \u00fcbergreifendes Konzept der Menschheitsgeschichte zugrunde, wonach sich die Menschheit immer weiter entwickelte, sozusagen der Sonne und dem Licht entgegen. Der Fortschrittsbegriff klingt f\u00fcr viele heute etwas \u201ealtbacken\u201d , aber die Idee vom Fort-schritt durch Innovation ist doch immer noch fest verwurzelt. Manchmal aber, und daf\u00fcr soll dieser Beitrag sensibilisieren \u2013 kann Innovation auch das Gegenst\u00fcck zu Fortschritt bedeuten, n\u00e4mlich Stabilit\u00e4t, Konstanz, Gleichgewicht. Manchmal brauchen wir das Neue dazu, um alte Gewohnheiten beizubehalten, um beste-hende Bed\u00fcrfnisse weiterhin zu befriedigen, auch wenn sich die Umst\u00e4nde deutlich gewan-delt haben. \nUnser Bed\u00fcrfnis nach N\u00e4he und Kommuni-\nkation\nEines dieser konstitutiven Bed\u00fcrfnisse des Men-\nschen ist das Bed\u00fcrfnis nach Kommunikation. Es hat sich faktisch kaum etwas daran ver\u00e4n-dert, dass der Mensch kommunizieren will \u2013 und zumeist innerhalb einer kleinen Gruppe \n40 JahreKommunikation immer und \u00fcberall \u00a7  37\nfester Bezugspersonen. Gepr\u00e4gt ist dies durch \nunsere Geschichte, in der der oder die Einzelne f\u00fcr eine ziemlich lange Zeit der Menschheitsge-schichte in kleinen Gruppen eng beieinander lebte und viele M\u00f6glichkeiten hatte, sich im Tagesverlauf und am Abend miteinander kon-tinuierlich auszutauschen. Jedes Mitglied die-ser Gruppe war pers\u00f6nlich bekannt, und \u00fcber die anderen Gruppenmitglieder und / oder ihre Erlebnisse zu reden war wohl ein wesentlicher Inhalt der Kommunikation; auch weil sich das Leben in fr\u00fcherer Zeit vergleichsweise langsam ver\u00e4nderte. Wir modernen Menschen des 21. Jahrhunderts sind alle das Ergebnis dieser Ent-wicklungsgeschichte und in vielen Punkten st\u00e4rker  \ndurch die Lebensbedingungen der letzten Jahr -\ntausende gepr\u00e4gt als durch die letzten 50 Jahre. \nDenn nach wie vor kommunizieren wir, trotz al-\nler Skalierungsm\u00f6glichkeiten der Informations- und Kommunikationstechnologien, in erstaun-lich kleinen Gruppen und Zusammenh\u00e4ngen. Dabei lie\u00dfe der Entwicklungspfad von der fr\u00fch-zeitlichen in unsere heutige post-moderne Zeit auch auf anderes schlie\u00dfen. Denn in h\u00f6chster Dynamik hat sich die Welt dramatisch ver\u00e4n-dert. Mehr als die H\u00e4lfte der Weltbev\u00f6lkerung lebt heute in St\u00e4dten, wovon einige gigantisch gro\u00df geworden sind. Mittlerweile gibt es welt-weit bereits 36 sogenannte Megacities, also St\u00e4dte mit mehr als 10 Millionen Einwohnern. Aber nur weil die potenzielle Gruppengr\u00f6\u00dfe von Kommunikationsteilnehmern und -teilneh-merinnen und die Kommunikationsdichte um ihn herum signifikant gewachsen sind, w\u00e4chst nicht unbedingt die Kontakt- und Kommunika-tionsf\u00e4higkeit des Menschen. Diese beschr\u00e4nkt sich dem Anthropologen Robin Dunbar zufolge auf 150 Freunde und Bekannte, von denen man die Namen und die wesentlichen Beziehungen untereinander kennen kann, auch bezeichnet als Dunbar-Zahl. Mit solchen Gruppengr\u00f6\u00dfen k\u00f6nnen wir alle ganz gut umgehen, Beziehun-gen aufbauen und pflegen, w\u00e4hrend Kontakte \u00fcber diese Gr\u00f6\u00dfenordnung hinaus schnell zur Herausforderung werden. Der Mensch ist also eher f\u00fcr das Zusammenleben in kleinen Grup-pen gemacht. Doch die Post-Moderne ist durch die Anony-mit\u00e4t der Gro\u00dfstadt, unglaublich wachsende Informationsstr\u00f6me, eine hohe Mobilit\u00e4t des Einzelnen und stetig wachsende Durchl\u00e4ssigkeit sozialer Beziehungen gepr\u00e4gt. Tagt\u00e4glich be-gegnen wir einer Vielzahl uns v\u00f6llig unbekann-ter Menschen. Jeder, der in einer Gro\u00dfstadt wie Berlin U-Bahn f\u00e4hrt, lernt diesen Zustand ken-nen und wird ihn mitunter als \u00dcberforderung wahrnehmen. So fasst etwa die neuste Modell-reihe der Berliner U-Bahn laut eigenen Angaben 330 Personen, den Fahrg\u00e4sten d\u00fcrfte dies in Sto\u00dfzeiten als eher konservative Sch\u00e4tzung er -\nscheinen. Aber auch engste Beziehungsgeflech-te bieten immer seltener Kontinuit\u00e4ten. Unsere heutigen Freiheiten und Perspektiven sowie erforderlichen Flexibilit\u00e4ts- und Mobilit\u00e4tsgrade bringen es mit sich, dass Freundschaften durch-l\u00e4ssiger werden, Familienzusammenh\u00e4nge sich aufl\u00f6sen oder durch Wegzug in andere St\u00e4dte und L\u00e4nder beachtliche Distanzen zu engen Freunden und Angeh\u00f6rigen entstehen. Immer seltener treffen wir also tats\u00e4chlich die Men-schen, mit denen wir eigentlich Kontakt haben wollen.\nTrotz alledem geht es uns in dieser Stresssitua-\ntion erstaunlich gut. Urs\u00e4chlich sind vor allem die vielz\u00e4hligen Innovationen im Bereich der In-formations- und Kommunikationstechnologien. Diese haben nicht die Kommunikation an sich ver\u00e4ndert, sondern vor allem dazu beigetra-gen, das Bed\u00fcrfnis nach Kommunikation auch bei sehr ver\u00e4nderten und sehr ver\u00e4nderlichen Lebensumst\u00e4nden zu befriedigen. Als Thurn und Taxis im Jahre 1490 das europaweite Post-wesen begr\u00fcndete, war dies im Grunde keine Innovation. Eine ausgepr\u00e4gte Briefkultur hatte es schon in der Antike gegeben. Aber erst das von Thurn und Taxis geschaffene Postwesen er -\nzeugte ein derart dichtes Kommunikationsnetz, das einen schriftlichen Austausch \u00fcber gro\u00dfe Distanzen h\u00f6chst effizient m\u00f6glich wurde. Die k\u00fcrzlich in das UNESCO-Weltdokumentenerbe aufgenommene, aus 15.000 Briefen bestehen-de Korrespondenz von Wilhelm Leibniz war f\u00fcr die damalige Zeit sicher eine Ausnahme, aber auch erst dank des Postwesens m\u00f6glich gewor -38 \nden. 1837 konstruierte Samuel Morse dann den \nMorsetelegraphen und schuf die M\u00f6glichkeit der globalen Kommunikation in Echtzeit, die mit dem ersten transatlantischen Tiefseekabel 1858 Wirklichkeit wurde. Bis Mitte der 1950er Jahre setzte sich das Telefon in den westlichen Industriegesellschaften als Mittel der fernm\u00fcnd-lichen Kommunikation durch, 1973 stellte Mo-torola den ersten Prototyp eines Mobiltelefons her. Mitte der 1980er Jahre wurde die SMS ein-gef\u00fchrt, 2007 das erste iPhone. WhatsApp und Slack erblickten 2009 das Licht der Welt. \nParallel dazu entwickelte sich auch die Ver -\nkehrstechnologie weiter, von der Kutsche \nzur Eisenbahn und vom Segelschiff \u00fcber das Dampfschiff bis zum Interkontinentalflug. Die Menschen wurden mobiler und die Entfernung, die ein Mensch in seinem Leben zur\u00fccklegte, wurde gr\u00f6\u00dfer. Zeitgleich wuchs die Bev\u00f6lke-rung und die Lebensr\u00e4ume, insbesondere St\u00e4dte, verdichteten sich. Dies lie\u00df die Dichte, Distanzen und die Geschwindigkeit der Kom-munikation immer weiter steigen. Neue Kom-munikationsm\u00f6glichkeiten machten eine breite Nutzung m\u00f6glich \u2013 immer preiswerter und da-durch St\u00fcck f\u00fcr St\u00fcck praktisch \u00fcberall, jeder -\nzeit und f\u00fcr jeden verf\u00fcgbar. Zwischen 2014 und 2017 stieg der Anteil der Smartphone- Nutzer von 55 auf 81 Prozent.\n1 Heute besitzen \n57 Millionen Deutsche ein Smartphone \u2013 und  \n2,5 Milliarden Menschen weltweit. Und dieses nehmen die Nutzerinnen und Nutzer, laut einer britischen Studie\n2, etwa 85-mal am Tag in die \nHand, um es auf neue Meldungen zu checken (wobei sie auf Nachfrage eher vermuten, etwa halb so h\u00e4ufig auf das Smartphone zu schauen).\nFunktionen der Kommunikation\nDer Siegeszug der modernen \u00dcberall-Kommuni- kation wurde begleitet von einem Dauerlamento, vor allem \u00fcber die vermeintliche Verdr\u00e4ngung der direkten Kommunikation. Dauertelefonierer in der Bahn werden als Gemein\u00fcbel wahrge-nommen, Kinder treffen Freunde nicht auf dem Spielplatz, sondern im Chat, Familienkommu- nikation am Mittagstisch wird durch die ge-meinsame WhatsApp-Gruppe ersetzt und mit \u201eFoodporn\u201c, mit Schnappsch\u00fcssen des eigenen Essens, die Selbstdarstellung in sozialen Medien angereichert. \nVergessen wird bei dieser Kritik, dass auch \nscheinbar grundlose Kommunikation eine so-ziale Funktion hat. Das vordergr\u00fcndig inhalts-leere Plaudern ist eine Art \u201eakustischer Fell-pflege\u201d, die Zuneigung oder zumindest doch Zugewandtheit und in vielen F\u00e4llen auch das Einfordern von Aufmerksamkeit zeigt. Es kann so soziale Bindungen durchaus anbahnen, zu-mindest aber st\u00e4rken und gegebenenfalls auch reaktivieren \u2013 \u00fcber gr\u00f6\u00dfte und k\u00fcrzeste Distan-zen hinweg. \nAuch eher negativ wahrgenommene Kommuni- \nkation hat seine Funktion. Klatsch und Tratsch \nAbb.1: Zentrale Innovationen der Informations- und Kommunikationstechnologien im Laufe der Zeit1861: Telefon\n(Johann Philipp Reis)\n1837: Morsetelegraph\n(Samuel Morse)1973: Mobiltelefon\n(Motorola)1858: Tiefseekabel 1992: SMS2007: iPhone\n(Apple)\n1490: Postwesen\n(Thurn und Taxis)Kommunikation immer und \u00fcberall \u00a7  39\nwirken als gesellschaftlicher Kitt und sind wich-  \ntiges Instrument sozialer Kontrolle. Selbst das \nGer\u00fccht, schlecht beleumdet und als \u00fcble Nach-  \nrede sogar zu einer S\u00fcnde erkl\u00e4rt, erf\u00fcllt durchaus  \nhilfreiche gesellschaftliche Funktionen. Es ist seit jeher der schnellste Kanal der Informations\u00fcber- tragung und wird heute durch die M\u00f6glichkeiten  \nsozialer Medien geradezu zum \u201eTurbo\u201d der Infor-  \nmationsverbreitung. Nat\u00fcrlich sind nicht alle Infor-  \nmationen, die in der Ger\u00fcchtek\u00fcche der sozialen  \nNetzwerke entstehen, objektive Beschreibungen  \nder Realit\u00e4t. Der Anteil des \u201ewei\u00dfen Rauschens\u201d,  \nalso belanglose Unwichtigkeiten oder falsche Informationen, ist sehr hoch; und nicht selten  \nwerden Ger\u00fcchte auch gezielt gestreut und  \ninteressengeleitet verst\u00e4rkt. \n\u00c4hnlich verh\u00e4lt es sich mit der Angleichung von \nWeltbildern und Meinungen, die heute schnell und abwertend als Filterblase beschrieben wird. Sie ist weder neu noch ohne soziale Funktion. Eine gemeinsame Weltsicht ist eine wichtige Voraussetzung f\u00fcr Solidarit\u00e4t und gemeinsa-mes Handeln. Wichtigkeit bemisst sich nicht allein anhand objektiver Kriterien, sondern auch entlang der Einsch\u00e4tzungen der eigenen Meinungs-\u201epeers\u201d. Schon die politischen Zei-tungen der Arbeiterbewegung sollten f\u00fcr ein gemeinsames Bild auf die Welt sorgen. Glei-ches taten die konservativen Medien und ver -\nmieden es aktiv, ihre Leser zu einem Blick \u00fcber die Grenzen der eigenen Meinung hinweg zu motivieren. Offen und neugierig auf die Ar -\ngumente und Positionen des sprichw\u00f6rtlichen Anderen zu schauen, war auch in der Welt der traditionellen Medien eher selten. Leser und  \nLeserinnen der Zeitung \u201eDie Welt\u201d kauften und kaufen sich wohl nur im Notfall eine Ausgabe der \u201etaz\u201d \u2013 und umgekehrt. \nDas Smartphone als Instrument der  \n\u00dcberall-Kommunikation\nOb Smalltalk, Tratsch oder echter Meinungs-\naustausch: Die zentrale Innovation, die heute diese unterschiedlichen Varianten von Kommu-nikation erm\u00f6glicht und damit zur kommunizie-renden Nabelschnur wird, die uns mit unseren Freunden und unserer Familie dauerhaft ver -bindet, ist das Smartphone. Quasi schon zum K\u00f6rperteil geworden, ist es stets dabei und all-gegenw\u00e4rtig, darf alles sehen und h\u00f6ren, was auch wir sehen und h\u00f6ren. Es kennt unsere Vitalparameter, unsere Vorlieben, unsere Ge-wohnheiten und jederzeit unseren Aufenthalts-ort. Als unser Auge, unser Ohr und unser Mund f\u00fcr die Wahrnehmung und den Austausch mit der Au\u00dfenwelt wird es so nicht nur zum digi-talen Abbild unserer physischen, sondern auch unserer psychischen Pr\u00e4senz.  \nUnsere postmoderne Welt, die kein Nah und \nFern, daf\u00fcr nur ein Jetzt und Gleich kennt, macht aber genau dies erforderlich. Erreichbar -\nkeit wird immer weniger eine Frage der Ent-fernung, sondern immer mehr der zeitlichen Verf\u00fcgbarkeit und unmittelbaren Reaktionsf\u00e4-higkeit. Postalische Korrespondenzen im Wo-chenrhythmus oder Festnetztelefonate in den eigenen vier W\u00e4nden verz\u00f6gerten Kommunika-tion oder beschr\u00e4nkten sie auf konkrete Orte. Jetzt ist Kommunikation \u00fcberall m\u00f6glich und wird entsprechend abverlangt. Das Smartphone macht sie so zum best\u00e4ndigen Strom und  schafft  \neine hohe soziale Interaktion auch \u00fcber gro\u00dfe Distanzen hinweg. Wir sind fast zur\u00fcckgekehrt in die vorindustriellen Zeiten der d\u00f6rflichen Gemeinschaft.\nDas schafft auch Raum f\u00fcr neue, digitale  \nInnovationen. Findige Start-ups wie \u201enextdoor\u201c \noder \u201enebenan.de\u201c erzeugen virtuell dort Kommunikations- und Interaktionsstrukturen, wo vorher keine bestanden oder nicht funktio- nierten. Mit den M\u00f6glichkeiten digitaler sozia-ler Medien wird mitten in der Anonymit\u00e4t der Gro\u00dfstadt eine digital vernetzte Nachbarschaft geschaffen, in der reale Alltagsgegenst\u00e4nde verschenkt oder getauscht, kleine Dienstleis-tungen angeboten und gemeinschaftliche Ak-tivit\u00e4ten innerhalb weniger Stra\u00dfenz\u00fcge ge-plant werden k\u00f6nnen. So lernen wir nicht nur die Nachbarn im Hausaufgang, sondern auch in den Stra\u00dfen der Umgebung kennen und  \nschlie\u00dfen vielleicht neue Freundschaften. Der st\u00e4dtische Kiez wird zum Dorf \u2013 und D\u00f6rfer fin-den zu neuer Gemeinschaft.40 \nBei allen Vorz\u00fcgen, die Innovationen zur Kom-\nmunikation des Menschen schaffen, bringen sie auch eine Reihe von Schattenseiten eines \u201ed\u00f6rflichen\u201c Lebens in kleinen sozialen Grup-pen mit sich. Der soziale Druck zu Angepasst-heit und Konformit\u00e4t steigt, die Filterblase f\u00fchrt dazu, dass unser Bild der Welt dem unserer  \nFacebook-Freunde gleicht. Wir liken und be-werten uns best\u00e4ndig gegenseitig, wir setzen uns permanent der Einordnung unseres sozi-alen Status durch unsere digitalen \u201eFreunde\u201d aus. Das Versprechen der Moderne von der L\u00f6sung der Fesseln, die uns unsere \u00fcberkom-mene soziale Herkunft auferlegt hatte, wird nicht mehr eingel\u00f6st. Zwar wird der famili\u00e4re Hintergrund weniger wichtig, daf\u00fcr definiert unsere Timeline unseren digitalen Status. Nicht einmal die Anonymit\u00e4t der Gro\u00dfstadt, in der jeder (innerhalb gesetzlicher Grenzen) machen kann, was er will, ist heute noch verl\u00e4sslich. Im  \nGegenteil: Anonymit\u00e4t ist sogar durch die  \nbreiten Datenspuren, die jeder von uns t\u00e4glich hinterl\u00e4sst, unm\u00f6glicher denn je. Die allumfas-sende digitale Vermessung und Beobachtung  \nunseres Lebens schlie\u00dflich versch\u00e4rft den sozialen  \nWettbewerb zwischen allen.Innovationen im Bereich der Kommunikation sind also Voraussetzung, um die psychischen Anfeindungen der Moderne \u00fcberhaupt auszu-halten. Sie erm\u00f6glichen soziale N\u00e4he und ein Leben in virtuellen Kleingruppen, sie machen erst frei f\u00fcr die hohen Mobilit\u00e4tsanforderungen und die hoch individuellen Lebensentw\u00fcrfe in modernen Gesellschaften. Sie bringen dabei allerdings Licht- und Schattenseiten des d\u00f6rf-lichen Lebens zur\u00fcck in die Wirklichkeit unse-res gro\u00dfst\u00e4dtischen Lebens. Sie f\u00fchren uns vor Augen, dass wir Menschen soziale Wesen sind und ohne dichte soziale Interaktion nicht leben k\u00f6nnen.\nInnovationen in der Kommunikationstechnologie \nhaben unser Leben in diesem Sinne nicht wirk-lich radikal ver\u00e4ndert. Sie haben uns vielmehr erm\u00f6glicht, uns an radikal ver\u00e4nderte Umwelt-bedingungen anzupassen und dabei weiter ein Leben zu f\u00fchren, wie wir es immer gef\u00fchrt ha-ben und immer f\u00fchren werden. Als Menschen, die am liebsten in einem engen sozialen Umfeld abz\u00e4hlbar vieler Freunde und Familienangeh\u00f6ri-ger leben und mit diesen in engem Kontakt und Austausch stehen. Im Zweifel auch virtuell.\n1 BITKOM (2018): Smartphone-Markt: Konjunktur und Trends. Berlin. www.bitkom.org/Presse/Anhaenge-an-PIs/2018/Bitkom-\n Pressekonferenz-Smartphone-Markt-22-02-2018-Praesentation-final.pdf [Zugriff am 26.4.2018].\n2 Sally Andrews et al. (2015): Beyond Self-Report: Tools to Compare Estimated and Real-World Smartphone Use. \nhttp://journals.plos\n.org/plosone/article?id=10.1371/journal.pone.0139004 [Zugriff am 26.4.2018].Wie ver\u00e4ndert Crowdsourcing die Gesellschaft? \u00a7  41\nWie ver\u00e4ndert Crowdsourcing die  \nGesellschaft?\nCarolin Thiem\nInnovation ist, in einem Satz, der berechtigte \nAnlass f\u00fcr die Hoffnung, dass es besser wird. Der Beweis, dass die Zukunft existiert. Dass es einen Fortschritt gibt, eine Perspektive.\n1\nDie Zukunft existiert und sie wird nicht mehr dem Zufall \u00fcberlassen. Waren es fr\u00fcher an-geblich schillernde Einzelpersonen wie Thomas Edison oder James Watt, die in ihren Garagen durch ihre Erfindungen anscheinend wie zuf\u00e4l-lig bestehende Verh\u00e4ltnisse \u00fcber Bord warfen, hat sich das Verst\u00e4ndnis \u00fcber die Entstehung von Innovationen in den letzten Jahren stark ge-wandelt. Erst wurde der Mythos des t\u00fcftelnden Alleingangs entmystifiziert und dann haben die Berichte zu Innovationslandschaften und Inno-vationsystemen die Vorstellung von einzelnen, rein technischen Innovationen abgel\u00f6st.\nSeit den 2000er Jahren wird von einem Wandel \ndes Innovationsparadigmas \u2013 von geschlossen hin zur offen zug\u00e4nglichen Herstellung von In-novationen \u2013 gesprochen. Der Druck auf die Un-ternehmen durch die Globalisierung der M\u00e4rkte und die vielen M\u00f6glichkeiten durch die neuen digitalen Technologien ver\u00e4nderten die Art zu denken in vielen Firmen. Das Forschen und Ent-wickeln hinter verschlossenen T\u00fcren erschien nicht mehr zeitgem\u00e4\u00df. Zudem forderten immer mehr Konsumenten und Konsumentinnen Mit-spracherechte. Dem Wunsch mitentscheiden zu k\u00f6nnen, wie beispielsweise das Produkt der Lieblingsmarke aussieht, wurde nach und nach stattgegeben. Gleichzeitig wurden Nutzer und Nutzerinnen, sogenannte Lead User\n2, durch das \nInternet sichtbar, die bereits allein an der Weiter -\nentwicklung von Konsumprodukten und Tech-nologien gearbeitet hatten.Hier wurde erkannt, dass nicht mehr einzelne Forscherinnen und Forscher in den F&E Abtei-lungen die Zukunft sein werden, sondern eine interaktive Wertsch\u00f6pfung ben\u00f6tigt wird. Nach und nach stiegen immer mehr Unternehmen auf diesen Zug auf und die Methoden, um diese \u00d6ffnung zielgerichtet zu gestalten, vervielfach-ten sich. Eine der wichtigsten und bekanntesten ist bis heute Crowdsourcing: Das Auslagern von Aufgaben an eine unbestimmte Menge poten-zieller Zuarbeiter im Internet.\n3 Outsourcing hei\u00dft \ndagegen, dass die Aufgabe an einen bestimm-ten Akteur, eine Firma oder einen Freelancer, abgegeben wird.\nDas spannende Ph\u00e4nomen \u201eCrowdsourcing\u201c \nsamt seiner zahlreichen Anwendungsm\u00f6glich-keiten \u00fcber den \u00f6konomischen Sektor hinaus soll vorgestellt sowie die Diskussion der aktuel-len Herausforderungen wiedergegeben werden. Crowdsourcing wird als Prozessinnovation ver -\nstanden, weil es neue interaktive Prozesse von Co-Produktion, Co-Kreation, Co-Marketing und auch Co-Funding hervorgebracht hat.\nDie m\u00f6glichen Aufgaben, die durch Crowdsour -\ncing bearbeitet werden sollen, sind mittlerwei-\nle un\u00fcberschaubar geworden. Sie reichen von standardisierbaren Routinet\u00e4tigkeiten, etwa Be-wertungen von Videos oder Blogeintr\u00e4gen, f\u00fcr Unternehmen bis hin zu kreativen Arbeiten f\u00fcr Verwaltungen, Nonprofit-Organisationen oder Konzernen. Zu diesen Arbeiten geh\u00f6ren auch das Erarbeiten von Prototypen f\u00fcr komplexe Problemstellungen \u2013 zum Beispiel f\u00fcr aktuelle politische Herausforderungen auf lokalem oder globalem Niveau \u2013 oder kreative Designl\u00f6sun-gen (wie neue Uhren und Schmuck-Designs \n40 Jahre42 \nmit Swarovski-Steinen). Ebenso gestaltet es sich \nunterschiedlich, ob und wie die Beteiligten ent-lohnt werden. Die Spannweite beinhaltet kleine Betr\u00e4ge bei Routineaufgaben zum Beispiel bei Amazons Mechanical Turk, gr\u00f6\u00dfere Geldpreise (Innocentive) oder gar keine monet\u00e4re, sondern allenfalls symbolische Entlohnung. \nCrowdsourcing ist \u00fcberall\nCrowdsourcing ist einstweilen in allen Branchen und gesellschaftlichen Teilbereichen angekom-men. Das rasant wachsende Interesse an dieser Technologie in verschiedenen sozialen Feldern verweist nicht nur auf eine neue gesellschaftliche Thematisierung der Crowd, sondern ebenso auf neue Formen des Zugriffs auf Arbeits-, Kreativi-t\u00e4ts- und Wissenskr\u00e4fte. Eines der bekanntesten Beispiele aus dem Bereich Crowdsourcing ist Wi-kipedia, die digitale Wissensplattform, bei der die Weisheit der Vielen propagiert wird.\n4 Wikipedia \nfolgt dem Leitsatz von Levy5: \u201eWissen sei am \ngenausten, wenn es aus verschiedenen Quellen der Bev\u00f6lkerung besteht\u201c. Durch die M\u00f6glich-keit Beitr\u00e4ge einzustellen, zu bearbeiten und zu l\u00f6schen wird die Demokratisierung der Wis-sensproduktion bei Wikipedia gelebt. Soziologi-sche Untersuchungen geben aber Aufschluss da-r\u00fcber, dass auch bei dieser digitalen Community Hierarchieverh\u00e4ltnisse bestehen und eben nicht  jede oder jeder beliebig Eintr\u00e4ge bearbeiten und l\u00f6schen kann. \nAu\u00dferdem gibt es Projekte, bei denen die Teil-\nnehmerinnen und Teilnehmer nicht wissen, dass sie Teil eines Crowdsourcings sind, wie bei ReCaptcha. Bei der \u00dcberpr\u00fcfung von per -\ns\u00f6nlichen Daten bei Online-Anbietern muss oft ein Feld mit Buchstaben und Zahlen entziffert werden. Diese Eingaben helfen alte B\u00fccher zu digitalisieren, d. h. fast jede und jeder hat schon mal an einem Crowdsourcing-Projekt teilge-nommen. Ein anderes Beispiel ist Duolingo, eine Plattform, auf der Sprachen gelernt werden k\u00f6nnen. Dort \u00fcbersetzen die Nutzenden gleich-zeitig Webseiten-Fragmente. Crowdsourcing dient demzufolge dazu, Schwarmintelligenz dann einzusetzen, wenn mit Computern nicht die gew\u00fcnschten Ergebnisse erzielt werden k\u00f6nnen.Die Medienwelt griff in den letzten Jahren auch immer \u00f6fter auf die Ideen der Crowd zur\u00fcck. So initiierte ZDFneo 2012 den \u201eViewers Contest\u201c. Bei diesem konnten Zuschauerinnen und Zu-schauer Sendungsideen per Video dem Sender vorschlagen. Als Preis gab es beispielsweise die Teilnahme an einem Fernsehworkshop sowie die M\u00f6glichkeit ein Dreh-Set zu besuchen. ProSie-benSat1 startete 2010 sogar einen Wettbewerb namens \u201eBrain Station\u201c. Bei diesem waren Ak-teure aus der Kreativwirtschaft aufgerufen neue TV-Formatideen einzureichen. Das beste Kon-zept wurde laut Unternehmensmitteilung mit einem Preisgeld von 2.500 Euro verg\u00fctet.\n6\nIn der Wissenschaft werden Freiwillige im In-ternet beispielsweise zur Kategorisierung von Sternbildern wie Galaxy Zoo oder f\u00fcr Zellbildana-lysen wie Cell Spotting rekrutiert. Diese Art der Beteiligung wird unter dem Begriff der Citizen oder Crowd Science zusammengefasst. B\u00fcrger -\nwissenschaftliche Projekte gibt es schon mehre-re Jahre (zum Beispiel Vereine, deren Mitglieder Schmetterlinge sammeln und diese kategori-sieren oder Initiativen zur Vogelbeobachtung) und ihre Anwendungsm\u00f6glichkeiten haben sich durch die Digitalisierung vervielf\u00e4ltigt. Heute werden durch einfache digitale Eingabemasken und Tutorials Nicht-Wissenschaftlerinnen und Wissenschaftler f\u00fcr die Bearbeitung der wissen-schaftlichen Bilder wie Waldbedeckungskarten oder Zellbilder geschult. Oft ist die Aufmachung solcher Plattformen spielerisch gestaltet. Auch sehr angesehene, bekannte Forschungsinstituti-onen nutzen die Crowd. Die US-amerikanische Raumfahrtbeh\u00f6rde NASA l\u00e4sst beispielsweise origami-inspirierte, faltbare Strahlenschutzschil-de entwickeln, mit denen Raumschiffe und As-tronauten w\u00e4hrend der Reisen in die Tiefen des Alls gesch\u00fctzt werden sollen. Es k\u00f6nnen auf ei-ner Plattform Designvorschl\u00e4ge eingereicht wer -\nden (DARPA \u2013 Defense Advanced Research Pro-jects Agency). Crowd Science ist ein Zeitvertreib und kein aufw\u00e4ndiges Hobby mehr, zu dem man sich hinaus in die Natur begeben muss.\nEbenso entf\u00e4llt durch diese Plattformen \u2013 im \nGegensatz zu b\u00fcrgerwissenschaftlicher Vereins-  \nt\u00e4tigkeit \u2013 immer h\u00e4ufiger der kommunikative Wie ver\u00e4ndert Crowdsourcing die Gesellschaft? \u00a7  43\nMoment. Ein Austausch zu den Ergebnissen, \nwie fr\u00fcher zu einer neuen Schmetterlingsart, findet nicht mehr statt, da nicht jede Plattform eine Foren- oder Kommentarfunktion enth\u00e4lt. Die Beteiligung an Citizen Science Projekten wird als eine Form der Demokratisierung der Wissenschaft angesehen. Genauer betrachtet, werden hier aber auch Aufgaben ausgelagert, die sonst von wissenschaftlichen Hilfskr\u00e4ften oder anderem wissenschaftlichen Personal \u00fcbernommen wurden. Aus diesem Grund steht die Frage nach einer Form von Entlohnung der B\u00fcrgerinnen und B\u00fcrger f\u00fcr ihre Arbeit auf den Plattformen ebenfalls im Raum. Au\u00dferdem wird diskutiert, wie bei Citizen Science Projekten Evi-denz hergestellt werden kann. Fragen, wie die Qualit\u00e4t der Daten gesichert werden kann und wer die durch solche Plattformen generierten Daten \u00fcberpr\u00fcft, werden diskutiert.\n7  \nDie Crowd \u201earbeitet\u201c nicht nur f\u00fcr Unterneh-men oder die Wissenschaft, sie erm\u00f6glicht zudem die Entwicklung von zuk\u00fcnftigen so-zialen Innovationen durch ihre finanzielle Un-terst\u00fctzung \u00fcber Crowdfunding-Plattformen wie Start Next oder Kickstarter (etwa Crowd-funding Initiative f\u00fcr Oculus Rift oder zum Be-dingungslosen Grundeinkommen). Die Diskus-sionen zu Crowdfunding ranken sich meist um die Herausforderung, welche Projekte unter -\nst\u00fctzenswert sind und wie lohnend die Inves-tition ist. In 2016 erreichten ca. 54 Prozent der crowdgefundeten Projekte ihr auferlegtes Ziel, das hei\u00dft knapp die H\u00e4lfte der Kampagnen war nicht erfolgreich.\n8  Die anf\u00e4ngliche Eupho-\nrie, dass dieses System Joint Venture Investing abl\u00f6sen wird, ist demnach weitestgehend ab-geklungen.Au\u00dferdem steht f\u00fcr die Anleger bei jedem Be-trag, der gespendet oder investiert wird, die Frage im Raum, ob die Projekte tats\u00e4chlich er -\nfolgversprechend sind und seri\u00f6s gemanagt  \nwerden.\n9  Beim Crowddonating f\u00e4llt dieser weg \u2013  \nda hier keine Anlage, sondern eine Spende get\u00e4-tigt wird. Aber auch hier ist nicht ohne Skepsis zu betrachten, ob das gespendete Geld tats\u00e4chlich f\u00fcr die beworbenen Zwecke verwendet wird. \nCrowdfunding-Initiativen wie Sciencestarter er -\nweitern \u00fcber die Crowd das F\u00f6rdergesch\u00e4ft, da \nauch Forschungsprojekte Gelder \u00fcber digitale Plattformen einwerben k\u00f6nnen. Sciencestarter sowie seine englischsprachigen Verwandten ha-ben das Ziel, die Finanzierung wissenschaftlicher Projekte zu flexibilisieren. Insbesondere werden diese Plattformen f\u00fcr Projekte und Anschaffun-gen empfohlen, welche ein Forschungsinstitut schwer selbst finanzieren kann, f\u00fcr die aber ein F\u00f6rderantrag \u00fcber klassische Wege wie \u00fcber die Deutsche Forschungsgemeinschaft oder das Bundesministerium f\u00fcr Forschung und Bildung einen zu hohen Verwaltungsaufwand bedeu-tet. Ein Beispiel aus diesem Bereich ist das Open Source Science Project (OSSP), welches die Was-serqualit\u00e4t des Mississippi kartografieren will. Dieses hat 64.000 US-Dollar eingeworben.\n10 \nEbenso bedienen sich St\u00e4dte und Kommunen der Kreativit\u00e4t der Crowd. Sogenanntes Citizen- sourcing ist die von Regierungen angewandte  \nCrowdsourcing-Praxis mit dem Ziel, die kollek-  \ntive Intelligenz anzuzapfen oder auch nur die Meinung der Bev\u00f6lkerung einzuholen.\n11 Diese \nPraxis selbst kann als Soziale Innovation be-  \nschrieben werden, da sich durch das Internet die Beteiligungspraxis ma\u00dfgeblich ver\u00e4ndert 44 \nhat.12 Es springen auch Parteien auf den Citi-\nzensourcing-Zug auf: So startete die CSU Ober -\nbayern 2013 unter dem Motto \u201eMeine Zukunft \nOberbayern: B\u00fcrger im Dialog\u201c die erste umfas-sende B\u00fcrgerbeteiligung einer Partei. Auf der Plattform wurde das Parteiprogramm diskutiert, Ideen f\u00fcr Inhalte abgefragt sowie Meinungen zu bestehenden Konzepten eingeholt. Die CSU war Vorreiter, in den letzten Jahren sind viele Parteien nachgezogen und versuchen aktiv ihre Basis digi-tal bei Entscheidungen zu integrieren.\nAndere Formen von Citizensourcing sind Platt-\nformen wie der Maerker Brandenburg\n13 oder \ndie SmarticipateApp14 in Hamburg. \u00dcber den \nMaerker (Plattform oder App) k\u00f6nnen Bewohne-rinnen und Bewohner der Region Brandenburg negative Auff\u00e4lligkeiten in ihrer Region melden. Das reicht von zu hoch gewachsenem Rasen auf einer Verkehrsinsel \u00fcber eine kaputte Parkbank bis zum Wunsch nach einem Zebrastreifen in der N\u00e4he einer Schule. Die Smarticipate App, ein derzeitiges Forschungsprojekt aus dem Bereich Smart City, geht sogar einen Schritt weiter. Bei diesem Projekt k\u00f6nnen Hamburgerinnen und Hamburger digital den Standort bestimmen, an dem ein neuer Baum gepflanzt werden soll. Dieser Vorschlag wird auf Basis der verf\u00fcgbaren Infrastrukturdaten sofort online gepr\u00fcft. Die App meldet zur\u00fcck, ob der Standort geeignet ist oder ob der Vorschlag optimiert werden sollte. Durch diese Art der Beteiligung werden Prozesse ver -\neinfacht, aber auch die Verantwortung von der kommunalen Verwaltung an die B\u00fcrgerinnen und B\u00fcrger \u00fcbertragen. \nDie oft gepredigte erh\u00f6hte Transparenz ist dabei \nnicht immer gegeben, denn die Hoheit \u00fcber die Bearbeitung der M\u00e4ngel oder ob tats\u00e4chlich ein Baum gepflanzt wird, obliegt immer noch der zust\u00e4ndigen Verwaltung. Digitale Beteiligungs-formate werden in der Politik als Revolution gefeiert, da sich jetzt schnell, einfach und ohne gro\u00dfen Aufwand \u2013 verglichen zur Teilnahme an einer mehrt\u00e4gigen B\u00fcrgerkonferenz \u2013 beteiligt werden kann. Studien sagen aber auch, dass die gro\u00dfe Ver\u00e4nderung bisher ausgeblieben ist und sich wenig neue Akteure beteiligen.\n15 Diese Aus-\nsage bezieht sich auf von Verwaltung oder Politik initiierte Formate; die Durchschlagskraft von so-zialen Medien bei Initiativen \u201evon unten\u201c ist bei Citizensourcing-Formaten nicht bedacht. \nDie Rechte der Crowdworker\nWie gezeigt wurde, findet Crowdsourcing als Prozessinnovation vielseitig in allen gesellschaft-lichen Teilbereichen Anwendung und beeinflusst die Innovationslandschaft. Wie jede Innovation bringt auch Crowdsourcing unintendierte Folgen mit sich. Crowdsourcing schafft Erwartungen an Flexibilisierung und Demokratisierung von Pro-zessen, aber auch eine neue Form von Arbeit. Aufgaben, die geringe oder eine spezifische Expertise wie Designkenntnisse ben\u00f6tigen, wer -\nden nicht mehr an das Personal weitergegeben, sondern \u00fcber eine digitale Plattform an selbst-st\u00e4ndige Crowdworker ausgelagert. Die Arbei-ter werden \u00fcber die Plattform entlohnt. Arbeit wird demzufolge von digitalen Infrastrukturen reorganisiert.\n16 Ein Argument f\u00fcr Crowdwork ist \ndie Anonymit\u00e4t der Arbeitnehmerinnen und Ar -\nbeitnehmer. Auf den Plattformen f\u00fcr Microtasks sind dem Kunden demografische Daten wie Geschlecht, Alter, Bildungsgrad, ethnischer Hin-tergrund, Vorstrafenregister und sexuelle Orien-tierung meist nicht bekannt. Crowdwork bietet demzufolge einen Zugang zum Arbeitsmarkt f\u00fcr Menschen, die eventuell sonst Diskriminierun-gen ausgesetzt w\u00e4ren oder gar keine Besch\u00e4fti-gung finden w\u00fcrden. \nCrowdwork als Soziale Innovation bringt aber \nnicht nur Vorteile mit sich, denn Crowdwork un-tersteht keinen Leistungskontrollen, es gibt keine Vorgesetzten, keine Kolleginnen oder Kollegen. Die Akteure der Crowd sind daher weniger sozi-al verbunden, aber auch zu nichts verpflichtet.\n17 \nDas ruft automatisch die Frage nach der Ent-lohnung auf, denn was f\u00fcr einen Crowdworker in einem Entwicklungsland ein Monatslohn ist, reicht f\u00fcr einen anderen aus einem Industrieland nicht mal einen Tag. F\u00fcr das Unternehmen ist dies profitabel, denn es wird jemanden finden, der die Aufgabe f\u00fcr den geplanten Lohn erle-digt. Von den meisten Plattformen wird au\u00dfer -\ndem von den Besch\u00e4ftigten verlangt, dass sie ihrer Kategorisierung als Selbstst\u00e4ndige bzw. unabh\u00e4ngige Auftragnehmer zustimmen. Die Wie ver\u00e4ndert Crowdsourcing die Gesellschaft? \u00a7  45\nCrowdworker haben demzufolge keinen An-\nspruch auf arbeitsrechtliche Grundlagen, wie die Zahlung eines Mindestlohns, bezahlten Urlaub, Elternzeit, Entlohnung w\u00e4hrend Krankheit oder \u00dcberstundenverg\u00fctung. Weiterhin bestehen bei Plattformen wie 99Designs (bei der Unterneh-men von Web-/App-Anwendungen \u00fcber Logos bis hin zu Merchandise-Artikeln Designarbeiten an die Crowd vergeben) noch Unklarheiten dar -\n\u00fcber, wie mit den Urheberrechten von den Vor -\nschl\u00e4gen ausgebildeter Selbstst\u00e4ndiger umzuge-hen ist, die nicht gewinnen. \nBei einer Designausschreibung ohne Crowdsour -\ncing w\u00fcrden die Dateien nur an den Auftrag-\ngeber gesendet, auf einer Plattform sind sie f\u00fcr alle Konkurrenten zug\u00e4nglich und es werden die Arbeitsstunden f\u00fcr die Entw\u00fcrfe nicht entlohnt. Das Unternehmen zahlt nur f\u00fcr den Siegerent-wurf, holt sich aber zahlreiche Anregungen und Ideen kostenfrei ins Haus. In Bezug auf das inter -\nnationale Recht wird bereits diskutiert, wie diese Fragen zu handhaben sind und wie die Regulie-rung solcher Plattformen aussehen kann. Die Crowd als Innovationsmotor f\u00fcr techni-\nsche und soziale Innovationen\nDurch Crowdsourcing haben sich Beteiligungs-\nprozesse in Politik, Wissenschaft und wirt-schaftlicher Wertsch\u00f6pfung derart gewandelt, dass sich Crowdsourcing selbst innovativ auf die  \nProduktion von G\u00fctern, Kreativit\u00e4t, und Wissen, aber auch auf den Finanz- und F\u00f6rdermarkt aus-wirkt. Durch die Aufz\u00e4hlung der verschiedenen Anwendungsbeispiele und deren Reflektion wird deutlich, dass Crowdsourcing nicht nur weitere Produktinnovationen hervorruft, sondern als Innovationsmotor auch verschiedene soziale Innovationen wie Gesetze zu digitaler Arbeit und einem ver\u00e4nderten Umgang mit dem  \nUrheberrecht nach sich ziehen wird. Die  \nZukunft wird zeigen, in welchen Bereichen die Crowd nachhaltig eine Rolle spielen wird oder wo sie von anderen Akteurinnen und Akteuren abgel\u00f6st wird.\n1 Lotter, Wolf (2018): Der Stoff aus dem das Neue ist. Vorabdruck seines Buches \u201eInnovation. Streitschrift f\u00fcr ein barrierefreies Denken. \n In: Brand eins \nThema: Innovation (5); Heft 8, S. 24\u201328.\n2 Van Hippel, Erik (1986): Lead Users. A Source of novel product concepts. In: Management Science, Vol. 32, S. 791\u201380.\n3 Howe, J. (2009): Crowdsourcing: Why the power of the crowd is driving the future of business (1. paperbacked). New York, NY: Three Rivers Press.\n4  Surowiecki, J. (2004): The wisdom of crowds: Why the many are smarter than the few and how collective wisdom shapes business, \n economies,\n societies, and nations. New York, NY: Doubleday.\n5 Levy, Pierre (1997): Collective Intelligence: Mankind\u00b4s Emerging World in Cyberspace. Cambridge, MA: Perseus Books.\n6 ProSiebenSat2 Media A G: BrainStation, ver\u00f6ffentlicht 11.2.2012. www.soenke-andresen.de/mediapool/89/893091/data/Brainstation_2012_-\n _ProSiebenSat1.de.pdf [Zugriff am 23.3.2018].\n7 Forschungsprojekt dazu von Sabine Maasen und Sascha Dickel \u201eEvidenz in der Citizen Science. Zwischen nicht-zertifizierter Expertise, \n professioneller Kontrolle und \nTechnisierung\u201c., nachzulesen unter http://gepris.dfg.de/gepris/projekt/335449718 [Zugriff am 23.3.2018].\n8 Mindsetmagazin (2016), aktuelle Statistik en sind derzeit nicht verf\u00fcgbar.\n9 Nickel, Valeria (2017): Crowdfunding: Vor- und Nachteile im \u00dcberblick. https://de.bergfuerst.com/ratgeber/crowdfunding-vorteile-nachteile, \n ver\u00f6ffentlicht am: 13.07.2017, [Zugriff am 28.3.2018].\n10 Herb, Ulrich (2012): Sciencestarter: Crowdfunding f\u00fcr wissenschaftliche Projekte, ver\u00f6ffentlicht am 21.11.2012, www.heise.de/newsticker/\n meldung/Sciencestarter-Crowdfunding-fuer\n-wissenschaftliche-Projekte-1753965.html [Zugriff am 29.3.2018].\n11 Hilgers, Dennis, und Ihl, Jan C. (2010): Citizensourcing: Applying the Concept of Open Innovation to the Public Sector. The International Journal of \n Public Participation 4,\n S. 68\u201388.\n12 Thiem, Carolin (2015): Neue Aufgaben, neue B\u00fcrger- Citizensourcing als soziale Innovation. In: Sozialwissenschaften und Berufspraxis (SuB), \n 38 Jg., Heft 2,\n S. 261\u2013273.\n13 https://maerker.brandenburg.de/bb/aktuell\n14 www.hamburg.de/pressearchiv-fhh/9806044/2017-11-01-bsw-smartathon/\n15 Dressel, K. et. al. (2012): Die partizipative Begleitung riskanter Entscheidungen als gesellschaftliche Innovation. In Beck, Gerald; Kropp Cordula und \n Deppe,\n Ina (Hg.): Gesellschaft innovativ. Wer sind die Akteure? 1. Aufl, 315-330. Wiesbaden. VS Verlag f\u00fcr Sozialwissenschaften / Springer Fachmedien \n16 Dickel, S. und Thiem, C. (2017): Bestellte Massen. Auf dem Weg zu einer Theorie der Crowd \u2013 Kongressband, 38. Kongress der Deutschen \n Gesellschaft f\u00fcr Soziologie 2016 in Bamberg.\n17 Gerber, C. und Krzywdzinsk, M. (2017): Sch\u00f6ne neue Arbeitswelt? Durch Crowdworking werden Aufgaben global verteilt. In: WZB Mitteilungen \nHeft 155 M\u00e4rz 2017. https://bibliothek.wzb.eu/artikel/2017/f-20463.pdf [Zugriff am 23.3.2018].46 \nVon Erbsen zu Designerbabies?\nDie CRISPR/Cas-Methode und ihre historischen Wurzeln\n \nEin Austausch eines Medizinethikers und einer Humanbiologin\nEine biotechnologische Innovation, die seit einigen Jahren weit \u00fcber Fachkreise \nhinaus die Menschen bewegt, verbirgt sich hinter der Bezeichnung \u201eCRISPR\u201c. Oft wird sie auch als \u201eGenschere\u201c bezeichnet. Mein Eindruck ist, dass in CRISPR einer -\nseits gro\u00dfe Hoffnungen gesetzt werden, die Technologie andererseits aber auch \u00c4ngste weckt. Man erhofft sich etwa wirksame Therapien gegen Erbkrankhei-ten oder auch Fortschritte in der Bek\u00e4mpfung von Krankheitserregern. Skeptiker bef\u00fcrchten jedoch eine tiefergehende Revolution in der Reproduktionsmedizin \u2013  \nbis hin zur \u201eMenschenz\u00fcchtung\u201c und der Erschaffung von \u201eDesignerbabies\u201c ganz nach den Vorstellungen ihrer Eltern. Aber auch weniger futuristische Szena-rien werden von Skeptikern angef\u00fchrt, etwa unumkehrbare Sch\u00e4digungen von Menschen durch Eingriffe in das menschliche Erbgut, deren langfristige Auswir -\nkungen erst in sp\u00e4teren Generationen sichtbar werden. Bevor man sich jedoch an eine Einsch\u00e4tzung und Abw\u00e4gung solcher und anderer Chancen und Risiken wagt, sollte man meines Erachtens verstehen, wie CRISPR genau funktioniert und welche Einsatzm\u00f6glichkeiten nach heutigem Wissensstand realistisch sind. Wie w\u00fcrdest du diese Aspekte jemandem erl\u00e4utern, der \u00fcber kein biomedizinisches Expertenwissen verf\u00fcgt?\nAus Sicht einer Naturwissenschaftlerin finde ich es sehr interessant zu beobach-\nten, welche Informationen zur CRISPR-Technologie in der allgemeinen Tagespresse ankommen und wie die Reaktionen darauf sind! Tats\u00e4chlich hat die Entdeckung dieser Technologie auch in der Fachszene einen richtiggehenden Hype ausgel\u00f6st, die Aufregung ist also alles andere als unbegr\u00fcndet. Zu deiner Frage, was eigent-lich hinter der kryptischen Abk\u00fcrzung und ihrer Anwendung steckt, um die es sich hier dreht: Das in seiner langen Form \u201eCRISPR/Cas9\u201c genannte Werkzeug ist ein neuartiges Verfahren der Genomeditierung, durch das mit nie zuvor er -\nreichter Pr\u00e4zision und Schnelligkeit die DNA, also auch das menschliche Erbgut, manipuliert werden kann. Stellt man sich das Genom als viele aufeinanderfolgen-de S\u00e4tze einer Geschichte vor, kann man mit CRISPR nun einzelne Buchstaben oder ganze Satzteile l\u00f6schen oder auch ersetzen und damit die Geschichte grund-legend ver\u00e4ndern. Das CRISPR/Cas9-System ist in bestimmten Organismen ein nat\u00fcrlicher Prozess, es wurde urspr\u00fcnglich von Bakterien als eine Art Immunge-d\u00e4chtnis entwickelt, um das eigene Erbgut vor den DNA-Sequenzen angreifender Viren zu sch\u00fctzen. Einmal von einem Virus infiziert, speichern die Bakterien  Dr. Tobias Hainz\nDr. Anne  \nDwertmann\n40 JahreVon Erbsen zu Designerbabies? \u00a7  47\neinen kleinen Teil der Virus-Erbinformation in den sogenannten \u201eclustered  \nregularly interspaced short palindromic repeats\" (CRISPR) im eigenen Genom ab. \nBei einer erneuten Infektion mit demselben Virus werden diese Abschnitte dann quasi als Blaupause verwendet, um die feindliche DNA schnell zu erkennen, das Protein Cas9 zerschneidet daraufhin sofort diese Sequenzen und macht das Virus damit unsch\u00e4dlich.\n1 \nKlingt n\u00fctzlich f\u00fcr die Immunabwehr in Bakterien, aber wie lassen sich die Er -\nkenntnisse auf den Menschen \u00fcbertragen? Au\u00dferdem gibt es diesen Mechanis-mus ja sicher schon viel l\u00e4nger als den Menschen \u2013 warum wurde er dann erst jetzt entdeckt?\nAnfang der 90er Jahre wurden erstmals CRISPR-Sequenzen in Bakteriengenomen \ncharakterisiert, in den 2000er Jahren wurde dann Cas9 entdeckt und nach und nach die Funktionsweise des ganzen Systems aufgekl\u00e4rt.\n2 Ohne die zu diesem \nZeitpunkt technologisch erstmals verf\u00fcgbaren DNA-Untersuchungsmethoden w\u00e4re dies vorher nicht m\u00f6glich gewesen. Das Interesse an der \u201eGenschere\u201c konzentrierte sich anfangs auch eher auf den biotechnologischen Bereich. Man hoffte, mit den neuen Erkenntnissen auf Prozesse der Lebensmittelindustrie, an denen Bakterien beteiligt sind, wie etwa die Joghurtherstellung, einwirken zu k\u00f6nnen. Erst die \u201eM\u00fctter\u201c der Technologie, Emanuelle Charpentier und  \nJennifer Doudna, sowie der Biotechnologe Feng Zhang wiesen 2012 darauf hin, dass sich mit der CRISPR-Methode gezielt Abschnitte aus dem Erbgut entfernen oder austauschen lassen, und zwar auch in Pflanzen, Tieren und Menschen. Damit ist in der Theorie vieles m\u00f6glich \u2013 so k\u00f6nnten zum Beispiel fehlerhafte Gene, die im Menschen zu Erbkrankheiten f\u00fchren, gegen gesunde Gene aus-getauscht werden. Oder es k\u00f6nnten die Virus-DNA-Sequenzen des HI-Virus vollst\u00e4ndig aus HIV-infizierten Menschen eliminiert und die Infektion damit voll-st\u00e4ndig beseitigt werden. Dar\u00fcber hinaus gibt es eine Reihe von Anwendungs- szenarien in der Tier- und Pflanzenz\u00fcchtung sowie in der chemischen Industrie.  \n Schon jetzt gibt es eine Reihe von zugelassenen Nutzpflanzen, die mit der CRISPR-Technologie ver\u00e4ndert wurden. Diese gelten sogar vor dem Gesetz derzeit als \u201enicht genmanipuliert\u201c, da die mit CRIPSR eingef\u00fchrten Genmutationen auch mit den klassischen Methoden der Pflanzenmutagenese, wie z. B. Bestrahlung, h\u00e4tten erzeugt werden k\u00f6nnen.\n3 Auch vor CRISPR gab es also schon M\u00f6glichkei-\nten der Genomeditierung, aber keine davon war so schnell, einfach und genau. Die Grundlagenforschung, beispielsweise im Bereich der Wirkstoffentwicklung, wurde durch die M\u00f6glichkeiten von CRISPR bereits revolutioniert.\n4 Insgesamt ist \ndas Potenzial der Technologie riesig \u2013 ein Nobelpreis f\u00fcr die Entdeckerinnen gilt als ausgemachte Sache.\nDer Nobelpreis soll laut Alfred Nobels Testament an Personen verliehen werden, \ndie der Menschheit den gr\u00f6\u00dften Nutzen gebracht haben. Das bedeutet, wenn die Verleihung des Preises an die CRISPR-Entdeckerinnen bereits eine ausgemachte Dr. Tobias Hainz\nDr. Tobias HainzDr. Anne  \nDwertmann48 \nSache ist, dann ist es ebenfalls eine ausgemachte Sache, dass die Methode in Zu-\nkunft zum gro\u00dfen Nutzen der Menschheit eingesetzt werden wird \u2013 sofern man Nobels Testament ernst nimmt. Das finde ich aus ethischer wie auch aus histori-scher Perspektive gleicherma\u00dfen interessant: \u201eNutzen\u201c ist in manchen ethischen Theorien eine zentrale Kategorie f\u00fcr die Beurteilung von Handlungen. Allerdings ist sie nicht ohne ihr Pendant zu denken \u2013 den \u201eSchaden\u201c, denn eine endg\u00fcltige Beurteilung sollte stets das Resultat einer Verrechnung von Nutzen und Schaden sein. Gerade Skeptiker, die der CRISPR-Methode ein hohes Schadenspotenzial zu-schreiben, k\u00f6nnten eine solche Prophezeiung des Nobelpreises f\u00fcr Charpentier und Doudna daher ein wenig voreilig finden. Umso wichtiger finde ich eine sach-liche Auseinandersetzung zu den Nutzen- und Schadenspotenzialen von CRISPR, denn es k\u00f6nnte um weit mehr gehen als um ein paar Millionen schwedische Kro-nen f\u00fcr den Nobelpreis. Historisch betrachtet ist auff\u00e4llig, dass ein notwendiger Vorl\u00e4ufer von CRISPR, n\u00e4mlich das Humangenomprojekt, von einem vergleichba-ren Hype begleitet wurde, aber die Hoffnungen nicht g\u00e4nzlich erf\u00fcllen konnte. Auch der Nobelpreis f\u00fcr die wichtigsten Beteiligten ist bislang ausgeblieben.\nDas stimmt. Mit gutem Grund verleiht das Nobel-Komitee seine Preise aber oft \nerst Jahrzehnte nach einer bahnbrechenden Entdeckung, um die langfristigen Folgen f\u00fcr die Menschheit besser absehen zu k\u00f6nnen. Ich sehe f\u00fcr die Treiber des Humangenomprojekts da durchaus noch eine reelle Chance! Obwohl es stimmt, dass sich die Erwartungen an die Entschl\u00fcsselung des Genoms zur Jahrtausendwende nicht erf\u00fcllt haben \u2013 damals war vorausgesagt worden, dass man in zehn Jahren die genetischen Grundlagen fast aller Krankheiten verste-hen wird, um eine weitere Dekade sp\u00e4ter einen Strau\u00df an neuen Therapie-m\u00f6glichkeiten in der Hand zu halten.\n5 Auch wenn man heute schon f\u00fcr knapp \ntausend Dollar innerhalb weniger Tage das menschliche Genom individueller Patienten entschl\u00fcsseln kann, ist die Interpretation dieser Information ungleich komplexer als vorausgeahnt. Die biomedizinische Grundlagenforschung wurde durch die neuen Erkenntnisse zur Erbgutinformation jedoch tats\u00e4chlich revoluti-oniert, nicht nur was die reine Erkenntnis betrifft, vor allem auch technologisch. Ohne den mit dem Humangenomprojekt verbundenen Innovationsschub w\u00e4re auch die umfassende Aufkl\u00e4rung des CRISPR/Cas9-Systems unm\u00f6glich gewe-sen. Leider profitiert der Patient jedoch bisher unmittelbar noch zu wenig davon.  \n In Bezug auf die zu hohen Erwartungen k\u00f6nnte es der CRISPR-Technologie \u00e4hnlich ergehen \u2013 trotz der enormen Auswirkungen auf die Grundlagenfor -\nschung ist die Technologie von einer kontrollierten und gut verstandenen An-wendung am Menschen immer noch meilenweit entfernt. Noch scheint die Genschere kleinste Fehler beim Schneiden des Genoms zu machen, die sich im Menschen allerdings fatal auswirken k\u00f6nnen. Au\u00dferdem ist es derzeit unm\u00f6g-lich, die CRISPR-Technologie effektiv in einem ausgewachsenen Organismus und nicht nur in einer befruchteten Eizelle im Reagenzglas anzuwenden. Ich w\u00fcrde hier jedoch f\u00fcr etwas Geduld pl\u00e4dieren, das zeigt auch die Geschichte. Wie oft wurden schon Neuentdeckungen zu fr\u00fchzeitig als \u201egescheitert\u201c erkl\u00e4rt oder auch viel zu lange komplett ignoriert.Dr. Anne  \nDwertmannVon Erbsen zu Designerbabies? \u00a7  49\nDas erinnert mich an das Schicksal einer weiteren Entdeckung, die als Vorl\u00e4ufer \nder CRISPR-Technologie gelten kann: Bereits in den 1860er Jahren beschrieb Gre-gor Mendel am Beispiel von Erbsenz\u00fcchtungen, wie die Vererbung von Merkma-len bei den allermeisten Pflanzen und Tieren funktioniert. Nicht umsonst spricht man auch heute noch von den Mendelschen Regeln, was die Bedeutung von Mendels Entdeckung unterstreicht. Ohne Mendels Erbsenz\u00fcchtungen und seine Beobachtungen \u2013 die er ohne das Wissen beschrieben hat, dass es etwas wie Gene \u00fcberhaupt gibt \u2013 h\u00e4tten wir heute vermutlich weder das Humangenom-projekt noch die CRISPR-Technologie. Allerdings wurden die Mendelschen Regeln \u00fcber mehrere Jahrzehnte kaum rezipiert. Dabei spielten zum Teil triviale Gr\u00fcnde eine Rolle, wie etwa das Desinteresse von Fachkollegen oder eine als umst\u00e4nd-lich empfundene Terminologie Mendels. Aber beispielsweise in der Sowjetunion wurden Mendels Erkenntnisse bis in die 1960er Jahre aus ideologischen Gr\u00fcnden tats\u00e4chlich systematisch unterdr\u00fcckt.\nAus heutiger Sicht ist das kaum nachzuvollziehen, wenn man bedenkt, dass die \nMendelschen Regeln als eine der wichtigsten Grundlagen f\u00fcr die moderne Pflan-zenzucht gelten. Was waren denn die Gr\u00fcnde f\u00fcr die Verleugnung einer solchen richtungsweisenden wissenschaftlichen Erkenntnis?\nIn der Sowjetunion hing man der Vorstellung an, Organismen k\u00f6nnten umweltbe-\ndingt erworbene Eigenschaften an ihre Nachkommen vererben. Wegen der Unver -\neinbarkeit der Mendelschen Regeln mit dieser auch als \u201eNeolamarckismus\u201c\n6  be-\nzeichneten Vorstellung setzte ihr einflussreichster Vordenker, Trofim Denissowitsch Lyssenko, seine politischen Beziehungen ein, um Mendels Erkenntnisse aus dem wis-senschaftlichen Diskurs zu verbannen. Folgen waren unter anderem die politische Verfolgung seiner wissenschaftlichen Kritiker und die Verschwendung knapper Res-sourcen f\u00fcr nutzlose Pflanzenzuchtexperimente, die sogar Hungersn\u00f6te verst\u00e4rkten.  \n Die Mendelschen Regeln hatten also mit besonders gro\u00dfen Startschwierigkeiten zu k\u00e4mpfen, bis sie in der Fachwelt angekommen waren und ihr Status als innova-tive Ideen best\u00e4tigt wurde. Diese H\u00fcrde hat CRISPR sicher schon genommen. Der Umgang mit den Mendelschen Regeln in der Sowjetunion weist f\u00fcr mich aber auf ein weiteres Problem hin, das man im Umgang mit CRISPR tunlichst vermeiden sollte, n\u00e4mlich eine ideologisch verzerrte Diskussion mit der Gefahr fataler Konse-quenzen. Es ist denkbar, dass manche Menschen CRISPR ablehnen, weil sie glau-ben, dass dadurch Eingriffe in naturgegebene Ph\u00e4nomene erm\u00f6glicht werden, die aus guten Gr\u00fcnden so sind, wie sie sind \u2013 im Sinne eines \u201enature knows best\u201c.\nIch kann mir vorstellen, dass f\u00fcr viele Menschen der Gedanke etwas Bedrohliches \nan sich hat, dass mit der CRISPR-Technologie zumindest theoretisch die biologi-sche Essenz eines jeden Organismus manipuliert werden k\u00f6nnte. Leider arbeitet die Natur beziehungsweise die Evolution nicht immer nur f\u00fcr uns \u2013 so passen sich beispielsweise Krankheitserreger in atemberaubender Geschwindigkeit an neue Dr. Tobias Hainz\nDr. Tobias HainzDr. Anne  \nDwertmann\nDr. Anne  \nDwertmann50 \nBehandlungen an oder breiten sich mit dem Klimawandel in immer neue Regionen \naus. Dies trifft beispielsweise auf die Parasitenerkrankung Malaria zu, an der alleine  \nin Afrika jedes Jahr hunderttausende Menschen sterben. Es wird derzeit an einer Anwendung der CRIPSR-Technologie geforscht, an den sogenannten Gene-Drives,  \ndie die Malaria substanziell eind\u00e4mmen oder wom\u00f6glich sogar ausrotten k\u00f6nnten.  \nDie Gene-Drives, einmal in die frei lebende Population der Malaria \u00fcbertragenden Anopheles-M\u00fccke eingef\u00fchrt, sorgen daf\u00fcr, dass bestimmte neu eingef\u00fchrte Gene in den M\u00fccken pr\u00e4ferentiell weitergegeben werden. So k\u00f6nnte \u00fcber einen relativ kurzen Zeitraum eine komplette Spezies mit Genen ausgestattet werden, die entweder eine Weiterentwicklung des Malariaparasiten in der M\u00fccke ver- hindern oder auch die Fortpflanzungsf\u00e4higkeit der M\u00fccken ausschalten und die Spezies damit wom\u00f6glich komplett ausrotten w\u00fcrden.\n7 Dabei stellt sich nat\u00fcrlich \nsofort die Frage nach den damit verbundenen \u00f6kologischen Risiken, aber auch die ethische Frage, ob die Ausrottung einer M\u00fcckenart zur Bek\u00e4mpfung der \u201eGei\u00dfel der Tropen\u201c nicht doch gerechtfertigt w\u00e4re. \nV\u00f6llige Zustimmung. Selbst wenn die Evolution ein in irgendeiner Weise  \ngelenkter Prozess w\u00e4re, dann sicher nicht immer zu unserem Vorteil \u2013 das zeigt \ndas Beispiel Malaria eindr\u00fccklich. Gene-Drives w\u00e4ren dann also eine M\u00f6glich-keit, direkt und kurzfristig sehr tief in evolution\u00e4re Prozesse einzugreifen, und zwar \u2013 zumindest vordergr\u00fcndig \u2013 zu unserem Vorteil. F\u00fcr eine wohlbegr\u00fcn-dete ethische Einsch\u00e4tzung reicht es aber noch nicht aus, ausreichend davon \u00fcberzeugt sein zu k\u00f6nnen, dass eine Anwendung zur Ausrottung des Malaria- parasiten oder zumindest der Anopheles-M\u00fccke als \u00dcbertr\u00e4ger f\u00fchren w\u00fcrde. Wie du schon erw\u00e4hnst, sollte man mindestens absch\u00e4tzen k\u00f6nnen, welche Auswirkung diese Form der Entfernung einer ganzen Spezies aus einem \u00d6kosystem  \nf\u00fcr andere dort lebende Arten h\u00e4tte. Bei einer befriedigenden Informations-  \nlage k\u00f6nnte man dann in einen Prozess der Abw\u00e4gung von Chancen \u2013  \nprim\u00e4r nat\u00fcrlich f\u00fcr uns Menschen \u2013 und Risiken eintreten, an dessen Ende eine wie auch immer geartete, in jedem Falle aber guten Gewissens vertret-bare ethische Empfehlung st\u00fcnde. Ich bef\u00fcrchte allerdings, dass in eine solche  \nDebatte nicht nur recht gut greif- und somit auch diskutierbare Argumente  \neingebracht w\u00fcrden, sondern auch deutlich voraussetzungsreichere Beitr\u00e4ge.  \n Diese k\u00f6nnten etwa der Natur einen Selbstwert zuschreiben und damit einer Ausrottung der Anopheles-M\u00fccke als Teil dieser Natur widersprechen. Das Pro-blem dabei ist: Solange man nicht transparent darlegt, weshalb die Natur einen Selbstwert haben soll, l\u00e4sst sich \u00fcber ein solches Argument schwer diskutieren. Ich glaube aber, dass die \u00c4ngste vieler Menschen sich gar nicht so sehr auf die Anwendungsm\u00f6glichkeiten von CRISPR auf andere Spezies beziehen, sondern auf uns Menschen selbst \u2013 vielleicht sogar mit dem Potenzial, irgendwann einmal die bereits erw\u00e4hnten \u201eDesignerbabies\u201c zu erzeugen. Der Deutsche Ethikrat hat sich 2017 in einer ad-hoc-Empfehlung mit Keimbahneingriffen\n8 beim Menschen \nbefasst, was noch einmal die Dringlichkeit des Themas unterstreicht.9 Wie sch\u00e4tzt \ndu das Potenzial von CRISPR f\u00fcr solche Anwendungen ein?Dr. Tobias HainzVon Erbsen zu Designerbabies? \u00a7  51\nRein technologisch gesehen sind wir von der sicheren Anwendung am Menschen, \nwie zuvor schon erw\u00e4hnt, noch weit entfernt. Tats\u00e4chlich kann heute niemand sagen, wann die Technologie \u00fcberhaupt \u201ereif\u201c genug f\u00fcr das Szenario Keim-bahneingriff beim Menschen w\u00e4re. Allerdings werden in der Forschung in den USA, China und Gro\u00dfbritannien bereits erste Fakten mit Experimenten an mensch-lichen Embryonen geschaffen, in denen krankheitsausl\u00f6sende Gene bereits eini-germa\u00dfen erfolgreich ausgeschaltet werden k\u00f6nnen. Ich denke, es ist auch his-torisch betrachtet relativ sicher, dass die Menschheit in absehbarer Zukunft ein Werkzeug in den H\u00e4nden halten wird, um tats\u00e4chlich das menschliche Erbgut ver -\n\u00e4ndern zu k\u00f6nnen \u2013 egal ob \u00fcber CRISPR oder eine andere Zukunftstechnologie.  \n Die M\u00f6glichkeit der Pr\u00e4implantationsdiagnostik hat uns bereits einen Vorge-schmack dazu gegeben, auch dazu, wie getrieben sich der gesellschaftliche Dis-kurs dabei gegen\u00fcber dem scheinbar unaufhaltsamen technologischen Fortschritt gezeigt hat. Wobei die Anwendung von CRISPR in der menschlichen Keimbahn erstmals in der Wissenschaftsgeschichte nicht nur Auswirkungen auf ein einzelnes ungeborenes Kind, sondern auch auf dessen noch nicht gezeugte Nachkommen unbestimmter Zahl bedeuten w\u00fcrde und damit weiter greifende Auswirkungen h\u00e4tte als jede Technologie davor. Ich bef\u00fcrworte daher eine umfassende ethische, rechtliche und gesellschaftliche Auseinandersetzung mit den Anwendungsm\u00f6g-lichkeiten von CRISPR. Nur in einer offenen Debatte k\u00f6nnen die Chancen und Risiken einer solchen Technologie wirklich umfassend gegeneinander abgewogen werden. Ich denke, die technologische M\u00f6glichkeit, das Erbgut von Menschen umfassend \u00e4ndern zu k\u00f6nnen wird irgendwann kommen \u2013 besser wir bereiten uns jetzt schon darauf vor.\nZu dieser Vorbereitung in Form einer offenen Debatte sollte meines Erachtens \nauch eine Auseinandersetzung mit der Frage geh\u00f6ren, wer eigentlich die \u201eBe-weislast\u201c f\u00fcr oder gegen Anwendungsm\u00f6glichkeiten von CRISPR tr\u00e4gt: die Be-f\u00fcrworter oder die Skeptiker? Wir haben schon viel \u00fcber Chancen und Risiken gesprochen, und auch \u00fcber Sicherheit. Dabei schwingt die folgende Frage mit: Wann sind bestimmte Anwendungsm\u00f6glichkeiten von CRISPR eigentlich sicher genug? Aber wenn man diese Frage stellt, b\u00fcrdet man die Beweislast implizit bereits den Bef\u00fcrwortern auf, denn man fordert ein Mindestma\u00df an Sicherheit, dessen Erreichen von den Bef\u00fcrwortern nachzuweisen ist. Im konkreten medizini-schen Anwendungsfall ist das auch gerechtfertigt, aber auf einer Vorstufe, auf der wir uns derzeit befinden, m\u00f6chte ich daf\u00fcr pl\u00e4dieren, auch eine andere, f\u00fcr mich gleichwertige Frage zu stellen, die zumindest teilweise die Beweislast umkehrt. Wann m\u00fcssen die Chancen, die bestimmte Anwendungen von CRISPR bieten, als so gro\u00df erachtet werden, dass man trotz etwaiger Sicherheitsbedenken oder anderer Vorbehalte ein Verbot der Erforschung dieser Anwendungen aus ethi-schen Gr\u00fcnden kaum noch rechtfertigen kann? W\u00e4hrend die erste Frage vor al-lem von den Bef\u00fcrwortern Antworten verlangt, nimmt die zweite Frage auch die Skeptiker in die Pflicht. Denn nun m\u00fcssen sie argumentieren \u2013 und zwar ethisch und empirisch \u2013 weswegen sie sich trotz gro\u00dfer Chancen gegen die Erforschung bestimmter CRISPR-Anwendungen aussprechen.\nDr. Tobias HainzDr. Anne  \nDwertmann52 \nDas sehe ich genau so. Oder um Professor Peter Dabrock, Theologe und Vorsit-\nzender des Deutschen Ethikrates zu zitieren: \u201eMan tr\u00e4gt Verantwortung f\u00fcr das, was man tut, aber auch f\u00fcr das, was man wider besseres Wissen verhindert\u201c.\n10  \nIch jedenfalls blicke positiv in die Zukunft und bin sehr gespannt, wie die Mensch-heit mit den neuen M\u00f6glichkeiten von CRISPR umgehen wird.Dr. Anne  \nDwertmann\n1 Fischer , Lars (2017): Die 5 wichtigsten Fragen zu CRISPR/Cas9. In: Spektrum, 24.3.2017. www.spektrum.de/wissen/wie-funktiOniert-crispr-\n cas9/1441060 [Zugriff am 28.3.2018].\n2 Broad Institute (o . J.): CRISPR Timeline. www.broadinstitute.org/what-broad/areas-focus/project-spotlight/crispr-timeline [Zugriff am 28.3.2018].\n3 Genetic Liter acy Project (o. J.): How are governments regulating CRISPR and New Breeding Technologies (NBTs)? \n https://gmo\n.geneticliteracyproject.org/FAQ/how-are-governments-regulating-crispr-and-new-breeding-technologies-nbts/ [Zugriff am 29.3.2018].\n4 Scott,  Andrew (2018): How CRISPR is transforming drug discovery. Gene editing is quietly revolutionizing the search for new drugs. In: \n Nature 555,\n S10-S11.\n5 W ade, Nicholas (2010): A Decade Later, Genetic Map Yields Few New Cures. In: New York Times, 12.6.2010. \n www\n.nytimes.com/2010/06/13/health/research/13genome.html [Zugriff am 28.3.2018].\n6 Der Neolamarckismus geht auf den fr anz\u00f6sischen Biologen Jean-Baptiste de Lamarck (1744-1829) zur\u00fcck, der unter anderem annahm, dass \n Organismen sich im Laufe ihres Lebens an die Bedingungen ihrer Umwelt anpassen und diese \nAnpassungen dann an ihre Nachkommen\n vererben.\n Das popul\u00e4rste, von Lamarck selbst verwendete Beispiel f\u00fcr diese Hypothese ist der Giraffenhals: Lamarck nahm an, dass ein karger\n Lebensr\naum Giraffen dazu gezwungen habe, sich nach hochgelegenen und dadurch f\u00fcr konkurrierende Tiere unerreichbare Bl\u00e4tter zu strecken,\n um an ausreichend Nahrung zu gelangen.\n Auf diese Weise habe sich durch die Streckbewegung zun\u00e4chst der Hals lebender Giraffen verl\u00e4ngert. \n Die \nVerl\u00e4ngerung sei dann durch Fortpflanzung an die Nachkommen weitergegeben worden. Um die Wende vom 19. zum 20. Jahrhundert war \n der Neolamarckismus noch wissenschaftlich gleichbedeutend mit der auf Charles Darwin zur\u00fcckgehenden \nTheorie der Evolution. Erst durch \n Erk\nenntnisse in der Genetik und deren Vereinbarkeit mit der Darwinschen Evolutionstheorie wurde der Neolamarckismus widerlegt und diese \n wissenschaftliche Auseinandersetzung \nentschieden.\n7 Eser , Uta; Kassel, Dieter (2017): Darf der Mensch die Malaria-M\u00fccke ausrotten? Uta Eser im Gespr\u00e4ch mit Dieter Kassel. Deutschlandfunk Kultur.\n \nwww.deutschlandfunkkultur.de/gene-drives-darf-der-mensch-die-malaria-muecke-ausrotten.1008.de.html?dram:article_id=398976 \n [Zugriff am 28.3.2018].\n8 Mit der K eimbahn wird eine Abfolge von Zellen im fr\u00fchen Embryonalstadium ab der befruchteten Eizelle bezeichnet, aus denen die Keimzellen \n (Eizellen bzw\n. Spermien) des erwachsenen Organismus entstehen. Werden die Kennzeichen dieser Zellen ver\u00e4ndert, so sind die Ver\u00e4nderungen \n an die Nachk\nommen vererbbar. Ver\u00e4nderungen in allen anderen, sogenannten somatischen Geweben wirken sich nicht auf nachfolgende \n Gener\nationen aus.\n9 Deutscher Ethikr at (2017): Keimbahneingriffe am menschlichen Embryo: Deutscher Ethikrat fordert globalen politischen Diskurs und internatio-\n nale Regulierung.\n Deutscher Ethikrat. Berlin. www.ethikrat.org/dateien/pdf/empfehlung-keimbahneingriffe-am-menschlichen-embryo.pdf \n [Zugriff am 28.3.2018].\n10 Deutsches \u00c4rzteblatt (2017): Debatte \u00fcber neue Regulierung genom-editierter Pflanzen gefordert. www.aerzteblatt.de/nachrichten/73111/\n Debatte-ueber\n-neue-Regulierung-genom-editierter-Pflanzen-gefordert [Zugriff am 29.3.2018].Was machen wir blo\u00df mit den Sozialen Innovationen? \u00a7  53\nWas machen wir blo\u00df mit den  \nSozialen Innovationen?\nMiriam Kreibich\n\u201cAlthough social innovations pop up in many \nareas and policies and in many disguises, and social innovation is researched from a number of theoretical and methodological angles, the conditions under which social innovations de-velop, flourish and sustain and finally lead to societal change are not yet fully understood both in political and academic circles.\u201d\n1   \nLetztens stellte ich mir die Frage, was man wohl in einem Museum f\u00fcr Soziale Innovati-onen ausstellen w\u00fcrde. Was f\u00fcr ein Exponat k\u00f6nnte eine Besucherin oder einen Besucher dort faszinieren? Wohl kaum eine Postkarte des ersten genossenschaftlichen Ladens der \u201eRedlichen Pioniere von Rochdale\u201c. Diese Gruppe von Webern in Nordengland gilt als eine der Begr\u00fcnder der konsumgenossen-schaftlichen Bewegung in der Mitte des 19. Jahrhunderts und gab den Ansto\u00df daf\u00fcr, dass sich innerhalb von nur 20 Jahren beachtliche 600 Konsumgenossenschaften mit 130.000 Mitgliedern und einem Umsatzvolumen von umgerechnet 56 Millionen Reichsmark in Eng-land und Schottland bildeten. Und erst recht nicht w\u00fcrde ein Foto einer gl\u00fccklichen Fami-lie vor einem Fr\u00f6bel-Kindergarten zu Beginn des 20. Jahrhunderts eine eigene Ausstellung rechtfertigen. Beides waren jedoch m\u00e4chtige Soziale Innovationen, die entscheidend zu ge-sellschaftlichem bzw. sozialem Wandel beige-tragen haben.\nObwohl wahrlich nicht neu, werden Soziale \nInnovationen in der Politik erst seit einigen Jahren zunehmend rezipiert. Sie spielen eine entscheidende Rolle in der Millenniums-Agen-da und in den Leitlinien der EU-Programme. Es gibt sogar Forschungseinrichtungen, die \u201eSo-ziale Innovationen\u201c heute in ihrem Namen tra-gen. Obama ma\u00df den Sozialen Innovationen so viel Bedeutung zu, dass er ein eigenes B\u00fcro \u201eOffice for Social Innovation und Civic Parti-cipation\u201c einrichtete, \u201eto create a more out-comes-driven government and social sector\u201c. Letztendlich ging es wohl vor allem darum zu wissen, welche Ma\u00dfnahmen und Methoden sich f\u00fcr die Allgemeinheit als die besten heraus-  \ngestellt haben. Diese wollte man kennen und \u2013  \nnoch besser \u2013 nutzen k\u00f6nnen. \nAuch auf europ\u00e4ischer Ebene besch\u00e4ftigt man \nsich mit Sozialen Innovationen: Im von der Eu-rop\u00e4ischen Kommission gef\u00f6rderten Projekt SI DRIVE (Social Innovation: Driving Force for Social Change)\n2 wurden \u00fcber 1.000 F\u00e4lle von \nSozialen Innovationen empirisch untersucht und neben sieben Hauptanwendungsfeldern\n3 \nauch die Akteure ins Visier genommen. Die Autoren zeigen, dass die bisherige Annahme, Soziale Innovationen entst\u00fcnden ausschlie\u00df-lich in der Zivilgesellschaft zur \u00dcberwindung von Marktversagen, so nicht haltbar ist. Eine Fokussierung auf diese Akteursgruppe sei deutlich zu kurz gegriffen, da Soziale Innova-tionen nicht nur in der Zivilgesellschaft, son-dern auch und vermehrt in der Wirtschaft, Politik und Wissenschaft entstehen. In einem anderen EU-gef\u00f6rderten Forschungsprojekt \u2013 transit (transformative social innovation theo-ry \u2013 wurden 20 transnationale Netzwerke in Europa und Lateinamerika untersucht.\n4 Dar-\nunter u. a. Ashoka, DESIS-network, FABLABS, Participatory Budgeting, Slow Food, Impact Hub und Transition Towns, um diesen \u201edy-namischen und komplexen Ph\u00e4nomen\u201c eine \n40 Jahre54 \nTheorie zugrunde legen zu k\u00f6nnen. Auch in \nDeutschland \u00e4u\u00dferte man sich zu dem Thema: Die Expertenkommission Forschung und Inno-vation (EFI) hat in ihrem Jahresgutachten 2017 auf die Bedeutung Sozialer Innovationen als Innovationstreiber f\u00fcr unsere Gesellschaft hin-gewiesen und gefordert, der bereits bestehen-den Erweiterung des Innovationsbegriffs auch konkrete Aktionen folgen zu lassen.\nDas Feld der Sozialen Innovationen ist breit \u2013 \neigentlich gibt es kein Feld ohne Soziale Inno-vationen, zumindest f\u00e4llt mir auf Anhieb keins ein ...\nSozialen Innovationen wird eine immer gr\u00f6-\n\u00dfere Rolle bei der L\u00f6sung gesellschaftlicher Herausforderungen zugesprochen. Trotzdem  \nwerden sie immer ein bisschen wie die \u201eSchmuddelkinder\u201c der Innovationen behan-delt. Man wei\u00df eigentlich nicht so richtig, was man damit anfangen und wie man sie bewer -\nten soll und erst recht nicht, ob und wie man sie f\u00f6rdern soll. Klar ist nur: Es gibt sehr viele und es werden \u2013 gef\u00fchlt, aber wohl auch fak-tisch \u2013 immer mehr. Doch die Unsicherheit im Umgang mit Sozialen Innovationen zeigt sich auch daran, dass sich aufgrund fehlender um-fassender Konzepte bisher kein eigenes Feld der Innovationspolitik zu Sozialen Innovatio-nen etablieren konnte. \nNehmen wir zum Beispiel den Bereich Bildung: \nDie Digitalisierung erm\u00f6glicht erstmalig eine allgemeine, freie und barrierearme Nutzung von Bildungsangeboten \u2013 unabh\u00e4ngig von individuellen oder gruppenspezifischen Vor -\naussetzungen (akademisch, finanziell, kulturell etc.). Das f\u00fchrt zu Ver\u00e4nderungen bestehender Lernarrangements, bei Gestaltungsm\u00f6glichkei-ten und Rahmenbedingungen der Wissensge-nerierung und beim Wissenstransfer (MOOCS, Blended Learning). Digitale \u00dcbungskonzepte oder andere innovative Simulationssysteme erm\u00f6glichen eine v\u00f6llig neue ort- und zeitun-abh\u00e4ngige Erstellung und Verbreitung von Bil-dungsinhalten. Dadurch k\u00f6nnen individuelle Bildungs- und Qualifizierungsbedarfe erf\u00fcllt werden \u2013 auch jenseits bestehender klassi-scher Bildungswege, Organisationsstrukturen und Formen der Zusammenarbeit. Mit Hilfe dieser \u201edigitalen Inklusion\u201c lassen sich innova-tive Bildungskonzepte entwickeln und umset-zen sowie neue Formen des Lernens und der Wissensvermittlung generieren. Durch Soziale  \nInnovationen k\u00f6nnen neue und organisations-  \n\u00fcbergreifende Bildungskonzepte das Verh\u00e4ltnis  \nzwischen Angebot und Nachfrage von Bildungs-  \ninhalten verbessern, neue Kooperationsformen  \nauf regionaler, nationaler und internationaler  \nEbene ansto\u00dfen, kulturelle Distanzen reduzieren  \nund Kreativit\u00e4t und Partizipation (auch genera-  \ntionen\u00fcbergreifend) f\u00f6rdern. Was beispielsweise  \nm\u00f6glich ist, haben uns drei Studentinnen  \nund Studenten mit der Kiron-Universit\u00e4t f\u00fcr  \nFl\u00fcchtende gezeigt. Das 2015 gegr\u00fcndete  \n\u201eSocial-Start-up\u201c entwickelte ein Konzept,  \ndurch das junge Fl\u00fcchtende ihre Studien orts-  \nunabh\u00e4ngig fortf\u00fchren k\u00f6nnen. Unterdessen sind weltweit mehr als 40 Universit\u00e4ten an dem Projekt beteiligt. \nOder nehmen wir den Bereich Energie: Ener -\ngiekooperativen, lokale Energieproduktion, \nRepairing-, Reusing- und Recyclingwerkst\u00e4t-ten oder Genossenschaften zur Schonung von Ressourcen und zur Verbesserung der Kreis-laufwirtschaft etc. bestehen bereits, werden gelebt und erprobt. Das traditionelle Konsu-ment-Erzeuger-Verh\u00e4ltnis steht l\u00e4ngst in Frage. Soziale Innovationen regen urbane Transfor -\nmationsprozesse an und entwickeln innovative Klimastadtkonzepte. Der systemische Charak-ter der Energiewende mit neuen Aufgaben, Dienstleistungen und auch Teilnehmenden bietet ein gro\u00dfes Potenzial f\u00fcr Soziale Innovati-onen. Insbesondere mit Blick auf den Wunsch vieler nach einem positiven Beitrag zur Ener -\ngiewende, nach mehr Lebensqualit\u00e4t und dem effizienten Gebrauch von Ressourcen in Rich-tung \u201eZero-Emission\u201c, nehmen Verbraucherin-nen und Verbraucher eine immer aktivere Rolle ein. Sie wollen mehr Nachhaltigkeit, Transpa-renz und Partizipation entlang der gesamten Wertsch\u00f6pfungskette. Dies erfordert neue und andere Formen der Nutzerintegration \u2013 viel-Was machen wir blo\u00df mit den Sozialen Innovationen? \u00a7  55\nfach ist heute die Sprache von \u201eProsumern\u201c, \nKonnektivit\u00e4t und Konvergenz. Wie hoch die Nachfrage nach alternativen Konzepten ist, zeigt der Erfolg der Energiegenossenschaften: In nur etwas mehr als zehn Jahren stieg laut Statistischem Bundesamt (2116) die Anzahl der Energiegenossenschaften von 66 im Jahr 2001 auf 888  im Jahr 2013.\nDer Bereich Mobilit\u00e4t ist noch stark von tech-\nnologischen L\u00f6sungsans\u00e4tzen wie alternativen  \nAntriebstechniken und der F\u00f6rderung der Elektro-  \nmobilit\u00e4t gepr\u00e4gt. Zudem fehlt an vielen Stellen ein wirksames Zusammenspiel von technolo-gischen M\u00f6glichkeiten und gesellschaftlichen Bedarfen. Aber  auch hier sind Ans\u00e4tze f\u00fcr ein sinnvolles Ineinandergreifen von technischen und sozialen Ma\u00dfnahmen sowie Strategien zur Verbesserung und Verbreiterung von sich ver\u00e4ndernden Mobilit\u00e4tsbedarfen zunehmend gew\u00fcnscht. Klassische Transportsysteme wie der private PKW verlieren besonders bei jun-gen Erwachsenen in den Metropolen massiv an Bedeutung. Mit Carsharing- oder Car-Poo-ling-Modellen, B\u00fcrgerbussen, Radfahrerb\u00fcros oder dem \u201elaufenden Schulbus\u201c, einem Be-gleitservice f\u00fcr Schulanf\u00e4nger, haben bereits Ideen den Schritt zu alternativen Services und Transportsystemen geschafft. Menschen ohne eigenes Auto brauchen nicht bei dem unge-planten Gro\u00dfeinkauf (nach dem Motto: \u201eIch gehe nur mal eben Kerzen holen.\u201c) vor IKEA zu stehen, weil ihnen die Drive-Now oder Car-to-go etc. App anzeigt, dass drei Autos auf dem Parkplatz f\u00fcr den Transport ihrer Waren zur Ver -\nf\u00fcgung stehen.\n\u00dcberhaupt die gesamte Sharing Economy ist \neine gro\u00dfartige Soziale Innovation! Was wird nicht heute alles geteilt? Die Lieblingsmusik, das heimische Sofa, der eigene Garten, die \u00fcb-riggebliebene Lasagne, Zeit, Wissen... Praktisch f\u00fcr alles gibt es \u2013 der Digitalisierung sei Dank! \u2013  \neine Plattform und f\u00fcr vieles zumindest aus-reichend viele Gleichgesinnte, die diese teilen m\u00f6chten, wie auch der Siegeszug von Airbnb gezeigt hat. Definition? Definitiv \nschwer!\nLange wurde in den wissenschaftlichen Krei-\nsen um eine gemeinsame Definition f\u00fcr Soziale  \nInnovationen gerungen, die auch eine Abgren-zung zu den Begriffen \u201enicht-technologische\u201c oder \u201esozio-\u00f6konomische\u201c Innovationen ent-h\u00e4lt. Wenngleich sich auch heute noch nicht alle, die sich wissenschaftlich mit dem Thema Soziale Innovationen besch\u00e4ftigen, gleicherma-\u00dfen mit der von Zapf \u00fcber Grunwald, Howaldt, Schwarz et. al.\n5 entwickelten Definition der \n\u201eNeukonfiguration bestehender sozialer Prak-tiken, die sichtbare gesellschaftliche Ver\u00e4nde-rungen mit sich bringen und Probleme oder Be-d\u00fcrfnisse besser l\u00f6sen bzw. befriedigen als dies auf der Grundlage etablierter Praktiken m\u00f6g-lich ist\u201c, gleicherma\u00dfen anfreunden k\u00f6nnen, so etabliert sie sich doch zunehmend in ihren drei Kernaussagen: Eine bereits bestehende so-ziale Praktik wird ver\u00e4ndert. Die Ver\u00e4nderung wird gesellschaftlich angenommen. Sie wird gesellschaftlich angenommen, weil sie zu ei-nem besseren Ergebnis f\u00fchrt. Das ist ein Ver -\nlauf der Entwicklung, wie er prinzipiell auch bei technologischen Innovationen vorkommt. Doch wie weiter? Soziale Innovationen k\u00f6nnen subs-titutiv sowie komplement\u00e4r sein. Sie entstehen \u00fcberwiegend aus gesellschaftlichen oder auch pers\u00f6nlichen Bedarfen und werden durch Indi-viduen oder Gruppen getrieben bzw. beziehen diese in die Entwicklung ihrer Innovation ein. Sie sind gekennzeichnet von einer systemischen Betrachtungsweise und stehen h\u00e4ufig quer zu gewachsenen Strukturen. Sie ver\u00e4ndern die He-rangehensweise der Menschen an Probleme, beziehen andere Akteure anders ein und ent-wickeln bedarfsgerechte Dienstleistungen. Sie k\u00f6nnen bestehende Pfadabh\u00e4ngigkeiten auf-l\u00f6sen und damit neue und andere Gesch\u00e4fts-modelle generieren. Nichts sagt die Definition jedoch dar\u00fcber aus, ob es sich hier nur um Non-Profit-Innovationen handelt oder ob diese nur im sozialen Bereich ihren Innovationshumus finden. Auch nicht, ob die neue soziale Praktik 56 \nm\u00f6glicherweise nicht-beabsichtigte Ergebnis-\nse zutage f\u00f6rdert oder zu Kollateralsch\u00e4den in anderen Bereichen f\u00fchren k\u00f6nnte \u2013 oder gar ein gesellschaftlicher Irrweg ist! Wenn man sich Uber und Facebook ansieht, so kann man durchaus hinterfragen, ob diese Sozialen Inno-vationen rundum w\u00fcnschenswert sind.\nAber nicht nur die Produkte und Prozesse \u00e4ndern \nsich, sondern auch der Blick auf die potenziellen Kunden. Bei der Entwicklung von Sozialen  \nInnovationen sind Industrie und Wissenschaft h\u00e4ufig nur noch \u201eMitwirkende\u201c, im \u00e4u\u00dfers-ten Falle auch nur noch Zaung\u00e4ste, um sie zu  \nbegleiten und zu unterst\u00fctzen. Transformations-  \nwissen ist gefragt, um die komplexen, systemi-schen Prozesse gestalten zu k\u00f6nnen. Das geht nicht ohne die Konsumenten. \u201ePraxisakteure\u201c werden immer st\u00e4rker in ehemals ausschlie\u00dflich  \nwissenschaftliche oder wirtschaftliche Prozesse der Problemfindung und Ergebniserzielung  \neingebunden bzw. \u00fcbernehmen sogar die bestimmende Rolle. Nutzerinnen und Nutzer  \nemanzipieren sich und \u00fcbernehmen mit  \n\u201eDaumen hoch oder runter\u201c Entscheidungen  \nf\u00fcr sich selbst oder f\u00fcr allgemeines gesell-  \nschaftliches Handeln.\nDieser \u201evertical change\u201c verdr\u00e4ngt Alther -\ngebrachtes und f\u00f6rdert auch auf der sozialen \nEbene einen Paradigmenwechsel. Dies betrifft vor allem unsere Arbeits- und Kommunikati-onsformen. Er betrifft aber auch Organisations-strukturen in Institutionen, der Verwaltung und Bildungs- und Gesundheitssystem. Sektoren  \n(z. B. Lebens-, Arbeits- und Wohnumfelder), die bisher getrennt waren, \u201everdichten\u201c sich und wachsen zusammen. Diese Konvergenz entwi-ckelt ihrerseits neue Produkte und Dienstleis-tungen oder Gesch\u00e4ftsmodelle. Doch was fangen wir jetzt \ndamit an? \nWelchen Stellenwert billigen wir Sozialen In-\nnovationen zu \u2013 in unserem noch immer stark technologisch gepr\u00e4gten Innovationsverst\u00e4nd-nis? Wie bewerten wir sie\n6? Wie sollen wir sie \nf\u00f6rdern? Sollen wir \u00fcberhaupt? Taugen sie gar wie \u201eFortschritt\u201c und \u201eNachhaltigkeit\u201c als neu-es gesellschaftliches Leitbild, wie Reinhard Hof-bauer vom Zentrum f\u00fcr Zukunftsstudien der FH Salzburg in seinem Aufsatz: \u201eSoziale Innovatio-nen als Leitbild f\u00fcr Soziale Entwicklung fragt?\n7  \nUnd wo Licht ist, ist auch Schatten. Auch das hat sich in den Diskussionen um Airbnb und Uber gezeigt. Die Forderung nach einer \u201eFol-genabsch\u00e4tzung Sozialer Innovationen\u201c wird daher zu Recht von einigen Forschungseinrich-tungen angemahnt. \nNur eins scheint sicher: F\u00fcr die Gestaltung \nund Beantwortung gesellschaftlicher Heraus-forderungen werden in allen Zukunftsfeldern gesellschaftlich gew\u00fcnschte und induzierte Innovationen ben\u00f6tigt. Diese lassen sich nicht nur durch technische Innovationen abdecken, sie brauchen auch gesellschaftliche Ver\u00e4nde-rungsprozesse. Soziale Innovationen waren und werden immer wichtige Treiber f\u00fcr den gesell-schaftlichen Wandel sein.\nIm neu erschienenen \u201eAtlas of Social Innovation \u2013  \nNew Practices for a better Future\u201c hat die  \nSozialforschungsstelle (sfs)\n8 der TU Dortmund \nBeispiele f\u00fcr Soziale Innovationen auf der  \nganzen Welt und aus unterschiedlichen Politik- \nfeldern zusammengestellt. Die Publikation zeigt,  \nwie die Gesellschaft Sozialen Innovationen  \nnutzen kann, um neue Praktiken f\u00fcr eine  \nbessere Zukunft langfristig zu etablieren.Was machen wir blo\u00df mit den Sozialen Innovationen? \u00a7  57\n1 Jenson,  Jane/ Harrisson, Denis (2013): Social innovation research in the European Union: Approaches, findings and future directions., S. 5: \n https://ec.europa.eu/research/social-sciences/pdf/policy_reviews/social_innov\nation.pdf [Zugriff am 7.5.2018]\n2 www.si-drive.eu/ \n3 Bildung und lebenslanges Lernen,  Besch\u00e4ftigung, Energie(versorgung), Klimawandel, Transport und Mobilit\u00e4t, Gesundheit und Soziales, \n Armutsbek\u00e4mpfung und nachhaltige Entwicklung\n4 www.transitsocialinnovation.eu\n5 Vgl . u. a. J\u00fcrgen Howaldt, Michael Schwarz (2010): Soziale Innovation im Fokus. Bielefeld.\n6 Einen Vorschlag unterbreitet eine Studie des Umweltbundesamtes zum Thema \u201eNachhaltiger Konsum durch soziale Innovationen\u201c. In ihr werden die\n Merkmale \u201eInnov\nativit\u00e4t\u201c, \u201eFormalisierung\u201c, \u201eEigeninitiative\u201c und \u201eGemeinschaftlichkeit\u201c der Bewertung Sozialer Innovationen zugrunde gelegt:\n Grad der Innovativit\u00e4t der alternativen Praxis, die \u00fcber das Ausma\u00df der Ver\u00e4nderung der etablierten Praktiken durch alternative Formen \n definiert wird.\n Grad der Formalisierung der alternativen Praxis, die einen Hinweis darauf liefert, wie stabil die Strukturen sind, die durch oder mit der \n alternativen Pr\naxis etabliert und aufrechterhalten werden.\n Grad der Eigeninitiative, der beschreibt, wie viel eigene Initiative notwendig ist, um die innovativen Alternativen zu initiieren und zu praktizieren.\n Grad der Gemeinschaftlichkeit, der sich darauf bezieht, ob zur Umsetzung der innovativen Idee Gemeinschaften gebildet werden m\u00fcssen und \n wie stark die Gemeinschaftlichk\neit der Beteiligten untereinander ist. \n7 Reinhard Hofbauer (2017).  www.zeitschrift-zukunftsforschung.de/ausgaben/2016/ausgabe1/4484 [Zugriff am 7.5.2018].\n8 www .socialinnovationatlas.net [Zugriff am 7.5.2018].Prof. Dr. Howaldt ist Direktor der Sozialforschungs-  \nstelle an der TU Dortmund und Autor mehrerer \nB\u00fccher zum Thema Soziale Innovationen: \nWeltweit erproben Soziale Innovatoren neue \nStrategien, um komplexen Herausforderungen wie dem Klimawandel, dem demografischen Wandel oder sozialer Ungleichheit zu begeg-nen. Soziale Innovationen, das sind kreative und zielgerichtete soziale Praktiken, die dazu beitragen, neue L\u00f6sungen f\u00fcr gesellschaftliche Probleme zu entwickeln. Sie ver\u00e4ndern die Art wie wir leben, arbeiten und konsumieren, wie wir uns organisieren und unsere politischen Prozesse gestalten. Oft lassen sich die Poten-ziale neuer Technologien nur dann entfalten, wenn diese in die Ver\u00e4nderung sozialer Prakti-ken eingebettet sind.\nAllerdings fehlen zurzeit in den meisten L\u00e4n-\ndern noch unterst\u00fctzende Infrastrukturen, wie sie im Bereich der Technologief\u00f6rderung erfolgreich entwickelt wurden, ebenso wie eine auf die F\u00f6rderung sozialer Innovationen ausgerichtete Innovationspolitik. Auch sind Universit\u00e4ten und Forschungsinstitute bisher nicht systematisch in die Entwicklung Sozialer Innovationen eingebunden. In der verst\u00e4rkten Einbindung des Themas in Forschung und Poli-tik liegt eine wichtige Herausforderung f\u00fcr die Zukunft. \n58 \nTransformation der Energieversorgung \u2013 \ndie Energiewende funktioniert nur digital\nDr. Stefan Wolf  Dr. Markus Gaa\u00df  Roman Korzynietz\nDie disruptive Kraft der Digitalisierung hat nicht \nnur die globale Kommunikation und die welt-weiten Logistikabl\u00e4ufe ver\u00e4ndert, sie wird auch zum bestimmenden Element der n\u00e4chsten Phase der Energiewende. Um die anstehende Transformation des deutschen Energiesystems in ihrer Dimension zu verdeutlichen, werden in diesem Beitrag das bisher erreichte, das aktuell geplante und das zuk\u00fcnftig m\u00f6gliche beschrie-ben und die zu l\u00f6senden Herausforderungen f\u00fcr Wissenschaft, Wirtschaft und Politik be-nannt.\nAusgel\u00f6st wurde die Energiewende durch eine \nReihe einschneidender Ereignisse. Eine \u00dcber -sicht dieser \u201eGame Changer\u201c findet sich in Abbildung 1. Die \u00d6lpreiskrisen der Jahre 1973 und 1979 sowie die Reaktorkatastrophen in Tschernobyl im Jahr 1986 und in Fukushima im Jahr 2011 befeuerten die Erforschung er -\nneuerbarer Energien und die Entwicklung von Effizienztechnologien. Der Beginn der Energie-wende war vor allem motiviert durch die nega-tiven Umweltauswirkungen und die begrenzte Verf\u00fcgbarkeit fossiler Ressourcen. Hinzu kamen unmittelbare gesundheitliche Auswirkungen durch Schadstoffbelastungen, die nicht zuletzt durch den aktuellen Abgasskandal der Auto-mobilindustrie einer breiten \u00d6ffentlichkeit ins Bewusstsein gerufen wurden. \n40 Jahre\nGame Changer\nPolitik EreignisseWirtschaft  \nund Technik1970 1990 2010 2030 2050\n  erste \u00d6lpreiskrise   Reaktorkatastrophe Fukushima\n  zweite \u00d6lpreiskrise   Abgasskandal\n  Reaktorkatastrophe Tschernobyl\n  Kyoto-Protokoll\n  Stromeinspeisungsgesetz\n  Erneuerbare-Energien-Gesetz\n  Energieeinsparverordnung\n  Atomausstieg\n  Europ\u00e4ischer Emissionshandel\n  Energiekonzept\n  Elektrizit\u00e4tsmarktliberalisierung\n  Gasmarktliberalisierung\n  Tesla Roadster   erster Windpark\n  erstes Photovoltaikkraftwerk\n  erstes Passivhaus   Offshore Windpark ohne F\u00f6rderung  Photovoltaik erreicht Netzparit\u00e4t  \u00dcbereinkommen von Paris\nAbb. 1: Game Changer der EnergiewendeTransformation der Energieversorgung \u00a7  59\nZudem reift zunehmend die Erkenntnis, dass die \nMenschheit mit ihrem Wirken einen globalen Klimawandel ausgel\u00f6st hat.\n1 Ohne wirksame \nGegenma\u00dfnahmen wird allein im Verlauf des 21. Jahrhunderts ein globaler Temperaturan-stieg von 4,8 \u00b0C erwartet.\n2 Das entspricht un-\ngef\u00e4hr der Erw\u00e4rmung seit dem H\u00f6hepunkt der letzten Eiszeit vor 22.000 Jahren. Zu dieser Zeit war Berlin vergletschert und der Meeresspiegel lag 120 Meter unter dem heutigen Niveau.\n3 Von \neinem weiteren Meeresspiegelanstieg w\u00e4re das Leben von mehr als 600 Millionen Menschen unmittelbar bedroht.\n4 Hinzu k\u00e4men die gravie-\nrenden Auswirkungen weiterer Ver\u00e4nderungen wie D\u00fcrren und Extremwetterereignisse. Diese Prognosen verdeutlichen die extremen Folgen des Klimawandels. Um diesem entgegenzuwir -\nken, ist weltweit eine drastische Reduktion von Treibhausgasemissionen und damit eine Abkehr von der fossilen Energieversorgung aus Kohle, \u00d6l und Gas unabdingbar.\nDiese globale Herausforderung verlangt nach \neinem international koordinierten Vorgehen. Seit der ersten Weltklimakonferenz im Jahr 1995 moderieren die Vereinten Nationen den politischen Abstimmungsprozess zum Schutz des Weltklimas. Im Kyoto-Protokoll von 1997 wurden erstmalig v\u00f6lkerrechtlich verbindliche Klimaziele vereinbart. Mit dem \u00dcbereinkom-men von Paris aus dem Jahr 2015 hat sich die Weltgemeinschaft auf das Ziel geeinigt, den globalen Temperaturanstieg auf deutlich unter 2 \u00b0C zu begrenzen. Die internationalen Verein-barungen zum Klimaschutz haben die jeweili-gen Bundesregierungen in Deutschland 2007 mit den Meseberger Beschl\u00fcssen, 2010 mit dem Energiekonzept sowie 2016 mit dem Kli-maschutzplan 2050 in einen nationalen Zielkor -\nridor \u00fcberf\u00fchrt. Demnach sollen bis zum Jahr 2050 die Treibhausgasemissionen in Deutsch-land um mindestens 80 bis 95 Prozent im Ver -\ngleich zum Referenzjahr 1990 gesenkt werden. Die entscheidenden Werkzeuge, um dieses Ziel zu erreichen, sind einerseits der effizientere Ein-satz von Energie und andererseits die Deckung des verbleibenden Energiebedarfs aus erneuer -\nbaren Quellen. Zur zentralen Herausforderung dieser Energiewende werden das Management der zunehmend dezentral erzeugten Energie sowie des fluktuierenden Energieangebots. Die notwendigen Ma\u00dfnahmen zur Bew\u00e4ltigung dieser Herausforderung lassen sich in drei Pha-sen gliedern. Diese Phasen dienen zugleich als strukturierendes Element f\u00fcr die nachfolgende Betrachtung der Energiewende.\nDie niedrig h\u00e4ngenden \nFr\u00fcchte sind gepfl\u00fcckt \u2013 Phase 1\nSeit dem Beginn der Energiewende in den \n1980er Jahren haben sich die erneuerbaren Energien von Nischentechnologien zu ausge-reiften Basistechnologien entwickelt. Antrieb f\u00fcr diesen technologischen Fortschritt war nicht zuletzt das Gesetz f\u00fcr den Ausbau er -\nneuerbarer Energien (EEG), das im Jahr 2000 in Deutschland in Kraft trat. Das Gesetz schuf wirtschaftliche Planungssicherheit f\u00fcr Inves-toren und setzte somit den Startpunkt f\u00fcr die Kommerzialisierung der Energiewende. Unter -\nst\u00fctzt wurde dieser Prozess durch den Start des europ\u00e4ischen Emissionshandels im Jahr 2005. Dieser gibt f\u00fcr die Stromerzeugung und die energieintensive Industrie einen Pfad mit einer j\u00e4hrlichen Verknappung der erlaubten CO\n2-Emissionen vor. Derzeit sind die Preise \nzum Erwerb von Emissionsrechten allerdings so gering, dass der Emissionshandel kaum Steuerungswirkung entfaltet. Aufgrund der Krise der s\u00fcdeurop\u00e4ischen Wirtschaft hat sich ein \u00dcberschuss an ungenutzten Emissionsrech-ten aufgebaut, der auf die Preise dr\u00fcckt. Es be-st\u00fcnde also die M\u00f6glichkeit, diese Situation zu nutzen und durch eine Tilgung \u00fcbersch\u00fcssiger Emissionsrechte die Geschwindigkeit der Ener -\ngiewende zu erh\u00f6hen. Zudem k\u00f6nnten h\u00f6here Preise f\u00fcr Emissionsrechte die Wettbewerbsf\u00e4-higkeit der erneuerbaren Energien weiter ver -\nbessern.60 \nMit der Nutzung der Windenergie zur Strom- \nerzeugung wird bereits seit Ende des 19. Jahr -\nhunderts experimentiert. Die ersten Windparks wurden 1980 in den USA und 1987 in Deutsch-land in Betrieb genommen. In dieser Zeit erlebte die Windenergie einen Technologiesprung  \ndurch die Entwicklung gro\u00dfer Windturbinen in D\u00e4nemark und Deutschland, die mehrere  \nMegawatt Leistung erreichten. Heute werden in Deutschland fast 30.000 Windkraftanlagen mit einer Gesamtleistung von circa 56 Gigawatt  \nbetrieben.\n5 Mit der weiterhin zunehmenden \nVerbreitung sinken die Kosten der Windenergie, so dass im Jahr 2017 erstmals Offshore-Windparks  \nohne staatliche F\u00f6rderung in Planung gingen.\nDie Photovoltaik wurde zu Beginn ihrer Ent-\nwicklung fast ausschlie\u00dflich in der Raumfahrt \ngenutzt. Ab Mitte der 1970er Jahre kamen Anwendungen an entlegenen Orten ohne ei-gene Stromversorgung, etwa in Signalanlagen auf \u00d6lbohrinseln oder im Telekommunikations-netz im australischen Outback, hinzu. Die erste gro\u00dftechnische Nutzung der Photovoltaik er -folgte mit der Inbetriebnahme eines Photovol-taikkraftwerks mit einem Megawatt Spitzenleis-tung in den USA im Jahr 1982. Seitdem wurde die Technologie erheblich weiterentwickelt, so dass die Kosten der Photovoltaik bis heute um 96 Prozent gesunken sind. In Deutschland wur -\nde 2012 die Netzparit\u00e4t erreicht. Seither kann Strom g\u00fcnstiger von einer Photovoltaikanlage erzeugt, als aus dem Netz bezogen werden. Dieser technische Fortschritt wurde zu wesent-lichen Anteilen durch die deutschen Aktivit\u00e4ten zur Stimulation der Photovoltaiknachfrage  (z. B. EEG-Einspeisetarife oder das 100.000 D\u00e4cher- Programm) erreicht.\nAuch die Erforschung und Nutzung der Bio-  \nenergie wurde von Politik und Wirtschaft vor -\nangetrieben. F\u00fcr die Geb\u00e4udebeheizung wurden \nBiomassekessel entwickelt und durch das Markt-anreizprogramm (MAP) gef\u00f6rdert. In Biogasanla-gen werden methanbildende Bakterien genutzt, um aus biogenen Abf\u00e4llen und landwirtschaftli-chen Erzeugnissen Biogas zu erzeugen. Das Bio-gas wird verstromt oder aufbereitet in das Gas-Abb. 2: Phasen der Energiewende  \nQuelle: Eigene Darstellung in Anlehnung an acatech (2017): Sektorkopplung \u2013 Optionen f\u00fcr die n\u00e4chste  Phase der Energiewende. Hg. v. acatech \u2013 Deutsche Akademie der Technikwissenschaften e. V . M\u00fcnchen1990 2010 2030 2050\n1 Basistechnologien:  -25 % CO 2\n- Entwicklung erneuerbarer Energien\n- Ausbau erneuerbarer Energien\n- Entwicklung von Effizienztechnologien\n- Entwicklung des Zielkorridors\n2 Systemintegration:  -55 % CO 2\n- Stromnetzausbau\n- Ausbau von Kurzzeitspeichern\n- Sektorenkopplung\n- Digitalisierung und Flexibilisierung\n- Ausbau der Elektromobilit\u00e4t\n- neues Strommarktdesign\n3 Speicherung:  -85 bis -95 % CO 2\n- Ausbau von Langzeitspeichern\n- Gro\u00dfskalige Elektrolyse\n- \n Synthetische Brennstof\nfe  \nf\u00fcr Industrie und Verkehr\n- st\u00e4rkere internationale V\nernetzung\nErneuerbare EnergienFossile EnergienPhasen der EnergiewendeTransformation der Energieversorgung \u00a7  61\nnetz eingespeist. Daf\u00fcr erh\u00e4lt der Betreiber eine \nVerg\u00fctung nach dem EEG. F\u00fcr den Verkehrssek-tor werden biogene Kraftstoffe wie Methanol oder Biodiesel hergestellt. Nach einem starken Anstieg der Bioenergienutzung in den 2000er Jahren stagniert der Ausbau aufgrund einer Debatte um die Nutzungskonkurrenz zwischen Energieerzeugung und Nahrungsmittelversor -\ngung. Neue Verfahren, wie die Kultivierung von Algen und die Nutzung von Pflanzenresten, sind bisher technisch aufw\u00e4ndig und wirtschaftlich nicht konkurrenzf\u00e4hig.\nEin weiteres wesentliches Element der Energie-\nwende ist die Steigerung der Energieeffizienz. Seit Mitte der 1970er Jahre ist eine zunehmen-de Entkopplung des Wirtschaftswachstums vom Energieverbrauch zu beobachten.\n6 Durch \ntechnische Entwicklungen und regulatorische Vorgaben wie die Energieeinsparverordnung (EnEV) wurde der W\u00e4rmebedarf neuer Geb\u00e4u-de seither um 90 Prozent reduziert. Mit dem Passivhaus wurde 1990 ein Geb\u00e4udekonzept vorgestellt, das vollst\u00e4ndig ohne klassische Hei-zungsanlage auskommt. Die Sanierungsquote der Bestandsgeb\u00e4ude verharrt allerdings auf niedrigem Niveau\n7, sodass der Anteil effizienter \nGeb\u00e4ude nur langsam steigt. In der Industrie sind hingegen signifikante Fortschritte in der Steigerung der Energieeffizienz zu verzeichnen. Hier wird dank Prozessoptimierung f\u00fcr die glei-che Wertsch\u00f6pfung heute 33 Prozent weniger Energie ben\u00f6tigt als noch 1990.\n8 Diese Effizi-\nenzsteigerung wird jedoch weitgehend vom Ausbau der Produktionskapazit\u00e4t kompensiert.  \nIm Verkehrssektor wurden bisher keine sig-\nnifikanten Erfolge in der Reduktion von Ener -\ngieverbrauch und Treibhausgasemissionen er -\nzielt. Allerdings hat sich unter anderem durch \ndie Aktivit\u00e4ten von Tesla die Wahrnehmung der Elektromobilit\u00e4t gewandelt. In der Folge gewann die Entwicklung elektrischer Fahrzeu-ge erheblich an Dynamik. Weiter beschleunigt wird diese Entwicklung durch den Abgas- skandal, ausgel\u00f6st durch die Manipulationen verschiedener Autohersteller zur Umgehung gesetzlicher Vorgaben. Zudem sehen sich Kom-munen verst\u00e4rkt mit Verfahren aufgrund von EU-Grenzwertverletzungen gesundheitssch\u00e4d-licher, \u00fcberwiegend verkehrsbedingter Emissi-onen konfrontiert. Gro\u00dfe Erwartungen werden in den Markthochlauf der Elektromobilit\u00e4t ge-setzt, denn Elektrofahrzeuge k\u00f6nnen mit Strom aus erneuerbaren Energien betrieben werden und ben\u00f6tigen bei gleicher Fahrleistung rund 70 Prozent weniger Energie als Fahrzeuge mit Verbrennungsmotor.\n9\nDie Entwicklung der Basistechnologien wird begleitet von der Erarbeitung des politischen Zielkorridors und der Anpassung der politi-schen Rahmenbedingungen. So hat die Bun-desregierung im Jahr 2002 den Atomausstieg beschlossen. Eine zwischenzeitliche Verl\u00e4nge-rung der Kraftwerkslaufzeiten wurde nach der Reaktorkatastrophe in Fukushima im Jahr 2011 wieder zur\u00fcckgezogen. Mit der Liberalisierung der Energiem\u00e4rkte wurden Erzeugung und Netze organisch und institutionell getrennt, so dass alle Energieerzeuger einen diskriminie-rungsfreien Netzzugang erhalten. Die Trennung sorgt daf\u00fcr, dass alle Erzeugungsanlagen ihre Leistung gleichberechtigt am Markt anbieten k\u00f6nnen.\nZudem hat die Bundesregierung mit dem Ener -\ngiekonzept von 2010 die Ziele der Energie-\nwende bis zum Jahr 2050 definiert. Durch den Klimaschutzplan 2050 wurde das \u00dcbereinkom-men von Paris in diese Ziele aufgenommen und in Treibhausgasemissionsziele f\u00fcr die einzelnen Wirtschaftssektoren \u00fcbersetzt. \nIn dieser ersten Phase der Energiewende wur -\nde viel erreicht. Die erneuerbaren Energien \nk\u00f6nnen sich bereits in einigen Marktsegmen-ten ohne F\u00f6rderung gegen fossile Energieer -\nzeugungstechnologien durchsetzen. Mehr als ein Drittel des Stroms stammt in Deutschland aus erneuerbaren Energien.\n10 Damit ist eine \nAusbaustufe erreicht, in der sich die wetter -\nabh\u00e4ngigen Schwankungen von Wind- und Solarstrom sp\u00fcrbar auf den Betrieb der Strom-netze auswirken. Dar\u00fcber hinaus konnte auch die Energieeffizienz gesteigert werden. Die 62 \nhierf\u00fcr notwendigen Technologien sind ver -\nf\u00fcgbar und werden durch Marktanreizpro-\ngramme in die Anwendung gebracht. Den-noch gen\u00fcgen die bisherigen Anstrengungen nicht, um dem Klimawandel mit der gebo-tenen Geschwindigkeit entgegenzuwirken. Das Klimaschutzziel f\u00fcr das Jahr 2020 wird voraussichtlich verfehlt. Um das n\u00e4chste Ziel im Jahr 2030 zu erreichen, muss Deutschland die Geschwindigkeit bei der Umsetzung \nder Energiewende verdoppeln. Daf\u00fcr sind erhebliche forschungs- und industriepolitische Anstrengungen notwendig. \nDie Digitalisierung f\u00fchrt \ndie Energiewende auf den Erfolgspfad \u2013  Phase 2\nDer Ausbau erneuerbarer Energien schreitet \nweiter voran. In der zweiten Phase der Ener -\ngiewende m\u00fcssen die Anfangserfolge bei der Transformation der Stromversorgung auf den Mobilit\u00e4tssektor, die Gas- und die W\u00e4rmever -\nsorgung \u00fcbertragen werden. Gleichzeitig wir -\nken sich die wetterabh\u00e4ngigen Schwankungen der Wind- und Solarenergie immer st\u00e4rker auf den Betrieb der Stromnetze aus. Damit steht die Energieversorgung vor einem Paradigmen-wechsel. Bisher wurde Strom immer genau dann erzeugt, wenn er ben\u00f6tigt wurde. K\u00fcnf-tig m\u00fcssen Ma\u00dfnahmen ergriffen werden, mit denen sich der Stromverbrauch und die Verf\u00fcg-barkeit erneuerbarer Energien st\u00e4rker vonein-ander entkoppeln lassen. \nDazu muss der Energieaustausch zwischen \nden verschiedenen Sektoren des Energiesys-tems intensiviert werden. Diese auch als Sek-torenkopplung bezeichnete Integration des Energiesystems bietet mehrere Vorteile. Zum ei-nen kann erneuerbarer Strom zur Verdr\u00e4ngung fossiler Energietr\u00e4ger genutzt werden und zum anderen f\u00fchrt die sektor\u00fcbergreifende Ver -\nwendung von Speichern zu einer optimierten Ausnutzung vorhandener Infrastrukturen. Die energetischen Kopplungs- und Speicherm\u00f6g-lichkeiten im Energiesystem sind in Abb. 3 gra-fisch aufbereitet.\nIm W\u00e4rmesektor kann Strom in Direkthei-\nzungen oder mittels W\u00e4rmepumpen in W\u00e4rme \ngewandelt werden. Anlagen zur Kraft-W\u00e4r -\nme-Kopplung (KWK) wandeln chemisch gebun-dene Energie wie Gas, \u00d6l etc. in W\u00e4rme und Strom. W\u00e4rmespeicher k\u00f6nnen zum netzdienli-chen Betrieb dieser Anlagen eingesetzt werden. Optionen f\u00fcr die Kopplung von Strom- und W\u00e4r -\nmesektor im Stadtbereich sind die lokale Optimie-rung des Energieaustauschs in Quartieren und die Einbindung von Power-to-Heat-Technologien in W\u00e4rmenetze. Ferner eignen sich W\u00e4rmenetze in besonderer Weise, um die W\u00e4rmeversorgung von dicht bebauten und mit historischer Bausub-stanz ausgestatteten Innenstadtbereichen zu de-karbonisieren, also in Richtung eines niedrigeren Umsatzes von Kohlenstoff umzustellen. In der Industrie k\u00f6nnen zudem Abw\u00e4rmestr\u00f6me effizi-enter genutzt werden.\nIm Gassektor k\u00f6nnen Power-to-Gas-Anlagen \nmit Hilfe der Elektrolyse Wasserstoff erzeugen. \nDieser kann entweder direkt genutzt oder zur Erzeugung synthetischer Kohlenwasserstoffe verwendet werden. Weiterhin k\u00f6nnen die er -\nheblichen Speicherkapazit\u00e4ten des Gasnetzes genutzt werden. Wasserstoff und synthetisch erzeugte Kohlenwasserstoffe k\u00f6nnen stofflich oder energetisch in der Industrie sowie ener -\ngetisch im Verkehrssektor und der Stromer -\nzeugung eingesetzt werden. Aufgrund der vergleichsweise geringen Effizienz der Energie-wandlungskette wird die Integration des Gas-sektors in gro\u00dfem Ma\u00dfstab erst dann erfolgen, wenn die \u00fcbrigen Kopplungsoptionen ausge-sch\u00f6pft sind. \nIm Verkehrssektor kann regenerativer Strom \nentweder direkt in Elektrofahrzeugen oder indi-\nrekt als Wasserstoff in Brennstoffzellenfahrzeu-gen sowie als Synthesegas oder Synthesekraft-Transformation der Energieversorgung \u00a7  63\nAbb. 3: Technologieoptionen und Energiefl\u00fcsse in der Sektorenkopplung \nQuelle: Eigene Darstellung in Anlehnung an Sterner, Michael; Thema, Martin; Eckert, Fabian; Moser, Albert; Sch\u00e4fer, Andreas; Drees,  \nTim et al. (2014): Stromspeicher in der Energiewende. Untersuchung zum Bedarf an neuen Stromspeichern in Deutschland f\u00fcr den Erzeugungsausgleich, Systemdienstleistungen und im Verteilnetz. Hg. v. Agora Energiewende. Berlin\nstoff in Verbrennungsmotorfahrzeugen genutzt \nwerden. Aus Effizienzgr\u00fcnden empfiehlt sich die direkte Stromnutzung \u00fcberall dort, wo die vergleichsweise geringen Energiedichten von Batterien akzeptiert werden k\u00f6nnen. Dar\u00fcber hinaus k\u00f6nnen die Batteriespeicher von Elektro- fahrzeugen, eine geeignete Ausstattung und Ladeinfrastruktur vorausgesetzt, zur Stabilisie-rung der Stromnetze eingesetzt werden. \nDamit die Kopplung der Energiesektoren eine \nstabilisierende Wirkung auf das Gesamtsystem entfalten kann, m\u00fcssen die Energiefl\u00fcsse intelli-gent gesteuert werden. Das stellt insbesondere die Betreiber von Verteilnetzen vor gro\u00dfe Her -\nausforderungen. An diese unterste Netzebene werden in Zukunft immer h\u00e4ufiger sowohl klei-ne Erzeugungsanlagen wie Blockheizkraftwer -ke oder Photovoltaikanlagen als auch Ladesta-tionen f\u00fcr Elektrofahrzeuge angeschlossen. Dadurch ergeben sich v\u00f6llig ver\u00e4nderte Anfor -\nderungen an die Netze. Bisher gibt es auf der Verteilnetzebene allerdings kaum M\u00f6glichkei-ten steuernd in die Stromfl\u00fcsse einzugreifen, da aufgrund fehlender Sensorik weder der Zustand des Netzes noch die aktuellen Stromfl\u00fcsse be-kannt sind. \nDie Digitalisierung liefert die notwendigen \nTechnologien und Werkzeuge, um die hohe \nKomplexit\u00e4t des integrierten Energiesystems beherrschbar zu machen. Die Ausstattung der Netze mit Sensorik und der Rollout von Smart Metern liefern Informationen zur Optimierung des Netzbetriebs. Die intelligente Steuerung der einzelnen Energiesystemkomponenten macht Power-to-Heat,  \nflexible KWKPower\n-to-Gas als  \nW\u00e4rmespeicherPower\n-to-Liquid als  \nStromkraftstoff1 4 7\nPower-to-Gas als  \nStromspeicherElektromobilit\u00e4t 3 6Power-to-Gas als \nStromkraftstoffPower-to-Gas als  \nEinspeichertechnologie2 5Stromspeicher\nW\u00e4rmespeicherStromsektor\nGassektor W\u00e4rmesektor\nGasspeicherVerkehrssektorKraftstoffspeicher\n4 57\n6 2 3 164 \ndiese flexibel einsetzbar. So k\u00f6nnen beispiels-\nweise energieintensive Industriebetriebe ihre Produktion in Zeiten verlagern, in denen reich-lich erneuerbarer Strom verf\u00fcgbar ist. Ein wei-teres Beispiel w\u00e4re die gesteuerte Ladung von Elektrofahrzeugen in Abh\u00e4ngigkeit der Netz-auslastung. \nMit diesen Flexibilit\u00e4tsoptionen wird die \nNachfrageseite in den Betrieb des Energiesys-tems integriert. Durch den Ausgleich von Stromnachfrage und -angebot k\u00f6nnen die Netze entlastet und Notma\u00dfnahmen wie Um-verteilung von Lastfl\u00fcssen (Redispatch) und das Abschalten erneuerbarer Erzeugungsanlagen (Einspeisemanagement) vermieden werden. Dazu kommt es vor allem dann, wenn die Prog-nose des wetterabh\u00e4ngigen Angebots erneuer -\nbarer Energien nicht korrekt war, wenn unvor -\nhergesehen ein Kraftwerk ausf\u00e4llt oder wenn kurzfristige Ertragsspitzen in der erneuerbaren Energieerzeugung auftreten. Die Kosten f\u00fcr diese Ma\u00dfnahmen belaufen sich in Deutschland j\u00e4hrlich auf mehrere hundert Millionen Euro.\n11 \nEntsprechend gro\u00df ist der Bedarf an pr\u00e4zisen Prognosen der Energiefl\u00fcsse und an flexiblen Steuerungsm\u00f6glichkeiten. Daf\u00fcr m\u00fcssen die Daten von Sensoren innerhalb des Netzes wie etwa Smart Meter gesammelt und informati-onstechnisch mit weiteren Daten wie beispiels-weise Wetterdaten kombiniert werden. Durch das intelligente Zusammenf\u00fchren von Daten k\u00f6nnen sich v\u00f6llig neue digitale Gesch\u00e4fts-modelle ergeben. Beispiele hierf\u00fcr sind die Nutzung k\u00fcnstlicher Intelligenz zur Erstellung pr\u00e4ziser Energieprognosen oder die Etablierung neuer M\u00e4rkte, auf denen etwa Flexibilit\u00e4tsopti-onen gehandelt werden. \nDiese Smart Markets sammeln Informationen \nzu den verf\u00fcgbaren Flexibilit\u00e4tsoptionen und \ndienen der Preisbildung f\u00fcr die angebotene Flexibilit\u00e4t. In Kombination mit den Netzzu-standsdaten erstellen diese Smart Markets au-tomatisiert eine Angebotshierarchie, die vom Netzbetreiber \u2013 perspektivisch ebenfalls auto-matisiert \u2013 abgerufen werden kann. Damit auch kleine Anlagen an diesem Handel teilnehmen k\u00f6nnen, b\u00fcndeln Aggregatoren viele dieser Anlagen auf Flexibilit\u00e4tsplattformen oder in vir -\ntuellen Kraftwerken und setzen sie gemeinsam am Markt ein. Auch im Handel von Strom er\u00f6ff-net die Digitalisierung neue Wertsch\u00f6pfungs-optionen. So arbeiten zahlreiche Unternehmen daran, einen dezentralen Stromhandel auf Basis der Blockchain-Technologie aufzubauen.\n12 Da-\nmit w\u00e4re es auch f\u00fcr kleine Erzeuger m\u00f6glich, ihren Strom selbst zu vermarkten. In Verbindung mit dem Internet-of-Things (IoT) ist es perspek-tivisch vorstellbar, dass Maschinen automatisiert Energie untereinander handeln. Aufgrund der zunehmenden Dezentralisierung und der stei-genden Komplexit\u00e4t des Energiesystems sind diese automatisierten Prozesse notwendig, um den Systembetrieb zu optimieren und die Kos-ten der Energiewende zu minimieren. Bei allen M\u00f6glichkeiten der Digitalisierung ist allerdings zu beachten, dass es sich beim Energiesystem um eine kritische Infrastruktur handelt, womit hohe Anforderungen an Versorgungsqualit\u00e4t, Sicherheit und Datenschutz einhergehen. Di-gitale Produkte und Gesch\u00e4ftsmodelle m\u00fcssen diesen Anforderungen gerecht werden. \nMit den erneuerbaren Energien ver\u00e4ndert sich \ndie Wertsch\u00f6pfungsstruktur im Energiemarkt v\u00f6llig. W\u00e4hrend die Kosten der fossilen Energie-erzeugung vor allem von den Brennstoffkosten abh\u00e4ngen, so dominieren bei den erneuerbaren Energien die anf\u00e4nglichen Investitionskosten. Die reine Erzeugung erneuerbarer Energien ver -\nursacht kaum zus\u00e4tzliche Kosten. Der Wert der Energie verlagert sich von der Energiebezugs-menge hin zur gesicherten Verf\u00fcgbarkeit. Das gegenw\u00e4rtige Energiemarktdesign ist allein \nauf die Energieerzeugungskosten fokussiert und kann diesen Wandel nicht zufriedenstel-lend abbilden. Ein k\u00fcnftiges Marktdesign muss die Aspekte Versorgungssicherheit und Netz-auslastung im Energiehandel ber\u00fccksichtigen.\nIn Deutschland gilt das Prinzip \u201eNetzoptimie-\nrung vor Netzausbau (NOVA)\u201c als Leitlinie f\u00fcr die Restrukturierung der Netzinfrastruktur. Dennoch werden zus\u00e4tzliche Stromleitungen von den Erzeugungsschwerpunkten erneuer -Transformation der Energieversorgung \u00a7  65\nbarer Energien im Norden des Landes zu den \nindustriell gepr\u00e4gten Verbrauchsschwerpunk-ten im Westen und S\u00fcden ben\u00f6tigt. Daher sieht der Netzentwicklungsplan der Bundes-netzagentur den Neubau von 2.800 Kilome-tern Leitungstrassen und die Verst\u00e4rkung von 2.900 Kilometern bestehender Trassen vor. Mit dem Markthochlauf der Elektromobilit\u00e4t und der weiteren Verbreitung der Photovoltaik wird zudem die Verst\u00e4rkung der Verteilnetze notwendig. Auch wenn mit der Flexibilisierung der Verbraucherseite der Bedarf an zus\u00e4tzlichen Netzkapazit\u00e4ten verringert werden kann, m\u00fcs-sen die Verteilnetze k\u00fcnftig gr\u00f6\u00dfere Strommen-gen transportieren.\nAus diesem Grund muss auch in der zweiten \nPhase der Energiewende die Energieeffizienz weiter vorangetrieben werden. Damit Ener -\ngieeffizienztechnologien Anwendung finden und erneuerbare Energien weiter ausgebaut werden, m\u00fcssen die Rahmenbedingungen entsprechend gestaltet werden. Der EU Treib-hausgas-Emissionshandel muss fortgesetzt und gest\u00e4rkt werden. Zudem muss die Verwendung fossiler Energietr\u00e4ger auch in den nicht vom Emissionshandel erfassten Wirtschaftssektoren unattraktiver werden. Das kann auf nationaler Ebene beispielsweise durch eine Neugestaltung der Steuern und Abgaben auf Energietr\u00e4ger geschehen. Diese Markteingriffe werfen aller -\ndings automatisch Fragen nach der Verteilung von Ertr\u00e4gen und Lasten der Energiewende auf. Die Politik ist gefordert, geeignete Rahmenbe-dingungen zu setzen und die Verteilungsfragen gerecht zu beantworten.\nDie Zukunft bringt neue \nHerausforderungen \u2013 Phase 3\nIn der dritten Phase werden erneuerbare Ener -\ngien die Energieerzeugung dominieren. Es \nkommt zunehmend zu Situationen, in denen ein \u00dcberschuss an Energie vorhanden ist. Zu-gleich muss die Energieversorgung auch dann gesichert werden, wenn weder Wind- noch Solarenergie in ausreichendem Ma\u00dfe verf\u00fcgbar sind. Ein Teil der L\u00f6sung dieses Problems wird die st\u00e4rkere internationale Vernetzung des Energiesystems sein. Bereits heute erstreckt sich das europ\u00e4ische Verbundnetz \u00fcber 24 L\u00e4nder von Portugal bis Rum\u00e4nien und von D\u00e4nemark bis Malta. Der vielf\u00e4ltige Technologiemix, etwa Wasserkraft in den Bergen, Geothermie im Rheingraben und Offshore Wind vor den K\u00fcs-ten, und die schiere Gr\u00f6\u00dfe dieses Energiever -\nbundes tragen dazu bei, lokal begrenzte Wet-terph\u00e4nomene auszugleichen. \nEin weiterer wichtiger Bestandteil auf dem \nWeg zu einem Energiesystem mit 80 bis 95 Prozent weniger CO\n2-Emissionen wird der \nEinsatz von Langzeitspeichern zur sp\u00e4teren \nNutzung \u00fcbersch\u00fcssiger Energie sein. Auf-grund der hohen Energiedichte und der guten Lagerbarkeit \u00fcber lange Zeitr\u00e4ume kommen hier chemische Energietr\u00e4ger zum Einsatz. Mit Power-to-Gas-Anlagen werden Wasserstoff und andere synthetische Brennstoffe erzeugt, die gelagert und sp\u00e4ter r\u00fcckverstromt werden k\u00f6nnen. Bereits heute k\u00f6nnen die Lagerkapazi-t\u00e4ten des Gasnetzes den gesamten deutschen Energiebedarf f\u00fcr mehr als eine Woche decken. In Zukunft w\u00e4re durch die effizientere Energie-nutzung und den Ausbau der Speicherkapazit\u00e4-ten eine Versorgung \u00fcber Wochen bis Monate m\u00f6glich. Dar\u00fcber hinaus k\u00f6nnen synthetische Brennstoffe \u00fcberall dort eingesetzt werden, wo erneuerbare Energien weder direkt, noch in Form von Strom genutzt werden k\u00f6nnen. Ein Beispiel hierf\u00fcr ist der Luftverkehr. Im Zu-sammenhang mit der Erzeugung synthetischer Kraftstoffe ist jedoch zu beachten, dass eine geeignete Kohlenstoffquelle gefunden werden muss. Um zus\u00e4tzliche Treibhausgasemissionen zu vermeiden, darf dieser nicht aus fossilen Quellen stammen.\nPerspektivisch kommt das erneuerbare Ener-\ngiesystem der Zukunft vollst\u00e4ndig ohne fos-sile Energietr\u00e4ger aus. Das Stromnetz bildet das 66 \nR\u00fcckgrat des Energiesystems. Die Energienach-\nfrage folgt flexibel dem Angebot erneuerbarer Energien. Dazu werden auftretende Energie-  \n\u00fcbersch\u00fcsse mit europ\u00e4ischen Nachbarn ausgetauscht oder zur sp\u00e4teren Nutzung in Stromspeichern, als W\u00e4rme oder gebunden in chemischen Energietr\u00e4gern gespeichert. Zudem wird in Zukunft dank der Effizienzgewinne, unter anderem aus der W\u00e4rmed\u00e4mmung von Geb\u00e4uden, dem Umstieg auf Elektromobilit\u00e4t oder der Einf\u00fchrung effizienterer Produktions- prozesse in der Industrie, deutlich weniger  \nEnergie ben\u00f6tigt. In der wirtschaftlichen Ge-  \nsamtbilanz der Energiewende gleichen sich die Kosten aus: f\u00fcr Investitionen in Energieeffizienz,  \nerneuerbare Energien und Energienetze, und die Ertr\u00e4ge, etwa aus Technologieexport und der Vermeidung externer Kosten. Bei einer weltweiten Durchf\u00fchrung der Energiewende ist f\u00fcr Deutschland sogar mit einer leicht positiven Bilanz zu rechnen.\n13\nUm diese Vision einer intelligenten und klima- \nfreundlichen Energieversorgung Realit\u00e4t werden zu lassen, muss der Ausbau erneuerbarer  \nEnergien weiter vorangetrieben und der Ein-satz fossiler Brennstoffe marginalisiert werden. Die Digitalisierung wird dazu beitragen, die  \nEnergiesektoren zu einem integrierten Gesamt-system zusammenzuf\u00fchren und die einzelnen Akteure zu vernetzen. Zudem erm\u00f6glicht sie die Einbindung und da-mit die aktive Beteiligung und Teilhabe von B\u00fcr -\ngerinnen und B\u00fcrgern an der Energiewende, so dass aus blo\u00dfen Konsumenten sogenannte Prosumer oder Prosumenten werden, die Ener -\ngie nicht nur beziehen \u2013 also konsumieren \u2013  \nsondern selbst produzieren. Damit die Treib-hausgasemissionen wie angestrebt um 80 bis 95 Prozent gegen\u00fcber 1990 reduziert werden k\u00f6nnen, sind eine intensivere internationale Vernetzung des Energiesystems und der Aufbau einer Infrastruktur zur langfristigen Speicherung von Energie notwendig. Dieser Transformati-onsprozess muss durch eine vorausschauende Forschung und Entwicklung begleitet werden, damit L\u00f6sungen und Produkte am Markt ver -\nf\u00fcgbar sind, wenn sie ben\u00f6tigt werden.\nAuf dem Weg der Energiewende sind wir ge-\nrade erst losgelaufen. Erste Erfolge bei der Etablierung der Basistechnologien der Energie-wende stimmen hoffnungsvoll. Mit Ausdauer und Beharrlichkeit k\u00f6nnen auch die n\u00e4chsten Schritte gelingen. Um die Chance zu bewahren, rechtzeitig ans Ziel zu gelangen und den Klima-wandel wirksam zu bek\u00e4mpfen, m\u00fcssen wir die Geschwindigkeit der Energiewende allerdings drastisch erh\u00f6hen. Transformation der Energieversorgung \u00a7  67\n1 Bernstein,  Lenny; Bosch, Peter; Canziani, Osvaldo; Chen, Zhenlin; Christ, Renate; Davidson, Ogunlade et al. (2007): Climate Change 2007:\n Synthesis Report.\n Summary for Policymakers. Hg. v. Intergovernmental Panel on Climate Change (IPCC). Valencia.\n2 P achauri, Rajendra; Allen, Myles R.; Barros, Vincente, R.; Broome, John; Cramer, Wolfgang; Christ, Renate et al. (2014): Klima\u00e4nderung 2014. \n IPCC-Synthesebericht.\n Hg. v. Intergovernmental Panel on Climate Change (IPCC). Genf.\n3 Fleming,  Kevin; Johnston, Paul; Zwartz, Dan; Yokoyama, Yusuke; Lambeck, Kurt; Chappell, John (1998): Refining the eustatic sea-level curve since \n the Last Glacial Maximum using far\n- and intermediate-field sites. In: Earth and Planetary Science Letters 163 (1-4), S. 327-342. DOI: 10.1016/\n \nS0012-821X(98)00198-8.\n4 Oliver -Smith, Anthony (2009): Sea Level Rise and the Vulnerability of Coastal Peoples. Responding to the Local Challenges of Global Climate. \n Hg.\n v. United Nations University. Bonn.\n5 WindGuard (2018)a: Status des Offshore-Windenergieausbaus in Deutschland 2017.  Hg. v. Deutsche WindGuard GmbH. Varel.\n WindGuard (2018)b: Status des Onshore-Windenergieausbaus in Deutschland 2017.\n Hg. v. Deutsche WindGuard GmbH. Varel.\n6 Bundesministerium f\u00fcr Wirtschaft und Energie (Hg.) (2018)a: 40 Jahre Energieforschung \u2013 Forschen f\u00fcr die Energiewende.  www.bmwi.de/\n Redaktion/DE/Artik\nel/Energie/Energieforschung/40-jahre-energieforschungsprogramm.html. [Zugriff am 3.4.2018].\n7 Rein,  Stefan (2016): Datenbasis zum Geb\u00e4udebestand \u2013 Zur Notwendigkeit eines besseren Informationsstandes \u00fcber die Wohn- und Nichtwohn-\n geb\u00e4ude in Deutschland.\n Hg. v. Bundesinstitut f\u00fcr Bau-, Stadt- und Raumforschung. Berlin. \n8 Bundesministerium f\u00fcr Wirtschaft und Energie (Hg.) (2018)b: Energiedaten. Gesamtausgabe. Berlin.\n9 Bezogen auf den F ahrzeugbetrieb mit der Systemgrenze Fahrzeug, siehe Quaschning, Volker (2016): Sektorkopplung durch die Energiewende \u2013 \n Anforderungen an den \nAusbau erneuerbarer Energien zum Erreichen der Pariser Klimaschutzziele unter Ber\u00fccksichtigung der Sektorkopplung.\n \nBerlin.\n10 Bundesministerium f\u00fcr Wirtschaft und Energie (Hg.) (2018)b: Energiedaten. Gesamtausgabe. Berlin.\n11 Agor a Energiewende (Hg.) (2017): Optimierung der Stromnetze. Sofortma\u00dfnahmen zur Senkung der Netzkosten und zur Rettung der deutschen \n Strompreiszone\n. Berlin.\n12 Seidel , Uwe (2018): Wie die Blockchain-Technologie Erneuerbare Energien auch ohne staatliche Zulage rentabel machen kann. In: Handelsblatt \n Journal\n, Sonderver\u00f6ffentlichung zum Thema \u201eENERGIEWIRTSCHAFT\u201c. D\u00fcsseldorf.\n13 BCG; prognos (2018): Klimapfade f\u00fcr Deutschland.  Hg. v. The Boston Consulting Group. M\u00fcnchen. Henning, Hans-Martin; Palzer, Andreas (2015): \n W\nas kostet die Energiewende? Wege zur Transformation des deutschen Energiesystems bis 2050. Freiburg.68 \nDie Evidenzbasierte Medizin \u2013 ein  \nkritischer Denkansatz erobert die Welt\nDr. Tatjana Heinen-Kammerer\nDie Erkenntnis, dass eine These in der Medizin \nnur so lange gilt, bis sie falsifiziert und durch neues Wissen abgel\u00f6st wird, ist aus heutiger Sicht trivial. Auch die Forderung, eine Thera-pie nach ihrem Nutzen und ihrem Risiko f\u00fcr den Patienten zu beurteilen, erscheint selbst-verst\u00e4ndlich. Aber die  Medizin verstand sich \u00fcber Jahrhunderte vor allem als eine Erkl\u00e4-rungswissenschaft im Kontext dogmatischer Systeme. Dabei stand nicht das Ergebnis der Behandlung im Vordergrund, sondern das (vermeintliche) Wissen.\n1 Frei nach dem Motto, \nwenn die Theorie nicht zur Praxis passt, muss die Praxis falsch sein. Anerkannte Lehrmeinun-gen anzuzweifeln oder \u00fcberhaupt nur im Rah-men einer Studie \u00fcberpr\u00fcfen zu wollen, war in der Medizin lange Zeit der Garant f\u00fcr einen Karrierestopp.\n2\nObwohl die F\u00e4higkeit bzw. Bereitschaft zur st\u00e4ndigen kritischen \u00dcberpr\u00fcfung und gege-benenfalls Verwerfung von Hypothesen heute ein Qualit\u00e4tskriterium f\u00fcr Wissenschaftlichkeit ist, galt dies f\u00fcr die Medizin lange Zeit nicht. Der Medizinbetrieb ist auch heute noch ein hochgradig autorit\u00e4res Umfeld, in dem der Ruhm von manchen Wissenschaftlerinnen und Wissenschaftlern auf einer bestimmten wissen-schaftlichen Hypothese basiert. Da ist es zwar nicht entschuldbar aber erkl\u00e4rbar, dass jeglicher Zweifel an dieser Hypothese im Keim erstickt wird. H\u00e4ngt die soziale Absicherung, Karriere und Einkommensmaximierung der Handelnden an dieser Hypothese, werden Zweifelnde be-  \nk\u00e4mpft bis hin zum Ausschluss von der wissen- schaftlichen Community. Insbesondere, wenn das wissenschaftliche Kartenhaus eine gewisse Gr\u00f6\u00dfe erreicht hat, droht bei Widerlegen der zu-grundeliegenden Thesen massiver Gesichtsver -\nlust. Hat sich eine Lehrmeinung durchgesetzt, erfordert es auf Seiten der Zweifler viel Mut, sie dennoch zu hinterfragen. So finden sich in der Literatur zum Teil skurril anmutende Beispiele wie die Annahme, Frauen h\u00e4tten weniger  \nZ\u00e4hne als M\u00e4nner. Wie einfach h\u00e4tte diese fal-sche Annahme im Rahmen einer Studie wider -\nlegt werden k\u00f6nnen.\n3 So harmlos dieses Beispiel \nist, finden sich in der Geschichte der Medizin auch Beispiele, in denen Menschen zu Schaden kamen. Die Hemmschwelle f\u00fcr kritische Nach- fragen durch Zweifelnde oder kritische Geister in der Medizin war Jahrhunderte lang jedoch sehr hoch. \nDas Bessere als Feind des Guten\nNun k\u00f6nnte der Leser auf die Idee kommen, dass dies eher historische Betrachtungen sind und sich die Zeiten l\u00e4ngst ge\u00e4ndert haben. Aber es existieren auch recht junge Beispiele. Die Beharrungskr\u00e4fte des Standards wirken ebenso bei der Entwicklung und Einf\u00fchrung neuer, effektiverer Therapien oder Operations-methoden, durch die bisherige Standardverfah-ren obsolet zu werden drohen. H\u00e4ufig konnten sich diese Innovationen nur weiter entwickeln, weil sich die Verfechter ins Ausland begaben. So etwa Kurt Semm, der als gelernter Instru-mentenmacher und Gyn\u00e4kologe Anfang der 1970er Jahre die minimalinvasive Chirurgie entwickelte und 1980 die weltweit erste mi-nimalinvasive Blinddarmoperation sowie die erste Entfernung eines Eierstocks durchf\u00fchrte.  \nMan kann sich leicht vorstellen, welch ein Affront dies f\u00fcr die etablierten Chirurgen be-deutete und so forderte der damalige Pr\u00e4sident der Deutschen Gesellschaft f\u00fcr Gyn\u00e4kologie \n40 JahreDie Evidenzbasierte Medizin \u2013 ein kritischer Denkansatz erobert die Welt \u00a7 69\nund Geburtshilfe, Kurt Semm die Approbation \nzu entziehen. Kurt Semm blieb daraufhin nur die M\u00f6glichkeit in die USA auszuweichen, um die Methode weiter zu entwickeln und verfei-nern zu k\u00f6nnen. Aus den USA konnte die Me-thode dann sp\u00e4ter wieder nach Deutschland importiert werden.\n4 Mittlerweile hat sich die \nminimalinvasive Chirurgie \u2013 zum Vorteil der  \nPatientinnen und Patienten \u2013 als Standardver -\nfahren durchgesetzt. \nAutorit\u00e4re Systeme und Eminenzen, ganz gleich \nauf welchem Gebiet, tun sich mit der Aufgabe von Deutungs- und Erkl\u00e4rungshoheit schwer, da die Handlungslogiken in solch einem Um-feld anderen Gesetzen als denen der Wissen-schaftlichkeit und der Rationalit\u00e4t gehorchen. Vor diesem Hintergrund entwickelte sich in den 1980er Jahren in Kanada die Idee von einer evi-denzbasierten Medizin (EbM) statt der bisheri-gen \u201eeminenzbasierten\u201c Medizin.\nTreibende Kraft der EbM war es, sich bei Be-\nhandlungsentscheidungen im Medizinbetrieb nicht mehr an \u00e4rztlichen Hierarchien und Lehr -\nmeinungen zu orientieren, sondern an den vorhandenen Forschungsergebnissen und wis-senschaftlichen Erkenntnissen.\n5 Dabei sollte der \neinzelne Arzt selbst bef\u00e4higt werden, Forsch- ungsergebnisse zu recherchieren, zu beurteilen und auf seine Fragen anwenden zu k\u00f6nnen.\n6 \nAls Wiege der EbM gilt eine Gruppe um den  \nInternisten und Nephrologen David L. Sackett von der McMaster-Universit\u00e4t in Hamilton/Ontario, Kanada. Was zun\u00e4chst als Bewegung entstanden war, griff rasch um sich, wurde weltweit aufgenommen und weiter entwickelt. Nat\u00fcrlich fordert ein derartiger Aufstand gegen das medizinische Establishment vielf\u00e4ltige Kritik heraus und so sah sich die Gruppe um Sackett gen\u00f6tigt, in einem Artikel 1996 noch einmal darzulegen, was EbM ist und was nicht.\n7 \nEbM ist definiert als der gewissenhafte, aus-dr\u00fcckliche und vern\u00fcnftige Gebrauch der  \ngegenw\u00e4rtig besten externen, wissenschaftli-chen Evidenz f\u00fcr Entscheidungen in der medizi-nischen Versorgung individueller Patientinnen und Patienten. Die Praxis der EbM bedeutet die Integration individueller klinischer Expertise mit der bestm\u00f6glichen externen Evidenz aus systematischer Forschung.\n8 Dabei ist evidenz-\nbasierte Medizin  eher eine Herangehensweise als ein medizinisches Leitbild oder eine Metho-de.\n9 EbM sieht vor, dass die \u00c4rztin bzw. der Arzt  \nsowohl die W\u00fcnsche und Anspr\u00fcche der Pa-  \ntientinnen und Patienten als auch die interne  \nExpertise wie auch die externe Evidenz auf  \nAbb. 1: Evidenzbasierte Medizin \nQuelle: M\u00f6glichkeiten und Grenzen \u00e4hnlich wie in Eichler et al. (2015): Deutsches \u00c4rzteblatt, Jg. 112, Heft 51-52.\nPatienten-\nerwartungen\nklinische\nExpertiseexterne\nEvidenz70 \nBasis der Studienlage f\u00fcr konkrete Entschei-  \ndungen heranzieht. Dabei k\u00f6nnen und d\u00fcrfen \nsich die Zielgr\u00f6\u00dfen der drei Wirkbereiche durch-  \naus widersprechen.10  \nDie Bef\u00e4higung der \u00c4rztinnen und \u00c4rzte, Stu-dien selbst zu recherchieren und zu bewerten, sollte von hierarchischen Denkbarrieren befrei-en. Mit der Zeit wurde jedoch deutlich, dass dies die einzelne Person sowohl hinsichtlich der F\u00e4higkeiten als auch hinsichtlich der n\u00f6tigen zeitlichen Ressourcen \u00fcberfordert. Einige Au-toren sprechen gar von Selbst\u00fcbersch\u00e4tzung, da \u00c4rztinnen und \u00c4rzte Wissenschaft anwen-den, aber keine Wissenschaftler sind.\n11 Einen \nL\u00f6sungsansatz bieten die Cochrane-Center, die die Studienlage zu einem Thema analysieren, in Health Technology Assessments (HTA) zusam-menfassen und der Community zur Verf\u00fcgung stellen. Ein weiteres Mittel, um relevante Infor -\nmationen aus der Wissenschaft in den Versor -\ngungsalltag zu transferieren, sind medizinische Leitlinien. Sie stellen  konkrete Handlungsemp-fehlungen f\u00fcr den Versorgungsablauf in Form von systematisch entwickelten Entscheidungs-hilfen bereit.\n12   So bedeutete der Siegeszug der \nEbM auch einen Entwicklungsschub f\u00fcr Leitlini-en und HTA. Wurde fr\u00fcher auf die herrschende Lehrmeinung verwiesen, um unerw\u00fcnschte, neue Therapieans\u00e4tze zu verhindern, so wird heute auf die fehlende oder unzureichende Evi-denz verwiesen. So ist die EbM zwar angetre-ten, um Hierarchien zu zerst\u00f6ren, hat aber neue Hierarchien in Form von Leitlinien und HTA ge-schaffen.\n13\nBedeutung der evidenzbasierten Medizin  \nf\u00fcr den Patienten\nDie EbM hat auch zu h\u00f6heren Anspr\u00fcchen aus \nund in Richtung der Patientinnen und Patienten gef\u00fchrt. Es entwickelte sich das Konzept des  \nshared decision-making, bei dem die Patientin-nen und Patienten mit ihren Pr\u00e4ferenzen vom Behandelnden in die Therapieentscheidung ein-bezogen werden. Auch hier stellt sich wie bei den Behandelnden die Frage, wie die Patientinnen und Patienten dazu bef\u00e4higt werden k\u00f6nnen und ob sie dies auch m\u00f6chten. Es f\u00fchrt weiter zu den Fragen, welche Gesundheitskompetenz die Patienten im Einzelfall mitbringen, wie die Behandelnden dies erkennen und welche In-formationen die Patientinnen und Patienten in welcher Form ben\u00f6tigen, um nachhaltige Entscheidungen treffen zu k\u00f6nnen. Hier steht die Forschung zur F\u00f6rderung der Gesundheits-kompetenz zumindest in Deutschland erst am Anfang.  \nBedeutung der evidenzbasierten Medizin  \nf\u00fcr das Gesundheitssystem in Deutschland\nAuch auf der Ebene des Gesundheitssystems hat \ndie EbM Spuren hinterlassen. Auf Systemebene gilt es vielf\u00e4ltige Entscheidungen zu treffen, sei es \u00fcber die Anwendung neuer diagnostischer, medizinisch-technischer oder therapeutischer M\u00f6glichkeiten oder welche Qualit\u00e4t mit welchen Indikatoren sichergestellt werden soll bis hin zur Frage, welche Screening-Ma\u00dfnahmen f\u00fcr  \nwelche Bev\u00f6lkerungsgruppen eingef\u00fchrt werden sollen. So entwickelte sich im angels\u00e4chsi-schen Raum die EbM in Richtung Evidence- Based Healthcare (EBHC). Muss in der EbM die \u00c4rztin bzw. der Arzt nun pers\u00f6nliche  \nErfahrung, Patientenw\u00fcnsche und externe Evidenz in Entscheidungen einflie\u00dfen las-sen, so gehen bei der EBHC die vorhandene  \nEvidenz, die zur Verf\u00fcgung stehenden Ressour -\ncen und die gesellschaftspolitischen Werte, auf denen das Gesundheitssystem  basiert, in systemrelevante Entscheidungen ein.\n14 Vor  \ndiesem Hintergrund wird auch verst\u00e4ndlich, dass es in den Gesundheitssystemen der unter- schiedlichen L\u00e4nder trotz gleicher internatio-naler Evidenzlage zu unterschiedlichen Bewer- tungen der Evidenz und unterschiedlichen  \nEntscheidungen kommen kann. Zur Beurteilung der Evidenz werden insbesondere zusammen- fassende Produkte der Evidenzbasierten Medizin,  \nwie Leitlinien, systematische \u00dcbersichtsarbeiten oder HTA herangezogen.\nIn Deutschland gewann die EbM insbesondere \ndurch die Arbeit der Arbeitsgemeinschaft der Wissenschaftlichen Medizinischen Fachgesell-schaft und des \u00c4rztlichen Zentrums f\u00fcr Qualit\u00e4t in der Medizin ab Mitte der 1990er Jahre bei Die Evidenzbasierte Medizin \u2013 ein kritischer Denkansatz erobert die Welt \u00a7 71\nder Erstellung von medizinischen Leitlinien an \nBedeutung. Die Auswirkungen der evidenzba-sierten Medizin konzentrierten sich vor diesem Hintergrund zun\u00e4chst auf die unmittelbare  \n\u00e4rztliche Behandlung. Sp\u00e4testens mit dem im Jahr 2004 in Kraft getretenen Gesetz zur  \nModernisierung der gesetzlichen Kranken-  \nversicherung griff der Gesetzgeber jedoch das Konzept auf und institutionalisierte es auf Ebene der Gesetzlichen Krankenversiche-rung (GKV).\n15  Die Grunds\u00e4tze der EbM und \nder EBHC finden sich daher in der Verfahrens-  \nordnung des Gemeinsamen Bundesausschus-ses\n16, der weitreichende Entscheidungen \u00fcber \nden Leistungskatalog und Verg\u00fctungsfragen des Gesundheitssystems trifft. Dabei muss f\u00fcr das Gesundheitssystem zun\u00e4chst beurteilt  \nwerden, ob eine medizinische Ma\u00dfnahme ei-nen h\u00f6heren Nutzen mit sich bringt als bis-herige Standardverfahren, ob der Effekt die Kosten rechtfertigt und ob sich das System die Ma\u00dfnahme \u00fcberhaupt leisten kann und will.\n17 Die Methoden der EbM haben sich nicht \nnur in Deutschland im Laufe der letzten Jah-re als Goldstandard der Bewertung medizini-scher Entwicklungen etabliert. Ihnen kommt  \nmittlerweile die Rolle eines Innovationsfilters  \nzu.Ver\u00e4nderte Rahmenbedingungen f\u00fcr die \nIndustrie\nDamit haben sich die Rahmenbedingungen \nnicht nur f\u00fcr die \u00c4rzteschaft ver\u00e4ndert, son-dern ebenso f\u00fcr die Industrie. In einem ersten Schritt erfolgte 2011 die Einf\u00fchrung der Nut-zenbewertung f\u00fcr Arzneimittel mit dem Arz-neimittelmarktneuordnungsgesetz, die ebenso implementierte Nutzenbewertung nicht-medi-kament\u00f6ser Verfahren nahm bisher eine eher untergeordnete Rolle ein. Mit der Einf\u00fchrung der fr\u00fchen Nutzenbewertung von Medizinpro-dukten hoher Risikoklassen\n18 mit dem GKV-Ver -\nsorgungsst\u00e4rkungsgesetz 2015 wendet sich das Blatt nun.\nWer Innovationen im Bereich der Arzneimittel \noder Medizintechnik heute ins GKV-System bringen will, sollte Wirksamkeit und Nutzen auf Basis hochwertiger Studien nachweisen k\u00f6nnen. In der Nutzenbewertung ist bei Erstat-tungsentscheidungen eine Konzentration auf randomisierte, kontrollierte klinische Studien zu beobachten, die jedoch bisher nur f\u00fcr einen kleinen Teil von medizinischen Fragestellungen \u00fcberhaupt vorliegen. Und so mahnen namhafte Autoren, bei den Anspr\u00fcchen an die Qualit\u00e4t der Studien zum Nutzennachweis Augenma\u00df Abb. 2: Entscheidungen auf Systemebene\nEvidenzRessourcen\nWerte72 \nzu bewahren. Zu beachten sei dabei, ob bereits \neine Vielzahl von Therapieoptionen zur Verf\u00fc-gung steht oder ob es sich um die Behandlung einer schwerwiegenden Erkrankung ohne Be-handlungsalternative handelt.\n19\nW\u00e4hrend die Pharmaindustrie bereits auf jah-relange Erfahrungen mit der Nutzenbewertung zur\u00fcckblicken kann, muss sich die Medizintech-nik erst noch anpassen. Bisher liegen im Bereich der mittelst\u00e4ndisch gepr\u00e4gten Medizintechnik vergleichsweise wenige randomisierte, kontrol-lierte klinische Studien vor, die einer Nutzenbe-wertung standhalten k\u00f6nnen. Beim Einsatz von Medizinprodukten, zum Beispiel im Rahmen von Operationen, entscheiden ma\u00dfgeblich die F\u00e4higkeiten und Fertigkeiten des Anwenders \u00fcber den Erfolg der Ma\u00dfnahme. Dement-sprechend kann der Outcome in diesen F\u00e4llen nicht eindeutig dem Anwender oder dem Me-dizinprodukt zugeordnet werden.  Dies macht randomisierte, kontrollierte klinische Studien, die auf den Nachweis der Kausalit\u00e4t gerichtet sind, zumindest interpretationsbed\u00fcrftig. Hinzu kommen schnelle Innovationszyklen, bei denen die Produkte im Sinne von Schrittinnovationen laufend weiterentwickelt werden, sowie eine geringe Flexibilit\u00e4t beim Anpassen des Studien-designs.\n21  Dementsprechend war der Anreiz f\u00fcr diese Stu-dien auf Seiten der Industrie bisher eher \u00fcber -\nschaubar.  \nDar\u00fcber hinaus muss auch erw\u00e4hnt werden, \ndass Verfahren etwa der fr\u00fchen Nutzenbewer -\ntung von neuen Methoden mit Medizinproduk-ten hoher Risikoklassen\n22 bis zur endg\u00fcltigen \nEntscheidung fast vier Jahre dauern k\u00f6nnen. Dies bedeutet eine besondere Herausforderung, da der Produktlebenszyklus in der Medizintech-nik vergleichsweise kurz ist. Typischerweise sind Medizinprodukte nach 18 bis 24 Monaten nach Markteinf\u00fchrung technisch \u00fcberholt.\n23 Bis das \nErgebnis der Nutzenbewertung also vorliegt, stehen die Chancen gut, dass es das Produkt in dieser Form nicht mehr gibt. Aber auch diese Herausforderungen k\u00f6nnen die Umsetzung der EbM nicht stoppen. Denn letztlich regen gerade sie zur Weiterentwicklung von Studiendesigns und Nutzenbewertung an.\n24  \nDie Evidenzbasierte Medizin hat vielf\u00e4ltige Ent-wicklungen im Gesundheitssystem angesto\u00dfen und ist mittlerweile zu einem entscheidenden Ma\u00dfstab f\u00fcr die Bewertung von Innovationen in der Medizin \u00fcber Grenzen und Gesundheitssys-teme hinweg geworden. In der Folge hat sich auch die gesamte Forschungslandschaft ver\u00e4n-dert. Die Evidenzbasierte Medizin \u2013 ein kritischer Denkansatz erobert die Welt \u00a7 73\n1 Vgl . Raspe, Heiner (2007): Theorie, Geschichte und Ethik der Evidenzbasierten Medizin (EbM). In: Lehrbuch Evidenzbasierte Medizin in Klinik und \n Pr\naxis, 2. \u00fcberarb. u. erweiterte Aufl. 2007, S. 15-29.\n2 Vgl . K\u00f6bberling, Johannes (2007): Der Zweifel als Triebkraft des Erkenntnisgewinns in der Medizin. In: Lehrbuch Evidenzbasierte Medizin in Klinik \n und Pr\naxis, 2. \u00fcberarb. u. erweiterte Aufl. 2007, S. 9.\n3 Ebd.  K\u00f6bberling, Johannes (2007)\n4 Vgl . Wikipedia: Kurt Semm, https://de.wikipedia.org/wiki/Kurt_Semm [Zugriff am 2.4.2018].\n5 Raspe , Heiner (2007): Theorie, Geschichte und Ethik der Evidenzbasierten Medizin (EbM). In: Lehrbuch Evidenzbasierte Medizin in Klinik und\n Pr\naxis, 2. \u00fcberarb. u. erweiterte Aufl. 2007, S. 15-29.\n6 Vgl . Eichler, Martin et al. (2015): Evidenzbasierte Medizin. M\u00f6glichkeiten und Grenzen. In: Deutsches \u00c4rzteblatt, Jg. 112, Heft 51-52, 2015.\n7 Sack ett, David et al.: Evidence based medicine: what it is and what it isn`t, www.ebm-netzwerk.de/was-ist-ebm/leitartikel-sackett/, \n [Zugriff am 1.4.2018].\n8 Vgl . Netzwerk f\u00fcr evidenzbasierte Medizin:  www.ebm-netzwerk.de/was-ist-ebm/leitartikel-sackett/ [Zugriff am 01.4.2018].\n9 Eichler , Martin et al. (2015): Evidenzbasierte Medizin. M\u00f6glichkeiten und Grenzen. In: Deutsches \u00c4rzteblatt, Jg. 112, Heft 51-52, 2015.\n 7 Sack\nett, David et al.: Evidence based medicine: what it is and what it isn`t, www.ebm-netzwerk.de/was-ist-ebm/leitartikel-sackett/,\n [Zugriff am 1.4.2018].\n10 Ebd.  Eichler, Martin et al. (2015)\n11 Ebd.  Eichler, Martin et al. (2015)\n12 Vgl . Kopp, Ina; Lelgemann, Monika; Ollenschl\u00e4ger, G\u00fcnter (2015): Evidenzbasierte Medizin und Leitlinien. In: Lehrbuch Evidenzbasierte Medizin in \n Klinik und Pr\naxis, 2. \u00fcberarb. u. erweiterte Aufl. 2007, S. 361-373.\n13 Eichler , Martin et al. (2015): Evidenzbasierte Medizin. M\u00f6glichkeiten und Grenzen. In: Deutsches \u00c4rzteblatt, Jg. 112, Heft 51-52, 2015.\n 7 Sack\nett, David et al.: Evidence based medicine: what it is and what it isn`t, www.ebm-netzwerk.de/was-ist-ebm/leitartikel-sackett/,\n [Zugriff am 1.4.2018].\n14 Vgl . Gibis, Bernhard et al. (2007): Systemsteuerung im Rahmen des SGB V: der Gemeinsame Bundesausschuss. In: Lehrbuch Evidenzbasierte \n Medizin in Klinik und Pr\naxis, 2. \u00fcberarb. u. erweiterte Aufl. 2007, S. 375-386.\n15 Vgl . Knieps, Franz: Zehn Jahre IQWiG 2014, S. 23.\n16 Der Gemeinsame Bundesausschuss (G-BA) ist das oberste Beschlussgremium der gemeinsamen Selbstverw altung der \u00c4rzte, Zahn\u00e4rzte, Psycho\n ther\napeuten, Krankenh\u00e4user und Krankenkassen in Deutschland. www.g-ba.de/\n17 Vgl . Busse, Reinhard; Gibis, Berhard (2007): Welche Evidenz braucht das System? In: Lehrbuch Evidenzbasierte Medizin in Klinik und Praxis, 2. \n \u00fcber\narb. u. erweiterte Aufl. 2007, S. 61-73.\n18 P aradebeispiel f\u00fcr Medizinprodukte der h\u00f6chsten Risikoklasse III sind alle aktiven, implantierbaren Medizinprodukte wie z. B. Herzschrittmacher.\n Daneben gibt es aber auch Medizinprodukte wie den Hirnspatel\n, der sehr viel \u00c4hnlichkeit mit einem Kaffeel\u00f6ffel hat, jedoch aufgrund der \n T\natsache, dass er bei Hirnoperationen mit Hirngewebe in Ber\u00fchrung kommt, in Risikoklasse III verortet ist. Vgl. Leonhard, Martin (2016): Medizin\n produkte\n. Alles gut geregelt? Druck auf mittelst\u00e4ndisch gepr\u00e4gte Branche w\u00e4chst weiter. In: Gesundheits\u00f6konomie und Qualit\u00e4tsmanagement \n 2016; 21:103-107.\n19 Gibis , Bernhard et al. (2007): Systemsteuerung im Rahmen des SGB V: der Gemeinsame Bundesausschuss. In: Lehrbuch Evidenzbasierte\n Medizin in Klinik und Pr\naxis, 2. \u00fcberarb. u. erweiterte Aufl. 2007, S. 375-386.\n20 Vgl . M\u00fchlbacher, Axel C.; Juhnke, Christin (2018): Nutzenbewertung f\u00fcr Untersuchungs- und Behandlungsmethoden mit Medizinprodukten hoher\n Klassen: Die \nAbw\u00e4gung von Patientennutzen, Evidenz und Zugang. Gesundheitswesen 2018; 80 (Suppl 2): 80 \u2013 87.\n21 Ebd.  M\u00fchlbacher, Axel C.; Juhnke, Christin (2018)\n22 Vgl . \u00a7 137 h SGB V .\n23 SPECT ARIS (2015): Die deutsche Medizintechnik-Industrie. SPECTARIS Jahrbuch 2015.\n24 M\u00fchlbacher , Axel C.; Juhnke, Christin (2018): Nutzenbewertung f\u00fcr Untersuchungs- und Behandlungsmethoden mit Medizinprodukten\n hoher Klassen: Die \nAbw\u00e4gung von Patientennutzen, Evidenz und Zugang. Gesundheitswesen 2018; 80 (Suppl 2): 80 \u2013 87.74 \nInnovation und radikale Innovation \u2013 \nworum handelt es sich und wie  planbar sind sie?\nEine Bestandsaufnahme mithilfe der Soziologie \n  \nDr. Hannes Kurtze\n\u201eDisruptive\u201c oder \u201eradikale\u201c Innovationen \nscheinen auf den ersten Blick sehr wichtige Innovationen zu sein. Mit ihnen werden gern Ver\u00e4nderungen von gro\u00dfer Tragweite assozi-iert: der Buchdruck h\u00e4ngt mit der Reforma-tion zusammen, der Dieselmotor mit dem Automobil. Was ist der Charakter solcher Innovationen und wie laufen sie ab? Nach ei-nem etwas sorgf\u00e4ltigeren Blick in die Details dieser Zusammenh\u00e4nge wird niemand ernst-haft behaupten wollen, dass hierbei rationale Einzelentscheidungen mit Blick auf eine ge-plante Zukunft bestimmend waren: Guten-berg stand weder die Reformation noch die Aufkl\u00e4rung im Sinn. Der Selbstz\u00fcndermotor war von Diesel zun\u00e4chst als station\u00e4rer Mo-tor f\u00fcr kleinere Betriebe gedacht, f\u00fcr die die Dampfmaschine zu aufw\u00e4ndig war. Heute hingegen sind vornehmlich Fahrzeuge mit dieser Verbrennungsmaschine ausgestattet. Auf der anderen Seite setzen Begriffe wie Innovationsmanagement, Innovationscont-rolling, Dienstleistungs- oder Gesch\u00e4ftsmo-dellinnovation gerade Planbarkeit und Steu-erbarkeit von Innovationen voraus. Nicht zu Unrecht lassen sich erfolgreiche Innovationen benennen, die es ohne kluge Planung oder Unternehmensstrategie nicht gegeben h\u00e4tte. \nDieser Kontrast l\u00e4sst erstens fragen, was \u00fcber -\nhaupt Innovationen sind. Wir fragen dann zweitens, inwiefern Innovationen und radikale \nInnovationen \u201eplanbar\u201c sind und \u00fcberlegen drit-  \ntens, wie man sie f\u00f6rdern kann. F\u00fcr diese Frage-stellungen greifen wir auf die Soziologie zur\u00fcck und gehen dabei insbesondere auf die Planbar -\nkeit und Steuerbarkeit von Innovationen ein.\nWas sind \u00fcberhaupt  \nInnovationen?\nInnovation ist aus Sicht der Soziologie ein allge-\nmein verst\u00e4ndlicher Sinnkontext, d. h. salopp gesprochen wird in der Gesellschaft wohlge-ordnet und viel \u00fcber Innovation geredet und geschrieben. Wenn in der Gesellschaft mit der Allgemeinform \u201eInnovation\u201c kommuniziert wird, dann fallen meistens folgende Aspekte zusammen\n1:\n     Innovation wir d meistens auf ein technisches \nArtefakt zur\u00fcckgef\u00fchrt.\n    Innovation wir d als folgenreiche Ver\u00e4nde-\nrung empfunden. Als radikale Innovationen werden Innovationen verstanden, deren Auswirkungen als gesamtgesellschaftlich folgenreich interpretiert werden.\n40 JahreInnovation und radikale Innovation \u2013 worum handelt es sich und wie planbar sind sie? \u00a7  75\n    Innovation wir d als neuartig beschrieben.\n    Dabei wir d Innovation als Verbesserung \nwahrgenommen.\nSo gefasst, ist Innovation im allgemeinen \nSprachgebrauch verbindlich und gel\u00e4ufig. In der Soziologie jedoch wird der Begriff der In-novation als Terminus oder Fachbegriff nicht verwendet. Der wesentliche Grund f\u00fcr diese Vakanz im soziologischen Begriffsrepertoi-re ist darin zu suchen, wie die Soziologie die Ver\u00e4nderung gesellschaftlicher Strukturen versteht und erkl\u00e4rt. Es ist f\u00fcr unsere Zwecke lohnenswert, dass wir dieser soziologischen Sicht detaillierter nachgehen. Daf\u00fcr w\u00e4hlen wir im Folgenden die so genannte soziologi-sche Systemtheorie, die zur Beschreibung von Ver\u00e4nderung den Begriff der Evolution einf\u00fchrt.\n2 \nDie Systemtheorie hebt sehr pr\u00e4zise hervor, dass man den Blick zun\u00e4chst auf ein soziales Referenzsystem fokussieren muss. Soziale Sys-teme sind, grob formuliert, kommunikationsba-sierte autonome soziale Zusammenh\u00e4nge wie die Wirtschaft, die Politik, die Massenmedien, aber auch Unternehmen, Familien oder zum Beispiel Redaktionssitzungen. Solche sozialen Systeme sind mittels Variation, Selektion und \nRestabilisierung zur Ver\u00e4nderung bzw. Evoluti-on imstande. Mit Variation meint die Soziologie die F\u00e4higkeit zur Irritation durch unerwartete oder unwahrscheinliche Abweichungen in der Umwelt von Bekanntem f\u00fcr das Referenzsys-tem \u2013 die meisten Abweichungen bleiben ohne weitere Folgen, das Referenzsystem geht ohne weiteres \u00fcber sie hinweg. In einigen F\u00e4llen wird jedoch vom Referenzsystem ein strukturell re-levanter Vorzugswert erkannt; diese F\u00e4higkeit wird als Selektion beschrieben. Die Restabili-sierung schlie\u00dflich beschreibt die F\u00e4higkeit der \u201eSicherung\u201c der Abweichung, d. h. f\u00fcr die Auf-nahme in die Systemstrukturen. \nDie Rede vom \u201eReferenzsystem\u201c und seiner  \n\u201eEvolution\u201c bietet h\u00e4ufig Anlass f\u00fcr Missver -\nst\u00e4ndnisse. Die Soziologie bem\u00fcht damit tat-\ns\u00e4chlich keine Metapher aus dem technischen Bereich wie zum Beispiel ein System kommu-nizierender R\u00f6hren. Gemeint sind wie oben er -\nw\u00e4hnt komplexe soziale Gef\u00fcge wie eine Or -\nganisation, wie ein Unternehmen, aber auch das System der Wirtschaft oder des Rechts. Sie sind in sich geschlossen, aber auch f\u00fcr ihre Umwelt offen und nehmen Ver\u00e4nderungen wie geschildert nach eigenen Ma\u00dfgaben vor. Die Pointe ist: Nicht die Umwelt des Referenz-systems entscheidet \u00fcber diese Ver\u00e4nderun-gen, sondern nur das Referenzsystem. Soziale Systeme f\u00fcgen sich in ihrer Ver\u00e4nderung bzw. Evolution nicht \u00e4u\u00dferen Entscheidungen und lassen sich nicht direkt lenken. Es mag zwar Erfahrungswerte geben, wie etwa die Wirt-schaft durch die Umwelt zur \u00c4nderung veran-lasst werden kann, etwa aus der Politik per Ge-setzesrahmen. Doch die Erfahrung lehrt eben auch, dass die Wirtschaft sich nicht zu einer bestimmten Inflationsrate hindirigieren l\u00e4sst oder dass Gesetzesrahmen in der Wirtschaft auch ganz andere Folgen haben k\u00f6nnen als in der Umwelt gew\u00fcnscht \u2013 siehe die steigenden Geh\u00e4lter nach Einf\u00fchrung der Offenlegungs-pflicht der Vorstandsbez\u00fcge von b\u00f6rsennotier -\nten Unternehmen. Soziale Systeme sind also f\u00fcr die Einfuhr von Irritationen umweltoffen und dennoch autonom.\nSind Innovationen und \nradikale Innovationen planbar?\nZur\u00fcck zu unserer Fragestellung: Wir haben oben \nden allgemeinen Gebrauch des Begriffes der In-novation und die soziologische Auffassung von Evolution getrennt. Bei der Ver\u00e4nderung sozialer Systeme erkannten wir eine deutliche Betonung der Autonomie der sozialen Systeme. Es ist nun recht einsichtig, dass bei Innovationsprozessen planende Entscheidungen mit Blick auf eine ge-plante Zukunft nicht die Effekte haben m\u00fcssen, die urspr\u00fcnglich intendiert wurden. Ob soziale Systeme die neuen angebotenen technischen M\u00f6glichkeiten in der gedachten Weise anneh-76 \nmen werden, ist nicht gesichert. Sie sind, knapp \nausgedr\u00fcckt, zu komplex und zu autonom. \nDas ist vielleicht kein verbl\u00fcffendes Ergebnis \u2013 \naber es ist hervorzuheben, dass wir in der Lage sind, diese Zusammenh\u00e4nge konzeptionell zu erfassen. Es ist nunmehr verst\u00e4ndlich, dass sich die Innovationsforschung mit dem Begriff der Systeminnovation auf das Milieu der Innovati-onen zu fokussieren beginnt \u2013 die Soziologie w\u00fcrde formulieren: sich auf die Systemreferenz bezieht\n3. Wir k\u00f6nnen au\u00dferdem den Erfolg des \nInnovationsmanagements erkl\u00e4ren. Er beruht auf au\u00dferordentlich detailliertem Erfahrungs-wissen im Bezugsrahmen sozialer Systeme, wie es zum Beispiel Marketingabteilungen zur Produkteinf\u00fchrung besitzen. Dennoch kann der Erfolg im Sinne eines Vollzugs intendierter Ver\u00e4nderungen in einem sozialen System damit nicht gesichert werden. Wir k\u00f6nnen n\u00e4mlich durch die Unterscheidung von Umwelt und Re-ferenzsystem auch erkl\u00e4ren, warum ein tech-nisches Artefakt wie der Dieselmotor oft nicht jene Resonanz in der Gesellschaft hervorruft wie urspr\u00fcnglich geplant. \nWie k\u00f6nnen Innovationen \ngef\u00f6rdert werden?\nBlicken wir hierzu in unsere Arbeit als Projekttr\u00e4-\nger, wo Verwertungspl\u00e4ne und Absch\u00e4tzungen des Innovationspotenzials eine Rolle spielen: Ein F\u00f6rderantrag, der zur\u00fcckhaltend geschrieben ist, erscheint nicht sehr erfolgversprechend. Insofern nimmt es nicht Wunder, wenn die potenzielle Reichweite der vorgestellten Innovation opti-mistisch in Richtung globaler oder gro\u00dfr\u00e4umiger Auswirkungen abgesch\u00e4tzt wird oder wenn das Verwertungskonzept sich nicht auf Nischenbe-reiche beschr\u00e4nkt. Mit unseren Ergebnissen k\u00f6n-nen wir jedoch zus\u00e4tzlich zur Empfehlung nach angemessener Zur\u00fcckhaltung pr\u00e4ziser formulie-ren, dass im Falle von sozialen Systemen Planbar -\nkeit nicht oder nur in sehr begrenztem Umfang unterstellt werden sollte. Solange die Resonanz der sozialen Systeme nicht abzusch\u00e4tzen ist, w\u00e4re zu empfehlen, sich den Blick auf eine ge-plante Zukunft zu verkneifen. Mindestens sollte sich auf die technisch absehbaren Potenziale beschr\u00e4nkt oder unter deutlicher Hervorhebung von Unsicherheit das Spektrum m\u00f6glicher Ver -\n\u00e4nderungen, Anwendungen und Umsetzungen bewertet werden. Dies gilt besonders f\u00fcr die ra-dikalen Innovationen, von denen gesamtgesell-schaftliche Ver\u00e4nderungen erwartet werden, d. h. wo es garantiert auf die Resonanz autonomer sozialer Systeme ankommt.\nOder in anderen Worten: Je sicherer eine Inno-\nvation eine folgenreiche Ver\u00e4nderung in sozia-len Systemen einschlie\u00dfen soll, desto weniger w\u00fcrden wir es in F\u00f6rderantr\u00e4gen empfehlen, den Innovationsvorgang mittels Arbeits- und Zeitplan vom \u201eEnde der Geschichte\u201c, also von der antizipierten erfolgreichen Etablierung der Innovation her zu erz\u00e4hlen. Stattdessen w\u00fcrden wir es begr\u00fc\u00dfen, wenn F\u00f6rderantr\u00e4ge narrativ in der Gegenwart beginnen und offen oder gern vision\u00e4r, jedoch nicht alternativlos planend  in die Zukunft schauen. Diese Empfehlung gilt besonders f\u00fcr radikale Innovationen, da sie wie dargestellt eigendynamische gesellschaftliche Austarierungsprozesse betreffen, die im Voraus kaum prognostiziert werden k\u00f6nnen.\n1 Vgl. Holger Braun-Th\u00fcrmann (2005): Innovation. T ranscript, Bielefeld, 2005. \n Vgl. a.: Cristina Besio, Robert J. Schmidt (2012): Innovation als spezi\nfische Form sozialer Evolution: \n Ein systemtheor\netischer Entwurf. Technical University Technology Studies Working Papers 3/2012, Berlin, 2012.\n2 Vgl. Niklas Luhmann (1997): Gesellschaft der Gesellschaft. Frankfurt a. M: Suhrkamp.\n3 Vgl. zur Systeminnovation auch den Beitrag von Peter Dortans in diesem Band.Digitale Hochschule \u00a7  77\nDigitale Hochschule\nDr. Ernst Andreas Hartmann\nDie Hochschulen waren bereits in den 90er \nJahren des vorigen Jahrhunderts Vorreiter und Innovationstreiber bei der Implementierung umfangreicher technischer Infrastrukturen, aber auch von ersten multimedialen Lernele-menten und universell nutzbaren E-Lear -\nning-Plattformen. Seitdem sind Campus-Ma-nagement- und Lern-Management-Systeme nicht mehr aus den Hochschulen wegzuden-ken. Mit der fortschreitenden Digitalisierung bei einer globalen Verf\u00fcgbarkeit von digitalen Inhalten und Services sind die Hochschulen heute mehr denn je auf innovative L\u00f6sun-gen in allen Leistungsbereichen \u2013 Lehre, For -\nschung, Wissenstransfer und interne Verwal-tung \u2013 angewiesen:\nIm Vordergrund der Diskussion und der \u00f6f-\nfentlichen Wahrnehmung zu digitalen Hoch-schulen steht aktuell die digitale Lehre, mit MOOCs (Massive Open Online Courses), SPOCs (Small Private Online Courses), Flipped Classrooms, virtuellen Laboren und Learning Analytics.\nDie digitale Forschung wird durch mehrere, \nteilweise voneinander unabh\u00e4ngige Trends gepr\u00e4gt. Data Science steht f\u00fcr ein Konzept empirischer Forschung, das mit der in allen empirischen Wissenschaften verbreiteten hypo-thetico-deduktiven Methodologie nicht mehr viel gemeinsam hat: Die Forschung beginnt nicht mehr (notwendigerweise) mit theorieba-sierten Hypothesen, die dann empirisch getes-tet werden; vielmehr sollen induktiv \u201edie Daten selbst sprechen\u201c. Gleichzeitig, und weitgehend unabh\u00e4ngig von solchen methodologischen Umbr\u00fcchen, entstehen digitale Forschungs-infrastrukturen, die neue M\u00f6glichkeiten der  \nSekund\u00e4rnutzung von Daten, der Replikation und Integration empirischer Befunde er\u00f6ffnen.Der Wissenstransfer aus der Hochschule in \ndie allgemeine \u00d6ffentlichkeit kann durch di-gitale Medien viel zielgruppengerechter, an-schaulicher und leichter zug\u00e4nglich gestaltet werden.\nDie Verwaltung der Hochschulen ist durch \nden breiten Einsatz von Campusmanagement-systemen bereits stark digitalisiert. Herausfor -\nderungen bestehen noch in der Integration dieser Systeme mit Lehr-Lernplattformen, For -\nschungsdateninfrastrukturen, digitalen Biblio-theken und externen Datenquellen, wie etwa digitalen Daten zu Hochschulzugangsberech-tigungen (beispielsweise digitale Abiturzeug-nisse).\nWie k\u00f6nnte das alles im Alltag aussehen? Ein \nAusflug in die zuk\u00fcnftige Welt der digitalen Hochschule zeigt einige Schlaglichter:\n    Helena hat gerade erfolgr eich ihr Abitur ab-\ngelegt und m\u00f6chte studieren. Sie sucht sich im Internet einen passenden Studiengang aus, klickt auf \u201eImmatrikulieren\u201c, gibt ihre e-Identity an und bekommt unmittelbar die R\u00fcckmeldung, dass sie eingeschrieben ist. Alle Voraussetzungen werden anhand digita-ler Daten automatisch gepr\u00fcft. Irgendwelche Papiere braucht sie daf\u00fcr nicht, und au\u00dfer ihr selbst ist kein anderer Mensch mit dem Vorgang befasst.\n     Helena nimmt mit vielen ander en Studien-\nanf\u00e4ngern an einer mehrt\u00e4gigen Einf\u00fch-\nrungsveranstaltung ihrer neuen Hochschule teil. Viele Professoren stellen in diesen Tagen ihre Fachgebiete vor und diskutieren mit den Erstsemestern. Kleine Gruppen von Erstse-mestern werden w\u00e4hrend der ganzen Zeit von humanoiden Robotern als Studienein-\n40 Jahre78 \ngangs-Coaches begleitet. Die Roboter wissen \nauch auf die entlegensten Fragen Antwor -\nten, werden nie ungeduldig und beantwor -\nten gerne Fragen zum tausendsten Mal. Sie k\u00f6nnen sich individuell auf die einzelnen Erst-semester einstellen, sie k\u00f6nnen auch Emotio-nen erkennen und haben keine Probleme mit Humor und Ironie.\n    W\u00e4hrend des Studiums macht Helena ein \nAuslandssemester. Im europ\u00e4ischen Studi-\nenangebots-Portal konnte sie vorher genau und verbindlich sehen, welche Kurse welcher ausl\u00e4ndischen Hochschule auf welche Modu-le ihres Heimat-Studiengangs anerkannt wer -\nden. Sobald sie an der Gasthochschule eine Pr\u00fcfung abgelegt hat, werden die Ergebnisse in einem elektronischen Open Badge doku-\nmentiert. Dieser Badge wird sofort und au-tomatisch in Helenas e-Portfolio eingelesen. Auch an ihrer Heimathochschule wird das Ergebnis sofort und automatisch als Studi-enleistung in einem elektronischen Zertifikat und f\u00fcr ihr elektronisches Abschlusszeugnis dokumentiert.\n     Nach ihr em Studium m\u00f6chte sich Helena \nauf passende Stellen bewerben. Sie kann \nalle Informationen und Belege ihres e-Port-folios differenziert und gezielt zu definier -\nten Zeitr\u00e4umen potenziellen Arbeitgebern  \nzug\u00e4nglich machen. Die Arbeitgeber be-\nn\u00f6tigen keine weiteren und insbesondere gar keine physischen Dokumente wie zum Beispiel Zeugniskopien. Daraus entste-hen auch wichtige Vorteile f\u00fcr die Arbeit-geber. Es m\u00fcssen nicht mehr Berge von pdf-Dokumenten gelesen und ausgewer -\ntet werden (von Papierdokumenten ganz zu schweigen), vielmehr k\u00f6nnen die Daten sofort digital gelesen, analysiert und auf-bereitet werden. Und nicht zuletzt: Wenn wesentliche Daten wie Zeugnisse und Zer -\ntifikate in einer sicheren digitalen Form \u2013  \nbeispielweise innerhalb einer Blockchain \u2013  \nvorliegen, werden Dokumentenf\u00e4lschungen sehr viel schwieriger, die Daten verl\u00e4sslicher.     Rupert hat sich nach einer Berufsausbildung \nzum Mechatr\noniker zum Industriemeister \nMechatronik weitergebildet. Nun sucht er Weiterbildungsangebote zum Thema In-dustrie 4.0. Mittel- bis langfristig kann er sich auch vorstellen, berufsbegleitend noch ein Hochschulstudium zu absolvieren, um seine Karriereaussichten zu verbessern. Im europ\u00e4ischen Studienangebots-Portal erh\u00e4lt er sofort Informationen dazu, welche Studi-enmodule welcher Hochschulen zu seinen In-teressen passen, berufsbegleitend und online studiert werden k\u00f6nnen. Weiterhin erh\u00e4lt er Informationen, auf welche Module seine Be-rufsbildung angerechnet wird, und wie er \nunterschiedliche Module unterschiedlicher Hochschulen \u00fcber die Zeit zu einem Bache-lor-Studiengang und -abschluss akkumulie-ren kann.\n    Rupert beginnt seine W eiterbildung mit \nHochschulzertifikaten zur CyberSecurity. Die Kurse sind komplett online, auch die Pr\u00fc-fungen. Pr\u00fcfungsergebnisse werden auch \nbei ihm sofort in Open Badges und in seinem e-Portfolio dokumentiert.\n    Rupert kann seine neuen Kenntnisse direkt \nam Arbeitsplatz umsetzen. Dazu tragen mehrere Faktoren bei. Ein Teil seines Studiums besteht aus praxisintegrierten Forschungs-, Innovations- und Lernprojekten. Zu Ruperts Aufgaben geh\u00f6rt es, einen Produktionsbe-reich auf additive Fertigungsverfahren um-zustellen. Dieses komplexe Projekt mit Lite-ratur- und Dokumentenanalyse, Konzeption, Planung, Umsetzung und kritischer Auswer -\ntung war f\u00fcr ihn zugleich ein Lehrprojekt, ein Teil seines Studiums. Zweitens kann Rupert Techniken der Erweiterten Realit\u00e4t mit seiner Datenbrille nutzen, um sich Informationen aus seinem Studium und  seiner Hochschule direkt bei der Arbeit verf\u00fcgbar zu machen. Drittens sind die neuen Produktionsanlagen so stark mit Datenerfassungs-, -analyse- und  -visualisierungstools ausgestattet, dass sie selbst direkt als Lernsysteme genutzt werden k\u00f6nnen.Digitale Hochschule \u00a7  79\n     Helenas und Ruperts Ler nverhalten wird mit \nLearning Analytics ausgewertet. Im Ergeb-\nnis werden ihnen erg\u00e4nzende Materialen  \n(z. B. MOOCs, Webinare, \u2026) empfohlen und direkt online zug\u00e4nglich gemacht. Wenn sie es w\u00fcnschen, werden die Daten auch ihren Tuto-ren an den jeweiligen Hochschulen vertraulich zur Verf\u00fcgung gestellt, damit die Tutoren sie noch besser betreuen und beraten k\u00f6nnen.\n    Anne ist Entwicklerin f\u00fcr digitale Medien an einer r\nenommierten deutschen Hochschule. \nSie arbeitet besonders daran, Erweiterte und Virtuelle Realit\u00e4t didaktisch zu nut-zen. Mit den von ihr entwickelten Lehr-/Lern-systemen k\u00f6nnen Studenten bei Exkursionen in ihren Datenbrillen Informationen zu Archi-tektur, Geschichte oder Botanik abrufen. Mit ihren VR-Systemen kann man mit allen Sin-nen eintauchen in die Korona eines Sterns, das Mitochondrium einer menschlichen K\u00f6r -\nperzelle, das Innere einer Werkzeugmaschi-ne, \u2026\n     Alexander ist Sozialwissenschaftler und er - \nforscht Bildungsbiografien. Seine Forschungs-\nergebnisse \u2013 qualitative Daten \u2013 stellt er bei einem Forschungsdatenzentrum ein, damit  \nandere Wissenschaftler seine Daten auch verwenden k\u00f6nnen. Umgekehrt nutzt er re-gelm\u00e4\u00dfig online Daten anderer Forscher, um sie mit seinen eigenen Daten zu vergleichen und, wo m\u00f6glich, zu integrieren. \n     Alexander ist auch Dozent f\u00fcr empirische Bil-\ndungsforschung. In seinen Seminaren \u2013 die \nteilweise als Webinare organisiert sind \u2013 nutzt er Daten der Forschungsdatenzentren; die Studenten k\u00f6nnen mit diesen Daten wissen-schaftliche Fragestellungen untersuchen und dabei ihre fachlichen wie auch methodischen Kompetenzen entwickeln. So verbindet \nAlexander ganz praktisch Forschung und  \nLehre.\nHochschulen als Einrichtungen der Forschung und der Lehre nehmen eine ganz besondere Rolle ein in den Innovationssystemen. Digitale Technologien erweitern entscheidend die M\u00f6g- lichkeiten der Hochschulen, diese Rolle auszu-gestalten. Durch digitale Konzepte und Tech-nologien wie Open Badges, e-Portfolios und Blockchain wird es m\u00f6glich, personenbezo-gene und angebotsbezogene Bildungs-daten auf einem neuen Qualit\u00e4tsniveau zur Verf\u00fcgung zu stellen. Personen werden ihre Bildungsdaten flexibel, sicher, gezielt und vor allem souver\u00e4n verwenden k\u00f6nnen. Informati-onen zu Bildungsangeboten der Hochschulen \u2013  ob traditionell oder weiterbildend \u2013 werden viel umfassender, differenzierter und aktueller zur Verf\u00fcgung stehen.\nDie Qualit\u00e4t der Lehre wird sich stark verbes-\nsern: Immersive digitale Medien erlauben v\u00f6llig \nneue Lernerlebnisse \u201emit allen Sinnen\u201c. Das Selbstlernen wird mehr und mehr durch digi-tale Medien unterst\u00fctzt; Dozenten k\u00f6nnen sich konzentrieren auf vertiefende Diskussionen, Be-ratung, Lernbegleitung und andere Aufgaben, die menschliche Kompetenzen erfordern. Lear -\nning Analytics wird dazu beitragen, dass Lern-angebote viel genauer auf individuelle Bedarfe zugeschnitten werden k\u00f6nnen.\nDie Zug\u00e4nglichkeit der Hochschulbildung wird \nsich f\u00fcr viele Menschen verbessern. Berufst\u00e4tige \nund Personen mit Familienpflichten profitieren von Angeboten, die sie zeitlich flexibel von zu Hause aus oder am Arbeitsplatz wahrnehmen k\u00f6nnen. Neue Formen der Mensch-Technik-In-teraktion (zum Beispiel Sprach-Ein- und -Aus-gabe, Gestenerkennung bis hin zu Brain-Com-puter-Interfaces) erschlie\u00dfen neue Zug\u00e4nge f\u00fcr Menschen mit Einschr\u00e4nkungen im Bereich des H\u00f6rens oder Sehens.\nAuch die r\u00e4umliche Zug\u00e4nglichkeit der Hoch-\nschulbildung wird sich deutlich verbessern. Menschen in entlegenen Regionen werden ohne Qualit\u00e4tsverluste an einer breiten \u2013 letzt-lich weltweiten \u2013 Palette von Angeboten der Hochschulbildung teilnehmen k\u00f6nnen. Hier liegen auch Chancen f\u00fcr Entwicklungsl\u00e4nder hinsichtlich der Teilhabe an weltweiten Wis-sensstr\u00f6men.80 \nDurch r\u00e4umlich und zeitlich flexibel nutzbare \nForschungsdatenbest\u00e4nde und ebenso r\u00e4um-lich und zeitlich flexibel gestaltbare Bildungs-angebote entstehen neue M\u00f6glichkeiten der Verbindung von Forschung und Lehre, des forschenden Lernens.\nWird sich also eine \nsch\u00f6ne, neue, digitale Hochschulwelt von allein einstellen, quasi naturge-setzlich, allein durch den Sog der technologischen Entwicklung?\nSicher nicht, auf dem Weg zur digitalen Zukunft \nder Hochschulen sind einige Herausforderun-gen zu bew\u00e4ltigen, schwierige Fragen zu be-antworten. Die Wirkung digitaler Medien und Systeme stellt sich nicht automatisch ein, und sie erschlie\u00dft sich nicht von allein. Dies betrifft alle Aspekte der digitalen Hochschule: Lehre, Forschung, Wissenstransfer, Verwaltung:\n    Welche digitalen Lehr-/Lernformate wirken \nwie auf was? Allein die Digitalisierung der Lehre d\u00fcrfte gar keine Wirkung haben. Vielmehr bieten digitale Techniken M\u00f6glich-keiten, grundlegende Aspekte des mensch-lichen Lernens besser anzusprechen: Das aktive Lernen kann durch digitale Lehr-/Lern-settings besonders herausgefordert werden, induktives Lernen kann in Simulationsumge-bungen effektiver und effizienter verlaufen als in der realen Welt \u2013 manchmal erm\u00f6glicht die virtuelle Umgebung auch erst experimen-telles, induktives Lernen, das in der Realit\u00e4t so gar nicht stattfinden k\u00f6nnte, weil es in den jeweiligen Kontexten zu gef\u00e4hrlich oder viel zu kostspielig w\u00e4re. Alle diese Wirkungs-mechanismen digitalen Lehrens und Lernens m\u00fcssen gut erforscht und verstanden wer -\nden, um die Potenziale der digitalen Technik gut nutzen zu k\u00f6nnen.\n     Ersetzen Big Data und Data Science einfach \ndie gute alte W\nelt Popper\u2018scher Erkenntnis- \nund Wissenschaftstheorie? Einfach so, durch die reine Kraft der Methoden? Oder wird nicht vielmehr ein neuer methodologi-scher, erkenntnis- und wissenschaftstheoreti-scher Diskurs herausgefordert, der die neuen M\u00f6glichkeiten der Datenanalyse kritisch be-gleitet und die wissenschaftliche Praxis ihrer Verwendung neu gestaltet?\n    Wie stellt sich Wissenstransfer aus den Hoch-\nschulen in die allgemeine \u00d6ffentlichkeit dar im Zeitalter sozialer Netzwerke? Wie sind wissenschaftliche Inhalte noch vermittel-bar, wie k\u00f6nnen Konzepte von Seriosit\u00e4t, Fundiertheit und fachlicher Unabh\u00e4ngigkeit kommuniziert, aufrechterhalten, vielleicht auch neu erfunden werden?\n    Welche Rolle spielen IT-Systeme f\u00fcr F\u00fch-\nrung und Steuerung, f\u00fcr die Governance  \neiner Hochschule? Dies betrifft nicht nur die IT-Governance, also die Steuerung und \nGestaltung des fortschreitenden Digitalisie-rungsprozesses der Hochschule, sondern zunehmend die Governance durch IT-Sys-teme, die Nutzung digitaler Technologien f\u00fcr die wirtschaftliche, soziale und wissen-schaftliche Positionierung und Entwicklung der Hochschulen. Welche Auswirkungen hat das auf die praktische M\u00f6glichkeit der Autonomie, des autonomen Handelns von Hochschulen? Viele dieser Fragen sind kaum untersucht, manche nicht einmal explizit hergeleitet und gestellt worden.\nDie Beantwortung dieser Fragen wird dar\u00fcber entscheiden, welche Konzepte der digitalen Hochschule unter welchen Bedingungen wel-che Aussichten auf Wirksamkeit und generell Erfolg haben werden.Digitale Hochschule \u00a7  81\nEs gibt aber auch einen Regelungsbereich, der \neine ganz grundlegende Bedeutung f\u00fcr den Er -\nfolg und die Akzeptanz der digitalen Hochschu-le hat: Dies sind Fragen des Datenschutzes und der informationellen Selbstbestimmung. \nWie die Verleihung des Big-Brother-Award \nan die beiden M\u00fcnchner Universit\u00e4ten \u2013 wie berechtigt auch immer \u2013 deutlich gemacht hat, kann die grundlegende Akzeptanz digi-taler L\u00f6sungen im Hochschulbereich an un-zureichenden Regelungen in diesem Bereich scheitern.\nSomit steht im Mittelpunkt der Ausgestaltung \nder digitalen Hochschule die Frage nach den Daten, nach Eigent\u00fcmerschaft, Kontrolle, Sou-ver\u00e4nit\u00e4t \u00fcber die Daten und nach Sicherheit der Daten:\n     Wie kann in der praktischen Umsetzung ge-\nw\u00e4hrleitet werden, dass die Individuen \u2013 hier \nvor allem Lernende, Lehrende und Forschen-de \u2013 tats\u00e4chlich wirksam und verl\u00e4sslich voll-st\u00e4ndige Kontrolle \u00fcber ihre Daten haben, \ninsbesondere, aber nicht nur im Kontext von Learning Analytics?\n     Welche Verantwortung haben hier die \nHochschulen zu tragen? In welchem Ma\u00dfe \nm\u00fcssen sie aktiv die Datensouver\u00e4nit\u00e4t der Individuen herbeif\u00fchren und sichern? Wel-che Aufgaben und Funktionen m\u00fcssen sie daf\u00fcr \u00fcbernehmen? Was m\u00fcssen sie selbst gew\u00e4hrleisten durch eigene T\u00e4tigkeit und Verantwortung, etwa durch eigenes Daten-hosting, was k\u00f6nnen sie unter welchen Be-dingungen an Dritte \u2013 beispielweise (private) Dienstleister und Intermedi\u00e4re \u2013 weiterge-ben, beauftragen?\n     Welche Rolle k\u00f6nnen, m\u00fcssen staatliche \noder parastaatliche Akteure auf Bundes- \noder Landesebene hier spielen, durch Regel-setzung, Regulation, Bereitstellung und\n /\noder \nKontrolle von Infrastruktur (z. B. Kursplatt-formen, Forschung- und Bildungsdateninfra-strukturen)?\n82 \nWenn es gelingt, diese Kontrolle der Datenei-\ngent\u00fcmer \u00fcber ihre Daten effektiv und effizient herzustellen, kann die digitale Hochschule ihre Rolle in regionalen, nationalen und globalen In-novationssystemen in einer ganz neuen Weise erf\u00fcllen:\nL\u00e4ngst \u00fcberf\u00e4llige Innovationen in der Lehre  \nund der Weiterbildung \u2013 wie etwa die Erset-\nzung der klassischen Vorlesung, F\u00f6rderung induktiven, erfahrungsbasierten Lernens \u2013 werden durch digitale Techniken und digital vermittelte Didaktiken \u2013 Inverted Classrooms, Simulationen, virtuelle Labore, Erweiterte und Virtuelle Realit\u00e4t \u2013 stark katalysiert und letzt-lich wirksam und \u201efl\u00e4chendeckend\u201c herbeige-f\u00fchrt.\nDie Verbindung von Forschung und Lehre \nwird auf einem neuen Niveau (wieder-)herge- \nstellt werden. Dazu tragen didaktische Inno- vationen wie forschungsprojektbasiertes Lernen ebenso bei wie die breite Verf\u00fcgbarkeit digitaler  \nForschungsdaten f\u00fcr die forschungsbasierte Lehre.Der Wissenstransfer zwischen Hochschule \nund Praxis kann mit digitalen Medien viel ziel-gruppengerechter, schneller, breiter, interakti-ver erfolgen.\nHeute hinkt die Digitalisierung der Hochschu-\nlen, abgesehen von bestimmten, stark digitali-sierten Forschungsbereichen, in vielen Aspekten noch der Digitalisierung anderer Gesellschafts-bereiche hinterher. So sind etwa Erweiterte und Virtuelle Realit\u00e4t heute in der Wirtschaft st\u00e4rker verbreitet als in der Hochschule. Je st\u00e4rker und integrativer die Digitalisierung aber voranschrei-tet, desto mehr w\u00e4chst auch die Chance, dass die digitale Hochschule einmal \u2013 zumindest in Teil- aspekten \u2013 Treiber der digitalen Innovation werden k\u00f6nnte. \u00c4hnlich wie Spiele-Anwen-dungen eine starke Rolle in der Entwicklung der Mensch-Technik-Interaktion inne haben, k\u00f6nnten etwa virtuelle Labore oder Labore in Telepr\u00e4senz und andere entstehende digitale Anwendungen in der Hochschullehre techni-sche Entwicklungen ansto\u00dfen, die auf andere Anwendungsfelder ausstrahlen.Wie Brot und Sprengstoff aus der Luft die Welt ver\u00e4nderten: Das Haber-Bosch-Verfahren \u00a7  83\nWie Brot und Sprengstoff aus  \nder Luft die Welt ver\u00e4nderten:  Das Haber-Bosch-Verfahren\nDr. Moritz Kirste  Dr. Jan Philipp Meyburg\nMit der Industriellen Revolution im sp\u00e4ten 18. \nJahrhundert und insbesondere im Verlauf des 19. Jahrhunderts begann die Bev\u00f6lkerung in Europa sehr schnell zu wachsen. Dieser massive Anstieg \u2013 allein in Europa waren es insgesamt 116 Prozent\n1 \u2013 wurde durch die Erschlie\u00dfung \nneuer Fl\u00e4chen f\u00fcr die Landwirtschaft und die effizientere Nutzung des vorhandenen Acker -\nlandes erm\u00f6glicht. Durch Justus von Liebigs Forschungen war seit Mitte des 19. Jahrhun-derts bekannt, dass Pflanzen wichtige anorga-nische N\u00e4hrstoffe, allen voran Stickstoff, aber auch Kalium und Phosphat ben\u00f6tigen und dass durch die zus\u00e4tzliche Ausbringung dieser Sub-stanzen die Ernteertr\u00e4ge signifikant gesteigert werden konnten. Warum aber ist gerade das Fehlen von Stickstoff dabei ein fundamentaler, ertragsbegrenzender Faktor?\nIm Vergleich zu den anderen Hauptn\u00e4hrele-\nmenten ist sein Anteil in lebender Materie gering. Der menschliche Organismus besteht beispielsweise nur zu ca. drei Prozent aus Stickstoff. Im Gegensatz zu anderen Elemen-ten, wie etwa Kohlenstoff, kann er von Pflan-zen nur aus dem Boden und nicht direkt aus der Luft aufgenommen werden. F\u00fcr die nat\u00fcr -\nliche Anreicherung des Bodens mit Stickstoff sorgen Bakterien, die sowohl atmosph\u00e4rischen Stickstoff als auch den in der toten Biomasse vorhandenen Stickstoff in f\u00fcr Pflanzen und damit letztlich auch f\u00fcr Menschen bioverf\u00fcg-bare chemische Verbindungen umwandeln. Im menschlichen Organismus wird er f\u00fcr den  \nAufbau von unverzichtbaren Biomolek\u00fclen wie DNA, RNA und Proteinen ben\u00f6tigt. Die beiden  \nNukleins\u00e4uren DNA und RNA dienen in den Zellen als Speicher und Transporteur gene-tischer Informationen, w\u00e4hrend Proteine als Botenstoffe, Rezeptoren, Katalysatoren und Strukturbausteine fungieren.\nSeit Beginn der Landwirtschaft versuchen Men-\nschen die Ernteertr\u00e4ge durch Unterst\u00fctzung des Pflanzenwachstums zu erh\u00f6hen, indem sie zus\u00e4tzliche Stickstoffverbindungen in Form von Mist oder Kompost auf die \u00c4cker ausbrin-gen oder durch eine gute Stickstoffversorgung garantierende wechselnde Fruchtfolge. Lange Zeit waren ihnen die zugrundeliegenden Pro-zesse nicht bekannt \u2013 erst durch Justus von Lie-bigs Erkenntnisse konnten im 19. Jahrhundert die Ertr\u00e4ge der Landwirtschaft gezielt mit Hilfe k\u00fcnstlicher D\u00fcngung auf der Basis von Salzen gesteigert und auf diese Weise die Bev\u00f6lkerung ern\u00e4hrt und ein verst\u00e4rktes Wachstum gew\u00e4hr -\nleistet werden. \nBereits 1798 hatte Thomas Robert Malthus das \nVerh\u00e4ltnis von Bev\u00f6lkerungswachstum und Bo-denertrag untersucht und ermittelt, dass die Lebensmittelproduktion auf Dauer jedoch nicht mit dem Wachstum der Menschheit Schritt halten k\u00f6nne. Die f\u00fcr die D\u00fcngung ben\u00f6tigten stickstoffhaltigen Salze wurden fast ausnahms-los durch die Erschlie\u00dfung von Salpetervorkom-men in der Atacama-W\u00fcste im Grenzgebiet zwischen Bolivien, Chile und Peru und durch den Abbau von Guano (Vogelmist) gewon-nen. Ein effizientes technisches Verfahren f\u00fcr \n40 Jahre84 \ndie Gewinnung von Stickstoff gab es nicht und \nsp\u00e4testens nach einer viel beachteten Rede von William Crookes vor der British Association for the Advancement of Science in Bristol im Jahre 1898 war absehbar, dass die nat\u00fcrlichen Stick-stoffvorkommen im Laufe des 20. Jahrhun-derts zuneige gehen w\u00fcrden.\n2 William Croo-\nkes prophezeite, dass der Welt neue Konflikte um die nat\u00fcrlichen Stickstoffvorkommen und Hungersn\u00f6te in ungeahntem Ausma\u00dfe drohen w\u00fcrden, wenn es nicht gel\u00e4nge, den in der Luft enthaltenen Stickstoff chemisch zu fixieren und als D\u00fcnger zu verwenden. Die Idee ist nahelie-gend, denn Luft besteht bis zu 80 Prozent aus elementarem Stickstoff, der in dieser Modifika-tion jedoch lediglich von speziellen Bakterien umgewandelt werden kann. Die Bindung von Luftstickstoff als sogenanntes Brot aus der Luft galt demnach zu Beginn des 20. Jahrhunderts als eine der gr\u00f6\u00dften chemischen Herausforde-rungen f\u00fcr die Ern\u00e4hrung und Versorgung der Menschheit. \nNeben anderen Chemikern begann im Jahr \n1904 auch Fritz Haber in Karlsruhe mit dem Studium der Darstellung von Ammoniak (NH\n3) aus Luft-Stickstoff (N 2) und Wasser -\nstoff (H 2) gem\u00e4\u00df der Reaktionsgleichung:  \nN2 + 3 H 2      2NH 3\nSynthetisierter Ammoniak kann anschlie\u00dfend als Ausgangsstoff f\u00fcr die D\u00fcngemittelherstel-lung verwendet werden. 1906 erkannte Haber, dass bei Normaldruck und einer Temperatur von 1000 \u00b0C die Ausbeute der Reaktion lediglich 0,004 Prozent betr\u00e4gt und die Reaktion unter diesen Umst\u00e4nden wirtschaftlich nicht effizient genutzt werden konnte\n3. Diesem Hindernis lie-\ngen einige fundamentale chemische und ther -\nmodynamische Zusammenh\u00e4nge zugrunde, die im Folgenden kurz erl\u00e4utert werden. \nChemische Reaktionen laufen \u00fcblicherweise bei \nkonstanter Temperatur (isotherm) und konstan-tem Druck (isobar) ab. Ohne \u00e4u\u00dfere Einfl\u00fcsse stellt sich ein Gleichgewichtszustand zwischen Ausgangstoffen \u2013 in diesem Falle N\n2 und H 2 \u2013  und Produkten, also NH 3, ein. Ist das System \njedoch nicht im Gleichgewicht, verl\u00e4uft die Reaktion jeweils in die Richtung, in die das Gleichgewicht ver\u00e4ndert wurde. Die obere Gleichung l\u00e4sst sich also als eine Art Waage vorstellen, bei der der Doppelpfeil das Zent-rum der Waage und die Ausgangsstoffe und Produkte die beiden Waagschalen bilden. Eine M\u00f6glichkeit, die Waage aus dem Gleichge-wicht zu bringen, ist die Temperatur. Bei der gew\u00fcnschten Richtung, also von links nach rechts, handelt es sich um eine exotherme Reaktion. Es wird W\u00e4rme frei, und demnach wird die Reaktion beg\u00fcnstigt, wenn man dem System W\u00e4rme entzieht und somit die Waage zugunsten der rechten Seite aus dem Gleich-gewicht bringt. \nEine zweite M\u00f6glichkeit ist der Druck. Erh\u00f6ht \nman den Druck in dem System, bewegt sich das Gleichgewicht auf die Seite, wo weniger Mole-k\u00fcle sind. Links befinden sich vier Molek\u00fcle pro Volumeneinheit (ein Stickstoff und drei Wasser -\nstoff) und auf der rechten Seite sind nur zwei Ammoniakmolek\u00fcle. Durch Druckerh\u00f6hung wird die gew\u00fcnschte Reaktion also beg\u00fcnstigt.\nZuletzt kann das Gleichgewicht beeinflusst \nwerden, indem kontinuierlich Stoff hinzugef\u00fcgt oder entnommen wird. Wird dem System Am-moniak entzogen, so entsteht ein \u00dcberschuss an Ausgangsstoffen, der wiederum weitere neue Reaktionen hin zu Ammoniak erm\u00f6glicht.\nChemische Reaktionen werden aber noch \ndurch einen weiteren Aspekt beeinflusst: Die sogenannte Reaktionskinetik, also die Ge-schwindigkeit, mit der die Reaktion abl\u00e4uft. Diese wird durch die H\u00f6he der Aktivierungse-nergie bestimmt, welche \u00fcberwunden werden muss, damit eine Reaktion \u00fcberhaupt ablaufen kann. Ist diese Aktivierungsenergie niedrig, so verl\u00e4uft die Reaktion schnell. Ist sie jedoch wie im Fall von Luft-Stickstoff (N\n2) sehr hoch, da \ndie Dreifachbindungen zwischen den beiden Stickstoffatomen aufgebrochen werden muss\n4, \ndann verl\u00e4uft die Reaktion sehr langsam und damit ineffizient. Die Reaktionsgeschwindigkeit Wie Brot und Sprengstoff aus der Luft die Welt ver\u00e4nderten: Das Haber-Bosch-Verfahren \u00a7  85\nkann beschleunigt werden, indem die Tempera-\ntur des Systems erh\u00f6ht und dadurch die Akti-vierungsenergie leichter \u00fcberwunden wird \u2013 ein Vorgang der jederzeit zuhause beim Kochen oder Backen nachvollzogen werden kann. \nF\u00fcr die Synthese von Ammoniak entsteht \ndurch die beschriebenen Zusammenh\u00e4nge eine Zwickm\u00fchle: Einerseits muss dem System f\u00fcr eine effiziente Reaktion W\u00e4rme zugef\u00fcgt wer -\nden, gleichzeitig steht dies im Gegensatz zur ersten Forderung, dass dem System aus Sicht der Waage und des Gleichgewichtes eigentlich W\u00e4rme entzogen und die Reaktion zus\u00e4tzlich durch hohen Druck und die Entnahme der End-produkte beg\u00fcnstigt werden m\u00fcsste. \nHaber erkannte dies und besch\u00e4ftigte sich in \nder Folge mit Druckreaktoren und entwickel-te zudem Reaktoren aus denen synthetisierter Ammoniak abflie\u00dfen konnte.\n5 Die Ammo-\nniaksynthese konnte jedoch auch in dieser Form weiterhin nicht wirtschaftlich realisiert werden. Den eigentlichen Ausweg fand Haber schlie\u00dflich, indem er geeignete Reaktionska-talysatoren verwendete. Katalysatoren verm\u00f6-gen chemische Reaktionen zu beschleunigen oder \u00fcberhaupt zu erm\u00f6glichen, indem sie alternative Reaktionspfade bieten, die deut-lich geringere Aktivierungsbarrieren als die urspr\u00fcngliche Reaktion aufweisen. Hierf\u00fcr kommen \u00fcblicherweise \u00dcbergangsmetalle in Frage, da sie freie Valenzen f\u00fcr die Adsorption (Bindung) und Reaktion der Edukte bieten, je-doch die entstehenden Produkte auch wieder desorbieren lassen (Sabatier-Prinzip).\n6 Haber \nidentifizierte zun\u00e4chst Osmium als geeignetes Katalysatormaterial.  Mit seinen Assistenten konnte Haber zeigen\n7, dass bei einem Druck \nvon 200 Atmosph\u00e4ren und einer Temperatur von 600 \u00b0C unter Verwendung von Osmi-um-Katalysatoren eine Ausbeute von 18 Pro-zent realisierbar war: Am 13. Oktober 1908 beantragte er beim kaiserlichen Patentamt in Abb. 1: Nachbau der Versuchsanordnung Fritz Habers zur Ammoniaksynthese \n86 \nBerlin ein Patent f\u00fcr ein \u201eVerfahren zur Syn-\nthetischen Darstellung von Ammoniak aus den Elementen\u201c. \nKurz darauf wurde Haber Mitarbeiter der Ba-\ndischen Anilin- und Soda-Fabrik in Ludwigsha-fen am Rhein (BASF) und \u00fcberlie\u00df dieser die wirtschaftliche Verwertung seiner Forschung.Er hatte zuvor aufgezeigt, dass die Synthese von Ammoniak aus Luft-Stickstoff und Was-serstoff mittels geeigneter Katalysatoren nur unter Hinnahme eines Kompromisses zwischen Temperatur, Druck, Konzentration und Reakti-onskinetik m\u00f6glich ist. Zus\u00e4tzlich mussten die technische Realisierbarkeit und der wirtschaft-liche Aufwand ber\u00fccksichtigt werden. Die zu-n\u00e4chst verwendeten Osmium-Katalysatoren waren zu teuer, weshalb nach Alternativen ge-sucht werden musste. Bei der BASF versuchten daher Carl Bosch und Alwin Mittasch, Stickstoff zun\u00e4chst an Metallnitriden und Metallcyaniden zu fixieren. Nach langer systematischer Suche in 20.000 Versuchen mit etwa 3.000 verschie-denen Katalysatoren fand Mittasch schlie\u00dflich Katalysatoren auf Basis von g\u00fcnstigen Eiseno-xiden, die eine gro\u00dftechnische Ammoniaksyn-these erm\u00f6glichen konnten.\n8 Auch heute noch \nwerden die von Mittasch identifizierten Katalysa-toren f\u00fcr die Ammoniaksynthese verwendet. Der zugrundeliegende Reaktionsmechanismus konn-te erst zum ausgehenden 20. Jahrhundert von Gerhard Ertl und seinen Mitarbeitern auf mole-kularer Ebene vollst\u00e4ndig aufgedeckt werden.\n9  Trotz des Verst\u00e4ndnisses der grunds\u00e4tzlichen chemischen Zusammenh\u00e4nge und der Ent-deckung eines g\u00fcnstigen Katalysators waren f\u00fcr eine Produktion im industriellen Ma\u00dfstab die verfahrenstechnischen Probleme f\u00fcr die Ammoniaksynthese bei enormen Dr\u00fccken von 200\u2013400 bar und die damit verbundenen ingenieurtechnischen Schwierigkeiten noch lange nicht gel\u00f6st.\n10 F\u00fcr die Konstruktion ge-\neigneter Reaktoren wurde bei der BASF mit der Unterst\u00fctzung des Vorstands und des Auf-sichtsrats sowie unter Umgehung der \u00fcblichen Zust\u00e4ndigkeiten und Abteilungszuschnitte eine Hochdruckwerkstatt eingerichtet.\n11 Spezialisten \nverschiedener Disziplinen (Chemie, Maschinen-bau, Physik) arbeiteten hier unter der Leitung von Carl Bosch gemeinsam an der technischen Ausf\u00fchrung der Ammoniaksynthese, f\u00fcr deren Umsetzung es zu diesem Zeitpunkt keinerlei technische Referenzen gab. \nAls gro\u00dfe Herausforderungen wurden insbe-\nsondere die Kontrolle und die Bereitstellung von Wasserstoff in industriellen Ma\u00dfst\u00e4ben, bei hohem Druck und hohen Temperaturen iden-tifiziert. Die zun\u00e4chst verwendeten Stahllegie-rungen der Reaktoren erwiesen sich als unge-eignet, da im Verlauf des Prozesses Wasserstoff dissoziierte, atomar in die Reaktorw\u00e4nde eindif-fundierte und diese hierdurch erodierte. Einge-drungener atomarer Wasserstoff rekombiniert vorwiegend an Gitterfehlstellen wieder zu H\n2 \nund verbleibt sodann im Metallgitter. Dies f\u00fchrt \nAbb. 2: Fritz Haber und Carl BoschWie Brot und Sprengstoff aus der Luft die Welt ver\u00e4nderten: Das Haber-Bosch-Verfahren \u00a7  87\nzu Spannungen und zu einer Verspr\u00f6dung des \nStahls (Wasserstoffverspr\u00f6dung), die schlie\u00dflich zu Rissen in den Reaktorw\u00e4nden f\u00fchren. In Er -\nkenntnis dessen wurden in der Folge austeniti-sche Stahllegierungen (vorwiegend Chrom-Ni-ckel-St\u00e4hle) entwickelt, die sich als weitgehend unempfindlich gegen die Wasserstoffverspr\u00f6-dung auch bei hohen Wasserstoffdr\u00fccken und hohen Reaktionstemperaturen erwiesen. In aus- tenitischen Legierungen und St\u00e4hlen liegt Eisen haupts\u00e4chlich in kubisch-fl\u00e4chenzentrierter  \nGitterstruktur vor. Dies erh\u00f6ht die Z\u00e4higkeit der  \nLegierung und somit dessen Widerstandsf\u00e4hig-keit gegen Br\u00fcche oder Rissausbreitung.\nDie interdisziplin\u00e4re Zusammenarbeit bei BASF \ngilt als herausragendes Beispiel f\u00fcr das effektive  \nZusammenspiel verschiedener Disziplinen in der chemischen Gro\u00dfindustrie. Das von Haber 1908 eingereichte Patent zur synthetischen Herstellung von Ammoniak wurde am 8. Juni 1911 vom Kaiserlichen Patentamt als Patent  Nr. 235421 ausgegeben\n12 und bereits 1913 nahm  \ndie BASF in ihrem Werk in Oppau erstmals eine industrielle Anlage in Betrieb. Sofort wurden hier nach dem entwickelten Verfahren t\u00e4glich zun\u00e4chst 30 Tonnen Ammoniak produziert.\n13 Im \nAnschluss befasste sich die BASF mit der Oxy-dation von Ammoniak zu Salpeter (Ammoni-umnitrat, NH\n4NO3), denn dieser kann von vielen \nPflanzen deutlich besser aufgenommen werden. \nMit dem Ausbruch des Ersten Weltkrieges 1914 \nr\u00fcckte jedoch eine andere Verwendung von Ammoniak als die zur D\u00fcngemittelherstellung in den Vordergrund: die Nutzung zur Sprengstoff-produktion. Da Deutschland \u00fcber keine eige-nen Salpetervorkommen verf\u00fcgte, kam der Salpetererzeugung eine milit\u00e4rische Schl\u00fcssel-funktion zu. Dieser Umstand veranlasste Carl Bosch zur Abgabe seines sogenannten Salpe -\nterversprechens gegen\u00fcber dem Kriegsministe-rium. Innerhalb weniger Monate wurde ein Ver -\nfahren zur Salpeterherstellung etabliert, so dass \nAbb. 3: Weltweite D\u00fcngemittel in Mio. Tonnen seit den 1960er Jahren bis heute. Ab 2015 handelt es sich um Sch\u00e4tzungen.  \nQuelle: UN: Food and Agriculture Organization of the United Nations. www.fao.org/home/en [Zugriff am 4.4.2018]. \nD\u00fcngemittelproduktion  \nSch\u00e4tzungenMillionen\n88 \nAbb. 4: Entwicklung der Weltbev\u00f6lkerung seit 1900 und Anteile der Weltbev\u00f6lkerung, die durch das Haber-Bosch-Verfahren \nern\u00e4hrt werden. \nim April 1915 bereits 1.000 Tonnen Salpeter \nund 1917 schon 13.000 Tonnen monatlich er -\nzeugt werden konnten.14  Erst mit dem Ende des \nErsten Weltkrieges 1918 wurden die Produktion von Ammoniak und die nachgelagerte Produk-tion von Salpeter wieder auf die Herstellung von D\u00fcngemitteln ausgerichtet. Trotz der zwei-schneidigen Nutzbarkeit der Ammoniaksynthe-se vergab die Nobelstiftung im Zusammenhang mit dem Haber-Bosch-Verfahren den Nobelpreis f\u00fcr Chemie 1918 an Fritz Haber und 1931 an Carl Bosch, sowie 2008 an Gerhard Ertl. \nOhne \u00dcbertreibung kann die Entdeckung des \nHaber-Bosch Verfahrens und die damit einher -\ngehende industrielle Produktion von D\u00fcngemit-teln als einer der Hauptfaktoren f\u00fcr die welt-weiten massiven Bev\u00f6lkerungszuw\u00e4chse im 20. Jahrhundert und die damit verbundenen Ver\u00e4n-derungen identifiziert werden.\n15 Anl\u00e4sslich des Milliarden\n Weltbev\u00f6lkerung gesamt\nohne Haber-Bosch-Verfahrendurch Haber-Bosch-Verfahren\nProzentualer Anteil der Weltbev\u00f6lkerung der  \ndurch Haber-Bosch-Verfahren ern\u00e4hrt wird\nWie Brot und Sprengstoff aus der Luft die Welt ver\u00e4nderten: Das Haber-Bosch-Verfahren \u00a7  89\n100-j\u00e4hrigen Jubil\u00e4ums des Haber-Bosch Ver -\nfahrens bezeichnete beispielsweise eine Ver\u00f6f-\nfentlichung in Nature Geoscience das 20. Jahr -\nhundert als ein Jahrhundert des Ammoniaks, welches das Aussehen der Welt ver\u00e4nderte.\n16 \nDieser Umstand l\u00e4sst sich mit einigen Zahlen belegen. \nSeit den 60er Jahren des 20. Jahrhunderts hat \nsich die D\u00fcngemittelproduktion ca. um den Faktor 6,5 auf aktuell ca. 200 Mio. Tonnen j\u00e4hrlich erh\u00f6ht, Abbildung 3. Diese riesigen Mengen D\u00fcnger werden auf die Felder aus-gebracht, f\u00f6rdern das Pflanzenwachstum und dienen im Nachgang einerseits zur Ern\u00e4hrung von Tieren und Menschen und andererseits zur Erzeugung von Bioenergie. Gleichzeitig werden ca. 2 Prozent des gesamten weltweiten Ener -\ngiebedarfs f\u00fcr die Ammoniakerzeugung durch das Haber-Bosch-Verfahren verwendet.\n17 Die \nWichtigkeit der Ammoniakerzeugung f\u00fcr die Weltbev\u00f6lkerung ist Organisationen wie der UN nat\u00fcrlich vollauf bewusst, weshalb beispiels-weise j\u00e4hrlich die produzierte Menge im soge-nannten \u201eworld fertilizer trends and outlook summary report\u201c\n18 mit dem Bedarf abgeglichen \nwird, um m\u00f6glichen Engp\u00e4ssen und damit dro-henden Hungersn\u00f6ten vorzubeugen. \nUnsere Abh\u00e4ngigkeit von der Ammoniaksyn-\nthese zeigt die Abbildung 4. Das Anwachsen der Weltbev\u00f6lkerung im Verlauf des 20. Jahr -\nhunderts von ca. 1,6 auf derzeit etwa 7,4 Mrd. Menschen kann zwar nicht ausschlie\u00dflich auf die Stickstoffd\u00fcngung zur\u00fcckgef\u00fchrt werden, der Anteil ist jedoch massiv. Ca. 48 Prozent der Weltbev\u00f6lkerung werden heute durch das Haber-Bosch-Verfahren ern\u00e4hrt.\n19,20 Man kann \ndiese Zahl auch noch auf andere Weise ver -\ndeutlichen. Durchschnittlich ist jedes zweite Stickstoffatom im K\u00f6rper eines jeden derzeit le-benden Menschen durch das Haber-Bosch-Ver -\nfahren synthetisiert worden. Welche gravie-renden Auswirkungen ein pl\u00f6tzliches Ende der synthetischen Erzeugung von Ammoniak h\u00e4tte, kann man sich leicht ausmalen. Die h\u00e4ufig nega-tive, \u00f6ffentliche Wahrnehmung der chemischen Industrie sollte diesbez\u00fcglich relativiert werden.Die weltweite Abh\u00e4ngigkeit vom Haber-  \nBosch-Verfahren hat nat\u00fcrlich auch eine Reihe von Kehrseiten. Neben dem hohen Energie-bedarf des Verfahrens ist der massive Bev\u00f6lke-rungszuwachs im Laufe des 20. Jahrhunderts, dessen Ende auch im 21. Jahrhundert bisher nicht in Sicht ist, ein m\u00f6gliches weltweites Pro-blem. Die damit verbundenen Umweltzerst\u00f6run-gen und der Klimawandel geh\u00f6ren sicherlich zu den gr\u00f6\u00dften Herausforderungen dieses Jahrhun-derts. Die massive Erzeugung von pflanzlichen Nahrungsmitteln bewirkt \u00fcber den Umweg des damit erm\u00f6glichten hohen Fleischkonsums ver -\nst\u00e4rkte Treibhausgasemissionen. Die Stickstoff-d\u00fcngung tr\u00e4gt aber auch direkt zum Klimawan-del bei, denn bei der bakteriellen Umsetzung der im Boden enthaltenen Nitrate entsteht N\n2O, wel-\nches in den tieferen Schichten der Atmosph\u00e4re den Treibhauseffekt f\u00f6rdert und in den oberen Schichten zur Zerst\u00f6rung der Ozonschicht bei-tr\u00e4gt. Zudem f\u00fchrt die \u00dcberd\u00fcngung in land-wirtschaftlich intensiv genutzten Regionen zur Erh\u00f6hung des Nitratspiegels, der wiederum das Grundwasser verunreinigt, und zu einer Versau-erung des Bodens f\u00fchrt.\nEin weiterer ungewollter Effekt von \u00dcberd\u00fcn-\ngung ist das \u00fcberm\u00e4\u00dfige Wachsen bestimmter nat\u00fcrlich vorkommender Pflanzen, welche etwa durch die sogenannte Algenbl\u00fcte vorhandene Vegetationssysteme zerst\u00f6ren. So wurden in Australien beispielsweise bereits gro\u00dfe Teile des Great Barrier-Riffs von Algen \u00fcberwachsen, weil D\u00fcnger von den Feldern des Bundesstaates Queensland eingeschwemmt wird. Zuletzt soll-te auch die stets und von Beginn an immer mit-gedachte weitere Verwendung der Ammoni-aksynthese nicht vergessen werden, n\u00e4mlich die zur Sprengstoffherstellung. Genaue Absch\u00e4t-zungen der Zahlen sind hier schwierig, einige Quellen geben die Zahl der Todesopfer durch Munition, die aufgrund des Haber-Bosch-Ver -\nfahren hergestellt werden konnte, jedoch mit ca. 100 bis 150 Millionen innerhalb des 20. Jahrhunderts an.\n21\nDie Tragweite und Bedeutung des Haber-  \nBosch-Verfahrens f\u00fcr die Menschheit des 20.  Weltbev\u00f6lkerung gesamt\nohne Haber-Bosch-Verfahrendurch Haber-Bosch-Verfahren90 \n1 Mortimer , I. (2014): Centuries of change. Which century saw the most change and why it matters to us. London: The Bodley Head.\n2  Crook es, W. (1898): Address of the President before the British Association for the Advancement of Science, Bristol, 1898. In: Science 28, \n V\nol. 8, Issue 200, S. 561\u2013575.\n3  F riedrich, B. (2005): Fritz Haber. Chemist, Nobel Laureate, German, Jew. By Dietrich Stoltzenberg. In: Angew. Chem. Int. Ed. 44 (26), \n S\n. 3957\u20133961.\n4  Holleman,  A. F .; Wiberg, E.; Wiberg, N. (2007): Lehrbuch der anorganischen Chemie. 102., stark umgearb. u. verb. Aufl. / von Nils Wiberg. \n Berlin u.\n a.: de Gruyter.\n5  F riedrich, B. (2005): Fritz Haber. Chemist, Nobel Laureate, German, Jew. By Dietrich Stoltzenberg. In: Angew. Chem. Int. Ed. 44 (26), \n S\n. 3957\u20133961.\n6  K olasinski, K. (2012): Surface Science. Foundations of Catalysis and Nanoscience. 3. ed. Hoboken: John Wiley & Sons.\n7  Hermann,  A. (1965): Haber und Bosch. Brot aus Luft \u2013 Die Ammoniaksynthese. In: Phys. Bl. 21 (4), S. 168\u2013171.\n8  Lemmermann, O. (1951): Alwin Mittasch. Geschichte der Ammoniaksynthese. Verlag Chemie, Berlin-Weinheim, 1951.\n9  Ertl , G. (1990): Elementarschritte bei der heterogenen Katalyse. In: Angew. Chem. 102 (11), S. 1258\u20131266.\n10 Bosch,  C. (1932): The development of the chemical high pressure method during the establishment of the new ammonia industry. \n Nobel Lecture\n. Stockholm, 1932.\n11 Hauschildt,  J.; Salomo, S.; Schultz, C.; Kock, A. (2016): Innovationsmanagement. 6., vollst\u00e4ndig aktualisierte und \u00fcberarbeitete Auflage. \n M\u00fcnchen: \nVerlag Franz Vahlen (Vahlens Handb\u00fccher).\n12 Badische Anilin- und Soda-Fabrik in Ludwigshafen am Rhein (1908): Verfahren zur synthetischen Darstellung von Ammoniak aus den Elementen. \n Angemeldet durch Badische \nAnilin- und Soda-Fabrik in Ludwigshafen am Rhein am 13. Oktober 1908. Anmeldenr: 235421.\n13 Appl, M. (1999): Ammonia. Principles and industrial practice. Weinheim u. a.: Wiley-VCH.\n14 Hermann,  A. (1965): Haber und Bosch. Brot aus Luft \u2013 Die Ammoniaksynthese. In: Phys. Bl. 21 (4), S. 168\u2013171.\n15 Mortimer , I. (2014): Centuries of change. Which century saw the most change and why it matters to us. London: The Bodley Head.\n16 Erisman,  J. W.; Sutton, M. A.; Galloway, J.; Klimont, Z.; Winiwarter, W. (2008): How a century of ammonia synthesis changed the world. \n In: Nature Geosci 1 (10),\n S. 636\u2013639.\n17 Pfromm,  P . H. (2017): Towards sustainable agriculture. Fossil-free ammonia. In: Journal of Renewable and Sustainable Energy 9 (3), S. 34702.\n18 UN (2017): World fertilizer trends and outlook to 2020. Summary Report. www.fao.org/3/a-i6895e.pdf [Zugriff am 4.4.2018].\n19 Erisman,  J. W.; Sutton, M. A.; Galloway, J.; Klimont, Z.; Winiwarter, W. (2008): How a century of ammonia synthesis changed the world. \n In: Nature Geosci 1 (10),\n S. 636\u2013639.\n20 Ritchie , H. (2017): How many people does synthetic fertilizer feed? https://ourworldindata.org/how-many-people-does-synthetic-fertilizer-feed.\n [Zugriff am 4.4.2018].\n21 Erisman,  J. W.; Sutton, M. A.; Galloway, J.; Klimont, Z.; Winiwarter, W. (2008): How a century of ammonia synthesis changed the world. \n In: Nature Geosci 1 (10),\n S. 636\u2013639.und 21. Jahrhunderts ist offensichtlich. Nach-\ndem im 19. Jahrhundert aufgrund der Sorge vor Hungersn\u00f6ten die chemische Fixierung von Luft-Stickstoff zur Ammoniakgewinnung als gr\u00f6\u00dfte Aufgabe der Chemie verstanden wurde und Haber, Bosch, Mittasch und ihren Assis-tenten dies schlie\u00dflich gelang, stellt sich nun zu Beginn des 21. Jahrhunderts die Frage nach einer vergleichbaren gr\u00f6\u00dften Herausforderung. Zweifelslos entsteht durch den nachgewiesenen Anstieg von CO\n2 in der Atmosph\u00e4re \u2013 der auch \nmit der massiven synthetischen Herstellung von Ammoniak zusammenh\u00e4ngt \u2013 eine solche Herausforderung und schon jetzt darf die Ent-wicklung eines gro\u00dftechnischen Verfahrens zur Bindung und Nutzung des verf\u00fcgbaren CO\n2 als \nn\u00e4chste gro\u00dfe Aufgabe f\u00fcr die interdisziplin\u00e4re Forschung aller L\u00e4nder angesehen werden. Innovationen im Spiegel der langfristigen Aktienkursentwicklung \u00a7  91\nInnovationen im Spiegel der lang- \nfristigen Aktienkursentwicklung \nDr. Sven Beyer  Dr. Werner Wilke\n \nEinfluss von Innovationen auf die Gesamt-marktentwicklung von Aktien\nAus Sicht der Wissenschaft und der Innova-\ntionsf\u00f6rderung f\u00fchrt die Auseinandersetzung mit historischen Entwicklungen in der Regel nicht zu eindeutigen Zukunftsprognosen \u2013 das ist und kann auch gar nicht der Anspruch sein. Stattdessen f\u00fchrt die intensive Auseinander -\nsetzung mit vergangenen Ereignissen und den Rahmenbedingungen, unter denen sich diese vollzogen haben, zu einem gesch\u00e4rften Blick auf die Entwicklungen in der j\u00fcngeren Ver -\ngangenheit und der Gegenwart. Es soll aus der zeitlichen Distanz der historischen Rekon-struktion heraus die M\u00f6glichkeit geschaffen werden, differenzierte Perspektiven auf das aktuelle Geschehen einzunehmen.\n1 Der vor -\nliegende Beitrag verkn\u00fcpft zwei f\u00fcr die mo-derne Gesellschaft wichtige Teilbereiche \u2013 die technologische Entwicklung der letzten zwei Jahrhunderte mit der finanzwirtschaftlichen \u2013  \nund geht insbesondere der Frage nach, ob und wenn ja wie sich bedeutende Innovatio-nen in der Entwicklung der Finanzm\u00e4rkte wi-derspiegeln.\nDie Prognose von Aktienkursen \u00fcbt seit Gene-\nrationen eine gro\u00dfe Faszination aus, w\u00fcrde ei-nem doch deren exakte Vorhersage immensen Reichtum garantieren, insbesondere wenn man der Erste w\u00e4re, der den Trend erkennt. Leider gilt aber auch das Bonmot, welches unter an-deren Mark Twain zugeschrieben wird, wonach Prognosen extrem schwierig sind, vor allem wenn sie die Zukunft betreffen. Finanzana-lysten erg\u00e4nzen dies gern mit der Bemerkung \u201enie war es schwerer als heute eine Prognose f\u00fcr dieses Jahr abzugeben\u201c. Nicht umsonst werden Aktienkurse auch als sogenannter  \nRandom Walk, also als ein reiner Zufallspro-zess, modelliert \u2013 eine Sichtweise, die f\u00fcr kurze  \nZeitr\u00e4ume auch best\u00e4tigt werden konnte. Ver -\nl\u00e4ngert man allerdings den Betrachtungszeit-raum auf mehrere Jahre, so l\u00e4sst sich unschwer erkennen, dass die Kurse durchaus ein tendie-rendes Verhalten zeigen. F\u00fcr Analysten und  \nAnleger ist bereits die Kenntnis der Richtung des vorherrschenden Trends, seine m\u00f6gliche Dauer und die Einsch\u00e4tzung seiner St\u00e4rke von gro\u00dfem Wert. Es geht dabei aus dieser \u00fcbergeordne-ten Sichtweise um eine Einsch\u00e4tzung, wie das  \naktuelle Kursniveau zu verorten ist in dem  \nSinne, ob sich der Markt eher in einer \u00fcberge- ordneten Aufw\u00e4rts- oder Abw\u00e4rtsbewegung  \nbefindet und welche R\u00fcckschl\u00fcsse auf das  \nk\u00fcnftige Kurspotenzial daraus abgeleitet werden  \nk\u00f6nnen. Hielscher konstatierte diesbez\u00fcglich:  \n\u201eFundierte Aktienanalysen erfordern ein lang-fristig orientiertes Vorstellungsmodell der Kurs- entwicklung, das es erlaubt, aktuelle Situationen  \nnicht nur isoliert, sondern jeweils in umfassen- deren Gesamtzusammenh\u00e4ngen zu beurteilen.\u201c\n2 \n Das von Hielscher aufgestellte Analysekonzept greift dazu auf die \u00dcberlegungen von Schum-peter zur\u00fcck und formuliert ganz in dessen Sin-ne die langfristige Aktienkursentwicklung als ein System kurz-, mittel- und langfristiger sich \u00fcberlagernder Wellen, die sich in ihrer Wirkung teils neutralisieren oder aber verst\u00e4rken. Neben den konjunkturell bedingten Wellenbewegun-gen mit einer Zeitdauer von in der Regel drei bis sieben Jahren spielen die vornehmlich durch Innovationen induzierten langfristigen Wellen \n40 Jahre92 \nmit einer Dauer von mehr als 30 bis 40 Jahren \neine herausragende Rolle.3\nAbbildung 1 zeigt die Tagesultimowerte des bekannten B\u00f6rsenbarometers Dow Jones In-dustrial Average (DJIA)\n4 vom Jahr seiner ersten \nBerechnung 1896 bis 2018 in halb-logarith-mischer Darstellung. Im Unterschied zum in Deutschland besser bekannten DAX werden bei diesem Index keine Dividenden reinvestiert; der Indexverlauf reflektiert damit ausschlie\u00dflich die Wertentwicklung der im Index enthaltenen Un-ternehmen. Der Wert bestimmt sich dabei im Wesentlichen aus der Erwartung der Marktteil-nehmer \u00fcber die zuk\u00fcnftigen Unternehmens-gewinne und der Rendite einer geeigneten alternativen Geldanlage. Zumindest \u00fcber die letzten rund 120 Jahre l\u00e4sst sich ohne Z\u00f6gern die Aussage treffen, dass die Kurse im langfristi-gen Mittel permanent steigen. Diese Trendkom-ponente wird auch als Basistrend bezeichnet und stellt so gesehen eine Best\u00e4tigung der von Andr\u00e9 Kostolany zugeschriebenen B\u00f6rsenweis-heit \u201eKaufen Sie Aktien, nehmen Sie Schlafta- bletten, und schauen Sie die Papiere nicht mehr an. Nach vielen Jahren werden Sie sehen: Sie sind reich.\u201c \nWer allerdings auf dem Hochpunkt der Aktien-\nhausse im Jahr 1929 mit dieser Strategie inves-tiert hatte, musste fast drei\u00dfig Jahre warten, um auch nur seinen Einstandskurs wieder zu sehen. Gleiches gilt f\u00fcr eine Investition ab Mit-te der 1960er Jahre. Erst ab 1982 l\u00f6sten sich die Kurse aus der fast zwei Jahrzehnte dauern-den Seitw\u00e4rtsbewegung und setzten zu einem riesigen heute noch andauernden Kursschub an \u2013 von rund 1.050 Punkten im Jahr 1982 bis auf mehr als 26.000 Punkte im Jahr 2018. Weder der Finanzderivaten zugeschriebene \u201eCrash\u201c im Jahr 1987 oder das \u201ePlatzen\u201c der Dot-Com-Blase Anfang des Jahres 2000, noch die Finanzkrise im Jahr 2008 haben dazu ge-f\u00fchrt, dass sich diese Entwicklung umkehrt. Aus langfristiger Sicht heraus waren dies viel-mehr nur verh\u00e4ltnism\u00e4\u00dfig kurze Episoden, an \nAbb. 1: Dow Jones Industrial Average 1896 bis 2018  \nQuelle: Indexdaten von https://stooq.com/q/d/?s=%5Edji&c=0 [Zugriff am 22.2.2018].\nInnovationen im Spiegel der langfristigen Aktienkursentwicklung \u00a7  93\nwelche im Anschluss die Kurse mit unvermin-\nderter Dynamik wieder nach oben kletterten. Offensichtlich lassen sich diese Entwicklungen nicht mehr allein mit klassisch konjunkturell bedingten Ver\u00e4nderungen erkl\u00e4ren. Es scheint vielmehr Marktkonstellationen zu geben, in denen sich die Ertragskraft einer Vielzahl von Unternehmen abseits von Einflussfaktoren, wie etwa Arbeitskosten, Rohstoffpreisen etc. so enorm steigert, dass die Bewertung von Unternehmen innerhalb weniger Jahre um den Faktor 10 oder mehr angehoben wird.\nInnovationen als Treiber der Langen Wellen\nAls Ursache f\u00fcr die beobachtbaren Phasen eines enormen Wachstums der Unterneh-mensgewinne kann auf die Arbeiten von Jo-seph Schumpeter zur\u00fcckgegriffen werden, der wiederum mit seinen \u00dcberlegungen auf der Beobachtung von Nikolaj Kondratieff zur wirtschaftlichen Entwicklung in sogenannten  Langen Wellen aufsetzte. Im Unterschied zu Kondratieff sah Schumpeter allerdings Inno-vationen als deren wesentlichen Einflussfak-tor und den dynamischen Unternehmer als Tr\u00e4ger der Diffusion von Innovationen in das aktuelle wirtschaftliche und gesellschaftliche Umfeld. Lange Wellen werden im Vorstel-lungsmodell von Schumpeter durch epochale technische Innovationen bestimmt, die von Gerhard Mensch sp\u00e4ter als Basisinnovationen bezeichnet wurden.\n5 Statt des sinusf\u00f6rmigen \nZyklusverlaufs im Modell von Schumpeter for -\nmulierte Mensch6 weiterhin ein Metamorpho-\nse-Modell, nach dem Basisinnovationen eine schubweise Entwicklung der Wirtschaft verur -\nsachen. Ohne im Weiteren auf die in diesem Zusammenhang existierende umfangreiche wirtschafts- und auch sozialwissenschaftliche Diskussion eingehen zu k\u00f6nnen, l\u00e4sst sich als kleinster gemeinsamer Nenner jedenfalls eine Unterscheidung in eine Phase \u201eAufschwung mit wachsender Prosperit\u00e4t und einigen re-zessiven Momenten\u201c und eine Phase \u201eAb-schwung mit allgemein abnehmenden \u00f6kono-mischen Aktivit\u00e4ten\u201c vornehmen.\n7\nAbb. 2: Kondratieff-Zyklen 1830 bis heute. Die orange eingezeichneten Swings deuten die Phase \u201eAufschwung mit wachsender \nProsperit\u00e4t und einigen rezessiven Momenten\u201c an. Quelle: DJIA. https://de.wikipedia.org/wiki/Dow_Jones_Industrial_Average [Zugriff am 15.4.2018].94 \nDie in Abbildung 2 gezeigten f\u00fcnf Kondra-\ntieff-Zyklen sind eine h\u00e4ufig anzutreffende Einteilung, die sich im Wesentlichen mit den Langen Wellen der Aktienkursentwicklung deckt. Danach w\u00fcrde die erste Welle bestimmt durch die Entwicklung der Dampfmaschine und M\u00f6glichkeit zur massenhaften Produktion von Baumwolle, die zweite Welle durch die Innova-tionen im Transportwesen mit der Entwicklung der dampfgetriebenen Eisenbahn sowie die Fortschritte bei der Stahlproduktion. Die dritte Welle war haupts\u00e4chlich getrieben durch In-novationen auf dem Gebiet der Elektrotechnik und der Chemie, w\u00e4hrend der Treiber f\u00fcr die vierte Welle die Massenmotorisierung sowie die Petrochemie waren. Von herausragender Be-deutung f\u00fcr die Ausbildung der f\u00fcnften Welle sind s\u00e4mtliche Innovationen im Zusammenhang mit der Informationstechnik.\nF\u00fcr die Darstellung der Kondratieff-Zyklen in \nAbbildung 2 haben wir die 10-j\u00e4hrigen Kursren-diten des DJIA verwendet, d. h. es wurde der Jahresendstand des Index von 1989 (= 2753) ins Verh\u00e4ltnis zu dem des Jahres 1980 (= 964) gesetzt und in Prozent ausgewiesen (= 186 Prozent). Die Indexdaten vor 1896 wurden auf der Grundlage der Kurse von einzelnen Aktien k\u00fcnstlich berechnet.\n8  Ferner ist zu ber\u00fccksichti-\ngen, dass die Wahl eines 10-Jahres-Zeitraumes f\u00fcr die Berechnung der Rendite willk\u00fcrlich ge-w\u00e4hlt ist und die Besonderheiten der Indexkon-struktion sowie auch dessen Zusammensetzung Einfluss auf dessen Verlauf haben. Die vorste-hende Tendenzaussage deckt sich aber mit de-nen anderer Autoren, deren Aussagen auf der Analyse ausgew\u00e4hlter gesamtwirtschaftlicher Gr\u00f6\u00dfen, wie zum Beispiel der Ver\u00e4nderungsrate des Bruttoinlandprodukts oder Au\u00dfenhandels-, Besch\u00e4ftigungs-, Investitions- und Produktions-daten fu\u00dfen.\n9  \nDer \u00dcbergang vom 4. auf den 5. Kondratieff sowie die \u00dcberlagerung dieser Entwicklung durch andere Megatrends l\u00e4sst sich auch an der Marktkapitalisierung der wertvollsten Unter -\nnehmen nach Branchen ablesen. So dominier -\nte in den 1980er Jahren noch die Energie- und \nAbb. 3: Marktkapitalisierung der 15 wertvollsten Unternehmen weltweit nach Branchen.  \nQuelle: Eigene Analyse auf der Grundlage der Daten von Portfolio Institutionell. www.portfolio-institutionell.de/fileadmin/user_upload/portfolio-international/pit_10_13_grafik_fullpage_28.pdf.  [Zugriff am 15.4.2018].\nInnovationen im Spiegel der langfristigen Aktienkursentwicklung \u00a7  95\nVersorgungsbranche im Zuge des ausklingen-\nden 4. Kondratieff deutlich vor allen anderen Branchen. Die Informations- und Kommuni-kationstechnologiebranche zeigte zu diesem Zeitpunkt immerhin schon einen Anteil von etwas mehr als 15 Prozent und nahm in den folgenden 20 Jahren stetig zu. Der gro\u00dfe Anteil des Finanzsektors 1990 ist insbesondere auf ja-panische Banken zur\u00fcckzuf\u00fchren, die befeuert durch die dortige riesige Immobilien- und Ak-tienmarktblase eine extrem hohe Marktkapita-lisierung aufwiesen. Der scheinbare R\u00fcckgang des IKT-Sektors im Jahr 2010 ist letztlich nur ein relativer, der durch den Megatrend \u201eWirt-schaftswachstum in China\u201c und den damit ein-hergehenden \u201eRessourcenhunger\u201c zu erkl\u00e4ren ist. Dies bedingte einen enormen Anstieg auch der \u00d6lpreise, und eine deutlich h\u00f6here Bewer -\ntung von Unternehmen des Energiesektors. \nIm Jahr 2017 haben die Big 5 der IKT-Branche \nApple, Alphabet (Google), Amazon, Facebook und Microsoft den Anteil, wie ihn die Ener -\ngie- und Versorgungsunternehmen Anfang der 1980er Jahre mit Ausklingen des 4. Kondra-tieff-Zyklus hatten. Angesichts der ungeheuren globalen Marktmacht der Big 5-Unternehmen gibt es inzwischen vermehrt Rufe nach deren Aufspaltung.\n10\nWas macht eine Innovation \nzur Basisinnovation?\nWelches sind aber nun die Merkmale, die In-\nnovationen auszeichnen m\u00fcssen, um als Ba-sisinnovation und damit als Treiber eines lang anhaltenden Wachstumspfades der wirtschaft-lichen Entwicklung zu dienen? Dazu folgen wir den \u00dcberlegungen des britischen Konjunk-turforschers Christopher Freeman\n11, wonach \ndas zentrale Merkmal einer Basisinnovation darin begr\u00fcndet ist, dass diese ein neues tech-nologisches Paradigma in einem f\u00fchrenden Sektor begr\u00fcndet, welches sich in Form von sekund\u00e4ren Folgewellen auf die gesamte In-dustrie und Wertsch\u00f6pfung einer Volkswirt-schaft ausbreitet. Im Zuge dieses von ihm als Diffusion bezeichneten Prozesses kommt es zu umfangreichen Anschluss-, Verbesserungs- und Erweiterungsinnovationen, was einher -\ngeht mit der Herausbildung neuer Absatz- und Beschaffungsm\u00e4rkte, einem beschleunigten Wirtschaftswachstum und der Ausbildung von verwandten Innovationen, denen Freeman die Bezeichnung \u201eNeue technologische Systeme\u201c gab. Die Bildung dieser technologischen Sys-teme wird von Freeman auch als Schwarmbil-dung bezeichnet und spielt zusammen mit dem \u201eBandwagon-Effekt\u201c die entscheidende Rolle f\u00fcr das starke Wachstum. Der Bandwagon-Ef-fekt beschreibt das Ph\u00e4nomen, dass immer mehr Investoren die technologischen Neuerun-gen weiterentwickeln und neue Anwendungs-felder erschlie\u00dfen. Abbildung 4 zeigt den Dif-fusionsprozess und die Neuen Technologischen Systeme am Beispiel des 1. Kondratieff.\nIm Mittelpunkt des 1. Kondratieff-Zyklus, der \nvon England als \u201eleading country\u201c ausging, stand die Basisinnovation \u201eDampfmaschine\u201c, die in Kombination mit dem mechanischen Webstuhl und der neu entwickelten Organi-sationsform \u201eFabrik\u201c erstmals eine industriel-le Massenfertigung von Textilien erm\u00f6glichte. Dampfgetriebene Webmaschinen waren um den Faktor 20 produktiver als die Konkurrenz im Ausland, Spinnmaschinen sogar um den Faktor 200. England wurde durch diese Pro-duktivit\u00e4tsspr\u00fcnge in k\u00fcrzester Zeit zum Global Player und zur industriellen Gro\u00dfmacht, ver -\ngleichbar mit dem heutigen Status der USA. Die Basisinnovation \u201eDampfmaschine\u201c war zwar die Initialz\u00fcndung, h\u00e4tte aber f\u00fcr sich allein ge-nommen nur wenig bewirkt. Es war vielmehr die Diffusion in vorgelagerte und anwendende Branchen, die den breit angelegten wirtschaft-lichen Aufschwung einleitete. Neben der Textil-industrie, die zu dieser Zeit fast dreimal so gro\u00df war wie die Schwerindustrie, profitierte der Maschinenbau (Antrieb f\u00fcr Bohr-, Dreh- und Fr\u00e4smaschinen), die H\u00fcttentechnik (Antrieb von Gebl\u00e4sen), die Metallumformtechnik (Walzen-96 \nnantrieb) und der Bergbau (Antrieb von Pum-\npen).12 Um die G\u00fcter von und zu den Fabriken \nund H\u00e4fen zu transportieren entstand zu dieser Zeit weiterhin ein umfangreiches Netz von Ka-n\u00e4len und Schleusen, die mit normierten Nar -\nrowboats betrieben wurden, die allerdings den enorm gestiegenen Bedarf an Transportleistung kaum bew\u00e4ltigen konnten. \nVon der Eisenbahn zum Personalcomputer \nund Internet\nIn der Regel entfaltet nicht eine einzelne Innova-\ntion einen breiten Aufschwung. Stattdessen ist es oftmals erst das Zusammenwirken mehrerer teils schon l\u00e4nger existierender Basisinnovatio-nen in Produkte, die einen latent vorhandenen breiten Bedarf scheinbar pl\u00f6tzlich decken. Ver -\ngleichbar mit dem starken Aufschwung der Tex-tilindustrie durch die Kombination der bereits existierenden Innovation \u201eMechanischer Web-stuhl\u201c mit der neu entstandenen Basisinnovati-on \u201eDampfmaschine\u201c war auch die Revolution im Transportwesen mit der Entwicklung der dampfgetriebenen Eisenbahn eine Kombinati-on von bereits vorhandenen und neuen tech-nologischen Entwicklungen im Sinne eines eher evolutorischen Prozesses. Dieser begann bereits im 16. Jahrhundert mit der Entwicklung von auf Holzschienen gef\u00fchrten Loren in den Gold-minen von Transsilvanien zum Transport von Ger\u00f6ll und Erz innerhalb der Bergwerke sowie zu den Verladestellen. Die Technik wurde von deutschen Bergwerksbetrieben im Erzgebirge adaptiert und verbreitete sich von dort nach ganz Europa\n13. Im 18. Jahrhundert wurden \ndann die ersten gusseisernen Winkelschienen f\u00fcr die Benutzung durch gew\u00f6hnliche Pferde-fuhrwerke auf besonders gef\u00e4hrlichen Stre-ckenabschnitten eingef\u00fchrt. Schon bald reifte auch der Gedanke, statt Pferden die Dampfma-schine als Antriebsquelle zu nutzen. Abb. 4: Technologisches System und Diffusion nach Freeman am Beispiel des 1. Kondratieff  \nQuelle: Wright, N. (2014): Die Wiederentdeckung Kondratieffs, Hamburg, S. 50.Dampfschiff\nEisen\nEisenh\u00fctten-\ntechnik\nStahl\nEisenformung\nGeb\u00e4ude/Br\u00fcckenMaschinenbauMetallbearbeitungMaterial\nMaterialGebl\u00e4se \nWalzenantrieb/\nUmformtechnik\nTextilindustrieEnergie\nEnergieKohlef\u00f6rderungKoks\nSchienenDampfmaschine\nAntriebLokomotive\nPumpen\nEnergieEisenschienen\nMetal working Innovationen im Spiegel der langfristigen Aktienkursentwicklung \u00a7  97\nObwohl aber bereits 1783 die Entwicklung ge-\nlang, die Kolbenbewegung der Dampfmaschine in eine Achsantriebskraft zu wandeln, dauert es noch bis zum Jahr 1825, bis in Gro\u00dfbritannien die erste \u00f6ffentliche Eisenbahn auf der Strecke Stockton-Darlington in Betrieb genommen wur -\nde. Voraussetzungen daf\u00fcr waren die Entwick-lung eines Antriebssystem f\u00fcr die R\u00e4der aus Kurbelzapfen und Stangen, welches deutlich zuverl\u00e4ssiger war als die bis dahin vorherrschen-den komplizierten Getriebekonstruktionen \u2013 re-volution\u00e4re Fortschritte in der Dampftechnolo-gie, die einen enormen Leistungszuwachs zur Folge hatten sowie insbesondere auch die deut-lich verbesserte Technologie bei der Herstellung von Schienen. Es war mithin also erst die Kom-bination einer Vielzahl von Faktoren, die den technologischen Durchbruch der Eisenbahn als massentaugliches Verkehrsmittel erm\u00f6glichte.\nDer wirtschaftliche Durchbruch der Eisenbahn \nlag insbesondere darin begr\u00fcndet, dass im Ver -\ngleich zu den Kosten der Narrowboats, die bis zu diesem Zeitpunkt in England \u00fcber ein weit verzweigtes Netz von Kan\u00e4len den Transport von Kohle, Eisen und anderen Masseng\u00fctern \u00fcbernommen hatten, die Verkehrswege deut-lich einfacher und kosteng\u00fcnstiger zu bauen waren und zum anderen deutlich gr\u00f6\u00dfere G\u00fc-termengen \u00fcber weitere Strecken schnell be-wegt werden konnten. Die Kursentwicklung der Eisenbahnaktien zeigt sehr anschaulich, dass sich die technologische Entwicklung, die wirtschaftliche Nutzbarmachung und auch die gesellschaftliche Akzeptanz in mehreren gro-\u00dfen Sch\u00fcben vollzogen haben:\nDie Strecke Stockton \u2013 Darlington war die erste \nauf \u00f6ffentlichem Boden betriebene Eisenbahn-verbindung und diente ausschlie\u00dflich der An-bindung lokaler Kohlefelder an den Hafen von Stockton im Sinne einer Erg\u00e4nzung der Kanal-schifffahrt. Auch die in der Folge gebaute Ver -\nbindung von Manchester nach Liverpool war anfangs rein f\u00fcr den G\u00fcterverkehr gedacht; wurde sp\u00e4ter aber auch f\u00fcr den Personenver -\nAbb. 5: Innovationssch\u00fcbe und Kursentwicklung im 2. Kondratieff am Beispiel der Entwicklung von englischen Eisenbahnaktien. \nQuelle: Gayer/Rostow/Schwartz (1975): The Growth and the Fluctuation of the British Economy 1790 \u2013 1850. A historical  statistical and theoretical Study of Britain\u2019s Economic Delvelopement, 2. Auflage, Hassocks, S. 373.\n98 \nkehr ge\u00f6ffnet. Entgegen allen Erwartungen \nwar es der Personenverkehr, der die zweite starke Wachstumsphase einl\u00e4utete. So wuchs die Transportleistung allein auf dieser Stre-cke von j\u00e4hrlich 180.000 Kutschenfahrg\u00e4sten auf 445.000 Reisende mit der Eisenbahn. Die  \nEisenbahn reduzierte die Reisekosten gegen-\u00fcber der Kutsche um 50 Prozent, die Fahrzeit um fast 75 Prozent und gew\u00e4hrte gleichzei-tig ein deutlich h\u00f6heres Ma\u00df an Sicherheit.  \nEinen weiteren gro\u00dfen Schub erfuhr die Wirt-schaft durch die Entstehung \u00fcberregionaler Eisenbahnsysteme. Alleine von 1841 bis 1850 wurden in Gro\u00dfbritannien \u00fcber 5.000 Meilen Schienennetz neu er\u00f6ffnet. Die Entwicklung setzte sich in Wellen fort, das Wachstum blieb ph\u00e4nomenal. Betrug das Passagieraufkommen allein in Gro\u00dfbritannien um 1850 bereits 80 Millionen, so waren es 1880 bereits 600 Milli-onen und 1900 mehr als 1 Milliarde Passagiere j\u00e4hrlich. \nBlicken wir noch mal zusammenfassend auf die \nIngredienzien des 2. Kondratieff: Es gab eine bislang fast ausschlie\u00dflich station\u00e4r betriebene Kraftquelle in Form der Dampfmaschine, es gab Loren auf Holzschienen zum Abraumtransport in den Bergwerken, es gab Fortschritte in der Eisenh\u00fcttentechnik und es gab einen perma-nent wachsenden Bedarf an Transportleistung, der mit den bestehenden Mitteln nicht mehr gedeckt werden konnte. \nSpringen wir nun in das Jahr 1980: Das Bild des \nComputers in der \u00d6ffentlichkeit war das von riesigen Apparaten, die nur von einem ganzen Team von Technikern und hochqualifizierten Maschinenbedienern (Operator) betrieben wer -\nden konnten und dar\u00fcber hinaus extrem teuer waren. Sowohl die Programmierer als auch die Endanwender konnten nicht in direkte Interak-tion mit dem Computer treten, sondern muss-ten \u00fcber zeitaufw\u00e4ndige Routinen die Eingaben und Ausgaben des Computers beim Operator in Auftrag geben. Dies war letztlich auch dem m\u00f6glichst wirtschaftlichen Betrieb dieser An-lagen geschuldet, die rund um die Uhr ausge-lastet werden sollten und daher \u00fcber die soge-nannte Stapelverarbeitung betrieben wurden.\n14 \nDas bis weit in die 1970er-Jahre hineinreichen-de kulturelle Leitbild, mit dem man \u00fcblicherwei-se auf diese Maschinen schaute war also sehr \u00e4hnlich dem der Dampfmaschine als station\u00e4r betriebene Gro\u00dfanlage.\nDie Ideengeschichte des Personalcomputers \nund des Internets, und damit der Beginn des f\u00fcnften Kondratieff, wird neben der Entwick-lung des elektronischen Digitalcomputers in den 1940er Jahren durch zwei weitere wichtige Entwicklungen gepr\u00e4gt. So beschrieb bereits 1945 der Analogrechenpionier V. Bush detail-liert, wie Menschen mit einer informationsver -\narbeitenden Maschine arbeiten und vor allem auch in Interaktion treten k\u00f6nnten. Der von ihm vorgestellte Memory Extender wurde zwar nie realisiert, beeinflusste aber in den 1960er Jahren eine ganze Reihe von jungen Computer -\nwissenschaftlern bei ihrer Arbeit an neuen Sys-temen. Eine weitere sehr wichtige Entwicklung f\u00fcr das Verh\u00e4ltnis von Mensch zu Maschine war die Etablierung der Kybernetik als wissenschaft-liche Disziplin, bei der der Mensch nicht mehr nur das Anh\u00e4ngsel von linearen Ein- und Aus-gabeprozessen war, sondern als Element von Regelkreisen mit der Technologie interagieren sollte. Insbesondere auch die Anforderungen des Milit\u00e4rs f\u00fchrten dazu, dass bereits in die-ser Zeit erste Mensch-Computer-Schnittstellen entwickelt wurden, wie wir sie auch heute ken-nen. So gab es bereits zu dieser Zeit die ers-ten Bildschirmsysteme f\u00fcr Texte und Grafiken, einen sogenannten Lichtgriffel als Eingabeger\u00e4t f\u00fcr grafische Elemente sowie die von Engelbart bereits Anfang der 1960er Jahre vorgestellte Computermaus. \nDer Personalcomputer, wie wir ihn heute ken-\nnen, wurde vom Grundsatz her bereits 1973 am Xerox-Forschungszentrum Palo Alto Research Center (PARC) entwickelt. Die Arbeitsstation mit dem Arbeitstitel \u201eXerox Alto\u201c hatte ein objekt- orientiertes Betriebssystem, eine grafische Be-nutzeroberfl\u00e4che, die \u00fcber eine Computermaus angesteuert wurde, WYSIWYG-Funktionalit\u00e4-ten, Text- und Grafikbearbeitungsprogramme, Innovationen im Spiegel der langfristigen Aktienkursentwicklung \u00a7  99\neine Ethernet-Schnittstelle zur Vernetzung mit \nanderen Arbeitsstationen, eine Wechselfestplat-te und sogar eine Anbindung zu einem lokalen Laserdrucker. Diese Entwicklung war allerdings ein reines Forschungsprojekt einer Gruppe jun-ger interdisziplin\u00e4r arbeitender Wissenschaftler und blieb so weitestgehend unbekannt. Erst ab 1978 bot Xerox eine weiterentwickelte Version des Alto zu einem Preis von 32.000 US-Dollar an. In einem Zeitraum von zehn Jahren wurden ca. 2.000 St\u00fcck hergestellt, was nicht einmal ann\u00e4hernd die Dimensionen der sp\u00e4teren Ver -\nbreitung des PC erreichte.\nAuch der Computer-Riese IBM brachte im \nJahr 1975 ein eigenes System auf den Markt, scheiterte jedoch insbesondere wegen zu ho-her Verkaufspreise und daran, dass das System nicht erweiterbar war und die einzig verf\u00fcgba-re Software ausschlie\u00dflich von IBM stammte. Wesentlich erfolgreicher waren dagegen die Produkte aus der Hobbyistenszene, die Mik-rocomputer aus teils vorgefertigten Baus\u00e4tzen selbst bastelten. Anfangs wurde der Mikro-computer insbesondere als neuartiges Spielge-r\u00e4t gesehen, es gab aber Ende der 1970er Jah-re bereits erste B\u00fcroanwendungen f\u00fcr diese Ger\u00e4te, wie etwa den Apple II oder den Com-modore PET. Der Erfolg des Apple II sowie die Herausbildung einer Reihe von Software-Un-ternehmen f\u00fchrten schlie\u00dflich 1980 auch bei IBM zu der \u00dcberzeugung, dass es an der Zeit sei, sich mit diesem Marktsegment ernsthaft zu befassen. Insbesondere bei kleinen und mittleren Unternehmen bestand gro\u00dfer Bedarf an der elektronischen Unterst\u00fctzung ihrer Ge-sch\u00e4ftsprozesse, der insbesondere durch die zu dieser Zeit aufkommenden ersten Tabellenkal-kulations- und Textverarbeitungsprogramme geweckt wurde. IBM beschritt bei der Neu-konzeption des IBM-PC diesmal einen v\u00f6llig anderen Weg: Der Preis wurde konkurrenz-f\u00e4hig angesetzt, es wurden handels\u00fcbliche Komponenten verwendet, neue Funktionen oder leistungsf\u00e4higere Komponenten konn-ten durch Steckkarten nachger\u00fcstet werden und das zum Einsatz kommende Betriebssys-tem MS-DOS durfte vom Hersteller Microsoft auch an andere lizenziert werden. Der IBM-PC wurde vom Fleck weg ein unglaublicher Er -\nfolg und schuf einen Quasi-Standard f\u00fcr den kompletten Markt der Mikrocomputer, dem sich alle anderen Anbieter mit Ausnahme von Apple anschlossen. Offener Industriestandard, handels\u00fcbliche Komponenten und eine breite herstellerunabh\u00e4ngige Software-Basis legen den Grundstein f\u00fcr den Massenmarkt der Ar -\nbeitsplatzrechner.\n15\nZu dieser Zeit startete Apple den Prozess, ei-nen Nachfolger f\u00fcr den erfolgreichen Apple II zu entwickeln. Bislang waren dessen K\u00e4ufer fast ausschlie\u00dflich Bastler, Privatanwender und Schulen. F\u00fcr das Nachfolgemodell sollte der Einstieg in das schnell wachsende Gesch\u00e4ft mit B\u00fcrocomputern gefunden werden. Einigen Mitarbeitern bei Apple waren die Arbeiten im PARC von Xerox bekannt und es gelang ihnen zwei Besichtigungstermine zu bekommen. Als Steve Jobs die grafische Benutzeroberfl\u00e4che sowie die \u00fcber eine Maus gesteuerte Eingabe des Xerox Alto sah, wurde ihm innerhalb von Minuten klar, wie in einer sehr nahen Zukunft Personalcomputer funktionieren w\u00fcrden. Die Einf\u00fchrung der grafischen Benutzeroberfl\u00e4-che f\u00fcr Personalcomputer durch Apple wurde  \nAbb. 6: Vorl\u00e4ufer des Personalcomputers von Xerox Anfang \nder 1970er Jahre100 \nschlie\u00dflich Mitte der 1980er Jahre durch \nMicrosoft unter dem Namen Windows \u00fcber -\nnommen und stellt bis heute den Industrie-  \nstandard dar. \nGenauso fortschrittlich wie die grafische Benut-\nzeroberfl\u00e4che des Xerox Alto war auch der Ge-danke, einen Laserdrucker als Bestandteil des PC-Arbeitsplatzes anzusehen. In den 1960er und 1970er Jahren beherrschten laut arbeiten-de Nadel- und Typenraddrucker die B\u00fcros und Institute, Grafiken wurden mit sogenannten Plottern erstellt. Professionelle Laserdrucker kosteten mehrere 100.000 US-Dollar. 1984 brachte HP mit dem LaserJet den ersten Desk-top-Laserdrucker der Welt auf den Markt. Der Preis lag bei ca. 3.500 US-Dollar. Hintergrund f\u00fcr diese Entwicklung war die L\u00f6sung des Prob-lems, den Laserstrahl zu modulieren. Zu Zeiten der ersten Laserdrucker kannte man nur gro\u00dfe und teure Gaslaser, deren Licht nicht schnell moduliert werden konnte. Sie erforderten kom-plizierte mechanische Optiken um das Laser -\nlicht abzulenken. Erst die sp\u00e4tere Entwicklung der Halbleiterlaser erm\u00f6glichte die einfache und kosteng\u00fcnstige Modulation des Lichtes und damit um Gr\u00f6\u00dfenordnung niedrigere Herstel-lungskosten bei ebenso dramatisch geringeren Abmessungen, die in jedem B\u00fcro Platz fanden. \nAuch hier ging mit der Halbleitertechnologie \neine Basisinnovation voraus, die Anfang der 50er Jahre mit den ersten Transistoren ihren Anfang nahm. Erst 20 Jahre sp\u00e4ter gelang es Gruppen in der Sowjetunion und den USA na-hezu zeitgleich, kleine Halbleiterlaser zu reali-sieren, die ohne aufw\u00e4ndige K\u00fchlung in Kon-sumelektroniken eingesetzt werden konnten. Alfjorow und Kroemer erhielten daf\u00fcr im Jahr 2000 den Nobelpreis in Physik.  \nDie grafische Benutzeroberfl\u00e4che legte schlie\u00df-\nlich auch den Grundstein f\u00fcr den zweiten gr\u00f6-\u00dferen Wachstumsschub im Zusammenhang mit der Digitalisierung. Nachdem der Personalcom-puter bereits Ende der 1980er Jahre an praktisch jedem B\u00fcroarbeitsplatz zu finden war, entstand zunehmend der Bedarf nach deren Vernet-zung. Wie der Digitalcomputer selbst, war auch der Gedanke der Vernetzung bereits in den 1940er Jahren entstanden. Wie beim Compu-ter war die Umgestaltung der Mensch-Com-puter-Schnittstelle der Moment, als das, was heute als Internet integraler Bestandteil unseres privaten und beruflichen Lebens geworden ist, seinen Durchbruch erlebte. Im Jahre 1993 wur -\nde der erste Web-Browser unter dem Namen Mosaic vorgestellt, der Text und Grafik einer HTML-Seite integriert unter einer grafischen Benutzeroberfl\u00e4che darstellte.\n16 Damit war es \nauch dem technischen Laien ohne weiteres m\u00f6glich, die Funktionen des Internet in vollem Umfang zu nutzen. In der Folge wuchs auch die Anzahl privater Nutzer von Personalcomputern und des Internets explosionsartig. Im Jahr 1995 startet schlie\u00dflich Amazon.com als reiner On-line-H\u00e4ndler neben vielen anderen in dieser Zeit entstandenen Gesch\u00e4ftsideen. \nDie ab Anfang der 1990er Jahre einsetzen-\nde Euphorie ist durchaus vergleichbar mit der \u201eRailway-Mania\u201c ab den 1830er Jahren. Die B\u00f6rsenkurse der Unternehmen, die direkt oder auch nur indirekt mit der Internet-\u00d6konomie in Verbindung gebracht wurden, erreichten Gr\u00f6\u00dfenordnungen, die selbst mit den optimis-tischsten Annahmen nicht mehr in Einklang zu bringen waren. Nach dem starken Kursanstieg in den 1980er Jahren und dem nochmals be-schleunigten Wachstum der Kurse bis zum Jahr 2000 setzte im Zuge des Platzen der DotCom- Blase eine deutliche Marktbereinigung ein. Heute, fast zwei Jahrzehnte sp\u00e4ter, zeigt sich aber auch, dass die Visionen und auch das pro-gnostizierte Umsatz- und Ertragspotenzial eini-ger Ideen, wie beispielsweise des Internet-Kauf-hauses, durchaus Substanz hatten. Es fehlten zur damaligen Zeit nur die technischen und infrastrukturellen Voraussetzungen in Form von ausreichender Bandbreite und damit Transakti-onsgeschwindigkeit, um den sofortigen Durch-bruch zu erm\u00f6glichen.\nAuch dem unzweifelhaft unser Arbeits- wie \nauch Privatleben pr\u00e4genden Hype der Smart-phones ging nicht eine einzelne Innovation vo-Innovationen im Spiegel der langfristigen Aktienkursentwicklung \u00a7  101\nraus. Die Kombination aus Basisinnovation wie \nder Mikroelektronik und zahlreichen teilweise daraus abgeleiteten \u2013 weiteren Innovationen wie Displaytechnologie, Wireless-Technologien, Breitband-Funknetze, Mikrosystemtechnik mit Mikrosensoren und Mikrooptiken sowie Lithi-um-Ionen-Akkus erm\u00f6glichte die nutzergerech-te technische Realisierung zu marktg\u00e4ngigen Preisen.\nDie solchen Produkten innewohnende Komple-\nxit\u00e4t f\u00fchrt zu der einen Erfolg insgesamt ein-schr\u00e4nkenden Bedingung, dass das Produkt nur so gut wie sein schw\u00e4chstes Glied sein kann. Auf das Smartphone angewandt wird deutlich, dass jede der genannten Teiltechnologien zu bestimmten Zeiten dieser limitierende Faktor war. Deutlich wird das exemplarisch an dem Vorl\u00e4ufer des heute fast als Goldstandard ge-feierten iPads. 1993\n17 pr\u00e4sentierte Apple-CEO \nJohn Scully stolz \u201eNewton ist hier! Das Zeitalter des PDA hat begonnen, eine Revolution f\u00fcr die Jackentasche\u201c. Tats\u00e4chlich war der Newton 19 cm hoch, zwei cm dick, 400 g schwer und kos-tete 700 Dollar. \nBereits damals kamen die noch heute verbrei-\nteten energiesparenden ARM-Chips zum Ein-satz, sie sind sozusagen die Komponente der Basisinnovation Mikroelektronik. Die Eingabe erfolgte durch einen Stift mittels wenig \u00fcber -\nzeugender Handschriftenerkennung.\n18 Doch \nwie das US-Magazin Home Office Computing schon 1994 schrieb: \u201eDie Menschen m\u00fcssten mit diesen Ger\u00e4ten \u00fcberall Daten senden und empfangen k\u00f6nnen (Texte, Faxe, vielleicht auch Audio- und Videodateien, Datenbanken aufru-fen und Online-Dienste nutzen k\u00f6nnen.\u201c Doch die gerade erst im Aufbau befindlichen Mobil-funknetze konnten das Senden und Empfangen von Daten mangels Bandbreite und Abdeckung nicht erf\u00fcllen: \u201eLeider ist das noch nicht m\u00f6g-lich. PDAs sind Hochgeschwindigkeitsz\u00fcge ohne Schienen.\u201c Apple war mit dem Newton zu fr\u00fch dran und stoppte 1998 die Produktion.\nUnd nicht nur die Technologie muss eine be-\nstimmte Reife erreichen, auch die Gesch\u00e4fts-modelle m\u00fcssen passen und auf entsprechende Akzeptanz sto\u00dfen. Diese Kombination erf\u00fcllt dann ein bisher nicht explizit ausgesproche-nes Bed\u00fcrfnis vieler Konsumenten. Auf unser Beispiel des Newton bezogen, kam neben den technischen Unzul\u00e4nglichkeiten auch Apples Festhalten an seiner Philosophie der in sich geschlossenen Apple- bzw. Mac-Welt. Alle Pe-ripherie und Software war propriet\u00e4r f\u00fcr die ei-genen Produkte. Daher gab es f\u00fcr den Newton nur eine sehr beschr\u00e4nkte Zahl von Program-men und damit Anwendungen. Ein limitieren-der Faktor, den Steve Jobs beim iPhone \u00fcber Bord warf. Mit dem f\u00fcr alle Entwickler weltweit offenen App-Store, eingebunden in die bereits zuvor f\u00fcr die Musikindustrie revolution\u00e4re iTu-nes-Plattform, wurden Kreativit\u00e4t und Anwen-dungen f\u00fcr das iPhone er\u00f6ffnet, die Apple allein niemals h\u00e4tte erfinden k\u00f6nnen. Das iPhone und sp\u00e4ter die anderen Smartphone-Plattformen wurden zur Basistechnologie f\u00fcr bisher unbe-kannte Bed\u00fcrfnisse und schafften Wertsch\u00f6p-fung weit \u00fcber den Verkauf reiner Hardware hinaus. Die Zeit war 2007 eben reif f\u00fcr diese Kombination aus Technologie, Infrastruktur und Gesch\u00e4ftsmodell. Sicherlich kam noch das ge-niale Marketing eines Steve Jobs hinzu, das f\u00fcr eine rasende Verbreitung sorgte und damit die neuen M\u00e4rkte mit sich zog.\nDie so geschaffenen Werte bilden sich nur 14 \nJahre nach der beinahe Pleite von Apple in dem Rang des seit 2011 wertvollsten Unternehmens \nAbb. 7: Newton (Revolution f\u00fcr die Jackentasche) im Vergleich \nzum iPhone \n102 \nder Welt ab. Die Dekade zuvor wurde von \nMicrosoft dominiert, das 1999 auf Rang 1 ge-langte. Dies war 1967 IBM gelungen, das erst rund 20 Jahre sp\u00e4ter diese Position an Microsoft abgab.\nFazit und Ausblick\nDie Auseinandersetzung mit historischen Ent-wicklungen f\u00fchrt nicht zu eindeutigen Zukunfts-prognosen \u2013 auch wir m\u00f6chten daher weder das Ende des f\u00fcnften noch den Beginn des sechsten Kondratieff-Zyklus ausrufen. In unseren Augen verdient aber die Verkn\u00fcpfung von Innovati-onsumfeld und Aktienmarktentwicklung noch st\u00e4rkere Aufmerksamkeit. Zwar sind auch Ak-tienmarktbewertungen nicht einfaktoriell und die M\u00e4rkte phasenweise durch \u00dcbertreibungen in beide Richtungen \u201everrauscht\u201c. Allerdings gilt auch, dass die Finanzm\u00e4rkte einschlie\u00dflich des Bereichs Venture Capital wohl die gr\u00f6\u00dften informationsverarbeitenden Systeme darstellen d\u00fcrften, bei denen mit Hilfe von Heerscharen von Banken, Unternehmensberatungen, Ana-lysten, Forschungseinrichtungen, Datenban-ken und Rechenleistung insbesondere auch der Antwort auf die eine Frage nachgegangen wird: Welches Unternehmen wird die n\u00e4chs-te IBM, Microsoft oder Apple? Insofern bietet es sich aus Sicht der Forschungsf\u00f6rderung an, mit wachem Auge auf die Entwicklungen im Finanzsektor zu schauen, um auch auf diesem Weg fr\u00fchzeitig Innovationsfelder oder sogar Basisinnovationen zu entdecken und entspre-chende Trends begleiten zu k\u00f6nnen.  Innovationen im Spiegel der langfristigen Aktienkursentwicklung \u00a7  103\n1 vgl . auch Friedewald, M. (1999): Die geistigen und technischen Wurzeln des Personalcomputers, S. 165.\n2 Hielscher , U.(1999): Investmentanalyse, 3. Aufl., M\u00fcnchen, S. 147.\n3 Es w \u00e4re nat\u00fcrlich zu kurz gesprungen, wollte man die Kursentwicklung von Aktien ausschlie\u00dflich auf einen oder wenige Faktoren reduzieren. \n Demogr\naphische Effekte, die Entstehung g\u00e4nzlich neuer M\u00e4rkte, wie durch die \u00d6ffnung und das enorme Wirtschaftswachstum Chinas in den \n letzten 25 J\nahren geschehen, fundamentale \u00c4nderungen im Finanzsystem oder das Herausbilden gesamtgesellschaftlicher Megatrends, wie \n z.\n B. Gesundheit, \u00f6kologische Lebensweise etc. haben nat\u00fcrlich ebenfalls Einfluss auf die Ertragslage der Unternehmen. Dennoch konnte \u00fcber \n die letzten 200 J\nahre immer wieder ein auff\u00e4lliger Zusammenhang zwischen Innovationen und einer nachhaltig starken Aktien-Gesamtmarkt-\n entwicklung beobachtet werden.\n4 Der DJIA umfasst drei\u00dfig an der New Yorker Stock Exchange gelistete Aktien von global agierenden Unternehmen aus einer Vielzahl von \n Br\nanchen. Im Jahr 2018 war nur noch ein Unternehmen im Index vertreten, das auch bei der ersten Berechnung im Jahre 1896 schon be-\n r\u00fccksichtigt wurde\n, n\u00e4mlich die von Thomas Edison gegr\u00fcndete General Electric Company. Es kann gezeigt werden, dass unter Auslassung \n der Kriegsjahre 1914 \u2013 1924 und 1940 \u2013 1949 die K\nursentwicklung des DJIA weitestgehend Deckungsgleich mit der des deutschen Aktien-\n marktes ist,\n vgl. Hielscher, U. (1999).\n5 Kretschmann,  D. (2014): Die langen Wellen der Konjunktur, Ansbach, S. 38-39.\n6 Im Gegensatz zu Schumpeters Theorie sieht Mensch den Ursprung eines neuen Kondratjeff-Zyklus nicht in der Phase des wirtschaftlichen \n Gleichgewichts\n, sondern in der Depression. Hier wollen die Unternehmer die Tristesse dieses Zustandes nicht mehr hinnehmen und f\u00fchren \n Basisinnov\nationen durch. Dadurch kommt es in der Depressionsphase zu einem schubweisen Entstehen von Basisinnovationen, was schlie\u00dflich \n zu einer neuen \nAufschwungphase f\u00fchrt. In dieser lassen die Innovationen stetig nach. Der Mangel an Innovationen f\u00fchrt schlie\u00dflich wieder in \n eine neue Depression,\n in der dann wieder ein neuer Aufschwung beginnen kann. Vgl. https://de.wikipedia.org/wiki/Kondratjew-Zyklus \n [Zugriff am 31.3.2018].\n7 Gr \u00e4be, H.-G. (2013): Lange Wellen und globale Krise, in: Sozial.Geschichte Online 11, http://www.stiftung-sozialgeschichte.de, 2013, S. 60.\n8 vgl . Stock Price Record, by Months, 1789 to Date,: Cycles Magazine, Foundation for the Study of Cycles, 1965, Bd. 16, S. 162.\n https://de\n.wikipedia.org/wiki/Dow_Jones_Industrial_Average [Zugriff am 31.3.2018].\n9 vgl . Kretschmann, D. (2014): Die langen Wellen der Konjunktur, Ansbach, S. 34-50.\n10 vgl . z. B. Macrons d\u00fcstere Prognose: \u201eWacht auf. Sie sind zu gro\u00df.\u201c, www.faz.net/aktuell/wirtschaft/diginomics/macron-facebook-und-\n google-k\noennten-zu-gross-werden-15522240.html?GEPC;s5 [Zugriff am 2.4.2018].\n11 Wright,  N.: Die Wiederentdeckung Kondratieffs, S. 48.\n12 Nefiodow , L.(2000): Der sechste Kondratieff, Bonn, S. 229.\n13 vgl . Hielscher, U. (2001): The Emergence of the Railway in Britain, London, S. 11.\n14 vgl . zur Entwicklungsgeschichte des Computers insb. auch Friedewald, M.: Die geistigen und technischen Wurzeln des Personal Computers, \n S\n. 166-171.\n15 vgl . Universit\u00e4t Erlangen, Fundst\u00fccke aus ISER BI86 \u2013 12/2011: Drei\u00dfig Jahre IBM Personal Computer, S. 68-70.\n16 vgl . Das erste Steinchen \u2013 Happy Birthday: Der Mosaic-Browser ist zehn Jahre alt, www.heise.de/ct/artikel/Das-erste-Steinchen-288826.html \n [Zugriff am 29.3.2018].\n17 Die Entwicklung des Newton Message P ad hatte Apple intern bereits 1987 gestartet. Wirtschaftlich wurde der Newton f\u00fcr Apple zu einem \n Desaster und k\nostete Scully seinen Job. Steve Jobs kehrte 1996 zu Apple zur\u00fcck.\n18 Scully: \u201eZukunft des Computings\u201c,  Jobs bei der Vorstellung des iPhones \u201eWer braucht noch einen Stylus? Wir haben selbst die zehn besten \n Eingabeger\n\u00e4te an uns \u2013 unsere Finger!\u201c104 \nInnovation f\u00fcr schnelle Prozessoren \nWie die EUV-Lithographie von Europa aus vom Mythos zur Praxis wird  \n  \nDr.  Antonia Schmalz\nNachdem Prometheus aus dem G\u00f6tterge-\nschlecht der Titanen die Erde betreten hatte, formte er aus dem Ton der Erde die Menschen. Er lehrte sie verschiedene Handwerke, Buchsta-ben und Zahlen, die Wirkung von Heilmitteln, den Lauf der Gestirne und vieles mehr. Zur Voll-endung ihrer Zivilisation, ihrer Kultur und ihrer Wissenschaft brachte er ihnen das Feuer, das er heimlich von den G\u00f6ttern entwendet hat-te. Doch dieser Raub erz\u00fcrnte den G\u00f6ttervater Zeus. Die allzu forsche und gierige Nutzung ih-rer neuen F\u00e4higkeiten und die daraus entstan-dene Technologia, die schon fast den K\u00fcnsten und Kr\u00e4ften der G\u00f6tter glich, war ihm schon lange ein Dorn im Auge. So ersann er eine Stra-fe, die den Menschen ihre uners\u00e4ttliche Gier zum Zwang und zur Last machen sollte. Fortan mussten die Menschen im Schwei\u00dfe ihres An-gesichts ewiglich die Technologia so weiter ent-wickeln, dass binnen zwei Jahren die von den Menschen als \u201eSchaltkreise\u201c und \u201eProzessoren\u201c bezeichneten Treiber der Technologia ihre Per -\nformanz verdoppelten.\nAnfangs verzweifelten die Menschen an der \nunl\u00f6sbar scheinenden Aufgabe. Man stelle sich im Vergleich nur vor, die Automobilindustrie solle pl\u00f6tzlich in einem Zwei-Jahresrhythmus den Aussto\u00df an Luftschadstoffen halbieren. Doch schnell stellten die Menschen fest, dass die \u201eMooresches Gesetz\u201c getaufte Forderung auch in ihrem eigenen \u00f6konomischen Kreislauf Sinn ergab. Alle 18 bis 24 Monate soll sich dem-nach die Anzahl der Schaltelemente in einem Prozessor-Chip verdoppeln (Abbildung 1). Da die Herstellungskosten im Wesentlichen mit der Fl\u00e4che skalieren, kann man so bei gleicher Leistung Fl\u00e4che und damit Kosten sparen oder bei gleichem Preis die Leistung erh\u00f6hen. Beide Aspekte zusammen mit einem typischerweise geringeren Stromverbrauch der neuen Techno-logien k\u00f6nnen zu neuen Anwendungen f\u00fchren und damit den Markt f\u00fcr Prozessoren weiter vergr\u00f6\u00dfern. Ein Teil der so erzielten Gewinne kann dann wieder investiert werden, um die immensen Kosten f\u00fcr Forschung und Anschaf-fungen zur Umsetzung des n\u00e4chsten Technolo-giesprungs zu finanzieren. \nDurch diese Erkenntnis auch aus eigenem An-\ntrieb motiviert gingen die Menschen gemeinsam mit ihrem Besch\u00fctzer Prometheus, dessen Name \u201eder Vorausdenkende\u201c bedeutet, die giganti-sche Aufgabe mit einem ausgereiften Plan an.\nDer Kreislauf konnte nur funktionieren wenn \nalle Akteure abgestimmt handelten und da-durch auch eine Planungssicherheit bekamen. So schufen die Menschen die International Technology Roadmap for Semiconductors (ITRS), in der die technischen Ziele und Beitr\u00e4ge mit den Technologieforschern, den Herstellern der Fertigungsanlagen sowie den Halbleiterher -\nstellern, die die verschiedensten Chips fertigen, und auch den Anwendern f\u00fcr Jahre im Voraus abgestimmt und regelm\u00e4\u00dfig aktualisiert wer -\nden. Jeder neue \u201eTechnologieknoten\u201c wurde mit der kleinsten Strukturgr\u00f6\u00dfe im Schaltkreis bezeichnet (Abbildung 1); alle Eigenschaften des neuen Knotens wie auch die Strategien zur Umsetzung wurden festgelegt. \nDas zentrale Herstellungskonzept f\u00fcr integrierte \nSchaltkreise ist die Fotolithographie. F\u00fcr jeden \n40 JahreInnovation f\u00fcr schnelle Prozessoren \u00a7  105\nSchaltkreis, der bestimmte Funktionen erf\u00fcllen \nsoll, gibt es eine Vorlage \u2013 meist eine Schatten-maske der Schaltkreisstrukturen, die mit Laser -\nlicht beleuchtet wird und st\u00fcckweise mehrfach auf einer mit einer funktionalen Schicht und mit Fotolack beschichteten Siliziumscheibe (\u201eWafer\u201c)  \nabgebildet wird (Details siehe Abbildung 2a). Wird der Lack entwickelt, kann danach, je nachdem ob eine Stelle belichtet wurde oder nicht, selektiv ge\u00e4tzt werden, sodass die abge-bildeten Strukturen in die funktionale Schicht \u00fcbertragen werden. \nDas einfachste Mittel, um immer kleinere \nStrukturen und damit dichtere Schaltkreise zu erzeugen, war immer kurzwelligeres Laserlicht zu verwenden. M\u00f6chte man mit einem Pinsel einen f\u00fcnf Millimeter breiten Strich zeichnen, verwendet man am besten einen f\u00fcnf Millime-ter breiten Pinsel. \nIn bew\u00e4hrter Tradition unterst\u00fctzte Prometheus \u2013  \nvon den G\u00f6ttern unbemerkt \u2013 die Menschen \nauch in den weiteren Entwicklungen, indem er den G\u00f6ttern immer neue Wellenl\u00e4ngen stahl. Licht mit Wellenl\u00e4ngen von 436 nm, 365 nm, 248 nm und 193 nm half den Menschen, mit dem Strafzyklus der G\u00f6tter Schritt zu halten und immer kleinere Strukturen zu erzeugen. Als jedoch Zeus dem R\u00e4uber auf die Schliche kam, war er aufs Neue erz\u00fcrnt und erdachte eine Hinterlist. Er lockte Prometheus mit Licht einer besonders kurzen Wellenl\u00e4nge von nur 13,5 nm, das die Menschen vermeintlich auf lange Sicht von ihren Sorgen befreien w\u00fcrde. Die-ses Licht, das unter den Menschen fortan EUV  \n(Extremes Ultraviolett) genannt wurde, versah Zeus jedoch heimlich mit zwei Eigenschaften, die es f\u00fcr die Menschen v\u00f6llig unbrauchbar  \nmachen sollten. \n1) \n EUV\n-Licht zu erzeugen ist extrem komplex \nund ineffizient. Hat die Quelle aber eine \nzu geringe Leistung, muss jeder einzelne Wafer l\u00e4nger belichtet werden und der Durchsatz der Fertigung sinkt. Damit kann der von den Menschen aufgebaute Wirt-schaftszyklus, der bisher die Innovations-  \nserie am Laufen hielt, nicht aufrechterhalten werden. \nAbb. 1: Illustration des Mooreschen Gesetzes. Die schwarzen Punkte zeigen die Entwicklung der Anzahl der Schaltelemente (Tran-\nsistoren) pro Chip-Fl\u00e4che f\u00fcr verschiedene kommerzielle Prozessoren. Die roten Punkte zeigen die jeweils kleinsten umsetzbaren Strukturgr\u00f6\u00dfen und f\u00fcr die sp\u00e4teren Jahre die g\u00e4ngigen Bezeichnungen der Technologieknoten (nach Intel). Die eingezeichneten Laserwellenl\u00e4ngen werden in der Herstellung der jeweiligen Prozessoren genutzt.\nLaserwellenl\u00e4nge:Transistoren pro mm2\nStrukturgr\u00f6\u00dfe (nm)436 nm\n1973 1976 1979 1982 1985 1988 1991 1994 1997N90\nN65\nN45\nN32\nN22\nN14Immersion\nDoppelbelichtung\n2000 2003 2006 2009 2012365 nm 248 nm 193 nm\n1280\n10000000\n1000000\n100000\n10000\n1000640\n320\n160\n80\n40\n20106 \n2)  EUV -Licht wird in jedem Festk\u00f6rper und nach \nk\u00fcrzesten Strecken sogar in Luft absorbiert. \nDamit muss die gesamte Belichtung im Vaku-um stattfinden und es k\u00f6nnen f\u00fcr die Abbil-dung der Maske auf den Wafer keine Linsen verwendet werden. EUV-Licht wird gr\u00f6\u00dften-teils im Linsenglas absorbiert ohne hindurch zu strahlen oder zumindest wie bei einem Spiegel reflektiert zu werden. Die deponierte Energie erw\u00e4rmt und verformt das Material. \nDoch die Menschen nahmen auch diese Her -\nausforderungen tapfer an. Durch eine besonde-re, aufw\u00e4ndige Beschichtung der Linsen- bzw. Spiegelk\u00f6rper, die aus \u00fcber 50 einzelnen Lagen von jeweils nur wenigen Nanometern (ein Mil-lionstel Millimeter) Dicke besteht, schafften sie es, dass immerhin etwa 70 Prozent des EUV-Lichts von der Oberfl\u00e4che reflektiert wurde (Details siehe Abbildung 2b). Dadurch konnte ein komplexes Abbildungssystem mit Spiegeln aufgebaut werden, das \u00e4hnlich den bisherigen Objektiven in die Lithographieanlage eingebaut werden kann.  \nAuch f\u00fcr die Verbesserung der EUV-Quelle \nhatten die Menschen immer neue Ideen. Man z\u00fcndete elektrische Entladungen in Xenon-Gas (GDPP: Gas-Discharge Produced Plasma). Dabei entstand EUV-Strahlung. Als die Intensit\u00e4t des erzeugten Lichtes nicht ausreichte, fingen eini-ge Gruppen an, die Entladung durch einen star -\nken Laser zu induzieren (LPP: Laser Produced Plasma) und Zinn statt Xenon zu nutzen. In neuen Systemen beschie\u00dft ein Kohlenstoffdio-xid-Laser mehrere Zehntausend einzelne Zinn-tropfen pro Sekunde.\nDas ganze System der EUV-Lithographie war \ndennoch so komplex, dass an allen Ecken und Enden mit immer neuen L\u00f6sungen um kleinste Verbesserungsschritte gek\u00e4mpft werden muss-te, doch dank der Kreativit\u00e4t der Menschen blieb die Hoffnung auf die Umsetzung der EUV-Lithographie f\u00fcr lange Zeit bestehen. \nEnde der 90er Jahre glaubten viele, EUV k\u00f6nne \nf\u00fcr den 65 nm-Knoten, der um 2005 /2006 her -um eingef\u00fchrt werden sollte, einsatzbereit sein. Nach ersten \u00f6ffentlich gef\u00f6rderten Forschungs-aktivit\u00e4ten in den USA formierte der gro\u00dfe Halbleiterhersteller Intel eine amerikanische Kollaboration namens EUV LLC, an der sich  \nneben ihm weitere gro\u00dfe Halbleiterhersteller, unter anderem auch Infineon und IBM, betei-ligten. Forschungspartner waren vor allem die gro\u00dfen amerikanischen \u201eNational Laboratories\u201c (NL) in Livermore (LLNL), Albuquerque (SNL) und Berkeley (LBNL), die der breiten Bev\u00f6lke-rung meist durch die Atomwaffenforschung be kannt sind. Durch die EUV LLC hat die Industrie zwischen 1997 und 2002 die gesamte For -\nschung zur EUV-Lithographie finanziert.\n1  \nIm Jahre 2001, gegen Ende der Laufzeit des EUV LLC-Vertrags, waren die Vorhersagen hervorra-gend und das Vertrauen in die Technologie gro\u00df. Ein erster Demonstrator, der unter Laborbedin-gungen die grunds\u00e4tzliche Funktion nachwies, stand \u2013 der Weg zur Kommerzialisierung schien begehbar. EUV wurde von vielen als die einzige L\u00f6sung f\u00fcr Technologieknoten unterhalb von 50 nm gesehen und nun sollte die Technologie in-nerhalb von wenigen Jahren bereit sein f\u00fcr den Einsatz in der Massenproduktion. Eine von vielen \u00e4hnlich klingenden \u00f6ffentlichen Aussagen laute-te etwa:\u201eA few hurdles still stand in the way of widespread adoption, but the technological pro-blems have been solved and extreme ultraviolet (EUV) lithography will be ready for production in the next few years, according to Charles Gwyn, EUV LLC program director.\u201d\n2\nDamit die Technologie von den Chipherstellern aber akzeptiert und wirtschaftlich in der Mas-senproduktion einsetzbar wurde, musste sie bestimmte Anforderungen erf\u00fcllen. Einerseits sollte ein Durchsatz von 125 Wafern pro Stunde und Anlage erzielt werden (Stand 2017). An-dererseits musste auch die finale Ausbeute an funktionierenden Chips pro Wafer ausreichend hoch sein.\nDer Durchsatz wird vor allem durch die Dauer \nbestimmt, f\u00fcr die ein einzelner Wafer belichtet werden muss. Je geringer aber die Intensit\u00e4t ist, Innovation f\u00fcr schnelle Prozessoren \u00a7  107\nAbb. 2: Fotolithographie \n a)\n F\notolithographie: Eine Maske, die eine Lage der Schaltkreisstrukturen eines Chips durch transparente und absorbierende  \n Bereiche darstellt,\n wird mit Laserlicht beleuchtet. Das durchscheinende Licht wird mit einem hochgenauen Objektiv auf einer \n \n Siliziumscheibe (W\nafer) abgebildet. Nach einer Belichtung wird der Wafer schrittweise verfahren und der gleiche Schaltkreis \n \n erneut abgebildet,\n so dass ein einzelner Wafer hunderte oder sogar tausende identischer Chips enthalten kann.  \n b)\n Mehrlagen-Spiegel (Bragg-Reflektor):\n Wird an einer Oberfl\u00e4che nur ein extrem geringer Anteil des einfallenden Lichts  \n reflektiert,\n kann man durch eine Stapelung von vielen reflektierenden Oberfl\u00e4chen (EUV: mehr als 50) im richtigen Abstand \n \n voneinander erreichen,\n dass sich die jeweils zur\u00fcckgespiegelten Lichtwellen \u00fcberlagern und verst\u00e4rken. Dabei muss die Dicke \n \n der einzelnen Lagen (EUV\n: wenige Nanometer) sehr genau an die betrachtete Wellenl\u00e4nge angepasst sein.  \n c)\n Mehrfachbelichtung:\n Strukturen in einem Abstand (pitch), der nicht mehr aufgel\u00f6st werden kann, werden auf zwei verschie- \n dene Mask\nen verteilt und nacheinander belichtet.  Die Breite einer einzelnen Linie (critical dimension) kann \u00fcber Prozess- \n par\nameter und den Fotolack beeinflusst werden.\ndie auf dem Wafer ankommt, desto l\u00e4nger ist \ndie ben\u00f6tigte Belichtungszeit, um eine Aktivie-rung des Fotolacks zu erreichen. F\u00fcr eine m\u00f6g-lichst kurze Belichtungszeit muss also die Quelle sehr leistungsstark sein und das Licht m\u00f6glichst ohne weitere Verluste durch das Abbildungssys-tem transportiert werden. Damit werden aber genau die zwei kritischsten Punkte des EUV-Lichts tangiert. Bei jeder einzelnen Reflexion an jedem Spiegel gehen etwa 30 Prozent des Lichts verloren. Damit \u00fcbersetzt sich die Forde-rung nach einem Durchsatz von 125 Wafern pro Stunde in eine Quellenleistung von 250 Watt (Stand 2017). Die EUV-Quellen der Labor -\ndemonstratoren aus dem Jahre 2002 lieferten eine Leistung von unter 5 Watt. \nLimitierende Faktoren f\u00fcr die finale Ausbeute \nsind Verunreinigungen im Prozess und  Defekte auf der Maske. Bei Strukturen, die nur noch we-nige Nanometer gro\u00df sind, sind Verunreinigun-gen durch einzelne, winzigste Partikel bereits \nSpiegelsubstratLichtquellea)\nc)b)\nMaske\nAbbildungs-  \nsystem\nW\naferEinfallender \nStrahl\u00dcberlagerung der Reflexionen 108 \nkritisch. Die Halbleiterfertigung findet schon \nseit langem hochautomatisiert in streng kontrol-  \nlierten, hochsauberen Reinr\u00e4umen statt. F\u00fcr EUV werden aber die Anforderungen noch  \neinmal erh\u00f6ht. Vor allem geringste Verunreini- gungen und kleinste Defekte auf der Maske haben eine verheerende Auswirkung auf die Ausbeute, da sich die Fehler auf jeden Chip \u00fcbertragen. Die defektfreie Herstellung sowie die Inspektion und Reparatur von EUV-Masken waren damit gro\u00dfe Steine auf dem Weg der EUV-Lithographie von der ersten Labordemon- stration in die Massenproduktion. \nNach dem ersten Labordemonstrator wurde die \nEUV-Technologie trotz der weiterhin vorhande-nen Herausforderungen von zahlreichen Unter -\nnehmen weiterentwickelt, die jeweils verschie-dene technologische Aspekte abdeckten. Die drei gro\u00dfen involvierten Anlagenhersteller und Systemintegratoren waren Nikon und Canon aus Japan, sowie ASML aus den Niederlanden. \nSelbst Zeus, der die Entwicklungen mit einer \nMischung aus Zorn und Bewunderung beob-achtete, bef\u00fcrchtete f\u00fcr eine kurze Zeit, dass der Erfindungsreichtum der Menschen, aber auch ihr Gier nach Reichtum und Fortschritt, die Grenzen der Natur verschieben und fast g\u00f6ttli-che Werke erschaffen k\u00f6nnte.  \nUm w\u00e4hrend dieser Entwicklungen gleichzei-\ntig die G\u00f6tter befriedigen und im treibenden Zwei-Jahresrhythmus die Strukturen verkleinern zu k\u00f6nnen, wurden parallel alle Aspekte der Chipherstellung mit der letzten verf\u00fcgbaren Wellenl\u00e4nge von 193 nm bis an die Grenzen ausgereizt. Durch ein einzigartiges Zusammen-spiel aller Prozesse, Materialien und Technologi-en schafften es die Menschen, mit dem 193nm-Licht Strukturen mit Breiten und Abst\u00e4nden von nur 48 nm herzustellen. Das hie\u00dfe mit einem 5 mm breiten Pinsel 1,2 mm breite Linien zu zeichnen. Gr\u00f6\u00dfter Hebel dabei war die Einf\u00fch-rung der sogenannten Immersionslithographie (bezeichnet als 193i). Hier wurde in den Spalt zwischen Objektiv und Wafer eine Fl\u00fcssigkeit eingebracht, die das Licht st\u00e4rker bricht als Luft und damit eine h\u00f6here Aufl\u00f6sung erlaubt. Durch diesen Trick konnten sogar alle verzwei-felten Pl\u00e4ne stillgelegt werden, den G\u00f6ttern noch eine Zwischenwellenl\u00e4nge von 157 nm zu stehlen, da auch dieses Licht wieder neue Prob-leme mit sich gebracht h\u00e4tte. \nDoch um 2008 kam der Zeitpunkt, zu dem mit \n32 nm der erste Technologieknoten anstand, der mit den bereits ausgereizten 193 nm unter  \nkeinen Umst\u00e4nden mehr machbar schien. Ob-wohl Nikon, Canon und ASML bereits einzelne Test- und Entwicklungsanlagen fertig gestellt und ausgeliefert hatten, war die EUV-Techno- logie weiterhin nicht reif f\u00fcr die Produktion. \nDie Menschen verfielen in Panik und die Aus-\nsicht auf die g\u00f6ttlichen Strafen, die sie sich f\u00fcr den Fall ausmalten, dass der Innovationszyklus unterbrochen wurde, lie\u00df sie des Nachts nicht mehr schlafen. \nSo wurde notgedrungen auf ein Konzept aus-\ngewichen, das zwar die Gr\u00f6\u00dfenskalierung ga-rantieren konnte, aber die f\u00fcr die menschliche \u00d6konomie wichtige Kostenskalierung st\u00f6rte. Bei der sogenannten Mehrfachstrukturierung (Multipatterning) wurde f\u00fcr einen einzelnen Wafer ein doppelter Maskensatz nacheinander belichtet (Details siehe Abbildung 2c). Dadurch konnte die Dichte der strukturierten Elemente weiter erh\u00f6ht werden, man ben\u00f6tigte aber pro Wafer und damit pro Chip mehr teure Masken und mehr Zeit, wodurch die Kosten stiegen. Die hochgenaue Ausrichtung der beiden Belich-tungsschritte zueinander stellte dabei eine neue technische Herausforderung dar. \nDoch nachdem diese Technologie einmal etab-\nliert war, lie\u00df sie sich im Prinzip auch f\u00fcr weitere Technologieknoten noch auf die Spitze und zu kleineren Strukturen treiben, indem das ge-w\u00fcnschte Muster nicht nur auf zwei, sondern auf drei oder vier Masken aufgeteilt wird. Da-durch w\u00fcrden allerdings sowohl die Kosten pro Wafer weiter steigen als  auch die Anforderun-gen an die Ausrichtungsgenauigkeit.Innovation f\u00fcr schnelle Prozessoren \u00a7  109\nDamit war pl\u00f6tzlich die Notwendigkeit und \n\u00dcberlegenheit der EUV-Lithographie nicht mehr eindeutig. Selbst wenn die Technologie eines Tages reif f\u00fcr die Massenproduktion w\u00e4re, w\u00e4ren die Investitionskosten in komplett neue EUV-Anlagen und die dazugeh\u00f6rige Infrastruk-tur wie auch die Betriebskosten enorm. Die Kostenrechnungen hingen von verschiedensten Faktoren, wie etwa der angenommenen Nutz-barkeitsdauer der EUV-Technologie allgemein und der konkreten Anlagen, ab und fielen sel-ten eindeutig aus. Die Wahrscheinlichkeit, dass EUV es wirklich in die Fertigung schaffen w\u00fcr -\nde, war damit drastisch gesunken.  \nMittelfristig wirkte sich diese Situation zusam-\nmen mit den immer noch vorhandenen H\u00fcrden bei der Industrialisierung der EUV-Lithographie auf die Strategien der betroffenen Unternehmen  \naus. Zwar gab es auch 2008 noch vorsichtige Pl\u00e4ne f\u00fcr EUV-Anlagen bei den drei Herstellern Nikon, Canon und ASML. Bereits 2009 brachte Nikon jedoch seine EUV-Entwicklungen auf unbestimmte Zeit zum Stillstand. Betrachtet  \nman heute die Webseiten der beiden japani-schen Unternehmen, taucht EUV nicht mehr auf.\nDen G\u00f6ttervater Zeus erfreuten diese Ent-\nwicklungen. Zwar hatten die Menschen es ge-schafft, den Strafzyklus mit dem Mooreschen Gesetz am Laufen zu halten, f\u00fcr den Raub  des g\u00f6ttlichen Lichts haben die Menschen aber Bu\u00dfe getan. Das von Zeus boshaft verwandel-te, unbrauchbar gemachte EUV-Licht hatte die Menschen Nerven, Zeit und Geld gekostet, hat-te die Branche in verschiedene Lager gespalten und den Menschen ihre Unzul\u00e4nglichkeiten vor Augen gef\u00fchrt. \nDoch auch Europa, Tochter des K\u00f6nigs Agenor, \nbeobachtete schon seit geraumer Zeit die Spiel-chen ihres ehemaligen Geliebten Zeus und war von den kleinen Fortschritten und der verbisse-nen Willensst\u00e4rke der Menschen beeindruckt. Dass Zeus die trotz der H\u00fcrden erzielten Erfol-ge ver\u00e4rgert hatten, kam der verlassenen Frau nur entgegen. Als das Blatt sich nun zu wen-den drohte und die Menschen bereit schienen aufzugeben, fasste Europa den Entschluss, die Menschen zu unterst\u00fctzen. \nUm den verbleibenden Systemintegrator ASML \naus den Niederlanden fand sich in Europa ein innovatives Netzwerk von Unternehmen, das fast alle Aspekte der EUV-Lithographie abde-cken konnte. Um die Weiterentwicklung der EUV-Quelle voranzutreiben, akquirierte ASML 2013 den vielversprechenden amerikanischen Hersteller Cymer, der nun als Teil von ASML die hochentwickelte Technologie ausschlie\u00dflich in diese Anlagen einbringt. Ein weiterer zent-raler Partner ist das deutsche Unternehmen Zeiss, das das Herzst\u00fcck der Lithographiean-  \nlage \u2013 die hochaufl\u00f6senden Optiken \u2013 entwickelt und exklusiv an ASML liefert sowie weltweite Patente auf die zentralen Schl\u00fcsseltechnolo-gien besitzt. F\u00fcr die neueste Generation der EUV-Objektive muss die Oberfl\u00e4chenform eines Spiegels mit bis zu einem Meter Durchmesser auf mehrere Pikometer (mehrere Milliardstel Millimeter) genau den Designvorgaben ent-sprechen.  AMTC, ein weiteres Unternehmen in Deutschland, ist einer von wenigen Masken-herstellern, die \u00fcberhaupt Kompetenzen f\u00fcr EUV besitzen. Am Forschungsinstitut IMEC in Belgien steht die n\u00f6tige Infrastruktur f\u00fcr weg-bereitende Forschungs- und Entwicklungsarbei-ten zur Verf\u00fcgung. Sogenannte Pilotlinien, die alle n\u00f6tigen Prozessschritte f\u00fcr eine erste Fer -\ntigung von neuesten Technologien abdecken, k\u00f6nnen hier entwickelt, integriert und getestet werden. Die in Deutschland und Europa starken Branchen der Automatisierungstechnik und der \nFun Fact\nIn den Entwurf eines Chips f\u00fcr den 14 nm-Knoten flie\u00dfen im Schnitt 200 Personenjahre Arbeit, es werden f\u00fcr die Herstellung der verschiedenen Lagen insgesamt 66 verschiedene Masken ben\u00f6tigt und ein Fertigungs-durchlauf dauert 90 Tage.\n3 110 \nMesstechnik tragen zur Beherrschung der ex- \ntremen Anforderungen an die Infrastruktur, zum Beispiel bez\u00fcglich Kontamination, bei. \nZusammen mit einer konsequenten, nachhalti-\ngen \u00f6ffentlichen F\u00f6rderung der Technologieent- wicklung auf nationaler und europ\u00e4ischer Ebe-ne von 1994 bis heute konnte dieses Netzwerk aus Unternehmen und Forschungseinrichtun-gen endlich zentrale technologische Durchbr\u00fc-che erzielen. Im Juli 2017 wurden durch ASML erstmals die geforderten 250 Watt Quellleis-tung in einer Fertigungsumgebung au\u00dferhalb des Labors demonstriert. Bereits Ende 2016 hatte ASML erstmals eine defektfreie Schutz-membran (Pellicle) vorgestellt, die im Betrieb Partikel von der Maske abschirmen soll und gleichzeitig die Abbildung nicht st\u00f6rt. Dies war neben der Quellleistung einer der kritischsten offenen Punkte.   \nDie gro\u00dfen Chip-Hersteller Samsung, Global-\nfoundries und TSMC haben sich in diesem Zuge 2017 erstmals zur Einf\u00fchrung der EUV-Techno-logie f\u00fcr den 7nm-Knoten bekannt und kon-krete Pl\u00e4ne ver\u00f6ffentlicht. Samsung hat hierf\u00fcr Anfang 2018 den Grundstein f\u00fcr eine neue, sechs Milliarden Dollar teure EUV-Halbleiterfa-brik gelegt. \nIn den 90er Jahren des 20. Jahrhunderts domi-\nnierte Nikon den Markt mit etwa 50 Prozent Marktanteil. Nach der erfolgreichen Einf\u00fchrung der Immersionslithographie im Jahr 2004 \u00fcber -\nnahm ASML jedoch die F\u00fchrung und besitzt den gr\u00f6\u00dften Marktanteil mit etwa 60 Prozent nach ausgelieferten Anlagen und sogar 70-80 Prozent nach Umsatzerl\u00f6sen.\n4 Derzeit ist ASML \nder einzige Lieferant von EUV-Lithographieanla-gen weltweit. Die EUV-Technologie gibt es nur \u201eMade in Europe\u201c. Damit kann sich Europa vor- aussichtlich f\u00fcr die n\u00e4chsten Jahre im \u00d6kosys-tem der Chip-Fertigung immerhin im Bereich der Anlagenherstellung gegen den weltweiten Wettbewerb behaupten und gleichzeitig dazu beitragen, die Entwicklung von innovativen, \nAbb. 3: Teil der EUV-Lithographie-Optik in der Fertigung von ZeissInnovation f\u00fcr schnelle Prozessoren \u00a7  111\nschnellen und kompakten Prozessor-Generatio-\nnen weiterzutreiben.\nWie es weitergeht, wenn im Innovationszyklus \ndes Mooreschen Gesetzes auch die EUV-Tech-nologie ausgereizt ist, ist die n\u00e4chste spannen-de Frage, auf die die Menschen eine Antwort finden m\u00fcssen.\n5 \nDie Erfolgsgeschichte der EUV-Entwicklungen zeigt einerseits die gro\u00dfe Chance und Triebkraft einer abgestimmten internationalen Roadmap f\u00fcr eine ganze Branche, wie sie basierend auf dem Mooreschen Gesetz f\u00fcr die Halbleiterin-dustrie vorliegt, andererseits die komplexe In-teraktion zwischen grunds\u00e4tzlicher technischer Machbarkeit und Umsetzung im wirtschaftli-chen Umfeld.Als Zeus d\u00e4mmerte, dass seine hinterh\u00e4ltige Rache nicht aufgegangen war, erzitterte der gesamte Olymp unter seinem Zorn. Eine seiner Geliebten, die listige Elektra, wusste jedoch ihren wutentbrannten Verehrer zu bes\u00e4nfti-gen. Durch eine Spracheingabe an einen On-line-Shop der Menschen bestellt sie ihm das neueste Smartphone, das mit einer autonomen Drohne bis an den Fu\u00df des Olymp geliefert wurde. Zeus war fortan damit besch\u00e4ftigt, die Spiele seiner zahlreichen Enkelkinder mit der hochaufl\u00f6senden Kamera festzuhalten und in den Sozialen Medien, die mit schnellsten Re-chenzentren betrieben wurden, mit den Men-schen zu teilen. \n1 Intel (Hrsg.).  (2001). Partners Unveil First Extreme Ultraviolet Chip-Making Machine. www.intel.com/pressroom/archive/releases/2001/\n 20010411tech.htm [Zugriff am 9.4.2018].\n2 Jeff Chapell (EDN Network,  Hrsg.). (2001): EUV LLC Says Technology is Ready. www.edn.com/electronics-news/4357234/EUV-LLC-Says-\n T\nechnology-is-Ready [Zugriff am 9.4.2018].\n3 V ortrag, EUV Litho Workshop 2017, \u201eEUV Mask Technology and Economics: Impact of Mask Costs on Pattering Strategy\u201c, Bryan Kasprowicz \n (Photronics Inc.),https://www\n.euvlitho.com/2017/P33.pdf [Zugriff am 9.4.2018].\n4 Prof . Steffen Wettengl. (2014). Holl\u00e4ndisch-schw\u00e4bisches Innovationsduo vor dem gro\u00dfen Sprung. Der BWL-Blog von Prof. Steffen Wettengl. \n http://wettengl\n.info/Blog/?p=4587 [Zugriff am 9.4.2018].\n5 Rick Merritt (EE Times, Hrsg.). (2018). Path to 2 nm May Not Be Worth It. Diminishing returns may evaporate at 5 nm. \n www\n.eetimes.com/document.asp?doc_id=1333109&page_number=1 [Zugriff am 9.4.2018]. Semiconductor Engineering (Hrsg.). \n T\nag: Next Generation Lithography. https://semiengineering.com/tag/next-generation-lithography  [Zugriff am 9.4.2018].112 \nWohlstand durch Materialeffizienz\nKleiner Einsatz, gro\u00dfe Wirkung \u2013 die demea \n  \nDr. Julia Kaltschew  Dr. Claudia Ritter \nMaterialeffizienz und Nachhaltigkeit\nAls vor gut 300 Jahren Hans Carl von Carlo-\nwitz, ein s\u00e4chsischer Berghauptmann, den Begriff Nachhaltigkeit ins Leben rief, hatte er sicher nicht die heutigen Produktionsstandorte in Deutschland im Kopf. Vielmehr ging es um eine \u00f6kologisch vertr\u00e4gliche und gleichzeitig wirtschaftlich lohnende Bewirtschaftung von W\u00e4ldern. Er formulierte als erster das Prin-zip der Nachhaltigkeit: Bei der Rodung von W\u00e4ldern m\u00fcsse man \u201ebedenken [...] wo ihre Nachkommen Holtz hernehmen sollen\". Denn \u201ewenn die Holtz und Waldung erst einmal rui-nirt, so bleiben auch die Eink\u00fcnffte auff unend-liche Jahre hinaus zur\u00fccke, \u2026 da\u00df also unter gleichen scheinbaren Profit ein unersetzlicher Schade liegt\u201c.\n1 Auch auf lange Sicht und f\u00fcr \ndie nachfolgenden Generationen sollte der Wald als Einkommensquelle dienen und den Lebensunterhalt sichern. \nAn Brisanz hat das Thema seitdem nicht ver -\nloren. Ganz im Gegenteil, der Umgang mit \nden nat\u00fcrlichen Ressourcen wird die Lebens-umst\u00e4nde auf der Erde in den kommenden Jahren dramatisch beeinflussen. Die wach-sende Weltbev\u00f6lkerung und die zunehmende \u00f6konomische Entwicklung f\u00fchren zu einem stetig steigenden Bedarf an Lebensmitteln, Wasser, Energie und Gebrauchsg\u00fctern \u2013 fast \u00fcberall auf der Welt w\u00e4chst die Nachfrage nach \u201emateriellen\u201c Produkten. Nicht nur der Lebensunterhalt soll gesichert werden, auch das Bed\u00fcrfnis nach Konsum w\u00e4chst stetig. Die \u00f6konomische Entwicklung und der technolo-gische Fortschritt gehen oft auf Kosten der Umwelt und ihrer Ressourcen. Die Ausgangs-materialien liefert immer die Natur. Doch sind die Rohstoffe auf der Erde endlich, ihre F\u00f6r -\nderung wird immer aufw\u00e4ndiger, kostspieli-ger, risikoreicher und schadet dem \u00d6kosystem zunehmend. \nWie lange kann unsere Umwelt wohl noch die-\nsen enormen Ressourcenbedarf und die damit verbundenen Ver\u00e4nderungen in unserem Le-bensraum vertragen, ohne dass die Menschen erhebliche Einschr\u00e4nkungen im Alltag hin-nehmen m\u00fcssen? Und was hat all das mit der \u00dcberschrift zu tun? \nGanz einfach, ein sparsamer Umgang mit Res-\nsourcen lohnt sich nicht nur aus \u00f6kologischer Sicht, sondern macht sich auch auf dem Konto bemerkbar. Steigende bzw. schwankende Prei-se f\u00fcr Rohstoffe und Materialien stellen eine zunehmende Belastung f\u00fcr Unternehmen des produzierenden Gewerbes dar. Eine gesicherte Versorgung mit Rohstoffen und Materialien ist von grundlegender Bedeutung f\u00fcr die dauer -\nhafte Leistungs- und Wettbewerbsf\u00e4higkeit der Wirtschaft. \nMaterialkosten stellen im Produzierenden Ge-\nwerbe nach Ver\u00f6ffentlichungen des Statisti-schen Bundesamts mit fast 43 Prozent den weitaus gr\u00f6\u00dften Kostenblock dar. Im Vergleich zu den gut 20 Prozent Personalkostenanteil ist das mehr als das Doppelte. Energiekosten hingegen verursachen nur 1,8 Prozent der Ge-samtkosten. Diese Zahlen verdeutlichen, dass Einsparungen im Bereich Material einen beson-ders gro\u00dfen Einfluss auf die Produktionskosten haben und die Wettbewerbsf\u00e4higkeit von Un-\n40 JahreWohlstand durch Materialeffizienz \u00a7 113\nternehmen durch Erschlie\u00dfung von Einsparpo-\ntenzialen deutlich verbessert werden kann.\nIst das aber nicht offensichtlich und eigentlich \nganz selbstverst\u00e4ndlich? Sollten nicht alle Un-ternehmen von sich aus auf den sparsamen Ein-satz von Produktionsmitteln aller Art achten? \nWeit gefehlt! Die Realit\u00e4t sieht leider anders \naus! Um Unternehmen zu helfen, ihre Einspar -\npotenziale zu identifizieren und wettbewerbs-f\u00e4higer zu werden, wurde die Deutsche Ma-terialeffizienzagentur (demea) vom damaligen Bundesministerium f\u00fcr Wirtschaft und Techno-logie gegr\u00fcndet. \nDie Deutsche Materialeffizienzagentur\nViele Unternehmer im verarbeitenden Gewerbe gehen davon aus, dass in ihren Unternehmen keine Materialverluste vorkommen, da nach ih-rer Ansicht alle Abl\u00e4ufe optimiert sind. In den seltenen F\u00e4llen, in denen ein Materialeinsparpo-tenzial im eigenen Betrieb vermutet wird, wird dieses Thema oft trotzdem nicht weiterverfolgt. Das liegt zum einen an fehlenden personellen Ressourcen und der m\u00fchsamen Einbindung von zus\u00e4tzlichen Aufgaben in das Tagesgesch\u00e4ft und zum anderen am erforderlichen Wissen, den ben\u00f6tigten Materialeinsatz zu analysie-ren, Effizienzpotenziale aufzusp\u00fcren und diese mit geeigneten Ma\u00dfnahmen zu erschlie\u00dfen. Zudem f\u00fcrchten Unternehmen eventuell an-fallende Investitionskosten. Deshalb unter -\nst\u00fctzte das BMWi kleine und mittelst\u00e4ndische Unternehmen durch Beratungsprogramme, den Rohstoff- und Materialeinsatz im Unter -\nnehmen zu verringern. Die demea f\u00fchrte diese F\u00f6rderprogramme im Auftrag des BMWi aus. Zu den Aufgaben der demea z\u00e4hlten dabei, das Bewusstsein f\u00fcr Rohstoff- und Materialeffizienz zu sch\u00e4rfen, Unternehmen zur Erschlie\u00dfung von Rohstoff- und Materialeffizienzpotenzialen zu motivieren und schlie\u00dflich die Erkennung und Erschlie\u00dfung von Einsparpotenzialen zu f\u00f6rdern.\nEin zentraler Bestandteil der Arbeit der demea \nwaren Aufbau und Pflege eines Beraterpools mit mehr als 200 Beratern. Die Beratungen der Unternehmen in den F\u00f6rderprogrammen wurden ausschlie\u00dflich von autorisierten Bera-tungsunternehmen durchgef\u00fchrt. So konnten die Unternehmen auf die Fachkompetenz des jeweiligen Beraters und die effiziente Durch-f\u00fchrung des Beratungsprojekts vertrauen. Der Fokus wurde stets auf das Aufsp\u00fcren konkreter Einsparungen von Rohstoffen und Material in der Produktkonstruktion, im Fertigungsprozess sowie im Umfeld der Produktion gelegt. Da den Unternehmen selbst oftmals nicht bewusst war, in welchen Umf\u00e4ngen Rohstoff- und Material-effizienzpotenziale bei ihnen verborgen liegen Abb. 1: Kostenstruktur im produzierenden Gewerbe in 2015  \nQuelle: Statistisches Bundesamt (Destatis) (2017): Produzierendes Gewerbe.Material 42,9 %\nEnergie 1,8 % Personal 20,5 %Handelsware 11,1 %Sonstiges 25,2 %114 \nund sie keinen akuten Handlungsbedarf sahen, \nwar es die Hauptaufgabe der Berater, die Un-ternehmen f\u00fcr das Thema zu sensibilisieren und mit spezifischem Fachwissen von au\u00dfen kritisch auf bestehende Prozesse zu schauen. Mit dem Blick von au\u00dfen k\u00f6nnen in der Regel eingespiel-te und zum Teil starre Prozesse besser hinter -\nfragt und analysiert werden. \nHierbei wurde festgestellt, dass Materialeffizi-\nenzpotenziale in jedem Unternehmen vorhanden sind. Mit einfachen Ma\u00dfnahmen und geringen Investitionen, die sich nach kurzer Zeit amorti-siert hatten, wurden durchschnittliche Einspar- ungen in H\u00f6he von etwa 2 Prozent des Jahres- umsatzes erreicht. \u00dcber das eingesparte Material  \nhinaus wurden in den Unternehmen auch weitere Einspareffekte erzielt, da in jedem  \nverarbeiteten Material bereits Kosten f\u00fcr Arbeit und Energie aus den vorgelagerten Prozessen enthalten sind. Die Unternehmen konnten auf  \ndiese Weise nicht nur ihre Rendite steigern, son-dern gleichzeitig auch die Umwelt entlasten.Die demea musste zun\u00e4chst daf\u00fcr sorgen, dass das Thema bei Unternehmen des produzie-  \nrenden Gewerbes und in der Fachszene st\u00e4rker in den Fokus r\u00fcckte. Neben zahlreichen regi-onalen Infoveranstaltungen fanden j\u00e4hrlich Konferenzen im BMWi statt, auf denen sich  \ninteressierte Unternehmen, Berater und Multi-  \nplikatoren vernetzen und \u00fcber neue Themen der Material- und Rohstoffeffizienz informieren konnten. Dabei wurde auch der Material- bzw. Rohstoffeffizienzpreis an Unternehmen und Forschungseinrichtungen verliehen. Pr\u00e4miert wurden innovative L\u00f6sungen zur nachhaltigen Steigerung der Materialeffizienz bzw. neue anwendungsorientierte Forschungsergebnisse zur Verbesserung der Materialeffizienz. Die demea wurde im Laufe der Zeit st\u00e4rker in der Fachszene wahrgenommen und vernetzte sich mit anderen Akteuren, beispielsweise im noch immer aktiven Kompetenzpool Ressourcenef-fienz und im EU-weiten Projekt REMake mit Partnern aus 7 L\u00e4ndern.\n Abb. 2: Ansatzpunkte f\u00fcr Materialeffizienz in allen Unternehmensbereichen\nMaterialeffizienz\nBauweiseKonstruktion Fertigung Fabrik-\norganisationLogistik\nMaterialien\nKomponenten-\nvielfaltBearbeitungs-\nprozesse\nWerkzeuge\nReinigung\nArbeitsplatz-\ngestaltungMaterialfluss\n LagerungDisposition\n Information \nEinkaufWohlstand durch Materialeffizienz \u00a7 115\nAns\u00e4tze zur Materialkostenreduzierung \nSchnell zeigte sich, dass die Einsparm\u00f6glichkei-\nten sehr facettenreich sind. Ansatzpunkte zur Verbesserung der Materialeffizienz finden sich in fast allen Unternehmensbereichen: bei der Produktkonstruktion, in den Fertigungsprozes-sen, bei der Fabrikorganisation, in der Logistik oder durch Recycling und Substitution.\nEin Beispiel: Sollten die f\u00fcr die Produktion be-\nn\u00f6tigten Holzvorr\u00e4te auf dem Hof ohne \u00dcber -\ndachung gelagert werden? Die erste Intuition sagt: nein! Und auch bei n\u00e4herer Betrachtung ist augenscheinlich, dass Holz, wenn es unge-sch\u00fctzt der Witterung ausgesetzt wird, schnel-ler altert und damit unn\u00f6tige Materialverluste entstehen. Tats\u00e4chlich waren es gerade die of-fensichtlichen Dinge, die von Materialeffizienz-beratern identifiziert wurden und deren Ver -\nbesserung zu einer deutlichen Steigerung der Materialeffizienz in Unternehmen f\u00fchrte.\nObwohl das Thema sehr komplex ist und eine \nVielzahl von Parametern und Prozessschritten zu beachten sind, sind es h\u00e4ufig die schlichten Ans\u00e4tze, die gro\u00dfe Verbesserungen bewirken. Auch scheint das Problem nicht selten in der Komplexit\u00e4t der Dinge zu liegen. Im Folgenden werden einige konkrete Ans\u00e4tze zur Senkung der Materialkosten und Beispiele aus den F\u00f6r -\nderprogrammen dargestellt.\nKostentransparenz und Information sind \nfundamentale Voraussetzungen f\u00fcr die Erkennung und Erschlie\u00dfung von Einspar -\npotenzialen. Wo sind welche Materialien gela-gert? Gibt es Restst\u00fccke, die verwendet werden k\u00f6nnten? Sind die Materialien schon f\u00fcr andere Produktionsprozesse verplant? Wichtige Infor -\nmationen m\u00fcssen klar und verst\u00e4ndlich doku-mentiert und allen Mitarbeitern zug\u00e4nglich ge-macht werden. Die Einbindung der Mitarbeiter ist generell ein zentraler Erfolgsfaktor bei der Erschlie\u00dfung von Materialeinsparpotenzialen. In den Bereichen Konstruktion, Produktion und Vertrieb t\u00e4tig, \u00fcben sie entscheidenden Einfluss auf den effizienten Umgang mit Material aus. Daher tr\u00e4gt eine Sensibilisierung und Schulung der Mitarbeiter sowie deren Einbindung in Ver -\nbesserungsprozesse entscheidend zur Verbesse-rung des Materialeinsatzes bei. \nDie Lagerorganisation stellt eine typische \nVerlustquelle dar, die nicht einfach zu er -\nkennen ist. Insbesondere in Betrieben, die mit der Zeit stark gewachsen sind, finden h\u00e4ufig unn\u00f6tige Materialtransporte statt. Dies erh\u00f6ht die Zahl von Besch\u00e4digungen oder Verwechs-lungen und somit die Ausschussquote. Nicht selten werden eingelagerte Materialien oder Komponenten nicht gefunden und aus der Not heraus nachbestellt oder nachproduziert. Auch kommt es immer wieder vor, dass Mate-rialien direkt aus dem Lager entsorgt werden, weil Produkte nicht mehr marktf\u00e4hig sind oder Komponenten nicht mehr verbaut werden k\u00f6n-nen, weil sie durch neue Versionen ersetzt wur -\nden. Schlanke, gut organisierte Lager erh\u00f6hen die Materialeffizienz und senken die Kapital- bindung.\nMaterialeinsparungen durch Weiterent-\nwicklung der Produktkonstruktion sind nicht auf den ersten Blick erkennbar und oft nur mit gr\u00f6\u00dferem Aufwand umsetz-bar. Aber die Hebelwirkung ist meist h\u00f6her \nals bei der Prozessoptimierung und wirkt sich auf weitere Bereiche aus. In vielen F\u00e4llen sind Komponenten \u00fcberdimensioniert oder sogar \u00fcberfl\u00fcssig. Welche Materialst\u00e4rken sind erfor -\nderlich? Welchen Belastungen ist das Produkt in der Nutzung ausgesetzt? L\u00e4sst sich die Kom-ponentenvielfalt reduzieren? Mit der Beantwor -\ntung dieser Fragen k\u00f6nnen neben verbesserten Gebrauchseigenschaften (z. B. geringeres Ge-wicht durch Leichtbauweise) auch Energieein-sparungen erzielt werden. Bei der Organisation der Fertigung ist es zudem sinnvoll, Auftr\u00e4ge zusammenzufassen, um vorhandenes Material optimal ausnutzen zu k\u00f6nnen. Durch geeig-nete quantitative Verschnittoptimierung und eine auftrags\u00fcbergreifende Produktion k\u00f6nnen Restl\u00e4ngen und -fl\u00e4chen mit wenigen Material-verlusten verbraucht werden. Dies gelingt am besten, je geringer die Teile- und Komponen-tenvielfalt ist.116 \nAuch durch die Auswahl der Bearbeitungs-\nprozesse kann die Materialeffizienz we-sentlich beeinflusst werden. Dabei muss bedacht werden, dass gerade in kleinen Unter -\nnehmen oft noch traditionelle Produktionstech-nologien eingesetzt werden, die weit entfernt sind von den neuesten Forschungsergebnissen. Spanabhebende Formgebungsprozesse bringen beispielsweise deutlich erkennbare Materialver -\nluste mit sich. Bei der Metallverarbeitung bietet es sich daher an, durch Verformung Rohlinge zu erzeugen, die der Zielstruktur sehr nahe kommen und nur noch leicht durch Drehen oder Fr\u00e4sen \u00fcberarbeitet werden m\u00fcssen. Ge-nerell bieten der Einsatz additiver Fertigung, neuer Verbundwerkstoffe und recyclingf\u00e4hi-ger Materialien enorme Einsparungspotenzia-le. Weitere wichtige Aspekte bei der Auswahl des geeigneten Bearbeitungsverfahrens sind Energieverbrauch und Prozesssicherheit bzw. Ausschussquoten. Auch der Werkzeugauswahl kommt eine gro\u00dfe Bedeutung zu. Schlechte oder schnell abnutzende Werkzeuge erh\u00f6hen die Ausschussquote und senken die Effizienz. \nIn fast allen Beratungsprojekten fiel auf, dass  \ngerade die kleinen Unternehmen keine kon-\nstant durchg\u00e4ngige Qualit\u00e4tskontrolle durch-f\u00fchren. Dabei ist dies ein wichtiger Ansatzpunkt f\u00fcr die Vermeidung von Materialverlusten. Fallen die M\u00e4ngel erst bei der Endkontrolle oder beim Kunden auf, sind viel Material, Arbeitszeit und ggf. Energie verschwendet worden.\nRessourcen schonen, \nWirtschaft st\u00e4rken\nDie Ergebnisse der Beratungen zeigen, dass mit \nrelativ kleinem Einsatz eine erstaunlich gro\u00dfe Wirkung erzielt werden konnte. Das ermittel-te durchschnittliche Einsparpotenzial lag bei 2 Prozent des Jahresumsatzes der Unternehmen. In einer Erstberatung (Potenzialanalyse) f\u00fcr ma-ximal 17.000 \u20ac wurden durchschnittliche Kos-teneinsparungen in H\u00f6he von 200.000 \u20ac allein beim Materialeinsatz aufgedeckt. Betrachtet man all diese Erkenntnisse aus den F\u00f6rderpro-grammen der demea wird schnell klar, dass in produzierenden Unternehmen viel Material verschwendet wird, was negative \u00f6konomische wie auch \u00f6kologische Auswirkungen hat.\nMaterial und Ressourcen stecken in allen Pro-\ndukten, deren Produktion und Verkauf die gute wirtschaftliche Lage in Deutschland auch weiterhin sichern sollen. Sowohl technische als auch soziale Innovationen oder neue Ge-sch\u00e4ftsmodelle sind gefragt, diesen Wohlstand aufrecht zu erhalten und den deutschen Mit-telstand wettbewerbsf\u00e4hig zu halten. Durch die interdisziplin\u00e4re Kooperation von Unternehmen und Forschungseinrichtungen verschiedener Bereiche m\u00fcssen Wissen zusammengetragen und sowohl neue Materialien als auch neue Produktionstechnologien in neue Produkte und Dienstleistungen umgesetzt werden. Einen ef-fizienten Umgang mit Ressourcen dabei von Beginn an mitzudenken, kann einerseits die Le-bensgrundlage k\u00fcnftiger Generationen sichern und ist gleichzeitig ein Wettbewerbsvorteil f\u00fcr den deutschen Mittelstand.\nEin Wandel im Umgang mit Ressourcen ist \u00fcber \nkurz oder lang vonn\u00f6ten. Das Zeitalter des hemmungslosen Konsums und der scheinbar unbegrenzten Ressourcen ist vorbei. Ein Anreiz f\u00fcr Unternehmen, sich dem Thema eher fr\u00fcher als sp\u00e4ter zu widmen, kann der finanzielle As-pekt sein. Nicht nur aus \u201emoralischer\u201c Sicht, sondern auch aus Gr\u00fcnden der Kosteneinspa-rung und des Wettbewerbs, ist der effiziente Einsatz von Ressourcen sinnvoll und notwen-dig. Ist Materialeffizienz \u2013 oder besser Ressour -\nceneffizienz \u2013 also ein wesentlicher Trend des 21. Jahrhunderts? \nDie Arbeit der demea reiht sich ein in ein Spek-\ntrum vielf\u00e4ltiger Projekte, die in der VDI/VDE-IT bis heute zum Thema Ressourceneffizienz durchgef\u00fchrt wurden. Das Neue bei der demea war die Einbeziehung kompetenter und erfah-rener Materialeffizienzberater, das Besondere Wohlstand durch Materialeffizienz \u00a7 117\nein schneller und unmittelbarer Beitrag zur Ver -\nbesserung der Materialeffizienz in den mittel-\nst\u00e4ndischen Unternehmen. So hat die \u00f6ffentli-che Hand mit der demea in vielen Unternehmen einen Innovationsschub angeregt: \u00fcber die Erschlie\u00dfung von Einspareffekten durch relativ einfache organisatorische Verbesserungen und die Reduktion des Materialeinsatzes hinaus, wurde auch ein offenerer Umgang mit Impul-sen von au\u00dfen, neuen Ideen der eigenen Mit-arbeiter und eine gewisse Innovationskultur in Gang gesetzt.\n1 Carlowitz, Hann\u00df Carl von (1713): Sylvicultura Oeconomica oder hau\u00dfwirthliche Nachricht und Naturm\u00e4\u00dfige Anweisung zur Wilden Baum-Zucht. 118 \nDie Innovation vor Augen\nDr. Marcel Kappel  Dr. Karsten Rapsch\nIn der heutigen Gesellschaft sind innovative \nIdeen und Produkte der Vergangenheit allge-genw\u00e4rtig. In manchen F\u00e4llen ist es m\u00f6glich, diese direkt zu benennen oder zu identifizie-ren und in manchen F\u00e4llen haben sich diese Technologien so stark in unser allt\u00e4gliches Le-ben integriert, dass wir diese als Innovation gar nicht mehr wahrnehmen. Dennoch hat die Menschheit in den vergangenen Jahrhunderten erstaunliche Technologien hervorgebracht, die unsere Gesellschaft bis heute nachhaltig pr\u00e4-gen, verbessern oder gar erst erm\u00f6glichen. Eine dieser Technologien wird heutzutage von mehr als 60 Prozent der \u00fcber 16-j\u00e4hrigen t\u00e4glich be-nutzt und sogar MacGyver w\u00e4re neidisch auf den Einfallsreichtum hinter dieser Innovation.\n1 \nOhne diese w\u00e4ren viele Menschen so stark in ihrem sozialen Leben eingeschr\u00e4nkt, dass ein normales Miteinander nicht m\u00f6glich w\u00e4re. Da-bei f\u00e4llt einem Gro\u00dfteil der Personen, die die-sen Gegenstand ben\u00f6tigen, gar nicht mehr auf, dass sie ihn fast immer dabei haben und er ein unverzichtbarer Teil ihres allt\u00e4glichen Lebens geworden ist. Das hei\u00dft jedoch nicht, dass sie ihn nicht mehr sehen. Vielmehr sehen gerade viele Menschen DURCH ihn hindurch, um die-sen Text zu lesen. Die Rede ist von der Brille.  \nIm Laufe der Jahrhunderte hat die Brille eine er -\nstaunliche Wandlung vollzogen, wobei sie sich \nstets den jeweiligen Zeiten, technologischen Rahmenbedingungen und den Herausforderun-gen der damaligen Gesellschaft angepasst hat. \u00dcber diese Zeit wurde sie weiterentwickelt, op-timiert, adaptiert und hat einen festen Platz in unserer heutigen Gesellschaft eingenommen. \n\u201eWenn man sich in unserer Zeit eine gr\u00f6\u00dfere \nMenge von Menschen betrachtet, findet man darunter nicht wenige, welche sich eines Gla-ses bedienen, um in der N\u00e4he oder in die Ferne besser zu sehen. Dies f\u00e4llt uns gar nicht mehr auf, wir sind gew\u00f6hnt, dieses wichtige Hilfsmit-tel im allgemeinen Gebrauche zu finden.\u201c\n2\nDie Feststellung wurde schon im Jahre 1903 vom deutschen Augenarzt Emil Bock getroffen. Mehr als 100 Jahre sp\u00e4ter trifft diese Aussa-ge immer noch zu, vielmehr ist die Brille noch mehr Teil unserer Gesellschaft geworden. \nSeit Anbeginn der Menschheit gab es keine Hil-\nfe f\u00fcr Fehlsichtige. W\u00e4hrend f\u00fcr Kurzsichtige die fernen Dinge verschwommen waren, war die N\u00e4he f\u00fcr die sogenannten \u201e\u00dcbersichtigen\" \u2013  \ndie Weitsichtigen \u2013 nicht mehr scharf zu er -\nkennen. Wer davon beeintr\u00e4chtigt war, hatte fr\u00fcher einfach Pech gehabt und musste damit leben! \nDer Erfolg der Brille in diesem Ma\u00dfe war in ih-\nren Anf\u00e4ngen noch lange nicht abzusehen. Die ersten Schritte hin zu einer optischen Sehhilfe gehen zur\u00fcck bis in die Antike, als Archimedes erste Untersuchungen an grob behauenen Kris-tallen durchf\u00fchrte, diese aber nicht als Sehhilfe verwendete. Trotzdem hielt sich lange das Ge-r\u00fccht, dass die ersten Sehhilfen in der Antike zu suchen seien. Zum Beispiel berichtete Mar -\nco Polo, dass in China Augengl\u00e4ser schon seit mehr als 1.000 Jahren bekannt waren. Diese Gl\u00e4ser erwiesen sich aber als magisches Utensil bei traditionellen Heilpraktiken und hatten kei-nerlei sehkorrigierende Wirkung. Auch berich-tete Plinius d. \u00c4. (23\u201379 n. Chr.), dass Kaiser Nero seine geliebten Gladiatorenk\u00e4mpfe immer durch einen Smaragden betrachtete. Neuere Forschungen ergaben jedoch, dass er dies nicht aufgrund einer Fehlsichtigkeit tat, sondern als Schutz gegen das glei\u00dfende Sonnenlicht in der Arena.\n3 In dieser Zeit war es g\u00e4ngige \nPraxis, sich bei nachlassender Sehkraft von ei-\n40 JahreDie Innovation vor Augen \u00a7  119\nnem Bediensteten vorlesen zu lassen, so wie es \nauch der Gelehrte und Politiker Cicero (106-43  \nv. Chr.) gehandhabt hat. Auch wenn dieser Ge-danke einen gewissen Charme hat, war dieses Prinzip sicherlich nicht dauerhaft zukunftsf\u00e4hig.\nErste konkrete mathematische Berechnun-\ngen zur Lichtbrechung und -reflexion wurden dann von Ibn al-Heitham (965-1039) in Basra angestellt. Er erkannte in seiner Abhandlung \u201eSchatz der Optik\" zudem auch die optische Vergr\u00f6\u00dferung von konvexen Linsen und fertigte als Erster sogenannte Lesesteine aus geschlif-fenem Glas mit einer glatten Grundfl\u00e4che an. Jahrhunderte sp\u00e4ter gelangten \u00dcbersetzungen der Schriften al-Heitams nach Westeuropa.\n4  \nItalienische M\u00f6nche griffen die Gedanken auf und entwickelten die Lesesteine weiter. Zwar mussten diese noch \u00fcber jeden einzelnen Buch-staben gef\u00fchrt werden, doch \u00e4lteren M\u00f6nchen war es nun wieder verg\u00f6nnt ihre Schriften zu entziffern. Es ist sicherlich auch kein Zufall, dass bei der umfangreichen Schreibarbeit der M\u00f6n-che in dunklen Klosterr\u00e4umen bei flackerndem Kerzenlicht das Aufkommen von einfachen Le-sehilfen auf durchaus fruchtbaren Boden fiel. Typische Materialien f\u00fcr die Linsen zu dieser Zeit waren Bergkristall oder auch der Edelstein Beryll \u2013 von dem sich auch der Name \u201eBrille\" ableitete. Einzig die Glash\u00fctten von Murano in Venedig waren im 13. Jahrhundert in der Lage, v\u00f6llig klares Glas ohne Blasen herzustellen. Es stellte sich heraus, dass dies ideal war f\u00fcr op-tische Sehhilfen. Im Jahre 1300 wurde die Her -\nstellung von Augengl\u00e4sern per Ratserlass regle-mentiert und erste Qualit\u00e4ts-Vorschriften und -bedingungen definiert.\n5\nDie Lesesteine der M\u00f6nche wurden zur beque-meren Handhabung bald auf beiden Seiten geschliffen, mit einem dicken Ring aus Eisen, Horn oder Holz eingefasst, sowie mit einer Halterung versehen, welche als \u201eManokel\u201c be-zeichnet wird. Seit dem 16. Jahrhundert sind solche Einhandgl\u00e4ser auch mit konkaven Linsen nachweisbar, also zum Gebrauch bei Kurzsich-tigkeit. Durch das Zusammennieten zweier die-ser Stielgl\u00e4ser entstand die erste Brillenform, die Nietbrille\n6. Zwar musste man diese Urform der \nBrille von Hand auf der Nase festhalten, jedoch war dadurch das Lesen und Schreiben bis ins hohe Alter m\u00f6glich. Diese Form der Brille wurde zum Inbegriff der Intellektualit\u00e4t, so dass mit-telalterliche Maler die gelehrigsten Figuren der Geschichte mit Brille abbildeten. Dadurch sind interessanterweise auf einigen Gem\u00e4lden aus dieser Zeit einige Anachronismen entstanden (wie in Abbildung 1). \nDie ersten Brillen, die zumindest eine gewisse \n\u00c4hnlichkeit mit den heutigen Modellen hatten, tauchten dann Ende des 15. Jahrhunderts auf. Hier wurde die Nietbrille von der B\u00fcgelbrille ab-gel\u00f6st, deren Fassung dann aus einem einzigen St\u00fcck bestand, wie beispielsweise aus Eisen, Silber, Bronze oder Leder. Als Zusatz zu die-sen Modellen wurde ein elastischer Ledersteg angebracht und mit einem Schlitz versehen. Dieser wurde dann verwendet, um das Gestell auf dem Nasenr\u00fccken zu fixieren. Hierbei lag auch das gr\u00f6\u00dfte Problem der damaligen Brillen-gestelle. Immer wieder rutschten die schweren \nAbb.1: Conrad von Soest malte 1403 in der Stadtkirche in \nBad Wildungen den sogenannten \u201eBrillenapostel\u201c. Dies ist die fr\u00fcheste Darstellung einer Brille n\u00f6rdlich der Alpen und gleichzeitig ein herrlicher Anachronismus.120 \nGl\u00e4ser von der Nase oder wurden so stark auf \nder Nase fixiert, dass der Tr\u00e4ger dies als \u00e4u-\u00dferst unangenehm empfand. Aufgrund der besonders edlen Materialien f\u00fcr die Fassung galten in dieser Zeit in Spanien besonders gro-\u00dfe Modelle gar als Statussymbol. Dort war das Tragen einer Brille ein Zeichen von Luxus und gesellschaftlichem Rang: je gr\u00f6sser die Gl\u00e4ser, desto teurer die Brille und umso h\u00f6her die gesellschaftliche Stellung des Tr\u00e4gers. In den anderen L\u00e4ndern hatte die Brille jedoch einen schweren Stand. Sie wurde zwar als Zeichen von Intelligenz angesehen, aber nat\u00fcrlich auch als ein Eingest\u00e4ndnis des \u00c4lterwerdens. Viele ber\u00fchmte Personen lehnten es deshalb auch ab eine Brille zu tragen, auch wenn sie stark kurzsichtig waren, wie beispielsweise Napole-on und Goethe ( \u201eSo oft ich durch eine Brille \nsehe, bin ich ein anderer Mensch und gefalle mir nicht.\u201c).\n7  \nIm 18. Jahrhundert kam dann die sogenann-te N\u00fcrnberger Drahtbrille auf den Markt. Hier wurden die Gl\u00e4ser durch d\u00fcnne metallene B\u00fc-gel gehalten. Damals bekam sie den \u00e4u\u00dferst treffenden, aber wenig schmeichelhaften Na-men \u201eNasenquetsche\u201c. Trotzdem setzte sie sich in ganz Europa durch und bot einen bis dahin nicht f\u00fcr m\u00f6glich gehaltenen Tragekomfort. \nSeit Ende des 18. Jahrhunderts ist auch das \nsogenannte Monokel bekannt. Bestehend aus nur einer Linse in einer runden Fassung wurde es nur von den Muskeln rund um das Auge gehalten. Insbesondere in der h\u00f6heren Gesellschaft in Deutschland und England lag dieses Modell voll im Trend. Die Franzosen konnten sich jedoch generell mit Brillen nicht anfreunden. Wenn man eine Brille tragen musste, war ihnen das ungemein peinlich. So setzte sich bei unseren westlichen Nachbarn die sogenannte \u201eScherenbrille\u201c durch. Diese wurde mit einer Hand vor die Augen gehal-ten, \u00e4hnlich wie ein Opernglas, und konnte gegebenenfalls schnell weggesteckt werden. Diese Variante war in der \u00d6ffentlichkeit so de-zent, dass sogar Napoleon und Goethe ihren Gefallen daran fanden.\n8Nach der Entwicklung der ersten Brille dauerte es fast 500 Jahre bis die Idee entstand, die Gl\u00e4-ser und die Fassung mit B\u00fcgeln seitlich an den Schl\u00e4fen zu fixieren. Die sogenannte Ohrenbril-le wurde Mitte des 18. Jahrhunderts in einer Vorform von einem Pariser Optiker und dann in einer verbesserten Form (mit Gelenken und verl\u00e4ngerten B\u00fcgel, so dass sie \u00fcber die Ohren reichten) von einem Londoner Optiker entwi-ckelt.\n9 Die Brille, so wie wir sie heute kennen, \nmit ihrer anatomisch perfekten Passung, wurde dann in den goldenen 20er Jahren entwickelt und in den Jahrzehnten danach bis heute st\u00e4n-dig weiter optimiert und individualisiert. \nAuch wenn der Entwicklungsweg hin zu den \nheutigen Modellen im Wesentlichen klar be-schrieben und nachvollziehbar ist, gab es doch viele Varianten und Techniken, die man heute als entwicklungstechnische Einbahnstra\u00dfe oder bestenfalls als Kuriosit\u00e4t bezeichnen w\u00fcrde. Da w\u00e4re zum Beispiel die Bandbrille zu nennen, die man sich mittels eines Lederbands einfach um den Kopf band, oder die Stirnreifbrille aus Stahl, bei der man nicht viel erkl\u00e4ren muss.\n10 Ein \nweiteres Beispiel ist die M\u00fctzenbrille, bei der die Linsen an einer M\u00fctze angebracht wurden. Wenn man dieses Modell trug, musste man, als eine der wenigen Ausnahmen in der damaligen Zeit, die Kopfbedeckung zur Begr\u00fc\u00dfung nicht abnehmen. Eigentlich ein tolles Verkaufsargu-ment! Es gab noch weitere Zwischenformen, wie zum Beispiel die Zweist\u00e4rkenbrille (Bifokal-brille), die von Benjamin Franklin (1706 \u20131790) erfunden wurde. Um die Korrektur von Kurz-sichtigkeit und Weitsichtigkeit in einer Brille zu kombinieren, fertigte er pro Seite zwei halbe Linsen an, die mit einer waagerechten Tren-nung in einem Rahmen untergebracht wurden. Dies stellte zu der damaligen Zeit eine bahn-brechende Innovation dar. Diese damals neu entwickelte Zweist\u00e4rkenbrille sollte jedoch erst zwei Jahrhunderte sp\u00e4ter in die breite Anwen-dung gehen.\n11\nDoch nicht nur der Mensch hat zur Ver\u00e4n-derung und Adaption der Brille beigetragen, sondern die Brille selbst hat in den letzten Die Innovation vor Augen \u00a7  121\nJahrzehnten auch Einfluss auf unsere heutige \nGesellschaft, den technologischen Fortschritt und direkt bzw. indirekt auf die Evolution der gesamten Menschheit genommen. Schon der Philosoph Ren\u00e9 Descartes hat angemerkt, dass die F\u00e4higkeit zu sehen eine unserer essenziells-ten F\u00e4higkeiten ist.\n12 Daher geh\u00f6ren alle in die-\nsem Zusammenhang diesen Sinn verst\u00e4rkenden oder erhaltenden Erfindungen zu den wichtigs-ten der Menschheit.  Die Brille ist nach heutiger Definition ein Medizinprodukt, welches dazu dient, k\u00f6rperliche M\u00e4ngel zu kompensieren und die volle Leistungsf\u00e4higkeit des menschli-chen K\u00f6rpers wieder her zu stellen.\n13\nDoch dar\u00fcber hinaus erm\u00f6glicht die Brille nicht nur die Kompensation k\u00f6rperlicher M\u00e4ngel, sondern vielmehr eine Leistungssteigerung ih-res Benutzers. So konnte in der Vergangenheit durch die Anwendung der Brille die zunehmen-de Sehschw\u00e4che von \u00e4lteren Menschen kom-pensiert werden. Dadurch konnten diese ihre Berufe, bei welchen es auf gute Augen ankam, l\u00e4nger aus\u00fcben und somit l\u00e4nger produktiv t\u00e4tig sein. So konnte durch die Nutzung von Brillen die Lebensarbeitszeit von beispielsweise Schrei-bern, Lektoren, Instrumenten- und Werkzeug-machern, Webern und Metallarbeitern mehr als verdoppelt werden.\n14 Zudem erlaubte die Brille \nauch Arbeiten, welche ohne Sehkorrektur bzw. -verst\u00e4rkung gar nicht m\u00f6glich gewesen w\u00e4ren. Beispiele hierf\u00fcr sind die Feinmechanik, die Her -\nstellung genauerer und pr\u00e4ziserer Werkzeuge und die Entwicklung komplizierter Maschinen.\n15   \nGeschichtlich gesehen war die Brille eine von mehreren Schl\u00fcsselerfindungen, welche bereits im Mittelalter die sp\u00e4tere \u00dcberlegenheit Euro-pas begr\u00fcndete.\n16 Provokativ formuliert k\u00f6nnte \nman somit schlussfolgern, dass die Erfindung der Brille ma\u00dfgeblich zur Entwicklung von Technologien, die wir heute als disruptiv oder innovativ bezeichnen, beigetragen hat. Unum-stritten ist hingegen, dass ohne die Erfindung der Brille unsere heutige Gesellschaft und unser allt\u00e4gliches Leben anders aussehen w\u00fcrden. \nDie belebte Welt, wie wir sie kennen, ist ein \nProdukt der Evolution. Ein Grundprinzip der Evolutionstheorie besteht darin, dass sich stets die effizientesten Eigenschaften einer Spezi-es durchsetzen (\u201esurvival of the fittest\u201c) und es somit zu einer kontinuierlichen Weiterent-wicklung innerhalb der Spezies kommt. Unbe-stritten ist wohl, dass der Mensch durch seine kontinuierliche genetische Weiterentwicklung zu einem der erfolgreichsten S\u00e4ugetiere auf unserem Planeten geworden ist. Das Ergeb-nis, welches wir heute kennen, ist jedoch kein reines Zufallsprodukt. Einer der wichtigsten Er -\nfolgsfaktoren in der evolution\u00e4ren Entwicklung des Menschen war seine F\u00e4higkeit, bereits fr\u00fch Werkzeuge herstellen und einsetzen zu k\u00f6n-nen, um seine k\u00f6rperlichen Limitierungen zu kompensieren. Zu eben jenen Werkzeugen geh\u00f6rt auch die Brille! Durch den Einsatz von Werkzeugen war der Mensch, im Vergleich zu anderen Lebewesen, in der Lage, seine eige-ne Evolution zu beeinflussen. Unter normalen Selektionsbedingungen w\u00fcrden starke Sehbe-hinderungen dazu f\u00fchren, dass das betroffe-ne Individuum sich gegen seine Artgenossen nicht durchzusetzen w\u00fcrde.\n17 Durch die Ver -\nwendung von Hilfsmitteln, wie zum Beispiel der Brille, konnte der Mensch diesem Selek-tionsdruck entgehen, und somit indirekt seine eigene Evolution ma\u00dfgeblich mitgestalten. Obwohl dies ein Teil der Wahrheit ist, zeigen aktuelle Studien, dass die Kurzsichtigkeit nicht allein ein Produkt der Evolution ist. Vielmehr belegen diese, dass die Kurzsichtigkeit ein Massenph\u00e4nomen der j\u00fcngsten Vergangenheit ist und im Vergleich zu klassischen genetischen Ver\u00e4nderungen deutlich schneller entsteht.\n18\nEine m\u00f6gliche Ursache f\u00fcr diesen rapiden An-stieg der Kurzsichtigkeit liefern verschiedene Studien. Es konnte gezeigt werden, dass offen-sichtlich ein Zusammenhang zwischen Kurzsich-tigkeit und Naharbeit besteht. Je mehr T\u00e4tigkei-ten im Nahbereich unserer Augen stattfinden (wie B\u00fcroarbeit, aber auch das stundenlange Starren auf sein Smartphone), desto wahr -\nscheinlicher ist es, von Kurzsichtigkeit betroffen zu sein. Schlussendlich ist es jedoch noch nicht abschlie\u00dfend gekl\u00e4rt, welche Ursachen tats\u00e4ch-lich verantwortlich gemacht werden k\u00f6nnen. 122 \nAndere Studien sehen den Hauptgrund nicht \nim Nahsehen, sondern vermuten einen Zusam-menhang zwischen Kurzsichtigkeit und der Auf-enthaltszeit im Freien. Demnach kann sich das Sonnenlicht auf das Augenwachstum auswir -\nken. Hauptrolle spielt in diesem Fall das Dopa-min, welches das Augenwachstum reguliert.\n19 \nIn einem sind sich die Studien aber einig und sicher: Rausgehen ins Freie kann den Augen nicht schaden! \nMit dem Wissen \u00fcber die Jahrhunderte alte \nEntwicklung und dem Umstand, dass die Brille uns mittlerweile so selbstverst\u00e4ndlich geworden ist, dass wir nicht lange dar\u00fcber nachdenken, wenn wir sie morgens aufsetzen, ist es doch einigerma\u00dfen erstaunlich, dass die Geschichte dazu bei der breiten Bev\u00f6lkerung weitgehend in Vergessenheit geraten ist. Dabei haben nur wenige Erfindungen so viel f\u00fcr die soziale In-klusion getan wie die einfache Korrekturbrille. F\u00fcr den Fall, dass man einen einfachen Seefeh-ler hat, jedoch keine M\u00f6glichkeit sich eine Kor -\nrekturbrille zu beschaffen, ist es laut der WHO dreimal wahrscheinlicher arbeitslos zu sein, sich bei einem Verkehrsunfall zu verletzen oder un-ter Depressionen zu leiden. Ohne Brille ist es zu-dem sehr schwer bzw. nicht m\u00f6glich ein Auto zu fahren, ein Buch zu lesen oder bestimmten T\u00e4tigkeiten nachzugehen, bei denen ein unein-geschr\u00e4nktes Sehverm\u00f6gen notwendig ist. Ein-fachste Formen des gesellschaftlichen Zusam-menseins werden extrem herausfordernd und k\u00f6nnen betroffene Personen vor ungeahnte Probleme stellen. Sehr konservativ sch\u00e4tzt die WHO, dass weltweit mehrere Hundert Millio-nen Menschen auf eine Sehhilfe angewiesen sind.\n20 Andere Studien gehen da noch erheblich \nweiter und nennen Zahlen von bis zu 1,5 Mrd. betroffenen Menschen nur f\u00fcr Kurzsichtigkeit oder bis zu 2,3 Mrd. Betroffenen f\u00fcr alle Seh-fehler, die mit einer einfachen Korrekturbrille \nAbb. 2: Im Jahre 2050 werden 60 Prozent der Weltbev\u00f6lkerung an Kurzsichtigkeit leiden. Jeder Zehnte w\u00e4re demnach sogar \nstark kurzsichtig. Im Vergleich zum Jahr 2000 also ein erheblicher Anstieg.  Quelle: Holden, B. A.; Fricke, T. R.; Wilson, D. A.; Jong, M.; Naidoo, K. S.; Sankaridurg, P .; Wong, T. Y .; Naduvilath, T. J.; Resnikoff, S. (2016): Global Prevalence of Myopia and High Myopia and Temporal Trends from 2000 through 2050. In: Ophthalmology 123 (2016) 5, S. 1036\u201342.50 %\n10 %2 %22 %\nVSDie Pr\u00e4valenz der Kurzsichtigkeit ist auf dem Vormarsch\nGesamte Weltbev\u00f6lkerung mit \nKurzsichtigkeit im Jahr 2000Prognostizierte Kurzsichtigkeit der gesamten Weltbev\u00f6lkerung im Jahr 2050\n  schwache/mittlere Kurzsichtigkeit  > -0.50 D          starke Kurzsichtigkeit > -5.00 DDie Innovation vor Augen \u00a7  123\nbehoben werden k\u00f6nnen \u2013 das entspricht mehr \nals 30 Prozent der jetzigen Weltbev\u00f6lkerung.21\nEs ist sicherlich interessant zu wissen, dass die globale Verteilung extrem unterschiedlich ist. Einige asiatische L\u00e4nder haben bei Kurzsichtig-keit eine Rate von \u00fcber 80 Prozent. Insbesonde-re in den Schulen und Universit\u00e4ten Singapurs liegt die Quote zwischen 80 und 90 Prozent. In Europa und in den USA liegt der Wert bei ca. 30 bis 40 Prozent, w\u00e4hrend in Afrika nur Werte zwischen 10 und 20 Prozent festgestellt wurden.\n22 Wenn Sie bereits jetzt der Meinung \nsind, dass diese Werte besorgniserregend klin-gen, d\u00fcrfen Sie nicht schockiert sein, wie eine m\u00f6gliche Zukunft aussehen k\u00f6nnte. \nLaut einer aktuellen Studie wird im Jahre 2050 \njeder zweite Mensch auf der Welt kurzsichtig sein. Aufgrund der Tatsache, dass die Zahlen zuk\u00fcnftig weiter steigen werden, k\u00f6nnen ei-gentlich nur noch Optiker und Augen\u00e4rzte zu-versichtlich in die Zukunft blicken.\n23\nObwohl sie von einem Gro\u00dfteil der Bev\u00f6lkerung ben\u00f6tigt wird, ist sie nicht von allen geliebt. Sie wird trotz ihrer ungeheuren N\u00fctzlichkeit in der \u00f6ffentlichen Wahrnehmung auch heute oftmals noch immer als optischer Makel angesehen. Abgesehen von Brillenwerbung zeigen Fotos in aktuellen Modejournalen und Zeitschriften nur in sehr geringer Zahl Brillentr\u00e4ger.\n24 Oder \nf\u00e4llt Ihnen spontan ein Kino- oder Fernsehheld mit Brille ein? Ausgenommen sind hier nat\u00fcr -\nlich Sonnenbrillen, die aus anderen Gr\u00fcnden in Filmen getragen werden. Man denke an dieser Stelle nur an einen James Bond, eine Marilyn Monroe oder einen John McLane mit Horn-brille. Ein interessanter Gedanke, aber wenig \u00fcberzeugend. Und sollte Ihnen doch noch ein Kinoheld einfallen wie etwa Harry Potter, dann sollen mit Hilfe der Brille bestimmte Eigenschaf-ten des Charakters, wie Intelligenz, Verletzlich-keit oder ein hohes Alter verdeutlicht werden. In Anbetracht des schwindelerregenden welt-weiten Anstiegs der Kurzsichtigkeit k\u00f6nnte sich die Sichtweise der Medien bei der Darstel-lung von Brillentr\u00e4gern jedoch in den n\u00e4chsten Jahrzehnten noch \u00e4ndern. Es gibt aber auch Menschen, die ihre Brille zum Markenzeichen gemacht haben. Hier geh\u00f6rt die Sehhilfe zum festen Bestandteil der \u00f6ffentlichen Wahrneh-mung. Prominente Beispiele sind hier: Elton John, Woody Allen, Gandhi und Johnny Depp, welcher seit der Geburt auf dem linken Auge fast blind und auf dem rechten Auge stark kurz-sichtig ist. Diese Liste lie\u00dfe sich noch um einiges verl\u00e4ngern, da immer mehr Menschen zu ihrer Sehhilfe stehen und diese nicht als st\u00f6renden Makel wahrnehmen. \nFakt ist jedoch, dass die Beeintr\u00e4chtigung durch \nSehbehinderungen kontinuierlich zunimmt und die Gesellschaft vor massive Probleme stellt. Besonders vor dem Hintergrund des demo-graphischen Wandels und der zunehmenden Digitalisierung in Kombination mit sich rapide ver\u00e4ndernden Arbeits- und Lebensbedingun-gen sind L\u00f6sungen und Konzepte notwendig, um diesen Ver\u00e4nderungen begegnen zu k\u00f6n-nen. Obwohl nicht eindeutig feststeht, welchen Einfluss die Brille auf unsere evolution\u00e4re Ent-wicklung hatte, kann jedoch guten Gewissens behauptet werden, dass sie auch in Zukunft ein unverzichtbares Hilfsmittel der Menschheit sein wird. In diesem Zusammenhang kann provo-kativ behauptet werden, dass die Brille unsere historische und technologische Entwicklung zu-n\u00e4chst erm\u00f6glicht hat und uns auch in Zukunft die Nutzung der Digitalisierung und die Adapti-on an die sich ver\u00e4ndernden Lebensbedingun-gen vereinfachen wird. Vielmehr ist und wird das Grundprinzip der Brille auch in Zukunft ein verl\u00e4ssliches Hilfsmittel der Menschheit darstel-len, unabh\u00e4ngig davon, wie sich die technische Ausgestaltung weiterentwickeln wird. Somit war, ist und bleibt die Brille einer der innovativs-ten Erfindungen der Menschheit.\nFazit\nAus den mittelalterlichen italienischen Kl\u00f6stern heraus und nach einer Jahrhunderte alten Ent-wicklung trat die Brille ihren Siegeszug um die Welt an. Dieser h\u00e4lt bis heute unver\u00e4ndert an und ein Ende des Erfolgs der einfachen Sehhil-fe ist mit Blick auf neuere Entwicklungen noch 124 \nlange nicht abzusehen. Oder mit anderen Wor -\nten ausgedr\u00fcckt: Die Geschichte der Brille ist \nnoch lange nicht zu Ende. Ganz im Gegenteil. Heutzutage und auch in Zukunft werden Gl\u00e4-ser, B\u00fcgel und Nasenauflagen optimiert und weiterentwickelt. Innovative Hightech-Werk-stoffe maximieren den Tragekomfort; die Gl\u00e4ser werden immer noch d\u00fcnner und leichter, die Fassungen immer stabiler und flexibler. L\u00e4ngst gibt es schon Modelle im Bereich von unter 15 Gramm Gewicht. Diese lange und kuriose Ent-wicklungsgeschichte der Brille bis zu den heu-tigen Modellen mit all ihren Irrungen und Wir -\nrungen zeigt aber auch, dass eine Innovation niemals zu Ende entwickelt und niemals fertig optimiert ist. Eine Innovation muss sich immer den \u00e4u\u00dferen Umst\u00e4nden und dem entsprechen-den Zeitgeist anpassen. Hier sei nochmal das Beispiel der Franklinschen Bifokalbrille genannt: Obwohl die Brille seiner Zeit um 200 Jahre vor -\naus war, hat sie sich Mitte des 18. Jahrhunderts noch nicht durchsetzen k\u00f6nnen. Damals waren zwei verschiedene Brillen mit unterschiedlichen optischen Werten einfach deutlich billiger und einfacher zu beschaffen als die Speziall\u00f6sung des Mannes auf dem 100 Dollar Schein. Heute sind der Vielfalt an Formen und Materialien je-doch kaum mehr Grenzen gesetzt.\nEine Prognose f\u00fcr die Zukunft der Brille ist, \nin Anbetracht von Laser-OPs, (irgendwann in-telligenten) Kontaktlinsen, aber auch Virtual und Augmented Reality Brillen, sehr schwie-rig. Aber angesichts des drastischen Anstiegs der Kurzsichtigkeit k\u00f6nnen zumindest Op-tiker sehr wahrscheinlich optimistisch in die Zukunft schauen. Schaden kann es f\u00fcr die eigenen Augen jedenfalls nicht, wenn man sich ab und zu mal vornimmt: \u201eMehr drau-\u00dfen, weniger drinnen.\u201c Auch sollten Sie mal Ihre eigene Brille abnehmen (die Wahrschein-lichkeit ist ja recht hoch, dass Sie eine auf der Nase haben) und genauer betrachten. Viel-leicht sehen Sie Ihre Brille, das Ergebnis ei-nes 700 Jahre langen Entwicklungsprozesses, dann mit anderen Augen.\n1 Institut f\u00fcr Demosk opie (2014): Brillenstudie. Allensbach.\n2 Bock,  E. (1903): Die Brille und ihre Geschichte. Wien. Verlag Josef Safar.\n3 Buck,  S (2002): Der gesch\u00e4rfte Blick. Zur Geschichte der Brille und ihrer Verwendung in Deutschland seit 1850. Marburg.\n4 V erma, R. L. (1969): Al-Hazen. Father of modern optics. In: al-Arabi (1969).\n5 White , L. (1961): Eilmer of Malmesbury, an Eleventh Century Aviator. A Case Study of Technological Innovation, Its Context and Tradition. \n In: \nTechnology and Culture (1961).\n6 Buck,  S. (2002): Der gesch\u00e4rfte Blick. Zur Geschichte der Brille und ihrer Verwendung in Deutschland seit 1850. Marburg. \n7 Goethe , J. W. v.; Muschg, A.(2006): Wilhelm Meisters Wanderjahre oder die Entsagenden, 1. Aufl., [Nachdr.]. Frankfurt am Main, Leipzig.\n8 Buck,  S. (2002): Der gesch\u00e4rfte Blick. Zur Geschichte der Brille und ihrer Verwendung in Deutschland seit 1850. Marburg.\n9 Rossi , F .(1989): Brillen. Vom Leseglas zum modischen Accessoire. M\u00fcnchen.\n10 M\u00fcnchow , W. (1984): Geschichte der Augenheilkunde. In: Der Augenarzt; 9 (1984).\n11 K uisle, A. (1997): Brillen. Gl\u00e4ser, Fassungen, Herstellung, 3. \u00fcberarb. Aufl. M\u00fcnchen.\n12 Descartes , R. R.(2017): La Dioptrique. Paris, l\u2019\u00e9dition originale du Discours est Leyde 1637.\n13 Bundesinstitut f\u00fcr Arzneimittel und Medizinprodukte: Medizinproduktgesetz. www.bfarm.de\n14 Landes , D. S. (1999): Wohlstand und Armut der Nationen. Warum die einen reich und die anderen arm sind, Berlin.\n15 Wikipedia: Brille .  https://de.wikipedia.org/wiki/Brille. [Zugriff am 5.4.2018].\n16 Landes , D. S. (1999): Wohlstand und Armut der Nationen. Warum die einen reich und die anderen arm sind, Berlin.\n17 R\u00fchli , F .; van Schaik, K.; Henneberg, M. (2016): Evolutionary Medicine. The Ongoing Evolution of Human Physiology and Metabolism. In: Physio- \n logy (Bethesda,\n Md.) 31 (2016) 6, S. 392\u201397. Kutschera, U. (2009): Tatsache Evolution. Was Darwin nicht wissen konnte, Orig.-Ausg. M\u00fcnchen.\n18 Morgan,  I.; Megaw, P . (2004): Using natural STOP growth signals to prevent excessive axial elongation and the development of myopia. \n In: \nAnnals of the Academy of Medicine, Singapore 33 (2004) 1, S. 16\u201320.\n19 J\u00f6rg Zittlau (2009): Die Menschheit wird kurzsichtig.  Axel Springer SE (Hrsg.). www.welt.de/welt_print/wissen/article5440310. \n [Zugriff am 05.04.2018] \nWallman, J.; Winawer, J. (2004): Homeostasis of eye growth and the question of myopia. In: Neuron 43 (2004) 4, S. 447\u201368.\n20 Bulletin of the World Health Organization 2012; 90:728-738. doi: 10.2471/BLT.12.104034 World Health Organization (2017): \n V\nision impairment and blindness. www.who.int/mediacentre/factsheets/fs282/en/. [Zugriff am 5.4.2018].\n21 F oster, P . J.; Jiang, Y . (2014): Epidemiology of myopia. In: Eye (London, England) 28 (2014) 2, S. 202\u201308.\n22 Dolgin,  E. (2015): The myopia boom. In: Nature 519 (2015) 7543, S. 276\u201378.\n23 Holden,  B. A.; Fricke, T. R.; Wilson, D. A.; Jong, M.; Naidoo, K. S.; Sankaridurg, P .; Wong, T. Y .; Naduvilath, T. J.; Resnikoff, S. (2016): \n Global Prev\nalence of Myopia and High Myopia and Temporal Trends from 2000 through 2050. In: Ophthalmology 123 (2016) 5, S. 1036\u201342.\n24 Buck,  S. (2002): Der gesch\u00e4rfte Blick. Zur Geschichte der Brille und ihrer Verwendung in Deutschland seit 1850. Marburg.Von der Schallplatte bis zum online Musikstreaming \u00a7  125\nVon der Schallplatte bis zum online \nMusikstreaming \nDie Digitalisierung der Musikindustrie \u2013 ein Lehrst\u00fcck f\u00fcr andere \nBranchen und Sektoren?\nKonstantin Schneider\nKaum ein anderer Markt hat die Folgen der Di-\ngitalisierung in den letzten 20 Jahren so stark zu sp\u00fcren bekommen wie die Musikindustrie. Vor der Digitalisierungswelle war der Musiksektor ein recht \u00fcbersichtlicher Markt. Das haupts\u00e4ch-liche Abspielmedium f\u00fcr Musik war die Schall-platte, die f\u00fcr den Verbraucher nur schwer zu vervielf\u00e4ltigen war. Die einzige M\u00f6glichkeit bot die Musikkassette, mit der Alben zumindest ko-piert und Lieder aus dem Radio aufgenommen werden konnten. \nDiese Musikwelt wirkt im Jahr 2018 wie aus der \nSteinzeit. Musik ist heute weitestgehend digi-tal verf\u00fcgbar und kann beliebig oft ohne jeg-lichen Qualit\u00e4tsverlust kopiert werden. Durch das Smartphone und Musikstreaming-Anbieter wie Deezer, Spotify oder Apple Music ist fast jeder Song jederzeit \u00fcberall verf\u00fcgbar. Die Mu-sikindustrie hat also einen enormen Wandel  durchlaufen. Ums\u00e4tze sind eingebrochen, Ge-sch\u00e4ftsmodelle haben sich ver\u00e4ndert und bis heute ist die Debatte \u00fcber den Wert k\u00fcnstle-rischer Leistung noch nicht beendet. Das Bei-spiel des Musikmarktes zeigt, welche Ver\u00e4nde-rungen durch die Digitalisierung hervorgerufen werden k\u00f6nnen und wie sie Strukturen ma\u00df-geblich ver\u00e4ndern kann. Daher lohnt sich eine vertiefende Betrachtung, um zu verstehen, ob andere Branchen von diesen Ver\u00e4nderungen lernen k\u00f6nnen. Dabei liegt der Fokus vor allem auf der Digitalisierung der Tontr\u00e4ger; Ver\u00e4nde-rungen im Bereich der Aufnahme- und Studio- technik sollen in diesem Beitrag nicht weiter betrachtet werden, da diese Prozesse die tie-fere Analyse sehr komplexer Zusammenh\u00e4nge erfordert h\u00e4tten. \nDie analoge Musikwelt \u2013 stetes Wachstum \nbis 1999\nMit der Einf\u00fchrung der Schallplatte zum Ende \ndes 19. Jahrhunderts entwickelte sich zuneh-mend die Musikindustrie und mit ihr auch die Plattenfirmen. Ihre Aufgabe ist es, Musik in Studios zu produzieren, aufzunehmen und anschlie\u00dfend auf Tontr\u00e4ger zu pressen. Zudem k\u00fcmmern sie sich um Vertrieb, Vermarktung und Verkauf. Dieses Prinzip hat sich zun\u00e4chst \u00fcber die Jahre kaum ver\u00e4ndert. Die Schallplatte wurde zwar technisch stetig weiterentwickelt, aber letztlich musste der Verbraucher die Mu-sik im Plattenladen kaufen. Ihm boten sich ei-gentlich keine Alternativen. Die Plattenfirmen hatten somit die absolute Hoheit \u00fcber die Mu-sikrechte, da Musik nur schwer kopiert und ver -\nvielf\u00e4ltigt werden konnte.\nLeichte Ver\u00e4nderungen dieses Prinzips kamen \nerst durch die Einf\u00fchrung der Musikkassette im Jahr 1965.\n1 Sie erm\u00f6glichte es, Musik beispiels-\nweise aus dem Radio aufzunehmen oder von einer Schallplatte zu kopieren. Schon damals gab es erste Diskussionen \u00fcber Eigentumsrech-te an der Musik. So titelte 1977 ein Artikel im \n40 Jahre126 \nSpiegel \u00fcber die Musikkassette \u201eKlang-Super -\nmarkt zum Nulltarif\u201c.2 Heute ist bekannt, dass \ndie Musikkassette die Ums\u00e4tze und Entwicklun-\ngen auf dem Musikmarkt nicht merklich nega-tiv beeinflusst hat. Es ist nicht zu massenhaften illegalen Kopien und Aufnahmen gekommen, wie einst bef\u00fcrchtet. Dies liegt vor allem daran, dass die Qualit\u00e4t der Kopien nicht besonders gut war und das Aufnehmen recht viel Zeit in Anspruch nahm. \nIm Jahr 1984 setzte sich die Compact Disc (CD) \nals ein neues Tontr\u00e4gerformat langsam durch. Auch dieses Mal schien es, dass dieses Format die Strukturen im Markt kaum ver\u00e4ndert. Im Gegenteil, die CD sorgte zun\u00e4chst einmal f\u00fcr eine weitere starke Umsatzsteigerung. So stieg der Umsatz der Musikindustrie in Deutschland von ca. 1,1 Mrd. Euro im Jahr 1984 auf 2,7 Mrd. Euro im Jahr 1998 stetig an.\n3 Doch die CD \nwar nicht nur einfach ein neuer Tontr\u00e4ger, son-dern ein ganz neues Speichermedium. Auf ihr wurden die Musikst\u00fccke nicht auf Tonspuren analog gespeichert, wie bei der Kassette oder der Schallplatte, sondern auf Dateien. Diese Dateien k\u00f6nnen ohne Qualit\u00e4tsverlust beliebig oft kopiert werden. Diese Entwicklung war der Startschuss f\u00fcr enorme Umw\u00e4lzungsprozesse in der Musikindustrie, die bis heute anhalten.\nDie Digitalisierung der \nMusikindustrie \u2013 Einbruch und Wiederauferstehung \nGro\u00dfe Umsatzeinbr\u00fcche zwischen 1999 \nund 2004\nDie Umw\u00e4lzungsprozesse in der Musikindustrie \nEnde der 1990er Jahre wurden nicht nur durch die CD allein ausgel\u00f6st, sondern durch eine Vielzahl unterschiedlicher Entwicklungen und Innovationen:\n    Entwicklung des MP3 Kompr essionsverfahren \n(eigentlich MPEG 1 Layer III)Kern dieses Verfahrens ist es, nur noch den f\u00fcr den Menschen h\u00f6rbaren Teil der Musik als Datei zu speichern. Dadurch konnte die Gr\u00f6\u00dfe einer Audiodatei um bis 85 Prozent verringert werden.  Anfang der 1990er Jahre wurde das Verfahren MPEG 1 Layer III (kurz MP3) zum Pa-tent angemeldet. Zwar wurde das Format \u00fcber die Jahre stetig weiterentwickelt (MPEG 2, 3, 4)  und verfeinert, aber das Grundprinzip blieb immer gleich. Bis heute ist das MP3-Format, das im Weiteren als Synonym f\u00fcr alle Weiter -\nentwicklungen stehen soll, das g\u00e4ngige Format zum Austausch von Musik.\n     Ausbau des Br eitband Internets\nAnfang der 2000er Jahre haben sich die Down-load-Raten im Internet durch den Ausbau der Breitband-Anschl\u00fcsse drastisch erh\u00f6ht. Waren vorher \u00fcber ein analoges Modem gerade ein-mal 56kb/s m\u00f6glich bzw. \u00fcber ISDN 128 kb/s, konnten schon mit den ersten DSL-Anschl\u00fcssen bis zu 1000kb/s (bzw. 1 mbit) erreicht werden. So konnte eine MP3-Datei binnen weniger Mi-nuten heruntergeladen werden. \n     Peer -2-Peer Netzwerke (Filesharing)\nPeer-2-Peer Netzwerke erm\u00f6glichen es, Dateien direkt zwischen Computern dezentral auszu-tauschen. Ein Peer-2-Peer Netzwerk kann aus vielen verschiedenen Computern bestehen. Die Netzwerke sind in der Regel vollkommen de-zentral organisiert. Es gibt allerdings Abwand-lungen, die einen zentralen Verzeichnisserver nutzen, um den Nutzern eine vereinfachte Suche zu erm\u00f6glichen. Die wohl ber\u00fchmteste Filesharing-Plattform ist Napster, auch wenn sie heute in der Form nicht mehr existiert. Weitere bekannte Plattformen sind etwa Bittorrent oder eMule.\n    G\u00fcnstige Speichermedien\nAuch die Speicherm\u00f6glichkeiten wur\nden mit \nder Zeit immer g\u00fcnstiger. Zun\u00e4chst einmal waren es vor allem der CD-Brenner und die CD-Rohlinge, die zur Kopie von Musik genutzt Von der Schallplatte bis zum online Musikstreaming \u00a7  127\nwurden. So besa\u00dfen 2004 bereits 41 Prozent \nder deutschen Haushalte einen CD-Brenner. Abgel\u00f6st wurde der CD-Rohling dann von mo-bilen Festplatten und dem USB-Stick. Auch die Zahl der MP3-Player stieg Anfang der 2000er Jahre deutlich an.\n 4 \nLetztlich war es ein Zusammenspiel all dieser verschiedenen Entwicklungen, die eine gro\u00dfe Z\u00e4sur im Musikmarkt ausl\u00f6sten. Den Anfang dieser Entwicklungen stellt das Jahr 1999 dar, in dem die Musiktauschb\u00f6rse Napster online ging.  Damit wurde eine Plattform geschaffen, die es den Nutzern erm\u00f6glichte, schnell und unproble- matisch MP3-Dateien auszutauschen. Musik wurde damit fast schlagartig zu einem \u00f6ffentli-chen Gut, das hei\u00dft  sie war fast f\u00fcr jeden ohne Einschr\u00e4nkungen frei zug\u00e4nglich, zumindest f\u00fcr diejenigen, die einen Breitband-Anschluss hatten.  \nDie Plattenfirmen und etablierten Akteure auf \ndem Musikmarkt reagierten zun\u00e4chst einmal auf diese Entwicklungen eher zur\u00fcckhaltend und versuchten ihre bestehenden Gesch\u00e4fts-modelle, die auf dem Verkauf von Alben und Singles beruhten, zu sichern. Die Musikindustrie steckte ihre Bem\u00fchungen in das Thema \u201eDigi-tal Rights Management\u201c (nachfolgend: DRM). Ziel war es, das massenhafte uneingeschr\u00e4nkte Kopieren und Austauschen von MP3-Dateien durch digitale Wasserzeichen oder andere Ver -\nschl\u00fcsselungsverfahren deutlich einzud\u00e4mmen. \nHeute ist bekannt, dass dieser Weg nicht wirk-\nlich erfolgreich war. Im Gegenteil, technisch waren die DRM-Systeme Anfang der 2000er Jahre noch nicht wirklich ausgereift. Sie f\u00fchrten zu erheblichen Einschr\u00e4nkungen beim Verbrau-cher. So konnte nicht mehr jeder CD-Player jede CD abspielen. Eigene Dateien, auch wenn sie legal erworben wurden, konnten nicht einfach auf andere Abspielger\u00e4te (PC, MP3-Player, etc.) kopiert werden. Die DRM-Systeme konnten die Entwicklungen auf dem Musikmarkt also kaum aufhalten. In den folgenden Jahren brachen die Ums\u00e4tze daher extrem ein. Von 1998 bis 2007 hatten die etablierten Plattenfirmen ein massi-ves Problem. Es war leichter und komfortabler, eine illegale MP3-Datei aus dem Internet herun- terzuladen als ein Musikst\u00fcck legal zu erwerben.\nErste legale Online-Angebote f\u00fcr Musik \u2013 \nder iTunes Store\nBewegung in den Markt kam erst durch die \nFirma Apple. Schon 2001 wurde mit dem Ver -\nkaufsstart des iPods ein wichtiger Meilenstein Abb.1 Entwicklung der Musikindustrie \nQuelle: Eigene Darstellung nach Bundesverband Musikindustrie e. V . (2012): Musik im digitalen Wandel \u2013 Eine Bilanz aus zehn Jahren Brennerstudie. Berlin.Ca. 1900\nEinf\u00fchrung der  \nSchallplatte1930er\nVinyl-Schall-\nplatte1965\nEinf\u00fchrung der \nMusikkassette1984\nCompact Disc \n(CD)1999 \nStart von \nNapster\n1991\nPatentierung \nder MP3 \n2003\nStart des I-Tune \nStores2008\nStart von SpotifyEntwicklung der Musikwirtschaft\nDigitalisierung128 \nzur Verbreitung digitaler Musik gelegt. Zudem \nwurde mit dem iTunes Store im Jahre 2004 ei-ne legale Alternative zu den bisher illegalen Tauschb\u00f6rsen geschaffen. Apple lie\u00df sich da-r\u00fcber hinaus noch ein sehr einfaches Preissys-tem einfallen.  MP3-Dateien konnten f\u00fcr einen g\u00fcnstigen einheitlichen Preis heruntergeladen werden (1 Euro pro Song; 9,90 Euro pro Album). Auch Apple setzte zun\u00e4chst auf MP3-Dateien mit DRM. Diese wurden allerdings schrittweise ab dem Jahr 2007 abgeschafft. Der Start des iTunes Store und weiterer legaler digitaler An-gebote konnte den Abw\u00e4rtstrend bei den  \nUms\u00e4tzen der Musikindustrie deutlich bremsen und stellte zum ersten Mal eine wirkliche Alter -\nnative zu den illegalen Downloadplattformen dar. Dies zeigt sich auch in den Umsatzzahlen, die im digitalen Vertrieb sukzessive anstiegen. Ab dem Jahr 2004 kletterten die Ums\u00e4tze mit legalen und bezahlten Downloads in Deutsch-land schrittweise nach oben, bis zum H\u00f6chst-stand im Jahr 2013 mit 255 Mio. Euro. \nTrotz dieser positiven Entwicklungen konnte \nauch der iTunes Store die sinkenden Ums\u00e4tze auf dem Musikmarkt nur etwas abmildern. Zu-mal im Jahr 2005 ein weiterer wichtiger Akteur in den Markt einstieg: Die Videoplattform You-Tube ging an den Start. Obwohl eigentlich f\u00fcr Videos gedacht, entwickelte sie sich schnell zu einer Plattform f\u00fcr Musik. Bis heute ist die Mu-sikindustrie im Konflikt mit der Videoplattform, da die H\u00f6he von Lizenzgeb\u00fchren f\u00fcr Musikst\u00fc-cke immer wieder diskutiert wird. \nSteigende Ums\u00e4tze durch \ndas Musikstreaming \nErst in den letzten Jahren erholten sich die Um-\ns\u00e4tze wieder ein wenig. Dies liegt vor allem an dem Musikstreaming, das zunehmend an Be-deutung auf dem Musikmarkt gewinnt. Inter -\nessanterweise war einer der Pioniere in diesem Bereich ein alt bekannter Name, n\u00e4mlich Naps-ter. Zwischenzeitlich wurde die Plattform von einer gro\u00dfer Plattenfirma, der Bertelsmann Mu-sic Group (BMG) gekauft und war bem\u00fcht, ein legales Vertriebsmodell zu entwickeln. Somit Abb. 2: Umsatzentwicklung des Musikmarktes in Deutschland von 1998 bis 2007 \nQuelle: Bundesverband Musikindustrie e. V . (2008): Musikindustrie in Zahlen 2007. Berlin. (Ver\u00e4nderung nominal gegen\u00fcber dem jeweiligen Vorjahr)  0 %\n  -5 %-10 %-15 %-20 %-1,4 %1998\n-2,3 %1999 \n-0,7 %2000\n-10,1 %2001\n-6,9 %2002\n-17,5 %2003 \n-3,5 %2004 \n-0,3 %2005\n-2,4 %2006\n-3,2 %2007Von der Schallplatte bis zum online Musikstreaming \u00a7  129\nhatte Napster schon im Jahr 2005 eine Musik-\nflatrate f\u00fcr 10 Euro angeboten. Damals konn-te sich der Nutzer die Musik entweder am PC anh\u00f6ren oder auf einem MP3-Stick speichern. Die Dateien zerst\u00f6rten sich nach vier Wochen selbst, wenn sie nicht wieder am PC aktualisiert wurden. Dieses System war etwas umst\u00e4ndlich und wurde vom Verbraucher nicht so richtig an-genommen. Erst Spotify konnte die Idee mit ei-ner eigenen App und einem werbefinanzierten Gratisangebot massentauglich machen. Dabei wird die Musik nicht mehr heruntergeladen, sondern direkt online gestreamt. Spotify, das 2008 an den Start ging (in Deutschland 2012), hat derzeit etwa 150 Mio. Nutzer, von denen etwa 70 Mio. ein bezahltes Abonnement abge-schlossen haben.  \nHeute ist das Musikstreaming der Wachstums-\nbereich in der Musikindustrie. Der Umsatz stieg von 320 Mio. Dollar im Jahr 2010 auf ca. 3,9 Mrd. Dollar im Jahr 2017.\n5 Auch in Deutschland sind \ndie Ums\u00e4tze zuletzt auf 549 Mio. Euro (2016) im Bereich Streaming deutlich gestiegen.\n6 \nIT-Schwergewichte wie Amazon und Apple  \nhaben inzwischen die Potenziale des Musik-streaming erkannt und sind in den Markt mit eingestiegen. Wie nachhaltig diese Gesch\u00e4fts-modelle tats\u00e4chlich sind, wird sich in den n\u00e4chs-ten Jahren noch zeigen. Bisher hat keiner dieser Dienste wirklich Gewinn gemacht. So hat Spo-tify alleine im letzten Jahr einen Verlust von 378 Mio. Euro zu verzeichnen.\n7 \nFolgen der Digitalisierung \nder Musikindustrie \nWirtschaftlich gesehen f\u00fchrten die Entwick-\nlungen ab 1999 zun\u00e4chst einmal zu enormen Einbu\u00dfen bei der Musikindustrie. So sank der Umsatz von 23,8 Mrd. Dollar im Jahr 1999 auf 15,7 Mrd. Dollar im Jahr 2016. Damit ist gut ein Drittel des Marktes in diesen Jahren wegge-brochen. Dies liegt vor allem an den physischen Tontr\u00e4gern, die 1999 noch f\u00fcr den gesamten  \nUmsatz der Musikindustrie verantwortlich waren.  \nInsgesamt brach der Markt f\u00fcr physische Ton-tr\u00e4ger um 77 Prozent ein.\n8  Abb. 3. Umsatzentwicklung der Musikindustrie nach Segmenten (Umsatz in Mrd. US$)  \nQuelle: Eigene Darstellung nach International Federation of the Phonographic Industry (2018): Global Music Report 2017 \u2013 annual state of the industry. London.Gesamt\n(1999\u20132016)Physische Tontr\u00e4ger\n(1999\u20132016)Digital Gesamt\n(2004\u20132010)Digital nur Streaming\n(2010\u20132016)25\n20151050\n0,45,423,8 23,8\n15,7\n7,4\n3,9+ 25 % / Jahr- 2 % / Jahr - 8 % / Jahr\n+ 43 % / Jahr\n0,32130 \nAb dem Jahr 2004 sind vor allem digitale Er -\nl\u00f6squellen f\u00fcr den Musikmarkt hinzugekom-\nmen. Sie sind in den letzten Jahren der abso-lute Wachstumsmotor, seit 2004 stiegen die Ums\u00e4tze in diesem Bereich um satte 25 Prozent pro Jahr. Absoluter Wachstumstreiber ist dabei das Musikstreaming, hier konnte in den letzten Jahren sogar eine Umsatzsteigerung von durch-schnittlich 42 Prozent im Jahr erreicht werden.\n9 \nAuch wenn sich die Wachstumsraten nicht di-rekt miteinander vergleichen lassen, weil sie sich auf unterschiedliche Zeitr\u00e4ume beziehen, zeigt sich, dass die Digitalisierung in der Musikindus-trie angekommen ist und inzwischen f\u00fcr stetig steigende Ums\u00e4tze sorgt.  Sie hat also nicht zur vollkommenen Aufl\u00f6sung des Marktes gef\u00fchrt. Neue Gesch\u00e4ftsmodelle wie das Musikstreaming sind entstanden und neue Marktteilnehmer, wie Spotify, Apple, Amazon oder Google hinzuge-kommen. Dennoch bleibt festzuhalten, dass die fr\u00fcheren Umsatzrekorde der physischen Tontr\u00e4-ger, insbesondere der CD, immer noch in weiter Ferne liegen. Es wird sich zeigen, ob die Musik-industrie irgendwann noch einmal diese Gr\u00f6\u00dfen-ordnungen erreichen kann. \nAber was f\u00fcr Folgen haben diese Entwicklun-\ngen f\u00fcr das Kulturgut Musik? Wird der Zugang f\u00fcr K\u00fcnstler durch die neuen Plattformen er -\nleichtert? Wird die Musik an sich vielseitiger, innovativer und mutiger? Diese Fragen lassen sich nur schwer beantworten. Zun\u00e4chst einmal haben Plattformen wie Spotify oder Youtube die Musikwelt f\u00fcr jeden K\u00fcnstler zug\u00e4nglich  \ngemacht. Fr\u00fcher hatte eine Band ohne Platten-vertrag kaum die M\u00f6glichkeit, ihre Musik zu ver -\n\u00f6ffentlichen und damit ein breiteres Publikum zu erreichen. Heute stehen solchen Bands bei Spotify gleich 150 Mio. Nutzer zur Verf\u00fcgung. Gleichzeitig ist es aber durch die Masse an  \nAngeboten wesentlich schwieriger geworden, die Aufmerksamkeit auf diesen Plattformen zu erregen. Hierzu braucht es wiederum professio-nelle Kampagnen, die nur mit Hilfe der Platten- industrie finanziert werden k\u00f6nnen. Heute muss eine Plattenfirma im Schnitt 0,5 bis 2 Mio. Dollar investieren, um einen K\u00fcnstler auf dem US-Markt zu platzieren. Das sind schon enorme Investitionen.\n10\nBands, die also einfach nur Musik machen und diese einer breiteren Masse zur Verf\u00fcgung stel-len wollen, haben nun einen leichteren Zugang zur \u00d6ffentlichkeit. Wollen die K\u00fcnstler aber wirklich von ihrer Musik leben und auch kom-merziell erfolgreich sein, ist es weiterhin sehr schwer, dies ohne einen Plattenvertrag und da-mit ohne die Unterst\u00fctzung einer der gro\u00dfen Labels zu erreichen. Denn auch wenn die gro-\u00dfen Plattenfirmen stagnierende Ums\u00e4tze haben und es in den letzten Jahren verschiedenste Konzentrationsprozesse gab, werden heute immer noch 75 Prozent des Musikmarktes von den gro\u00dfen Plattenfirmen Sony Music Enter -\ntainment (22,2 Prozent), Universal Music Group (32,8 Prozent) und der Warner Music Group (18,1 Prozent)  beherrscht.  Auch vor der Digi-talisierung hatten die Major Labels eine \u00e4hnlich gro\u00dfe Marktmacht. \nLehren aus der Musikindustrie\nDie Musikindustrie hat wohl als erste Branche die massiven Ver\u00e4nderungen, die durch Digita-lisierungsprozesse hervorgerufen werden k\u00f6n-nen, direkt gesp\u00fcrt. Nat\u00fcrlich hat der Musik-markt ganz spezifische Eigenschaften, die sich nicht einfach auf andere Sektoren \u00fcbertragen lassen. Trotzdem k\u00f6nnen einige Lehren aus dem Beispiel Musikwirtschaft gezogen werden, die sich im Bereich Digitalisierung auf andere Bran-chen \u00fcbertragen lassen.\nDigitalisierung beinhaltet \nein komplexes Zusammen-  \nspiel verschiedenster  Innovationen\nEs gibt nicht die eine Idee oder Innovation, die \nstrukturver\u00e4nderte Prozesse ausl\u00f6st, sondern das Beispiel Musikindustrie zeigt, dass es ein Von der Schallplatte bis zum online Musikstreaming \u00a7  131\nZusammenspiel verschiedenster technologi-\nscher- und Dienstleistungs-Innovationen (vor allem neuer Gesch\u00e4ftsmodelle) ist, die den Wandel vorantreiben. In diesem Fall handelt es sich vor allem um ein Wechselspiel beider Inno-vationsarten. \nZun\u00e4chst einmal waren es technische Neuerun-\ngen wie MP3-Dateien, Breitband-Anschluss, CD-Brenner, die zu einem massenhaften illega-len Austausch von MP3-Dateien gef\u00fchrt haben. Es fehlte an passenden Gesch\u00e4ftsmodellen, die eine Antwort auf diese Entwicklung geben konnten. Erst mit dem iPod in Kombination mit dem iTunes-Store wurde diese Problema-tik zumindest ansatzweise gel\u00f6st. Auf der an-deren Seite hatte Napster schon 2005 mit der Musik-Flatrate ein innovatives Gesch\u00e4ftsmodell entwickelt, das zun\u00e4chst aber wenig Aufmerk-samkeit auf sich gezogen hat. Erst als 2007 mit dem iPhone sich langsam auch das Smartphone insgesamt durchgesetzt hatte, waren die tech-nischen Voraussetzungen geschaffen und Spo-tify konnte mit seiner App das Gesch\u00e4ftsmodell etablieren. \nAber nicht nur dieses Wechselspiel aus Tech-\nnologie und zugeh\u00f6rigen Gesch\u00e4ftsmodellen macht das Thema Digitalisierung so herausfor -\ndernd. Es sind auch die immer komplexer wer -\nden Innovationsprozesse. Diese sind heute n\u00e4m-lich vor allem branchen\u00fcbergreifend und global:\nAbb. 4: Ums\u00e4tze Musikindustrie 2016 in Deutschland nach Segmenten \nQuelle: Eigene Darstellung nach Bundesverband Musikindustrie e. V . (2017): Musikindustrie in Zahlen 2016. Berlin.37,8 % Digital\n62,1 % Physisch1,50 %\nDigital Sonstiges \nDownloads\nAudio Streaming\nCD-Alben\nVinyl-Alben\nMusik DVD\nPhysisch Sonstige 0,50 %12,20 %\n24,10 %\n53,80 %\n4,40 %\n3,40 %132 \n    branchen\u00fcbergr eifend\nViele der technischen Innovationen wie MP3-  \nDatei, Breitband-Abschl\u00fcsse, Peer2Peer-Netz-\nwerke sind zun\u00e4chst einmal vollkommen unab-h\u00e4ngig voneinander entstanden und hatten mit dem Thema Musik (die MP3-Datei mal ausge-nommen) eigentlich nichts gemein. Erst ihr Zu-sammenspiel hat die immensen Ver\u00e4nderungen auf den M\u00e4rkten ausgel\u00f6st. \n    global \nGerade auch die \nDigitalisierung zeigt, dass \nheute Innovationsprozesse mehr und mehr standortunabh\u00e4ngig sind. Die MP3-Datei wur -\nde beispielsweise in Deutschland entwickelt, das eigentlich erste funktionierende Gesch\u00e4fts-modell durch die Firma Apple in den USA und Spotify, der erfolgreichste Streaming-Dienstan-bieter im Musikbereich, hat seinen Firmensitz in Schweden. Die Prozesse im Themenfeld Di-gitalisierung sind also \u00e4u\u00dferst komplex. Innova-tionen, die heute vielleicht noch nicht relevant sind, k\u00f6nnen durch Ideen aus anderen Berei-chen oder durch neue Gesch\u00e4ftsmodelle auf einmal eine marktbeherrschende Stellung ein-nehmen. Die Herausforderung wird sein, diese Prozesse zu beobachten und zu analysieren, um daraus die richtigen Schl\u00fcsse zu ziehen. \nBestehende Strukturen und neue M\u00e4rkte \nexistieren lange Zeit parallel\nDas Beispiel Musikindustrie zeigt auch, dass \nbestehende M\u00e4rkte, Technologien und Produk-te nicht einfach so wegbrechen, sondern dass eine recht lange Zeit Parallelstrukturen aus un-terschiedlichen Gesch\u00e4ftsmodellen existieren k\u00f6nnen.  \nObwohl schon lange totgesagt, ist die CD auch \nim Jahr 2016 mit einem Anteil von 53,8 Pro-zent immer noch der Hauptumsatzbringer der Musikindustrie in Deutschland\n11, auch weltweit \nsind es immerhin noch 34 Prozent.12 Sogar \ndie Schallplatte feierte in den letzten Jahren ein kleines Comeback als Nischenprodukt.  So stiegen die Ums\u00e4tze von Vinyl-Alben von ca. 4 Mio. Euro im Jahr 2005 auf \u00fcber 70 Mio. im Jahr 2017 an.\n13  \nR\u00fcckblickend l\u00e4sst sich leicht sagen, dass die Musikindustrie die Digitalisierung verschlafen hat. Dabei wird aber gern vergessen, dass sie vor enormen Herausforderungen stand. Das ge-winnbringende CD-Gesch\u00e4ft musste am Laufen gehalten werden, w\u00e4hrend gleichzeitig in neue Technologien und Gesch\u00e4ftsmodelle investiert werden musste. Erschwerend kam hinzu, dass diese neuen Gesch\u00e4ftsmodelle die bestehenden Strukturen obsolet machten. Dieser Spagat zwi-schen der Aufrechterhaltung der bestehenden Gesch\u00e4ftsmodelle, die zun\u00e4chst noch die Ge-winnbringer sind, und der Investition in neue Technologiefelder und M\u00e4rkte wird auch f\u00fcr andere Branchen schwierig zu bew\u00e4ltigen sein. Denn auch hier machen die neuen Gesch\u00e4fts-modelle bestehende Strukturen \u00fcberfl\u00fcssig. Die-se Herausforderung f\u00fcr die Unternehmen wird h\u00e4ufig untersch\u00e4tzt und \u00fcbersehen.  \nDieser Kraftakt ist \u00fcbrigens sowohl f\u00fcr KMU \nals auch f\u00fcr Gro\u00dfunternehmen schwer zu ma-nagen. W\u00e4hrend bei Kleinunternehmen eine falsche Investition schnell zu einem Existenzpro-blem werden kann, haben Aktiengesellschaf-ten das Problem, das Aktion\u00e4re Gewinne und Dividenden erwarten. Diese generiert aber das Kerngesch\u00e4ft. Zuk\u00fcnftige Gewinne, die durch neue Gesch\u00e4ftsfelder entstehen, spiegeln sich eher selten im Aktienkurs wieder. \nDie Digitalisierung l\u00e4sst sich nicht  \naufhalten \nTrotz dieser Probleme m\u00fcssen sich die Firmen \nder Herausforderung der Digitalisierung stellen. Denn eines zeigt das Beispiel der Musikindus-trie auch: Die Digitalisierung l\u00e4sst sich nicht aufhalten. Wenn die Unternehmen nicht selbst aktiv werden, werden andere neue Akteure in die M\u00e4rkte eindringen und diese erobern. Die Musikindustrie hat lange versucht die Entwick-lungen aufzuhalten und ist damit letztlich ge-scheitert. Durch ihr Z\u00f6gern hat sie es zugelas-sen, dass es gerade zwischen den Jahren 1999 und 2004 f\u00fcr den Verbraucher einfacher war, Von der Schallplatte bis zum online Musikstreaming \u00a7  133\n1 Bundesverband Musikindustrie e . V . (2008): Musikindustrie in Zahlen 2007. Berlin.\n2 Der Spiegel (1977): Klang-Supermarkt zum Nulltarif .  www.spiegel.de/spiegel/print/d-40915958.html [Zugriff am 1.4.2018].\n3 Bundesverband Musikindustrie e . V . (2017): Musikindustrie in Zahlen 2016. Berlin.\n4 Bundesverband Musikindustrie e . V . (2012): Musik im digitalen Wandel \u2013 Eine Bilanz aus zehn Jahren Brennerstudie. Berlin.\n5 International F ederation of the Phonographic Industry (IFPI) (2018): Global Music Report 2017 \u2013 annual state of the indus-try. London.\n6 Bundesverband Musikindustrie e . V .  (2017): Musikindustrie in Zahlen 2016. Berlin.\n7 Manager Magazin (2018): Warum Spotify trotz Horror-Verlusten an die B\u00f6rse geht: Tech-Wette f\u00fcr die Massen. www.manager-\n magazin.de/finanzen/boerse/spotify-boersengang-des-streaming-dienstes-trotz-horror\n-verlusten-a-1201045.html [Zugriff am 1.4.2018]\n8 International F ederation of the Phonographic Industry (2018): Global Music Report 2017 \u2013 annual state of the industry. London.\n9 International F ederation of the Phonographic Industry (2018): Global Music Report 2017 \u2013 annual state of the industry. London.\n10 International F ederation of the Phonographic Industry (2016): Investing in Music-The Value of Record Companies. London.\n11 Bundesverband Musikindustrie e . V . (2017): Musikindustrie in Zahlen 2016. Berlin.\n12 International F ederation of the Phonographic Industry (2016): Investing in Music-The Value of Record Companies. London.\n13 Bundesverband Musikindustrie e . V . (2017): Musikindustrie in Zahlen 2016. Berlin.sich illegale Musik aus dem Netz zu ziehen als \nsie im Plattenladen zu kaufen. Bis heute leidet die Musikindustrie unter dieser Phase enorm.\nEin solcher Zustand sollte in anderen Branchen \nm\u00f6glichst verhindert werden. Daher ist es wich-tig, sich fr\u00fchzeitig mit der Thematik zu besch\u00e4f-tigen und die eigenen Gesch\u00e4ftsmodelle immer wieder in Frage zu stellen. Viele Unternehmen tun dies heute, weil sie aus Beispielen wie der Musikindustrie gelernt haben, dass sie sich die-sen Prozessen kaum entziehen k\u00f6nnen. Letztlich l\u00e4uft die Digitalisierung in den verschiedenen Branchen und Sektoren h\u00f6chst unterschiedlich ab, klare Musterl\u00f6sungen und Vorgehenswei-sen wird es zur L\u00f6sung der vielf\u00e4ltigen Aufga-ben kaum geben. Dennoch zeigt das Beispiel der Musikindustrie, dass sich ein Blick \u00fcber den Tellerrand hinaus lohnt, um Fehler zu vermeiden und von Erfahrungen zu profitieren. 134 \nAntibiotika\nWie ein vergessenes Experiment die Behandlung von Infektions-\nkrankheiten revolutionierte\nDr. Claudia Baumann  Dr. Eva Suhren\nDie Pest und Co. \u2013  bakterielle Infektions-\nkrankheiten\nInfektionskrankheiten haben die Geschichte \nder Menschheit immer wieder in vielen Berei-chen ber\u00fchrt sowie beeinflusst und tun es zum Teil heute noch. Schon die Erw\u00e4hnung der Pest ruft leichtes Unbehagen und Sorge hervor, ob-wohl die Krankheit heutzutage bei fr\u00fchzeitiger Erkennung und Behandlung \u2013 dank der Entde-ckung der Antibiotika vor gut 100 Jahren \u2013 re-lativ gut behandelt werden kann. Die Pest wird als eine der gro\u00dfen Seuchen bereits in der Bibel benannt und die gro\u00dfen Pestseuchen forderten bis zum Ende des 19. Jahrhunderts weltweit Millionen von Menschenleben.\n1\nVon der Cholera in Indien berichteten portugie-sische Entdecker das erste Mal Mitte des 16. Jahrhunderts und auch diese Erkrankung kos-tete und kostet nach wie vor in gro\u00dfen Epide-mien unz\u00e4hligen Menschen das Leben. Zuletzt machte 2010 ein gro\u00dfer Cholera-Ausbruch in Haiti Schlagzeilen, der sich in dem von dem Erd-beben geschw\u00e4chten Land besonders schnell ausbreiten konnte. Auch heute noch hat Haiti, aufgrund von extrem schlechten sanit\u00e4ren Be-dingungen und einem nicht funktionierenden Gesundheitssystem, mit der vor 2010 als aus-gerottet geltenden Erkrankung zu k\u00e4mpfen.\n2 \nDie Tuberkulose, auf deren Existenz sich bereits Hinweise aus der Antike finden, hat besonders im 17. Jahrhundert mit einer dichteren Besie-delung der st\u00e4dtischen R\u00e4ume und den damit einhergehenden schlechteren hygienischen Be-dingungen an Bedeutung gewonnen. Obwohl Mitte des 20 Jahrhunderts mit der Entdeckung der Antibiotika eine Heilung der Tuberkulo-se m\u00f6glich wurde, ist die Verbreitung dieser Krankheit heute wieder angestiegen. Dies liegt auch in einer Resistenzentwicklung der Tuber -\nkulose-Erreger begr\u00fcndet, was dazu f\u00fchrte, dass die WHO die Tuberkulose 1993 zum welt-weiten Notfall erkl\u00e4rte.\n3 \nZu den gro\u00dfen bakteriellen Seuchen z\u00e4hlen und z\u00e4hlten Syphilis, Typhus, Lepra, Tuberkulose, Pest und Cholera. Die Ursachen der Erkrankun-gen waren lange Zeit unklar. So galt Tuberku-lose beispielsweise als Erbkrankheit und wur -\nde mit Frischluftkuren behandelt. Die Syphilis, deren Herkunft bis heute ungekl\u00e4rt ist, wurde lange Zeit mit einer Quecksilberkur behandelt, die jedoch \u00e4hnlich sch\u00e4dlich wie die Erkran-kung selbst war. Als Ursache f\u00fcr die Cholera \nAbb. 1: Die Pest in Ashdod, Kupferstich einer alttestamenta- \nrischen Szene von \u00c9tienne Picart (ca. 1677)\n40 JahreAntibiotika \u00a7 135\nwurden sogenannte \u201eMiasmen\u201c, also D\u00fcnste, \nangenommen, bis Mitte des 19. Jahrhunderts der Erreger Vibrio Cholerae identifiziert werden konnte.  Die Miasmentheorie oder die Kontagi-onstheorie (Infektion durch das Ber\u00fchren eines Kranken) waren die beiden dominierenden An-nahmen, wie Seuchen sich verbreiteten. Die Er -\nkenntnis, dass mikroskopisch kleine Erreger, wie etwa Bakterien, Krankheiten ausl\u00f6sen k\u00f6nnen, reifte erst mit der Entdeckung des Erregerbak-teriums der Tuberkulose, dem Mycobacterium tuberculosis,  durch Robert Koch im Jahre 1882. Damit wurde gleichzeitig der Weg zu einer ur -\ns\u00e4chlichen Behandlung geebnet.\n5\nPenicillin \u2013 ein Game Changer, der mehrmals  \nentdeckt werden musste\nVor 100 Jahren lag die durchschnittliche Le-benserwartung noch etwa 30 Jahre niedriger als heute. Es ist davon auszugehen, dass An-tibiotika und andere Arzneimittel \u2013 neben Fak-toren wie verbesserter Wasserqualit\u00e4t, Hygiene und Ern\u00e4hrung \u2013 ein Grund daf\u00fcr sind, dass die Lebenserwartung in Deutschland deutlich ge-stiegen ist.\n7 1910 wurde mit Salvarsan das ers-te Antibiotikum gegen Syphilis auf den Markt gebracht.\n8 Noch bekannter ist wohl die Entde-\nckung des Penicillins. Als der Wissenschaftler Alexander Fleming 1928 aus seinem Urlaub zu-r\u00fcckkam, entdeckte er in einer seiner Petrischa-len, in der er Bakterienkolonien wachsen lie\u00df, einen Schimmelpilz. Fleming bemerkte, dass um den Schimmelpilz herum keine Bakterien wachsen konnten und der Pilz offensichtlich in der Lage war, die Bakterien in seiner Umgebung abzut\u00f6ten. Anstatt die verunreinigte Kultur zu verwerfen, fing Fleming an, mit dem Extrakt des Schimmels zu experimentieren und fand heraus, dass er weitere Bakterienarten abt\u00f6ten konnte.\n9 \nGemeinhin gilt Fleming als der Entdecker des Penicillins, doch tats\u00e4chlich wurde Penicillin zuvor bereits zweimal entdeckt \u2013 und wieder vergessen. So isolierte bereits 1893 der italie-nische Arzt Bartolomeo Gosio eine Substanz aus einem Pilz der Gattung Penicillium, die das Wachstum von Milzbranderregern hemmt. Seine Ver\u00f6ffentlichungen fanden jedoch keine breitere Beachtung, da sie auf Italienisch ver -\nBakterien und deren Detektion\nBakterien sind einzellige Mikroorganismen, die keinen Zellkern besitzen und etwa 0,1 bis 700 \u00b5m gro\u00df sind. Bakterien lassen sich nach verschiedenen Merkmalen einteilen, wie etwa das Aussehen (z. B. st\u00e4bchenf\u00f6rmig,  spiralf\u00f6rmig, rund), nach dem Sauer-stoffbedarf (aerob = sauerstoffverbrauchend, anaerob = k\u00f6nnen ohne Sauerstoff leben) oder nach dem F\u00e4rbeverhalten. Das unterschiedliche F\u00e4rbeverhalten der Bakterien wird auch zur Diagnostik des Erregers einer Erkrankung ausgenutzt. Die Gram-F\u00e4rbung, eine der wichtigsten F\u00e4rbungen der medizinischen Mikrobiologie, bei der die Bakterien mit einer Farbstoff-L\u00f6sung behandelt werden, unterteilt die Bakterien in grampositive (blaue Einf\u00e4rbung) und gramnegative (rote Einf\u00e4rbung) Erreger, was in der unterschiedlichen Membranstruktur der Erreger begr\u00fcndet liegt. W\u00e4hrend grampositive Bakterien eine dicke Peptidoglykanschicht aus Murein besitzen, haben gramnegative Bakterien nur eine d\u00fcnne Peptidoglykanschicht aus Murein sowie eine zus\u00e4tzliche \u00e4u\u00dfere Lipidmembran, so dass Farbstoffe leichter wieder ausgesp\u00fclt werden.\n6 Durch das Lichtmikroskop kann \nso anhand des F\u00e4rbeverhaltens und typischer morphologischer Merkmale eine erste Verdachtsdiagnose erstellt werden. Mit zus\u00e4tzlichen molekularbiologischen Methoden lassen sich die Bakterien anschlie\u00dfend noch spezifischer identifizieren.i136 \nfasst waren und nicht \u00fcbersetzt wurden. Vier \nJahre sp\u00e4ter schrieb der franz\u00f6sische Milit\u00e4rarzt Ernest Duchesne seine Doktorarbeit \u00fcber die antibiotische Wirkung von Schimmelpilzen. Er war in einem Milit\u00e4rhospital auf arabische Stall-burschen aufmerksam geworden, die die S\u00e4ttel in dunklen, feuchten R\u00e4umen lagerten, damit sie Schimmel ansetzen. Sie behaupteten, die Scheuerwunden an den Pferder\u00fccken w\u00fcrden dadurch schneller abheilen. Duchesne experi-mentierte daraufhin mit Kolibakterien und ei-nem Penicillium-Stamm und fand heraus, dass dieser das Wachstum der Bakterien tats\u00e4chlich unterdr\u00fcckte. Doch die Zeit war noch nicht reif f\u00fcr diese Entdeckung und seine Doktorarbeit wurde vom Institute Pasteur abgelehnt.\n10\nNach Flemings Wiederentdeckung des Penicil-lins sollten noch einmal fast 10 Jahre verge-hen, bis 1938 die Forscher Howard W. Florey und Ernst B. Chain auf der systematischen Suche nach bakterienabt\u00f6tenden Stoffen auf die Forschungsergebnisse Flemings stie\u00dfen. Erst 1941 wurde der erste Mensch mit Penicil-lin behandelt, bevor das Medikament Anfang der 1940er Jahre der Allgemeinheit zur Ver -\nf\u00fcgung stand. 1945 erhielten Fleming, Chain und Florey f\u00fcr ihre Entdeckung den Nobelpreis. Penicillin nahm nicht nur der Tuberkulose, der Lungenentz\u00fcndung und vielen anderen Infek-tionskrankheiten den Schrecken, sondern l\u00f6ste auch in aller Welt die systematische Suche nach weiteren Antibiotika aus. Es begann die soge-nannte Goldene \u00c4ra der Antibiotika, die eine Flut immer neuer Wirkstoffe und Kombinatio-nen mit sich brachte, sodass sich Antibiotika zu einem der Grundpfeiler der modernen Medizin entwickelten.\n11 Diese Entwicklung hat zusam-\nAbb. 2: Angriffspunkte von Antibiotika im und am Bakterium50 50 50\n30 30 30RibosomTHFA\nDHFADNA\nmRNAZellwandsynthese  \nCycloserin \nVancomycin Teichoplanin Bacitracin Penicilline Cephalosporine Monobactame CarbapenemeZellwand\nPeriplasmaZellmembranDNA-Gyrase  \nQuinolone\nDNA-abh\u00e4ngige  \nRNA-Polymerase \nRifampin\nProteinsynthese   \n(50s-Inhibitoren)  \nErythromycin  \n(Makrolide) \nChloramphenical Clindamycin\nProteinsynthese   \n(30s-Inhibitoren)  \nTetracyclin Spectinomycin Streptomycin Gentamicin Tobramycin  \n(Aminoglykoside) \nAmikacinChloramphenicol- \nTransacetylase\nProteinsynthese  (tRNA)  \nMupirocin\nZellmembran  \nPolymyxinePeriplasma  \n\u03b2-Lactamasen \nAminoglykosid- modifizierende EnzymePABAFols\u00e4ure- \nmetabolismus  \nTrimethoprim \nSulfonamideAntibiotika \u00a7 137\nWelche Arten von Antibiotika gibt es und wie  \nwirken sie?\nAntibiotika sind prim\u00e4r von Mikroorganismen gebildete Substanzen, die das Wachs-\ntum anderer Mikroorganismen hemmen oder diese abt\u00f6ten. Chemotherapeutika sind \nsynthetisch hergestellte Substanzen mit antimikrobieller Wirkung.12 Umgangssprachlich \nwerden jedoch Wirkstoffe zur Behandlung von Infektionskrankheiten eher als Antibiotika bezeichnet, w\u00e4hrend der Begriff Chemotherapeutika vor allem mit der Tumortherapie in Verbindung gebracht wird, weshalb in diesem Artikel der Begriff Antibiotikum bzw. Antibiotika verwendet wird.\nAntibiotika, die Bakterien in ihrem Wachstum hemmen, werden als bakteriostatisch be-\nzeichnet, w\u00e4hrend bakterizide Wirkstoffe die Erreger abt\u00f6ten. Bei letzteren wird noch unterschieden zwischen bakteriziden Wirkstoffen, die proliferierende, also sich vermeh-rende Erreger abt\u00f6ten, und degenerativ bakteriziden Wirkstoffen, die alle Entwicklungs-stufen von Bakterien abt\u00f6ten.\nAntibiotika lassen sich dar\u00fcber hinaus nach weiteren Kriterien einteilen: neben der bak-\nteriostatischen oder bakteriziden Wirksamkeit sind dies die chemische Struktur, die durch die Antibiotika angreifbaren Erreger oder die Wirkmechanismen.\nDie unterschiedlichen Antibiotika greifen die Erreger an verschiedenen Punkten an. So \nk\u00f6nnen Antibiotika die Zellwandsynthese der Bakterien behindern (\u03b2-Laktam-Antibiotika, Glykopeptide), die Integrit\u00e4t der Bakterienzellwand st\u00f6ren (Colistin, Polymyxin B), die Funktion der DNA (Nitroimidazole, Chinolone) oder die Proteinsynthese (Aminoglykoside, Tetrazykline, Chloramphenicol, Makrolide) beeinflussen sowie in den Fols\u00e4ure-Metabo-lismus eingreifen (Trimethoprim, Sulfonamide). Die Zusammenh\u00e4nge der Wirkmechanis-men von Antibiotika sind komplex und werden mitunter noch immer untersucht.\nDie Wirkung von Antibiotika ist zudem abh\u00e4ngig von weiteren Faktoren wie u. a. der \nk\u00f6pereigenen Abwehr, dem Stoffwechsel der Bakterien, dem pH-Wert des infizierten Gewebes sowie dem Infektionsort (z. B. intra-/extrazellul\u00e4r, Gewebe/Knochen).\nmen mit einer Verbesserung der Hygiene und der allgemeinen Lebensbedingungen zu einem fundamentalen Fortschritt in der Bek\u00e4mpfung von Infektionskrankheiten gef\u00fchrt.\nResistenzentwicklung \u2013 wie sich Bakterien \nwehren\nNach der Markteinf\u00fchrung eines jeden Anti-\nbiotikums entstehen in Bakterien fr\u00fcher oder sp\u00e4ter Resistenzen, wodurch die von ihnen ausgel\u00f6ste Erkrankung nicht mehr mit diesem Antibiotikum behandelbar ist. Als Resistenz wird eine Erregervermehrung trotz wirksamer Konzentration des Antibiotikums am Wirkort bezeichnet. Eine prim\u00e4re Resistenz besteht, wenn eine Bakterienart genetisch bedingt im-mer unempfindlich gegen ein bestimmtes Anti-biotikum ist. Von einer Mutationsresistenz wird Proteinsynthese   \n(50s-Inhibitoren)  \nErythromycin  \n(Makrolide) \nChloramphenical Clindamycin\nProteinsynthese   \n(30s-Inhibitoren)  \nTetracyclin Spectinomycin Streptomycin Gentamicin Tobramycin  \n(Aminoglykoside) \nAmikacin138 \ngesprochen, wenn vor Beginn der Therapie ein-\nzelne Erreger durch Mutation resistent gegen ein Antibiotikum werden, auf das sie eigentlich empfindlich reagieren. Eine sekund\u00e4re Resis-tenz entsteht, wenn es w\u00e4hrend der Therapie durch den Selektionsdruck des Antibiotikums zu einer Vermehrung der durch Mutation resis-tent gewordenen Erreger kommt.\n13  \nResistenzen in Bakterien werden durch Resis-tenzgene ausgel\u00f6st, die in Form von Plasmiden \u2013  \nkleine ringf\u00f6rmige Erbinformationen enthal-tende DNA-Molek\u00fcle, die au\u00dferhalb der Chro-mosomen in Bakterien vorkommen und sich autonom replizieren \u2013 auf andere Erreger \u00fcber -\ntragbar sind. Bakterien entwickeln so mithilfe der Resistenzgene Mechanismen, mit denen die Wirkmechanismen der Antibiotika unsch\u00e4d-lich gemacht werden. So k\u00f6nnen Bakterien bei-spielsweise Enzyme bilden (\u03b2-Laktamasen), die das Antibiotikum zersetzen, sie k\u00f6nnen Angriffs-  \npunkte des Antibiotikums strukturell ver\u00e4ndern, einen Stoffwechsel-Bypass bilden, so dass der Angriffspunkt im Stoffwechsel des Bakteriums ersetzt wird, oder durch eine Ver\u00e4nderung der Membranpermeabilit\u00e4t das Eindringen des Wirkstoffs in den Erreger verhindern. Eine Kreuzresistenz besteht, wenn ein Bakterium gegen alle Vertreter einer bestimmten Antibio-tikagruppe mit gleichem Wirkmechanismus re-sistent ist (etwa Penicilline und Cephalosporine) und als Multiresistenz wird die fehlende Emp-findlichkeit gegen\u00fcber mehreren Antibiotika-klassen bezeichnet.\n14 Die Tuberkulose und wei-\ntere bakterielle Infektionserkrankungen weisen inzwischen extrem arzneimittelresistente Er -\nreger auf, die gegen alle Erstlinien-Antibiotika und mindestens zwei der Zweitlinien-Antibioti-ka resistent geworden sind.\n15 Damit stehen f\u00fcr \nderartige Erreger bereits diverse Behandlungs-optionen nicht mehr zur Verf\u00fcgung.\nDie Entwicklung von Resistenzen ist eine uralte \nEigenschaft von Bakterien. Selbst in Bakterien, die seit vier Millionen Jahren isoliert lebten, konnten Forscher Resistenzen nachweisen.\n16  \nNichtsdestotrotz beschleunigt die unsachge-m\u00e4\u00dfe Anwendung von Antibiotika die Entwick-lung dieser Resistenzbildung. Zun\u00e4chst wurde die Resistenzentwicklung gegen antibiotische Wirkstoffe kaum wahrgenommen und die mit ihr einhergehende Problematik jahrzehntelang weitestgehend ignoriert \u2013 eine fatale Fehlein-sch\u00e4tzung, da immer mehr Bakterien multiple Resistenzen ausbilden und die von ihnen ausge-l\u00f6sten Krankheiten mitunter kaum noch behan-delt werden k\u00f6nnen.\nBakterielle Infektionen werden wieder zur \nGefahr\nAntibiotika geh\u00f6ren nach wie vor zu den am \nh\u00e4ufigsten verordneten und auch preiswertes-ten Arzneimitteln. So werden sch\u00e4tzungsweise 600 bis 700 Tonnen Antibiotika in Deutschland in der Humanmedizin j\u00e4hrlich verbraucht, 85 Prozent davon werden von niedergelassenen \u00c4rzten verordnet.\n17  Im Kontrast dazu stehen \ndie Empfehlungen zur Minimierung des Ein-satzes von Antibiotika, um die Entstehung von Resistenzen zu minimieren.\n18 Auch die Erwar -\ntungshaltung der Patienten stellt ein Problem beim Einsatz von Antibiotika dar. So ergab sich bei einer Umfrage, dass w\u00e4hrend der Grippe- und Erk\u00e4ltungszeit ein Gro\u00dfteil der Patienten eine Antibiotika-Verordnung erwartet, wenn ihre Erk\u00e4ltungsbeschwerden nicht von selbst besser werden. Diese Erwartungshaltung ist vor allem dann problematisch, wenn sie sich auf das Verordnungsverhalten der \u00c4rzte auswirkt. Auch Wissensl\u00fccken f\u00fchren zu verschobenen Erwartungshaltungen der Patienten. So denken 31 Prozent der Deutschen, Antibiotika w\u00fcrden bei Virusinfekten wirken und 19 Prozent erhof-fen sich Hilfe bei Pilzinfektionen. Es braucht da-her mehr Aufkl\u00e4rung f\u00fcr den Einsatz und den Nutzen von Antibiotika, um die Wertsch\u00e4tzung f\u00fcr deren Bedeutung im Kampf gegen mitunter sonst t\u00f6dliche, bakterielle Infektionen zu erh\u00f6-hen.\n19 \nNeben dem Einsatz von Antibiotika in der Hu-manmedizin muss auch der Einsatz in der Tier -\nhaltung und -medizin kritisch be\u00e4ugt werden. Pharmazeutische Unternehmen und Gro\u00df-h\u00e4ndler  haben im Jahr 2013 insgesamt 1.452 Tonnen Antibiotika an Tier\u00e4rzte in Deutschland Antibiotika \u00a7 139\nabgegeben. Bei Nutz- wie auch Klein- und \nHeimtieren wurden in den letzten Jahren ver -\nmehrt multiresistente Keime nachgewiesen, die auf den Menschen \u00fcbertragen werden k\u00f6nnen.\n20 \nHierbei k\u00f6nnen aus Mast- und Lebensmittel-betrieben antibiotische Wirkstoffe auch in die Umwelt gelangen und eine signifikante Rolle bei der Entstehung und Verbreitung von Resis-tenzen gegen medizinisch wichtige Antibiotika spielen.\n21 \nVor dem Hintergrund der steigenden Resis-tenzentwicklung besteht ein stetig wachsender Bedarf an neuen, innovativen Antibiotika. Dass es an eben diesen allerdings mangelt, hat zum einen \u00f6konomische Gr\u00fcnde. Derzeit k\u00f6nnen die kostspielig zu entwickelnden Antibiotika ihre Entwicklungskosten nicht wieder einspie-len und sind daher f\u00fcr wirtschaftlich agieren-de Pharmaunternehmen eher unattraktiv. Es ist \u00f6konomisch wesentlich sinnvoller, ein Medika-ment gegen eine chronische Krankheit zu ent-wickeln, das Patienten \u00fcber Jahre einnehmen m\u00fcssen. Zudem kommt erschwerend hinzu, dass neue Antibiotika vermutlich f\u00fcr Notf\u00e4lle zur\u00fcckgehalten werden w\u00fcrden, um die Resis-tenzbildung gegen die neuen Wirkstoffe m\u00f6g-lichst lang hinausz\u00f6gern zu k\u00f6nnen. Dar\u00fcber hinaus sind neue Antibiotika extrem schwer zu finden und viele aussichtsreiche Wirkstoffe haben sich in Tests zur Anwendbarkeit zum Bei-spiel als zu giftig erwiesen.\n22 \nDurch die mangelnde gesellschaftliche Wert-sch\u00e4tzung von Antibiotika und den R\u00fcckgang der Antibiotikaforschung seitens der Industrie hat sich die Anzahl der neu zugelassenen an-tibiotischen Wirkstoffe drastisch reduziert. Um dem entgegenzuwirken ist neben der Entwick-lung neuer antibiotischer Wirkstoffe auch der Erhalt der Wirksamkeit der derzeit verf\u00fcgbaren Antibiotika unbedingt erforderlich. Hierf\u00fcr sind der sparsame Einsatz von Antibiotika und neue, pr\u00e4zise diagnostische Verfahren vonn\u00f6ten, mit denen nicht nur die Art der Infektion und das urs\u00e4chliche Bakterium, sondern auch dessen Resistenzprofil detektiert wird, damit das pas-sende Antibiotikum gezielt eingesetzt werden kann. Auch der One-Health Ansatz, der einer ganzheitlichen, interdisziplin\u00e4ren Betrachtung entspricht und die komplexen Zusammenh\u00e4nge zwischen Mensch, Tier, Umwelt und Gesund-heit beschreibt, ist f\u00fcr eine Aufrechterhaltung unserer antibiotischen Therapiem\u00f6glichkeiten von entscheidender Bedeutung. \nUm in all diesen Bereichen Erfolge zu erzie-\nlen, wurden in den letzten Jahren zahlreiche Programme, Initiativen und Kooperationen ins Leben gerufen, die auf nationaler und vor al-lem internationaler Ebene mithilfe der verschie-densten Disziplinen daf\u00fcr sorgen sollen, dass wir auch in Zukunft gegen bakterielle Infekti-onskrankheiten gewappnet sind. Ganz im Sinne von Robert Koch:\n\u201eIch w\u00fcnsche, dass im Kriege gegen die kleins-\nten, aber gef\u00e4hrlichsten Feinde des Menschen-geschlechts eine Nation die andere immer wie-der \u00fcberfl\u00fcgeln m\u00f6ge.\u201c\n23140 \n1 Pharmazeutische Zeitung (23/2015): Infektionsgeschichte: Alte Seuchen und neue Antibiotika. Avoxa \u2013 Mediengruppe Deutscher Apotheker GmbH. \n www\n.pharmazeutische-zeitung.de/index.php?id=58138 [Zugriff am 11.4.2018].\n2 CDC \u2013 Choler a 2010: Cholera in Haiti. www.cdc.gov/cholera/haiti/index.html  [Zugriff am 11.4.2018].\n3 WHO (1993): WHO declares tuberculosis a global emergency. In: Sozial- und Praventivmedizin 38 (4), S. 251\u2013252.\n4 Dobson,  Mary J. (2009): Seuchen, die die Welt ver\u00e4nderten. Von Cholera bis SARS. Unter Mitarbeit von Ute Mareik. Autoris. dt. Ausg. Hamburg: \n G + J/RBA (National geogr\naphic history).\n5 Deutsches \u00c4rzteblatt (2007): Robert Koch (1843\u20131910): Die Entdeckung des Tuberkelbazillus. www.aerzteblatt.de/archiv/54941/\n Robert-K\noch-(1843-1910)-Die-Entdeckung-des-Tuberkelbazillus  [Zugriff am 11.4.2018].\n6 Spektrum (1999): Gr am-F\u00e4rbung. www.spektrum.de/lexikon/biologie/gram-faerbung/29134  [Zugriff am 11.4.2018].\n7 Pharmazeutische Zeitung (2015): Antibiotika: Wichtig wie eh und je. Avoxa \u2013 Mediengruppe Deutscher Apotheker GmbH. \n www\n.pharmazeutische-zeitung.de/index.php?id=56845 [Zugriff am 11.4.2018].\n8 Dobson,  Mary J. (2009): Seuchen, die die Welt ver\u00e4nderten. Von Cholera bis SARS. Unter Mitarbeit von Ute Mareik. Autoris. dt. Ausg. Hamburg: \n G + J/RBA (National geogr\naphic history).\n9 Science History Institute (2017): Alexander Fleming. www.sciencehistory.org/historical-profile/alexander-fleming  [Zugriff am 11.4.2018].\n10 Stadler , Marc; Dersch, Petra (2016): How to overcome the antibiotic crisis. Facts, challenges, technologies and future perspectives. Cham, \n Switzerland: Springer (Current topics in microbiology and immunology,\n volume 398).\n11 Leopoldina Stellungnahme 2013: Antibiotika-Forschung. Probleme und Perspektiven, [Zugriff am 11.4.2018].\n12 Karow , Thomas; Lang-Roth, Ruth (2016): Allgemeine und Spezielle Pharmakologie und Toxikologie. Vorlesungsorientierte Darstellung und \n klinischer Leitfaden f\u00fcr Studium und Pr\naxis 2017. 25. Auflage. Pulheim: Thomas Karow.\n13 Stock und Wiedemann (1998): Die Bestimmung der nat\u00fcrlichen Antibiotika-Empfindlichkeit. In: Chemotherapie Journal 7. Jahrgang (4/1998), \n [Zugriff am 11.4.2018].\n14 Munita,  Jose M.; Arias, Cesar A. (2016): Mechanisms of Antibiotic Resistance. In: Microbiology spectrum 4 (2). DOI: 10.1128/microbiolspec.\n \nVMBF-0016-2015.\n15 WHO (2018): Global antimicrobial resistance surveillance system (GLASS) report.  Early implementation 2016-2017, [Zugriff am 11.4.2018].\n16 Bhullar , Kirandeep; Waglechner, Nicholas; Pawlowski, Andrew; Koteva, Kalinka; Banks, Eric D.; Johnston, Michael D. et al. (2012): \n Antibiotic resistance is prev\nalent in an isolated cave microbiome. In: PloS one 7 (4), e34953. DOI: 10.1371/journal.pone.0034953.\n17 B\u00e4tzing-F eigenbaum, J\u00f6rg; Schulz, Maike; Schulz, Mandy; Hering, Ramona; Gisbert-Miralles, Jana; Kern, Winfreid V . (2015): \n Entwicklung des \nAntibiotikaverbrauchs in der ambulanten vertrags\u00e4rztlichen Versorgung, [Zugriff am 11.4.2018].\n18 T he Review on Antimicrobial Resistance 2016: TACKLING DRUG-RESISTANT INFECTIONS GLOBALLY . FINAL REPORT AND RECOMMENDATIONS. \n Chaired by Jim O'Neill\n, [Zugriff am 11.4.2018].\n19 DAK-Umfr age 2017: Junge Erwachsene nehmen oft Antibiotika. www.dak.de/dak/bundes-themen/junge-erwachsene-nehmen-oft-\n antibiotika-1972760.html [Zugriff am 11.4.2018].\n20 Die Bundesregierung: DAR T 2020. Antibiotika-Resistenzen bek\u00e4mpfen zum Wohl von Mensch und Tier, [Zugriff am 11.4.2018].\n21 Gullberg,  Erik; Cao, Sha; Berg, Otto G.; Ilb\u00e4ck, Carolina; Sandegren, Linus; Hughes, Diarmaid; Andersson, Dan I. (2011): \n Selection of resistant bacteria at very low antibiotic concentr\nations. In: PLoS pathogens 7 (7), e1002158. DOI: 10.1371/journal.ppat.1002158.\n22 Spektrum (2017): Antibiotikaresistenzen. Die neue Welt der Superbakterien. www.spektrum.de/wissen/gehen-uns-die-antibiotika-aus/1443165 \n [Zugriff am 11.4.2018].\n23 Inschrift am Denkmal von Robert K och in der Luisenstra\u00dfe in BerlinDas Smartphone \u00a7  141\n\u00bbDer Allsprecher. [\u2026] Erteilt in jedem Augen-\nblicke Orts- und astronomische Zeit, L\u00e4nge und Breite, Wetterstand und Wettervoraussage. Ersetzt Kennkarte, P\u00e4sse, Uhr, Sonnenuhr und Kompa\u00df, nautisches und meteorologisches Ge-r\u00e4t. Vermittelt automatisch die genaue Position des Tr\u00e4gers an alle Rettungswarten bei Gefah-ren zu Lande, auf dem Wasser und in der Luft. Verweist im Peilverfahren an jeden gew\u00fcnsch-ten Ort. Weist auch den Kontostand des Tr\u00e4gers beim Energeion aus und ersetzt auf diese Weise das Scheckbuch bei jeder Bank und jeder Post-anstalt, und in unmittelbarer Verrechnung die Fahrkarten auf allen Verkehrsmitteln. [\u2026] Ver -\nmittelt die Programme aller Sender und Nach-richtenagenturen, Akademien, Universit\u00e4ten, sowie die Permanentsendungen des Punktam-tes und des Zentralarchivs. Hat Anschlu\u00df an alle Radiostationen mit ihren Str\u00f6men des Wis-sens, der Bildung und Unterhaltung, soweit sie durch Ton und Wort zu \u00fcbermitteln sind. Gibt Einblick in alle B\u00fccher und Manuskripte, soweit sie durch das Zentralarchiv akustisch aufgenommen sind, ist an Theater, Konzerte, B\u00f6rsen, Lotterien, Versammlungen, Wahlakte und Konferenzen anzuschlie\u00dfen, und kann als Zeitung, als ideales Auskunftsmittel, als Biblio-thek und Lexikon verwandt werden. Gew\u00e4hrt Verbindung mit jedem anderen Phonophor der Welt, [\u2026] Auch kann eine beliebige Menge von Anschl\u00fcssen gleichzeitig belegt werden \u2014 das hei\u00dft, da\u00df Konferenzen, Vortr\u00e4ge, Wahlakte, Beratungen m\u00f6glich sind. Auf diese Weise ver -\neinen sich die Vorz\u00fcge der Telephone mit denen der Radios. [\u2026] Das Eigent\u00fcmliche beruht auf der Vereinfachung, auf der Verdichtung in ei-nen kleinen Apparat; Man m\u00f6chte meinen, da\u00df der Stoff mit seinen kristallenen Gittern und seinen strahlenden Metallen unmittelbare Intel-ligenz gewonnen h\u00e4tte, [\u2026]\u00ab\n1 Das Smartphone \nWie ein digitales Multitool s\u00e4mtliche Lebensbereiche ver\u00e4nderte \n  \nJohannes Mock  \nDieses Zitat entstammt der Feder des umstrit-\ntenen Autors Ernst J\u00fcnger. In seinem 1949 ver -\n\u00f6ffentlichtem Roman \u201eHeliopolis\u201c beschreibt J\u00fcnger ein Ger\u00e4t namens Phonophor. Die  \nBeschreibung des technischen Multifunktions-ger\u00e4tes erinnert stark an einen gegenw\u00e4rtig omnipr\u00e4senten Gebrauchsgegenstand: das Smartphone. \nHeute sind Smartphones aus unserem All-\ntag kaum wegzudenken. Junge Erwachsene schauen durchschnittlich 80 Mal t\u00e4glich auf ihr Smartphone. Ob man sich mit einem \u00f6ffentli-chen Verkehrsmittel bewegt, die Fu\u00dfg\u00e4nger -\nzone passiert oder im Wartezimmer einer Arzt-praxis sitzt: Die Hybridger\u00e4te mit dem gro\u00dfen Touchscreen sind stets in den H\u00e4nden unserer Mitmenschen zu sehen. Dies war jedoch nicht immer so. Inwiefern das Smartphone eine In-novation ist, die zu gro\u00dfen Ver\u00e4nderungen in s\u00e4mtlichen Bereichen unseres Lebens gef\u00fchrt hat, soll im Folgenden betrachtet werden. \nPer Definition ist das Smartphone ein Mobil-\ntelefon, das die technologischen Vorausset-zungen bietet, zus\u00e4tzlich viele T\u00e4tigkeiten, die fr\u00fcher an einem Computer verrichtet wurden, mobil auf diesem Ger\u00e4t durchzuf\u00fchren. Fast alle aktuellen Modelle lassen sich \u00fcber einen Touchscreen und nicht wie ihre Vorg\u00e4nger \u00fcber \n40 Jahre142 \neine alphanumerische Tastatur bedienen. Sie \nbieten die Voraussetzungen, eine Verbindung mit dem Internet herzustellen. Ihre Betriebssys-teme sind so gestaltet, dass die Ger\u00e4te durch den Download und die Installation von Apps um zahlreiche Software-Funktionen erweitert werden k\u00f6nnen. Das Smartphone zeichnet sich also dadurch aus, dass es die Funktionsweisen einiger fr\u00fcher getrennter Ger\u00e4te in sich ver -\neint und mobil nutzbar macht. Bildhaft k\u00f6nnte man es als das Multitool oder das Schweizer Taschenmesser des digitalen Zeitalters betrach-ten. Wie normale Mobiltelefone nutzen wir es, um zu telefonieren und SMS zu schreiben. Sie dienen als Uhr, Wecker und Kalender. Der mo-bile Internetzugang erm\u00f6glicht zudem neben dem Versenden und Empfangen von E-Mails, das Aufrufen von Webseiten, das Nutzen von Messenger Apps, Diensten wie Skype und die Kommunikation \u00fcber Social Media Plattformen wie Facebook. \nEs gab auch zuvor herk\u00f6mmliche Mobiltelefo-\nne, die eine Verbindung zum Internet aufbau-en konnten, doch fragen wir uns: \u201eKennen wir jemanden der dies wirklich genutzt hat?\u201c Die Antwort f\u00e4llt meist negativ aus. Sensortechnik, Kameras und Mikrofone erm\u00f6glichen heute das Aufzeichnen, Bearbeiten und Versenden von audiovisuellen Daten. Die gro\u00dfen Displays die-nen zur Bedienung und Wiedergabe von Medi-en. Spiele, komplexe Anwendungen, Sprachas-sistenten, Enzyklop\u00e4dien und Programme, welche die Inanspruchnahme von Dienstleis-tungen erm\u00f6glichen, k\u00f6nnen auf den Ger\u00e4ten installiert und mobil verwendet werden. Sie erf\u00fcllen die Rolle von Navigationsger\u00e4ten, was durch integrierte GPS-Technologie erm\u00f6glicht wird. Mobil Gesch\u00e4ftsabschl\u00fcsse zu t\u00e4tigen, unsere Konten zu verwalten oder mittlerweile auch viele andere Ger\u00e4te zu steuern, die \u00fcber ein Heimnetzwerk, Bluetooth oder das Internet mit dem Smartphone verbunden werden k\u00f6n-nen, ist dank dieser Innovation von vielen Men-schen t\u00e4glich ausge\u00fcbte Praxis. Angefangen vom Computer, der heimischen TV- oder Ste-reoanlage bis hin zur Steuerung von Heizung, Jalousien und anderen Bestandteilen des so genannten Smart Homes: Immer mehr Kompo-nenten unserer allt\u00e4glichen Umgebung werden vernetzt und Teil des \u201eInternet of Things\u201c.\nDie ersten Smartphones wurden von Beginn \nbis Mitte der 90er Jahre entwickelt. Vorl\u00e4ufer der Ger\u00e4te, welche heute die Bezeichnung Smartphone tragen, ist der von Bellsouth und IBM entwickelte SIMON. Der von Nokia ein-gef\u00fchrte Personal Communicator gilt als das erste Smartphone. Das Ger\u00e4t wurde als mobi-les B\u00fcro beworben und zu sehr hohen Preisen vermarktet. Der Nokia Communicator bestach dadurch, dass er neben der M\u00f6glichkeit, Ad-ressdatenbanken zu verwalten und anzulegen, auch Faxe versenden konnte und den Nutzerin-nen und Nutzern einen HTML-f\u00e4higen Browser bot. 1999 brachte der damals in der Mobilfunk-branche marktf\u00fchrende Hersteller das Modell Nokia 7110 auf den Markt. Von nun an war es m\u00f6glich, f\u00fcr eine mobile Verbindung optimierte Webseiten aufzurufen. Dieses Ger\u00e4t gilt als das erste \u201eWap-Handy.\u201c Mit weiteren Modellen der Hersteller Nokia, Blackberry und Motorola wur -\nde die M\u00f6glichkeit der mobilen Internetnutzung umgesetzt. Zusammen mit der Firma Blackberry dominierte Nokia den Smartphonemarkt. Bis zum Jahr 2006 war Nokias Symbian das meist-genutzte Betriebssystem (OS). Nat\u00fcrlich hatten auch herk\u00f6mmliche Mobilfunkger\u00e4te Multi-mediafunktionen und konnten etwa als Spei-cher- und Wiedergabeger\u00e4t f\u00fcr MP3 verwendet werden. Die im Folgenden beschriebenen Neu-erungen durch das Smartphone machten diese Funktionen jedoch erst benutzerfreundlich. \nDie Vorstellung des ersten iPhone ist der ent-\nscheidende Wendepunkt in der Geschichte des Smartphones. In einer mittlerweile vielfach zi-tierten Pr\u00e4sentation k\u00fcndigte Steve Jobs am 9. Januar 2007 auf der Messe MacWorld das erste Apple-Smartphone an. Als er dabei versprach, drei Technologien in einem Ger\u00e4t zu vereinigen (\u201eeinen Widescreen iPod mit Touch-Kontrolle, ein revolution\u00e4res Mobiltelefon und ein bahn-brechendes Internet-Kommunikations-Ger\u00e4t\u201c), war der \u00d6ffentlichkeit noch nicht bewusst, welches Ausma\u00df der durch das erste iPho-Das Smartphone \u00a7  143\nne in Gang gesetzte Transformationsprozess \ns\u00e4mtlicher Lebensbereiche annehmen w\u00fcrde2: \nDie Multitouch-Funktion revolutionierte die Bedienung von Ger\u00e4ten \u00fcber Displays und war eine der vielen Eigenschaften des iPhones, die den Erfolg des Produktes bedingten. Andere Hersteller zogen schnell nach und so wurden Produkte auf Basis anderer OS ebenfalls \u00fcber das Display bedienbar. 2008 wurde das erste Android Smartphone, das HTC Dream, auf dem Markt eingef\u00fchrt. Von diesem Zeitpunkt an begann ein Wettrennen zwischen Herstellern von Mobilfunkger\u00e4ten. Die Verkaufszahlen der Smartphones stiegen an. Als Marktf\u00fchrer konn-ten sich Samsung und Apple durchsetzen. Im Bereich der Betriebssysteme setzten sich Apples iOS und Googles Android durch. In den folgen-den zehn Jahren wurde die Hardware der mo-bilen Allesk\u00f6nner immer weiter verbessert: Die Kameras wurden kleiner sowie sch\u00e4rfer, die Re-chenleistung h\u00f6her, die Displays hochaufl\u00f6sen-der, die Sensoren genauer und die Funktions-weise der Betriebssysteme wurde verbessert. Die zur Verf\u00fcgung stehenden Funktionen durch Apps nahmen zu. \nDas Smartphone \u2013 eine \ndisruptive Innovation\nDie Smartphones holten ihre Vorg\u00e4nger in-\nnerhalb weniger Jahre ein und setzten sich somit als neuer Standard durch. Im Jahr 2017 existierten weltweit \u00fcber 2,4 Milliarden Smart-phonebesitzer.\n3 In den Jahren 2007 bis 2017 \nsank ebenfalls der Absatz aller elektronischen Ger\u00e4te, deren Funktionsweise nun in einem Ger\u00e4t zusammengefasst wurde. Dazu geh\u00f6ren vor allem Digitalkameras und MP3-Player, aber auch Navigationssysteme. Gegenwertig besit-zen also mehr Menschen ein Smartphone als ein herk\u00f6mmliches Mobilfunkger\u00e4t. Doch was genau macht den nicht reversiblen Siegeszug des Smartphones aus und wie genau ist seine rasche Ausbreitung zu verstehen? Die Eigenschaft einer so genannten disruptiven Innovation ist es, etablierte Technologien oder Verfahrensweisen abzul\u00f6sen. Innerhalb dieses Vorganges finden sowohl im Privatleben als auch in der Berufswelt, Industrie und Wirtschaft einschl\u00e4gige Ver\u00e4nderungen statt. In vielen F\u00e4l-len wird von einer disruptiven Innovation ge-sprochen, wenn eine herk\u00f6mmliche Technolo-gie oder Verfahrensweise stark digitalisiert und dadurch ihre Funktionsweise vereinfacht oder extrem erweitert wurde. Vor dem Hintergrund des bis hier Gesagten l\u00e4sst sich vermuten, dass Smartphones eine solche disruptive Innovation par Excellence darstellen.\n4\nRelevant f\u00fcr die seit 2007 ansteigende Nachfra-ge sind die zahlreichen M\u00f6glichkeiten, die dem Benutzer durch mobile Apps geboten werden. In diesem Zusammenhang wird der App-Store zum Mittelpunkt der digitalen Revolution. Er bietet Nutzenden einerseits die M\u00f6glichkeit, zahlreiche Programme mit verschiedenen Funk-tionen zu installieren. Andererseits konnten Softwareentwickler auf der ganzen Welt nun ihre Kreativit\u00e4t nutzen um einen neuen Markt zu erschlie\u00dfen. Als weitere ausschlaggebende Faktoren f\u00fcr den Siegeszug des Smartphones gelten die intuitive Bedienung, das Design, das Zusammenspiel von Hard- und Software sowie Branding bzw. die Marketingstrategien der Her -\nsteller. \nMobile Apps sind also ein wichtiger Bestandteil \ndieser Erfolgsgeschichte. Es ist klar, dass diese nicht allein durch die Einf\u00fchrung des techni-schen Artefakts stattfinden konnte. Der mobile Zugriff auf das Internet musste gew\u00e4hrleistet sein, um Daten austauschen zu k\u00f6nnen. Eine vorweggehende Innovation schuf die Rahmen-bedingung f\u00fcr den Erfolg der Multifunktions-ger\u00e4te: die Einf\u00fchrung des 3G-Mobilfunkstan-dards.\n5 Regierungen erkannten diese Trends \nschnell. Um die Jahrtausendwende wurden erstmals Lizenzen zur Bewirtschaftung der Stan-dards versteigert. Doch erst mit dem steigenden Bedarf mussten Netze umgebaut und neue In-frastrukturen geschaffen werden, um den An-forderungen gerecht zu werden. Seit dem Jahr 144 \n2008 stieg beispielsweise das Datenvolumen im \nDeutschen Mobilfunk von elf Petabyte auf ca. 1.200 Petabyte im Jahr 2017 an.\n6 Diese Men-\nge entspr\u00e4che etwa 285 Billionen B\u00fcchern in englischer Sprache und somit 17.400 Mal der Library of Congress. Durch das Aufkommen der modernen Smartphones stiegen auf Seiten der Hersteller der Bedarf an Displays, Kameras, Flashspeicher, Sensortechnologien und Funk-hardware. Der Bedarf an einer Fertigung in gro-\u00dfen St\u00fcckzahlen ist auf die ansteigende Nach-frage zur\u00fcckzuf\u00fchren. Es wurden daf\u00fcr neue Fertigungsketten und Lieferprozesse geschaf-fen. Die Anspr\u00fcche an die Hardware wuchsen immer weiter. Es ist fraglich, ob die Entwicklung der Kameratechnik ohne das Smartphone das heutige hohe Niveau erreicht h\u00e4tte. \nDie bis dahin bestehende Mobilfunkindustrie \nwurde einem radikalen Transformationsprozess unterworfen; neue Industriezweige wurden entwickelt und neue M\u00e4rkte geschaffen. Mit den mobilen Apps entstand ein vollst\u00e4ndig neu-er Markt. Die Hardware und Entwicklungsbran-che begann zu boomen. Die Zahl der weltweit Besch\u00e4ftigten f\u00fcr mobile App-Entwicklungen lag im Jahr 2016 bei 12 Millionen Personen.\nMit Verbreitung der Apparate seit 2007 wuchs \ndie Nachfrage stetig weiter. Man spricht in diesem Zusammenhang von einem positiven Netzwerkeffekt: Besitzen nur wenige Personen ein solches Ger\u00e4t, sind die M\u00f6glichkeiten der Inanspruchnahme von Dienstleistungen wie Kommunikationsservices durch Social Media limitiert. Mit steigender Anzahl von Nutzerin-nen und Nutzern steigen jedoch die Vorz\u00fcge des Besitzes. Das Netzwerk breitet sich aus und es sind mehr potenzielle Kommunikati-onspartner verf\u00fcgbar. Auch bei der Einf\u00fch-rung des Telefons vor einem Jahrhundert stieg der Nutzen ein Telefon zu besitzen mit dem Wachstum des Netzwerkes. Social Media kann in diesem Zusammenhang als eine treibende Kraft verstanden werden. Dieser Effekt wirkt sich sowohl auf die Seite des Angebots von Hardware und Services als auch auf die Seite der Nutzenden aus. Mit steigender Nachfrage bei den Anbietern der Services wuchs wiede-rum die Nachfrage nach Ger\u00e4ten bei den Pro-duzenten. \nGoogle und Apple k\u00f6nnen als die wirtschaft-\nlichen Gewinner dieses Prozesses gesehen werden. Beide waren vorher keine Akteure in der Mobilfunkbranche. Sie sind von au\u00dferhalb in die Branche eingestiegen, haben somit den Start des disruptiven Prozesses ma\u00dfgeblich beeinflusst und dabei ganz unterschiedliche Strategien verfolgt. Worin lag jedoch ihre Mo-tivation? Diese war klar \u00f6konomischer Natur. Google konnte durch das Eindringen in das Gesch\u00e4ft mit Smartphones klar seine wirt-schaftliche Machtposition, die auf dem Such-maschinenservice beruht, verteidigen. Schon vor Einf\u00fchrung des Smartphones galt Google durch seine Dienstleistungen als f\u00fchrend im Internet. Google war nie ein Hersteller von Hardware. Durch die Entwicklung des erfolg-reichen Android konnte das Unternehmen den Markt erobern, ohne in die Hardware-Branche einsteigen zu m\u00fcssen. Apple hingegen war seit Beginn des Jahrtausends Teil der Unter -\nhaltungsmedienindustrie. Der Erfolg des iPods und von iTunes wurde durch Handys bedroht, die in der Lage waren, Musik wiederzugeben, Fotos zu machen und Videos abzuspielen. Um den Verlust gro\u00dfer Anteile in der Entertainm-entbranche durch Mobilfunkger\u00e4te abzuwen-den, musste Apple selbst ein multifunktionales Mobilfunkger\u00e4t entwickeln. Ebenso konnte der Hardwarehersteller durch den Einstieg in den Mobilfunkmarkt sein Portfolio entschei-dend ausweiten und das eigene Wachstum steigern. Dieses Wachstum ist mit Sicherheit eine grundlegende Motivation. Durch iOS konnte Apple seine verf\u00fcgbaren Strukturen im Bereich Medien auf das Thema Software erweitern. Dieser strategische Gedanke und folglich hohe Investitionen in Forschung und Entwicklung legten den Grundstein f\u00fcr die Entwicklung des Smartphones. \nPrim\u00e4r haben sich mit der Verbreitung des \nSmartphones das Ma\u00df sowie die Art und Wei-se, wie wir das Internet nutzen, stark gewan-Das Smartphone \u00a7  145\ndelt. Fast alle zuvor im Internet vollzogenen \nHandlungen k\u00f6nnen nun mobil vollzogen werden. Ebenso wurde der Spielraum m\u00f6gli-cher Handlungsweisen erweitert. Die Netze wurden bedarfsgerecht ausgebaut. F\u00fcr viele Menschen ist es mittlerweile Teil des Alltags, \u00fcber ihr Mobilfunkger\u00e4t Musik oder Filme zu streamen. Mobilit\u00e4t erh\u00e4lt in diesem Zuge einen komplett neuen Stellenwert. Der wei-tere Ausbau der Netze von 3G \u00fcber den Zwi-schenschritt LTE zum neuen Standard 5G hin wird diese Entwicklungstendenz auf s\u00e4mtliche Technologien, die in unserem Alltag verwurzelt sind, ausdehnen und den durch das Smartpho-ne in Gang gesetzten Transformationsprozess beschleunigen. Ebenfalls hat sich die Art und Weise menschlicher Kommunikation stark ver\u00e4ndert. Durch den Erfolg von Social Media wandelten sich unsere Sprache und unsere kommunikativen Gepflogenheiten. Wie wir mit Informationen \u00fcber uns selbst umgehen, welche Informationen wir bereit sind preiszu-geben und welchen Stellenwert wir der Selbst-darstellung unserer Mitmenschen einr\u00e4umen, hat sich durch den mobilen Zugriff auf Social Media und die M\u00f6glichkeit, Bild- und Tonma-terial immer und \u00fcberall zu teilen, gewandelt. Wir sind freiz\u00fcgiger geworden.\nDie Wahrnehmung und die Bewertung unserer \nUmwelt haben sich im Rahmen des hier be-schriebenen Prozesses ebenfalls transformiert. Die H\u00e4ufigkeit, mit der wir nach dem Vorhan-densein von Wi-Fi oder entsprechenden Pass-w\u00f6rtern fragen, ist Beleg f\u00fcr diese Tatsache. Fragen wie \u201eWarum sollte ich noch ein Buch mitnehmen?\u201c, \u201eHabt ihr eine Steckdose?\u201c oder \u201eWarum hat dieses Ger\u00e4t keinen Touch-Screen?\u201c zeigen die Selbstverst\u00e4ndlichkeit, mit der wir Smartphones benutzen, die Allt\u00e4glich-keit der Bedienung von Touchscreens und den zunehmenden R\u00fcckgang von Printmedien an. Ebenso ist der allt\u00e4gliche R\u00fcckgriff auf Suchma-schinen, mit deren Hilfe Sachlagen gekl\u00e4rt oder neue Argumente zur Untermauerung eigener Positionen gefunden werden sollen, Indikator f\u00fcr bedeutungsvolle Eingriffe in unsere Hand-lungs- und Kommunikationsweise. Der Status von Information wird in diesem Zuge einem Wandel unterzogen, denn f\u00fcr die Besitzerinnen und Besitzer von Smartphones stehen Online- Enzyklop\u00e4dien und Suchmaschinen jederzeit zur Verf\u00fcgung.\nDie Verhaltens\u00e4nderungen haben eine Reor -\nganisation unserer Umwelt und den Umbau \nder Infrastruktur f\u00fcr den fl\u00e4chendeckenden Zugang zu mobilen Daten erforderlich ge-macht. Wi-Fi-Hotspots zur Erm\u00f6glichung eines Internetzugangs sind \u00fcber unsere St\u00e4dte ver -\nteilt, Funknetze werden ausgebaut. Nicht nur in Geb\u00e4uden, sondern auch in \u00f6ffentlichen Verkehrsmitteln steht vermehrt der Zugang zu Netzwerken und somit zum Internet zur Verf\u00fcgung. Das Smartphone ist ein stetiger Begleiter in unserem Alltag geworden. Von ei-nigen Dienstleistern und Serviceanbietern wird bez\u00fcglich der Kommunikation mit Kunden der Besitz eines Smartphones vorausgesetzt. Dies birgt nat\u00fcrlich die Gefahr, dass Personen, die kein Smartphone besitzen, im Zuge dieser Ent-wicklung abgeh\u00e4ngt werden k\u00f6nnen. Parallel dazu w\u00fcnschen sich viele B\u00fcrgerinnen und B\u00fcrger verst\u00e4rkt eine smartphonefreundliche-re Umgebung \u2013 wir wollen smart wohnen und smart leben. Trotz der steigenden Mobilit\u00e4t und der vielfachen Erleichterung unseres All-tags darf dennoch nicht \u00fcbersehen werden, dass mit Innovationen auch neue Herausforde-rungen und Problemstellungen auf s\u00e4mtlichen Ebenen zu Tage treten k\u00f6nnen. \nDie Begriffe Datenhoheit, Datenschutz, Daten-\nmacht und Datenmissbrauch stecken ein The-menfeld ab, das mit dem Erfolg des Smartpho-nes stark an Relevanz gewonnen hat. Seitdem immer mehr Menschen das Smartphone nut-zen, um Informationen zu teilen, \u00fcber das Inter -\nnet zu kommunizieren, mobil Inhalte des Webs abzurufen und Gesch\u00e4ftsabschl\u00fcsse zu t\u00e4tigen, entstand eine unfassbar gro\u00dfe Menge an Da-ten. Der Schutz dieser Daten ist eine entschei-dende Herausforderung unserer Gegenwart. Der Missbrauch dieser Daten kann nicht nur zur Verletzung der Privatsph\u00e4re f\u00fchren, sondern auch zur gezielten Manipulation, wie beispiels -146 \nweise die derzeitige Debatte um Facebook, \nCambridge Analytica und den Umgang mit  \nDaten im Zuge des US-Wahlkampfs 2016 zeigt. Ein weiteres Beispiel, anhand dessen die  \nHerausforderung durch die Innovation illustriert werden kann, ist der Umgang mit Daten, die von Gesundheits-Apps und Wearables erzeugt werden. Kritische Stimmen sehen ein Problem darin, dass personenbezogene Daten \u00fcber den  \nGesundheitszustand in die H\u00e4nde von Arbeitge-  \nbern und Versicherungen gelangen k\u00f6nnten  \nund Entscheidungen \u00fcber die Beitragseinstu -\nfungen oder die Ausgestaltung der Besch\u00e4fti-  \ngungsverh\u00e4ltnisse beeinflussen. All dies illustriert  \nnicht nur die facettenreichen Ver\u00e4nderungen  \ndurch eine disruptive Innovation, sondern  \ndass Gesellschaft und Innovation zusammen  \nzu denken sind. Eine Innovation, wie die hier  \nbesprochene, erleichtert und verbessert unser Leben auf der einen Seite, w\u00e4hrend sie gleich-zeitig Politik, Wirtschaft, Wissenschaft und das Individuum vor gro\u00dfe Herausforderungen stellt.\n7 \nDie Rolle des Smartphones \nam Beispiel politischer Bewegungen \nWie bereits angedeutet, spielt das Smartpho-\nne mittlerweile auch eine Rolle in der Sph\u00e4re des Politischen und somit im Politikjourna-lismus. W\u00e4hrend der als Arabischer Fr\u00fchling bekannten politischen Umschw\u00fcnge im Jahr 2011 wurden \u201eneue Medien zum Mittel der Selbsterm\u00e4chtigung\u201c.\n8 In diesem Zusammen-\nhang etablierte sich die Plattform Facebook als das wichtigste Medium zur Mobilisierung der Bev\u00f6lkerung. Der Kurznachrichtendienst Twitter und die Plattform YouTube wurden zu den Kan\u00e4len, mit deren Hilfe der Welt\u00f6ffent-lichkeit Informationen \u00fcber die Proteste mit-geteilt wurden. Doch es war das Smartphone, das die technologische Voraussetzung bot, aufgenommene Bilder und Videos schnell zu verarbeiten, zu kommentieren, mit Informatio-nen \u00fcber die eigene Position zu versehen und online bereit zu stellen. Dies diente zur Verbrei-tung von Informationen \u00fcber die Proteste und somit zu einer Steigerung der nationalen und internationalen Aufmerksamkeit. Besonders in Situationen, in denen professionellen Journalis-ten die Aus\u00fcbung ihres Berufs erschwert oder unm\u00f6glich gemacht wurde, konnten Video-  \nmaterial und Fotos schnell im Internet ver\u00f6ffent- licht werden. Protestteilnehmer wurden zu  \nsogenannten B\u00fcrger-Journalisten. Bedeutende Nachrichtensender nahmen Zugriff auf diese Materialien und sorgten f\u00fcr eine weltweite Verbreitung. Somit erhielt das von den Teil-nehmern an den Protesten aufgenommene Rohmaterial Gewichtung in einer wesentlich gr\u00f6\u00dferen Dimension. Die Rolle des Smartpho-nes f\u00fcr den Journalismus und die \u00d6ffentlichkeit wird an diesem Beispiel deutlich. Sowohl Jour -\nnalisten als auch Privatpersonen werden durch das digitale Multitool bef\u00e4higt, Informationen aufzuzeichnen, zu kommentieren und mit der \u00d6ffentlichkeit zu teilen. Weiterhin sind inner -\nhalb  dieser Entwicklung klassische Strukturen aufgel\u00f6st worden. Bisherige Rezipienten bzw. Konsumenten k\u00f6nnen nun zu Prosumenten von Nachrichten und Medien werden, sei es durch Social Media, Blogs oder Kurznachrichtendiens-te. Neue partizipative Elemente am politischen Zeitgeschehen sind im Rahmen des Innovati-onsprozesses entstanden. An dieser Stelle soll eine weitere Transformation, die auf dem Feld des Journalismus durch Smartphones und die neuen Konzepte des mobilen Zugriffs auf In-formationen in Gang gesetzt wurde, erw\u00e4hnt werden: Wir konsumieren unsere Nachrichten immer mehr in digitaler als gedruckter Form. Die im Januar 2018 aufgekommenen Proteste im Iran und der damit einhergehende massive R\u00fcckgriff auf mobile Apps belegen, wie die Technologie als Werkzeug innerhalb politischer Prozesse etabliert ist.\n9 \nFazit\nDas Smartphone ist eine Innovation, die s\u00e4mt-liche Bereiche unseres Lebens gewandelt hat. Eine Umfrage zeigt, dass sich mittlerweile 71 Das Smartphone \u00a7  147\nProzent der Smartphone Nutzenden in Deutsch-\nland ein Leben ohne das Ger\u00e4t nicht mehr vor -\nstellen k\u00f6nnen.6 Dies zeugt von der immensen \nAkzeptanz gegen\u00fcber der Innovation und mag wohl auf die damit einhergehenden vielf\u00e4ltigen Erleichterungen in unserem Alltag zur\u00fcckzuf\u00fch-ren sein. Durch das Smartphone hat sich unsere Lebenswelt ver\u00e4ndert und gleichzeitig haben wir es als Teil unseres Alltags akzeptiert. Inner -\nhalb von nur zehn Jahren ist es zu unserem ste-tigen Begleiter geworden. Mittlerweile ziehen wir es PCs und Laptops vor, um auf das Inter -\nnet zuzugreifen. Es lie\u00df andere Produkte, de-ren Funktion es inkorporierte, obsolet werden. Auch wenn derzeit die Verkaufszahlen leicht stagnieren, sich eine S\u00e4ttigung des Marktes an-deutet und ein Innovationsplateau zu verzeich-nen ist bzw. bei neuen Modellen Verbesserun-gen nur inkrementeller Natur sind, schm\u00e4lert dies nicht den Status als eine der wichtigsten technologischen Neuerungen der vergangenen Jahrzehnte. Der Fokus der Verbraucher verschiebt sich nun jedoch langsam auf andere Produkte. Bei ge-nauerer Betrachtung wird deutlich, dass das Interesse an den Technologien steigt, als deren Wegbereiter das Smartphone gilt: Sprachassis-tenten, Augmented Reality- und Virtual Reali-ty-Produkte. Einige Experten gehen davon aus, dass mit der Einf\u00fchrung des neuen Telekommu-nikationsstandards 5G die Wertsch\u00f6pfung des Smartphones weiter ausgebaut werden k\u00f6nnte. Durch seine Omnipr\u00e4senz und durch die vielf\u00e4l-tigen Funktionsweisen erweitert es das Reper -\ntoire menschlicher Handlungsm\u00f6glichkeiten wie kaum eine Innovation zuvor. Selbst wenn die Displays kleiner werden oder verschwinden, die Ger\u00e4te nicht mehr in der Hand, sondern um das Handgelenk getragen werden und die Be-dienung sich auf die Spracheingabe verlagern wird, zeigt dies nicht eine Abwendung vom Smartphone an. Diese Ph\u00e4nomene verweisen auf eine sehr hohe Akzeptanz der neuartigen Ger\u00e4te. Wir w\u00fcnschen uns intuitivere Bedie-\nAbb. 1: Smartphones spielen bei Protesten auf der Stra\u00dfe eine immer gr\u00f6\u00dfere Rolle wie zum Beispiel in Hongkong.148 \nnungen. Die immer intelligenteren Programme \ninterpretieren unser Verhalten und beginnen f\u00fcr uns voraus zu denken oder machen  \nServices immer individueller. Damit \u00e4ndert sich die Mensch-Maschine-Schnittstelle. Durch die Wearables wird die Ann\u00e4herung zwischen menschlichem K\u00f6rper und multifunktionalem Kommunikationsger\u00e4t immer gr\u00f6\u00dfer. Technik- vision\u00e4re tr\u00e4umen heute davon, die durch Smartphones geschaffenen M\u00f6glichkeiten \u00fcber Gedankenbewegungen \u2013 mittels Brain-Com-  \nputer-Interfaces \u2013 nutzbar zu machen.\n1 J\u00fcnger, E. (1949): Heliopolis \u2013 R\u00fcckblick auf eine Stadt. T\u00fcbingen. S. 347 - 349.\n2 Montag, C. (2018): Homo Digitalis. Smartphones, Soziale Netzwerke und das Gehirn. Wiesbaden.\n3 Murphy, D.: 2,4 BN Smartphone Users in 2017, Say E.Marketer: (http://mobilemarketingmagazine.com/24bn-smartphone-users-in-2017-\n says-emark\neter) [Zugriff am 7.5.2018].\n4 Bendel, O.: Disruptive Technologien. https://wirtschaftslexikon.gabler.de/definition/disruptive-technologien-54194 [Zugriff am 7.5.2018]. \n5 Madsen Strojer, E.; Prethun Hartington, S.: Disruptive Technologies and Networking in Telecom Industries. Aarhus 2015. S. 4. \n \nwww.omicsonline.org/open-access/disruptive-technologies-and-networking-in-telecom-industries-2375-4389-1000165.php?aid=65836 \n [Zugriff am 7.5.2018].\n \n6 Bitkom (2017): Smartphone-Markt. Konjunktur und Trends. www.bitkom.org/Presse/Anhaenge-an-PIs/2017/02-Februar/Bitkom-\n Pressek\nonferenz-Smartphone-Markt-Konjunktur-und-Trends-22-02-2017-Praesentation.pdf [Zugriff am 7.5.2018].\n7 Vor allem im Bereich der Psychologie werden Ph\u00e4nomene wie Smartphonesucht, Depression durch die sich \u00e4ndernde Qualit\u00e4t unserer \n K\nommunikation und die Abnahme kognitiver F\u00e4higkeiten diskutiert. Die Literatur zu diesem Thema ist tief und komplex. vergl. Montag, C. (2018)\n8 El Difaroui, Asiem: Die Rolle der neuen Medien im Arabischen Fr\u00fchling. www.bpb.de/internationales/afrika/arabischer-fruehling/52420/die-\n rolle-der\n-neuen-medien?p=all [Zugriff am 7.5.2018]. \n9 Quinn, M.: One Difference Between 2018 and 2009 Iran Protests: 48 Million Smartphones. www.voanews.com/a/difference-between-\n 2009-and-2018-ir\nan-protests-is-48-million-smartphones-/4190712.html [Zugriff am 7.5.2018].Meta-Innovationen oder die Innovation des Innovationssystems selbst \u00a7  149\nMeta-Innovationen oder die Innovation \ndes Innovationssystems selbst\nPeter Dortans\nWorum soll es in diesem Beitrag gehen \nund was ist der Anspruch?\nDas nationale Innovationssystem in Deutsch-\nland f\u00f6rdert nicht nur Innovationen, es unter -\nliegt auch selbst einem Innovationsdruck, von dem die VDI/VDE-IT als Teil des Systems betrof-fen ist. Nach einigen kurzen Anmerkungen zur Rolle der VDI/VDE-IT und zum Innovationssys-tem befasst sich dieser Text mit einem Beispiel f\u00fcr Meta-Innovationen. Er tut dies anhand der zurzeit diskutierten Forderung nach einer F\u00f6rderung von radikalen Innovationen. Diese \u00dcberlegungen sind f\u00fcr die VDI/VDE-IT auch vor dem Hintergrund ihres eigenen Gesch\u00e4fts-modells interessant, weil n\u00e4mlich von einigen Akteuren unterstellt wird, dass man f\u00fcr diese keine Projekttr\u00e4ger ben\u00f6tigt. \nEin langj\u00e4hriger Weggef\u00e4hrte von Seiten der \nGesellschafter des Unternehmens hat einmal gesagt: Die VDI/VDE-IT ist ein Kind des Minis-teriums (damals Bundesministerium f\u00fcr For -\nschung und Technologie, BMFT, gegr\u00fcndet 1972) und wird es immer bleiben. Wir sind stolz darauf und mit Begeisterung seit 1978 Teil des deutschen und europ\u00e4ischen Innovations-systems und Tochterunternehmen der beiden gro\u00dfen deutschen Ingenieurvereinigungen. F\u00fcr Deutschland und sein Innovationssystem t\u00e4tig zu sein, ist uns deshalb wichtig. Gleichzeitig muss man eine gewisse kritische Distanz zum eigenen Handeln haben, um es weiter entwi-ckeln zu k\u00f6nnen. Nur weil etwas immer schon gemacht wurde und gut war, muss das nicht f\u00fcr alle Zukunft richtig sein. Andererseits ist nicht alles, was neu ist oder neu klingt, deshalb auch gut.Die Rolle der VDI/VDE-IT\nDie VDI/VDE Innovation + Technik GmbH mit ihren Vorl\u00e4uferinstitutionen ist seit 40 Jahren Teil des deutschen und europ\u00e4ischen Innova-tionssystems. Wie der Beitrag, den das Unter -\nnehmen in dieser langen Zeit mit vielen hundert engagierten und begeisterten Mitarbeiterinnen und Mitarbeitern geleistet hat, zu bewerten ist, mag der Leser entscheiden. Wenn es aber ein Element gibt, das sich positiv durch die gesam-ten 40 Jahre zieht, dann ist es die Bereitschaft des Teams, sich dem Wettbewerb der Ideen zu stellen und sich dem vollen Innovationsdruck des Innovationssystems selbst auszusetzen. Inhouse-Vergaben, Grundfinanzierungen oder die Einbindung in gro\u00dfe grundfinanzierte Or -\nganisationen standen f\u00fcr die VDI/VDE-IT nie zur Debatte. Das Unternehmen lebt von seinen im Wettbewerb gewonnenen Auftr\u00e4gen und nur von diesen. \nSeit seiner Gr\u00fcndung ist die besondere Kom-\npetenz f\u00fcr die F\u00f6rderung von KMU ein Merk-mal des Unternehmens, entstanden durch die mit der Gr\u00fcndung verbundene Aufgabe der Einf\u00fchrung der Mikroelektronik bei KMU. Aus-gehend von dieser Konfiguration wurde das Know-how-Spektrum \u00fcber die Themen Gr\u00fcn-dung, Informationstechnik, Bildung, Arbeit, Gesundheit und weitere bis heute konsequent ausgebaut.\nZur Rolle der VD/VDE-IT geh\u00f6rt auch die kla-\nre Abgrenzung zu den anderen Akteuren im Innovationssystem. Das Parlament und die Ministerien gestalten Politik, geforscht wird an Universit\u00e4ten, Forschungseinrichtungen und in Unternehmen \u2013 die VDI/VDE-IT be-\n40 Jahre150 \nr\u00e4t die Akteure des Innovationssystems zu  \n(neuen) Strategien und Instrumenten in  \ndiversen Themenfeldern und setzt Ma\u00df  \nnahmen im Auftrag um. Sie analysiert und \nevaluiert das Innovationssystem in einigen  \nTeilen und tr\u00e4gt damit auch zu dessen  \nWeiterentwicklung bei.\nGelegentlich wird die Frage diskutiert, ob Pro-\njekttr\u00e4ger f\u00fcr das deutsche Innovationssystem unverzichtbar sind. Das sollte man mit einer guten Portion Bescheidenheit bezweifeln, es gibt fast immer andere Optionen. Aufgabe der  \nVDI/VDE-IT und ihrer Wettbewerber ist es viel-mehr, immer nachzuweisen, dass ihre Einbin-dung zu einem international sehr wettbewerbs-f\u00e4higen Innovationssystem f\u00fchrt. Gerade die wettbewerbliche Vergabe von Projekttr\u00e4ger -\nschaften zum Management der staatlichen F\u00f6r -\nderprogramme in Deutschland f\u00fchrt zu immer neuen Ideen und zu einer starken Kunden- und Klientenorientierung, wobei Kunden Ministeri-en und Klienten gef\u00f6rderte Einrichtungen und Unternehmen sind. F\u00f6rdereinrichtungen im Besitz des \u00f6ffentlichen Auftraggebers sind ein-facher zu beauftragen, f\u00fchren aber durch feh-lenden Wettbewerb nach unserer \u00dcberzeugung langfristig zu schlechteren Ergebnissen. Hier kommt der gleiche Effekt zum Tragen wie bei hohen Schutzz\u00f6llen f\u00fcr bestimmte Industrien. Weniger Wettbewerb f\u00fchrt fast nie zu besseren Ergebnissen.\nWegen dieser wettbewerblichen Marktpositi-\nonierung diskutieren die Mitarbeiterinnen und Mitarbeiter der VDI/VDE-IT leidenschaftlich mit anderen Partnern im Innovationssystem dessen Weiterentwicklung und \u00fcber Innovationen des Systems selbst. \nZum Begriff des Innovationssystems\nIm Brockhaus von 1970 findet sich der Begriff Innovation oder Innovationssystem nicht, in der Ausgabe von 2001 wird ihm als Schl\u00fcsselbe-griff ein Sonderkapitel gewidmet.\n1 Das Thema \nInnovation ist heute sicher in der Mitte der Ge-sellschaft angekommen, auch wenn es in der \u00f6ffentlichen Wahrnehmung oft hinter anderen Themen wie Wirtschaft und Bildung zur\u00fcck-stehen muss. Innovationspolitik erzeugt eben in der Regel keine tagesaktuellen Schlagzeilen, was f\u00fcr die elektronischen und Printmedien aber wichtig ist.\nDie OECD definierte 1999 ein Innovationssys-\ntem wie folgt:\n\u201cThe market and non-market institutions in a \ncountry that influence the direction and speed of innovation and the technology diffusion can be said to constitute a national innovation sys-tem. Innovation systems also exist at other le-vels, e.g. there are worldwide, regional or local networks of firms and clusters of industries.\u201d\n2\nDamit sind Forschungseinrichtungen, Bildungs-einrichtungen und Unternehmen wie auch Fi-nanziers gleicherma\u00dfen erfasst und eben auch die Projekttr\u00e4ger.\nInnovationssysteme bestehen aus vielen ver -\nschiedenen Bestandteilen und, wenn es gut \nl\u00e4uft, ist das Ganze mehr als die Summe sei-ner Teile. Diese Bestandteile sind \u00f6ffentliche oder private Institutionen, Regierungsstellen oder auch Einzelpersonen. Es k\u00f6nnen \u201eoffizi-elle\u201c und offenkundige Partner des Innovati-onssystems sein, wie es Bundesministerien, Forschungseinrichtungen oder Transfereinrich-tungen und Finanziers wie der Hightech Gr\u00fcn-derfonds sind. Es k\u00f6nnen auch Partner sein, die sich ihrer Rolle im Innovationssystem nicht oder nur sehr begrenzt bewusst sind wie etwa Juristen, Steuerberater oder Handwerker. Das gesamte System ist sehr stark verwoben und fast alle Faktoren beeinflussen sich gegensei-tig, was nat\u00fcrlich nichts Neues ist.\nEin wesentlicher Faktor f\u00fcr das Innovationssystem  \nsind auch die gesetzlichen Rahmenbedingungen \nf\u00fcr die Akteure in einer Volkswirtschaft. Sind unsere Rahmenbedingungen \u00fcberhaupt so auf-gestellt, dass zum Beispiel disruptive Innovatio-nen auf Gebieten, in denen die deutsche Wirt-schaft nachhaltig stark ist, erfolgen k\u00f6nnten, oder  \nUnternehmensentwicklungen wie bei Google, Meta-Innovationen oder die Innovation des Innovationssystems selbst \u00a7  151\nApple usw. m\u00f6glich w\u00e4ren? Was w\u00e4re, wenn \nein b\u00f6rsennotiertes Industrieunternehmen zehn Jahre alle Gewinne in FuE investiert und nicht aussch\u00fcttet und dann den Durchbruch erzielt? W\u00e4re ein solches Unternehmen nicht zwischen-zeitig l\u00e4ngst von einem liquiden US-Konzern oder einem Staatsfonds gekauft und zerlegt worden? \nMeta-Innovationen oder die Innovation im \nInnovationssystem selbst\nAn dieser Stelle sei die Frage gestellt, ob und \nwie innovativ ein Innovationssystem selbst sein muss. Wann bzw. warum m\u00fcssen neue Elemen-te dazukommen und wie unterscheidet man bei diesen zwischen Innovationsinventionen (tolle neue Idee) und Innovationsinnovationen (tolle neue Idee, die auch wirkt)? K\u00f6nnte f\u00fcr ein nationales oder sektorales Inno-vationssystem dasselbe gelten wie f\u00fcr Unter -\nnehmen? Wer im Wettbewerb um zukunfts-f\u00e4hige Produkte, also innovative Produkte und Verfahren, stehen bleibt, wird auf Dauer nicht bestehen k\u00f6nnen. Innovationssysteme existieren, um diesen Wettstreit um Wettbe-werbsf\u00e4higkeit innerhalb und zwischen den Volkswirtschaften zu beeinflussen. Die Pro-dukte und M\u00e4rkte ver\u00e4nderten sich in den letzten Jahrzehnten mit zunehmender Ge-schwindigkeit und damit \u00e4ndern sich auch die f\u00fcr Unternehmen relevanten Erfolgsfaktoren. Innovationssysteme setzen an den Erfolgsfak-toren der Unternehmen an. Sie haben deshalb zum Beispiel Know-how \u00fcber Forschungsf\u00f6r -\nderung, Kontakte \u00fcber Netzwerke und \u00fcber Bildungsthemen die Leistungsf\u00e4higkeit der Belegschaften gef\u00f6rdert. Selten werden be-Abb. 1: Akteure des deutschen Forschungs- und Innovationssystems \nQuelle: Eigene Darstellung erg\u00e4nzt um Projekttr\u00e4ger nach Bundesministerium f\u00fcr Bildung und Forschung (2016): Bundesbericht Forschung und Innovation 2016, S. 53. www.bmbf.de/pub/Bufi_2016_Hauptband.pdf [Zugriff am 7.5.2018].\nBundesregierung\n16 LandesregierungenWissenschaftsrat\nEvaluation und \nBeratungGemeinsame \nWissenschafts-\nkonferenz  \nKoordinierung\n\u00d6ffentliche Forschung\n   Forschungsorganisationen  \n(MPG, Fraunhofer, HGF, \nLeibniz-Gemeinschaft)\nIndustrie-\nforschung\n AiF\n  Zuse-GemeinschaftIntermedi\u00e4re\n  Deutsche Forschungs- \ngemeinschaft (DFG)\n Stiftungen (\u00f6ffentliche und private)\n Stifterverband\n Verb\u00e4nde und KammernBeratung\n Expertenkommission\n  Forschung und  \nInnovation\n Hightech-Forum \n Innovationsdialog\nForschung und Entwicklung in der Wirtschaft\n Gro\u00dfe und multinationale Unternehmen\n Kleine und mittelst\u00e4ndische UnternehmenEurop\u00e4ische \nKommission\nProjekttr\u00e4ger\n Hochschulen\n Akademien\n Ressortforschung152 \nstehende Erfolgsfaktoren vollkommen obsolet, \nKnow-how beispielsweise ist schon immer und wird auch immer relevant sein. Deshalb sind neue Elemente im Innovationssystem auch meistens zus\u00e4tzlich zu bestehenden eingef\u00fchrt worden. Das System selbst muss sich also un-bedingt auch weiterentwickeln und offen f\u00fcr Meta-Innovationen sein. \nInnovative Unternehmen und deren Leitungen \nf\u00fchlen sich vielleicht manchmal Herstellern von Me-Too-Produkten \u00fcberlegen, nicht im-mer zu Recht. Wie ist es nun bei Me-Too-Pro-dukten in Innovationssystemen? Steuerliche Forschungsf\u00f6rderung oder eine deutsche DARPA\n3 w\u00e4ren vielleicht Me-Too-Produkte, \naber andererseits ist es keine schlechte Idee, eine Idee intelligent zu kopieren, wenn sie denn erfolgreich ist. Es muss also nicht im-mer unbedingt eine radikale Innovation sein. Hauptsache, die Methode erreicht ihr Ziel, manchmal auch dadurch, dass man sie weiter entwickelt oder verfeinert.\nUnternehmen und Volkswirtschaften m\u00fcssen \nalso immer wieder neue Wege suchen, An-s\u00e4tze der Konkurrenz, also anderer Volkswirt-schaften, pr\u00fcfen und ggf. verbessert \u00fcber -\nnehmen.\nSeit vielen Jahren wird eine steuerliche For -\nschungsf\u00f6rderung diskutiert und von ver -\nschiedenen Akteuren des Innovationssystems \ngefordert.\n4 Weiterhin wird seit dem Innovati-\nonsdialog 2017 eine Agentur f\u00fcr radikale In-novationen diskutiert, die manchmal auch als eine deutsche DARPA bezeichnet wird.\n5 Beides \nw\u00e4ren im weiteren Sinne Me-Too-Produkte, da die USA diese Instrumente schon einsetzen. Was spricht dagegen, es ihnen gleich zu tun? Nichts! Wenn eine Methode in einem ande-ren, vergleichbaren Umfeld gut funktioniert, darf, ja muss man sie kopieren, gerade auch dann, wenn es keine bessere Idee gibt. Wich-tig ist, dass man die Methode auf die eigenen Gegebenheiten anpasst und aus den Fehlern der anderen lernt. Dann wird aus dieser Idee, dieser Invention eine Innovation im Innovati-onssystem, da sie dann die  Wirkung erreicht, die intendiert ist.\nDeutschland hat sein Innovationssystem in \nden letzten Jahren mit der missionsorientier -\nten Hightech Strategie und der konzentrierten KMU-F\u00f6rderung etwa durch das ZIM-Programm des BMWi und die KMU-Innovativ-F\u00f6rderung des BMBF und zahlreiche weitere Instrumente der Ministerien bereits in seiner strategischen Ausrichtung innovativ weiterentwickelt und die positive wirtschaftliche Entwicklung ist si-cherlich auch eine Folge des Innovationssys-tems und seiner Innovationsf\u00e4higkeit. Mit einer Agentur f\u00fcr radikale Innovationen w\u00fcrde nun eine Weiterentwicklung mit einem neuen Teil-nehmer erfolgen.\nDie F\u00f6rderung von Innovationen hat in Deutsch-\nland eine lange Tradition. Mit den Ma\u00dfnahmen des damaligen BMFT Mitte der 70er Jahre wur -\nde der Fokus auf die Unternehmen und dort vor allem auf die KMU gelenkt. Eine Verbundpro-jektf\u00f6rderung, bei denen etwa KMU, GU, Uni-versit\u00e4ten und au\u00dferuniversit\u00e4re Forschungs-einrichtungen zusammenarbeiten, ist seit vielen Jahren ein erfolgreich erprobtes Instrument.\nDie anderen Volkswirtschaften bleiben eben-\nfalls nicht stehen und entwickeln ihre Innova-tionssysteme weiter. Oft finden dazu \u201eFact Fin-ding Missions\u201c nach Deutschland statt. Kanada hat sich beispielsweise f\u00fcr ZIM interessiert, wohl auch, weil man von der eigenen steuerlichen FuE F\u00f6rderung nicht nur begeistert ist (angeb-lich war die steuerliche FuE z. B. in Kanada teil-weise sehr aufw\u00e4ndig in der Administration).\nEin Aspekt, der zu unserem nationalen Innovati-\nonssystem aktuell diskutiert wird, ist die Forde-rung nach disruptiven Innovationen verbunden mit der Forderung, b\u00fcrokratischen Aufwand zu reduzieren. Beide Aspekte sind Grund genug, \u00fcber eine Weiterentwicklung des Innovations-systems nachzudenken: Das passiert auch bei vielen Akteuren und es betrifft ein Unterneh-men, das wie die VDI/VDE-IT viele Projekttr\u00e4ger -\nschaften betreut, insbesondere.Meta-Innovationen oder die Innovation des Innovationssystems selbst \u00a7  153\nDisruptive Innovationen \u2013 \nWorum geht es?\nDisruptive Innovationen aus den USA haben \ndeutsche Unternehmen, und nicht nur diese, in den letzten Jahren vor erhebliche Herausforde-rungen gestellt. Plattformen wie Amazon, Fa-cebook und Google, Hersteller wie Apple und Microsoft \u00e4ndern mit ihren Gesch\u00e4ftsmodellen die Spielregeln auf den M\u00e4rkten drastisch. Es ist allgemein bekannt, dass es aus Deutschland bzw. Europa keine vergleichbaren Impulse gibt. Mit ihren zum Teil extrem gro\u00dfen Liquidit\u00e4ts-reserven greifen diese globalen Player Unter -\nnehmen anderer Branchen in Deutschland an, etwa Amazon deutsche Handelsunternehmen oder Tesla deutsche Automobilhersteller. Ob sie damit langfristig erfolgreich sein werden, ist noch nicht entschieden. Allerdings zeigt die Er -\nfahrung, dass, wenn solche Angriffe erfolgreich sind, den bisherigen Anbietern in den betroffe-nen Branchen das Aus oder eine Weiterexistenz als Nischenanbieter, wie z. B. der Uhren- und Fotoindustrie nach dem Mikroelektronikschock der 70er Jahre, droht. \nDisruptiv bedeutet \u201est\u00f6rend\u201c oder \u201eunterbre-\nchend\u201c. Und genau das sind diese Innovatio-nen f\u00fcr die bisherigen Anbieter in den M\u00e4rkten. Wenn solche disruptiven oder radikalen Inno-vationen nicht auch aus Deutschland kommen, ist das eindeutig eine Herausforderung f\u00fcr das nationale Innovationssystem in Deutschland insgesamt. \nDabei sollte man die Frage, ob diese Unterneh-\nmen mit ihren radikalen Innovationen volks-wirtschaftlich und gesellschaftlich positiv oder negativ zu bewerten sind, nicht vorschnell be-antworten. Die wesentliche Wertsch\u00f6pfung zum Beispiel von Apple findet offensichtlich nicht in den USA statt und auch der Einzelhan-del in den USA leidet unter Amazon.\nRadikale Innovationen kommen mehrheitlich \nnicht von \u201ealten Bekannten\u201c der Branchen, sondern von bis dato unbekannten Akteuren. Die erfolgreichste Suchmaschine des Internets kam nicht von Microsoft, das beste Smartphone nicht von Nokia und der gr\u00f6\u00dfte Onlinehandel ist nicht von Sears oder der Metro aufgebaut worden. Es ist vielleicht gewagt zu behaupten, dass radikale Innovationen oft wehtun und manchmal an der Grenze der Legalit\u00e4t stattfin-den. Andererseits sind Google und Facebook wirtschaftlich erfolgreich, seit sie die Nutzerda-ten unter Vernachl\u00e4ssigung des Datenschutzes konsequent ausbeuten. Auch die Bedrohung des Einzelhandels durch Amazon k\u00f6nnte noch in mancherlei Hinsicht schmerzhafte Folgen ha-ben.\nWas macht die DARPA \naus? Was kann man von ihr lernen?\nAlle disruptiven Innovationen der oben er -\nw\u00e4hnten Unternehmen nutzten konsequent \ndie M\u00f6glichkeiten neuer Technologien und haben diese zum Teil auch weiterentwickelt. Aber eine intensive FuE-T\u00e4tigkeit wurde von diesen Akteuren im Rahmen ihrer Startphase nicht durchgef\u00fchrt. In der F\u00f6rderung disrupti-ver Innovationen durch die DARPA ist dieser Aspekt durchaus zu sehen. Gew\u00fcnscht wer -\nden Ergebnisse, die schnell verf\u00fcgbar und milit\u00e4risch nutzbar sind. Der DARPA-Challen-ge-Ansatz muss, im Unterschied zur DARPA finanzierten Forschung, m\u00f6glicherweise eher als l\u00f6sungsorientiert denn als technologieori-entiert angesehen werden. Will man disruptive Innovationen ansto\u00dfen, k\u00f6nnte das dennoch ein interessanter Ansatz sein.\nWenn man das deutsche oder europ\u00e4ische In-\nnovationssystem mit Blick auf die radikalen Innovationen weiterentwickeln will, ist eine Me-Too-Strategie, die sich ein erfolgreiches Vorbild wie die DARPA nimmt, sicherlich be-denkenswert. Die DARPA beansprucht auf ihrer 154 \nWebsite in der Tat einige sehr wesentliche Inno-\nvationen als Ergebnis ihres Wirkens.6\nUm Ans\u00e4tze von anderen Innovationssyste-men zu \u00fcbertragen, ist die Analyse des Kon-textes von gro\u00dfer Bedeutung. Die DARPA hat folgendes Mission Statement: \u201eFor sixty ye-ars, DARPA has held to a singular and endu-ring mission: to make pivotal investments in breakthrough technologies for national secu-rity\u201c.\n7 \u00dcber ihre Investitionsstrategie schreibt \nsie: \u201eDARPA\u2019s investment strategy begins with a portfolio approach. Reaching for outsized impact means taking on risk, and high risk in pursuit of high payoff is a hallmark of DAR-PA\u2019s programs\u201c.\n8 Der entscheidende Aspekt \nist die Erzielung hoher Gewinne bei hohem Risiko, gleichzeitig will man einen Beitrag f\u00fcr die nationale Sicherheit leisten. In diesem Zusammenhang wird auch der dual-use An-satz diskutiert, also die milit\u00e4rische und zivile Nutzung von Forschungsergebnissen. Wenn man die milit\u00e4rische Nutzung als Option ausschlie\u00dft, wird man sich ein anderes Lead-kundenmodell \u00fcberlegen m\u00fcssen. Sicherheit k\u00f6nnte auch ohne milit\u00e4rische Auspr\u00e4gung ein Feld sein.\nDie DARPA bezeichnet ihre Forschung als eine \n\u201eanwendungs- oder nutzerinspirierte Grund-lagenforschung\u201c. Die Dauer der einzelnen Forschungsaktivit\u00e4ten liegt zwischen f\u00fcnf und zehn Jahren. In dieser Zeit kommt es regelm\u00e4-\u00dfig zu einer Rotation der Verantwortlichen in den Forschungsvorhaben. Diese Personalrota-tion wird bei der DARPA als ein wesentliches Element angesehen.\nDie aktuelle DARPA-Challenge \u201eThe Spectrum \nCollaboration Challenge (SC2)\u201c passt sehr gut in dieses Schema.\n9 Der Sieger wird m\u00f6glicher -\nweise in der Lage sein, eine intelligente Nut-zung vorhandener Frequenzspektren mit Hilfe von k\u00fcnstlicher Intelligenz zu realisieren. Das k\u00f6nnte gro\u00dfe Folgen f\u00fcr die Dominanz eines solchen Unternehmens in einer digitalisierten Welt haben.Aspekte bei der Initiierung disruptiver \nInnovationen\nWas bedeutet dies f\u00fcr das deutsche Innovati-\nonssystem? Innovationen finden in der Wirt-schaft, in Unternehmen und auf M\u00e4rkten statt. Der Staat kann sie nicht fordern, ja vielleicht nur schwer f\u00f6rdern. Schon in fr\u00fcheren Jahren wirk-te die Forderung: \u201eEs muss mehr innoviert wer -\nden!\u201c auf den einen oder anderen abgehoben. Nun also die Forderung: Es muss mehr und vor allem disruptiv innoviert werden.\nWas ist die Rolle des Staates? Marianna Maz-\nzucato hat zur Rolle des Staates ein interessan-tes Buch geschrieben \u201eThe Entrepreneurial Sta-te\u201c. Der deutsche Titel lautet: \u201eDas Kapital des Staates\u201c. Offensichtlich tut sich in Deutschland selbst ein Verlag schwer, den Staat als unter -\nnehmerisch zu sehen. Mazzucato schreibt vom Staat als Unternehmer, der hohe Risiken ein-geht und die Grundlagen f\u00fcr die wesentlichen Innovationen des 20. Jahrhunderts geschaffen hat. Zu Recht weist sie darauf hin, dass von der Eisenbahn \u00fcber das Internet bis hin zu Phar -\nma- und Nanoforschung der Staat die riskanten Ausgaben f\u00fcr die Forschung und die Ausbil-dung \u00fcbernommen hat. Das gilt sicher auch f\u00fcr Deutschland. Nur welche Forschungsergebnisse dann von Unternehmen zu welchem Zeitpunkt aufgegriffen werden, darauf hat der Staat we-nig Einfluss. Manche Ergebnisse werden nie erfolgreich aufgegriffen (z. B. Transrapid). Hier k\u00f6nnte ein der DARPA-Challenge vergleichba-res Konzept greifen.\nDieses F\u00f6rderformat der DARPA, die DAR-\nPA-Challenge, ist vermutlich ihr bekanntestes, wenngleich hier nur ein Bruchteil des Budgets verwendet wird. Das Interessante bei einem solchen Wettbewerb ist, dass nicht die For -\nschungsthemen im Vordergrund stehen, son-dern die sehr pr\u00e4zise Formulierung einer sehr ambitionierten Aufgabenstellung. Die DARPA wird sich zu diesem Zeitpunkt kaum mit der Fra-ge befassen, wer die Projekte durchf\u00fchren soll, noch befasst sie sich mit Details der Umsetzung (analog verf\u00e4hrt das BMBF bei seinen missions-orientierten Ma\u00dfnahmen). Ausgelobt wird von Meta-Innovationen oder die Innovation des Innovationssystems selbst \u00a7  155\nder DARPA lediglich ein h\u00f6heres Preisgeld, das \nnach einem life-contest vergeben wird.\nZu gestalten ist jedoch auch eine Strategie oder \nMethode, wie die Gewinner dann motiviert werden, m\u00f6glichst in Deutschland eine Innova-tion umsetzen.\nW\u00e4re ein Elektroauto, das einen vergleichbaren \nPreis wie ein Fahrzeug mit Verbrennungsmo-tor und vergleichbare Leistungen h\u00e4tte, eine disruptive Innovation? Vermutlich schon. Tesla versucht dies. Die wirtschaftlichen und techni-schen Erfolge \u00fcberzeugen jedoch nicht wirk-lich. Bislang ist mit gro\u00dfem unternehmerischen Mut viel Geld verbrannt worden. Dennoch wird dieses Experiment in den USA und nicht im Autoland Deutschland gewagt. Falls Tesla der Durchbruch gelingt, k\u00f6nnte die deutsche Au-tomobilindustrie vor einem \u00e4hnlichen Problem stehen, wie die Kamera- und Uhrenindustrie in den 70er Jahren. Falls nicht, bleibt alles beim Alten und in den USA haben einige Investoren viel Geld verloren. Allerdings w\u00fcrde man ei-nem deutschen Autobauer einen Wagen von der eingeschr\u00e4nkten Zuverl\u00e4ssigkeit eines Tesla wohl auch nachhaltig ver\u00fcbeln. \nAuch in den USA sind Investitionen in innovative \nTechnologieunternehmen \u00fcbrigens nicht durch-g\u00e4ngig und schon immer en vogue gewesen. Warren Buffet h\u00e4tte die Chance gehabt bei der Gr\u00fcndung von Intel, als eine vergleichsweise geringe Investition von 2,5 Mio. Dollar ben\u00f6tigt wurde, mit einzusteigen. Er tat es nicht, weil er Technologieunternehmen durchaus misstraute, wie Alice Schroeder in ihrer Biographie \u00fcber Buffet schreibt.\n10 Es scheint daher auf jeden Fall \nrichtig, wenn der Staat nicht aufh\u00f6rt, in riskante Projekte zu investieren, wenn der (volks-)wirt-schaftliche oder gesellschaftliche Nutzen im Er -\nfolgsfall nur gro\u00df genug ist. Jede H\u00e4me im Fall des Misserfolgs w\u00e4re jedenfalls fehl am Platze. \nWichtig, auch wenn es ordnungspolitisch schwie-  \nrig ist, bleibt allerdings die Verwertungsfrage. \nForschungsergebnisse, die mit deutschen Steuer-  \ngeldern erzielt wurden, sollten auch zum Nutzen  der deutschen Volkswirtschaft und dann der euro-  \np\u00e4ischen verwertet werden \u2013 und daf\u00fcr braucht es Unternehmer im eigenen Land. \nWenn man einen Projekttr\u00e4ger leitet, steht \nman diesen Gedanken nachdenklich gegen-\u00fcber, denn Projekttr\u00e4ger verdienen ihr Geld bisher nicht mit einer DARPA. Auf der ande-ren Seite gilt, wer Innovation predigt, darf sich selbst nicht wegducken. Nur weil ein anderes Gesch\u00e4ftsmodell das eigene beeintr\u00e4chtigt, macht Ablehnung keinen Sinn. Das gilt f\u00fcr die Industrie wie f\u00fcr alle Partner im Innovations-system. \nWas k\u00f6nnten wichtige Erfolgskriterien sein? \nKann es disruptive Innovationen mit alten Be-kannten in Industrie und Forschung geben, oder erfordern neue L\u00f6sungen neue Player und wie motiviert man diese? Zu diesen Fragen k\u00f6nnten Projekttr\u00e4ger einiges beitragen, auch wenn sie m\u00f6glicherweise nicht unmittelbar Teil der L\u00f6sung sind. Aber: Wer innovativ sein will, muss sich auch neben sein eigenes Gesch\u00e4fts-modell stellen k\u00f6nnen oder innovative Ans\u00e4tze als Chance zur Erweiterung seiner Gesch\u00e4ftst\u00e4-tigkeit verstehen.\nMindset f\u00fcr die Akteure im Innovationssystem\nKeine Angst vor Misserfolgen! Wenn das Er -\ngebnis disruptiv sein soll, dann darf die Mess-latte der Aufgabenstellung nicht niedrig liegen und dann ist Scheitern eine Option und kein Problem. Wenn die Aufgabe sehr herausfor -\ndernd ist, muss man neue Player zulassen, auch wenn sie das Risiko scheinbar erh\u00f6hen. Die Aufgabe, bessere Schreibmaschinen zu bauen, wurde auch nicht von der Feinmecha-nik in Verbindung mit Schreibmaschinenher -\nstellern gel\u00f6st.\nAuch wenn die Forschungsarbeiten viele Jahre \nin Anspruch nehmen k\u00f6nnen, muss Zeitdruck aufgebaut werden \u2013 sonst fehlt die Dynamik. Deshalb sollte man auch keine neuen Struktu-ren schaffen, die den Antrieb haben, sich zu verselbst\u00e4ndigen und Dauerarbeitsverh\u00e4ltnisse bereitzustellen.156 \nGovernance und Rahmenbedingungen f\u00fcr \nFuE-Projekte\nGovernance stellt den Ordnungsrahmen f\u00fcr die \nLeitung und \u00dcberwachung von Systemen dar. Sollen FuE-Projekte mit dem Ziel, disruptive In-novationen hervorzubringen, vorangetrieben werden, sollte man \u00fcber einige Spielregeln nachdenken. \nDie verantwortlichen Personen m\u00fcssen f\u00fcr die \nResultate verantwortlich sein. Eine hohe Fle-xibilit\u00e4t in der Vorgehensweise muss m\u00f6glich sein: Jeder Ansatz, der sich als Irrweg erweist, muss sofort gestoppt werden k\u00f6nnen. Keine Partnereinrichtung und keine Person hat einen Anspruch, bis zum Schluss der Laufzeit dabei zu bleiben und das Budget auszusch\u00f6pfen. Die Mittel d\u00fcrfen nat\u00fcrlich nur f\u00fcr das Vorhaben aufgewendet werden, ob dies aber in Unter -\nauftr\u00e4gen, Geh\u00e4ltern, Investitionen in Anlagen oder Dienstreisen erfolgt, sollte nicht einzeln genehmigt werden m\u00fcssen. Das stellt erhebli-che Herausforderungen an die Art der Finanzie-rung.\nDie Steuerung der Forschungsarbeit sollte \u00fcber \nMeilensteine erfolgen. Diese m\u00fcssen so defi-niert sein, dass durch sie nicht das Controlling der Projektf\u00f6rderung durch die Hintert\u00fcr zu-r\u00fcckkehrt. Meilensteine sind als Zwischenresul-tate zu verstehen, die das Vertrauen st\u00e4rken, dass das Ziel erreicht wird. Wenn eben dieses Vertrauen bei einem inhaltlich kompetenten Kontrollgremium verlorengeht, muss ein Ab-bruch jederzeit m\u00f6glich sein. Ein solcher Ab-bruch sollte in keinem Fall als Versagen der Beteiligten gewertet, aber gut dokumentiert werden. Wichtig ist, dass auch aus Fehlversu-chen gelernt wird.\nRegeln f\u00fcr die Finanzierung\nDie Finanzierung von Forschung f\u00fcr disruptive Innovationen darf keine klassische Projektf\u00f6r -\nderung sein! Vielmehr muss dies als ein Invest-ment eines unternehmerisch handelnden Staa-tes verstanden werden. Ein Investment erfolgt immer unter Risiko. Letztlich ist es im positiven Sinne eine Wette auf die Zukunft. Im Risiko liegt allerdings eine gro\u00dfe \u00dcbereinstimmung mit der Projektf\u00f6rderung, die ebenfalls Vorhaben mit erh\u00f6htem Risiko finanziert.\nEs kann deshalb auch keine Aufteilung des \nBudgets nach Jahren oder Kostenarten geben. Richtig ist: Wer das Geld des Steuerzahlers verwenden m\u00f6chte, muss dar\u00fcber Rechen-schaft ablegen. Das N\u00e4here regelt etwa die Bundeshaushaltsordnung. Auch an dieser Stel-le wird man neue Wege gehen m\u00fcssen, sonst wird zu viel Zeit mit der Rechtfertigung von Entscheidungen verbracht, oder \u2013 schlimmer noch \u2013 Entscheidungen werden nicht getrof-fen. Hier k\u00f6nnte man sich eine permanente Kostenevaluation vorstellen, indem ein Dritter eine st\u00e4ndige Rechnungspr\u00fcfung in Form einer Begleitung vornimmt. Gepr\u00fcft wird nur, ob die Mittel f\u00fcr Personal eingesetzt werden, das an der Forschung beteiligt ist, und die Sachmittel f\u00fcr die Forschung verwendet werden. Vermut-lich wird man auch die Regeln der \u00f6ffentlichen Beschaffung nicht anwenden k\u00f6nnen. Es liegt viel in der Verantwortung der Forschenden. Die Details dieser Regeln m\u00fcssen sorgf\u00e4ltig ab-gestimmt werden und die aktuelle Rechtslage m\u00fcsste \u00fcberpr\u00fcft werden. Aber so ist das bei disruptiven Innovationen: Sie st\u00f6ren und sie brechen bestehende Regeln \u2013 schon in der Vor -\nbereitung!\nKommunikation als Teil der Herausforde-\nrung\nTransparenz ist bei einem solchen Vorgehen \nvon hoher Bedeutung, allerdings ohne wich-tige Geheimnisse vor der Zeit zu offenbaren. Die \u00d6ffentlichkeit als Investor hat ein Recht auf Informationen \u00fcber die Vorhaben und den gew\u00e4hlten Weg. Unternehmen, die mit den Ergebnissen sp\u00e4ter eine disruptive Innovation gestalten sollen, m\u00fcssen permanent \u00fcber den Fortschritt informiert werden und ggf. zur Mit-arbeit eingeladen werden. \nDie Kommunikation zu solchen Vorhaben muss \nsich als spannende Geschichte darstellen, um die Mitte der Gesellschaft zu erreichen und eine positive Grundhaltung zu bef\u00f6rdern. Dies Meta-Innovationen oder die Innovation des Innovationssystems selbst \u00a7  157\nist durchaus eine Aufgabe f\u00fcr die Verantwortli-\nchen der Forschungsarbeit.\nFazit\nGeld ist nicht alles! Die Bedingungen f\u00fcr seine Verwendung entscheiden \u00fcber seinen Wert. Der Trade-off zwischen dem Erfordernis zur Kontrolle der Vorgehensweise und der erforder -\nlichen schnellen Flexibilit\u00e4t f\u00fcr die Wirksamkeit eines Investments ist die Herausforderung. Wenn ein Innovationssystem disruptive Inno-vationen beg\u00fcnstigen soll, muss es sich selbst zum Teil neu erfinden. Das bedeutet eine sehr herausfordernde Aufgabe f\u00fcr die Gestalter in Legislative, Exekutive und f\u00fcr Dienstleister, die nicht nur an die Akquisition neuer Auftr\u00e4ge denken, sondern an das gro\u00dfe Ziel. Die VDI/VDE-IT steht daf\u00fcr seit ihrer Gr\u00fcndung zur Ver -\nf\u00fcgung.\n1 F. A. Brockhaus (1970): Brockhaus Studienausgabe. Wiesbaden, Bd. 10, S. 555.\n2 OECD (1999): Managing National Innovation Systems, S. 23. http://echo.iat.sfu.ca/library/oecd99_managing_National_IS.pdf \n \n[Zugriff am 7.5.2018].\n3 Defense Advanced Research Projects Agency\n4 z. B. EFI-Expertenkommission Forschung und Innovation (2008): \n \nEFI-Gutachten. Berlin: EFI, S. 35. www.e-fi.de/fileadmin/Gutachten_2008/EFI_Gutachten_2008.pdf [Zugriff 7.5.2018].\n5 EFI \u2013 Expertenkommission Forschung und Innovation (2018): Gutachten zu Forschung, Innovation und technologischer Leistungsf\u00e4higkeit \n Deutschlands 2018, Berlin: EFI, S. 62. www.e-fi.de/fileadmin/Gutachten_2018/EFI_Gutachten_2018.pdf [Zugriff am 7.5.2018].\n6 www.darpa.mil/Timeline/index.html\n7 www.darpa.mil/about-us/about-darpa\n8 www.darpa.mil/our-research\n9 www.darpa.mil/news-events/spectrum-collaboration-challenge-sc2\n10 Schroeder, Alice (2008): Warren Buffet: Das Leben ist wie ein Schneeball. M\u00fcnchen. vgl. S. 430.158 \nX-Strahlen: Wie die Entdeckung  \nWilhelm Conrad R\u00f6ntgens die  moderne Medizin pr\u00e4gte\nStephan Krumm\nDie Entdeckung der R\u00f6ntgenstrahlung bzw. \nX-Strahlen im Jahr 1895 markierte in vielerlei Hinsicht den Beginn einer bemerkenswerten Entwicklung: Die bewusste Nicht-Patentie-rung der Technologie, die rasante Verbreitung und Kommerzialisierung, die sorglose Nutzung ohne Folgenabsch\u00e4tzung und nicht zuletzt der ma\u00dfgebliche Einfluss auf die Diagnostik und medizinische Behandlung waren bis zu diesem Zeitpunkt f\u00fcr die Medizintechnik beispiellos. \nErstmals war es \u00c4rztinnen und \u00c4rzten m\u00f6glich, \nohne invasive Ma\u00dfnahmen das Innere des le-benden Menschen umfassend in die Diagnose einzubeziehen. Sowohl durch die Weiterent-wicklung der R\u00f6ntgentechnik selbst wie bei-spielsweise die Computertomographie als auch durch \u00e4u\u00dfere technologische Fortschritte wur -\nden Hersteller und Anwender immer wieder vor neue Herausforderungen gestellt, etwa durch Digitalisierung und Vernetzung. Dabei haben die heute in der radiologischen Diagnostik ein-gesetzten Verfahren nur noch das physikalische Grundprinzip mit den ersten R\u00f6ntgenger\u00e4ten gemein. Zunehmend erreichen auch Entwick-lungen aus dem Bereich der k\u00fcnstlichen Intel-ligenz die Radiologie. \nDer Beitrag zeigt anhand der R\u00f6ntgentechnik, \nwie sich auch vermeintlich erprobte Technolo-gien weiterentwickeln und Hersteller Innovatio-nen in Produkte integrieren m\u00fcssen, um wett-bewerbsf\u00e4hig zu bleiben. Zugleich sollen die Gefahren zu schneller und unbedachter Tech-nikadaption und die soziotechnischen Folgen moderner Bildgebung auf die Behandlung von Patientinnen und Patienten beleuchtet werden. \nDie Entdeckung der X-Strahlen: Revolution \nper Zufall \nAm 8. November 1895 machte Wilhelm Con-\nrad R\u00f6ntgen in seinem Labor an der Universit\u00e4t W\u00fcrzburg die Entdeckung, die \u2013 zumindest im deutschsprachigen Raum \u2013 seitdem seinen Na-men tr\u00e4gt. Per Zufall entdeckte er beim Experi-mentieren mit Kathodenstrahlr\u00f6hren die sp\u00e4ter auf Vorschlag eines Kollegen nach ihm benann-te R\u00f6ntgenstrahlung.\n1 Es folgen arbeitsreiche \nWochen mit zahlreichen Versuchen. Noch im gleichen Jahr fertigte er das erste R\u00f6ntgenbild der Hand seiner Ehefrau Bertha an. Es ist die Geburtsstunde der Radiologie. Bereits am 6. Januar 1896 erscheint in der Londoner Tages-zeitung \u201eThe Daily Chronicle\u201c eine kurze Notiz von dessen Wiener Korrespondenten mit dem Titel \u201eRemarkable Scientific Discovery\u201c, in dem die Eigenschaften und die Funktionsweise des Versuchsaufbaus von R\u00f6ntgen beschrieben werden. Wie schnell sich die Nachricht der Entdeckung verbreitete, zeigt sich auch daran, dass R\u00f6ntgen bereits am Abend des 12. Januar 1896 eine Vorf\u00fchrung seiner Entdeckung vor der kaiserlichen Familie, Vertretern des Hoch-adels und ranghohen Milit\u00e4rs im Schloss zu Berlin abhielt. Das Potenzial der Entdeckung im medizinischen Bereich wurde schon sehr fr\u00fch erkannt.\n2\nDie ersten medizinisch-wissenschaftlichen Mel-dungen zur Entdeckung wurden bereits wenig \n40 JahreX-Strahlen: Wie die Entdeckung Wilhelm Conrad R\u00f6ntgens die moderne Medizin pr\u00e4gte \u00a7 159\nsp\u00e4ter in der \u201eDeutschen medicinischen Wo-\nchenschrift\u201c ver\u00f6ffentlicht. Im September 1897 erschien gar die erste deutschsprachige radio-logische Fachzeitschrift \u201eFortschritte auf dem Gebiet der R\u00f6ntgenstrahlen\u201c.\n3 Im Jahr 1896 \nbegannen die Firmen Siemens & Halske sowie Reiniger, Gebbert & Schall (sp\u00e4ter in Siemens aufgegangen) die Fabrikation von R\u00f6ntgenr\u00f6h-ren und -apparaten.\n4\nAufgrund der wenige Jahrzehnte zuvor erstma-lig eingerichteten interkontinentalen Telegra-fenleitungen verbreitete sich die Entdeckung innerhalb kurzer Zeit \u00fcber den Globus. Gleich-zeitig verzichtete R\u00f6ntgen darauf, die Ergebnis-se seiner Forschungen zur\u00fcck zu halten oder patentieren zu lassen. Sein Ziel war es, den Menschen die Vorteile der Technologie m\u00f6g-lichst schnell zug\u00e4nglich zu machen, sodass diese Nutzen stiften konnte. Auch aufgrund des vergleichsweise simplen Versuchsaufbaus be-gannen weltweit zeitnah Forschungsaktivit\u00e4ten im Bereich der R\u00f6ntgentechnik. R\u00f6ntgen selbst wandte sich vergleichsweise schnell anderen Forschungsthemen zu.\n5\nDie fr\u00fche Euphorie rund um die Technologie f\u00fchrte allerdings dazu, dass Betrachtungen der Sicherheitsrisiken zun\u00e4chst kaum eine Rolle spielten. Im Jahr 1896 wurden zwar die ersten Strahlensch\u00e4den und Nebenwirkungen doku-mentiert, wie lokaler Haarausfall, Hautr\u00f6tung, Dermatitis, die Langzeitfolgen f\u00fcr die Gesund-heit wurden jedoch lange Zeit vernachl\u00e4ssigt.\n6 \nFr\u00fche R\u00f6ntgenger\u00e4te ben\u00f6tigten bei \u00e4hnlichen Belichtungsverh\u00e4ltnissen im Vergleich zu mo-dernen Ger\u00e4ten bis zu 1.500 Mal mehr Strah-lung bei einer Belichtungsdauer von ca. 90 Minuten. Bei heutigen Ger\u00e4ten liegt diese bei wenigen Millisekunden.\n7\nWenngleich die medizinische Anwendung be-reits fr\u00fch im Fokus der Entwicklung lag, wurde das Potenzial der Technologie auch f\u00fcr weitere Felder erkannt, wie etwa zerst\u00f6rungsfreie Ma-terialpr\u00fcfung oder Sicherheitstechnik. \nDie Reifung der R\u00f6ntgentechnik\nDie Entdeckung und Nutzung der R\u00f6ntgen-strahlung kann ohne Zweifel als eine der gr\u00f6\u00df-ten medizintechnischen (Sprung-)Innovationen bezeichnet werden und hat die Behandlung von Patientinnen und Patienten nachhaltig ver\u00e4ndert. Vor dieser Entwicklung bestand f\u00fcr \u00c4rztinnen und \u00c4rzte keine umfassende M\u00f6g-lichkeit, erkrankte Menschen ohne sichtbare \u00e4u\u00dfere Beschwerden ohne invasive Verfahren zu untersuchen und die Beschwerden entspre-chend ad\u00e4quat zu diagnostizieren.\n8\nNach der Verbreitung der Entdeckung wurden in rasantem Tempo technische Verbesserungen, wie die Nutzung von elektrolytischen Stromunter -\nbrechern oder die Blendentechnik eingef\u00fchrt\n9, \ndie auch dazu beitrugen, dass die Technologie w\u00e4hrend des 1. Weltkriegs fl\u00e4chendeckend ein-gesetzt wurde.\n10 Erstmals konnten Schussfraktu-\nren und Stecksch\u00fcsse sichtbar gemacht werden. Anschlie\u00dfende Entwicklungen wie die einfach zu transportierende R\u00f6ntgenkugel oder Bildverst\u00e4r -\nker trugen zur raschen Verbreitung bei.\n11\nAbb. 1: Fr\u00fche R\u00f6ntgenaufnahme einer menschlichen Hand \nmit Ring160 \nDie R\u00f6ntgentechnik bildete die Grundlage f\u00fcr \ndie moderne diagnostische Bildgebung. So wurden Anfang der 1970er Jahre die ersten Computertomographen (CT) entwickelt. Die ersten kommerziellen Ger\u00e4te wurden 1972 auf dem Markt eingef\u00fchrt.\n12 Auch diese Technolo-\ngie fand in Krankenh\u00e4usern innerhalb weniger Jahre eine starke Verbreitung. Herk\u00f6mmliches Projektionsr\u00f6ntgen f\u00fchrt dazu, dass sogenann-te Schattenbilder entstehen. Hierbei verdecken sich Organe gegenseitig und Strukturen sind nicht eindeutig zuordbar.\n13 Dieses Problem um-\ngehen CT durch die Erstellung von Schnittbil-dern.\nEbenfalls Anfang der 1970er Jahre startete der \n\u00e4hnlich erfolgreiche Siegeszug der Magnetre-sonanztomographie (MRT). Hierbei wird auf die Nutzung von Gesundheit gef\u00e4hrdender R\u00f6ntgenstrahlung oder anderer ionisierender Strahlung verzichtet und mit starken elektroma-gnetischen Feldern gearbeitet. Somit basiert die Technologie zwar auf einem grunds\u00e4tzlich an-deren physikalischen Prinzip, ist jedoch f\u00fcr die diagnostische Bildgebung einer der wichtigs-ten Meilensteine und wird daher im Folgenden ebenfalls ber\u00fccksichtigt. Wenngleich CT und MRT wesentlich komplexere technische Ver -\nfahren und Konstruktionen zugrunde liegen, konnten sich auch diese Technologien schnell im Versorgungsgeschehen durchsetzen.\nW\u00e4hrend der letzten Jahrzehnte standen die \nbildgebende Diagnostik im Allgemeinen und die R\u00f6ntgentechnik im Speziellen mehreren gro\u00dfen technischen Herausforderungen gegen-\u00fcber,  beispielsweise Reduktion der Strahlenex-position und Kontrasterh\u00f6hung der Aufnah-men. Eine der bisher vermutlich folgenreichsten \u00c4nderungen bestand in der Digitalisierung der R\u00f6ntgentechnik. Zwar war die Nutzung von Computern bereits Grundvoraussetzung f\u00fcr die CT-Technologie, die \u00dcbertragung auf das klas-sische Projektionsr\u00f6ntgen sowie die entspre-chende fl\u00e4chendeckende Kommerzialisierung fanden allerdings erst Jahre sp\u00e4ter statt. \nDie bildgebende Diagnostik war damit ein Aus-\ngangspunkt f\u00fcr die Digitalisierung der Doku-mentation des gesamten Krankenhauses. W\u00e4h-rend analoge R\u00f6ntgenaufnahmen in langen Regalen archiviert wurden, mussten f\u00fcr die di-gitalen Informationen ad\u00e4quate Speicherm\u00f6g-lichkeiten gefunden werden. Dies f\u00fchrte zur Etablierung von R\u00f6ntgeninformationssystemen (RIS) und digitalen Bildarchivierungssystemen (PACS: Picture Archiving and Communication System).\n16\nWas ist ein CT? Was ist ein MRT?\nDie Computertomographie bzw. Computertomografie, Abk\u00fcrzung CT, ist ein bildge-bendes Verfahren in der Radiologie. Mittels computergest\u00fctzten Berechnungen werden bei der CT auf Basis der Absorptionswerte von durch den K\u00f6rper tretenden R\u00f6ntgensi-gnalen Schnittbilder erzeugt. Durch die rechnerbasierte Auswertung einer Vielzahl von R\u00f6ntgenbildern, die aus verschiedenen Richtungen aufgenommen werden, k\u00f6nnen Schnittbilder rekonstruiert und sogar 3D-Modelle erzeugt werden.\n14\nDie Magnetresonanztomographie, abgek\u00fcrzt MRT oder MR, ist ebenfalls ein bildge-bendes Verfahren. Das grundlegende Funktionsprinzip basiert auf dem physikalischen Aspekt der Kernspinresonanz. Mittels der MRT lassen sich ebenfalls Schnittbilder und 3D-Modelle erzeugen. MRT bietet insbesondere bei weichen K\u00f6rperstrukturen einen besseren Kontrast, wobei Patientinnen und Patienten keiner ionisierenden Strahlung ausgesetzt sind.\n15iX-Strahlen: Wie die Entdeckung Wilhelm Conrad R\u00f6ntgens die moderne Medizin pr\u00e4gte \u00a7 161\nRadiologie an Dr. Watson: Bitte \u00fcbernehmen  \nSie!\nDie bildgebende Diagnostik war und ist auch in \neinem weiteren technologischen Trend ein Vor -\nreiter: der Anwendung K\u00fcnstlicher Intelligenz (KI). Bereits in den 1970er Jahren wurden erste Publikationen zum Einsatz von CAD-Systemen ver\u00f6ffentlicht (CAD: computer-aided detection oder computer aided diagnosis). Diese unterst\u00fct-zen die \u00c4rztinnen und \u00c4rzte bei der Befundung von digitalen gespeicherten Aufnahmen. Insbe-sondere im Bereich der CT- und MRT-Auswer -\ntung ist diese Unterst\u00fctzung notwendig, da die Bilddaten einer Untersuchung mehrere Tausend Einzelaufnahmen umfassen k\u00f6nnen. Die manu-elle Befundung durch das Fachpersonal w\u00e4re nicht nur sehr zeitaufw\u00e4ndig, sondern erfordert gleichzeitig ein hohes Ma\u00df an Konzentration. CAD-Systeme dienen der Analyse der Aufnah-men sowie der Identifikation von Auff\u00e4lligkeiten. Entsprechende Systeme werden bereits seit eini-gen Jahren im klinischen Alltag angewendet. \nK\u00fcnstliche Intelligenz im Sinne der aktuell \u00f6f-\nfentlich h\u00e4ufig diskutierten Deep Learning Al-gorithmen, bei denen der Computer anhand ei-nes Trainingsdatensatzes einen entsprechenden Analyse-Algorithmus selbstst\u00e4ndig optimiert, sind aktuell jedoch vorwiegend in Forschungs-projekten und Prototypen zu finden. Nichtsdes-totrotz ist nach aktuellem Stand davon auszu-gehen, dass Patientinnen und Patienten in der bildgebenden Diagnostik als eine der ersten Gruppen von den neuen KI-Technologien pro-fitieren werden. Die potenziellen technischen M\u00f6glichkeiten zur Unterst\u00fctzung der \u00c4rztinnen und \u00c4rzte beschr\u00e4nken sich dabei nicht nur dar -auf Auff\u00e4lligkeiten zu markieren. Denkbar ist die M\u00f6glichkeit, automatisiert Volumenmessungen durchzuf\u00fchren oder die Konsistenz und Struk-tur von L\u00e4sionen zu bestimmen. Au\u00dferdem k\u00f6nnte KI die Analyse des Krankheitsverlaufs erleichtern, indem etwa relevante Schnittbilder automatisiert identifiziert und ausgerichtet so-wie im Zeitverlauf verglichen werden. \nEin weiteres denkbares Einsatzfeld von KI ist die \nErmittlung und Reduktion der zur Untersuchung notwendigen Strahlungsdosis anhand der indi-viduellen Patientencharakteristika.\n18 Technische \nInnovationen in diesem Feld kommen neben etablierten Medizintechnikunternehmen wie Siemens oder General Electric auch von gro\u00dfen IT-Unternehmen wie IBM mit ihrer KI namens \u201eWatson\u201c. Im Zuge der Entwicklungen rund um das Thema K\u00fcnstliche Intelligenz dr\u00e4ngen zumindest f\u00fcr den Softwarebereich zunehmend neue Anbieter auf den Markt, der in dieser Hin-sicht vielfach durch die Produktideen von Start- ups gepr\u00e4gt wird.\n19\nWettbewerb treibt Innovation\nDer Markt f\u00fcr technische Ger\u00e4te zur bildge-benden Diagnostik weist eine oligopolistische Struktur auf und wird durch die Hersteller Siemens, General Electric (GE) und Philips do-miniert, die zusammen einen Marktanteil von nahezu zwei Drittel erreichen.\n20 Siemens bzw. \ndessen Vorg\u00e4ngerfirmen21 sowie GE22 sind be-\nreits seit den fr\u00fchen Anf\u00e4ngen der R\u00f6ntgen-technologie Ende der 1890er Jahre in diesem Bereich aktiv. Auch Philips kann auf eine lange Historie zur\u00fcckblicken und produzierte bereits in den 1910er Jahren erste Ger\u00e4te.\n23 Aufgrund \nR\u00f6ntgen hilft beim Schuhkauf: Unter dem Pedoskop, auch bekannt als Schuh-Flu-oroskop, konnten Kundinnen und Kunden bis in die 1970er Jahre mittels R\u00f6ntgen-\naufnahmen Sitz und Passform von Schuhen \u00fcberpr\u00fcfen. Insbesondere beim Schuhkauf f\u00fcr Kinder war die Anwendung beliebt. Urspr\u00fcnglich in den 1920er Jahren entwickelt, dauerte es einige Jahrzehnte, bis die gesundheitlichen Gefahren zu einem Verbot der Anwendung in Schuhgesch\u00e4ften f\u00fchrten. In Deutschland geschah dies Anfang der 1970er Jahre.\n17 i162 \nder langen Erfahrung und des Entwicklungs-\nvorsprungs der etablierten Hersteller weist der Markt der bildgebenden Verfahren sehr hohe Markteintrittsbarrieren auf, insbesondere f\u00fcr Gro\u00dfger\u00e4te wie CT oder MRT. Zum einen ist zur Entwicklung der komplexen Ger\u00e4te erhebliches Hard- und Software Know-how notwendig. Zum anderen werden die Ger\u00e4te vor allem in einem sehr kostensensitiven und schwer zu er -\nreichenden Markt \u2013 der station\u00e4ren Versorgung im Krankenhaus \u2013 verkauft und betrieben. Dies f\u00fchrt dazu, dass neue Wettbewerber er -\nhebliche Investitionen t\u00e4tigen m\u00fcssten, um zu ernstzunehmenden Konkurrenten zu werden. Trotz der bestehenden Marktmacht erfolgte eine stetige Weiterentwicklung der technischen Verfahren. Gleichzeitig hat diese jedoch auch dazu gef\u00fchrt, dass die Hersteller relativ ge-schlossene Systeme und propriet\u00e4re L\u00f6sungen angeboten haben und weiterhin anbieten, wo-mit ein barrierefreier Umstieg zwischen einzel-nen Systemen erschwert wird.Soziotechnische Folgen moderner  \nBildgebung\nNicht nur f\u00fcr \u00c4rztinnen und \u00c4rzte, sondern \nauch f\u00fcr Patientinnen und Patienten ist die bildgebende Diagnostik zum festen Bestand-teil vieler medizinischer Behandlungen gewor -\nden. Statistisch betrachtet wird jeder Mensch in Deutschland pro Jahr 1,7 Mal einer R\u00f6nt-genanwendung unterzogen.\n24 Davon sind ca. \n40 Prozent der F\u00e4lle auf zahnmedizinische An-wendungen zur\u00fcckzuf\u00fchren. Im Zeitraum von 2007 bis 2014 nahmen insbesondere Mam-mographien (35 Prozent) und CT-Untersuchun-gen (40 Prozent) zu; gleiches gilt f\u00fcr MRT-Un-tersuchungen (55 Prozent), bei denen jedoch keine sch\u00e4dliche Strahlung erzeugt wird.\n25 Die \nZunahme an dosisintensiven Untersuchungen, insbesondere beim CT, hat auch zur Folge, dass trotz der Fortschritte in der R\u00f6ntgentech-nik in den vergangenen 30 Jahren, die zu einer erheblichen Reduktion der Strahlendosis der meisten R\u00f6ntgenanwendungen gef\u00fchrt haben, \nAbb. 2: Vollstation\u00e4re Bildgebende Diagnostik \nQuelle: eigene Auswertung nach Statistisches Bundesamt (2014 \u2013 2017): Fallpauschalenbezogene Krankenhausstatistik (DRG- Statistik) Diagnosen, Prozeduren, Fallpauschalen und Case Mix der vollstation\u00e4ren Patientinnen und Patienten in Krankenh\u00e4u-sern. www.destatis.de/DE/Publikationen/Thematisch/Gesundheit/Krankenhaeuser/FallpauschalenKrankenhaus2120640167004 pdf?__blob=publicationFile  [Zugriff  am 23.4.2018].\nX-Strahlen: Wie die Entdeckung Wilhelm Conrad R\u00f6ntgens die moderne Medizin pr\u00e4gte \u00a7 163\ndie mittlere Strahlenexposition zunimmt. Circa \n9 Prozent der R\u00f6ntgenanwendungen entfallen auf CT-Untersuchungen und sind damit gleich-zeitig f\u00fcr 65 Prozent der kollektiven effektiven Strahlendosis verantwortlich.\n26 \nEine Abschw\u00e4chung des Trends zu mehr Bild-gebung z. B. im vollstation\u00e4ren Bereich ist u. a. aufgrund des zunehmenden Anteils der \u00e4lteren Bev\u00f6lkerung derzeit nicht erkennbar (siehe Ab-bildung 2). Wie in Abbildung 3 zu erkennen ist, werden in der Bev\u00f6lkerungsgruppe der 60- bis 80-j\u00e4hrigen besonders h\u00e4ufig entsprechende Untersuchungen durchgef\u00fchrt.\nAuch wenn die Gefahren zu h\u00e4ufiger radiolo-\ngischer Untersuchungen seit Jahrzehnten gut erforscht sowie in der Breite bekannt sind und sich der vergleichsweise sorglose Umgang mit R\u00f6ntgenstrahlung gelegt hat, so stellt sich wei-terhin die Frage, ob alle Untersuchungen tat-s\u00e4chlich notwendig sind. Kritisiert wird beispielsweise, dass teilweise Doppeluntersuchungen oder nicht notwen-dige Diagnostik durchgef\u00fchrt werden. So hat sich der Ausschuss f\u00fcr Bildung, Forschung und Technikfolgenabsch\u00e4tzung im Jahr 2015 mit der Frage auseinandergesetzt, ob technischer Fortschritt im Gesundheitswesen eine Quelle f\u00fcr Kostensteigerungen oder eine Chance f\u00fcr Kostensenkungen ist und hierf\u00fcr n\u00e4her den Einsatz von MRT bei R\u00fcckenschmerzen unter -\nsucht. Da MRT f\u00fcr eine Vielzahl von Krank-heitsbildern zus\u00e4tzliche Informationen liefern kann, kam es in den vergangenen Jahrzehn-ten zu einer starken Indikations- und Anwen-dungsausweitung. MRT werden jedoch h\u00e4ufig auch in Situationen angewandt, in denen keine ernsthafte Erkrankung vermutet wird, wie etwa bei Kreuzschmerzen. Dies ist einer der Gr\u00fcnde, warum sich die MRT zu einem entscheidenden Kostentreiber entwickelt hat.\n27 Gleiches gilt f\u00fcr \ndie Untersuchung von Kreuzschmerzen mittels CT. Allerdings sind hierbei neben den Kosten \nAbb. 3: Alter und vollstation\u00e4re Bildgebende Diagnostik \nQuelle: eigene Auswertung nach Statistisches Bundesamt (2017): Staat & Gesellschaft - Bev\u00f6lkerungsstand - Bev\u00f6lkerung - Statistisches Bundesamt (Destatis). www.destatis.de/DE/ZahlenFakten/GesellschaftStaat/Bevoelkerung/Bevoelkerungsstand/Tabellen_/lrbev01.html [Zugriff am 23.4.2018].\n164 \ninsbesondere auch die gesundheitlichen Risiken \ndurch die R\u00f6ntgenstrahlung zu ber\u00fccksichti-gen.\n28\nDie hohen Kosten entstehen nicht nur aufgrund der enormen Anfangsinvestitionen bei der An-schaffung, sondern auch durch den verh\u00e4ltnis-m\u00e4\u00dfig hohen Betriebs- und Personalaufwand, der zur Nutzung einer CT- oder MRT-Anlage sowie der anschlie\u00dfenden Befundung notwen-dig ist. Die technische Anwendung von R\u00f6nt-genstrahlung beschr\u00e4nkt sich jedoch nicht nur auf die diagnostische Bildgebung. Sie wird bei-spielsweise in der Strahlentherapie zur Krebsbe-handlung eingesetzt.Fazit \nDie Entwicklung der R\u00f6ntgentechnologie blickt auf eine mehr als 120-j\u00e4hrige Historie zur\u00fcck. Sie war zum einen selbst Ausgangspunkt f\u00fcr zahlreiche technische Innovationen und Op-timierungen, wie Weiterentwicklung des her -\nk\u00f6mmlichen R\u00f6ntgens, Computertomographie  oder reduzierte Strahlenexposition, und gleich-zeitig zahlreichen externen technischen Um-w\u00e4lzungen, wie Digitalisierung, Vernetzung im Krankenhaus, Telemedizin und k\u00fcnstliche Intelligenz, ausgesetzt. Dies hatte zur Folge, dass sich selbst marktf\u00fchrende Hersteller immer wieder auf neue technische Herausforderungen einstellen und ihre Produkte kontinuierlich wei-terentwickeln mussten, um wettbewerbsf\u00e4hig zu bleiben. Abb. 4: Durchschnittliche j\u00e4hrliche Strahlenbelastung nach Strahlenquellen \nQuelle: BfS (2016): Strahlenschutz Konkret. R\u00f6ntgendiagnostik \u2013 Nutzen und Risiken. Hg. v. Bundesamt f\u00fcr Strahlenschutz\n0 0,5 1 1,5 2 2,5 3 3,5 4 4,5 Strahlenbelastung in mSv/a Durchschnittliche j\u00e4hrliche Strahlenbelastung  \nSonstiges* Kosmische Strahlung Nahrung Terrestrische Strahlung Radon Medizin  \n *Kerntechnische Anlagen; Atombomben-Fallout; Tschernobyl; Forschung, Technik, Haushalt0 0,5 1 1,5 2 2,5 3 3,5 4 4,5 Strahlenbelastung in mSv/a Durchschnittliche j\u00e4hrliche Strahlenbelastung  \nSonstiges* Kosmische Strahlung Nahrung Terrestrische Strahlung Radon Medizin  \n *Kerntechnische Anlagen; Atombomben-Fallout; Tschernobyl; Forschung, Technik, Haushalt0 0,5 1 1,5 2 2,5 3 3,5 4 4,5 Strahlenbelastung in mSv/a Durchschnittliche j\u00e4hrliche Strahlenbelastung  \nSonstiges* Kosmische Strahlung Nahrung Terrestrische Strahlung Radon Medizin  \n *Kerntechnische Anlagen; Atombomben-Fallout; Tschernobyl; Forschung, Technik, Haushalt0 0,5 1 1,5 2 2,5 3 3,5 4 4,5 Strahlenbelastung in mSv/a Durchschnittliche j\u00e4hrliche Strahlenbelastung  \nSonstiges* Kosmische Strahlung Nahrung Terrestrische Strahlung Radon Medizin  \n *Kerntechnische Anlagen; Atombomben-Fallout; Tschernobyl; Forschung, Technik, Haushalt0 0,5 1 1,5 2 2,5 3 3,5 4 4,5 Strahlenbelastung in mSv/a Durchschnittliche j\u00e4hrliche Strahlenbelastung  \nSonstiges* Kosmische Strahlung Nahrung Terrestrische Strahlung Radon Medizin  \n *Kerntechnische Anlagen; Atombomben-Fallout; Tschernobyl; Forschung, Technik, Haushalt0 0,5 1 1,5 2 2,5 3 3,5 4 4,5 Strahlenbelastung in mSv/a Durchschnittliche j\u00e4hrliche Strahlenbelastung  \nSonstiges* Kosmische Strahlung Nahrung Terrestrische Strahlung Radon Medizin  \n *Kerntechnische Anlagen; Atombomben-Fallout; Tschernobyl; Forschung, Technik, Haushalt0 0,5 1 1,5 2 2,5 3 3,5 4 4,5 Strahlenbelastung in mSv/a Durchschnittliche j\u00e4hrliche Strahlenbelastung  \nSonstiges* Kosmische Strahlung Nahrung Terrestrische Strahlung Radon Medizin   \n *Kerntechnische Anlagen; Atombomben-Fallout; Tschernobyl; Forschung, Technik, HaushaltX-Strahlen: Wie die Entdeckung Wilhelm Conrad R\u00f6ntgens die moderne Medizin pr\u00e4gte \u00a7 165\n1 Riechmann, J . (2014): Der Einfluss der Entdeckung der R\u00f6ntgenstrahlen auf die Diagnostik und Therapie in der Urologie. Die erste Epoche von \nden Anf\u00e4ngen bis zur retrograden Harntr aktdarstellung. Medizinischen Hochschule Hannover . Hannover. https://d-nb .info/981085857/34  \n [Zugriff am 23.4.2018].\n2 K\u00fctterer, G . (2005): Ach, wenn es doch ein Mittel g \u00e4be, den Menschen durchsich tig zu machen wie eine Qualle! Die R\u00f6ntgentechnik in ih ren ersten\nbeiden Jahrzehnten - ein besonders faszinierendes St\u00fcck Medizin- und Technikgeschichte , dargestellt in Zitaten. Norderstedt: Books on Demand.\n3 ebd. K \u00fctterer , G. (2005)\n4 Siemens AG (2016): Hintergrund-Information: Die Meilensteine der Medizintechnik-Geschichte von Siemens . Hg. v. Siemens AG Communications \nand Government\n Affairs. M\u00fcnchen. www .siemens .com/press/pool/de/events/2014/healthcare/2014-05-medmuseum/hintergrund-medmuseum-d.pdf  \n \n[Zugriff am 23.4.2018].\n5 Knopp , G. (2017): Die Sternstunden der Deutschen: Edel Elements.\n6 swissr\nadiology consulting (2017): Geschichte des R\u00f6ntgen - Radiologie24. www .radiologie24.ch/radiologie-mediathek/lexika-radiologie24/\nkurze-geschichte-der-radiologie/roentgen_1895-1900 [Zugriff am 4.4.2018].\n7 Kemerink, M.; Dierichs , T. J.; Dierichs , J.; Huynen, H. J. M.; Wildberger , J. E.; van Engelshoven, J. M. A.; K emerink, G . J. (2011): Characteristics of \n \na first-generation x-ray system. In: Radiology 259 (2), S. 5 34\u2013539. DOI: 10.1148/r adiol .11101899.\n8 Riechmann, J. (2014): De r Einfluss der Entdeckung  der R\u00f6ntge nstrahl en auf die Diagnostik und Therapie in der Urologie. Die erste Epoche von den Anf\u00e4ngen\n \nbis zur retro graden Harntraktdarstellung. Medizinischen H ochschule Hannover. Hannover .  https://d-nb .info/981085857/34 [Zugriff am 23.4.2018].\n9 Albers-Sch\u00f6nberg, H. (2008): Vor hundert J ahren. Die Entwicklung und der derzeitige Stand der Roentgentechnik. In: Zeitschrift f\u00fcr Evidenz, \n Fortbildung und Qualit\u00e4t im Gesundheitswesen 102 (2), S. 117\u2013119. DOI: 10.1016/j.zefq.2008.02.015.\n10 Ruisinger , M. M. (o . J.): R\u00f6ntgenbilder im Ersten W eltkrieg. Hg. v. Deutsche R\u00f6ntgengesellschaft e . V. Deutsches Medizinhistorische Museum. \n www.drg.de/de-DE/1666/roentgenbilder-im-ersten-weltkrieg [Zugriff am 4.4.2018].\n11 Siemens AG (2016): Hintergrund-Information: Die Meilensteine der Medizintechnik-Geschichte von Siemens . Hg. v. Siemens AG Communications\nand Government\n Affairs. M\u00fcnchen. www .siemens .com/press/pool/de/events/2014/healthcare/2014-05-medmuseum/hintergrund-medmuseum-d.pdf\n \n[Zugriff am 23.4.2018].\n12 Kramer , M.; Gomercic, H. (2009): CT- und MRT-Atlas . Transversalanatomie des Hundes , 12 T abellen. Hg. v. Michael Mihaljevic. Stuttgart: Parey.\n13 D\u00f6ssel , O. (2016): Bildgebende Verfahren in der Medizin. Berlin, Heidelberg: Springer Berlin Heidelberg.\n14 Buzug, T. M. (2004): Einf\u00fchrung in die Computertomographie . Mathematisch-physikalische Grundlagen der Bildrek onstruktion. Berlin, Heidelberg, \ns\n.l.: Springer Berlin Heidelberg. http://dx.doi .org/10.1007/978-3-642-18593-9. \n15 Hombach, V.; Barkhausen, J. J. (2009): Kardiovaskul\u00e4re Magnetresonanztomographie . Atlas und DVD ; mit 28 T abellen. Stuttgart: Schattauer. \n http://deposit.d-nb.de/cgi-bin/dokserv?id=3097086&prov=M&dok_var=1&dok_ext=htm [Zugriff am 4.4.2018].\n16 Wiley, G. (o. J .): The Prophet Motive: How PA CS Was Developed and Sold - Axis Imaging News . Hg. v. Decisions in Axis Imaging News. \n www.axisimagingnews.com/2005/05/the-prophet-motive-how-pacs-was-developed-and-sold/ [Zugriff am 24.4.2018].\n17 Spitzer, M. (2012): Das Pedoskop: Aus der Geschichte kann man lernen! In: Nervenheilkunde (4), S. 203\u2013207. \n https://thieme-connect.de/products/ejournals/abstract/10.1055/s-0038-1628160 [Zugriff am 23.4.2018].\n18 Fornell , D. (2017): Examples of How Artificial Intelligence Will Improve Medical Imaging. H g. v. itn imaging technology news . \n www.itnonline.com/videos/video-examples-how-artificial-intelligence-will-improve-medical-imaging [Zugriff am 24.4.2018]. \n19 Harvey, H. (2017): T he A-Z Guide to r adiology AI companies showcasing at RSNA 2017. https://medium.com/@\n DrHughHarvey/the-a-z-guide-to-radiology-ai-companies-showcasing-at-rsna-2017-8c9976db90df [Zugriff am 23.4.2018].\n20 Statista (2017): Top 10 Medizintechnikunternehmen nach weltweiten Marktanteilen im Segment bildgebende Diagnostik 2016 und 2022 | \n Statistik. https://de .statista.com/statistik/daten/studie/332494/umfrage/fuehrende-medizintechnikunternehmen-nach-weltweiten-\n marktanteilen-im-segment-bildgebende-diagnostik [Zugriff am 11.4.2018]. \n21 Siemens AG (2016): Hintergrund-Information: Die Meilensteine der Medizintechnik-Geschichte von Siemens . Hg. v. Siemens AG Communications\nand Government\n Affairs. M\u00fcnchen. www .siemens .com/press/pool/de/events/2014/healthcare/2014-05-medmuseum/hintergrund-medmuseum-d.pdf\n \n[Zugriff am 23.4.2018].\n22 Kellner , T. (2014): Seeing the Unseen: The Past 100 Years and the Future of Medical Imaging. Hg. v. Gener al Electric. \nwww.ge.com/reports/post/104081928440/seeing-the-unseen-the-past-100-years-and-the  [Zugriff am 23.4.2018].\n23 Philips (o . J.): History of X-r ay. Hg. v. Philips. www .philips .com/consumer files/newscenter/main/shared/assets/Downloadablefile/FACT_SHEET_\nX-ray_history.pdf  [Zugriff am 23.4.2018].\n24 Datenjahr 2014\n25 Bundesamt f\u00fcr Strahlenschutz (2018): R\u00f6ntgendiagnostik: H\u00e4ufigkeit und Strahlenexposition. H g. v. Bundesamt f\u00fcr Strahlenschutz. \n www.bfs.de/DE/themen/ion/anwendung-medizin/diagnostik/roentgen/haeufigkeit-exposition.html [Zugriff am 11.4.2018].\n26 Bundesamt f\u00fcr Strahlenschutz (2016): Strahlenschutz K onkret. R\u00f6ntgendiagnostik - Nutzen und Risiken. \n27 Deutscher Bundestag (2015): Technischer Fortschritt im Gesundheitswesen: Quelle f\u00fcr Kostensteigerungen oder Chance f\u00fcr Kostensenkungen? \n http://dip21.bundestag.de/dip21/btd/18/042/1804283.pdf [Zugriff am 4.4.2018]. \n28 Gilbert, F. J .; Grant, A. M.; Gillan, M. G. C .; Vale , L. D.; Campbell , M. K.; Scott, N. W. et al. (2004): Low back pain. Influence of early MR imaging or \nCT on treatment and outcome-multicenter randomized trial.\n In: Radiology 231 (2), S. 343\u2013351. DOI: 10.1148/radiol.2312030886.Obwohl diese Entwicklungen immer wieder \nsehr deutliche Mehrwerte f\u00fcr Patientinnen und Patienten gebracht haben, hat sich das grund-legende physikalische Prinzip nicht ver\u00e4ndert. Die Bedeutung der bildgebenden Diagnostik ist trotz immer wieder \u00f6ffentlich artikulierter Kritikpunkte ungebrochen. Insbesondere in Anbetracht des demographischen Wandels ist nicht davon auszugehen, dass sich das stetige Wachstum der radiologischen Anwendungen in den n\u00e4chsten Jahren abschw\u00e4cht oder gar umkehrt.166 \nDer neue Pflegebed\u00fcrftigkeitsbegriff \nAufbruch in eine digital unterst\u00fctzte Pflege (Oder wusste Tocotronic \ndamals schon etwas, was wir noch nicht wussten?)\nMaxie Lutze  Markus Adelberg\nAls die Hamburger-Schule Band Tocotronic \n1995 sloganhaft \u201eDigital ist besser\u201c sangen,  \nbeschrieben Musikjournalisten die Kl\u00e4nge als \u201eeinfach\u201c, ja geradezu \u201edilettantisch\u201c. Den Stand der Digitalisierung vor 23 Jahren im Vergleich zu heute haben diese Attribute ganz sicher gut wiedergegeben. Heute \u00fcberholt, war die CD als digitales Medium damals noch relativ neu. \nAls die VDI/VDE-IT 2010 die ersten Schritte in \nSachen digitale und technische Assistenzsyste-me f\u00fcr \u00e4ltere Menschen und kurz danach f\u00fcr Menschen mit Pflegebedarf machte, hatte sich in der Alten- sowie Kranken- und Gesundheits-pflege auch noch nicht viel an dem Stand der Digitalisierung ge\u00e4ndert. \nGame Changer \u2013 Menschen im Mittelpunkt\nTechnologien haben sich im Laufe der Jah-re dramatisch weiterentwickelt. Die tiefgrei-fenden Branchenver\u00e4nderungen im techno-logischen Bereich haben eins gemein: Sie zeichnen sich durch eine zunehmende Kon-zentration auf die Bed\u00fcrfnisse und die Rolle des Menschen aus. \nBef\u00f6rdert wird die Entwicklung \u201evom Men-\nschen im Mittelpunkt\u201d von drei Trends: \n     Einerseits die zunehmende Anerkennung und Auseinandersetzung mit Nichtwissen\n1 \n\u00fcber Menschen, nicht nur als Antrieb von Wissenschaft und Forschung, sondern auch f\u00fcr k\u00fcnftige Gesch\u00e4ftmodelle und Absatz-m\u00e4rkte.      Ander erseits das Fortschreiten interdiszipli-\nn\u00e4ren Denkens, Lernens und Arbeitens, bei denen Konzepte \u00fcber Disziplinen hinweg gedacht zu interdisziplin\u00e4ren Denkans\u00e4tzen werden, die in kooperativen Prozessen zu komplexen Probleml\u00f6sungen \u2013 integrierte Probleml\u00f6sungskompetenz \u2013 f\u00fchren. \n     Au\u00dfer dem ein sich wandelndes Menschen-\nbild, weg von einer Fokussierung auf die De-fizite und hin zu den Potenzialen, auch im ho-hen Alter.\n2 Den Menschen in den Mittelpunkt \nzu stellen, ist dabei kein Ph\u00e4nomen einzelner Forschungsdisziplinen oder rein technologi-scher Branchen. Human- oder Nutzerzent-rierung (engl. Human- oder User-Centred, H/UCD) betrifft die Gestaltung von Lern-An-geboten und B\u00fcrger-Services ebenso wie die Entwicklung von digitalen Technologien und physischen Produkten. Der Ansatz erkennt an, dass nicht alle Informationen \u00fcber die Bed\u00fcrfnisse von Menschen bekannt sind und diese Unwissenheit genutzt werden kann, um neues Wissen zu generieren, etwa um neue Technologien zu entwickeln. Die Identi-fikation menschlicher Bed\u00fcrfnisse und W\u00fcn-sche spielen bei der Gestaltung eine zentrale Rolle, um daraus die Frage abzuleiten: Welche dieser Herausforderungen k\u00f6nnen mittels neuer Technologien gel\u00f6st werden?  \nBed\u00fcrfnisse und F\u00e4higkeiten von Menschen \nmit Pflegebedarf\nStatt neuer Technologien und Digitalisierung \nstand 1995 in der Pflege die Einf\u00fchrung der \n40 JahreDer neue Pflegebed\u00fcrftigkeitsbegriff \u00a7  167\nPflegeversicherung auf dem Plan. Eine damit \nverbundene Orientierung von Pflegebed\u00fcrftig-keit an der Berechnung einzelner Verrichtungen nach Zeitvorgaben hat seitdem das gesellschaft-liche Verst\u00e4ndnis von professioneller Pflege in Deutschland gepr\u00e4gt. So waren als Beispiel f\u00fcr das Duschen pflegebed\u00fcrftiger Menschen 15 bis 20 Minuten vorgesehen, Abweichungen davon mussten begr\u00fcndet und dokumentiert werden.\n3 Vor allem deshalb ist das System sp\u00e4-\nter auch in die Kritik geraten. Die Kritik galt einer Diskrepanz zwischen den tats\u00e4chlichen Bedarfslagen pflegebed\u00fcrftiger Menschen und dem vorhandenen pflegerischen Versorgungs-angebot.\n4\nDie Fokussierung auf Zeit und k\u00f6rperliche Defi-zite schloss pr\u00e4ventive und rehabilitative Pflege aus. Beratende und edukative Interventionen wurden nicht ber\u00fccksichtigt. Essentielle As-pekte der Lebensqualit\u00e4t wie soziale Interakti-on, Teilhabe und Kommunikation erhielten zu wenig Aufmerksamkeit. Daher kam es auch bei Menschen mit eingeschr\u00e4nkter Alltagskompe-tenz zu unzureichenden Einsch\u00e4tzungen der Pflegebed\u00fcrftigkeit bez\u00fcglich des Aufwandes f\u00fcr Pflege, Betreuung und Anleitung.\nSeit 2017 gilt in Deutschland ein neuer Pfle-\ngebed\u00fcrftigkeitsbegriff (PB) und damit ver -\nbunden ein neues Begutachtungsinstrument (BI). Der Begriff zeichnet sich durch die Zen-trierung auf die pflegebed\u00fcrftige Person und ihre Bed\u00fcrfnisse aus. Die Begutachtung eines pflegebed\u00fcrftigen Menschen erfolgt nun nicht mehr anhand seiner Defizite, sondern sie stellt den Grad seiner Selbstst\u00e4ndigkeit fest. Dabei werden auch die M\u00f6glichkeiten zur Selbstver -\nsorgung, die Gestaltung seines Alltagslebens sowie seiner sozialen Kontakte und au\u00dferh\u00e4us-lichen Aktivit\u00e4ten intensiver als zuvor in die Beurteilung des Unterst\u00fctzungsbedarfs ein-bezogen. Zudem k\u00f6nnen kognitive Aspekte \u2013  \ndie insbesondere f\u00fcr Menschen mit Demenz relevant sind \u2013 sowie pr\u00e4ventive und rehabi-litative M\u00f6glichkeiten nun gewertet werden. Der Begriff steht damit f\u00fcr einen Kulturwan-del in der Pflege. Der pflegebed\u00fcrftige Mensch mit seinen vorhandenen F\u00e4higkeiten steht im Mittelpunkt. \nDas neue Begutachtungsinstrument (BI) be-\nwertet die Pflegebed\u00fcrftigkeit anhand von f\u00fcnf Modulen, die unterschiedliche Lebensbereiche widerspiegeln und verschieden gewichtet wer -\nden (vgl. Abbildung 1). \n     Modul 1 \u201eSelbstversorgung\u201d (40 Pr ozent) \numfasst vor allem K\u00f6rperpflege und Ern\u00e4h-rung.  \n    Modul 2 \u201eBew\u00e4ltigung und selbst\u00e4ndiger Umgang mit krankheits-/therapiebedingten Anfor\nderungen und Belastungen\u201d (20 Pro-\nzent) beschreibt T\u00e4tigkeiten wie selbstst\u00e4n-dige Medikamenteneinnahme, Verbands-wechsel oder Arztbesuche.\n    Modul 3 \u201eGestaltung des Alltagslebens und soziale Kontakte\u201d (15 Pr\nozent) beurteilt die \nF\u00e4higkeit zur selbstst\u00e4ndigen gesellschaftli-chen Teilhabe. \n     Modul 4 umfasst die zwei Ber eiche \u201eKogni-\ntive und kommunikative F\u00e4higkeiten\u201d sowie \u201eVerhaltensweisen und psychische Proble-me\u201d (15 Prozent) und sch\u00e4tzt krankheitsbe-dingte Einschr\u00e4nkungen oder vorhandene Selbst\u00e4ndigkeit im Hinblick auf Entschei-dungen, Orientierung, Gef\u00e4hrdungen oder Beeintr\u00e4chtigungen ein. \n    Modul 5  \u201eMobilit\u00e4t\u201d (10 Prozent) umfasst \ndie F\u00e4higkeit zur Fortbewegung sowie die Lagever\u00e4nderung des K\u00f6rpers.\nTechnikgestaltung f\u00fcr und mit Menschen \nEine gezielte Ausrichtung von Prozessen und Produkten auf Menschen und ihre Bed\u00fcrfnis-se ist ein Paradigma, das im Zuge der Digita-lisierung immer st\u00e4rker in den Fokus r\u00fcckt. So sind methodische Ans\u00e4tze wie \u201eUser-Centered Design\u201d oder \u201eDesign Thinking\u201d in s\u00e4mtliche Bereiche der Arbeitswelt und auch die Politik-gestaltung diffundiert. 168 \nDas sogenannte nutzerzentrierte Design \nwurde in den 80er Jahren gepr\u00e4gt.5 Es be-\ndeutet, sich auf die Bed\u00fcrfnisse der Nutzen-den eines Produktes zu konzentrieren, Akti-vit\u00e4ten und Aufgaben zu analysieren sowie eine allgemeine Anforderungsanalyse durch-zuf\u00fchren. Es schlie\u00dft ein, w\u00e4hrend der Pro-duktentwicklung fr\u00fchzeitige Tests sowie Eva-luierungen durchzuf\u00fchren und schrittweise das Produkt zu qualifizieren (iterativ). Ebenso wie die verwandte Entwicklung Human-Cen-tered Design (HCD) werden Menschen als das wichtigste Element von Informations-systemen betrachtet. Eigenschaften und F\u00e4-higkeiten sollen so explizit bei Interaktionen von Menschen mit interaktiven Technologien ber\u00fccksichtigt werden. H/UCD stehen damit f\u00fcr einen Wandel von einer technikzentrier -\nten hin zu einer menschenzentrierten Tech-nologieentwicklung. H/UCD sind seit Jahrzehnten Forschungsge-genstand der Wissenschaft und stehen in Zusammenhang mit der Erkenntnis, dass die Konzentration auf den Menschen bessere Er -\ngebnisse f\u00fcr die Gestaltung von Produkten und deren Nutzung liefert. Damit wurde der Ansatz auch zunehmend f\u00fcr die Industrie inter-  \nessant. Gro\u00dfbritannien hat mit der Festlegung von Design-Grunds\u00e4tzen f\u00fcr die Gestaltung von B\u00fcrgerinformationen und -services UCD in die politische Arbeit eingebunden.\n6\nUCD hat sich seither weiter aufgef\u00e4chert und entwickelt (vgl. Tabelle 1). User Experience (UX) und Interaktionsdesign (IxD) sind weitere Auspr\u00e4gungen einer auf den Menschen aus-gerichteten Technologiegestaltung. Trotz ihres unterschiedlichen Fokus\u2019 liegt deren gemein-samer Kern darin, digitale Produkte immer im Hinblick auf die Nutzbarkeit zu optimieren. Die eingesetzten Methoden und gewonnenen Abb. 1: Begutachtungsinstrument zur Erhebung des Pflegebedarfs in f\u00fcnf Lebensbereichen \nQuelle: GKV-Spitzenverband (2017): Pflegebegutachtung - f\u00fcnf Pflegegrade. www.gkv-spitzenverband.de/service/versicher-ten_service/pflegebegutachtung_ab_2017/fuenf_pflegegrade.jsp [Zugriff am 26.4.2018].15 %\nKognitive und \nkommunikative F\u00e4higkeiten\nsowie Verhaltensweisen \nund psychische Probleme15 %\nGestaltung des Alltagslebens \nund soziale Kontrolle\n40 % \nSelbstversorgung \n(K\u00f6rperpflege, Ern\u00e4hrung etc.)20 %\nBew\u00e4ltigung von und \nselbstst\u00e4ndiger Umgang \nmit krankheits- oder \ntherapiebedingten \nAnforderungen und \nBelastungen10 %\nMobilit\u00e4tDer neue Pflegebed\u00fcrftigkeitsbegriff und das neue Begutachtungsinstrument im \u00dcberblick \u2013\nSechs Lebensbereiche werden in f\u00fcnf Modulen betrachtet und gewichtetDer neue Pflegebed\u00fcrftigkeitsbegriff \u00a7  169\nErgebnisse sind eine Reaktion und Weiterent-\nwicklung auf Ver\u00e4nderungen in der technolo-gischen Landschaft. Die Entwicklungen von Technologien einschlie\u00dflich sich wandelnder Eingabem\u00f6glichkeiten wie Gesten oder Sprache f\u00fchren zu einer kontinuierlichen Qualifizierung und Verbreitung von Design- und Evaluierungs-methoden in Bezug auf Hardware, Software und Dienstleistungen. Auch individuelle Unter -\nschiede bei der Verwendung durch verschiede-ne (Be-)Nutzergruppen unter Ber\u00fccksichtigung von Alter, Kultur und Geschlecht gewinnen an Bedeutung. Zunehmend konzentriert sich die Forschung au\u00dferdem auf umfassendere Anlie-gen wie die Auswirkungen von Technologie-design und -nutzung auf soziale und kulturelle Aspekte sowie die globale Nachhaltigkeit. \u00dcber die Zeit gesehen ist eine Verschiebung des De-signprozesses immer weiter zum Nutzer erfolgt (vgl. Tabelle 1). In der Regel schlie\u00dft eine bed\u00fcrfnisorientierte Entwicklung auch die F\u00e4higkeiten von Men-schen mit ein. Schutzbed\u00fcrftige Gruppen wie pflegebed\u00fcrftige Menschen standen bei der Entwicklung von Technologien und Produkten bisher allerdings kaum im Fokus. Von Bedeu-tung ist, dass sich sowohl die kognitiven als auch k\u00f6rperlichen F\u00e4higkeiten bei Pflegebe-d\u00fcrftigkeit kontinuierlich ver\u00e4ndern k\u00f6nnen.\nMenschen im Mittelpunkt der Entwicklung \nvon Pflegetechnologien \nDie Alten-, Kranken- und Gesundheitspflege ist \nein gesellschaftlicher Bereich, in dem der Ein-satz von unterst\u00fctzender Technik und Technolo-gien zunehmend in den Fokus r\u00fcckt. Seit Jahren steigt die Zahl pflegebed\u00fcrftiger Menschen\n7, \nw\u00e4hrend es immer schwieriger wird, ausrei-chend Personal in der Pflege zu finden.\n8  Da sich \nschon heute eine erhebliche Versorgungsl\u00fccke abzeichnet, wird mit dem Einsatz innovativer Tabelle 1: Eigene Darstellung \u2013 Entwicklung nutzerorientierter Designprozesse Phase                                Ansatz und Nutzerrolle                   Rolle von T echnik\nUnterst\u00fctzte  \nTechniknutzungAnpassung des Nutzerverhaltens an \ndie T echnik durch Hilfestellung bei der \nNutzung von Technik (Dokumentation, Training, Beratung)Technologien als Werkzeug von Experten \nNutzbare und  \nsinnvolle Technik  \n(Usability, UI)Gebrauchstauglichkeit dur\nch leichte  \nErlernbarkeit und Nutzung von TechnikT\nechnologie als Erm\u00f6glicher \nzur Erreichung von Nutzer-\nzielen\nErfahrungen gestalten \n(User Experience)V\nertiefung des Verst\u00e4ndnis \u00fcber das  \nErleben von Menschengruppen,  \nCo-Creation und PersonalisierungT\nechnologie als Bestandteil \nbestehender (Gesch\u00e4fts-)Prozesse\nInnovationen  \ngestaltenNutzer\nerwartungen und- verhalten  \ntransformieren (Probleme und unent- \ndeckte Bed\u00fcrfnisse erschlie\u00dfen)T\nechnologie als Proxy f\u00fcr \nDienstleistungen; Transfor -\nmation der Wertsch\u00f6pfung 170 \nTechnologien wie der elektronischen Dokumen-\ntation, digitalen Assistenzsystemen, Telecare und Robotik die Hoffnung auf Unterst\u00fctzung und Entlastung verbunden. Zugleich gibt es Vorbehalte bei der Vorstellung, Technik in die auf Beziehungsarbeit beruhende pflegerische Versorgung von Menschen st\u00e4rker einzubin-den. Auch deshalb schreitet die Digitalisierung in der Pflege langsamer voran als in anderen Branchen, wie der \u00e4rztlichen Gesundheitsver -\nsorgung.\n9\nDennoch, einige Kernprozesse wie die Doku-mentation im station\u00e4ren und ambulanten Bereich sowie die Routenplanung in der am-bulanten Versorgung erfolgen inzwischen viel-fach elektronisch.\n10 Der Pflegeprozess bietet \nnoch mehr Potenzial, wie die folgenden Bei-spiele zeigen:\n      Das Seniorenzentrum Br eipohls Hof bietet \nBewohnerinnen und Bewohnern umfangrei-che technische Assistenz- und Sicherheits-funktionen. Ein Pflegebett unterst\u00fctzt bei der Sturzprophylaxe, eine Rufanlage funkti-oniert ohne das Abheben eines H\u00f6rers und das Dusch-WC gibt Sicherheit bei der per -\ns\u00f6nlichen Hygiene. Als zentrales Kommuni-kationsmedium (Video-Telefonie, Internet) dient ein Smart-TV mit integrierter Sprach- und Gestensteuerung zur Aufrechterhal-tung sozialer Kontakte und gesellschaftli-cher Teilhabe. \n11\n     Auch Roboter werden in der Pflege einge -\nsetzt. In einer Wohngruppe f\u00fcr demenzkran-ke Menschen des Deutschen Roten Kreuzes (DRK) wird die Roboter-Robbe \u201eParo\u201d ein-gesetzt, die Schwanz und Augen bewegen sowie T\u00f6ne der Zufriedenheit von sich geben kann. Im Inneren ist der Therapieroboter mit Sensoren und Motoren ausgestattet, die es erm\u00f6glichen, auf Ger\u00e4usche wie Namen und Gr\u00fc\u00dfe zu reagieren. Mittels \u201eParo\u201d k\u00f6nnen Therapeuten Menschen mit demenziellen und neurologischen Erkrankungen aktivie-ren, beruhigen und unterst\u00fctzen.\n12Abb. 2: Designprozesse, bei denen Menschen im Fokus stehen, in Anlehnung an Beger Design (2018)  \nQuelle: Beger Design (2018): Interface Design \u2013 Funktion mit Vision. http:/wordpress.begerdesign.com/\nkompetenzen/interface-design/ [Zugriff am 2.5.2018].Ideenentwicklung\nNutzer\nverstehenEntwicklung\nentwicklung\nInteraktionenUnter-\nsuchung\nUse\ncasesValidierung\nPrototyp\nEvaluationUser\nCentered\nDesignDer neue Pflegebed\u00fcrftigkeitsbegriff \u00a7  171\n    Den gr o\u00dfen Anteil der Pflege tragen in \nDeutschland die Familien pflegebed\u00fcrftiger \nPersonen. F\u00fcr pflegende Angeh\u00f6rige sind die psychischen und physischen Belastungen oft hoch, besonders wenn sie selbst schon \u00e4lter sind. Fehlen Anleitung und Unterst\u00fctzung, ist die Situation schnell \u00fcberfordernd. Un-terst\u00fctzung bieten mittlerweile verschiedene Apps, wie etwa die App \u201eDAK Pflegeguide\u201c, die situationsgerecht verst\u00e4ndliche Informati-onen und Schulungen oder Dienstleistungen zur Entlastung vermittelt. So k\u00f6nnen Pflege-hilfsmittel direkt \u00fcber die App bestellt oder Bescheinigungen wie Arbeitsunf\u00e4higkeit ein-gereicht werden.\n13\nBisher am weitesten verbreitet sind L\u00f6sungen in der Sicherheits- und Kommunikationstechnik, beispielsweise Rufanlagen und Notrufsyste-me. Das bekannteste Beispiel ist der klassische Hausnotruf, welcher Anfang der 70er Jahre entwickelt wurde. Die meisten Entwicklungen und Dienstleistungen befinden sich allerdings noch in der Vormarktphase. \nAufgrund des akuten Handlungsbedarfs sind \ndie Erwartungen an innovative Pflegetechno-logien hoch. Unterschiedliche hinderliche Fak-toren k\u00f6nnen derzeit ausgemacht werden, die eine Etablierung von modernen Technologien in Pflegesettings erschweren: Mangelnde Ak-zeptanz, z\u00e4he Wissensdiffundierung, fehlende empirische Belege \u00fcber den individuellen und pflegerischen Nutzen von Pflegetechnologien, geringe Beachtung von IT-Kompetenzen in der pflegerischen Aus-, Fort- und Weiterbildung so-wie fehlende Gesch\u00e4ftsmodelle in einem stark regulierten Gesundheitsmarkt z\u00e4hlen zu den meistgenannten Aspekten.\n14\nDer neue Pflegebed\u00fcrftigkeitsbegriff (PB) \nals Innovationsimpuls \nIn unserer Rolle als Technologie- und Innova-\ntions-Beratungsunternehmen besch\u00e4ftigt sich die VDI/VDE-IT seit 2010 umfassend mit der Frage, wie neue Technologien gef\u00f6rdert und dabei die Wirkung f\u00fcr die Gesellschaft gewinn-bringend gestaltet werden kann. Die Rolle des neuen Pflegebed\u00fcrftigkeitsbegriffs (PB) f\u00fcr die Pflege wurde bereits dargestellt. Was aber be-deutet dieser f\u00fcr die Entwicklung neuer Tech-nologien?\n     Pflegebed\u00fcrftige als Adr essaten neuer Tech-\nnologien ganzheitlich wahrnehmen: Damit \nverbunden ist die Chance, Technikentwick-lung k\u00fcnftig noch st\u00e4rker auf Menschen und ihre F\u00e4higkeiten sowie Bed\u00fcrfnisse aus-zurichten und defizitorientierte Sichtweisen zu \u00fcberwinden. Auch wenn k\u00f6rperliche und kognitive Beeintr\u00e4chtigungen unweigerlich Ver\u00e4nderungen mit sich bringen, birgt die Ber\u00fccksichtigung des neuen PB das Poten-zial, einen Beitrag zu Lebensqualit\u00e4t wie die F\u00f6rderung der sozialen Einbindung (Teilhabe) und der Kommunikation zu leisten.\n     Pflegebed\u00fcrftige spezi fisch wahrnehmen: \nPflegebed\u00fcrftige als homo demographicus, also als statistische Gr\u00f6\u00dfe und Motivations-punkt f\u00fcr Technikentwicklung zu begreifen, greift zu kurz. Der PB steht f\u00fcr eine indivi-duelle Bedarfserfassung, die anhand der Module des Begutachtungsinstruments (BI) in unterschiedlichen Lebensbereichen gef\u00f6r -\ndert werden kann. Bei der Technikentwick-lung kann dieser herangezogen werden, um die Bed\u00fcrfnisse strukturiert zu erheben und  sie durch geeignete Methoden zu vertiefen. Statt vermeintlicher Probleme \u201eder\u201d Pflege-bed\u00fcrftigen werden so echte Bedarfe spezifi-scher Gruppen adressiert.  \n     Bef\u00e4higende T echnologien entwickeln: Der PB  \norientiert sich an den F\u00e4higkeiten pflegebe-d\u00fcrftiger Menschen und folgt somit einem ressourcenorientierten Ansatz, der auch die Pr\u00e4vention einschlie\u00dft. Existierende Notfall- und Sicherheitstechnologien erf\u00fcllen wichtige Grundbed\u00fcrfnisse. Ein Fokus auf sie allein ver -\nnachl\u00e4ssigt M\u00f6glichkeiten, Verschlechterungen der Bed\u00fcrftigkeit vorzubeugen (Pr\u00e4vention) und rehabilitative Ma\u00dfnahmen zu f\u00f6rdern. Der PB er\u00f6ffnet damit Raum f\u00fcr die Entwicklung von Technologien, die anregen, ohne zu \u00fcber -\nfordern oder gar solche, die Spa\u00df machen.172 \n    Nutzenaspekte von Pflegetechnologien ein -\nordnen: Bis heute sind empirische Nachwei-\nse \u00fcber Effekte von Pflegetechnologien rar. Wenn es um die Frage geht, wie diese k\u00fcnf-tig finanziert werden k\u00f6nnen, m\u00fcssen Erfah-rungen gemacht und belastbare Messungen durchgef\u00fchrt werden. Zudem werden Krite-rien ben\u00f6tigt, die der Bewertung zugrunde gelegt werden k\u00f6nnen. Die mit dem BI for -\nmulierten Lebensbereiche, k\u00f6nnen als Teil der Nutzenerhebung herangezogen werden. Ei-nen ersten Ansatz hat VDI/VDE-IT mit IEGUS 2013  mit vorlegen k\u00f6nnen.\n15 \nDie Einbindung des PB und des BI in die nutzer -\nzentrierte Gestaltung (UCD) bietet die M\u00f6glich-keit, die Zielgruppe Pflegebed\u00fcrftige und ihre Bedarfe zu differenzieren sowie Bed\u00fcrfnissen, W\u00fcnschen und Einschr\u00e4nkungen eingehend Aufmerksamkeit zu schenken. \nAlle Perspektiven sind von Bedeutung \nWas bei der Entwicklung von Pflegetechnologi-en bislang vielfach unber\u00fccksichtigt bleibt, ist die (Nutzer-)Perspektive anderer an der Pflege beteiligter Personengruppen. Angeh\u00f6rige, Per -\nsonen und Organisationen innerhalb des Ge-sundheits- und Pflegewesens sowie Entschei-dungstr\u00e4ger aus Verwaltung und Politik \u2013 alle von ihnen haben auch eine eigenst\u00e4ndige Per -spektive auf die pflegerische Versorgung und verbinden damit unterschiedliche Anforderun-gen und Faktoren. \nGeht es um die Perspektive Angeh\u00f6riger, ist \nfestzustellen, dass \u00fcber ihre Bed\u00fcrfnisse und Le-benslagen wenig konkretes Wissen vorliegt\n16, \nwas f\u00fcr die Gestaltung von Technologie her -\nangezogen werden kann; gleiches gilt f\u00fcr die verschiedenen Personengruppen der profes-sionellen Pflege. Daraus resultieren unwei-gerlich auch Schwierigkeiten, wenn es um die Finanzierung neuer Pflegetechnologien geht. Stakeholder-Alignment \u2013 die Kl\u00e4rung wichtiger Nutzungsfragen aller in der Pflege relevanten Akteure \u2013 ist das Schlagwort, das k\u00fcnftig inhaltlich zu gestalten ist. Damit ist die Notwendigkeit f\u00fcr einen gemeinsamen Dialog zwischen allen Akteuren wie Entwicklerinnen und Entwicklern, Personen der Pflege, Verwal-tung und Politik angesprochen, die mit dem Ansatz der integrierten Forschung  Folge leis-ten (vgl. Beitrag von Stubbe und Wei\u00df in die-sem Band). \nTechnologien wandeln sich schnell,  \nMenschen hingegen langsam \nHaben Tocotronic Recht behalten mit ihrem Lied \n\u201eDigital ist besser\u201c? Die Antwort darauf lieferte ein Jahr sp\u00e4ter Fettes Brot mit dem Lied \u201eJein\u201d. Eine pauschale Antwort gibt es nicht. \nDie Technologisierung und Digitalisierung un-\ngeeigneter Prozesse in der Pflege birgt keinen Mehrwert f\u00fcr pflegebed\u00fcrftige Menschen, ihre Angeh\u00f6rigen oder Personen der professionel-len Pflege. Die ausgew\u00e4hlten Beispiele zeigen aber Technologiel\u00f6sungen, die den Menschen in den Mittelpunkt stellen und zur Steigerung von Sicherheit, Selbstbestimmtheit und Unter -\nst\u00fctzung beitragen k\u00f6nnen. \nEs gilt sich bewusst zu machen, dass die heuti-\nge Lebenserwartung vieler Menschen sowie die Anzahl der Pflegebed\u00fcrftigen im Verh\u00e4ltnis zu den Versorgungsressourcen ein anthropologi-sches Novum darstellen, die alle Beteiligten als Homo dialogus fordern.Abb. 3: Eine Technologie \u2013 unterschiedliche Ziele, ein Ziel \u2013 \nunterschiedliche WegeDer neue Pflegebed\u00fcrftigkeitsbegriff \u00a7  173\nWelche Ideen haben Pflegebed\u00fcrftige, Angeh\u00f6-\nrige und Pflegende f\u00fcr die Gestaltung der neu-en digitalen Versorgungswelt? Welche tech-nischen und nicht-technischen Kompetenzen brauchen sie, um diese aktiv gestalten k\u00f6nnen?\nAu\u00dfer Frage steht, dass Technik allein diese \nHerausforderungen nicht l\u00f6st. Menschen- bzw. nutzerzentrierte Gestaltungsans\u00e4tze stellen je-doch ein gro\u00dfes Repertoire zur Verf\u00fcgung, mit dem Prozesse der pflegerischen Versorgung allgemein und der Einsatz von Technik im Spe-ziellen sinnvoll gestaltet werden k\u00f6nnen. Der n\u00e4chste Schritt f\u00fcr eine nutzerzentrierte Gestal-tung in der Pflege liegt darin, Methoden und Formate f\u00fcr ein gemeinsames Forschen und Entwickeln mit vulnerablen Personengruppen, wie Demenzbetroffenen oder mobilit\u00e4tsbeein-tr\u00e4chtigen Menschen, zu finden. Sie sollten sich eignen, k\u00fcnftige Technologien gemeinsam zu entwerfen und zur Anwendung zu bringen. \nTrotz der dr\u00e4ngenden Herausforderungen in der \nPflege bedarf es also Geduld, gepaart mit ei-nem kontinuierlichen Dialog dar\u00fcber, wie wir \u2013  \nwenn wir in die Situation kommen \u2013 k\u00fcnftig pflegen und gepflegt werden wollen. Genauso wie eine Etablierung des neuen Pflegebed\u00fcrf-tigkeitsbegriffs ben\u00f6tigt die menschenzent-rierte Technikgestaltung in der Pflege Zeit und Raum f\u00fcr Erfahrungen.\n1 Harari, Yuval Noah (2015): Eine kurze Geschichte der Menschheit. Unter Mitarbeit von J\u00fcrgen Neubauer. 4. Aufl. M\u00fcnchen: Pantheon.\n2 Kruse, Andreas (2012): Generali Altersstudie 2013. Wie \u00e4ltere Menschen leben denken und sich engagieren. Orig.-Ausg. Frankfurt am Main: \n Fischer \nTaschenbuch (Fischer, 18935).\n3 Bundesweites Pflegenetzwerk (2014): Orientierungswerte zur Pflegezeitbemessung. www.pflegestufe.com/pflege/orientierungswerte-zur-pflege\n zeitbemessung [Zugriff am 2.5.2018].\n4 Gohde, J\u00fcrgen (2013): Reformbedarf der Pflegeversicherung. In: G&S Gesundheits- und Sozialpolitik 67 (4), S. 7\u201313. DOI: \n \n10.5771/1611-5821-2013-4-7.\n5 Norman, Donald A. (Hg.) (1986): User centered system design. New perspectives on human-computer interaction. Hillsdale NJ u. a.: Erlbaum.\n6 GOV .UK (2012): Government design principles. www.gov.uk/guidance/government-design-principles. [Zugriff am 2.5.2018].\n7 Statistisches Bundesamt (Destatis) (2015): Pflegestatistik 2013 - Pflege im Rahmen der Pflegeversicherung \u2013 Deutschlandergebnisse.\n8 Bertelsmann Stiftung (2012): Themenreport \u201ePflege 2030 - Was ist zu erwarten \u2013 was ist zu tun? www.bertelsmann-stiftung.de/fileadmin/files/\n BSt/Publikationen/Gr\nauePublikationen/GP_Themenreport_Pflege_2030.pdf. [Zugriff am 2.5.2018].\n9 \u00c4rzte Zeitung Online (Hg.) (2018): Smart Health: Digitalisierung verdient mehr Aufmerksamkeit. www.aerztezeitung.de/praxis_wirtschaft/e-he\n alth/article/958282/gastbeitr\nag-smart-health-digitalisierung-verdient-aufmerksamkeit.html [zugriff am 2.5.2018].\n Bundesministerium f\u00fcr Wirtschaft und Energie (BMWi) (2017): Monitoring Report Wirtschaft DIGITAL 2017. Hg. v. Bundesministerium f\u00fcr Wirt\n schaft und Energie (BMWi).\n www.bmwi.de/Redaktion/DE/Publikationen/Digitale-Welt/monitoring-report-wirtschaft-digital-2017.pdf?__blob=pu\n blicationFile&v=18  [Zugriff am 14.2.2018].\n10 Initiative Neue Qualit\u00e4t der Arbeit (INQA)- Offensive Gesund Pflegen- BGW (2018): Digitalisierung in der Pflege: Wie intelligente Technologien \n die \nArbeit profesionell Pflegender ver\u00e4ndern. www.inqa.de/SharedDocs/PDFs/DE/Publikationen/pflege-4.0.pdf?__blob=publicationFile&v=2 \n [Zugriff am 2.5.2018].\n \n IGES (2017): Digitalisierung in der ambulanten Pflege \u2013 Chancen und Hemmnisse\n. www.iges.com/e6/e1621/e10211/e15829/e21725/e21792\n e21794/attr_objs21796/LangfassungAbschlussberichtDigitalisierungPflege_IGES_ger\n.pdf [Zugriff am 2.5.2018].\n11 v. Bodelschwinghsche Stiftungen Bethel (Hg.) (2018): Assistive Technologie. www.altenhilfe-bethel.de/.cms/Unsere_Angebote/Altenheime/Senio\n renzentrum_Breipohls_Hof/Assistive_T\nechnologie/177 [Zugriff am 2.5.2018].\n12 Patock, Mareike (2017): Roboter-Robbe hilft Demenzkranken. Hg. v. Neue Westf\u00e4lische. www.nw.de/lokal/kreis_herford/spenge/21909856_\n Roboter\n-Robbe-hilft-Demenzkranken.html?em_cnt=21909856 [Zugriff am 2.5.2018].\n13 DAK-Gesundheit (2017): DAK Pflegeguide: Die App f\u00fcr pflegende Angeh\u00f6rige. So erleichtern wir Ihren Pflege-Alltag. www.dak.de/dak/leistun\n gen/app-dak-pflegeguide-1863678.html  [Zugriff am 8.5.2018).\n14 Wei\u00df, Christine; Lutze, Maxie; Compagna, Diego; Braeseke, Grit; Richter, Tobias; Merda, Meiko (2013): Unterst\u00fctzung Pflegebed\u00fcrftiger durch \n technische \nAssistenzsysteme. Abschlussbericht zur Studie. Hg. v. Bundesministerium f\u00fcr Gesundheit (BMG). VDI/VDE Innovation + Technik GmbH; \n IEGUS\n. Berlin, zuletzt gepr\u00fcft am 7.7.2016.\n15 Ebd. Wei\u00df, Christine et al. (2013)\n16 Hielscher, Volker; Kirchen-Peters, Sabine; Nock, Lukas; Ischebeck, Max (2017): Pflege in den eigenen vier W\u00e4nden: Zeitaufwand und Kosten. \n Pflegebed\u00fcrftige und ihre \nAngeh\u00f6rigen geben Auskunft, zuletzt gepr\u00fcft am 11.7.2017.174 \nMarkus Adelberg\nMarkus Adelberg ist seit 2017 als Berater in der VDI/VDE-IT im Bereich  \nDemografischer Wandel und Zukunftsforschung t\u00e4tig. Er absolvierte seine \nAusbildung zur examinierten Pflegefachkraft. Anschlie\u00dfend folgten meh-rere Jahre der Berufst\u00e4tigkeit in der vollstation\u00e4ren gerontopsychiatrischen  \nBetreuung und Versorgung. 2014 absolvierte Markus Adelberg seinen B. Sc. im Studiengang Gesundheits- und Pflegemanagement mit dem Schwerpunkt Assistenzsysteme im Alter. Danach folgte 2016 der erfolgreiche Abschluss  \n(M. Sc.) an der medizinischen Fakult\u00e4t der Martin Luther Universit\u00e4t Halle in dem Studiengang Gesundheits- und Pflegewissenschaft. \n \nDr. Claudia Baumann\nClaudia Baumann ist Biomedizinerin und promovierte an der Humboldt Uni-\nversit\u00e4t Berlin im Bereich der Experimentellen Immunologie. Dabei setzte sie sich mit k\u00f6rpereigenen Alarmsignalen auseinander, die bei Virusinfektionen freigegeben werden, um die Zellen der Immunabwehr zu aktivieren. Seit 2017 ist sie als Beraterin in der VDI/VDE-IT im Bereich Kommunikationssys-teme, Mensch-Technik-Interaktion, Gesundheit t\u00e4tig und ber\u00e4t in Fragen der Gesundheitsforschung und -versorgung.\n \nDr. Sven Beyer\nSven Beyer ist Wirtschaftsingenieur mit technischer Fachrichtung Nachrich-\ntentechnik. Er promovierte im Bereich Finanzierung und war vor seiner T\u00e4tig-keit bei VDI/VDE Innovation + Technik GmbH Partner bei einer internationa-len Wirtschaftspr\u00fcfungsgesellschaft. Seit 2017 ist er Abteilungsleiter f\u00fcr die Bereiche Rechnungswesen, Einkauf und Objektverwaltung.\n \nAlfons Botthof\nAlfons Botthof ist Physiker, Direktor des Instituts f\u00fcr Innovation und Tech-\nnik sowie Leiter des Bereichs Gesellschaft und Innovation in der VDI/VDE Innovation + Technik GmbH. Seine Arbeitsschwerpunkte umfassen ange-wandte Innovationsforschung bzw. Politikberatung zu Hochtechnologiethe-men, die Konzeption, Koordination und Durchf\u00fchrung Innovationsprozesse  \nunterst\u00fctzender Ma\u00dfnahmen, Begleitforschungen sowie die Evaluation staatlicher F\u00f6rderungsma\u00dfnahmen. Alfons Botthof leitete Begleitforschun-gen u. a. zu Mikrosystemtechnik und autonomen Systemen und ist einge-bunden in Prozesse und Netzwerke zum Zukunftsprojekt Industrie 4.0 der Bundesregierung. Des weiteren unterst\u00fctzt er das BMBF bei der Bearbeitung strategischer Themen.Autorinnen und Autoren\n40 JahreAutorinnen und Autoren  \u00a7 175\n \nPeter Dortans\nPeter Dortans ist seit 1999 einer der Gesch\u00e4ftsf\u00fchrer der VDI/VDE Innovation \n+ Technik GmbH. Er studierte an der Universit\u00e4t K\u00f6ln Betriebswirtschaftslehre und war danach mehrere Jahre im In- und Ausland f\u00fcr die ESSO AG in den Bereichen Marketing und Controlling t\u00e4tig. 1994 \u00fcbernahm Peter Dortans bei der VDI/VDE-IT die Leitung der Abteilung Innovationsmanagement und war ab 1998 Leiter des Bereiches Betriebswirtschaftliche Beratung. In seiner Position als Gesch\u00e4ftsf\u00fchrer ist er u. a. f\u00fcr die Themengebiete Strategische Unternehmensentwicklung, Bildung und Wissenschaft sowie Demografi-scher Wandel und Zukunftsforschung zust\u00e4ndig. \n \nDr. Anne Dwertmann\nAnne Dwertmann studierte Humanbiologie und promovierte in der moleku-\nlaren Krebsforschung. Seit 2013 arbeitet sie bei der VDI/VDE Innovation + Technik GmbH als wissenschaftliche Mitarbeiterin f\u00fcr den Bereich Kommuni-kationssysteme, Mensch-Technik-Interaktion und Gesundheit. Sie ist Projekt-leiterin in der Projekttr\u00e4gerschaft zur Wirkstoffforschung- und -entwicklung f\u00fcr das Referat \u201eForschung f\u00fcr globale Gesundheit\u201c im Bundesministerium f\u00fcr Bildung und Forschung und ber\u00e4t das Bundesgesundheitsministerium in Fragen zur personalisierten Medizin.\n \nDr. Anne Endmann\nAnne Endmann ist Biotechnologin und Beraterin im Bereich Kommunikati-\nonssysteme, Mensch-Technik-Interaktion und Gesundheit. Im Anschluss an eine Promotion am Helmholtz-Zentrum f\u00fcr Infektionsforschung in Braun-schweig arbeitete sie mehrere Jahre als Projektleiterin in der Impfstoffent-wicklung bei einem Biotechnologieunternehmen. Seit 2015 ist sie bei der VDI/VDE-IT t\u00e4tig und ber\u00e4t im Auftrag des Bundesministeriums f\u00fcr Bildung und Forschung zur Ausgestaltung von F\u00f6rderma\u00dfnahmen im Bereich der pharmazeutischen Forschung und Entwicklung in Wissenschaft und Wirt-schaft mit dem Schwerpunkt der Translation von Forschungsergebnissen in die Gesundheitsversorgung.\n \nDr. Markus Gaa\u00df\nMarkus Gaa\u00df ist Diplom-Physiker und seit 2015 als Berater in der VDI/VDE In-\nnovation + Technik GmbH im Bereich Industrielle Forschung und Entwicklung t\u00e4tig. Zuvor promovierte er an der Universit\u00e4t Regensburg unter anderem im Kontext des Sonderforschungsbereichs \u201eSpinph\u00e4nomene in reduzierten Dimensionen\u201c bzw. des Graduiertenkollegs \u201eElectronic Properties of Carbon Based Nanostructures\u201c, wo er sich mit quantenmechanischen Effekten beim Stromtransport in Kohlenstoffnanostrukturen besch\u00e4ftigte. Anschlie\u00dfend war er wissenschaftlicher Mitarbeiter am Bayerischen Zentrum f\u00fcr Ange-wandte Energieforschung e. V. und forschte dort zu Themen wie W\u00e4rme-speicherung und rationellem Energieeinsatz.\n176 \nDr. Tobias Hainz\nTobias Hainz ist Philosoph mit einer Spezialisierung in der biomedizinischen \nEthik und promovierte mit einer Arbeit zur ethischen Bewertung von hypo-thetischen Technologien zur Verl\u00e4ngerung der menschlichen Lebensspanne. Seit 2017 ist er als Berater im Bereich Kommunikationssysteme, Mensch-Tech-nik-Interaktion, Gesundheit der VDI/VDE Innovation + Technik GmbH t\u00e4tig. Zuvor forschte er als Postdoktorand zur Ethik neuartiger und zuk\u00fcnftiger Biotechnologien sowie zu B\u00fcrgerbeteiligung in der medizinischen Forschung und Innovation.\nDr. Ernst Hartmann\nErnst Hartmann leitet den Bereich Bildung und Wissenschaft und geh\u00f6rt als Gr\u00fcndungsdirektor der Leitung des iit an. Er besch\u00e4ftigt sich mit der Digita-lisierung in Forschung und Lehre, der wissenschaftlichen Weiterbildung und der Arbeitsgestaltung f\u00fcr Industrie 4.0. Er ist Arbeits- und Organisationspsy-chologe, lehrt Arbeitssystemgestaltung an der RWTH Aachen und war vor seiner T\u00e4tigkeit bei der VDI/VDE-IT unter anderem als Arbeitspsychologe in der Industrie t\u00e4tig.\nDr. Tatjana Heinen-Kammerer \nDr. Tatjana Heinen-Kammerer ist Volkswirtin mit sozialwissenschaftlicher Richtung und seit 2017 als Seniorberaterin in der VDI/VDE Innovation + Technik  \nGmbH im Bereich Gesundheit t\u00e4tig. Zuvor arbeitete sie lange Zeit in der Krebs-fr\u00fcherkennung und der Versorgungsforschung, wie auch in der Medizin-  \ntechnik und einem f\u00fchrenden Verband der pharmazeutischen Industrie. Ihre Expertise liegt dar\u00fcber hinaus in der Nutzenbewertung, der Gesundheits-  \nsystemforschung und Gesundheits\u00f6konomie. Sie publizierte eine Vielzahl von wissenschaftlichen Beitr\u00e4gen und Artikeln in der Versorgungsforschung. \nDr. Julia Kaltschew\nJulia Kaltschew ist Physikerin und promovierte an der ETH Z\u00fcrich \u00fcber  \nMagnetismus in Halbleiterstrukturen. Seit 2010 ist sie als Beraterin bei der VDI/VDE-IT t\u00e4tig. Die Schwerpunkte ihrer Arbeit liegen auf der Begutach-tung und Begleitung von Projekten in den Themenfeldern Elektroniksysteme,  \nautomatisiertes Fahren und Materialeffizienz f\u00fcr verschiedene Bundesminis-terien und Landeseinrichtungen. Als Autorin ist sie an Ver\u00f6ffentlichungen im Bereich Materialeffizienz und Positionspapieren zum Thema Elektromobilit\u00e4t und automatisiertes Fahren beteiligt.\nDr. Marcel Kappel\nMarcel Kappel ist seit 2015 als wissenschaftlicher Berater bei der VDI/VDE-IT im Bereich \u201eKommunikationssysteme und Mensch-Technik-Interaktion\u201c f\u00fcr das Bundesministeriums f\u00fcr Bildung und Forschung und f\u00fcr den Modernit\u00e4tsfonds des Bundesministeriums f\u00fcr Verkehr und digitale Infrastruktur t\u00e4tig. Zuvor war er drei Jahre als Entwicklungsingenieur f\u00fcr Fahrzeugakustik und physikalische Komfortbewertung besch\u00e4ftigt. An der Universit\u00e4t Potsdam promovierte er im Bereich der angewandten Physik kondensierter Materie mit Arbeiten auf den Gebieten Akustik, Sensorik und Physik der Musikinstrumente.\nAutorinnen und Autoren \u00a7  177\nDr. Moritz Kirste\nMoritz Kirste ist promovierter Physiker und in der VDI/VDE Innovation + Tech-\nnik GmbH als Berater im Bereich Kommunikationssysteme, Mensch-Tech-nik-Interaktion, Gesundheit t\u00e4tig. Er besch\u00e4ftigt sich mit den Themen k\u00fcnstliche Intelligenz, Robotik, Data Science und innovativen, digitalen Tech-nologien. Vor seiner T\u00e4tigkeit in der VDI/VDE-IT erforschte er in der Grund-lagenforschung am Fritz-Haber-Institut der Max-Planck-Gesellschaft und der Academia Sinica in Taiwan physikalische und chemische Prozesse in der Gas-phase. Moritz Kirste ist Gastdozent an der Beuth Hochschule f\u00fcr Technik Berlin und Rezensent f\u00fcr Fachzeitschriften. \nRoman Korzynietz\nRoman Korzynietz ist seit 2017 als Berater in der VDI/VDE Innovation + Tech-nik GmbH im Bereich Zukunftstechnologien und Europa t\u00e4tig. Als Diplom-In-genieur f\u00fcr Maschinenbau - Erneuerbare Energien mit langj\u00e4hriger internati-onaler Erfahrung in der Projektentwicklung und Forschung ber\u00e4t, analysiert und forscht er schwerpunktm\u00e4\u00dfig in den Themenbereichen Erneuerbare Energien, Energiewende und Nachhaltigkeit. Zuvor besch\u00e4ftigte er sich mit der Entwicklung und Nutzung solarer Hochtemperatur-Technologien.\nMiriam Kreibich\nMiriam Kreibich ist wissenschaftliche Mitarbeiterin und Stellvertretende Be-reichsleiterin im Bereich Gesellschaft in der VDI/VDE Innovation + Technik GmbH. Als Seniormanagerin ber\u00e4t sie \u00f6ffentliche Auftraggeber zu  innovati-onspolitischen Themen, insbesondere zu Fragen des Wissens- und Erkennt-nistransfers und der Sozialen Innovationen. Miriam Kreibich hat Soziologie und Osteuropawissenschaften an der Freien Universit\u00e4t Berlin studiert. Vor dem Studium war sie freie Unternehmerin und Redakteurin. \nStephan Krumm\nStephan Krumm studierte Wirtschaftsingenieurwesen in den Fachrichtungen Elektrotechnik und Medizintechnik in Ilmenau, Berlin und Barcelona. Seit 2017 arbeitet er bei der VDI/VDE-IT als wissenschaftlicher Mitarbeiter und ber\u00e4t das Bundesministerium f\u00fcr Gesundheit in Fragen rund um die Themen eHealth und digitale Technologien. Vor dieser T\u00e4tigkeit war er als Berater am IGES Institut im Bereich Krankenversicherung t\u00e4tig und arbeitete u. a. an der Entwicklung von Benchmarkingans\u00e4tzen zum Vergleich des Leistungsma-nagements innerhalb der GKV.\nDr. Hannes Kurtze\nHannes Kurtze ist promovierter Physiker. Bis 2012 forschte er als Doktorand und Postdoc zu Halbleiter-Nanostrukturen an der TU Dortmund. Nebenher stu-dierte er Technikphilosophie an der TU Darmstadt. Seit 2012 ist er bei der VDI/VDE Innovation + Technik GmbH. Im Jahr 2014 war er im Rahmen einer Perso-nalausleihe beim Bundesministerium f\u00fcr Bildung und Forschung t\u00e4tig. Derzeit arbeitet Hannes Kurtze bei der VDI/VDE-IT f\u00fcr das BMBF u. a. zum Thema Digi-talisierung der Wissenschaft und zur Validierung des wissenschaftlichen Innova-tionspotenzials mit Schwerpunkt Ingenieurwissenschaften und Physik.\n178 \n \nDr. Lisette Leonhardt\nLisette Leonhardt ist Biochemikerin und in der VDI/VDE Innovation + Technik \nGmbH beratend f\u00fcr Projekttr\u00e4gerschaften des Bundesministeriums f\u00fcr Bil-dung und Forschung sowie des Bundesministeriums f\u00fcr Gesundheit t\u00e4tig. Im Rahmen ihrer Promotion am Leibniz-Zentrum f\u00fcr Medizin und Biowissen-schaften besch\u00e4ftigte sie sich mit der allergischen Immunantwort der Lunge. Anschlie\u00dfend war sie mehrere Jahre in einem zur BASF-Gruppe geh\u00f6renden Unternehmen als Projektleiterin f\u00fcr Metabolite Profiling Studien unterschied-lichster Indikationsgebiete t\u00e4tig. \n \nMaxie Lutze\nMaxie Lutze ist Informatikerin und Human-Factors Expertin. Sie ber\u00e4t und \nforscht seit 2011 im Bereich \u201eDemografischer Wandel und Zukunftsfor -\nschung\u201c. Ihre Aufgabenschwerpunkte liegen in der fachlichen Begut-achtung und Betreuung nationaler und europ\u00e4ischer Projekte sowie der Entwicklung innovations- und technologiepolitischer Ma\u00dfnahmen. Sie verantwortet f\u00fcr das Bundesministerium f\u00fcr Bildung und Forschung die Ausgestaltung der Initiative \u201ePflegeinnovationen 2020\u201c und begleitet das Cluster \u201eZukunft der Pflege\u201c.\n \nDr. Jan Philipp Meyburg\nJan Philipp Meyburg ist seit 2017 als Berater in der VDI/VDE Innovation \n+ Technik GmbH im Bereich Kommunikationssysteme, Mensch-Technik-  \nInteraktion, Gesundheit t\u00e4tig und hospitiert derzeit im Bundesminis-  \nterium f\u00fcr Bildung und Forschung in Bonn. Zuvor studierte er Design und Chemie und untersuchte in der physikalischen Chemie Energiefl\u00fcsse und Umladungen infolge von oberfl\u00e4chenkatalysierten Reaktionen mit Me-tall-Isolator-Metall-D\u00fcnnschichtsystemen. Als Freelancer legte er seinen gestalterischen Fokus auf kartografische Visualisierungen, Informations-grafik und Typografie.\n \nJohannes Mock\nJohannes Mock studierte Philosophie an der Philipps-Universit\u00e4t Marburg \nund der Technischen Universit\u00e4t Dresden. W\u00e4hrend des Studiums setzte er sich unter anderem mit Technikphilosophie, Wissenschaftstheorie und Um-weltethik auseinander. Seine aktuellen Arbeitsschwerpunkte sind Technik-  \nethik sowie die Auseinandersetzung mit Human Enhancement-Technologien.  \nSeit Januar 2018 ist bei der VDI/VDE-IT als Projektassistent im Bereich Ge-sellschaft und Innovation t\u00e4tig.\n Autorinnen und Autoren \u00a7 179\nDr. Karsten Rapsch\nKarsten Rapsch ist seit 2017 als Berater in der VDI/VDE Innovation + Technik \nGmbH im Bereich Kommunikationssysteme, Mensch-Technik-Interaktion, Gesundheit t\u00e4tig und arbeitet prim\u00e4r in Projekttr\u00e4gerschaften f\u00fcr das Bun-desministerium f\u00fcr Bildung und Forschung. Zuvor promovierte und arbeite-te er an der Technischen Universit\u00e4t Berlin und dem Fraunhofer Institut f\u00fcr Zelltherapie und Immunologie zu den Themen Antibiotikaresistenzen, inno-vative Wirkstoffmolek\u00fcle f\u00fcr die pharmazeutische Entwicklung und Schnell-diagnostika f\u00fcr das on-site monitoring von bakteriellen Kontaminationen und Infektionen. \n \nDr. Claudia Ritter \nClaudia Ritter ist seit 2008 in der VDI/VDE Innovation + Technik GmbH \nim Bereich Innovation und Kooperation t\u00e4tig und als Projektleiterin und Seniorberaterin mit den Themen Mittelstandf\u00f6rderung, Vernetzung von Wirtschaft und Wissenschaft sowie Technologietransfer im Auftrag des BMWi betraut. Sie promovierte an der Humboldt-Universit\u00e4t zu Berlin in physikalischer Chemie und forschte als Post-Doc in den USA an Themen zur Oberfl\u00e4chencharakterisierung und Nanotribologie. Als Autorin ist sie an Ver\u00f6ffentlichungen und Studien zu Materialeffizienz, Netzwerken, Trends und Innovationen beteiligt.\n \nDr. Antonia Schmalz\nAntonia Schmalz ist Physikerin und promovierte 2012 am Max-Planck-Institut \nf\u00fcr Quantenoptik. In der M\u00fcnchner Gesch\u00e4ftsstelle der VDI/VDE-IT arbeitet sie seitdem als wissenschaftliche Mitarbeiterin in verschiedenen Projekttr\u00e4-gerschaften rund um das Thema Elektronische Systeme, unter anderem mit den Schwerpunkten Electronic Design Automation und Halbleiterfertigung.\n \nKonstantin Schneider \nKonstantin Schneider absolvierte sein Studium der Geographie an der Phi-\nlipps-Universit\u00e4t Marburg. Seit \u00fcber 10 Jahren besch\u00e4ftigt er sich mit den Themen Clustern, Innovationsf\u00f6rderung und Regionalentwicklung. Zudem arbeitete er in seiner Zeit bei der Medien- und Filmgesellschaft Baden-W\u00fcrt-temberg an der Schnittstelle zwischen Digital- und Kreativwirtschaft. Seit 2014 ist er als Projektleiter bei der VDI/VDE-IT am Standort Stuttgart t\u00e4tig. Neben der stellvertretenden Leitung der Cluster-Agentur Baden-W\u00fcrttem-berg wirkt er in verschiedenen Projekten zum Thema Smart Specialisation und regionaler Standortentwicklung mit. \n180 \nDr. Patrick Schweitzer\nPatrick Schweitzer ist seit 2014 als Berater in der VDI/VDE Innovation + Tech-\nnik GmbH im Bereich Kommunikationssysteme, Mensch-Technik-Interaktion, Gesundheit t\u00e4tig. Er besch\u00e4ftigt sich haupts\u00e4chlich mit Projekten und Fragen rund um IT-Sicherheit und Privacy. Zuvor arbeitete er bei der X-Lane GbR als IT-Consultant, nachdem er an der Universit\u00e4t Luxemburg zu dem Thema Bedrohungsanalysen in der IT-Sicherheit promovierte.\n \nDr. Julian Stubbe\nJulian Stubbe ist seit 2017 als Berater in der VDI/VDE-IT im Bereich  \nDemografischer Wandel und Zukunftsforschung t\u00e4tig. Zuvor promovierte \ner an der Technischen Universit\u00e4t Berlin im Graduiertenkolleg \u201eInnova-  \ntionsgesellschaft heute\u201c, wo er sich mit Fragen gesellschaftlicher, wissen-schaftlicher und k\u00fcnstlerischer Innovationen auseinandersetzte. Er ver\u00f6f-fentlichte und begutachtete Aufs\u00e4tze zu Themen wie der gesellschaftlichen Bedeutung technischer Kreativit\u00e4t sowie zu methodischen Fragen der Inno-vationsforschung.\n \nDr. Eva Suhren\nEva Suhren ist Apothekerin und Gesundheitswissenschaftlerin. In den letzten \nJahren war sie als Projektkoordinatorin in der internationalen Zusammen-arbeit bei verschiedenen Hilfsprojekten in Haiti sowie in der \u00f6ffentlichen Apotheke t\u00e4tig. Eva Suhren hat in der onkologischen Grundlagenforschung promoviert und eine qualitative Masterstudie im Bereich subjektives Gesund-heitsempfinden erarbeitet. Seit 2017 ist sie als fachliche Beraterin in der  \nVDI/VDE Innovation + Technik GmbH zum Thema Gesundheit t\u00e4tig.\n \nCarolin Thiem\nCarolin Thiem unterst\u00fctzt die VDI/VDE Innovation + Technik GmbH im Be-\nreich Gesellschaft und Innovation. Als fachliche Beraterin besch\u00e4ftigt sie sich mit den Auswirkungen des digitalen Wandels auf die Gesellschaft und mit der F\u00f6rderung von Sozialen Innovationen. Sie verfolgt weiterhin ihre Promo-tion in Wissenschafts- und Technikforschung an der TU M\u00fcnchen zu \u201eNeuen \u00d6ffentlichkeiten\u201c. Zuvor war sie t\u00e4tig in der Innovations- und Design-  \nForschung bei der HYVE AG und der Service Innovation Labs GmbH.\n \nD\u00e9sir\u00e9e Tillack\nD\u00e9sir\u00e9e Tillack ist Diplom-Journalistin und wechselte im Jahr 2017 als  \nBeraterin zum Institut f\u00fcr Innovation + Technik in der VDI/VDE Innovation \n+ Technik GmbH, nachdem sie sechs Jahre lang Referentin in der Abteilung \u00d6ffentlichkeitsarbeit war. Dort konzipierte und begleitete sie PR-Aktivit\u00e4ten und Veranstaltungen vor allem f\u00fcr das Bundesministerium f\u00fcr Bildung und Forschung sowie das Bundesministerium f\u00fcr Wirtschaft und Energie. Zuvor hatte D\u00e9sir\u00e9e Tillack bei Turner Broadcasting System (u. a. CNN International)  \ngearbeitet.\nAutoren und Autorinnen \u00a7  181\nChristine Wei\u00df\nChristine Wei\u00df studierte Maschinenbau mit Fachrichtung Biomedizinische \nTechnik an der TU Berlin. Im Rahmen des Studiums arbeitete sie als Werks-studentin bei Siemens Medical Systems in den USA und in Erlangen. An-schlie\u00dfend sammelte Christine Wei\u00df f\u00fcnf Jahre Industrieerfahrung als me-dizintechnische Entwicklungsingenieurin bei B. Braun Melsungen. Seit 2000 arbeitet sie f\u00fcr die VDI/VDE-IT als wissenschaftliche Mitarbeiterin f\u00fcr Gesund-heit und Demografie und ist seit 2011 Seniormanagerin und stellvertretende Leiterin des Bereichs Demografischer Wandel und Zukunftsforschung.\n \nDr. Jan Wessels\nJan Wessels ist Politologe und arbeitet seit 2000 bei der VDI/VDE Innovation \n+ Technik GmbH. Seine Schwerpunkte liegen in der Evaluation von For -\nschungs-, Technologie- und Innovationspolitik sowie in der strategischen Politikberatung zu Themen der Innovationspolitik, insbesondere f\u00fcr das Bundesministerium f\u00fcr Bildung und Forschung und das Bundesministerium f\u00fcr Wirtschaft und Energie. Jan Wessels ist Sprecher des Arbeitskreises For -\nschungs-, Technologie- und Innovationspolitik der DeGEval \u2013 Gesellschaft f\u00fcr Evaluation. \n \nDr. Werner Wilke\nWerner Wilke ist promovierter Physiker und seit 1999 einer der Gesch\u00e4fts-\nf\u00fchrer der VDI/VDE Innovation + Technik GmbH. Sein Studium absolvierte er an der Technischen Universit\u00e4t Berlin, war danach als wissenschaftlicher Mitarbeiter am Fritz-Haber-Institut der Max-Planck-Gesellschaft, bevor er bei der Auergesellschaft GmbH die Leitung der Abteilung Product Management \u00fcbernahm. Seit 1995 ist er bei der VDI/VDE-IT t\u00e4tig, zun\u00e4chst als Abteilungs-leiter, dann als Leiter des Bereiches Technik. In seinem Zust\u00e4ndigkeitsbereich als Gesch\u00e4ftsf\u00fchrer der VDI/VDE-IT liegen u. a. die Themengebiete Kommu-nikationssysteme, Mensch-Technik-Interaktion, Digitalisierung, industrielle Forschung und Innovation sowie Zukunftstechnologien. \n \nDr. Stefan Wolf\nStefan Wolf ist Ingenieur und seit 2018 als Berater in der VDI/VDE Innovation \n+ Technik GmbH im Bereich Zukunftstechnologien und Europa t\u00e4tig. Im  \nAuftrag von Kunden aus Politik und Wirtschaft liefert er Expertise zu Inno-vationsfragen in den Themenbereichen Energiewende und Elektromobilit\u00e4t. Zuvor promovierte er an der Universit\u00e4t Stuttgart auf dem Gebiet der Ener -\ngiesystemanalyse. \nF\u00fcr die Mitarbeit am Peer-Review danken wir Alfons Botthof, Dr. Marc Bovenschulte, Dr. Claudia Brunnlieb, Dr. Kristian D\u00f6brich, Peter Dortans, Dr. Anne Dwertmann, Dr. Anne Endmann, Wolfram Gro\u00df, Volker H\u00e4rtwig, Doris Johnsen, Dr. Katja Karrer-Gauss, Stephan Krumm, Ulrich Kuchelmeister,  \nDr. Lisette Leonhardt, Dr. Joachim Lepping, Dr. Gerd Meier zu K\u00f6cker, Lasse Reising, Dr. Michael Schubert, Dr. Markus Sch\u00fcrholz, Uwe Seidel, Dr. Eva Suhren, Guido Zinke.182 \nBildnachweise\nS. 12:  \u00a9 Ingo Bartussek/Fotolia\nS. 24:\n \u00a9 Ever\nett Historical/shutterstock\nS. 30:\n \u00a9 Lisette Leonhar\ndt\nS. 43:\n \u00a9 ibr\neakstock/Fotolia\nS. 57:\n \u00a9 J\u00fcrgen Howaldt\nS. 81:\n \u00a9 W\navebreakmedia /iStock\nS. 85:\n \u00a9 BASF\nS. 86:\n links: \u201eHaber\n, Fritz (1868 \u2013 1934)\u201c von ETH-Bibliothek Z\u00fcrich, Bildarchiv \n (http://ba.e- pics.ethz.ch/latelogin.jspx?r\necords=:34054&r=152751823 0202\n #1527518355446_4) / Fotograf: Photographisches Institut der ETH Z\u00fcrich\n \n / PI_29-C-0097 / CC \nBY-SA (https://creativecommons.org/licenses/by-sa/4.0/deed.de)\n r\nechts: \u00a9 BASF\nS. 99:\n \u00a9 Jan Braun/ Heinz Nixdorf MuseumsForum\nS. 101:\n \u201eNewton and iPhone: ARM and ARM\u201c von Blake Patterson \n \n(https://www.flickr.com/photos/35448539@N00/2379207825/) \n CC BY 2.0 (https://cr\neativecommons.org/licenses/by/2.0/deed.de)\nS. 110:\n \u00a9 Zeiss\nS. 119:\n \u00a9 Stephan Hahn\nS. 134:\n \u00a9 Ever\nett Historical/shutterstock\nS. 147:\n \u00a9 Meiyi524/iStock\nS. 159:\n \u201eX-ray of the bones of a hand with a ring on one finger\u201c von W\nilhelm Konrad \n \n von R\u00f6ntgen (https://wellcomecollection.org/works/zj6wp4ad) CC BY \n \n(https://creativecommons.org/licenses/by/4.0/)\nS. 172: \u00a9 designed by Dooder / Freepik\nS. 174 ff.: \u00a9 Anke JacobS. 177:\n Foto Kr\neibich \u00a9 Annette KorollImpressum \u00a7  183\nImpressum \nHerausgeber: \nVDI/VDE Innovation + Technik GmbHHauptsitz in Berlin: Steinplatz 1, 10623 Berlinin M\u00fcnchen: Heimerstra\u00dfe 37, 80339 M\u00fcnchenin Dresden: Kramergasse 2, 01067 Dresdenin Bonn: Dreizehnmorgenweg 36, 53175 Bonnin Stuttgart (Projektb\u00fcro): Willi-Bleicher-Stra\u00dfe 19, 70174 Stuttgart\nRedaktion, Gestaltung und Realisation: \nVDI/VDE Innovation + Technik GmbH, Agentur 33 GmbH\nDruck: \nSch\u00f6ne Drucksachen GmbH\nStand: \nJuni 2018ISBN: 978-3-89750-191-1", "language": "PDF", "image": "PDF", "pagetype": "PDF", "links": "PDF"}