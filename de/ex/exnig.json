{"title": "PDF", "author": "PDF", "url": "https://www.heise.de/ix/downloads/05/2/4/5/3/2/6/2/rz-infrastruktur-2018-02.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "id": "PDF", "license": "PDF", "body": "PDF", "comments": "PDF", "commentsbody": "PDF", "raw_text": "PDF", "text": "Eine Themenbeilage der Heise Medien GmbH & Co. KG\nRECHENZENTREN \nUND INFRASTRUKTUR\nSERVER, KABEL, CLOUD-COMPUTING\u2161\n2018\nWo der Mainframe-Codemunter weiterl\u00e4uft\npowered by \u2b1b www.rechenzentren-infrastruktur.deHybrid Cloud: Warum wir uns in \nProvisorien einrichtenStorage: Welche Flash-Speicher klug \ngenug f\u00fcr KI sindRZ-Design: Wann sich Gleichstrom \nim Datacenter auszahlt100GbE: Was bei Multimode-Messungen \nmit MTP/MPO giltSensorik: Wie Live-Umgebungsdaten \nins DCIM einflie\u00dfenAll-IP: Wohin ISDN-Anlagen ohne \nISDN umziehen \nRechenzentren und Infrastruktur \u2161/2018 3EDITORIAL\nZum Beispiel der Deutsche Bauernverband.Dort ist es l\u00e4ngst klar, dass die Fl\u00e4chenfarmenin Mecklenburg-Vorpommern ganz andere In-teressen haben, als eine Allg\u00e4uer Almwirt-schaft. In der RZ-Landschaft sieht es ganz\u00e4hnlich aus. Auch hier arbeiten Hyperscalerund High-Performance-Datacenter oft mit ei-genen L\u00f6sungen und profitieren von Skalen-effekten, wo \u201enormale\u201c Rechenzentren sys-tembedingt an ihre Grenzen sto\u00dfen. Initiativen wie OCP (Open Compute Project)und Open19 haben sich aber vorgenommen,den Vendor Lock-in aufzubrechen und ent-wickeln eigene Hardware-Designs, die aufEnergieeffizienz und optimale Total Cost ofOwnership getrimmt sind. Ein interessanterNebeneffekt: Gleichstrom wird dadurch zueiner erw\u00e4genswerten Alternative (Seite 22).Ein Beispiel zeigt au\u00dferdem, dass sich inSachen Green IT viel durch eine \u00fcberlegteRZ-Bauweise erreichen l\u00e4sst (Seite 9).Au\u00dferdem haben die gro\u00dfen Datenbank-transakteure, also Banken, Versicherer etc.,ihre Mainframes keineswegs ausgemustert \u2013im Gegenteil: IBM ist mit dem z14-Absatzziemlich zufrieden und gewinnt sogar neueFans, berichtet Ariane R\u00fcdiger im Schwer-punkt dieser Beilage (Seite 6). Die Kern -argumente liegen bei Parallelperformanz,Ausfallsicherheit \u2013 und seit dem j\u00fcngstenDSGVO-Wirbel auch wieder bei der Informa-tionssicherheit. \u00dcbrigens lie\u00dfe sich sogarohne neue Hardware bew\u00e4hrter Gro\u00dfrechner-code ganz ohne Programmieraufwand umzie-hen: auf Software-defined Mainframes imContainer (Seite 4).Noch ein weiterer Trend dr\u00fcckt in die Data-center: Artificial Intelligence. Auf Compu-ting-Seite ist das ganz gut abzuarbeiten,daf\u00fcr sorgt vor allem Nvidia mit spezialisier-ten GPU-Chips. Anders sieht es auf derSpeicherseite aus, denn k\u00fcnstliche Intel -ligenz m\u00f6chte unstrukturierte Workloadsschneller parallel abarbeiten, als eine serielle Storage-Architektur Daten liefernkann. Diese \u201ePerformancel\u00fccke zwischenRechen- und Speicherressourcen\u201c l\u00e4sst sichmit Flash-basierten Objektspeicherl\u00f6sun-gen, NVMe/NVMe-oF und Shared Accelera-ted Storage aber schlie\u00dfen (Seite 12). Zu-gleich sollten sich RZ-Betreiber bewusstmachen, dass die meisten der derzeitigenGesch\u00e4ftsmodelle zwar nach Hybrid Cloudsund Multi-Clouds verlangen, dass das abereine zeitlich befristete Zwischenl\u00f6sung blei-ben wird: \u201eHybrid-Clouds sind ein Mittel derWahl auf bestimmte Zeit; gehen wir hier malvon einem Zeitraum von vier bis sechs Jah-ren aus\u201c, sagt Axel Oppermann in seinerMarktanalyse ab Seite 10. Dazu gibt es noch handfeste Praxistipps:wie man Sensortechnik f\u00fcr Umgebungs -daten bruchlos ins DCIM integriert (Seite 16)und wie man 100-Gigabit-Ethernet-Mehr -faserstrecken mit MTP/MPO-Steckern richtigmisst (Seite 24). Zum Schluss das Wetter f\u00fcr Landwirte: Wer-fen Sie einfach einen Blick auf mundiwebser-vices.com \u2013 dort stehen die Weltraumdatendes EU-Erdbeobachtungsprogramms Coper-nicus (Seite 20) f\u00fcr Anwender und Entwicklermit eigenen Ideen bereit.\nThomas Jannot Die Gro\u00dfen rechnen anders \nInhalt\nGro\u00dfrechner im ContainerSoftware-defined Mainframes          4Mehr MIPS auf den Mainframe!Die Zentralrechner sind zur\u00fcck         6Turm mit LuftschachtEnergieeffizienz je nach Bauweise                             9Der l\u00e4ngere ZwischenschrittDerzeit setzt alles auf Hybrid Clouds                                 10Klug genug f\u00fcr k\u00fcnstlicheIntelligenzKI-Anforderungen und Speicherstruktur                             12Anlagenanschl\u00fcsse bekommen AufschubPBX-L\u00f6sungen f\u00fcr All-IP-Telefonie                          14Intelligente Messtechnikverhindert Ausf\u00e4lleDCIM mit verteilter Sensorik           16Der Cloud-AtlasWeltraumdaten per Copernicus DIAS                             20Einmal umwandeln gen\u00fcgtRZ-Designs f\u00fcr Gleichstromversorgung                   22Zw\u00f6lf Fasern im D\u00e4mpfungstestMehrfaserstrecken mit MTP/MPO-Steckern                        24Mainframe-Anwendern stehen gleich inmehrerlei Hinsicht Probleme ins Haus. Zu-\nn\u00e4chst einmal sieht die Verf\u00fcgbarkeit von Spe-zialisten in Zukunft d\u00fcster aus. Im Gegensatzzu heute geh\u00f6rte vor 20 Jahren die Vermittlungvon Mainframe-Kenntnissen, in der Systempro-grammierung und in Entwicklungssprachenwie COBOL und PL/1 oft zum Lehrplan anHochschulen und Fortbildungseinrichtungen.Jedoch gehen die meisten dieser Experten ent-weder bald in den Ruhestand oder sind bereitsin Rente. Diese Entwicklung war schon langeabsehbar. Bereits 1999 wurden etliche Ent-wickler aus dem Ruhestand geholt, um dieCodes fit f\u00fcr das Jahr 2000 zu machen.\nDie Experten fehlen\nHeute erscheint der Bereich Mainframe f\u00fcrden Nachwuchs immer weniger attraktiv. Ge-gen\u00fcber beliebten Programmiersprachen wieJava ziehen COBOL und PL/1 den K\u00fcrzeren.Vereinzelt gibt es Weiterbildungsma\u00dfnahmen,die Unternehmen gemeinsam mit Hochschu-len anbieten. Namentlich die eng mit IBM ko-operierende European Mainframe Academyund das Academic Mainframe Consortiumsind auf diesem Gebiet aktiv und bem\u00fchensich um die Vermittlung zwischen Firmen, dieNachwuchs suchen, und jungen Menschen,die Interesse zeigen. Allerdings sind Mainfra-mes an deutschen Hochschulen selten, so-dass die Studierenden meist keine Chancehaben, am eigenen Institut praktische Erfah-rungen zu sammeln. Au\u00dferdem richten sichdiese Projekte an eine j\u00fcngere Zielgruppe,wohingegen Unternehmen erfahrene Expertenvorziehen. Wobei bei der Auswahl nicht nurdie IT-Eignung ma\u00dfgeblich ist, sondern auchdie Erfahrung im Fachbereich, in dem sich dieEntwickler bewegen. Quereinsteiger spielenin diesem Segment kaum eine Rolle. Ein weiteres Problem f\u00fcr den Mainframe\nist die Verf\u00fcgbarkeit alternativer L\u00f6sungen \u2013vergleichbare x86-Server sind wesentlichkosteng\u00fcnstiger. Selbst eingefleischte Main -frame-Anh\u00e4nger m\u00fcssen zugeben, dass nebendem Dinosaurier-Image und dem Mangel anExpertennachwuchs die Kosten f\u00fcr Software-lizenzen in vielen F\u00e4llen eine Abkehr vomMainframe bewirken. Eine Losl\u00f6sung vomMainframe h\u00e4tte auch den Vorteil, dass derAnwender sich aus der vielschichtigen Nut-zung von Mainframe-Systemsoftware l\u00f6senk\u00f6nnte. Aber eine Migration ist schwierig. Esgibt zu viel alten Code, und die Routinen sindvielfach miteinander verkn\u00fcpft. Die Main -frame-Anwendungen sind zu sehr in die Funk-tion des Unternehmens eingewoben, als dasssie im Rahmen einer IT-Umstellung abge-schafft werden k\u00f6nnten. \nRekodierung m\u00f6glich, \naber schwierig\nMittlerweile gibt es einige M\u00f6glichkeiten, mitder eine Mainframe-Migration machbar ist. Ei-nige IT-Dienstleister bieten eine Rekodierungan. Dort arbeiten Entwickler an der Portierungdes Codes auf eine x86-Plattform. Dieser neueCode l\u00e4uft dann nativ auf dem dort verwende-ten Betriebssystem und bildet die Funktions-weise des alten Codes ab. Diese Methode istzwar der grundlegendste Bruch und eine guteGelegenheit, sein IT-System neu zu konzipierenund sich von alten, ungenutzten Routinen zuverabschieden, birgt aber einige Gefahren. \nZun\u00e4chst k\u00f6nnen durch die Rekodierung\nFehler entstehen, deren Beseitigung zus\u00e4tzli-che Ressourcen bindet. Eine manuelle Anpas-sung eines komplexen Systems ist auch sehrzeitaufwendig und eignet sich eher f\u00fcr Pro-jekte mit einem kleineren Umfang. Nicht zuletzt erfordert eine Rekodierung auch orga-nisatorische Anpassungen in der IT-Struktur. Mit einem Nicht-Mainframe-basierten Systemm\u00fcssen au\u00dferdem bisherige Mainframe-Ex-perten eine neue Rolle finden.\n4\nRechenzentren und Infrastruktur \u2161/2018SOFTWARE-DEFINED MAINFRAME\nGro\u00dfrechner im Container\nOhne jede \u00c4nderung wandern Legacy-Anwendungen in Software-defined Mainframes\nEine der Schl\u00fcsselfragen der RZ-Modernisierung ist: Was geschieht mit den Mainframes? Sie stellt sich immerwieder, wenn Software und Hardware erneuert werden m\u00fcssen. Bislang kam letztlich meist ein Nachfolgemodellzum Zuge \u2013 es gibt einfach zu viel Legacy Code. Doch es gibt auch Alternativen zur Migration. \nRekompilierung er\u00fcbrigt sich: Der LzLabs Software Defined Mainframe \u00fcbernimmt LegacyCode bruchlos vom alten Mainframe in Container auf preisg\u00fcnstigen Linux-Plattformen.\nQuelle: LzLabs GmbHDoch es gibt auch handfeste technische\nGr\u00fcnde f\u00fcr Schwierigkeiten bei der Reko -dierung. Ein Life Cycle Management, dasSource code, Compiler Reports und Lademo-dule durchgehend dokumentiert, ist seltenvorhanden. Oft existieren nicht dokumentier-te Routinen. Ebenso stellt sich die Frage, aufwelchem Code die Anwendung tats\u00e4chlichbasiert und welcher nicht mehr relevant ist.Die Analyse hierf\u00fcr umfasst daher nicht nurdie eigentliche Routine, sondern auch dieUmgebung, in die sie eingebunden ist. Eine Dependency Map, die die Abh\u00e4ngigkeit dereinzelnen Routinen zueinander auflistet, gibtes in aller Regel nicht. Betrachtet man beider Rekodierung nicht nur die im laufendenBetrieb verwendeten Programmteile, son-dern auch \u201etoten Code\u201c, so k\u00f6nnte das Mi-grationsteam versuchen, Probleme, die innicht mehr verwendeten Modulen bestehen,zu l\u00f6sen \u2013 ohne, dass dies \u00fcberhaupt not-wendig w\u00e4re. \nDas Problem liegt im Detail\nBei Rekodierung oder auch nur Rekompilie-rung kommen auch grundlegende Problemezum Vorschein. Mainframes und herk\u00f6mm -liche offene Betriebssysteme wie Linux nut-zen unterschiedliche Code-Tabellen. W\u00e4hrendin der x86-Welt Unicode beziehungsweiseASCII zum Tragen kommt, nutzt der Mainfra-me mit EBCDIC seine eigene, propriet\u00e4reCode-Tabelle. Dies hat umfangreiche An-passungen zur Folge. Falls die Migrations-beauftragten diesem Umstand nicht ausrei-chend beachten, sind Inkompatibilit\u00e4tenwortw\u00f6rtlich vorprogrammiert. ASCII bezie-hungsweise Unicode sortieren aufsteigend:Zahlen vor Gro\u00dfbuchstaben vor Kleinbuch-staben; EBCDIC nutzt die umgekehrte Rei-henfolge. Bei s\u00e4mtlichen Routinen, derenCode unangepasst \u00fcbernommen wird, ver-\u00e4ndert sich bei Sortierfolgen das Ergebnis.Damit \u00e4ndert sich die Business-Logik, unddas Resultat wird unbrauchbar. \nEin anderes Beispiel sind abweichende\nnumerische Formate. Das bei Mainframes oftverwendete Format Packed Decimal findetau\u00dferhalb der Mainframe-Welt keine Ent-sprechung. Auch die Adressierung bei Bin\u00e4r-formaten ist unterschiedlich. Mainframesnutzen daf\u00fcr Big Endian und speichern dash\u00f6chstwertige Byte an der kleinsten Speiche-radresse. Anders bei x86-Systemen: Hierkommt Little Endian zum Tragen. Das kleins-te Byte erh\u00e4lt die kleinste Adresse. Obwohlganze Zahlen syntaktisch g\u00fcltig bleiben, \u00e4n-dern sich ihre Werte vollkommen. Auch f\u00fch-ren Mainframes und x86-Server Gleitkom-maoperationen unterschiedlich aus, was be-sonders bei finanzmathematischen Anwen-dungen schwer wiegt, falls der zu migrieren-de Code nicht aufwendig angepasst wird.\nAnwendung im Container\nDoch welchen Weg k\u00f6nnten Unternehmengehen, um unabh\u00e4ngig von ihrer Mainframe-Infrastruktur zu werden? Ein gangbarer Wegw\u00e4re die Nutzung von Mainframes in Contai-nern, die \u2013 wie zum Beispiel ein Software-defined Mainframe (SDM) \u2013 eine entspre-chende Laufzeitumgebung bieten, sodass dieApplikationssoftware ohne Transformationvon Datenformaten und ohne eine Neukom-pilierung die unterliegende offene Betriebs-systemumgebung nutzen kann. Hier versiehtein quasi virtueller Mainframe-Container umdie eigentliche Applikation seinen Dienst wieein physischer, nur unter direkter Verwen-dung von Linux. Anwendungen m\u00fcssen nichtneu kompiliert werden, sondern lediglich,wie bei Containern \u00fcblich, in das unterlie-gende Betriebssystem integriert werden. Daskann besonders dann von Vorteil sein, wenneinige Routinen bereits so lange im Unter-nehmen in Einsatz sind, dass der Zugriff aufdie urspr\u00fcnglichen Entwickler nicht mehr er-folgen kann. Oft sind das die Module, dienoch \u201emit viel Gl\u00fcck\u201c modifikationsfrei funk-tionieren. \nUm eine Portierung \u00fcberhaupt zu erm\u00f6g-\nlichen, sollte der Software-defined Mainfra-me \u00fcber ad\u00e4quate Transaktionsmonitore,Datenbanken und Batch-Verarbeitungsmo-dule verf\u00fcgen, die den Systemen auf einemMainframe entsprechen. So k\u00f6nnen IT-Ver-antwortliche Legacy-Code ohne Rekompilie-rung in einem Container laufen lassen. Dader Container eine abgeschlossene Einheitbildet und \u00fcber definierte Schnittstellenverf\u00fcgt, kann Legacy Code beispielsweisemit Java-Anwendungen interagieren, dieauf dem Betriebssystem der x86-Serverlaufen. Damit entf\u00e4llt auch der Zwang, dasgesamte Mainframesystem zu migrieren.Eine schrittweise Entwicklung vom Mainf-rame hin zur x86-Architektur ist so m\u00f6glichund risikoarm zu bewerkstelligen. \nDamit ver\u00e4ndert sich auch die Struktur \neines Rechenzentrums. Die Verwendung vonx86-Servern erm\u00f6glicht flexiblere Planung.Und weil SDMs in Containern arbeiten, sindsie prinzipiell in die Cloud verschiebbar. Ei-nige Anbieter wie Microsoft mit Azure oderAmazon mit AWS k\u00f6nnen entsprechende vir-tuelle Mainframes bereits hosten.\nDale Vecchio, \nChief Marketing Officer, LzLabs\n5\nRechenzentren und Infrastruktur \u2161/2018SOFTWARE-DEFINED MAINFRAMEMit dem Aufkommen von Arbeitsplatz- und Abteilungsrechnernschien es lange Zeit v\u00f6llig klar: Der Weg der Gro\u00dfrechner konnte\nauf Dauer nur ins Abseits f\u00fchren. Eine ganze Generation von IT-Spe-zialisten lebte als Mainframer in der Vorstellung, einer aussterbendenArt anzugeh\u00f6ren. Spezialisten f\u00fcr andere IT-Formen hielten sich f\u00fcr dieAvantgarde und glaubten an ihre Aufgabe, die l\u00e4ngst f\u00e4llige Abl\u00f6sungder Boliden in den zentralisierten Rechenzentren zu bef\u00f6rdern.\nAlternativen im Stresstest\nDerweil entstanden in den Unternehmen mit der verteilten IT komplexe,miteinander vernetzte Hardwaresilos mit un\u00fcbersichtlichen Protokoll-stacks. Solche Infrastrukturen sind teuer zu betreiben und zu warten,Fehler lassen sich manchmal nur nach langwierigen Analysen einerFehlerquelle zuordnen, und wenn jemand mehr Storage oder einen neuenServer braucht, kann es durchaus Monate dauern, bis dem Wunsch ent-sprochen wird \u2013 einfach deshalb, weil es nicht schneller geht.\nDerartige Systeme sind zudem h\u00e4ufig entweder unterausgelastet\noder am \u00dcberlaufen. Dem sollte durch Virtualisierung abgeholfen wer-den, was sich aber als h\u00f6chst unvollkommenes Heilmittel entpuppte.Dazu suchten mit dem Aufkommen von Internet, Windows-Plattformenund Android-Smartphones bislang kaum gekannte Sch\u00e4dlingsflutenaus dem Dark Web die Infrastrukturen der geplagten IT-Manager heim.Die Folge: 80 % ihrer Zeit verbringen sie mit Routine, nur 20 % mit derEntwicklung kreativer neuer Ideen, die dem Kerngesch\u00e4ft nutzen.\nDann kam die Cloud \u2013 funktional betrachtet nichts weiter als ein\nh\u00f6chst modular aufgebauter Mainframe, der seine Services nicht mehrnur Firmenmitarbeitern, sondern einer breiten Allgemeinheit zur Ver-f\u00fcgung stellt. Was in den Rechenzentren von AWS, Google oder Amazonsteht, basiert zwar auf Standardprozessoren, doch die Ger\u00e4te, die ge-nutzt werden, sind l\u00e4ngst so aufgebaut, wie es die jeweiligen Cloud-Hyperscaler von den Hardwarelieferanten w\u00fcnschen \u2013 angepasst anhochskalierbare Umgebungen und im Gebrauch austauschbar.\nAuch hyperkonvergente Infrastrukturen, die unter einem Hypervisor\nund Betriebssystem alle Systemkomponenten, gepackt in integrierteStandardmodule, bereitstellen, sind im Grunde ein Versuch, die wild-w\u00fcchsig wachsende IT in Abteilungen wieder st\u00e4rker zu zentralisieren,gleichzeitig aber flexibel zu halten. Sie sollen den Management- undSkalierungsaufwand in Grenzen halten und cloud\u00e4hnliche Services f\u00fcrdie Anwender erm\u00f6glichen.\nZur\u00fcck in die Zukunft\nDas alles kann man sich zumindest hinsichtlich vieler Kerngesch\u00e4fts-prozesse wunderbar ersparen, das scheinen langsam viele IT-Abtei-lungen von Gro\u00dfunternehmen zu erkennen. Denn im Rechenzentrumsteht oft noch ein Mainframe, auf dem nach wie vor, meist ohne gr\u00f6-\u00dfere Friktionen, jahrzehntealte Software vor sich hin l\u00e4uft und bei-spielsweise ohne gro\u00dfes Gewese den monatlichen Lohndurchlauf f\u00fcrsechsstellige Mitarbeiterzahlen durchpumpt. Die inzwischen ebenfallsoft jahrzehntealten Abl\u00f6sungsprojekte haben sich n\u00e4mlich in den meis-ten Unternehmen als schwierig bis undurchf\u00fchrbar erwiesen. Also wirdjetzt vielerorts die Parole \u201eZur\u00fcck, marsch, marsch!\u201c ausgegeben.\nDoch dank einiger Modernisierungsschritte auf Herstellerseite\nscheint es inzwischen durchaus vorstellbar, den Mainframe auch mitin eine cloudisierte und serviceorientierte, softwaregetriebene IT-Zu-kunft als soliden Unterbau mitzunehmen.\nDas zeigte sich beispielsweise auf einem Workshop zum Thema\nIBM Mainframe des Software- und Beratungshauses ARS in M\u00fcnchen.Es hat sich auf Themen rund um IBM-Mainframes, -Lizenzmanagementund \u00c4hnliches spezialisiert. Die Workshops begannen vor drei Jahrenmit einer Handvoll Besuchern. Vor einigen Wochen kamen schon rund40 Neugierige, gr\u00f6\u00dftenteils von Unternehmen und Institutionen, in de-nen ein IBM-Mainframe im Rechenzentrum parallel zu moderneren In-frastrukturen l\u00e4uft. Und viele von ihnen berichteten, dass in ihren H\u00e4u-sern Abl\u00f6sungsprojekte entweder bereits selbst wieder abgel\u00f6st\n6\nRechenzentren und Infrastruktur \u2161/2018HARDWARE\nMehr MIPS auf denMainframe!\nDie klassischen Zentralrechner sind zur\u00fcck und gewinnen zusehends neue Anh\u00e4nger\n\u00dcber Jahrzehnte hinweg galt der Mainframe als Auslaufmodell. Doch zuerst wollten die Maschinen einfach nichtauslaufen, und aktuell scheint sich das Thema von selbst zu erledigen: IBM meldet Mehrabs\u00e4tze, dieMainframe-Anwender berichten von neuen Projekten und haben gute Argumente f\u00fcr ihre Sache.\n\u201eTransaktionssicherheit, Hochverf\u00fcgbarkeit und Sicherheit desMainframes lassen sich von modularen Architekturen nichtreproduzieren\u201c \u2013 Prof. Philipp Brune, Hochschule Neu-Ulm. \nQuelle: R\u00fcdiger werden oder kurz davor stehen. Allenthalben bilden sich neue Arbeits-gruppen, die den Mainframe bei IT-Fachleuten, Anwendern und Gesch\u00e4fts-leitung wieder gesellschaftsf\u00e4hig machen und neue Anwendungendorthin verlagern sollen.\nBei der genossenschaftlich organisierten DATEV e.V. etwa hat sich\ndie Gruppe zTalents entwickelt, junge Programmierer und System -spezialisten, die die Arbeit mit dem Mainframe interessanter finden alsdie mit verteilten oder hochmodularen Architekturen. \u201eRund 80 von etwa 1800 bis 2000 DATEV-IT-Spezialisten sind dabei\u201c, berichtet Andreas Bechtloff, selbst ein zTalent. \u201eIch finde die Funktionalit\u00e4t desMainframes cool\u201c, begr\u00fcndet er, warum er sich auf dieses Gebiet spe-zialisiert, \u201eje mehr man einsteigt, desto cooler.\u201c Bechtloff will, dass\u201edie Emotionalit\u00e4t aus der Debatte um die Workload-Platzierung genom-\nmen wird.\u201c Wenn eine Load am besten auf dem Mainframe laufe, dannsolle man sie auch dort laufen lassen und nicht aus politischen Gr\u00fcn-den auf anderen Plattformen. Die DATEV zum Beispiel betreibt zweigespiegelte z14-Systeme.\nz.future bei T-Systems\nBei T-Systems wurde inzwischen ein komplettes abteilungs\u00fcbergrei-fendes Mainframe-Innovationsprogramm eingerichtet. \u201eBis 2017 gabes bei uns keine strategische Weiterentwicklung der Mainframe-Archi-tektur\u201c, berichtete Gundula Folkerts, T-Systems. \u201eInzwischen verwen-det unser Management die Begriffe Management und Mainframe in einem Satz.\u201c Man nutzte nach wie vor alte Sprachen und Architekturenwie Cobol und entwickelte nach Wasserfall-Methodik. Doch die Main -frame-Abl\u00f6sungsprojekte, die parallel gefahren wurden, erwiesen sichals zu aufwendig. Deshalb entwickelte T-Systems 2017 zusammen mitdem Software- und Beratungshaus PKS, das sich auf die Softwareana-lyse spezialisiert hat, eine Mainframe-Modernisierungsstrategie. ImNovember 2017 wurde dann das Mainframe-Innovationsteam gebildet,das nun arbeitet. Es soll die geplante Strategie umsetzen und Schrittf\u00fcr Schritt die gesamte Mainframe-Architektur renovieren. Dazu geh\u00f6rtauch ein ger\u00fctteltes Ma\u00df an Mainframe-Imagepflege. Das Motto desTeams lautet: \u201ez.future.einfach.machen.\u201cDabei wird z/Linux statt z/OS als neue Betriebssystemplattform im-\nplementiert, um auch eine z-System-Cloud betreiben und moderneProgrammiersprachen besser nutzen zu k\u00f6nnen. Als Leuchtturmappli-kationen hat T-Systems Blockchain, Kryptografie und Cloud definiert.Die noch vorhandene IDMS-Datenbank soll durch DB/2 abgel\u00f6st wer-den, Cobol durch Java. Eine zeitgem\u00e4\u00dfe Entwicklungsumgebung samtKonfigurationsmanagement ist ebenfalls geplant. Entwickelt wird zu-k\u00fcnftig mit agilen Methoden, mit Scrum und nach DevOps-Prinzipien.\nDas Leuchtturmprojekt Blockchain wird mithilfe von Programmierung\nmit C auf z/Linux f\u00fcr einen Usecase aus der Automobilindustrie umge-setzt. Dabei kommt IBMs bevorzugtes Open-Source-Produkt f\u00fcr denAufbau eines verteilten Hauptbuches, Hyperledger Fabric, zum Einsatz.Derzeit liegt Hyperledger Fabric direkt auf einer LPAR, soll aber sp\u00e4terin eine virtuelle Maschine verlagert werden.\nBesonders vorteilhaft wirkt sich die hohe Leistung des Mainframes\nbeim Berechnen der Hashwerte aus. Verglichen mit konventionellen\n7\nRechenzentren und Infrastruktur \u2161/2018HARDWARE\n\u201eJe mehr ich in den Mainframe einsteige, desto cooler finde ichihn\u201c \u2013 Andreas Bechtloff, zTalent bei DATEV.\nQuelle: R\u00fcdigerwerden oder kurz davor stehen. Allenthalben bilden sich neue Arbeits-gruppen, die den Mainframe bei IT-Fachleuten, Anwendern und Gesch\u00e4fts-leitung wieder gesellschaftsf\u00e4hig machen und neue Anwendungendorthin verlagern sollen.\nBei der genossenschaftlich organisierten DATEV e.V. etwa hat sich\ndie Gruppe zTalents entwickelt, junge Programmierer und System -spezialisten, die die Arbeit mit dem Mainframe interessanter finden alsdie mit verteilten oder hochmodularen Architekturen. \u201eRund 80 von etwa 1800 bis 2000 DATEV-IT-Spezialisten sind dabei\u201c, berichtet Andreas Bechtloff, selbst ein zTalent. \u201eIch finde die Funktionalit\u00e4t desMainframes cool\u201c, begr\u00fcndet er, warum er sich auf dieses Gebiet spe-zialisiert, \u201eje mehr man einsteigt, desto cooler.\u201c Bechtloff will, dass\u201edie Emotionalit\u00e4t aus der Debatte um die Workload-Platzierung genom-\nmen wird.\u201c Wenn eine Load am besten auf dem Mainframe laufe, dannsolle man sie auch dort laufen lassen und nicht aus politischen Gr\u00fcn-den auf anderen Plattformen. Die DATEV zum Beispiel betreibt zweigespiegelte z14-Systeme.\nz.future bei T-Systems\nBei T-Systems wurde inzwischen ein komplettes abteilungs\u00fcbergrei-fendes Mainframe-Innovationsprogramm eingerichtet. \u201eBis 2017 gabes bei uns keine strategische Weiterentwicklung der Mainframe-Archi-tektur\u201c, berichtete Gundula Folkerts, T-Systems. \u201eInzwischen verwen-det unser Management die Begriffe Management und Mainframe in einem Satz.\u201c Man nutzte nach wie vor alte Sprachen und Architekturenwie Cobol und entwickelte nach Wasserfall-Methodik. Doch die Main -frame-Abl\u00f6sungsprojekte, die parallel gefahren wurden, erwiesen sichals zu aufwendig. Deshalb entwickelte T-Systems 2017 zusammen mitdem Software- und Beratungshaus PKS, das sich auf die Softwareana-lyse spezialisiert hat, eine Mainframe-Modernisierungsstrategie. ImNovember 2017 wurde dann das Mainframe-Innovationsteam gebildet,das nun arbeitet. Es soll die geplante Strategie umsetzen und Schrittf\u00fcr Schritt die gesamte Mainframe-Architektur renovieren. Dazu geh\u00f6rtauch ein ger\u00fctteltes Ma\u00df an Mainframe-Imagepflege. Das Motto desTeams lautet: \u201ez.future.einfach.machen.\u201cDabei wird z/Linux statt z/OS als neue Betriebssystemplattform im-\nplementiert, um auch eine z-System-Cloud betreiben und moderneProgrammiersprachen besser nutzen zu k\u00f6nnen. Als Leuchtturmappli-kationen hat T-Systems Blockchain, Kryptografie und Cloud definiert.Die noch vorhandene IDMS-Datenbank soll durch DB/2 abgel\u00f6st wer-den, Cobol durch Java. Eine zeitgem\u00e4\u00dfe Entwicklungsumgebung samtKonfigurationsmanagement ist ebenfalls geplant. Entwickelt wird zu-k\u00fcnftig mit agilen Methoden, mit Scrum und nach DevOps-Prinzipien.\nDas Leuchtturmprojekt Blockchain wird mithilfe von Programmierung\nmit C auf z/Linux f\u00fcr einen Usecase aus der Automobilindustrie umge-setzt. Dabei kommt IBMs bevorzugtes Open-Source-Produkt f\u00fcr denAufbau eines verteilten Hauptbuches, Hyperledger Fabric, zum Einsatz.Derzeit liegt Hyperledger Fabric direkt auf einer LPAR, soll aber sp\u00e4terin eine virtuelle Maschine verlagert werden.\nBesonders vorteilhaft wirkt sich die hohe Leistung des Mainframes\nbeim Berechnen der Hashwerte aus. Verglichen mit konventionellen\n7 Rechenzentren und Infrastruktur \u2161/2018HARDWARE\n\u201eJe mehr ich in den Mainframe einsteige, desto cooler finde ichihn\u201c \u2013 Andreas Bechtloff, zTalent bei DATEV.\nQuelle: R\u00fcdigerx86-Rechnern der aktuellen Generation leistet der verwendete z13drei- bis zehnmal mehr \u2013 je l\u00e4nger der Schl\u00fcssel, desto gr\u00f6\u00dfer wirdder Abstand. Block chains unterschiedlicher Betreiber sollen sich sau-ber getrennt voneinander auf einem System betreiben lassen, wennsie in getrennte Secure Service Container gepackt werden.\nDocker auf dem Mainframe\nNach der schrittweisen Migration auf eine Java-Architektur, f\u00fcr die esbereits eine Mainframe-Referenzarchitektur gibt, sollen auch Docker-Container auf dem Mainframe m\u00f6glich werden. DB/2 erh\u00e4lt eine App-server-GUI, die einzelnen Datenbankservices werden also als Apps \u00fcbereine grafische Schnittstelle bereitgestellt, wie man das aus dem Internetgewohnt ist. Um die Portierung der alten Cobol-Software auf die neueJava-Umgebung durchzuf\u00fchren, wird teils neu geschrieben, teils kom-men Werkzeuge zum Einsatz. Allerdings erzeugen diese einen rein tech-nischen Code ohne Java Business Objects, der dann wieder umgestricktwerden muss.\nNeue Prozesse legt T-Systems jetzt grunds\u00e4tzlich als Micro -\nservices unter z/Linux auf dem Mainframe ab; die Mitarbeiter, diebislang Microservices f\u00fcr andere Plattformen entwickelt haben, wer-den auf den Mainframe migriert. Die Kommunikation der Microser-vices mit der DB/s-Datenbank auf demselben System erfolgt derzeit\u00fcber Hypersockets.\nStatt der gewohnten CICS-Logik erh\u00e4lt die Software RESTful-APIs,\ndenn sie l\u00e4sst sich nicht ohne Programmieraufwand als Service be-reitstellen. Der Zugriff erfolgt \u00fcber Middleware, wobei Open-Source-\nund IBM-Tools eingesetztwerden. Demn\u00e4chst sollauch versucht werden,CICS-Transaktionen mitgekapselten Funktionen zurealisieren, die dann in derneuen Umgebung weiterbetrieben werden k\u00f6nnten.Das funktioniert allerdingsnur bei Transaktionen ohneInteraktionen mit den An-wendern.Attraktiv durch Datenschutz\nDas Projekt zeigt, dass gerade da, wo Zuverl\u00e4ssigkeit, Leistung undSicherheit eine wichtige Rolle spielen, der Mainframe deutlich anCharme gewinnt \u2013 m\u00f6glicherweise auch eine Auswirkung der ver-sch\u00e4rften Datenschutzregeln, die seit dem 25. Mai europaweit gelten.So wies Tobias Leicher, IBM, darauf hin, dass die Nutzung der mit demz14 m\u00f6glichen Komplettverschl\u00fcsselung zwar das System teurer ma-che: um 10 %. Verglichen mit den hohen Strafen, die in Zukunft beiDatenschutzpannen gegen Firmen verh\u00e4ngt werden k\u00f6nnen, die dieSicherheit ihrer Kundendaten nicht priorisieren, scheint das moderat.Zur Erinnerung: In schweren F\u00e4llen k\u00f6nnen die Datensch\u00fctzer bis zu4 % vom weltweiten Umsatz eines Unternehmens als Bu\u00dfgeld einfor-dern. Bei Firmen mit mehrstelligem Milliardenumsatz k\u00f6nnen da leichtzweistellige Millionensummen zustande kommen.\nPhilipp Brune, Professor f\u00fcr Wirtschaftsinformatik an der Hoch -\nschule Neu-Ulm sieht das \u00e4hnlich: \u201eEs gibt einen Umschwung im Denken.Viele erkennen, dass der Mainframe einzigartig hinsichtlich Trans -aktionsdurchsatz, Hochverf\u00fcgbarkeit und Sicherheit ist, und erkl\u00e4renihn wieder zur strategischen Plattform.\u201c Es sei bei den modularen Architekturans\u00e4tzen wie der Hyperkonvergenz nicht machbar, dieMainframe-Leistung in Software abzubilden. Schlie\u00dflich setze Trans-aktionsverarbeitung Datenkonsistenz voraus, und die verursache beimodularen Architekturen einen immensen Aufwand wegen der Kom-munikation, die zwischen den Knoten n\u00f6tig ist.\nNeue Preispolitik bei IBM\nDiese Argumente scheinen auch viele Praktiker zu \u00fcberzeugen. Dazukommt, dass IBM anscheinend die Zeichen der Zeit erkannt hat undseine vormals horrenden Preise seit 2014 flexibler und insgesamtwettbewerbsf\u00e4higer gestaltet. So gibt es seitdem ein spezielles Pricingf\u00fcr mobile Workloads, 2015 folgte ein attraktiveres Preismodell f\u00fcr denBetrieb zweier aktiver Maschinen in zwei unterschiedlichen L\u00e4ndern.2017 wurde ein Container Pricing eingef\u00fchrt, wobei die Container auchauf mehreren LPARs liegen d\u00fcrfen. F\u00fcr drei Standardszenarien, soge-nannte Solutions, n\u00e4mlich Anwendungsentwicklung, Test und neue An-wendungen, wurden vollkommen neue Metriken eingef\u00fchrt. Zum Be-reich \u201eneue Anwendungen\u201c geh\u00f6rt etwa eine Payment Pricing Solutionf\u00fcr elektronische Bezahlsysteme, bei der Kunden nicht mehr pro ge-nutzter Ressource, sondern pro Transaktion an IBM zahlen. \u201eDas isterst der Anfang\u201c, versprach ARS-Gesch\u00e4ftsf\u00fchrer Joachim Gucker.\nDie Auswirkungen lie\u00dfen nicht lange auf sich warten: Zur Ank\u00fcndi-\ngung seiner 14. Generation des z-Systems in diesem Fr\u00fchjahr konnteIBM massives Absatzwachstum bei Mainframes verk\u00fcnden. In Europakam es vor allem durch mehr Verarbeitungspower bei bereits vorhan-denen Systemen zustande, in Asien aber, mit seinen stark wachsendenUnternehmen, wurden auch neue Mainframes verkauft. Angesichts derEU-DSGVO f\u00fchrt IBM die starke Datensicherheit der mittlerweile auchcloudtauglichen Mainframes als Argument ins Feld.\n\u00c4rgerlich aus Anwenderperspektive ist nur, dass es zu IBM als\nMainframe-Lieferanten faktisch so gut wie keine Alternative gibt. Fujitsu entwickelt zwar die ehemalige Siemens-Plattform BS/2000weiter, doch ist ihr weltweiter Marktanteil vergleichsweise marginal.F\u00fcr Kunden ist es selten gut, wenn nur ein Anbieter existiert, derletztlich Preise und Angebot diktieren kann. Hier Ver\u00e4nderungen zuerwarten, erscheint bislang illusion\u00e4r, doch war die IT-Branche schonf\u00fcr so manche \u00dcberraschung gut.\nAriane R\u00fcdiger,\nfreie Journalistin, M\u00fcnchen\n8\nRechenzentren und Infrastruktur \u2161/2018HARDWARE\nDer z14 ist auch alsMainframe in nur einemeinzigen 19-Zoll-Racklieferbar. So passt dasGer\u00e4t in jedesRechenzentrum. \nQelle: IBMIn Deutschland verbrauchen alle Rechenzentren zusammen etwa 12,4 Milliarden kWh Strom pro Jahr \u2013 das entspricht einem Anteil von\n2,3 % am gesamten Stromverbrauch. Mit steigender Tendenz: In denn\u00e4chsten zehn Jahren d\u00fcrfte der absolute Energieverbrauch durch Data -center um satte 30 % zunehmen. Auf diese Zahlen kommt das unab-h\u00e4ngige Borderstep Institut f\u00fcr Innovation und Nachhaltigkeit. Wenig ver-wunderlich also, dass Unternehmen nicht nur in Deutschland nachinnovativen L\u00f6sungen suchen, um Energie und damit Kosten zu sparen.\nWarm- und Kaltg\u00e4nge\nDen gr\u00f6\u00dften Anteil, an dem sich au\u00dferdem am meisten drehen l\u00e4sst,macht weiterhin die RZ-Klimatisierung aus. Allerdings k\u00f6nnen Betreibermittlerweile verschiedene Technologien zur Reduzierung der ben\u00f6tigtenEnergiemenge nutzen. Eine M\u00f6glichkeit ist die Luftk\u00fchlung: Hierbei istes \u00fcblich, die Racks Front gegen Front mit Warm- und Kaltg\u00e4ngen imWechsel mit entsprechender Kaltluftzuf\u00fchrung \u00fcber einen Doppelbodenanzuordnen. Diese Konstruktionsweise sorgt zun\u00e4chst daf\u00fcr, dass diegek\u00fchlte Zuluft in den Kaltgang durch den Doppelboden eingeblasenwird. Im n\u00e4chsten Schritt wird sie von beiden Seiten von den Serverneingezogen, damit sie letztendlich auf der R\u00fcckseite der Racks in denWarmgang heraustreten kann. Mit dieser Anordnung k\u00f6nnen, bei ent-sprechend guter Planung und Umsetzung, 6 bis 8 kW K\u00fchlleistung proRack eingespart werden.\nBei luftgek\u00fchlten R\u00e4umen spielt die R\u00fccklufttemperatur eine wichtige\nRolle. Eine hohe R\u00fccklufttemperatur ist gleichbedeutend mit einerenergie effizienten Arbeitsweise der Anlage. Dabei ist eine gut geplanteund sorgf\u00e4ltig ausgef\u00fchrte Luftf\u00fchrung im Rechenzentrum erforderlich.So ist beispielsweise die erw\u00e4hnte Anordnung von Kalt- und Warmg\u00e4n-gen strikt einzuhalten \u2013 ansonsten riskiert man Luftverwirbelungen.\nBesonders in kalten und gem\u00e4\u00dfigten Klimazonen kann die soge-\nnannte freie K\u00fchlung zum Einsatz kommen. Bei der freien K\u00fchlung wirdzwischen direkter und indirekter K\u00fchlung unterschieden. Bei einemSystem mit direkter freier K\u00fchlung wird die k\u00fchle Au\u00dfenluft in den zuk\u00fchlenden Raum direkt eingebracht. Bei der indirekten freien K\u00fchlungwird mithilfe von Luft-Wasser-W\u00e4rmetauschern die W\u00e4rme an die Au\u00dfen-luft abgef\u00fchrt. Das Einsparpotenzial hier: bis zu 50 % im Vergleich zumausschlie\u00dflichen Einsatz von K\u00e4ltemaschinen.\nIn Kombination mit Fl\u00fcssigk\u00fchlung \nDass sich auf diese Weise ganze Datacenter \u201egr\u00fcn\u201c k\u00fchlen lassen, be-weist der franz\u00f6sische Provider OVH, der zwei interessante Ans\u00e4tzeverfolgt, um seine Rechenzenten energieeffizienter zu machen: Luft-k\u00fchlung im Geb\u00e4ude und eine spezielle K\u00fchlfl\u00fcssigkeit, die on the rackdurch die Server flie\u00dft. Die Fl\u00fcssigkeitsk\u00fchlung befindet sich im Chassisder Server und wird an w\u00e4rmeintensiven Komponenten (Prozessorenetc.) vorbeigeleitet. Dabei werden etwa 70 % der W\u00e4rme aufgenom-men. Pumpen bef\u00f6rdern anschlie\u00dfend die erw\u00e4rmte Fl\u00fcssigkeit nachau\u00dfen. Dort sind W\u00e4rmetauscher installiert, die daf\u00fcr sorgen, dass die Fl\u00fcssigkeit sich wieder abk\u00fchlt. Das System ist redundant konzi-piert und nutzt zur Pumpensteuerung abwechselnd mehrere Ger\u00e4te.F\u00fcr den Einsatz der K\u00fchlfl\u00fcssigkeit wurden spezielle Sicherheitsvor-kehrungen getroffen.\nBei der K\u00fchlung per Luft erzielen gro\u00dfe Luftsch\u00e4chte einen Kamin -\neffekt: Durch den Sog wird die warme Luft aus den R\u00e4umen gezogen.Kalt- und Warmgassen sind getrennt und kontrollieren die Luftzirkula-tion im Inneren der Serverchassis. Durch seitliche \u00d6ffnungen wird k\u00fchleAu\u00dfenluft auf die Geh\u00e4use der Server geleitet und gelangt so direktauf Ventilatoren und Prozessoren im Inneren der Server. Die erw\u00e4rmteLuft wird anschlie\u00dfend durch Warmgassen an der Serverr\u00fcckfront abgef\u00fchrt. In den Gassen befinden sich Absauger, die die warme Luftabtransportieren. Dabei ist jedes Chassis mit seiner eigenen Ventilationausger\u00fcstet. Mit einem solchen System gelangt die kalte Luft schnellzu den zu k\u00fchlenden Komponenten. OVH hat auf diese Weise seineEnergiekosten effektiv halbiert.\nEnergieeffizienz ist Kosteneffizienz\nDie hohen Energiepreise in Deutschland zwingen Rechenzentrumsbe-treiber dazu, weiter nach innovativen L\u00f6sungen Ausschau zu halten.Zuk\u00fcnftig ist ein intelligentes, automatisiertes Energiemanagement gefordert, das jede Komponente der IT-Infrastruktur nach Bedarf regeltund \u00dcberkapazit\u00e4ten vermeidet. Ein anderer bzw. paralleler Ansatz istder, dass Rechenzentren selbst als Stromerzeuger funktionieren. Mitder Abw\u00e4rme l\u00e4sst sich beispielsweise per thermoelektrischem Gene-rator Strom erzeugen. \nDr. Jens Zeyer,\nMarketing & PR Executive, OVH Germany\n9\nRechenzentren und Infrastruktur \u2161/2018GREEN DATACENTER\nTurm mit Luftschacht\nWenn es zwischen den Servern zieht, funktioniert die K\u00fchlung am effektivsten\nDurchdachte Energie- und K\u00fchlkonzepte k\u00f6nnen den RZ-Energieverbrauch deutlich senken. Entscheidend istdabei allerdings die Bauweise, die ma\u00dfgeblich die Luftf\u00fchrung zwischen den Racks bestimmt. Im konkretenBeispiel hat ein beabsichtigter Kamineffekt dazu beigetragen, die Energiekosten zu halbieren.\nQuelle: OVHDank des Turmkonzeptsstr\u00f6mt die k\u00fchle Luft direktauf der Vorderseite derServer ein und reguliert so die Temperatur derVentilatoren und Luft einl\u00e4sse der Maschinen. Damit erreichen die OVH-Rechen-zentren einen PUE-Wert unter 1,2.Diese digitale Transformation. Diese digitalen Transformationsziele. Alldiese Ver\u00e4nderungen. Immer mehr Manager erliegen diesem Wahn,\ndiesem Virus. Immer mehr Unternehmen wenden sich dieser sogenann-ten digitalen Transformation zu; sie wollen Innovation, sie wollen Wachs-tum. Sie brauchen es. Und sie werden hierf\u00fcr auf eigene Rechenzentrenund die Cloud angewiesen sein, um die zugrunde liegenden Systeme,also sowohl die Legacy-Systeme als auch die neuen \u201edigitalen\u201c Dienste,bereitzustellen. Sie treiben die Nachfrage nach mehr Rechenleistung, diehochgradig reaktionsschnell, skalierbar, verwertbar und agil ist, immerweiter voran. Aber: Sie verlangen eine andere Denke im Rechenzentrum.Hybrid Cloud, Multi Cloud. Und dar\u00fcber hinaus.\nDiese Cloud\nFakt ist, dass eine echte und vollst\u00e4ndige Cloud-Migration selbst f\u00fcrdie fortschrittlichsten und am weitesten fortgeschrittenen Unternehmennoch in weiter Ferne liegt \u2013 sofern diese Situation \u00fcberhaupt gewolltist. Dies bedeutet, dass Unternehmen nach M\u00f6glichkeiten suchen m\u00fcs-sen, ihre Rechenzentren, ihre lokalen L\u00f6sungen mit ihren cloudbasier-ten Services zu verbinden, damit ihre Systeme ihre Gesch\u00e4ftsprozesseunterst\u00fctzen. Warum? Eine einzige Cloud w\u00fcrde nie ausreichen, egalwie sehr Amazon Web Services, Microsoft etc. es sich auch w\u00fcnschen.\nEs geht hier nicht nur um die Herstellerbindung, den sogenannten\nVendor Lock-in. Es geht vielmehr darum, dass niemand auf die M\u00f6g-lichkeit verzichten will \u2013 oder sollte \u2013, den besten verf\u00fcgbaren Service,die beste Cloud f\u00fcr einen bestimmten Bedarf zu w\u00e4hlen. Deshalb m\u00fcs-sen in naher Zukunft noch mehr Zeit und Gewicht darauf gelegt werden, die gesch\u00e4ftlichen Anforderungen und die technischen Voraus-setzungen zu bewerten, um die Art der Infrastruktur auf die Workloadsanzupassen. Und/oder umgekehrt. Die Herausforderung liegt also mitanderen Worten darin, L\u00f6sungen f\u00fcr Probleme bzw. Anforderungenauszuw\u00e4hlen, die den derzeitigen und zuk\u00fcnftigen Bedarfen im Unter-nehmen gerecht werden.\nDiese Hybrid-Cloud\nDamit den wachsenden Anforderungen an Rechenzentren gen\u00fcge getanwird und zus\u00e4tzliche Vorteile wie Agilit\u00e4t, Skalierbarkeit und regelm\u00e4\u00dfigglobale Reichweite geboten werden, verwandelt sich das traditionelleRechenzentrum in ein hybrides Rechenzentrum. Und diese Entwicklungwird in den kommenden f\u00fcnf Jahren nicht an Bedeutung verlieren. Viel-mehr wird die Hybrid Cloud weiterhin in der Mehrzahl der Unternehmeneine sehr hohe Priorit\u00e4t haben. Warum? Weil diese Form den heutigenGesch\u00e4ftsanforderungen entspricht und gleichzeitig der kleinste gemein-same Nenner ist, um Anforderungen und Trends wie ML (Machine Lear-ning) und KI/AI (k\u00fcnstliche Intelligenz/Artificial Intelligence) abzubilden. \nDies spiegelt sich auch in den Marktzahlen wider: Die Berater von\nIDC prognostizieren den weltweiten Markt f\u00fcr Hybrid-Cloud-Data Services im Jahr 2021 auf ungef\u00e4hr 70 Milliarden US-Dollar. DieMarktforscher von ISG in ihrer Studie \u201eProvider Lens Germany 2018\u201csehen allein den deutschen Public-Cloud-Markt in diesem Jahr beirund 17 Milliarden Euro. Auch sie sehen eine extreme Nachfrage nachHybrid-Cloud-L\u00f6sungen und -Services. Insbesondere Anbieter von Hybrid-Integration und Broker-Services sind mit ihrer technischen undorganisatorischen Expertise gefragt.\nDiese Hybrid-Cloud-Anbieter\nAm Hybrid-Cloud-Markt tummelt sich alles, was in der IT-IndustrieRang und Namen hat, ferner zahlreiche Spezialisten. Nat\u00fcrlich sind hierVMware, AWS, Microsoft, Rackspace, HP , Google, IBM und Cisco zunennen, aber auch, von vielen noch immer nicht gew\u00fcrdigt, AlibabaCloud oder auch Red Hat sowie NTT. Ganz zu schweigen von den zahl-reichen Serviceanbietern in diesem Kontext.\nDabei sind die Strategien durchaus unterschiedlich: W\u00e4hrend VMware\nPartnerschaften mit Amazon und Google mit Cisco eingegangen ist, lie-fert Microsoft vieles aus einer Hand. Neben Azure und Windows Serverauch Azure Stack, eine Appliance, gedacht als On-premises-Version derPublic Cloud Azure. Branchenger\u00fcchte lassen allerdings den Schluss zu,dass Azure Stack nicht der erhoffte Stra\u00dfenfeger ist. Die Anzahl der aus-gelieferten Einheiten, respektive der Kunden, soll \u00fcberraschend kleinsein. Der Grund hierf\u00fcr liegt insbesondere an den Preisen und dem Appliance-Ansatz. Der f\u00fcr das zweite Halbjahr 2018 angek\u00fcndigte Win -dows Server 2019 soll das Hybrid-Cloud-Gesch\u00e4ft f\u00fcr Microsoft weiterforcieren. Dies soll \u00fcber verbesserte Container-Services, Linux und zahl-reiche Funktionen f\u00fcr Compliance und Sicherheit erreicht werden.\n10\nRechenzentren und Infrastruktur \u2161/2018HYBRID CLOUD\nDer l\u00e4ngere Zwischenschritt\nRZ-Anbieter d\u00fcrfen sich darauf einstellen, dass ihre Kunden noch mehr Cloud verlangen\nDer Cloud- und Rechenzentrumsbereich wird in den kommenden Jahren ein wichtiger Faktor f\u00fcr die Wirtschaftim Allgemeinen und f\u00fcr jedes einzelne Unternehmen sein. Warum? Weil es sich um die Motoren derGesch\u00e4ftsmodelle handelt. Auf absehbare Zeit sind Hybrid- und Multi-Cloud-L\u00f6sungen das Mittel der Wahl.\nF\u00fcr IBM zeichen sich (industrietaugliche) Hybrid Clouds durchsechs Merkmale aus: Integration, Sichtbarkeit/Kontrolle,Sicherheit, DevOps, Portabilit\u00e4t und Datenmanagement.\nQuelle: IBMDie Partnerschaft von VMware und AWS zielt darauf ab, ein inte-\ngriertes Cloud-Angebot bereitzustellen, das jeder der Anbieter in dieserForm nicht allein hinbekommen w\u00fcrde. Im Kern geht es darum, aufvSphere-basierte Cloud-Umgebungen mit den AWS-Services einfach,sicher und sinnvoll zu verschmelzen. VMware-Cloud on AWS ist dasvon VMware entwickelte Software-definierte Rechenzentrum (SDDC),das in der AWS-Cloud l\u00e4uft, sodass Anwender quasi jede beliebige An-wendung in Public-, Private- oder Hybrid-Cloud-Umgebungen ausf\u00fch-ren k\u00f6nnen. Mit dem Service laufen VMware, vSphere, vSAN und NSXauf der AWS-Cloud. Der Dienst ist f\u00fcr den Betrieb auf einer dediziertenBare-Metal-AWS-Infrastruktur optimiert. Neben der Kooperation mitAWS ist VMware unter anderem noch eine Partnerschaft mit IBM ein-gegangen. Ein Plus f\u00fcr VMware-Kunden sind au\u00dferdem die zahlreichenPartnerschaften mit Cloud-Anbietern, hierzu z\u00e4hlen Microsoft, AWS,Google und IBM, und ein eigenes Cloud-Provider-Partner-Programm,an dem nach Unternehmensangaben \u00fcber 4.000 Partner teilnehmen.\nRackspace wiederum arbeitet mit einer Vielzahl von Cloud-Anbie-\ntern zusammen. Ziel ist es, ein breites Portfolio anzubieten. Die hybride Cloud-L\u00f6sung von Rackspace basiert auf RackConnect, dasdie privaten Clouds eines Unternehmens mit den Diensten von Rack-space und/oder Public-Cloud-Angeboten von AWS, Microsoft oderGoogle verbindet.\nAuch IBM adressiert das Thema Hybrid Cloud vollumf\u00e4nglich, nicht\nnur \u00fcber Partnerschaften. Von Servern \u00fcber Mainframes bis hin zuSpeichersystemen und Software bietet IBM umfassende Ans\u00e4tze. DieCloud-Plattform von IBM kombiniert Platform as a Service mit Infra-structure as a Service und umfasst um die 170 Dienste f\u00fcr on premisesund Public Cloud. Das, was als IBM Cloud vermarktet wird, ist im Prin-zip die neue Dachmarke, die durch das Zusammenlegen von Bluemix,SoftLayer und Watson kreiert wurde. Die Services umfassen unter anderem virtualisiertes und Bare-Metal-Hosting, DevOps, Containerund Serverless Computing, Blockchain, AI/ML und High PerformanceComputing. Mit dem Bare-Metal-Angebot ist es m\u00f6glich, lokale Work -loads, die auf IBM-Plattformen laufen, ohne oder mit nur geringen \u00c4nde-rungen in die Cloud zu verlagern.\nWie andere Cloud-Provider auch hat sich Google zun\u00e4chst auf\n\u201eCloud pure play\u201c konzentriert. Im Gegensatz zu anderen Anbietern istGoogle erst relativ sp\u00e4t umgeschwenkt. Partnerschaften mit Cisco sollenden Bereich nun forcieren. Jedoch: W\u00e4hrend es f\u00fcr Google wahrschein-lich eine weitere beliebige Partnerschaft ist, handelt es sich f\u00fcr Ciscotats\u00e4chlich um eine reale Weiterentwicklung des Cloud-Gesch\u00e4fts, derCloud-Strategie.\nIm magischen Viereck\nEine hybride Cloud kombiniert vorhandene Rechenzentrumsressourcenmit vorgefertigten IT-Infrastrukturressourcen wie Computing, Net -working, Storage, Applikationen und Services, die Skalierungsfunktionenbieten, die in IaaS- oder Public-Cloud-Angeboten zu finden sind. HybridClouds bieten Vorteile wie zukunftssichere Investitionen f\u00fcr Unterneh-men, Sicherheit und Flexibilit\u00e4t und so weiter mit den sch\u00f6nen Marketing-Botschaften. Und so weiter mit den Erfolgsgeschichten. Doch halt! Stopp.Ein anderer Blick auf die Hybrid-Cloud ist wichtig.\nDie These: W\u00e4hrend die Hybrid Cloud als Modell, insbesondere im\nKontext mit Multi-Cloud-Strategien, relevant ist, kann sie erstens f\u00fcr vieleWorkloads nur als ein Zwischenschritt verstanden werden. Hybrid-Cloudssind ein Mittel der Wahl auf bestimmte Zeit; gehen wir hier mal von einemZeitraum von vier bis sechs Jahren aus. Zum anderen werden die Vor-teile von Hybrid und Multi-Clouds nicht dar\u00fcber hinwegt\u00e4uschen, dassdas eigene Rechenzentrum f\u00fcr viele Unternehmen wieder an Bedeutunggewinnen wird; dass viele Unternehmen den Aufbau von Private Cloudsforcieren werden. In diesem Zusammenhang ist zu erw\u00e4hnen, dass Hybrid Clouds nicht zwingend g\u00fcnstiger und einfacher sind.\nUntermauerung der These: Vor einiger Zeit, so vor vier bis f\u00fcnf Jah-\nren, begannen viele, begannen immer mehr Unternehmen damit, einenrelevanten Teil ihrer Infrastruktur und \u201ealles Neue\u201c in die Public Cloudzu verlagern. Sie bauten hybride Szenarien auf. Ein prim\u00e4res Ziel: Kos-ten reduzieren. Schaut man heute etwas genauer hin, wird sichtbar,dass oft nur wenige oder gar keine dieser Ziele erreicht wurden. Stelltman n\u00e4mlich ROI-Rechnungen von Cloud-Projekten der \u201eersten Gene-ration\u201c sorgf\u00e4ltig auf und vergleicht Opex-Budgets mit L\u00f6sungen, dieman im eigenen Unternehmen entwickelt oder betreibt, betrachtet mandie Management-Ressourcen und die Aufw\u00e4nde, dann wird sichtbar,dass mit mehr architektonischer Flexibilit\u00e4t nicht mehr technische Kon-trolle oder bessere Sicherheit einhergeht. Vielmehr wird klar, dass essich in Wirklichkeit um ein magisches Viereck mit den Eckpunkten Kos-ten, Sicherheit, Flexibilit\u00e4t und Komplexit\u00e4t handelt. Dass nicht alle Anforderungen gleichzeitig optimiert bzw. maximiert werden k\u00f6nnen.\nAuf das Ger\u00e4t ausgerichtet\nDie Zeiten, in denen Unternehmen Cloud-Services in erster Linie alsMittel zur Erweiterung der Infrastruktur betrachteten, sind schon l\u00e4ngervorbei. Klar ist: Die Infrastruktur ist nach wie vor kritisch. Sie sollteaber nicht der prim\u00e4re Grund sein, die Cloud einzuf\u00fchren. Ein noch im-mer oft vorgebrachter Anlass f\u00fcr Hybrid-Szenarien sind Compliance-Anforderungen. Vielfach wird unterstellt, dass diese Anforderungennicht in einem Pure-Public-Cloud-Konstrukt realisiert werden k\u00f6nnten.Auch dies sollte aber nicht mehr der prim\u00e4re Grund sein. Vielmehrm\u00fcssen die gesch\u00e4ftlichen Anforderungen im Vordergrund stehen. Also:Der prim\u00e4re Grund f\u00fcr hybride Cloud-Szenarien m\u00fcssen die Anforde-rungen der Gesch\u00e4ftsbereiche sein. Die Fragen dazu lauten: Wie kannich das Gesch\u00e4ftsziel optimiert und nachhaltig erreichen? Wann mussich meine operative Ausrichtung im Rahmen meiner Strategie \u00e4ndern?\nDie Ziele k\u00f6nnen mit hybriden Modellen als Zwischenschritt reali-\nsiert werden. Mit einem Zwischenschritt zu einer vollst\u00e4ndigen Public-Cloud-Infrastruktur oder einer vollst\u00e4ndigen privaten Cloud. Auch einbelastbarer solider Kompromiss zwischen einer Aufteilung in \u201eeigenesRechenzentrum\u201c und Public Cloud, bezogen auf einzelne dezidierte Gesch\u00e4ftsanforderungen, bleibt immer nur ein Kompromiss.\nAxel Oppermann,\nAvispador\n11\nRechenzentren und Infrastruktur \u2161/2018HYBRID CLOUD\nRackConnect verbindet eigene Firmenserver mit der ManagedCloud zur Multi-Hybrid-Cloud \u00fcber mehrere Umgebungen, Anbieterund Rechenzentren hinweg. IDC stuft den Anbieter als Leader imSegment \u201ePlatforms \u2013 Managed OpenStack Distributors\u201c ein.\nQuelle: RackspaceDie meisten Unternehmen verf\u00fcgen \u00fcber ein riesiges Datenarchiv \u2013und wissen oft gar nicht, welche n\u00fctzlichen Informationen darin\nenthalten sind. Die j\u00fcngsten Fortschritte im Bereich der k\u00fcnstlichen Intelligenz (KI), des maschinellen Lernens (ML) und der Big-Data-Analytik\nmachen es m\u00f6glich, sich die Daten zunutze zu machen.\nDie Daten, um die es geht, liegen jedoch \u00fcberwiegend in unstruk-\nturierter Form vor, was die Unternehmen vor erhebliche Herausforde-rungen stellt. Geeignete Datenmanagement- und Speicherl\u00f6sungengibt es aber bereits. Die neuen Datenplattformen der beginnenden KI-\u00c4ra basieren auf objektorientierter Speicherung und Verwaltung \u2013ein zeitgem\u00e4\u00dfer Ansatz, der sich in der Praxis in anspruchsvollen Anwen-dungen schon vielfach bew\u00e4hrt hat.\nLauter unstrukturierte Daten\nDoch was sind eigentlich \u201eunstrukturierte Daten\u201c? G\u00e4ngige Definitio-nen verweisen darauf, dass unstrukturierte Daten nicht gut f\u00fcr die Ver-waltung in einer relationalen Datenbank geeignet sind, womit die Herausforderungen f\u00fcr Unternehmen beginnen, die Ambitionen in Rich-tung KI und Big Data verfolgen. Meist handelt es sich um Text- undMultimediainhalte, wie E-Mail-Verkehr, Textverarbeitungsdokumente,Pr\u00e4sentationen, Web Content, aber auch Grafik-, Video- und Audioda-teien. Diese k\u00f6nnen intern durchaus in gewisser Weise strukturiertsein, die enthaltenen Informationen lassen sich aber nur schwer in einer Datenbank zug\u00e4nglich machen.\nWurden unstrukturierte Daten jahrzehntelang als Nebenprodukt zu-\nnehmend durchdigitalisierter Gesch\u00e4ftsprozesse betrachtet, gewinnensie neuerdings immens an Bedeutung. Generell dreht sich heute allesum Daten. Hierbei ist zwangsl\u00e4ufig auch der riesige Anteil der unstruk-turierten Daten ins Visier der Unternehmen gelangt.\nDas Volumen der unstrukturierten Daten nimmt wesentlich schneller \u2013\nn\u00e4mlich exponentiell \u2013 zu als die Menge in der geordneten Welt derstrukturierten Daten. Da Speicherplatz immer g\u00fcnstiger wird, werdenunstrukturierte Daten gro\u00dfz\u00fcgig archiviert, was sich mit zunehmendemInteresse f\u00fcr den potenziellen Wert der Daten kaum \u00e4ndern wird. Jetztgilt es, daraus neue, wertvolle Erkenntnisse zu gewinnen, um besserfundierte Gesch\u00e4ftsentscheidungen zu unterst\u00fctzen und k\u00fcnftig voraus-schauender zu agieren. \nInnovationen auf Speicherseite\nModerne Datenanalytik setzt jedoch moderne Speichertechnologie voraus. Die erste Goldgr\u00e4berstimmung (analog zum schon l\u00e4nger gebr\u00e4uchlichen Begriff des Data Mining) wird derzeit jedoch in vielenUnternehmen getr\u00fcbt. Dies liegt daran, dass sich unstrukturierte Datengegen eine Analyse str\u00e4uben, zumindest mit Speichertechnologie vongestern. Herk\u00f6mmliche Speicherl\u00f6sungen, die auf serieller Blockarchi-tektur basieren, k\u00f6nnen schlicht nicht gen\u00fcgend Daten in der ben\u00f6tigtenGeschwindigkeit zur parallelen Berechnung an die heute verf\u00fcgbaren,durchaus KI-f\u00e4higen Hochleistungsprozessoren liefern.\nW\u00e4hrend das Interesse an KI in den letzten Jahren zugenommen\nhat und das Volumen der unstrukturierten Daten explodiert, lie\u00df die Innovation bei den gebr\u00e4uchlichen Speichertechnologien weitgehendauf sich warten. Die wesentlichen Grundprinzipien haben sich seit Jahr-\n12\nRechenzentren und Infrastruktur \u2161/2018STORAGE\nKlug genug f\u00fcr k\u00fcnstliche Intelligenz\nNeue L\u00f6sungen schlie\u00dfen die L\u00fccke zwischen KI-Anforderungen und Speicherstruktur\nArtificial Intelligence zieht Daten ohne Ende, am liebsten in Echtzeit. Erst die Bew\u00e4ltigung riesiger Mengenunstrukturierter Daten mittels vollst\u00e4ndig Flash-basierten Objektspeicherl\u00f6sungen wird KI endg\u00fcltig zumDurchbruch verhelfen. Damit ist dann auch der Weg zum datenzentrischen Unternehmen frei.\n\u201eMassively parallel\u201c lautet die Grundanforderung f\u00fcr jede KI-taugliche IT.\nQuelle: Pure Storage zehnten nicht ver\u00e4ndert. Fakt ist: Die meisten Speichertechnologienwurden in der vergangenen \u00c4ra der seriellen Verarbeitung konzipiert,was die Performancel\u00fccke zwischen Rechen- und Speicherressourcenimmer gr\u00f6\u00dfer werden lie\u00df.\nDer Durchbruch in Sachen KI gelang erst durch die j\u00fcngsten Fort-\nschritte in den Bereichen DL (Deep Learning), GPU (Graphics ProcessingUnit) und insbesondere bei der Speichertechnologie. Deep Learning istein Rechenmodell mit massiv parallelen neuronalen Netzwerken, inspi-riert von der Funktionsweise des menschlichen Gehirns. Das DL-Modellarbeitet nach dem Prinzip des Lernens aus vielen Beispielen. Zugleicherm\u00f6glichen es heute modernste GPUs, also Grafikprozessoren mit Tau-senden von Kernen, diese DL-Algorithmen auszuf\u00fchren, die die paralleleNatur der menschlichen Gehirnt\u00e4tigkeit nachahmen.\nHinzu kommt die ma\u00dfgebliche neue, zuvor bisweilen untersch\u00e4tzte\nRolle der Speichertechnologie. KI stellt unterschiedliche Anforderungenan die zugrundeliegende Storage-Architektur. Um KI-Algorithmen wei-terzuentwickeln und zu verbessern, muss der Speicher eine umfas-sende Leistung f\u00fcr alle Arten von Zugriffsmustern bieten \u2013 von kleinenbis gro\u00dfen Dateien, von zuf\u00e4lligen bis sequenziellen Zugriffsmustern,von niedriger bis hoher Parallelit\u00e4t. Entscheidend ist dar\u00fcber hinausdie F\u00e4higkeit, einfach linear und unterbrechungsfrei zu skalieren, umdie Kapazit\u00e4t und Leistung zu steigern.\nNeue Speicher f\u00fcr KI-Workloads\nDaher sind heute Speicherl\u00f6sungen gefragt, die von Grund auf f\u00fcr moderne, unstrukturierte Workloads entwickelt wurden. Erst damit gelingtes, unstrukturierte Daten effizient zu speichern, einfach zu verwaltenund besser nutzbar zu machen. \nIn den letzten zwei Jahren sind erste vollst\u00e4ndig Flash-basierte \nObjektspeicherplattformen auf den Markt gekommen. Solche L\u00f6sungensind auf einer breit gefassten parallelen End-to-End-Architektur auf-gebaut. Sie stellen ein flexibles Scale-out-System bereit, das Benutzerndie erforderlichen Ressourcen f\u00fcr die Verarbeitung vieler Petabytes anunstrukturierten Datens\u00e4tzen bietet \u2013 auf einem \u00e4hnlichen Preisniveauwie Hybrid-Arrays. Die modernen Objektspeicherl\u00f6sungen sind jedochoptimiert f\u00fcr hohe Parallelit\u00e4t, hohe Bandbreite, hohe IOPS-Raten, enormeMetadatenperformance und eine konstant niedrige Latenz, bei gerin-gem Platzbedarf im Rechenzentrum. Typische Workloads in heutigenHochleistungsanwendungen \u2013 KI, ML, DL, Big-Data-Analytik, aufwen-dige Simulationen oder Genomforschung etc. \u2013 k\u00f6nnen damit problem-los bew\u00e4ltigt werden.\nDer j\u00fcngste Trend geht zu einer Infrastruktur, die \u201eAI ready\u201c ist, also\nzu einer speziell f\u00fcr KI konzipierten Rechen- und Speicherumgebung.Diese wird Unternehmen in die Lage versetzen, ohne gro\u00dfen Imple-mentierungsaufwand Daten in bisher unerreichter Geschwindigkeit inInnovationen umzusetzen. Eine derartige integrierte Software- undHardwarekombination l\u00f6st die oft komplexen Infrastrukturprobleme,die Unternehmen bislang davon abgehalten haben, eine KI-L\u00f6sung zuimplementieren. Der Ausweg ist eine \u201eschl\u00fcsselfertige\u201c Kombinationaus Flash-basiertem Objektspeicher mit mehreren GPU-basiertenHochleistungscomputern, die eine Performance im PetaFLOP-Bereichversprechen.\nMit dem Aufkommen von KI und Machine Learning sind die Daten\nvom Informationsgut zum Kern der Innovation geworden. Es reicht nichtmehr aus, nur datengetrieben zu sein. Unternehmen m\u00fcssen datenzen-trisch werden. Die Daten befinden sich mittlerweile in einer Multi-Cloud-Umgebung, wo sie gespeichert, ausgetauscht und analysiert werden.Die Entwicklung hin zu webbasierten Anwendungsarchitekturen hat die Anforderungen an die Speicherung ebenso erheblich ver\u00e4ndert.Das datenzentrische Unternehmen \nNeue Technologien wie Flash-basierte Objektspeicher und KI-Infra-strukturl\u00f6sungen erm\u00f6glichen es, das Rechenzentrum neu zu konzi-pieren. Bisherige Speichersilos im Rechenzentrum werden aufgebro-chen, um einen breiten Datenaustausch zu erm\u00f6glichen. Die dadurchweitaus effizientere und leistungsf\u00e4higere Datenspeicherung und -ver-arbeitung erm\u00f6glicht es Unternehmen, mehr aus ihrem Datenpool herauszuholen \u2013 insbesondere aus den bislang schwer nutzbaren unstrukturierten Daten.\nOptimierte Ans\u00e4tze f\u00fcr die Kommunikation zwischen Datenverar-\nbeitung und Speicher, namentlich die modernen Speicherklassenpro-tokolle NVMe (Non-volatile Memory Express) und NVMe-oF (NVMe overFabrics), haben ein neues Potenzial erschlossen. Das Rechenzentrumkann um die Daten herum gestaltet werden \u2013 im Sinne einer daten-zentrischen Architektur. Ein schnelles Netzwerk bietet dabei flexibelskalierbaren Zugriff auf Shared-Accelerated-Storage-Ressourcen.Speicher- und Rechenressourcen sind entkoppelt, woraus flexiblereSkalierbarkeit resultiert, w\u00e4hrend die erforderliche Performance gew\u00e4hrleistet bleibt. Dies ist ein \u00fcberzeugender Ansatz f\u00fcr moderne,massiv parallele, datengesteuerte Cloud-Anwendungen. Riesige Daten-s\u00e4tze k\u00f6nnen latenzarm verarbeitet werden, worauf es bei KI- und ML-Szenarien, Echtzeitanalytik und Anwendungen im rapide wachsenden(Industrial) Internet of Things ankommt. Die gesamte datenzentrischeInfrastruktur ist ausgelegt auf agilen Datenaustausch zwischen Anwen-dungen untereinander und dem Datenspeicher. Die neuen vollst\u00e4ndigFlash-basierten Objektspeicherl\u00f6sungen spielen dabei eine entschei-dende Rolle \u2013 als uneingeschr\u00e4nkt KI-f\u00e4hige Datendrehschreibe aufH\u00f6he der Zeit.\nMarkus Grau,\nPrincipal Systems Engineer, Pure Storage Germany GmbH\n13\nRechenzentren und Infrastruktur \u2161/2018STORAGE\nQuelle: Pure Storage \nIm M\u00e4rz 2018 kam die AI-ready-Infrastruktur AIRI f\u00fcr skalierbareKI-Anwendungen auf den Markt: Pure Storage FlashBlade plusNvidia DGX-1.Anlagen- und Prim\u00e4rmultiplexanschl\u00fcsse laufen auf einer anderenPlattform als Double-Play-Anschl\u00fcsse\u201c,  erkl\u00e4rt Klaus M\u00fcller,  Leiter\nstrategische Entwicklung und Transformation bei der Telekom Deutsch-land Gesch\u00e4ftskunden.  Deshalb sei hier der Umstellungstermin zum\nJahreswechsel 2018/2019 nicht so strikt.  Bei einem Pressegespr\u00e4ch\nw\u00e4hrend der Hausmesse Digital South Mitte Mai in M\u00fcnchen verk\u00fcn-dete die Telekom die aktuellen Zahlen der Umstellung auf All-IP ,  wies\nauf unterst\u00fctzende Angebote gerade f\u00fcr Gesch\u00e4ftskunden hin und pr\u00e4-sentierte verschiedene Umstellungsszenarien.\nDer Umstellungsgrad bei Gesch\u00e4ftskundenanschl\u00fcssen liegt dem-\nnach mit 1,9 Millionen Anschl\u00fcssen bei 85 %.  Das betrifft haupts\u00e4ch-\nlich kleinere Unternehmen und Filialisten.  Denn die Telekom brachte\nihren SIP-Trunk erst vor einem Jahr auf den Markt und die Deutsch-landLAN CloudPBX noch deutlich sp\u00e4ter.  Derzeit verkauft sie laut M\u00fcller\nrund 1600 SIP-Trunks und 300 Cloud-Telefonanlagen pro Woche anGesch\u00e4ftskunden.  Die SIP-Trunk-L\u00f6sung kam laut Karsten Lebahn,  Lei-\nter IP Transformation Sonderdienste bei der Telekom,  erst deshalb so\nsp\u00e4t auf den Markt,  weil sie auch f\u00fcr die Gro\u00dfkunden von T-Systemseingesetzt wird.  Entsprechend robust muss sie sein und dabei m\u00f6g-\nlichst viele TK-Anlagen und Dienste unterst\u00fctzen.\nSIP-Trunk-Anbindung\nSIP-Trunks ersetzen k\u00fcnftig den Anlagenanschluss.  Damit die TK-An-\nlage oder die entsprechende Voice-over-IP-Serversoftware im Unter-nehmen reibungslos mit der Software  im Carrier-Netz kommuniziert,\nsind an den R\u00e4ndern von LAN und Carrier-Netz SBC (Session BorderController) notwendig.  Diese koordinieren die SIP-Kommunikation  \nzwischen  Netzanbieter  und IP-Kommunikationsserver  im Unternehmen.\nAufgrund der unterschiedlichen Auslegung des SIP-Protokolls unter-st\u00fctzt nicht jeder Netzanbieter jede Anlage,  auch die Telekom nicht.\nDeshalb sollten sich Firmen,  die im LAN bereits eine IP-TK-Anlage  \nbetreiben,  vorab beim Hersteller erkundigen,  welche Netzanbieter diese\nAnlage mit der betriebenen Softwareversion unterst\u00fctzt.  Sollte es kei-\nnen geben,  ist entweder ein Software-Upgrade notwendig oder eine\ndarauf abgestimmte Konfiguration im SBC.\n14\nRechenzentren und Infrastruktur \u2161/2018ALL-IP\nAnlagenanschl\u00fcssebekommen Aufschub\nDie Umstellung auf reine IP-Telefonie hat die problematischen F\u00e4lle noch vor sich\nSeit zwei Jahren predigt die Telekom,  dass ISDN Ende 2018 abgeschaltet wird.  Bis Mitte Mai wurden bereits\nmehr als 90 % der Sprach-/Datenanschl\u00fcsse auf Breitband umgestellt.  F\u00fcr Filialen und kleine B\u00fcros gilt der\nTermin weiterhin,  doch Niederlassungen mit eigener TK-Anlage bekommen eine letzte Frist.\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n F\u00fcr Gesch\u00e4ftskunden,  die bisher ihre Telefonie mit einer klassischen\nISDN-TK-Anlage realisiert haben,  ist es m\u00f6glich,  die bisherige L\u00f6sung\nmit den Endger\u00e4ten weiter zu betreiben und \u00fcber ein Gateway mit demIP-Netz des Providers zu verbinden.  Doch dann werden zahlreiche ISDN-\nDienste nicht mehr funktionieren.\nVon der IP-TK-Anlage zur Cloud\nSehr viele  Unternehmen  nutzen  die All-IP-Umstellung  zur Einbindung  von\nVoice over IP als gesch\u00e4ftskritischer Anwendung in die Unternehmens-IT. Doch das LAN muss daf\u00fcr ausgelegt sein:  nicht nur mit einem  \nentsprechenden Bandbreitenmanagement und der Priorisierung vonSprachdaten,  sondern auch mit einer \u00dcberarbeitung des Ausfallsicher-\nheitskonzeptes.\nDie IP-TK-Anlage im Unternehmen kann ein dedizierter Kommuni-\nkationsserver sein,  eine Serversoftware oder eine Anwendung in der\nUnternehmenscloud.  Alternativ bietet sich auch eine Private-Cloud-L\u00f6-\nsung im Rechenzentrum eines Colocators an.  Dort lassen sich in einer\nabgesicherten Umgebung vielf\u00e4ltige Hybrid-Cloud-Anwendungsszena-rien realisieren,  die weit \u00fcber klassische UCC-L\u00f6sungen (Unified Com-\nmunication and Collaboration) hinausgehen.\nF\u00fcr Gesch\u00e4ftskunden  bietet  die Telekom  Migrationsworkshops  an. Laut\nKlaus M\u00fcller haben bereits mehr als 43.000 solcher Workshops stattge-funden.  Nach dem  ersten Anschreiben der Telekom h\u00e4tten jetzt die meis-\nten Unternehmen ihre vorhandene Infrastruktur bereits dokumentiert.\nWer noch in der Migration stecke,  solle laut Karsten Lebahn nicht\nnur ein besonderes Augenmerk auf Sonderdienste wie Faxger\u00e4te oderrein analoge Anschl\u00fcsse legen,  sondern auch s\u00e4mtliche Rufweiterlei-\ntungen genau dokumentieren.  Denn mit der Umstellung m\u00fcssten diese\nWeiterleitungen wieder neu konfiguriert werden,  lie\u00dfen sich aber\nmanchmal nicht mehr rekonstruieren.  Solche Tipps erhalten Unterneh-\nmen in der Regel kostenlos in den Workshops oder von Projektmana-gern,  die die Telekom extra f\u00fcr die IP-Umstellung bereitgestellt hat.  Ge-\nrade Firmen  mit vielen  Filialen  oder  Franchising-Partnern  profitieren\nauch von Rollout-Begleitern.  Diese erstellen den Rollout-Plan in enger\nZusammenarbeit mit den Unternehmen,  sodass selbst Firmen mit 1000bis 2000 Filialen,  aber wenigen IT-Mitarbeitern 80 bis 100 Filialen pro\nWoche umstellen k\u00f6nnen.\nUnternehmen mit Anlagen- oder Prim\u00e4rmultiplexanschluss sollten\nsich trotz Fristverl\u00e4ngerung rechtzeitig auf die Umstellung vorbereiten.Die entsprechenden Projektmanager und Rollout-Begleiter werden n\u00e4m-lich laut Lebahn im n\u00e4chsten Jahr nicht mehr zur Verf\u00fcgung stehen.\nFTTB f\u00fcr Gewerbegebiete\nBasis f\u00fcr die Umstellung auf All-IP ist der Netzausbau auf Fiber to theCurb und Vectoring.  Damit stehen bis zu 100 MBit/s Bandbreite zur Ver-\nf\u00fcgung.  An manchen Stellen wird bereits auf Supervectoring umgestellt.\nDas erlaubt Bandbreiten bis 250 MBit/s.  Doch diese Techniken seien nur\n\u00dcbergangstechnologien.  Langfristig soll das Telekom-Netz laut M\u00fcller f\u00fcr\nFiber to the Building/Home (FTTB/H) und 1 GBit/s ausgebaut werden.Das ist einfacher,  wenn die Glasfaser bereits bis zum Multifunktionsge-\nh\u00e4use am Stra\u00dfenrand liegt.\nUnternehmen k\u00f6nnen sich bis zum 15.  Juli ohne zus\u00e4tzliche An-\nschlusskosten Glasfaser bis ins Geb\u00e4ude legen lassen.  Danach kostet\nes \u00fcber 670 Euro.  Aber Vorsicht:  Das ist nur kostenfrei,  solange die Er-\nschlie\u00dfungskosten unter 30.000 Euro bleiben! Liegen sie auch nur ei-nen Euro  dar\u00fcber,  muss  der Auftraggeber  komplett  f\u00fcr die Erschlie\u00dfung\naufkommen.\nEine wichtige Zielgruppe f\u00fcr den 1-GBit/s-FTTB-Anschluss Deutsch-\nlandLAN Connect IP sieht die Telekom bei Gewerbegebieten mit 20 bis40 Firmen.  Das sind deutschlandweit etwa 10.000 St\u00fcck.  Hier sei zum\neinen von Vorteil,  dass bereits FTTC verlegt sei,  und zum anderen,  dass\ngen\u00fcgend potenzielle Kunden vorhanden sind,  sodass sich die Ausbau-\nkosten tragen.  Bis 2022 will die Telekom 3000 solcher Gewerbegebiete\nmit FTTB versorgt haben.  \u00dcber 50 sind laut M\u00fcller bereits freigegeben\nund im Ausbau,  bei 75 weiteren sei die Vorvermarktung abgeschlossen.\nAuch hier verlangt die Telekom nichts f\u00fcr die Bereitstellung des Netzes.Der Einstiegstarif f\u00fcr die Nutzer liegt bei knapp 80 Euro.  Details zum\nGigabit-Anschluss findet man derzeit unter www.telekom.de/Vollglas.\nDoris Piepenbrink,\nfreie Journalistin,  M\u00fcnchen\n15\nRechenzentren und Infrastruktur \u2161/2018ALL-IP\n Mit Anwendungen wie IP-Telefonie und der immer umfassenderen  \nVirtualisierung steigen die Verf\u00fcgbarkeitsanforderungen an ein Rechen-zentrum.  Das gilt auch f\u00fcr kleine und mittelst\u00e4ndische RZ,  bei denen\ndie Umweltdaten bisher nur rudiment\u00e4r \u00fcberwacht wurden.  \nAnforderungsanalyse nach DIN EN 50600\n\u00dcber eine Anforderungsanalyse nach DIN EN 50600 k\u00f6nnen IT-Verant-wortliche ermitteln,  an welchen Stellen und wie tiefgehend sie in ihren\nRZ Stromverbrauch und Umweltwerte ermitteln und \u00fcberwachen sollen.Die Normenreihe f\u00fcr die Auslegung von Rechenzentren basiert auf einerBedarfs- und Risikoanalyse.  Um die hierbei festgelegten Ziele und Bed\u00fcrf-nisse zu erreichen,  ben\u00f6tigt der Betreiber \u201ewirksame Informationen f\u00fcr\ndas Management und den Betrieb\u201c.  Diese k\u00f6nnen bei jedem Unterneh-\nmen je nach ermittelter Verf\u00fcgbarkeits- und physikalischer Schutzklassegem\u00e4\u00df DIN EN 50600-1 unterschiedlich detailliert ausfallen.  Die \nGranularit\u00e4tsniveaus stellen die Einteilung f\u00fcr die \u201eBef\u00e4higung zur Ener-gieeffizienz\u201c dar.  Daraus folgt unter anderem,  an welchen Stellen die\nEnergieverbrauchswerte zu erfassen sind.  Die Normenreihe gibt f\u00fcr die\nverschiedenen Klassen und Niveaus auch Empfehlungen f\u00fcr die prak-tische Umsetzung.  F\u00fcr das Datacenter Infrastructure Management\n(DCIM) sind dabei folgende Teilnormen relevant:  DIN EN 50600-2-2\n(Stromversorgung),  DIN EN 50600-2-3 (\u00dcberwachung der Umgebung),\nDIN EN 50600-2-5 (Sicherungssysteme) und DIN EN 50600-99-1 (Emp-fohlene Praktiken f\u00fcr das Energiemanagement).\nPraktische Umsetzung\nEin DCIM kann auf viele verschiedene Arten realisiert werden.  Solche\nL\u00f6sungen zeigen auf diversen Konsolen anschaulich,  wie das Rechen-\nzentrum aufgebaut ist.  Sie veranschaulichen,  welche Ger\u00e4te wo im RZ\nvorhanden sind \u2013 sowohl aus r\u00e4umlicher Sicht als auch aus Sicht derVerkabelung,  der Belegung der Kernkomponenten wie des Stromver-\nteilnetzes oder der Vernetzung aller Systemkomponenten.  Dar\u00fcber  \nhinaus sammelt ein DCIM alle verf\u00fcgbaren Daten der angeschlossenenSystemkomponenten und korreliert sie.  Es zeigt,  wie stark welche RZ-\nBereiche ausgelastet sind,  darunter auch den Stromverbrauch oder die\nK\u00fchlleistung.  Es sammelt Messwerte \u00fcber Umgebungsparameter wie\nTemperatur und Luftfeuchte und steuert Zugangssysteme.  Mit DCIM\nlassen sich Lastspitzen,  beispielsweise im Stromverbrauch,  besser  \nbewerten und mit weiteren Protokolldaten in Relation setzen.  Bei den\nmeisten Parametern ist es \u00fcbrigens sinnvoll,  jeweils zwei obere und\nzwei untere Schwellwerte zu definieren.  So wird der Administrator\nfr\u00fchzeitig gewarnt und kann rechtzeitig Gegenma\u00dfnahmen ergreifen.\nSensoreinbindung \nF\u00fcr die Datensammlung arbeiten die meisten  L\u00f6sungen  mit 1HE-Steuer  -\neinheiten f\u00fcr den Rack-Einbau.  Der Anwender kann daran mehrere\nSensoren anschlie\u00dfen.  Sie verf\u00fcgen in der Regel \u00fcber ein Display,  das\ndie anliegenden Messwerte anzeigt.  Parallel dazu werden die Daten\nzum Beispiel \u00fcbers LAN an eine zentrale Managementsoftware gesen-det. Es geht aber auch platzsparender:  Viele Rechenzentren setzen in\nihren Schr\u00e4nken bereits PDUs (Power Distribution Units) zur Stromver-teilung und -messung ein.  Die programmierbaren iPDUs von Raritan\n16\nRechenzentren und Infrastruktur \u2161/2018DCIM-SENSORIK\nIntelligente Messtechnikverhindert Ausf\u00e4lle\nEin DCIM mit verteilter Sensorik schafft \u00dcberblick und sichert die Verf\u00fcgbarkeit\nZugangskontrollen,  die \u00dcberwachung der Verbrauchsdaten oder das fr\u00fchzeitige Aufsp\u00fcren von Hitzenestern sind\nin mittleren RZ genauso wichtig wie in Gro\u00dfrechenzentren.  Der Markt bietet dazu vielf\u00e4ltige Sensoren und\n\u00dcberwachungssysteme an,  die sich einfach in vorhandene Infrastrukturen integrieren lassen.\nRZ-Manager ben\u00f6tigen f\u00fcr ihr DCIM zahlreiche Informationen,  um\ndie Sicherheit,  Verf\u00fcgbarkeit und Bezahlbarkeit der Dienste zu\ngew\u00e4hrleisten.\nQuelle:  Raritan  verf\u00fcgen zudem \u00fcber einen Sensorport, der unter anderem \u00fcber diewebbasierte Software der PDU angesprochen werden kann. Die iPDUswerden wie sonst auch seitlich am Holm oder ganz oben oder untenim Schrank montiert. Sie ben\u00f6tigen keine zus\u00e4tzliche Verkabelung, unddie Stromversorgung f\u00fcr die angeschlossenen Sensoren wird \u00fcber diePDU mitgeliefert. \nDie 1HE-Steuereinheiten und die iPDUs geben die Messdaten per\nSNMP , TCP oder \u00fcber eine serielle Busschnittstelle wie Modbus an dieManagementplattform weiter. Umfang und Aufbau der L\u00f6sung richtensich nach dem Bedarf. Es gibt einfache Monitoring-L\u00f6sungen, etwa allein zur Auswertung der Verbrauchsdaten oder der Umgebungsdaten,sowie modulare Systeme, die sich zu einer umfassenden DCIM-Soft-ware erweitern lassen. Konfiguration und Monitoring erfolgen dabeimeist webbasiert und remote \u00fcbers LAN oder WLAN sowie vor Ort \u00fcbereinen Konsolenanschluss (USB- oder RS232C-Schnittstelle).\nStromverbrauch\nEine \u00dcberwachung des Stromverbrauchs erm\u00f6glicht einen energiespa-renden Betrieb und eine detaillierte Analyse der Verbraucher im Rechenzentrum. So ist schnell ersichtlich, wann welche KomponentenAuslastungsspitzen verursachen.\n\u00dcber die Anforderungsanalyse ergibt sich f\u00fcr ein Rechenzentrum\ndas Granularit\u00e4tsniveau f\u00fcr die Messung von Verbrauchskennwerten.Um Aussagen \u00fcber die PUE (Power Usage Effectiveness) treffen zu k\u00f6n-nen, muss je nach Aufbau des Rechenzentrums der Verbrauch an ver-schiedenen Stellen gemessen werden. Wichtig ist, dass die verwendeteEnergie f\u00fcr IT-Ger\u00e4te getrennt von der Energie gemessen wird, die f\u00fcrandere Aufgaben wie K\u00fchlung genutzt wird. Messungen am Unterver-teiler (Niveau 2) k\u00f6nnen zum Beispiel ausreichen, wenn in den IT-Schr\u00e4nken wirklich nur IT-Ger\u00e4te sind. Sind aber Schr\u00e4nke mit inte-griertem Schrankk\u00fchlsystem im Einsatz, entspricht das dem Granula-rit\u00e4tsniveau 3. Dann sollte dort per PDU an jeder Steckdose im IT-Schrank gemessen werden. \nGrunds\u00e4tzlich gilt: Je detaillierter diese Unterscheidung erfolgt, umso\nbesser kann der Betreiber einsch\u00e4tzen, wo in seinem RZ noch Einspa-rungspotenziale sind. Mit den ermittelten Verbrauchswerten l\u00e4sst sichzum Beispiel die Lastverteilung optimieren, die Serverauslastung undgenerell die PUE verbessern. Dar\u00fcber hinaus dienen die Strom- undSpannungsmessungen nat\u00fcrlich auch dazu, die Verf\u00fcgbarkeit zu erh\u00f6-hen. Um St\u00f6rf\u00e4lle fr\u00fchzeitig zu erkennen, sollten deshalb zum Beispielzus\u00e4tzlich Messpunkte am Eingang und an den Schutzschaltern \n17\nRechenzentren und Infrastruktur \u2161/2018DCIM-SENSORIK\nSunbird Software hat f\u00fcr seine DCIM-Monitoring-Software Power IQ patentierte psychrometische Diagramme entwickelt, um Luftfeuchteund Temperatur in den von ASHRAE oder vom Hersteller geforderten Toleranzbereichen zu halten. Verantwortliche k\u00f6nnen dar\u00fcberschnell R\u00fcckschl\u00fcsse auf das Temperatur- bzw. Feuchteverhalten im RZ ziehen.\nQuelle: Sunbird Software \nDie programmierbaren iPDUs von Raritan verteilen und messen nicht nur Strom, sondern verf\u00fcgen zudem \u00fcbereinen RJ12-Sensor-Port.\nQuelle: Raritangesetzt werden. Typische Messgr\u00f6\u00dfen sind Spannung, Strom, Leis-tungsfaktor, Scheinleistung sowie die verbrauchten Kilowattstunden. \nTemperatur und Feuchte \nAktive Komponenten haben h\u00e4ufig konkrete Vorgaben zu Temperaturund Luftfeuchte in ihren Datenbl\u00e4ttern, die eingehalten werden m\u00fcssen.Die f\u00fcr die Messung ma\u00dfgebliche Temperatur ist somit die direkt amServerrack. Die American Society of Heating, Refrigerating and Air-Con-ditioning Engineers (ASHRAE) hat eine \u00fcberschaubare Methode f\u00fcr einesinnvolle Temperaturmessung im IT-Schrank entwickelt. Der Anwendermisst dabei oben, in der Mitte und unten im Schrank. Das w\u00fcrde aus-reichen, um die Temperatur genau zu steuern. Dazu k\u00f6nnen mehrereSensoren verwendet werden, manche Hersteller bieten auch entspre-chend der ASHRAE-Empfehlung einen Messaufnehmer mit drei Mess-k\u00f6pfen im notwendigen Abstand an, was die Installation erleichtert.\nDie Anforderungen an die relative Luftfeuchte sind im Rechenzen-\ntrum ebenfalls hoch und mit engen Toleranzen belegt. Zu trockene Luftkann zu elektrostatischer Aufladung f\u00fchren, zu feuchte zu Korrosionan den Ger\u00e4ten. Die Luftfeuchte sollte zum einen m\u00f6glichst an der Zuluft gemessen werden, noch bevor sie durch den Schrank geht. Zumanderen empfiehlt ASHRAE eine kombinierte Messung von Temperaturund Luftfeuchte mit gemeinsamen Messpunkten, die f\u00fcr das Klimama-nagement herangezogen werden k\u00f6nnen. \nAbgesehen davon sollten Grenzwert\u00fcberschreitungen generell m\u00f6g-\nlichst direkt an den Sensoren gut sichtbar angezeigt werden, damit dasWartungspersonal sie auf einen Blick erkennen kann. Au\u00dferdem solltendie Sensoren leicht austauschbar sein. Denn erfahrungsgem\u00e4\u00df steigtnach einigen Jahren der Messfehler aufgrund von Langzeitdrift merklich.F\u00fcr das Klimamanagement im\nSchrank hat ASHRAE ein Diagramm alspraktisches Hilfsmittel ver\u00f6ffentlicht.Dieses ASHRAE-Diagramm bildet dieerfassten Messpunkte mit ihrer Tempe-ratur auf der X-Achse und ihrer relati-ven Feuchte auf der Y-Achse ab. Solangesich diese Messpunkte innerhalb einesbestimmten Bereiches befinden, ist allesin Ordnung (gr\u00fcne Messpunkte); sobaldsich ein Wert aufgrund einer Tempera-tur- oder Feuchteschwankung au\u00dfer-halb des erlaubten Bereiches befindet,wird der Messpunkt rot. Dann sind\nMa\u00dfnahmen zu ergreifen, um den Wert wieder in den gr\u00fcnen Bereichzu bringen. Mit dem ASHRAE-Diagramm kann ein RZ-Verantwortlicherschnell R\u00fcckschl\u00fcsse auf das Temperatur- bzw. Feuchteverhalten ziehen. Befinden sich zum Beispiel alle Messpunkte im erlaubten Bereich, aber nahe am linken Rand, so hei\u00dft das, dass es gefahrlosm\u00f6glich ist, die K\u00fchltemperatur anzuheben. Eine Erh\u00f6hung f\u00fchrt direktzu Energieeinsparungen. Die Grenzwerte f\u00fcr den erlaubten Bereich geben ASHRAE oder zum Beispiel Serverhersteller vor.\nWasser, Luft und Vibration\nUndichte Wasserzuf\u00fchrungen sorgen zum einen f\u00fcr eine ungen\u00fcgendeK\u00fchlung, f\u00fchren aber vor allem zu Besch\u00e4digungen an Bauelementenoder zu Kurzschl\u00fcssen. \u00c4hnliches gilt f\u00fcr eine Ansammlung von Kon-denswasser. Aus diesem Grund sollten unter den Zuleitungen und amSchrankboden Leckagesensoren angebracht werden. Diese schlagenAlarm, sobald sie Fl\u00fcssigkeit detektieren. \nVor allem in Schr\u00e4nken mit viel aktiver Technik (Serverschr\u00e4nke,\nSwitching-Fabrics etc.) ist ein K\u00fchlkonzept mit gelenktem Luftstromsinnvoll, um potenzielle Hitzenester ausreichend zu k\u00fchlen. Bei einemKomponententausch oder beim Ausfall eines L\u00fcfters kann sich derLuftstrom jedoch ver\u00e4ndern. Um sicherzugehen, dass die CPUs weiterausreichend k\u00fchlende Luft erhalten, sollte die Zuluft an den kritischenStellen sowie im Doppelboden \u00fcberwacht werden. Dar\u00fcber hinauskann es sinnvoll sein, den Differenzluftdruck zwischen Warm- und Kalt-gang bzw. oberhalb und unterhalb des Doppelbodens zu ermitteln. Mit-hilfe der Messdaten von Differenzluftdruck, Lufteintritts- und Austritts-temperatur kann zum Beispiel die Leistung von L\u00fcfter und Kompressoreiner K\u00fchlanlage geregelt werden.\nServer reagieren empfindlich auf Ersch\u00fctterungen. Vibra-\ntionen treten nicht nur in erdbebengef\u00e4hrdeten Regionen auf,sondern auch in der N\u00e4he von Baustellen, viel befahrenenBahntrassen oder gro\u00dfen Maschinen. Hier m\u00fcssen die emp-findlichen Ger\u00e4te entsprechend gesch\u00fctzt werden. Mit einemVibrationssensor kann man zum Beispiel messen, ob ein Ein-zelereignis verantwortlich ist f\u00fcr eine erh\u00f6hte Fehlerratebeim Festplattenzugriff. Bei Maschinen mit rotierenden Teilenkann der Anwender mit dem Vibrationssensor auch eineTrendverfolgung durchf\u00fchren. \nAsset Management und Zugangskontrolle\nEs gibt verschiedene M\u00f6glichkeiten, Ger\u00e4te, Komponentenund Racks in die Inventarisierung des Rechenzentrums auf-zunehmen. Raritan etwa arbeitet mit sogenannten Asset \n18\nRechenzentren und Infrastruktur \u2161/2018DCIM-SENSORIK\nQuelle: RaritanDie Messdaten kommen per SNMP , TCP/IP oder Modbus in das DCIM-System.\nQuelle: Raritan\nEs gibt die verschiedensten\nUmweltsensoren, im Bild dargestellt \nsind von links nach rechts Sensoren \nf\u00fcr Temperatur und Feuchte,\nDifferenzdruckluft und zwei f\u00fcr Leckage.Management Tags, in denen jeweils eine ID-Nummer f\u00fcr das ange-schlossene Ger\u00e4t abgespeichert ist. Die Tags werden fest mit diesemGer\u00e4t verbunden und f\u00fchren zu einem Asset Management Strip (AMS),der neben der 19-Zoll-Ebene senkrecht im Schrank eingebaut ist. Die-ser bietet f\u00fcr jede HE einen Anschlusspunkt sowie LEDs, die \u00fcber denZustand der angeschlossenen Ger\u00e4te informieren. Bladeserver-AMSsbieten das Gleiche f\u00fcr Bladeserver oder andere Komponenten, die ineinen Einbaurahmen integriert werden. Der AMS ist direkt mit der iPDUbzw. der 1HE-Steuereinheit EMX verbunden und \u00fcbermittelt per SNMP ,welcher Tag mit welchem Anschlusspunkt verbunden ist. Dar\u00fcber istes einfach zu ermitteln, in welchem Rack und an welcher Stelle imRack sich ein bestimmter Server befindet. Das sind Basisinformationenf\u00fcr ein DCIM-System.\nDar\u00fcber hinaus lassen sich auch Zugangskontrollen in solche \nSysteme integrieren. Diese werden entweder an Rack- oder Einhau-sungst\u00fcren angebracht oder an der Grenze zwischen zwei Schutz-klassen. Sie bestehen in der Regel aus einem Verriegelungssystem,Sensoren, die \u00fcber T\u00fcrzustand und Verriegelungszustand informieren,sowie einem Authentifizierungsmechanismus mit verschl\u00fcsselterKommunikation.\nDifferenzstrommessung\nDifferenzstrommessungen dienen dem Brandschutz und indirekt auchdem Personenschutz, da das System bei einer Grenzwert\u00fcberschrei-tung einen Alarm ausgeben kann. Diese Messungen sind nach DIN VDE0100 zwingend erforderlich. So schreibt die DGUV V3 die regelm\u00e4\u00dfigePr\u00fcfung von elektrischen Anlagen und Betriebsmitteln nach bestimm-ten Kriterien vor. Dazu m\u00fcssen die Anlagen abgeschaltet werden, wasim RZ aber meist schwer realisierbar ist. Eine permanente Differenz-strom\u00fcberwachung kombiniert mit weiteren Prozessen wird unter Um-st\u00e4nden von der Berufsgenossenschaft akzeptiert, sodass man Pr\u00fcf-zyklen verl\u00e4ngern kann oder sogar komplett von der turnusm\u00e4\u00dfigenPr\u00fcfung befreit wird. \nF\u00fcr den Personenschutz entscheidend ist, welcher Strom durch den\nK\u00f6rper flie\u00dft. Daher d\u00fcrfen Personen nicht mit Bauteilen in Ber\u00fchrungkommen, die unter Spannung stehen und einen Stromfluss von 30 mAoder mehr durch den K\u00f6rper hervorrufen. F\u00fcr den Brandschutz sindmaximal 300 mA zul\u00e4ssig. Server beispielsweise haben bauartbedingteinen Fehlerstrom. Deshalb sollten nach einer Analyse individuelleSchwellwerte festgelegt werden. Je feiner die Messpunkte verteilt sind,umso genauer kann der Administrator bei Grenzwertverletzungen dieUrsache lokalisieren. Aus diesem Grund bieten moderne PDUs heuteeine permanente \u00dcberwachung der Differenzstromwerte mit einstell-baren Schwellwerten und einer softwaregesteuerten Funktionskontrollean. Werden die Daten mit einer DCIM-L\u00f6sung verarbeitet, lassen sichaus den Messdaten Trends ermitteln und Handlungsketten bei \u00dcber-schreiten eines Schwellwerts definieren.\nAuswertung und Alarmierung\nVerschiedene Ereignisse erfordern unterschiedliche Benachrichti-gungsarten. Bei Feuer oder \u00dcberflutung sind ein m\u00f6glichst lauter, gutsichtbarer Alarm und eine Benachrichtigung \u00fcber alle Kan\u00e4le notwen-dig. Oft sind damit gleich automatische Abl\u00e4ufe wie der Ruf der Feuerwehr sowie das \u00d6ffnen der Fluchtt\u00fcren gekoppelt. WerdenGrenzwerte oder gar nur Schwellwerte bei Messungen erreicht, mussder daf\u00fcr zust\u00e4ndige Sachbearbeiter informiert werden, um das Pro-blem kompetent zu analysieren. \nGrunds\u00e4tzlich sollte man immer parallel mehrere Benachrichti-\ngungswege konfigurieren, etwa optisch \u00fcber LEDs und akustisch \u00fcbereinen Alarm am Sensor. H\u00e4ufig werden auch rollenbasiert E-Mailsoder SMS versendet. Viele DCIM-Systeme arbeiten heute mit Stan-dardschnittstellen wie SNMP , TCP/IP und seriellen Bussystemen zurIntegration von Sensoren und Aktoren. Die PDU-basierte L\u00f6sung vonRaritan bietet eine einfache M\u00f6glichkeit, Sensoren und Aktoren im RZzu integrieren. Sie m\u00fcssen einfach nur an den entsprechenden Sen-sorports angeschlossen werden. Der Anwender hat viele M\u00f6glichkei-ten, die iPDUs remote zu konfigurieren und zu administrieren. Die L\u00f6sung unterst\u00fctzt IPv4 und IPv6. Der Zugriff ist passwortgesch\u00fctzt,au\u00dferdem kann der Administrator Rollen definieren und sie bestimm-ten Anwendern zuordnen. Auch eine RADIUS-basierende Authentifi-zierung ist konfigurierbar.\nZudem l\u00e4sst sich die L\u00f6sung nahtlos in die modulare DCIM-L\u00f6sung\nvon Sunbird Software oder in ein anderes DCIM-System mit SNMP ,TCP/IP oder Modbus-Schnittstelle einbinden. Die Daten k\u00f6nnen auf einer gemeinsamen Oberfl\u00e4che ausgewertet und sowohl von der IT-Abteilung als auch vom Geb\u00e4udemanagement genutzt werden.\nRoberto Sammler, \nSales Engineer DACH, Raritan Deutschland\n19\nRechenzentren und Infrastruktur \u2161/2018DCIM-SENSORIK\nEs gibt heute so gut wie nichts, was man nicht messen und in einDCIM aufnehmen k\u00f6nnte: RZ-Technik und Umgebungsdaten, auchf\u00fcr fast alle Bussysteme der Geb\u00e4udeautomation gibt es IP-Gate-ways, die die Daten aus BACnet (Geb\u00e4udemanagement), KNX(Raumautomation), Dali (Beleuchtung), Modbus (Heizung/Klima) undanderen in SNMP und HTTP umsetzen, sodass sie \u00fcbers LAN in einezentrale Management-L\u00f6sung integriert werden k\u00f6nnen. F\u00fcr Funk-sensoren sind solche Gateways ebenso verf\u00fcgbar, zum Beispiel f\u00fcrdie batterielos betriebenen Enocean- oder Zigbee-Sensoren. W\u00e4hrend Data Center Infrastructure Management in den meistenRZ unter den Aspekten von Automatisierung und Energieeffizienzgesehen wird, geht es bei Edge- und Mikro-RZ direkt ans Einge-machte \u2013 umso mehr, je st\u00e4rker sich immer mehr Rechenleistungan den Ursprung der Datengenerierung verlagert. Edge-Datacenterbefinden sich zum Teil im Freien, wie Trafoh\u00e4uschen. Der gr\u00f6\u00dfteTeil der Steuerung geschieht hier remote. Und es liegt auf der Hand,dass es hier ohne Ersch\u00fctterungs- und Au\u00dfentemperaturkontrollenetc. gar nicht geht. F\u00fcr Sunbird Software ist DCIM daher \u201eein kriti-scher Erfolgsfaktor am Edge\u201c.Am Edge wird es allerdings nicht mehr m\u00f6glich sein, Sensorik undDCIM-Funktionen \u201eschrittweise\u201c zu implementieren, denn dortgeh\u00f6ren sie zur Sicherheitsgrundausstattung von Anfang an. Hinzukommt, dass ein Betreiber in der Regel mehrere bis viele Edge-Stationen per DCIM \u00fcberwachen wird. Auch daf\u00fcr muss das Systemalso ausgelegt sein. Als passendes Schlagwort dazu bewirbt sichbereits das K\u00fcrzel DMaaS: Data Center Management as a Service.Diese Sorte Software kommt zwar aus dem Bed\u00fcrfnis nach umfas-sendem RZ-Management \u2013 parallel zu den Digital Twins in derIndustrie \u2013, trifft sich aber am Edge mit der Notwendigkeit, eineVielzahl verteilter Rechenstandorte im Griff zu behalten.            (red) \nDCIM UND DATA CENTER MANAGEMENT AS A SERVICENikolaus Kopernikus war ein Revolution\u00e4r: Er erkannte um 1500,dass die Erde sich um die Sonne dreht. Den Beweis f\u00fcr die damals\numstrittene Theorie lieferte der Mathematiker Johannes Kepler ersteinhundert Jahre sp\u00e4ter. Das nach Kopernikus benannte Erdbeobach-tungsprogramm liefert daf\u00fcr t\u00e4glich 20 Terabyte an Satellitendaten ausdem All. Copernicus DIAS (Data and Information Access Service) stelltsie f\u00fcr jedermann kostenlos bereit.\nDie EU-Kommission koordiniert und steuert das Copernicus-Pro-\ngramm. Gemeinsam mit den Mitgliedsstaaten, der ESA, der Europ\u00e4i-schen Organisation f\u00fcr meteorologische Satelliten (EUMETSAT), demEurop\u00e4ischen Zentrum f\u00fcr mittelfristige Wettervorhersage (ECMWF),weiteren EU-Agenturen und Mercator Oc\u00e9an setzt die Kommission dieInitiative um. Eine zentrale Herausforderung: Die Menge und Vielfalt anDaten macht den Zugriff schwer. \nSo w\u00e4re es zum einen nicht praktikabel, wenn Anwender die Daten\nerst herunterladen m\u00fcssten, um sie zu bearbeiten. Zum anderen istGeoinformatik komplex und rechenintensiv. An dieser Stelle setzen dieMundi Web Services an, die ein Konsortium um den franz\u00f6sischen IT-Dienstleister Atos entwickelt hat; beteiligt sind unter anderem dasDeutsche Zentrum f\u00fcr Luft- und Raumfahrt (DLR), die italienische e-GEOSsowie Spacemetric (Schweden), Sinergise (Slowenien). Mundi bringtAnwender und vorbereitete Analyseservices genau da zusammen, wodie Daten bereits liegen \u2013 im Cloud-Rechenzentrum.\nDaten, Anwender und Anbieter\nDie Mundi Web Services stehen in der Open Telekom Cloud bereit, einemPublic-Cloud-Angebot auf Basis der freien Cloud-Computing-ArchitekturOpenStack. In der Open Telekom Cloud lassen sich die Erdbeobachtungs-daten mit eigenen Programmen analysieren oder auswerten. Oder dieAnwender greifen auf die vorbereiteten Geodatendienste zu: Im MundiMarketplace stehen bereits Anwendungen zur Verf\u00fcgung. Drittanbietersind eingeladen, entsprechende Services aufzubauen, zu betreiben und \u2013wie in einem App-Store \u2013 zu vermarkten.\nDie ESA liefert die Satellitendaten kontinuierlich an. Dar\u00fcber hinaus\nerg\u00e4nzt Mundi Informationen der NASA, von privaten Betreibern oderaus Open-Data-Verzeichnissen aus dem Internet sowie aus vielen wei-teren Quellen. Alle Informationen h\u00e4lt der Object Based Storage (OBS)der Open Telekom Cloud zentral vor. Auf eine Dauer von vier Jahrengerechnet entsteht so eine Datenbank mit mehr als 40 Petabyte. \nDie OBS-Datenhaltung optimiert eine Middleware. Je nach Aktualit\u00e4t,\nNachfrage und damit erwarteter Zugriffsintensit\u00e4t wandern die Coperni-\n20\nRechenzentren und Infrastruktur \u2161/2018COPERNICUS DIAS\nDer Cloud-Atlas\nDie EU-Kommission macht Big Data aus dem All \u00fcber Public-Cloud-Server verf\u00fcgbar\n20 Terabyte an Satellitendaten liefert die europ\u00e4ische Raumfahrtagentur ESA t\u00e4glich in die Open Telekom Cloud.Dort stehen die Informationen des Erdbeobachtungsprogramms Copernicus seit Juni 2018 f\u00fcr jedermannkostenlos bereit. Die ersten Services sind ebenfalls bereits verf\u00fcgbar.\nArchitektur der Mundi Web Services: Die Satellitendaten werden direkt in der Open Telekom Cloud vorgehalten und verarbeitet.\nQuelle: Mundi Web Servicescus-Daten dann in Speicherbereiche mit anderen Leistungsklassen:Standard, Warm oder Cold. Auf Daten im Standard-OBS kann sehr oftam Tag zugegriffen werden. Speicherklasse Warm ist f\u00fcr monatliche undCold f\u00fcr einzelne Zugriffe im Jahr gedacht. Pro gespeichertem Gigabytefallen die Kosten f\u00fcr die Ressourcen anders aus, was eine \u00f6konomischeDatenhaltung erm\u00f6glicht. Auf diese Weise kann der Mundi Web Servicedie Daten kostenlos zur Verf\u00fcgung stellen. Wer Analyseservices und da-mit Rechenressourcen nutzt, bezahlt im Pay-per-use-Modell.\nMetadaten erleichtern Services\nEin Metadatenservice indiziert zudem alle Daten. So lassen sich sp\u00e4-ter die Bild- und Datenkacheln finden, die die Satelliten mit ihren Ka-meras und Sensoren aufnehmen. Die ESA liefert alle Daten mit Me-tainformationen an, zum Beispiel mit Angaben zum Satelliten selbst.So arbeiten die Erdbeobachter stets paarweise und sind \u2013 je nachAufgabe \u2013 in sechs Gruppen organisiert, den sogenannten Sentinel-Familien. Ob Ozeane, Atmosph\u00e4re oder Landmassen: Jedes Gespannim Orbit verf\u00fcgt \u00fcber bestimmte Sensoren \u2013 von Multispektralkame-ras \u00fcber Doppler-Radare bis hin zu Radiometern, um Oberfl\u00e4chentem-peraturen auf 0,3 \u00b0C genau zu bestimmen. Der Mundi Web Serviceerg\u00e4nzt die Metainformationen beispielsweise um Details zur Wolken-abdeckung. \nDar\u00fcber hinaus sollen k\u00fcnftig auch aggregierte Datenpakete bereit-\nstehen. Das k\u00f6nnen beispielsweise Bilder sein, die bereinigt von atmo-sph\u00e4rischen St\u00f6reffekten sind. Anwender k\u00f6nnen sich den Aufberei-tungsschritt dann sparen und die Aggregate direkt per API in eigeneApplikationen einbinden. Die Verarbeitung der Copernicus-Daten in derCloud macht in jedem Fall aufwendige Downloads hinf\u00e4llig. Statt um\u00dcbertragungskapazit\u00e4ten zu konkurrieren, konkurrieren die Anbieter mitihren Services selbst. Auf dem Mundi Marketplace soll eine Vielzahl anDiensten entstehen.\nAuch notwendige Tools, um gro\u00dfe Datenmengen analysieren und\nverarbeiten zu k\u00f6nnen, stehen in der Open Telekom Cloud als Soft-ware as a Service (SaaS) bereit: So nutzen Anbieter beim Mundi WebService beispielsweise MapReduce, um schnell gro\u00dfe Datenmengenparallel \u00fcber einen Hadoop-Cluster zu verarbeiten. Wer keine virtuel-len Maschinen auf Elastic-Cloud-Servern nutzen m\u00f6chte, nutzt Bare-Metal-Server. Auch Datenbanken sind als Platform as a Service ver-f\u00fcgbar.\nRessourcen f\u00fcr die Forschung\nDie EU-Kommission geht davon aus, dass Copernicus DIAS nicht nurden Blick der Menschheit auf den Planeten ver\u00e4ndern wird, sonderndass aus den Daten und ihren Anwendungen mehr als 48.000 neueJobs entstehen. Nach einer Transitions- und Testphase ist das Angebotin der Open Telekom Cloud im Juni 2018 an den Start gegangen. Der-artige Public-Cloud-L\u00f6sungen sind in Forschung und Wissenschaftzunehmend gefragt. Denn Institute und Universit\u00e4ten k\u00f6nnen denwachsenden Speicher- und Rechenbedarf nicht mehr mit internenRessourcen \u00f6konomisch decken. So ist beispielsweise unter der F\u00fch-rung des europ\u00e4ischen Kernforschungszentrums CERN bereits die For-schungs-Cloud Helix Nebula in Betrieb gegangen. \nNils Klute,\nFachredakteur f\u00fcr IT-Themen, K\u00f6ln\n21\nRechenzentren und Infrastruktur \u2161/2018Copernicus ist nicht nur \u201edas ehrgeizigste zivile Erdbeobach-tungsprogramm aller Zeiten\u201c (Europ\u00e4ische Union), sondern auchein milliardenschweres Innovationsprogramm: Stand 6. Juni 2018sieht der EU-Haushaltsvorschlag vor, 2021 \u2013 2027 insgesamt 16 Milliarden Euro in die Weltraumprogramme zu investieren.Davon sollen 9,7 Milliarden Euro auf die Satellitennavigationssys-teme Galileo und EGNOS entfallen, 5,8 Mil-liarden Euro auf Copernicus. Zugleichsollen die bestehenden Anstrengungen zueinem \u00fcbergreifenden neuen Weltraum-programm zusammengefasst werden.Hintergrund dieses Haushaltsvorschlagsist zum einen das empfindlicher gewor-dene europ\u00e4ische Sicherheitsbed\u00fcrfnis,das die \u201estrategische Unabh\u00e4ngigkeitEuropas im Hinblick auf kritische Infra-strukturen, Technologie, Sicherheit undVerteidigung\u201c als Priorit\u00e4t erkannt hat.Zum anderen f\u00fchrt die Union wirtschaft-liche Argumente ins Feld: \u201eMehr als 10 % des BIP der EU sind bereits vonweltraumgest\u00fctzten Diensten abh\u00e4ngig\u201c,sagt Kommissionsvizepr\u00e4sident Maro\u0161\u0160ef\u010dovi\u010d. Zu den konkreten Zielen geh\u00f6rt\ndaher auch die F\u00f6rderung von innovativen Start-ups aus der Welt-raumbranche, die im Rahmen des InvestEU-Programms leichterenZugang zu Risikokapital erhalten sollen. Insofern darf man er -warten, dass auch die DIAS-Dienste weiter ausgebaut werden, dieUnternehmen den Zugang zu den Copernicus-Daten m\u00f6glichsteinfach machen. Dass die Telekom hier bereits den Fu\u00df in der T\u00fcr hat, d\u00fcrfte f\u00fcrdas gr\u00f6\u00dfte TK-Unternehmen Europas aber auch mit Blick auf\nGalileo und EGNOS interessant sein.W\u00e4hrend Copernicus vor allem f\u00fcr Klima -daten wichtig ist, geht es bei der Satelliten-navigation um die n\u00e4chste technologischeZukunft: um Infrastrukturen f\u00fcr autonomeund vernetzte Fahrzeuge und um das Inter-net der Dinge. Und an diesem Ende schlie\u00dftsich f\u00fcr die Telekom der Kreis \u2013 denn genauauf diesen Feldern ist sie mit NarrowBand-IoT und vor allem dem Mobilfunkstandard5G bereits h\u00f6chst aktiv. Ebenso wichtig ist die Nachricht aber f\u00fcr Edge-Ausr\u00fcster und -L\u00f6sungsanbieter. Denn den immensenDatenverkehr solcher Mobilit\u00e4tsszenarienwerden zentrale RZ gar nicht stemmenk\u00f6nnen. Es zeichnet sich bereits ab, dassder L\u00f6wenanteil der Rechenleistung inmodularen, kompakten Kleinrechenzentrenim Feld stattfinden wird. Entsprechende\nMicro Datacenter gibt es bereits, unter anderem von Dell, HPEund Rittal. Auf der Cebit 2018 hat zuletzt Delta aus Taiwan seinmodulares Edge-Konzept pr\u00e4sentiert.                                     (red)\nEDGE UND IOT AM RANDE DES WELTRAUMS\nQuelle: Delta ElectronicsCOPERNICUS DIAS\nDelta hat ein komplettes Infrastruktur-Planungskonzept f\u00fcr Edge-Rechenzentren vorgelegt.Mit Gleichstromkomponenten im Rechenzentrum ergeben sich f\u00fcrUnternehmen neue Potenziale zur Kostenoptimierung. Grundlage\nhierf\u00fcr sind die bei den offenen Standards OCP (Open Compute Project)und Open19 verwendeten Technologien, die auf den Einsatz vonGleichstrom innerhalb von IT-Racks setzen. Damit gelingt der Aufbauvon sehr homogenen und skalierbaren Rechenzentren. Weitere Vorteilesind eine optimierte Energieversorgung \u00fcber nur noch ein oder zweizentrale Power Shelves mit n+1-Netzteilen pro Rack, das alle IT-Kom-ponenten im Serverschrank versorgt. Somit wird auch eine effizientereK\u00fchlung erreicht, da weniger Netzteile vorhanden sind. Gleichzeitigvereinfachen sich durch die hohe Standardisierung die Wartung unddas Ersatzteilmanagement.\nEnergieverteilung im Rack\nDie beiden Technologien OCP und Open19 verfolgen zwar die gleichenZiele, unterscheiden sich dennoch voneinander. Die Breite der Schr\u00e4nkeist mit 600 mm identisch, OCP erlaubt jedoch 21-Zoll-Einsch\u00fcbe mitH\u00f6heneinheiten von 48 mm, die damit etwas gr\u00f6\u00dfer als \u00fcblich aus-fallen. Bei Open19 k\u00f6nnen traditionelle 19-Zoll-Racks verwendet wer-den. Die Stromversorgung erfolgt bei beiden Systemen \u00fcber Gleich-strom: W\u00e4hrend es bei Open19 einen speziellen Kabelbaum auf derR\u00fcckseite gibt, wird ein OCP-Schrank komplett von vorne bedient. DieEnergieverteilung erfolgt hier an der R\u00fcckseite des Racks \u00fcber eine12-V- bzw. 48-V-Stromleiste mit einer automatischen Kontaktierung,sobald eine IT-Komponente eingeschoben wird. Das erlaubt bei demOCP-Konzept eine sehr schnelle Montage und einen raschen Aus-tausch einzelner Module. Allerdings: Durch die zentrale Stromleistel\u00e4sst sich der Stromverbrauch einzelner Komponenten nicht messenbzw. schalten, w\u00e4hrend dies bei dem Open19-Kabelbaum weiterhinm\u00f6glich ist.\nDes Weiteren sollten IT-Verantwortliche auch das Thema Redundanz\nbeachten: Bei traditionellen Anlagen werden Server mit einer A- undB-Stromversorgung f\u00fcr h\u00f6chste Ausfallsicherheit betrieben. Ist der IT-\n22\nRechenzentren und Infrastruktur \u2161/2018AC/DC\nEinmal umwandeln gen\u00fcgt\nDurch neue RZ-Designs wird Gleichstrom zu einer interessanten Alternative\nF\u00fcr IT-Verantwortliche sind die Energiekosten im Rechenzentrum ein ewiges \u00c4rgernis. Neue Impulse gebenInitiativen wie OCP und Open19, die eine zentrale Gleichstromversorgung aller IT-Komponenten innerhalb vonIT-Racks erm\u00f6glichen. Der Markt ist noch jung, aber es gibt bereits L\u00f6sungen.\nLange Zeit war es schlicht so: Google, Amazon und andere gro\u00dfeHyperscale-Rechenzentren lie\u00dfen sich ihre Hardware ma\u00dfschnei-dern. Aufgrund der schieren Gr\u00f6\u00dfe dieser Abnehmer war dasm\u00f6glich. Alle anderen mussten nehmen, was es gibt. Und oft genugstellte sich dabei heraus, dass Standard-Umsetzungen und Form-faktoren unterschiedlicher Hersteller nicht so reibungslos zusam-menpassen wie gew\u00fcnscht, dass sie nicht so flexibel sind und nichtso skalierbar. Mit diesem \u201eDistributed Vendor Lock-in\u201c wollten sichetliche Anwender nicht mehr zufriedengeben. So entstanden zuerstdas Open Compute Project (OPC), dann die Open19 Foundation.OPC wurde von Facebook angesto\u00dfen, wo man auf eigene Faustbegonnen hatte, mit eigenen Serverdesigns zu experimentieren;von Anfang an mit dabei sind au\u00dferdem Intel, Rackspace Hostingund Goldman Sachs, mittlerweile sind so gut wie alle wichtigenPlayer der Branche dabei: Cisco, Dell, Google, HP , IBM, Microsoft,Nvidia, Schneider Electric, VMware etc., ebenso die DeutscheTelekom, Rittal und Canonical. Ein Grund f\u00fcr die flotte Entwicklungder Open-Server-Hardware-Initiative ist, dass sie rasch harteErfolge vorweisen konnte: Die OCP-Datencenter von Facebookzeigten schon fr\u00fch eine erstaunliche Energieeffizienz und \u2013 dassorgte f\u00fcr noch mehr Aufmerksamkeit \u2013 eine niedrige TCO (TotalCost of Ownership). Auf der Webpr\u00e4senz des Projekts findet manim Bereich Marketplace mittlerweile eine breite Auswahl an L\u00f6sun-gen, die als \u201eOCP-Accepted\u201c oder \u201eOCP-Inspired\u201c ausgezeichnetsind. Der Unterschied liegt im Wesentlichen darin, ob das DesignOpen Source ist oder nicht: Bei OCP Accepted sind die Informatio-nen frei verf\u00fcgbar, bei OCP-Inspired ist das nicht notwendig derFall \u2013 dieses Privileg genie\u00dfen Gold-, Silver- oder Platinum-Mitglie-der. Beide Labels signalisieren aber, dass die L\u00f6sungen voll undganz den OCP-Spezifikationen gerecht werden.Das Ausgangsproblem hat sich f\u00fcr die meisten RZ-Betreiberdadurch allerdings nicht gel\u00f6st. Es hat sich vielmehr innerhalb derOCP noch einmal repliziert, auch dort schieden sich die Geister inHyperscale- und HPC-Kunden einerseits, in \u201enormale\u201c RZ-Anwen-der andererseits. Die praktische Konsequenz war die Gr\u00fcndung derOpen19 Foundation, die 2016/2017 startete. Treibende Kraft warhier LinkedIn, mit Unterst\u00fctzung von Flex, GE Digital, HP und VaporIO. Die Zahl 19 im Namen verweist darauf, dass sich diese Gruppeauf kosteneffiziente und unkomplizierte Hardware-Bereitstellung in19-Zoll-Racks nach EIA-Standard ausgerichtet hat. Bestechend ist,dass diese L\u00f6sung mit deutlich weniger Komponentendublettenauskommt (Kabel, PDUs, Stecker etc.), indem sie den Schrankinhaltin drei Abteilungen sortiert: Brick Cage, Power Shelf und NetworkSwitch. Die Ausrichtung von Open19 ist insofern deutlich n\u00e4her amBedarf von kleinen und mittleren Rechenzentren als die mituntersehr spezifisch eingestellte Strategie des Open Compute Projects.Und: Das Open19-Konzept ist ausdr\u00fccklich f\u00fcr Edge-Installationenentwickelt \u2013 bei den RZ-K\u00e4sten am Netzwerkrand n\u00e4mlich k\u00f6nnteeine flotte, einfache Standard bereitstellung zum entscheidendenKriterium werden.                                                                       (red) \nOPEN COMPUTE PROJECT UND OPEN19 FOUNDATIONSchrank nur mit einer zentralen Stromschiene versehen,  muss die Re-\ndundanz an anderer Stelle erfolgen \u2013 so kann man beispielsweise dieGleichrichter \u00fcber zwei getrennte Stromnetze versorgen.\nDie Stromversorgung wird bei beiden Varianten \u00fcber optional im\nSchrank integrierte Gleichstrom-USV-Systeme abgesichert.  Hier sollten\ndie Betreiber die Brandlast pr\u00fcfen,  da diese \u00fcber die Fl\u00e4che des Rechen-\nzentrums hinweg steigt.  Ob sich eine zentrale USV oder ein im Schrank\nintegriertes System besser eignet,  ergibt sich aus Faktoren wie zum\nBeispiel der ben\u00f6tigten Ausfallsicherheit,  der geplanten Nutzung oder\nder Qualit\u00e4t des Stromnetzes.  Je nach Gegebenheit vor Ort kann  \nes auch sinnvoll sein,  ein Gleichstrombackbone im Rechenzentrum  \nzu installieren,  anstatt jedes Rack noch mit Wechselstrom zu  \nversorgen.  Hier sollte der h\u00f6here Aufwand f\u00fcr ein DC-Backbone mit  \nzu erwartenden Effizienzgewinnen durch weniger Wandlungsverlusteverrechnet werden.\nWann lohnt sich Gleichstrom?\nAllgemeing\u00fcltige Berechnungsgrundlagen,  ab wann sich Gleichstrom\nwirklich rechnet,  kann heute kein Anbieter seri\u00f6s vorlegen.  Vielmehr\nsind individuelle Betrachtungen unter Ber\u00fccksichtigung von Parame-tern wie der geplanten Nutzung,  dem Standort oder der Energiekosten\nnotwendig.  Der Effizienzgewinn,  der sich bei Gleichstrom durch weni-\nger Spannungswandler ergibt,  liegt erfahrungsgem\u00e4\u00df im Schnitt bei\nrund 5 % des Gesamtstroms.  Diese Gr\u00f6\u00dfenordnung ist deutlich zu  \ngering,  um damit ein neues Infrastrukturprojekt zu rechtfertigen.  Daher\nsollten weitere Aspekte in die Berechnung einflie\u00dfen,  etwa eine Opti-\nmierung der K\u00fchlsysteme \u2013 und sp\u00e4testens an diesem Punkt wird eineindividuelle Analyse notwendig.  Wirtschaftlich rentabel wird ein Gleich-\nstromprojekt also insbesondere dann,  wenn eine durchg\u00e4ngige  \nDC-Architektur im Rechenzentrum  aufgebaut  wird,  bei der auch  die\nK\u00fchlsysteme einbezogen werden.\nHierzu ein Beispiel f\u00fcr eine effiziente OCP-Anlage:  Diese sollte mit\neiner Warmgangschottung betrieben werden,  bei der es voneinander\ngetrennte Zonen f\u00fcr kalte und warme Luft gibt \u2013 ein Standardverfah-ren in vielen Rechenzentren.  Zus\u00e4tzlich gibt es OCP-Racks mit opti-\nmierter Thermodynamik im IT-Schrank,  sodass eine gleichm\u00e4\u00dfige  \nVerteilung der von au\u00dfen zugef\u00fchrten Kaltluft erfolgt,  wodurch die  \nEffizienz der K\u00fchlsysteme steigt.  Dar\u00fcber hinaus erlaubt die Spezifi-kation der OCP-Hardware eine h\u00f6here Eingangstemperatur der K\u00fchl-luft von bis zu 30 \u00b0C.  Die verbesserte Energiebilanz ergibt sich somit\naus der Kombination der thermischen,  elektrischen und mechanischen\nOptimierung.\nOCP und Open19 im Rennen\nPrinzipiell zeigt sich,  dass Gleichstromracks insbesondere bei sehr  \nhomogenen und gro\u00dfen Installationen verwendet werden,  wie sie bei\nHyperscale-Cloud-Providern vorkommen.  Hier greifen die Skaleneffekte\nrund um den operativen Betrieb und bei den Energiekosten.  Auch f\u00fcr\nTelekommunikationsanbieter ist diese Architektur sinnvoll,  da die bei\nGleichstrom genutzten 48 V im Rack bereits bei vielen TK-Systemenverwendet werden.\nBeide Standards befinden sich technologisch auf einem ausgereiften\nLevel,  der die produktive Nutzung erlaubt.  Dennoch arbeiten Hersteller\nauch weiterhin gemeinsam mit Kunden an der kontinuierlichen  \nWeiterentwicklung ihrer L\u00f6sungen,  sodass immer wieder neue Pro-\ndukte am Markt erscheinen.  CIOs sollten daher den Markt beobachten\nund sich regelm\u00e4\u00dfig \u00fcber Neuerungen informieren.  Ob sich nur ein\nStandard durchsetzt oder ob sich sogar beide am Markt etablieren,wird letztlich auch von den Herstellern abh\u00e4ngen.  Mittlerweile enga-\ngiert sich eine Reihe von Anbietern bei der Entwicklung beider Stan-dards und bietet bereits entsprechende IT-Racks an.  Je mehr L\u00f6-\nsungsanbieter bei Gleichstrom an einem Strang ziehen,  desto\ng\u00fcnstiger werden die Komponenten,  wodurch die Wirtschaftlichkeit\neines DC-Datacenters weiter steigt.\nBernd Hanstein,\nHauptabteilungsleiter Produktmanagement IT,  Rittal\n23\n Rechenzentren und Infrastruktur \u2161/2018AC/DC\nMit dem Open19-Rack bietet Rittal eine Gleichstroml\u00f6sung auf derg\u00e4ngigen 19-Zoll-Rackbasis.  Die Anschl\u00fcsse werden nicht auf eine\nzentrale Stromschiene an der R\u00fcckseite des Schrankes adaptiert,sondern \u00fcber einen speziellen Kabelbaum auf der R\u00fcckseite mit denPower Shelves verbunden.\nQuelle:  Rittal\nDie OCP-Racks mit 12 V DC und 48 V DC sind energieeffizientdurch Gleichstrom,  standardisiert f\u00fcr k\u00fcrzere Time to Market und\nskalierbar f\u00fcr flexiblere Anpassungen.\nQuelle:  RittalDie Bedeutung der Datacenter hat sich \u00fcber die Jahre stark ver\u00e4n-dert: Immer mehr Daten werden direkt im Rechenzentrum verar-\nbeitet und neuartige Systemarchitekturen gewinnen an Relevanz, etwadie sogenannte Spine-Leaf-Architektur, die Prozessoren und Daten-banken untereinander vernetzt. Gleichzeitig entstehen mehr und mehrlokale Rechenzentren, die regionale Daten verarbeiten, beispielsweisef\u00fcr die Echtzeitverkehrsleittechnik. Die Vermittlungsstationen der Netz-betreiber n\u00e4hern sich zunehmend an die Architektur der Rechenzentrenan. Auch dort steigt die Menge der Verbindungen innerhalb einer Sta-tion deutlich. Und auch dort dominieren 100-Gigabit-Verbindungen. \n100-Gigabit-Ethernet-\u00dcbertragung \nIm Gegensatz zum Weitverkehr, wo \u00dcbertragungssignale auf einer Wel-lenl\u00e4nge und mit h\u00f6herstufigen Modulationsverfahren kodiert und dannvia DWDM (Dense Wavelength Division Multiplexing) \u00fcbertragen wer-den, m\u00fcssen in Rechenzentren und Vermittlungsstationen lediglich kurzeVerbindungen von oft nicht einmal 100 m \u00fcberbr\u00fcckt werden. Dazuwerden optische Schnittstellen f\u00fcr 40/100-Gigabit-Ethernet genutzt,die in der IEEE802.3ba definiert sind. \nIn der Regel \u00fcbertragen Transceiver das 100GbE-Signal parallel auf\nvier Wellenl\u00e4ngen mit jeweils 25 GBit/s. Um die \u00dcbertragung auch in be-stehende Systeme zu integrieren, bedienen sie unterschiedliche Reich-weiten und Wellenl\u00e4ngen. Bei der Standardschnittstelle 100GBASE-SR4wird momentan beispielsweise der Formfaktor QSFP28 verwendet. F\u00fcr die Entwicklung neuer Transceiver spielen vor allem zwei Fak-\ntoren eine wichtige Rolle: Preis und Packungsdichte. Es ist daher nichterstaunlich, dass Integration und Einsatz von Multimode-Fasern in Rechenzentren und Vermittlungsstationen immer weiter zunehmen. Als\u00dcbertragungsstandard hat sich 100GBASE-SR4 etabliert, der vier Multi -mode-Fasern pro Richtung umfasst und bei OM4-Fasern Reichweitenvon bis zu 125 m abdeckt. Das ist f\u00fcr die meisten F\u00e4lle ausreichend.F\u00fcr l\u00e4ngere Verbindungen, beispielsweise im Campus-Bereich, istSinglemode immer noch die erste Wahl. Hier bietet sich der PSM4-Standard an, der auf vier parallel gef\u00fchrte Fasern je Richtung setzt. Inbeiden F\u00e4llen werden MTP/MPO-Stecker genutzt, um den Umgang mitder Technik zu vereinfachen. Bei 100-Gigabit-Ethernet werden dabeivon zw\u00f6lf Fasern nur die Fasern 1 bis 4 und 9 bis 12 genutzt. SollenVerbindungen von 1/10 GBit/s geb\u00fcndelt werden, k\u00f6nnen insgesamtsechs Duplex-Verbindungen mit einem MTP/MPO-Stecker gestecktwerden.\nAnschl\u00fcsse mit MTP/MPO\nDer MPO-Stecker zeichnet sich durch jeweils zwei F\u00fchrungsstifte aus,welche die notwendige mechanische Stabilit\u00e4t liefern, um optischeVerbindungen f\u00fcr alle zw\u00f6lf Fasern herzustellen. Es gibt dabei sowohlStecker mit Pin (male) sowie ohne Pin (female). Bei der Verkabelungist somit darauf zu achten, die jeweils richtigen Kabel einzusetzen.Denn wenn gleiche Gender aufeinander gesteckt werden, kommt keineoptische Verbindung zustande. \nAktive Systemelemente sowie die Trunk-Verkabelung zwischen den\nGestellen verf\u00fcgen \u00fcblicherweise \u00fcber MTP/MPO-Stecker mit Pin. Ent-sprechend sollten hier Patchkabel eingesetzt werden, die keine Pinsan den Enden haben. Sollen zwei Transceiver verbunden werden, wer-den Patchkabel mit gekreuzter Polarit\u00e4t ben\u00f6tigt. Diese werden jeweilsan einer Seite eingesetzt. \n100GBASE-SR4-Transceiver (IEEE 802.3ba) ben\u00f6tigen zur richtigen\nVerbindung ein Verbindungskabel mit gekreuzter Polarit\u00e4t vom Typ B.Das Trunkkabel entspricht \u00fcblicherweise Typ A. F\u00fcr die Parallel\u00fcber-tragung von 1/10-Gigabit-Ethernet ist ein Patchkabel mit der paarwei-sen Vertauschung vom Typ C notwendig. Zus\u00e4tzlich verf\u00fcgen die Kupp-lungen f\u00fcr MPO-Stecker \u00fcber eine F\u00fchrungsnut (Key up und Keydown). Diese verhindert die Aufhebung der Polarit\u00e4t durch das Drehendes symmetrischen MTP/MPO-Steckers. \nDie Messungen an derartigen Kabeln werden durch die mechani-\nsche Kodierung und Genderisierung beeinflusst. \u00dcblicherweise wird\n24\nRechenzentren und Infrastruktur \u2161/2018100GBE \nZw\u00f6lf Fasern im D\u00e4mpfungstest\nMehrfaserstrecken mit MTP/MPO-Steckern erfordern hochpr\u00e4zise Messverfahren \n100-Gigabit-Ethernet ist heute die Standard\u00fcbertragungsrate in Rechenzentren und Telekommunikationsnetzen.Solche LWL-Kabel mit ausreichender Genauigkeit und replizierbar zu messen, ist keineswegs trivial. Die normativen Anforderungen an zukunftsf\u00e4hige Glasfaserverbindungen sind zuletzt deutlich gestiegen. \nD\u00e4mpfungsmessplatz von VIAVI f\u00fcr Mehrfaserstecker mitMTP/MPO\nQuelle: VIAVInach der Installation die Einf\u00fcged\u00e4mpfung ermittelt. Bereits bei der Re-ferenzierung der Messger\u00e4te ist zu beachten, welche Stecker die Kabelhaben. Aktive Elemente wie Transceiver werden \u00fcblicherweise mit Pinausgestattet. Bei der Gestell-zu-Gestell-Verbindung (Trunkkabel) gibtes unterschiedliche Empfehlungen bez\u00fcglich der Genderisierung. \nDie Referenzmessung zur Ermittlung der Einf\u00fcged\u00e4mpfung wird\ndurch die Art der MPO-Stecker beeinflusst. Die im Weitverkehr \u00fcblicheReferenzmethode mit zwei Messkabeln (Test Reference Cord/TRC)kann nicht durchgef\u00fchrt werden, wenn das zu messende Kabel an bei-den Enden \u00fcber gleiche Stecker verf\u00fcgt. \nDie Referenzmethode mit drei Patchkabeln bietet den Vorteil, dass\nauch Messobjekte mit unterschiedlichen Steckern gepr\u00fcft werden k\u00f6nnen, wobei das mittlere Referenzkabel gleiche Stecker wie das zumessende Kabel haben muss. Allerdings bleiben im Messergebnis dieD\u00e4mpfungswerte der Steckverbinder unber\u00fccksichtigt. Je nach Refe-renzmethode beinhaltet das Messergebnis die D\u00e4mpfungswerte derSteckverbinder oder eben nicht. \nTier-1-Messungen nach ISO/IEC \nDie Ermittlung der Einf\u00fcged\u00e4mpfung eines Kabels entspricht denMessmethoden f\u00fcr Duplex-LWL-Kabel mit seinen unterschiedlichenStandardisierungen: ANSI/TIA-526-14-C-2015 beim Multimode-Kabelund ANSI/TIA-526-7-A beim Singlemode-Kabel bzw. nach den euro-p\u00e4ischen Normen IEC 61280-4-1 (Multimode) und IEC 61280-4-2(Singlemode). Dort sind die maximalen D\u00e4mpfungswerte f\u00fcr Splei\u00dfeund Stecker festgelegt. Aus der Referenzmethode errechnet sich zusammen mit der Faserd\u00e4mpfung von 3,5 dB/km bei einer Wellen-l\u00e4nge von 850 nm bzw. von 1,5 dB/km bei 1300 nm und der Anzahlder Steckverbinder die maximale D\u00e4mpfung eines Verbindungskabels.Die Differenz vom Messwert zum maximalen D\u00e4mpfungswert ist dieReserve. Zur Einbeziehung der Faserd\u00e4mpfung muss die Kabell\u00e4ngeermittelt werden. Die L\u00e4ngenmessung erfolgt \u00fcblicherweise via OTDR(Optical Time-Domain-Reflectometry). Andernfalls muss die L\u00e4ngeaufwendig mit einem Pulslaufzeitverfahren am Tier-1-Messplatz er-mittelt werden. Gem\u00e4\u00df der Standardisierung kann die Referenzierungmit einem, zwei oder drei Referenzkabeln durchgef\u00fchrt werden. F\u00fcrdiese sind jeweils bessere optische Parameter (Reference Grade) ge-fordert. Fallweise werden die Stecker dabei nicht, teilweise oder kom-plett in das Ergebnis einbezogen.Moderne D\u00e4mpfungsmesspl\u00e4tze lassen sich f\u00fcr MPO-12-Kabel nut-\nzen. F\u00fcr 40/100-Gigabit-Ethernet sind je vier Fasern erforderlich, Faser1 bis 4 f\u00fcr die Senderichtung, Faser 9 bis 12 f\u00fcr die Gegenrichtung.Die ungenutzten Fasern m\u00fcssen in diesem Fall aber nicht unbedingtgemessen werden. \nTier-2-Messung bei MTP/MPO-Mehrfaserkabeln \nBei Abnahmemessungen der strukturierten Verkabelung nach TIA undIEC ist die OTDR-Messung (Tier 2) nicht verbindlich vorgeschrieben.Werden AOC (Active Optical Cable) genutzt, kann bei kurzen Kabeln in-nerhalb eines Gestells darauf verzichtet werden. Bei l\u00e4ngeren Verbin-\n25\n Rechenzentren und Infrastruktur \u2161/2018100GBE \nPolarit\u00e4t von Mehrfaserkabeln mit MTP/MPO-Stecker\nQuelle: VIAVI\nDie erste Tabelle zeigt die Maximalwerte bez\u00fcglich \nder Kabel- und Steckerd\u00e4mpfung f\u00fcr OM3 und OM4-\nFasern. Die zweite Tabelle listet die \u00fcblichen\nSteckerd\u00e4mpfungen f\u00fcr Standard- und\nReferenzstecker auf. Die maximale Einf\u00fcged\u00e4mpfung\nvon 1,5 dB bei der OM4-Faser f\u00fcr ein 150 m langes\nKabel zeigt auch, dass der Standard-MPO-Stecker\nhier nicht eingesetzt werden kann. Die maximale\nSteckerd\u00e4mpfung l\u00e4ge in Summe bei 1,7 dB. Gefragt\nist hier ein Stecker mit niedriger Maximald\u00e4mpfung\nund deutlich geringerer D\u00e4mpfung. Die niedrigen\nmaximalen D\u00e4mpfungswerte machen den direkten\nEinfluss sauberer Stecker auf Verbindungsqualit\u00e4t\nund -funktionalit\u00e4t deutlich. Netzbetreiber sollten\ndaher immer mit geeigneten Pr\u00fcfungen und\nVideomikroskopen auf die Sauberkeit der\nSteckerstirnfl\u00e4chen achten. Wichtig ist hier der\nStandard IEC 61300-3-35 mit seinen Kriterien zur\nBeurteilung der Steckerstirnfl\u00e4chen.REICHWEITEN UND MAXIMALE D\u00c4MPFUNGSWERTEVON OM3- UND OM4-FASERN \nEINF\u00dcGED\u00c4MPFUNGSWERTE BEI MPO-STECKERN (US-CONEC) Faser Reichweite\n(m)Max. Einf\u00fcged\u00e4mpfung\n(dB)Max. D\u00e4mpfungsbudget f\u00fcr \nSteckverbindungen (dB)\nOM3 100 1,9 1,5\nOM4 150 1,5 1\nStandard Elite\nFaserklasse Typ. (dB) Max. (dB) Typ. (dB) Max. (dB)\nMultimode 0,2 0,6 0,1 0,35\nSingle Mode 0,25 0,75 0,1 0,35dungen zwischen Gestellreihen oder in Vermittlungsstationen ist dieMessung allerdings sinnvoll. Messtechnisch gesehen sind die Verbin-dungen bez\u00fcglich Dynamik und Reichweite keine allzu gro\u00dfe Heraus-forderung f\u00fcr ein OTDR. Da 100GBASE-PSM4 allerdings eine maximaleReichweite von 500 m hat, sollte das eingesetzte OTDR eine hohe Auf-l\u00f6sung und sehr kurze Totzonen aufweisen. Nur so lassen sich nah bei-einanderliegende Ereignisse separat darstellen. Da die Vermessung allerFasern eines MTP/MPO-Kabels mit einem Breakout-Kabel zeitaufwendigund fehleranf\u00e4llig ist, empfiehlt sich der Einsatz optischer Schalter, die\u00fcber die Messroutine des OTDR gleichgesteuert werden. \nModerne Mehrfaserstecker verf\u00fcgen \u00fcber so minimale D\u00e4mpfungs-\nwerte, dass sie f\u00fcr alle Fasern eines Mehrfasersteckers die gleichenWerte wie Einzelfaserstecker garantieren. Besonders geeignet f\u00fcr40/100GbE-Systeme ist der MPO12-Stecker, mit dem sich besondershohe Packungsdichten an den Patchfeldern im Rechenzentrum erzielenlassen. Dies ist vor allem im Hinblick auf das kommende 400-Gigabit-Ethernet von Bedeutung. F\u00fcr die n\u00e4chste Generation mit 400GbE wer-den bereits acht Fasern in beiden Richtungen ben\u00f6tigt. Der MPO16-Stecker wurde bereits daf\u00fcr definiert. \nUm eine reibungslose Daten\u00fcbertragung sicherzustellen, ist auf die\nReinigung und Sauberkeit von Mehrfasersteckern besonders zu achten.Die Reinigung mit herk\u00f6mmlichen Reinigungsb\u00e4ndern ist dabeischwierig. Die MTP/MPO-Konstruktion sieht Faser\u00fcberst\u00e4nde vor, wasdie Ablagerung von Staub beg\u00fcnstigt. Zudem hat die Polymer-Ferruleelektrostatische Eigenschaften, die Staub anziehen.\nPeter Winterling, \nSenior Solution Specialist Fiber Optic, \nVIAVI Solutions Deutschland GmbH\n26\nRechenzentren und Infrastruktur \u2161/2018100GBE \nResultate am D\u00e4mpfungsmessplatz: Die linke Grafik zeigt, dass D\u00e4mpfung und Reserve bei 850 nm am geringsten sind (1,35 dB bzw.0,45 dB). Die L\u00e4nge des Kabels (Typ B) ist zusammen mit der Polarit\u00e4t dargestellt. Gleichzeitig werden die Polarit\u00e4t des Kabels grafischund die der Einzelergebnisse tabellarisch gezeigt. Der simulierte Fehler in den Fasern 4 bis 9 zeigt die Darstellung im Fehlerfall. In dieserMesskonfiguration wurden die vier mittleren Fasern der Verbindung einer 40GBASE-SR4 gemessen. In die Gesamtbewertung wurden sieaber nicht einbezogen (gelbe Markierung). Messpl\u00e4tze f\u00fcr Multimode-MPO-Fasern m\u00fcssen zudem die Konditionen f\u00fcr Encircled Fluxnach IEC 61280-1-4 erf\u00fcllen. \nQuelle: VIAVI \nImpressum Themenbeilage Rechenzentren und Infrastruktur\nRedaktion just 4 business GmbH\nTelefon: 08061 34811100, Fax: 08061 34811109, \nE-Mail: tj@just4business.de\nVerantwortliche Redakteure:Thomas Jannot (v. i. S. d. P.), Ralph Novak, Florian Eichberger (red, Lektorat)Autoren dieser Ausgabe:Markus Grau, Bernd Hanstein, Nils Klute, Axel Oppermann, Doris Piepenbrink, ArianeR\u00fcdiger, Roberto Sammler, Dale Vecchio, Peter Winterling, Dr. Jens ZeyerDTP-Produktion: Lisa Hemmerling, Matthias Timm, Hinstorff Media, RostockKorrektorat:Ricardo Ulbricht, Hinstorff Media, RostockTitelbild: Fotolia, \u00a9 zentiliaVerlag\nHeise Medien GmbH & Co. KG, Postfach 61 04 07, 30604 Hannover; Karl-Wiechert-Allee 10, 30625 Hannover; Telefon: 0511 5352-0, Telefax: 0511 5352-129Gesch\u00e4ftsf\u00fchrer: Ansgar Heise, Dr. Alfons Schr\u00e4derMitglieder der Gesch\u00e4ftsleitung: Beate Gerold, J\u00f6rg M\u00fchleVerlagsleiter: Dr. Alfons Schr\u00e4derAnzeigenleitung (verantwortlich f\u00fcr den Anzeigenteil): Michael Hanke (-167), E-Mail: michael.hanke@heise.de, www.heise.de/mediadaten/ixLeiter Vetrieb und Marketing: Andr\u00e9 LuxDruck: Dierichs Druck + Media GmbH & Co. KG, Frankfurter Stra\u00dfe 168, 34121 KasselEine Haftung f\u00fcr die Richtigkeit der  Ver\u00f6ffentlich ungen kann trotz sorgf\u00e4ltiger Pr\u00fcfungdurch die Redaktion vom Herausgeber nicht \u00fcbernommen werden. Kein Teil dieserPublikation darf ohne ausdr\u00fcckliche schriftliche Genehmigung des Verlages verbreitetwerden; das schlie\u00dft ausdr\u00fccklich auch die Ver\u00f6ffentlichung auf Websites ein.Printed in Germany\u00a9 Copyright by Heise Medien GmbH & Co. KG\nDie Inserenten\nAT+C                         www.atc-systeme.de                          S. 7\nB1 Systems                www.b1-systems.de                           S. 27\nbytec                          www.bytec.de                                     S. 28DC                              www.datacenter-group                       S. 5\nFNT                            www.fnt.de                                         S. 2\nRittal                          www.rittal.de                                      S. 14, 15\nDie hier abgedruckten Seitenzahlen sind nicht verbindlich. Redaktionelle Gr\u00fcnde k\u00f6nnen \u00c4nderungen erforderlich machen.", "language": "PDF", "image": "PDF", "pagetype": "PDF", "links": "PDF"}