{"title": "PDF", "author": "PDF", "url": "https://www.ethikrat.org/fileadmin/Publikationen/Stellungnahmen/deutsch/stellungnahme-mensch-und-maschine.pdf", "hostname": "PDF", "description": "PDF", "sitename": "PDF", "date": "PDF", "id": "PDF", "license": "PDF", "body": "PDF", "comments": "PDF", "commentsbody": "PDF", "raw_text": "PDF", "text": "Deutscher Ethikrat\nMensch und Maschine \u2013 \nHerausforderungen durch \nK\u00fcnstliche Intelligenz\nSTELLUNGNAHME\nDeutscher Ethikrat\nMensch und Maschine \u2013 \nHerausforderungen durch \nK\u00fcnstliche Intelligenz\nSTELLUNGNAHME\n20. M\u00e4rz 2023Herausgegeben vom Deutschen Ethikrat\nJ\u00e4gerstra\u00dfe 22/23 \u00b7 D-10117 Berlin\nTelefon: +49/30/20370-242 \u00b7 Telefax: +49/30/20370-252\nE-Mail: kontakt@ethikrat.org\nwww.ethikrat.org\n\u00a9 2023 Deutscher Ethikrat, Berlin\nAlle Rechte vorbehalten.\nEine Abdruckgenehmigung wird auf Anfrage gern erteilt.\nLayout: Torsten Kulick\nTitelillustration: pinkeyes/Shutterstock.com5DANKSAGUNG\nAn dieser Stellungnahme haben zahlreiche Personen unter -\nst\u00fctzend mitgewirkt:\nUlrike von Luxburg, Matthias Bethge, Tanja Schultz und \nStefan Remy boten zum Projektbeginn bei einer \u00f6ffentlichen \nAnh\u00f6rung am 25. Februar 2021 wertvolle Orientierung zu den \naktuellen und absehbaren Entwicklungen im Bereich K\u00fcnst-\nlicher Intelligenz. Inge Molenaar und Ute Schmid erg\u00e4nzten \ndies im Rahmen einer weiteren, nicht \u00f6ffentlichen Anh\u00f6rung \nsowie mit schriftlicher Expertise zum Einsatz von KI in der \nSchule und Matthias May gew\u00e4hrte hilfreiche Einblicke in die \nAnwendung algorithmischer Systeme in der medizinischen \nDiagnostik.\nWolfgang Schulz, Indra Spiecker genannt D\u00f6hmann und \nnoch einmal Ute Schmid brachten ihren Sachverstand zu ju-\nristischen und informatikspezifischen Passagen der Stellung-\nnahme ein. Carl Friedrich Gethmann begleitete die Arbeit der \nStellungnahme auch nach dem Ende seiner Amtszeit im Deut-\nschen Ethikrat im Februar 2021 als nunmehr externes Mitglied \nder Arbeitsgruppe \u201eMensch und Maschine\u201c und auch Andreas \nKruse wirkte bis zu seinem Ausscheiden aus dem Ethikrat im \nM\u00e4rz 2022 an der Stellungnahme mit.\nDer Deutsche Ethikrat dankt allen Mitwirkenden sehr \nherzlich f\u00fcr ihre Unterst\u00fctzung!7INHALTSVERZEICHNIS\nZUSAMMENFASSUNG  ...........................................................................................  11\n1\t EINLEITUNG \t ...................................................................................................  78\nTEIL I: TECHNISCHE UND PHILOSOPHISCHE \nGRUNDLEGUNGEN\n2\t ZENTRALE \tENTWICKLUNGEN \tUND\tTECHNISCHE \t\nGRUNDLAGEN \tK\u00dcNSTLICHER \tINTELLIGENZ \t ................  86\n2.1\t Historischer\tKontext\t  ................................................................................  86\n2.2\t KI\tim\t21.\tJahrhundert:\tBig\tData,\tAlgorithmen\tund\t\nsoziotechnische\t\u00d6kosysteme\t  ...........................................................  92\n2.2.1\t Digitale\tDurchdringung\tder\tmenschlichen\tLebenswelt\t  ........................  92\n2.2.2\t Daten\tund\tdigitale\tInfrastrukturen\t  ...............................................................  94\n2.2.3\t Algorithmen\tund\tDatenverarbeitung\t  ...........................................................  97\n2.2.4\t Einsatzbereiche\talgorithmischer\tSysteme\tund\u00a0KI\t  ....................................  105\n2.2.5\t Ethische\tLeitlinien\tund\tregulativer\tRahmen\tf\u00fcr\talgorithmische\t\nSysteme\tund\tKI\t  ......................................................................................................  108\n3\t ZENTRALE \tBEGRIFFE \tUND\tPHILOSOPHISCHE \t\nGRUNDLAGEN \t .............................................................................................  116\n3.1\t K\u00fcnstliche\tIntelligenz:\tbegriffliche\tAnalyse\t  .........................  116\n3.2\t Intelligenz\tund\tVernunft\t  .......................................................................  123\n3.2.1\t Intelligenz\t  ................................................................................................................  123\n3.2.2\t Vernunft\t  ...................................................................................................................  129\n3.3\t Handlung\tund\tVerantwortung\t  .........................................................  135\n3.3.1\t Handlung\t  .................................................................................................................  135\n3.3.2\t Verantwortung\t  ......................................................................................................  140\n3.4\t Anthropologische\tAspekte\tdes\tMensch-Maschine-\nVerh\u00e4ltnisses\t  ...................................................................................................  145\n3.4.1\t Philosophische\tGrundbestimmung\tdes\tMenschseins\t  ...........................  145\n3.4.2\t Der\tMensch\tals\tMaschine\t\u2013\tdie\tMaschine\tals\tMensch?\t  .......................  149\n3.4.3\t Verleiblichte\tVernunft\t  ........................................................................................  156\n3.5\t Fazit\t  .........................................................................................................................  161\n4\t MENSCH-TECHNIK-RELATIONEN \t .............................................  164\n4.1\t Einleitung\t  ...........................................................................................................  164\n4.2\t Technikdeterminismus\tversus\tSozialkonstruktivismus  .. 16584.3\t Mehrstufige\tMensch-Technik-Wechselwirkungen\t  ..........  170\n4.4\t Erweiterung\tund\tVerminderung\tmenschlicher\t\nAutonomie\tund\tAutorschaft\t  ..............................................................  177\n4.5\t Fazit\t  .........................................................................................................................  183\nTEIL II: AUSGEW\u00c4HLTE ANWENDUNGEN UND \nSEKTORSPEZIFISCHE EMPFEHLUNGEN\n5\t MEDIZIN \t ............................................................................................................  190\n5.1\t Einleitung\t  ...........................................................................................................  190\n5.2\t Einsatz\tvon\tKI-Systemen\tin\tder\tMedizin\t  .................................  192\n5.2.1\t Entwicklung\tvon\tKI-Systemen\t  .........................................................................  192\n5.2.2\t KI\tin\tder\tmedizinischen\tForschung\t  ...............................................................  196\n5.2.3\t KI\tin\tder\tmedizinischen\tVersorgung\t  .............................................................  199\n5.3\t Fazit\tund\tEmpfehlungen\t  .......................................................................  215\n6\t BILDUNG \t ...........................................................................................................  219\n6.1\t Einleitung\t  ...........................................................................................................  219\n6.2\t Zum\tBildungsbegriff\t  .................................................................................  221\n6.3\t Einsatzm\u00f6glichkeiten\tdatenbasierter,\tKI-gest\u00fctzter\t\nLehr-\tund\tLernsysteme\t  ...........................................................................  225\n6.4\t Mensch-Maschine-Relationen\tin\tder\tschulischen\t\nBildung:\tErweitern,\tVermindern,\tErsetzen\t  .............................  228\n6.5\t Grunds\u00e4tzliche\tDiskussion:\tKI\tim\tschulischen\t\nBildungsprozess\t  ............................................................................................  239\n6.6\t Fazit\tund\tEmpfehlungen\t  .......................................................................  244\n7\t \u00d6FFENTLICHE \tKOMMUNIKATION \tUND\t\nMEINUNGSBILDUNG \t ............................................................................  251\n7.1\t Einleitung\t  ...........................................................................................................  251\n7.2\t Das\tInternet\tals\tsoziotechnisches\tSystem:\t\nFunktionsweise\tsozialer\tMedien\t  ....................................................  252\n7.2.1\t Neue\tsoziotechnische\tInfrastrukturen\t  ........................................................  252\n7.2.2\t Informationsauswahl\tund\tKuratierung\t  ........................................................  254\n7.2.3\t Moderation\tvon\tInhalten\t  ..................................................................................  258\n7.2.4\t Auswirkungen\tauf\tdie\tErweiterung\tund\tVerminderung\t\nmenschlicher\tHandlungsf\u00e4higkeiten\t  ............................................................  262\n7.3\t Informationsqualit\u00e4t\t  ................................................................................  264\n7.3.1\t Falschnachrichten\tund\tVerschw\u00f6rungstheorien\t  ......................................  266\n7.3.2\t Filterblasen\tund\tEchokammern\t  ......................................................................  26897.3.3\t Moralische\tund\temotionale\tAufladung\t  .......................................................  270\n7.3.4\t Relevanz\tder\tbeobachteten\tEffekte\t  ...............................................................  272\n7.4\t Diskursqualit\u00e4t\t  ..............................................................................................  273\n7.4.1\t Politische\tPolarisierung\t  .....................................................................................  275\n7.4.2\t Politische\tWerbung\tund\tManipulation\t  ........................................................  279\n7.4.3\t Spannungsfeld\tDiskursverrohung\tund\t\u00c4u\u00dferungsfreiheit\t  ...................  284\n7.4.4\t Erweiternde\tund\tvermindernde\tR\u00fcckwirkungen\tauf\tden\t\n\u00f6ffentlichen\tVernunftgebrauch\t  .......................................................................  288\n7.5\t Fazit\tund\tEmpfehlungen\t  .......................................................................  289\n8\t \u00d6FFENTLICHE \tVERWALTUNG \t .......................................................  298\n8.1\t Einleitung\t  ...........................................................................................................  298\n8.2\t Ethische\tFragen\talgorithmischer\tAutomatisierung\tim\t\nVerwaltungshandeln\t .................................................................................  299\n8.3\t Automatische\tEntscheidungssysteme\tam\tBeispiel\t\ndes\tSozialwesens\t  .........................................................................................  306\n8.3.1\t Erweiterung\tprofessioneller\tHandlungskompetenz\t  ...............................  307\n8.3.2\t Verminderung\tvon\tEntscheidungskompetenz,\tHandlungsoptionen\t\nund\tAutorschaft\t  ....................................................................................................  313\n8.4\t Predictive\tPolicing\t\u2013\tKI\tin\tder\t\nKriminalit\u00e4tsbek\u00e4mpfung\t  .....................................................................  320\n8.5\t Fazit\tund\tEmpfehlungen\t  .......................................................................  327\nTEIL III: QUERSCHNITTSTHEMEN UND \n\u00dcBERGREIFENDE EMPFEHLUNGEN\n9\t ZUSAMMENFASSUNG \tDER\tBISHERIGEN \t \nANALYSE \t ............................................................................................................  334\n9.1\t Anthropologische\tund\tethische\tGrundorientierung\t  .... 334\n9.2\t Einsichten\taus\tden\tAnwendungsfeldern\t  .................................  339\n10\t ENTFALTUNG \tVON\tQUERSCHNITTSTHEMEN \tUND\t\nEMPFEHLUNGEN \t ......................................................................................  345\n10.1\t Querschnittsthema\t1:\tErweiterung\tund\t\nVerminderung\tvon\tHandlungsm\u00f6glichkeiten\t  .....................  346\n10.2\t Querschnittsthema\t2:\tWissenserzeugung\tdurch\tKI\t\nund\tUmgang\tmit\tKI-gest\u00fctzten\tVoraussagen\t  .....................  348\n10.3\t Querschnittsthema\t3:\tGef\u00e4hrdung\tdes\tIndividuums\t\ndurch\tstatistische\tStratifizierung\t  ..................................................  351\n10.4\t Querschnittsthema\t4:\tAuswirkungen\tvon\tKI\tauf\t\nmenschliche\tKompetenzen\tund\tFertigkeiten\t  .....................  3531010.5\t Querschnittsthema\t5:\tSchutz\tvon\tPrivatsph\u00e4re\tund\t\nAutonomie\tversus\tGefahren\tdurch\t\u00dcberwachung\t\nund\tChilling-Effekte\t ...................................................................................  357\n10.6\t Querschnittsthema\t6:\tDatensouver\u00e4nit\u00e4t\tund\t\ngemeinwohlorientierte\tDatennutzung\t  .....................................  361\n10.7\t Querschnittsthema\t7:\tKritische\tInfrastrukturen,\t\nAbh\u00e4ngigkeiten\tund\u00a0Resilienz\t  ..........................................................  366\n10.8\t Querschnittsthema\t8:\tPfadabh\u00e4ngigkeiten,\t\nZweitverwertung\tund\tMissbrauchsgefahren\t  ......................  369\n10.9\t Querschnittsthema\t9:\tBias\tund\tDiskriminierung\t  ............  372\n10.10\t Querschnittsthema\t10:\tTransparenz\tund\t\nNachvollziehbarkeit\t\u2013\tKontrolle\tund\tVerantwortung  ... 376\n10.11\t Fazit\t  .........................................................................................................................  379\nLITERATURVERZEICHNIS \t ....................................................................................  381\nABK\u00dcRZUNGSVERZEICHNIS \t ...........................................................................  40211ZUSAMMENFASSUNG\nEinleitung\n1) Digitale Technologien und K\u00fcnstliche Intelligenz (KI) \nhaben mittlerweile in nahezu allen Bereichen des \u00f6f-\nfentlichen und privaten Lebens Einzug gehalten. F\u00fcr die \nethische Bewertung solcher Entwicklungen und ihres \nEinsatzes in verschiedenen Bereichen ist es n\u00f6tig, nicht \nnur die Technologien zu verstehen, sondern auch ihre \nWechselwirkungen mit den Personen, die sie verwenden \noder von ihrer Anwendung betroffen sind. Zentral ist \ndabei die Frage, welche Auswirkungen damit verbunden \nsind, wenn T\u00e4tigkeiten, welche zuvor Menschen vorbe-\nhalten waren, an Maschinen delegiert werden. Werden \nmenschliche Autorschaft und Handlungsm\u00f6glichkeiten \ndurch den Einsatz von KI erweitert oder vermindert?\n2) In der vorliegenden Stellungnahme geht der Deutsche \nEthikrat dieser Frage nach und schreibt damit Themen \nfort, die bereits in den Stellungnahmen \u201eBig Data und \nGesundheit \u2013 Datensouver\u00e4nit\u00e4t als informationelle \nFreiheitsgestaltung\u201c (2017) sowie \u201eRobotik f\u00fcr gute Pfle-\nge\u201c (2019) angeschnitten wurden. Er reagiert mit den ak-\ntuellen Ausf\u00fchrungen zudem auf eine im Oktober 2020 \nvom Pr\u00e4sidenten des Deutschen Bundestages formulierte \nBitte, eine multidisziplin\u00e4re Stellungnahme zu den ethi-\nschen Fragen des Verh\u00e4ltnisses von Mensch und Maschi-\nne zu erarbeiten.\n3) Die Stellungnahme gliedert sich in drei Teile. Im ers-\nten Teil geht es um die technischen und philosophischen \nGrundlagen des Themas. Im zweiten Teil werden die \nzuvor angestellten \u00dcberlegungen anhand von ethischen \nAnalysen in vier ausgew\u00e4hlten Anwendungsfeldern exem-\nplarisch konkretisiert: der Medizin, der schulischen Bil-\ndung, der \u00f6ffentlichen Kommunikation und Meinungs-\nbildung sowie der \u00f6ffentlichen Verwaltung. Im dritten 12Teil werden zehn in allen Anwendungsbereichen rele-\nvante Querschnittsthemen entfaltet, welche jeweils auch \n\u00fcbergreifende Empfehlungen enthalten.\nTEIL I: TECHNISCHE UND PHILOSOPHISCHE \nGRUNDLEGUNGEN\nZentrale Entwicklungen und technische Grundlagen \nK\u00fcnstlicher Intelligenz\n4) Die Idee von Maschinen, deren F\u00e4higkeiten in bestimm-\nten, f\u00fcr das menschliche Wesen besonders pr\u00e4genden \nKernbereichen wie dem Erkennen, Lernen oder Handeln \nmenschlichen F\u00e4higkeiten \u00e4hneln oder diese sogar \u00fcber -\ntreffen, l\u00e4sst sich bis in die griechische Mythologie zu-\nr\u00fcckverfolgen, Jahrtausende vor der Erfindung von Soft-\nwaresystemen. Mit dem Bau der ersten Computer im 20. \nJahrhundert r\u00fcckte die Existenz maschineller Intelligenz \nerstmals in greifbare N\u00e4he. Der Mathematiker Alan Tu-\nring formulierte 1950 ein sp\u00e4ter als Turing-Test bezeich-\nnetes Kriterium f\u00fcr KI, nach dem maschinelle Intelligenz \ndann vorl\u00e4ge, wenn das Verhalten einer Maschine f\u00fcr \nmenschliche Beobachter nicht von dem eines Menschen \nunterscheidbar erscheint.\n5) Die fr\u00fche Forschung zu KI ging davon aus, dass man \nmenschliches Lernen oder menschliche Intelligenz so \ngenau beschreiben k\u00f6nne, dass eine Maschine dazu ge-\nbracht werden kann, sie zu simulieren. Konkrete KI-For -\nschungsthemen, die bis heute eine Rolle spielen, waren \nvon Anfang an zum Beispiel Mustererkennung, Sprach-\nverarbeitung, Abstraktionsf\u00e4higkeit, Kreativit\u00e4t und \nflexibles Probleml\u00f6sen. Flankiert von Fortschritten bei \nder Entwicklung von Computerhardware und Program-\nmiersprachen entstand bald gro\u00dfer Optimismus \u00fcber \ndie Potenziale maschineller Intelligenz. In den folgenden \nJahrzehnten wechselten sich enthusiastische Phasen mit 13sogenannten \u201eKI-Wintern\u201c ab, w\u00e4hrend derer Entt\u00e4u-\nschungen \u00fcber vermeintlich ausbleibende praktische Er -\nfolge im Vordergrund standen und F\u00f6rdermittel gek\u00fcrzt \nwurden.\n6) Weiterentwicklungen in einzelnen KI-Kerngebieten, die \nEntstehung paralleler Datenverarbeitungsmethoden und \ndes Internets sowie das wachsende Engagement von For -\nschungsorganisationen, Milit\u00e4r und Industrie pr\u00e4gten die \nKI-Forschung im sp\u00e4ten 20. Jahrhundert. Parallel dazu \nentstand ein kritischer Diskurs, im Zuge dessen sich auch \ndie Computerethik als eigene Disziplin etablierte. Dabei \nkamen zunehmend auch philosophische Zweifel auf, ob \ninsbesondere die von einigen Forschenden in Aussicht \ngestellten Visionen einer generellen oder starken KI je-\nmals realisiert werden k\u00f6nnten \u2013 oder sollten.\n7) Um die Jahrtausendwende nahmen drei Entwicklungen \nFahrt auf, die der Entwicklung von KI zu einer bis heute \nanhaltenden Dynamik verhalfen: erstens eine deutliche \nLeistungssteigerung und Miniaturisierung von Compu-\ntern, zweitens eine zunehmende Vernetzung digitaler \nSysteme und drittens damit verbundene neue M\u00f6glich-\nkeiten der Datenzusammenf\u00fchrung und -auswertung.\n8) Diese Entwicklungen haben zu einer intensivierten \nDurchdringung der Alltagswelt mit Computern gef\u00fchrt, \ndarunter auch zahlreiche vernetzte und mit Sensoren \nversehene \u201esmarte\u201c Alltagsbegleiter wie Mobiltelefone, \nUhren und Haushaltsger\u00e4te. Es entstehen soziotechni-\nsche Daten\u00f6kosysteme, in denen \u00fcber Ger\u00e4te und die sie \nverkn\u00fcpfenden Datennetzwerke zunehmend akkurate \nund umfangreiche digitale Repr\u00e4sentationen der Bewe-\ngungen, Handlungen, Eigenschaften und Pr\u00e4ferenzen \nvieler Personen entstehen. Solche digitalen Abbilder \nk\u00f6nnen nicht nur ausgewertet werden, sondern wirken \nauch auf menschliches Verhalten zur\u00fcck, indem auf ihrer \nGrundlage Menschen Informationen oder Handlungs-\nempfehlungen angeboten werden.149) Das Fundament solcher digitalen Operationen und In-\nteraktionen bilden Daten und die sie begleitenden Me-\ntadaten, die jeweils von h\u00f6chst unterschiedlicher Natur \nwie Qualit\u00e4t sein k\u00f6nnen. Die Qualit\u00e4t eines Datensatzes \nh\u00e4ngt dabei nicht nur davon ab, wie genau, vollst\u00e4ndig, \naktuell oder detailliert seine Daten sind, sondern auch \nvom Verh\u00e4ltnis zwischen den Erhebungs- und den An-\nwendungskontexten. Daten k\u00f6nnen einer jeweiligen \nFrage oder Aufgabenstellung mehr oder weniger ange-\nmessen sein. Werden solche Fragen von Qualit\u00e4t und \nPassung nicht rechtzeitig und hinreichend ber\u00fccksich-\ntigt, sind Fehler, Verzerrungen (Bias) und irref\u00fchrende \nAnalysen m\u00f6glich.\n10) Entscheidend f\u00fcr die Leistungsf\u00e4higkeit datengetriebener \nAnwendungen sind auch die Hardware und Infrastruk-\ntur, die f\u00fcr die Handhabung und Nutzung von Daten zur \nVerf\u00fcgung stehen. Hier kommen aktuell sowohl \u00fcber das \nInternet zug\u00e4ngliche Dienste zum Einsatz (Cloud-Com-\nputing), hinter denen Gro\u00dfeinrichtungen stehen, die auf \nDatenspeicherung und/oder Datenanalyse spezialisiert \nsind, wie auch immer leistungsf\u00e4higere M\u00f6glichkeiten, \nDaten zumindest teilweise bereits lokal in den Ger\u00e4ten, \ndie sie erheben, zu verarbeiten (Edge-Computing).\n11) Herzst\u00fcck jeglicher Datenverarbeitung sind Algorith-\nmen: Verarbeitungsanweisungen, die vorgeben, wie \neingegebene Daten meist schrittweise nach klar definier -\nten Regeln umgeformt werden, bis der gesuchte Ausga-\nbewert erreicht ist. Im Kontext aktueller KI-Forschung \nsind statistische Analysen, mit denen Regelm\u00e4\u00dfigkeiten \nin Daten erkannt sowie Zusammenh\u00e4nge zwischen ein-\nzelnen Merkmalen identifiziert werden, von besonderer \nBedeutung. Auf dieser Grundlage k\u00f6nnen Vorhersagen \nf\u00fcr \u00e4hnliche Datens\u00e4tze oder k\u00fcnftige Entwicklungen \nabgeleitet werden. Geht es darum, kausale Mechanismen \nnachzuweisen, sind in der Regel weitere \u00dcberlegungen \nund Untersuchungen n\u00f6tig, die eine plausible Erkl\u00e4rung 15f\u00fcr den vermuteten Wirkzusammenhang zwischen \nMerkmalen anbieten, die sich auch empirisch \u2013 zum Bei-\nspiel in Experimenten \u2013 \u00fcberpr\u00fcfen l\u00e4sst.\n12) Statistische Analysen enthalten Unsicherheiten, die sich \nin der Regel nicht ganz ausmerzen lassen. Mit der Mi-\nnimierung bestimmter Fehlerquellen k\u00f6nnen zudem \nandere Fehlerquellen verst\u00e4rkt werden. Welche Fehler \nin statistischen Analysen am ehesten in Kauf zu nehmen \nsind, h\u00e4ngt daher auch immer von der konkreten Frage-\nstellung und Zwecksetzung ab und ist in zahlreichen Be-\nreichen nicht nur eine technisch-methodische, sondern \nauch eine ethische Frage.\n13) Die in KI-Systemen verwendeten algorithmischen Ver -\nfahren und Systeme werden vielfach unter dem Stichwort \n\u201emaschinelles Lernen\u201c zusammengefasst und zeichnen \nsich dadurch aus, dass sie ihre Mustersuche, Modellbil-\ndung und sonstige Funktionsweise datenbasiert optimie-\nren k\u00f6nnen. Dabei gibt es anfangs eine Trainingsphase, \nin der ein Algorithmus sein Modell zur Mustererken-\nnung durch wiederholte Analyse von Trainingsdaten \naufbaut und verfeinert.\n14) Maschinelles Lernen umfasst unterschiedliche Ans\u00e4tze. \nBeim \u00fcberwachten Lernen sind die Zuordnungen zwi-\nschen den Eingabe- und den gesuchten Ausgabedaten im \nTrainingsdatensatz bereits bekannt, beispielsweise Bil-\nder von gesunder Haut und Hautkrebs, deren gesicherte \nZuordnung zu einer dieser beiden Kategorien in einem \nEtikett (Label) vermerkt ist. Un\u00fcberwachtes Lernen \nhingegen funktioniert ohne vorherige Etikettierung der \nTrainingsdaten; stattdessen \u201esucht\u201c der Algorithmus ei-\ngenst\u00e4ndig nach Mustern in Daten. Beim Verst\u00e4rkungs-\nlernen optimiert der Algorithmus seine Operationen auf \nbestimmte Ziele hin und erh\u00e4lt dabei in der Trainings-\nphase f\u00fcr jeden Versuch eine R\u00fcckmeldung, ob dieser \nSchritt das System dem Ziel n\u00e4hergebracht oder es davon \nentfernt hat.1615) Deep Learning ist ein Teilbereich des maschinellen Ler -\nnens, der besonders f\u00fcr den Umgang mit gro\u00dfen Daten-\nmengen geeignet ist und in den letzten Jahren zu einem \nwichtigen Treiber f\u00fcr viele KI-Anwendungen geworden \nist. Hier kommen sogenannte neuronale Netze zum Ein-\nsatz, deren Funktionsweise entfernt an Netzwerkstruktu-\nren im Gehirn angelehnt ist.\n16) Die algorithmischen Strategien, die im Laufe des Trai-\nnings zur Bew\u00e4ltigung der jeweiligen Aufgaben ent-\nwickelt werden, sind in der Regel selbst f\u00fcr geschultes \nPersonal, das den Code einsehen kann, nicht vollst\u00e4ndig \nnachvollziehbar (Blackbox). Es gibt verschiedene L\u00f6-\nsungsans\u00e4tze, um trotzdem eine f\u00fcr die jeweilige Ziel-\ngruppe angemessene Transparenz, Interpretierbarkeit \noder Erkl\u00e4rbarkeit algorithmischer Prozesse zu erreichen \n(Explainable AI). Deren Auswahl und Anwendung ist je-\ndoch technisch anspruchsvoll.\n17) Die kombinierten Entwicklungen von Hardware und \nSoftware, Vernetzung und Datenproduktion haben viel-\nf\u00e4ltig einsetzbare Anwendungsm\u00f6glichkeiten von KI \nhervorgebracht. KI-Systeme k\u00f6nnen beispielsweise in-\nzwischen Menschen in anspruchsvollen Strategiespielen \nwie Schach und Go schlagen (MuZero) oder komplexe \nTexte produzieren, deren maschineller Ursprung oftmals \nnicht mehr zu erkennen ist (ChatGPT).\n18) Der Deutsche Ethikrat nimmt in dieser Stellungnahme \nvier Handlungsfelder in den Blick, in denen der Einsatz \nvon KI entweder schon besonders weitreichende Ver\u00e4n-\nderungen mit sich bringt oder dies in n\u00e4herer Zukunft \nbewirken k\u00f6nnte. In der Medizin stellt maschinelles Ler -\nnen beispielsweise Fortschritte bei Diagnostik und indivi-\ndualisierten Pr\u00e4ventions- und Therapieempfehlungen in \nAussicht. In der schulischen Bildung entstehen vielf\u00e4ltige \nAns\u00e4tze, die Vermittlung von Wissen und Kompetenzen \nin der Schule mithilfe von KI effektiver zu gestalten. In \nder \u00f6ffentlichen Kommunikation und Meinungsbildung 17l\u00e4uft inzwischen ein Gro\u00dfteil des Informationsaus-\ntauschs \u00fcber digitale Plattformen und soziale Medien ab. \nIn der \u00f6ffentlichen Verwaltung ber\u00fchrt der Einsatz algo-\nrithmisch gest\u00fctzter Entscheidungshilfen und Prognosen \ndas Leben vieler Menschen, beispielsweise bei der Beur -\nteilung oder \u00dcberwachung von Personen im Bereich des \nSozial- oder Polizeiwesens.\n19) Um auf die mit solchen Ver\u00e4nderungen verbundenen \nHerausforderungen f\u00fcr das menschliche Miteinander \nzu reagieren, sind bereits eine Reihe von Regularien ent-\nstanden oder aktuell in der Entwicklung. Dazu geh\u00f6rt \nzum einen eine F\u00fclle an Leitlinien, die von Kodizes ein-\nzelner Unternehmen \u00fcber Richtlinien von Fachgesell-\nschaften bis hin zu Werken auf nationaler oder internati-\nonaler Ebene reicht. Parallel entwickelt sich zum anderen \nauch der regulative Rahmen weiter, beispielsweise in den \nMediengesetzen in Deutschland. Da soziotechnische \nEntwicklungen im KI-Bereich h\u00e4ufig von international \nagierenden IT-Unternehmen vorangetrieben werden, \ngewinnen Regelungen auf \u00fcbernationaler Ebene zuneh-\nmend an Bedeutung, in der Europ\u00e4ischen Union bei-\nspielsweise die Datenschutz-Grundverordnung und der \nVorschlag f\u00fcr einen Artificial Intelligence Act.\n20) Diese Entwicklungen ber\u00fccksichtigend fokussiert der \nDeutsche Ethikrat nicht auf den rechtlichen Rahmen, \nsondern gr\u00fcndet seine Analyse der Konsequenzen digita-\nler Entwicklungen f\u00fcr das menschliche Zusammenleben \nauf einer philosophischen Auseinandersetzung mit den \nanthropologischen Grundbegriffen, die im Mittelpunkt \ndes menschlichen Selbstverst\u00e4ndnisses stehen. Darauf \naufbauend entwickelt er ein Verst\u00e4ndnis von Mensch-\nTechnik-Relationen, in dem es entscheidend darauf \nankommt, wie die Delegation menschlicher T\u00e4tigkeiten \nan Maschinen und algorithmische Systeme auf zentra-\nle anthropologische Konzepte zur\u00fcckwirkt und dabei 18insbesondere menschliche Autorschaft erweitert oder \nvermindert.\nZentrale Begriffe und philosophische Grundlagen\n21) Das Verst\u00e4ndnis des Begriffs der K\u00fcnstlichen Intelligenz \nhat sich im Laufe der Jahre ver\u00e4ndert und unterscheidet \nsich sowohl innerhalb als auch zwischen verschiedenen \nBerufsgruppen und Disziplinen. Eine gro\u00dfe Rolle spielt \ndie Unterscheidung zwischen sogenannter schwacher \nund starker KI, wobei letztere Vision eine menschen-\n\u00e4hnliche oder gar menschliche F\u00e4higkeiten \u00fcbertreffen-\nde KI beschreibt. Weitere Begriffspaare, mit denen un-\nterschiedliche Formen oder Grade der Ann\u00e4herung von \nKI an menschliche Intelligenz erfasst werden sollen, sind \nspezielle versus allgemeine KI sowie enge versus breite \nKI.\n22) Die Charakterisierung als spezielle, enge oder schwache \nKI einerseits sowie allgemeine, breite oder starke KI an-\ndererseits verweist nicht nur jeweils auf Differenzen zwi-\nschen zwei Polen. Dahinter verstecken sich, insbeson-\ndere beim Begriffspaar der schwachen und starken KI, \nvielmehr auch unterschiedliche Verst\u00e4ndnisse von Intel-\nligenz sowie unterschiedliche Positionen hinsichtlich der \nKernfrage, ob es qualitative und kategorische oder nur \nquantitative und prinzipiell \u00fcberwindbare Unterschiede \nzwischen menschlicher Intelligenz und KI gibt.\n23) Wichtig ist zum einen die Differenz hinsichtlich der \nBreite bzw. Enge des F\u00e4higkeitenspektrums der KI. Die \nmeisten KI-Anwendungen entfalten ihre jeweilige Leis-\ntung auf klar umrissenen, engen Gebieten oder Dom\u00e4-\nnen. Zum anderen geht es jedoch auch darum, ob Intel-\nligenz an bestimmte mentale Voraussetzungen gekn\u00fcpft \nist, welche \u00fcber die blo\u00dfe Simulation von Verst\u00e4ndnis \nhinausgehen. Es ergibt sich also die Frage, ob Intelligenz \nin allgemeiner oder starker Form jemals vollumf\u00e4nglich 19Maschinen zukommen kann oder ob daf\u00fcr spezifisch \nmenschliche Eigenschaften Voraussetzung sind.\n24) Antworten auf diese Frage variieren in unterschiedli-\nchen anthropologischen Theoriemodellen. Aus behavi-\noristischer Sicht w\u00fcrden manche in einem humanoiden \nRoboter mit perfekten Bewegungsf\u00e4higkeiten und einer \nmenschen\u00e4hnlichen Mimik und Gestik ein Beispiel brei-\nter oder gar starker KI sehen, wenn er in der Lage w\u00e4re, \nalle menschlichen kognitiven F\u00e4higkeiten perfekt zu si-\nmulieren. Nach anderen Konzeptionen w\u00e4re hingegen zu \nbestreiten, dass damit eine Form starker KI vorliege, da \nauch eine perfekte Simulation nicht garantiere, dass ein \nsolcher Roboter mentale Zust\u00e4nde aufweise, \u00fcber Ein-\nsichts- und Urteilsf\u00e4higkeit sowie \u00fcber emotive Einstel-\nlungen wie Hoffnungen und \u00c4ngste verf\u00fcge.\n25) In dieser Stellungnahme wird vorausgesetzt, dass die \nUnterscheidung zwischen enger und breiter KI quan-\ntitativer bzw. gradueller Natur ist, die Entstehung einer \nstarken KI jedoch einen qualitativen Sprung bedeuten \nw\u00fcrde. Als enge KI gelten dabei Anwendungen, welche \nmenschliche F\u00e4higkeiten in einer Dom\u00e4ne simulieren, \num spezifische Aufgaben zu erf\u00fcllen. Breite KI erweitert \ndas Spektrum ihrer Anwendbarkeit \u00fcber einzelne Dom\u00e4-\nnen hinaus. Der Begriff der starken KI wird f\u00fcr die Vision \neiner K\u00fcnstlichen Intelligenz verwendet, die jenseits der \nm\u00f6glicherweise perfekten Simulation menschlicher Ko-\ngnition auch \u00fcber mentale Zust\u00e4nde, Einsichtsf\u00e4higkeit \nund Emotionen verf\u00fcgen w\u00fcrde.\n26) Eine wichtige Grundlage f\u00fcr Diskussionen \u00fcber die ak-\ntuellen und m\u00f6glichen k\u00fcnftigen Potenziale von KI sind \nVorstellungen zu menschlicher Intelligenz. Aus psycho-\nlogischer Perspektive ist Intelligenz als ein hypotheti-\nsches Konstrukt aufzufassen, das als solches zwar verbal \numschrieben werden kann, zum Beispiel im Sinne von \nVerstehen, Urteilen und Schlussfolgern oder zielge-\nrichtetem Handeln, rationalem Denken und effektiver 20Auseinandersetzung mit der Umwelt, aber nicht direkt \nbeobachtbar ist. Intelligenztests erm\u00f6glichen hier eine \nOperationalisierung, indem sie Situationen anbieten, in \ndenen Menschen Verhalten zeigen k\u00f6nnen, das vor dem \nHintergrund eines theoretischen Vorverst\u00e4ndnisses als \nmehr oder weniger \u201eintelligent\u201c bezeichnet werden kann.\n27) Die Frage, ob Intelligenz eine einheitliche F\u00e4higkeit ist \noder viele F\u00e4higkeiten umfasst, die gegebenenfalls auch \nvoneinander unabh\u00e4ngig sein k\u00f6nnen, ist empirisch \nnicht eindeutig zu kl\u00e4ren. Viel diskutiert und mit Blick \nauf KI von Relevanz ist auch der Zusammenhang von In-\ntelligenz und Kreativit\u00e4t. Eine wichtige Rolle spielt hier -\nbei die Unterscheidung zwischen konvergentem Denken, \ndas durch logische Schlussfolgerungen zu einer einzigen \noder besten L\u00f6sung gelangt, und dem f\u00fcr Kreativit\u00e4t cha-\nrakteristischen divergenten Denken, das mehrere alter -\nnative L\u00f6sungen finden kann, die jeweils den gegebenen \nAnforderungen entsprechen.\n28) In j\u00fcngerer Zeit hat sich der Blick auf Intelligenz sukzes-\nsive erweitert, beispielsweise mit Konzepten wie die der \nsozialen bzw. emotionalen Intelligenz. Dar\u00fcber hinaus \nentwickelte sich rund um die Stichworte embodied, em-\nbedded, enactive und extended Kognition ein Forschungs-\nfeld, welches in Philosophie, Psychologie und Robotik die \nRolle des K\u00f6rpers einerseits sowie der Umwelt anderer -\nseits f\u00fcr Intelligenz und kognitive Leistungen erforscht. \nSp\u00e4testens diese Erweiterungen werfen die grunds\u00e4tz-\nliche Frage auf, wie die \u00dcbertragung des Intelligenzbe-\ngriffs auf technische Artefakte zu verstehen ist. Man soll-\nte daher die Verwendung des Ausdrucks \u201eIntelligenz\u201c in \nder Wortverbindung \u201eK\u00fcnstliche Intelligenz\u201c eher als \neine Metapher einordnen, deren Beschreibungs- und Er -\nkl\u00e4rungsfunktion genauerer Aufkl\u00e4rung bedarf.\n29) Der Begriff der Vernunft wurde bereits lange vor der \nEinf\u00fchrung des Begriffs der Intelligenz verwendet, um \ndie spezifische menschliche F\u00e4higkeit zu kennzeichnen, 21sich in der Welt zu orientieren, selbstverantwortlich zu \nhandeln und so der eigenen Lebenspraxis eine koh\u00e4rente \nStruktur zu geben. Intelligenz ist f\u00fcr Vernunft eine wich-\ntige Voraussetzung, aber keine hinreichende Bedingung.\n30) Der Vernunftbegriff ist \u00fcberaus komplex und umfasst ein \nmehrdimensionales Beziehungsgef\u00fcge von Denk-, Refle-\nxions- und Operationsformen, das in seiner Gesamtheit \nim Dienste einer m\u00f6glichst ad\u00e4quaten Wirklichkeitser -\nschlie\u00dfung steht und in einen komplexen sozialen und \nkulturellen Kontext verwoben ist. Von grundlegender \nBedeutung ist dabei die Gegen\u00fcberstellung von theo-\nretischer Vernunft, die sich auf den Erkenntnisgewinn \nrichtet, um zu wahren empirischen oder apriorischen \nUrteilen zu gelangen, und praktischer Vernunft, die auf \nein koh\u00e4rentes, verantwortliches Handeln abzielt, um ein \ngutes Leben zu erm\u00f6glichen.\n31) Vor allem im Blick auf theoretische Vernunft scheinen \nsich einige Parallelen zur Arbeitsweise von KI-Systemen \naufzudr\u00e4ngen. In beiden Bereichen spielen F\u00e4higkeiten \nder Informationsverarbeitung, des Lernens, des logi-\nschen Schlussfolgerns und konsistenten Regelfolgens \nsowie der sinnvollen Verkn\u00fcpfung gespeicherter Infor -\nmationen eine zentrale Rolle. Bei n\u00e4herer Betrachtung \nzeigen sich jedoch insofern gravierende Differenzen, als \nsich nicht nur die Arbeitsweise des menschlichen Ge-\nd\u00e4chtnisses in mehrfacher Hinsicht vom technischen \nSpeicher eines Computers unterscheidet, sondern auch \ndie menschliche Urteilspraxis technisch nicht substitu-\nierbar ist. Zumindest die bislang verf\u00fcgbaren KI-Systeme \nverf\u00fcgen nicht \u00fcber die daf\u00fcr relevanten F\u00e4higkeiten des \nSinnverstehens, der Intentionalit\u00e4t und der Referenz auf \neine au\u00dfersprachliche Wirklichkeit.\n32) Dies best\u00e4tigt sich erst recht f\u00fcr die praktische Vernunft, \ndie insofern noch von weit komplexerer Natur ist, als \nihr Ziel nicht nur in wohlbegr\u00fcndeten praktischen Ein-\nzelurteilen, sondern in einem m\u00f6glichst richtigen und 22verantwortlichen Handeln besteht, das \u00fcber einen langen \nZeitraum aufrechterhalten wird, eine koh\u00e4rente Ord-\nnung der Praxis garantiert und damit ein insgesamt gutes \nLeben erm\u00f6glicht. Dazu bedarf es mehrerer Einzelkom-\npetenzen, deren Simulationsm\u00f6glichkeiten durch techni-\nsche Artefakte kontrovers diskutiert werden.\n33) Zu diesen Einzelkompetenzen geh\u00f6ren erstens ein Ver -\nst\u00e4ndnis der f\u00fcr unsere Moralsprache bedeutsamen Be-\ngriffe zur Bezeichnung moralisch relevanter G\u00fcter, Wer -\nte und Haltungen, zweitens ein Unterscheidungs- und \nEinf\u00fchlungsverm\u00f6gen, drittens die F\u00e4higkeit zur Ab-\nw\u00e4gung konfligierender G\u00fcter und Werte, viertens die \nBef\u00e4higung zum reflektierten Umgang mit Regeln un-\nterschiedlicher Reichweite, f\u00fcnftens die Kompetenz zum \nintuitiven Erfassen komplexer Handlungssituationen \nund Umst\u00e4nde, sechstens ein Urteilsverm\u00f6gen, siebtens \ndie F\u00e4higkeit zur Begr\u00fcndung der eigenen moralischen \nUrteile und der ihnen korrespondierenden Praxis und \nachtens eine Affekt- und Impulskontrolle, um die jeweils \ngef\u00e4llten praktischen Urteile auch handlungswirksam \nwerden zu lassen.\n34) W\u00e4hrend partielle \u00dcberschneidungen des Kompetenz-\nprofils moderner KI-Systeme mit dem komplexen Ph\u00e4-\nnomen menschlicher Vernunft durchaus m\u00f6glich sind, \nist zu ber\u00fccksichtigen, dass die hier genannten Einzel-\nf\u00e4higkeiten nicht beziehungslos nebeneinanderstehen. \nVielmehr ist von vielf\u00e4ltigen Wechselwirkungen, R\u00fcck-\nkopplungen und Bedingungsverh\u00e4ltnissen zwischen ih-\nnen auszugehen. Sie bilden einen integralen Bestandteil \neiner komplexen menschlichen Natur, die als leibseeli-\nsche Einheit zu verstehen ist. Menschliche Vernunft ist \nstets als verleiblichte Vernunft zu begreifen. Praktische \nVernunft ist zudem nicht aus einer rein individualisti-\nschen Perspektive zu verstehen. Da jeder Mensch Teil \neiner sozialen Mitwelt und kulturellen Umgebung ist, die \nsich nachhaltig auf seine Sozialisation auswirken, m\u00fcssen 23auch \u00fcberindividuelle kulturelle Faktoren in die Deutung \nder praktischen Vernunft einbezogen werden.\n35) Ein angemessenes Verst\u00e4ndnis insbesondere des prak-\ntischen Vernunftgebrauchs ist eng mit unserem basalen \nSelbstverst\u00e4ndnis als handlungsf\u00e4hige Personen verbun-\nden. Nicht jedes menschliche Tun, das auf die Umwelt \neinwirkt, ist als Handlung zu verstehen, sondern nur sol-\nches, das zweckgerichtet, beabsichtigt und kontrolliert \nist. Unterstellt man, dass Maschinen nicht zweckgerich-\ntet operieren, also keine Absichten haben, dann ist die \nZuschreibung von Handlungen in Bezug auf Maschinen \nin diesem engen Sinne nicht m\u00f6glich.\n36) Im KI-Diskurs kommt allerdings seit der Jahrtausend-\nwende zunehmend die Frage auf, in welchem Sinne Ma-\nschinen au\u00dferhalb des obigen engen Handlungsbegriffs \ndoch in bestimmten Kontexten in einem weiteren Sin-\nne handeln k\u00f6nnen, zum Beispiel wenn Entscheidungen \nkomplett an Softwaresysteme delegiert werden. Daran \nankn\u00fcpfend gibt es einen Diskurs, ob und inwieweit zu-\nnehmend eigenst\u00e4ndige, das hei\u00dft ohne menschliches \nZutun funktionierende maschinelle Systeme als \u201eAgen-\nten\u201c in der Folge f\u00fcr ihr \u201eHandeln\u201c verantwortlich ge-\nmacht werden k\u00f6nnen, etwa mit Blick auf Fragen der \nHaftung.\n37) Selbst wenn Maschinen komplexe Vollz\u00fcge oder Opera-\ntionen durchf\u00fchren, damit Ver\u00e4nderungen in der Welt \nbewirken und flexibel mit anspruchsvollen Herausforde-\nrungen der menschlichen Lebenswelt umgehen k\u00f6nnen, \nf\u00fchren sie diese Ver\u00e4nderungen aber nicht absichtlich \nherbei und haben sie diese daher auch nicht in einem \nmoralischen und rechtlichen Sinne zu verantworten. Vor \ndiesem Hintergrund scheint es sinnvoll, den Handlungs-\nbegriff im engen Sinne Menschen vorzubehalten, um in-\nflation\u00e4ren Ausweitungen des Akteursstatus zu vermei-\nden und konzeptionelle Grenzziehungen zu erm\u00f6glichen.2438) Entscheidend ist demnach das Konzept der Handlungs-\nurheberschaft bzw. Autorschaft, das auf die universelle \nmenschliche Erfahrung verweist, sich selbst und andere \nim Hinblick auf bestimmte Ereignisse und Zust\u00e4nde als \nUrheber anzusehen. Die F\u00e4higkeit zur Handlungsurhe-\nberschaft kann als Grundlage von Autonomie betrach-\ntet werden, also daf\u00fcr, dass handelnde Menschen ihre \nHandlungen nach Maximen ausrichten k\u00f6nnen, die sie \nsich selber setzen.\n39) Die Umst\u00e4nde und Folgen von Handlungen k\u00f6nnen f\u00fcr \nderen moralische und rechtliche Bewertung von Bedeu-\ntung sein. So k\u00f6nnen aus Handlungen beispielsweise \nneben den beabsichtigten Folgen auch nicht beabsich-\ntigte, aber den Handelnden erkennbare Folgen erwach-\nsen. Dies ist relevant f\u00fcr das Konzept von Fahrl\u00e4ssigkeit, \ndas im Kontext von KI eine gro\u00dfe Rolle spielt. Und auch \nwenn prim\u00e4r einzelne Menschen handeln, schlie\u00dft dies \nein Konzept kollektiver Handlungen nicht aus, bei denen \nmehrere Personen von vornherein in einem Kontext der \nKoordination agieren.\n40) Auch Technologie kann erheblichen Einfluss auf \nmenschliches Handeln oder die menschliche Handlungs-\nerfahrung haben. Die zunehmende Durchdringung der \nmenschlichen Lebenswelt mit informationstechnisch im-\nmer leistungsf\u00e4higeren Maschinen f\u00fchrt zu hybriden, so-\nziotechnischen Konstellationen, in denen Menschen und \nMaschinen eng verwoben sind und auf komplexe Weise \ninteragieren. Zudem k\u00f6nnen manche maschinellen Sys-\nteme menschliches Tun zum Teil so gut imitieren, dass \ndie Simulation wie intentionales menschliches Handeln \nerscheint. Vor diesem Hintergrund ist es sinnvoll, an ei-\nnem engen Handlungsbegriff, der an das zentrale Kriteri-\num der Intentionalit\u00e4t gebunden ist, festzuhalten.\n41) Das Intentionalit\u00e4tskriterium ist zudem entscheidend \nf\u00fcr die M\u00f6glichkeit der Zuschreibung von Verantwor -\ntung im Kontext von Mensch-Maschine-Interaktionen 25in zunehmend komplexer soziotechnischer Vernetzung. \nVerantwortung kann als Konzept einer f\u00fcnffachen Re-\nlation gefasst werden: Wer (Verantwortungssubjekt) ist \nf\u00fcr was (Verantwortungsobjekt), gegen\u00fcber wem (Be-\ntroffenen), vor wem (Instanz) und unter welcher Norm \nverantwortlich?\n42) In der Verantwortungsdiskussion zu wissenschaftlich-\ntechnischem Fortschritt ist zu bedenken, dass die Hand-\nlungsfolgen neuer Entwicklungen oft nur unter hohen \nund nicht eliminierbaren Wissensunsicherheiten abge-\nsch\u00e4tzt werden k\u00f6nnen. Verantwortungszuschreibung \nmuss daher die Dimension des Handelns unter Unsi-\ncherheit ber\u00fccksichtigen.\n43) Moralische Verantwortung k\u00f6nnen nur nat\u00fcrliche Per -\nsonen \u00fcbernehmen, die \u00fcber Handlungsf\u00e4higkeit verf\u00fc-\ngen, das hei\u00dft in der Lage sind, aktiv, zweckgerichtet und \nkontrolliert auf die Umwelt einzuwirken und dadurch \nVer\u00e4nderungen zu verursachen. Tr\u00e4fe dies auch auf Ma-\nschinen zu, w\u00e4ren auch diese verantwortungsf\u00e4hig. Dann \nm\u00fcsste Maschinen der Personenstatus zugeschrieben \nwerden, was jedoch weder aktuell noch angesichts der in \nabsehbarer Zukunft erwartbaren qualitativen Entwick-\nlungen maschineller Systeme angemessen w\u00e4re. Ver -\nantwortung kann daher nicht direkt von maschinellen \nSystemen \u00fcbernommen werden, sondern nur von den \nMenschen, die in je unterschiedlichen Funktionen hinter \ndiesen Systemen stehen, gegebenenfalls im Rahmen ins-\ntitutioneller Verantwortung.\n44) Wer jeweils konkret wie viel Verantwortung tr\u00e4gt, ist \nh\u00e4ufig schwierig zu bestimmen. Die facettenreichen Ver -\nantwortungsgef\u00fcge zwischen Individuen, Organisatio-\nnen und Staat werden noch komplexer, wenn die Wech-\nselwirkungen zwischen diesen Beteiligten zumindest \nteilweise von algorithmischen Systemen gest\u00fctzt oder \nvermittelt werden, welche mitunter kaum durchschau-\nbar sind oder autonom zu agieren scheinen. Vor einem 26solchen Hintergrund ist eine angemessene Gestaltung \nvon Multiakteursverantwortung zentral.\n45) Handlung, Vernunft und Verantwortung stehen im \nZentrum humanistischer Philosophie. Menschen sind \nbef\u00e4higt zur Handlungsurheberschaft und somit zur \nAutorschaft ihres Lebens. Sie sind frei und tragen da-\nher Verantwortung f\u00fcr die Gestaltung ihres Handelns. \nFreiheit und Verantwortung sind zwei sich wechselseitig \nbedingende Aspekte menschlicher Autorschaft. Autor -\nschaft ist wiederum an Vernunftf\u00e4higkeit gebunden.\n46) Im Mittelpunkt dieser Trias aus Vernunft, Freiheit und \nVerantwortung steht das Ph\u00e4nomen der Affektion durch \nGr\u00fcnde. Praktische Gr\u00fcnde sprechen f\u00fcr Handlungen, \ntheoretische Gr\u00fcnde sprechen f\u00fcr \u00dcberzeugungen. In \nder Regel gibt es Gr\u00fcnde, das eine zu tun und das andere \nzu lassen, die gegeneinander abgewogen werden m\u00fcssen. \nDer Konflikt von Gr\u00fcnden zwingt dann zur Abw\u00e4gung \nund zur Systematisierung dieser Abw\u00e4gung in Gestalt \nethischer Theoriebildung.\n47) Die menschliche Lebensform ist von reaktiven Einstel-\nlungen und moralischen Gef\u00fchlen gepr\u00e4gt, die von nor -\nmativen Gr\u00fcnden begleitet sind. Freiheit kommt insofern \nins Spiel, als wir diese zur\u00fcckstellen, wenn wir erfahren, \ndass eine Person in ihrem Handeln nicht frei war. Diese \nPraxis der Zuschreibung von Freiheit und Verantwor -\ntung ist essenziell f\u00fcr die Grundlegung moralischer Beur -\nteilung. Die Normen von Moral und Recht sind ohne die \nAnnahme menschlicher Verantwortung und damit von \nFreiheits- und Vernunftf\u00e4higkeit unbegr\u00fcndet.\n48) Eine Herausforderung dieser humanistischen Perspek-\ntive kommt aus den Neurowissenschaften. Empirische \nStudien, nach denen beispielsweise das motorische Zen-\ntrum des Gehirns schon mit der Vorbereitung einer Be-\nwegung beginnt, bevor man sich bewusst f\u00fcr die Ausf\u00fch-\nrung der Bewegung entschieden hat, werden mitunter \nals Beleg daf\u00fcr interpretiert, dass es Freiheit und damit 27menschliche Verantwortlichkeit nicht gebe. Tats\u00e4chlich \nlassen solche Befunde jedoch unterschiedliche Inter -\npretationen zu und eignen sich nicht als Widerlegung \nmenschlicher Freiheit und Verantwortung.\n49) Eine zweite Kritik der humanistischen Anthropologie \nwird von der KI-Debatte inspiriert. Sie changiert zwi-\nschen einer \u00dcberwindung des Menschen in Gestalt des \nTranshumanismus, der mit neuen Mensch-Maschine-\nSymbiosen die Reichweite menschlichen Wirkens in \nneue Dimensionen heben m\u00f6chte, und einem Maschi-\nnenparadigma, das den menschlichen Geist auf das Mo-\ndell eines algorithmischen Systems reduziert. Gerade \nletzteres entfaltet besondere Relevanz im Kontext dieser \nStellungnahme, da es gro\u00dfen Einfluss auf die Interpreta-\ntion der Wechselwirkungen zwischen Mensch und Ma-\nschine und deren R\u00fcckwirkungen auf das menschliche \nSelbstverst\u00e4ndnis hat.\n50) In Maschinenparadigmen werden Menschen materia-\nlistisch als Maschinen oder Maschinen animistisch mit \nmentalen Zust\u00e4nden ausgestattet und als menschen-\ngleich gedeutet. Die in KI-Diskursen teilweise verbrei-\ntete Tendenz, eine \u00e4u\u00dferliche Ununterscheidbarkeit von \nmenschlicher und maschineller Performanz pauschal \nmit der Annahme von Intelligenz und Denkverm\u00f6gen \nsolcher Maschinen gleichzusetzen, ist das Ergebnis be-\nstimmter theoretischer Vorannahmen insbesondere be-\nhavioristischer und funktionalistischer Art.\n51) Der Behaviorismus versucht, menschliches Verhalten \nauf der Grundlage pr\u00e4zise beschreibbarer Reiz-Reaktion-\nSchemata zu erkl\u00e4ren und die Psychologie damit in eine \nexakte Wissenschaft zu verwandeln; das Innenleben der -\nart beschriebener Organismen wird dabei komplett aus-\ngeblendet. Der Funktionalismus beruht auf der Annah-\nme, dass mentale Zust\u00e4nde funktional vollst\u00e4ndig erfasst \nwerden k\u00f6nnen und die Frage nach der Seinsart menta-\nler Zust\u00e4nde zugunsten der genauen Beschreibung ihrer 28Funktion aufgehoben werden kann und sollte. Durch die \nThese der multiplen Realisierung, nach der bestimmte \nmentale Ereignisse, Eigenschaften oder Zust\u00e4nde durch \nganz unterschiedliche physikalische Ereignisse, Eigen-\nschaften oder Zust\u00e4nde realisiert werden k\u00f6nnen, scheint \nes zudem m\u00f6glich, auch Computern mentale Zust\u00e4nde \nzuzuschreiben, obwohl sie keine biologischen Strukturen \nbesitzen.\n52) Kritik am Funktionalismus verweist auf ph\u00e4nomena-\nles Bewusstsein, nach dem die mentalen Zust\u00e4nde eines \nWesens entscheidend von Empfindungsqualit\u00e4ten ab-\nh\u00e4ngen, die allein aufgrund \u00e4u\u00dferen Verhaltens nicht \nzug\u00e4nglich sind. Dieses ph\u00e4nomenale Bewusstsein setzt \ndem Verm\u00f6gen, die Qualit\u00e4t des Erlebens oder die men-\ntalen Zust\u00e4nde anderer Lebewesen zu beurteilen, gewis-\nse Grenzen und l\u00e4sst die funktionalistisch inspirierte \nMensch-Computer-Analogie als eine fragw\u00fcrdige Re-\nduktion erscheinen.\n53) Ein weiteres Argument gegen den Funktionalismus \nstammt aus John Searles Gedankenexperiment zum \n\u201echinesischen Zimmer\u201c, in dem eine Person aus einer \nKammer anhand einer genauen Gebrauchsanleitung chi-\nnesische Antworten auf Fragen herausreicht. Nicht diese \nPerson beherrscht die chinesische Sprache und auch kein \n\u00dcbersetzungscomputer, sondern diejenigen, die die Ge-\nbrauchsanleitung bzw. den Algorithmus zur Beantwor -\ntung der Fragen verfasst haben.\n54) In der Zur\u00fcckweisung funktionalistischer Maschinenpa-\nradigmen wird die Bedeutung der gesamten Lebenser -\nfahrung f\u00fcr die Vernunft deutlich. Menschliche Vernunft \nist leibliche Vernunft. Der Leib ist Ausgangspunkt und \nBestandteil jeder Wahrnehmung und Empfindung und \nals solcher Voraussetzung f\u00fcr menschliches In-der-Welt-\nSein und die Herstellung von Beziehungen zu anderen. \nKognitive F\u00e4higkeiten sind in ihrem Entstehungs- und 29Vollzugsprozess also an Sinnlichkeit und Leiblichkeit, \nSozialit\u00e4t und Kulturalit\u00e4t gebunden.\n55) Daraus ergeben sich auch Grenzen der Formalisierbarkeit \nund Simulierbarkeit menschlicher Vernunft. Die Aneig-\nnung menschlicher Erfahrung ist immer mit Deutungs-\nprozessen verbunden und setzt immer ein Beteiligtsein, \nein Engagement voraus. Auch hier spielt der Leib eine \nwichtige Rolle, denn er erm\u00f6glicht ein Handeln, das al-\nlein mittels bewusster Planung und Berechnung so nicht \nm\u00f6glich w\u00e4re. Darin gr\u00fcndet eine Nichtsimulierbarkeit \ndes Denkens, vor deren Hintergrund die Entwicklung \nvon KI an Grenzen st\u00f6\u00dft.\n56) Aus den bisherigen \u00dcberlegungen l\u00e4sst sich zusammen-\nfassen, dass menschliche Intelligenz unaufl\u00f6slich mit \nden vielf\u00e4ltigen Dimensionen der menschlichen Lebens-\nwelt verbunden ist. Sie operiert gr\u00fcndegeleitet und ist \nAusdruck von akzeptierten Werten und Normen. Es ist \nfraglich, ob eine derart gr\u00fcndegeleitete, multidimensio-\nnal bestimmte und soziokulturell eingebettete koh\u00e4rente \nPraxis selbst f\u00fcr komplexe maschinelle Systeme jemals \nplausibel sein k\u00f6nnte.\nMensch-Technik-Relationen\n57) Menschen entwickeln, gestalten und nutzen Technik als \nMittel zum Zweck. Die mehr oder minder umfassende \nDelegation menschlicher T\u00e4tigkeiten an Maschinen \u2013 bis \nhin zur vollst\u00e4ndigen Ersetzung menschlicher Handlun-\ngen durch maschinelle Vollz\u00fcge \u2013 wirkt allerdings h\u00e4ufig \nzur\u00fcck auf menschliche Handlungsm\u00f6glichkeiten, Fer -\ntigkeiten, Autorschaft und Verantwortungs\u00fcbernahme \nund kann diese jeweils erweitern oder vermindern. Die \ndrei Begriffe des Erweiterns, Verminderns und Ersetzens \ndienen in dieser Stellungnahme als analytische Matrix.\n58) Technikgestaltung wird im sozialen Konstruktivismus \nals Prozess beschrieben, der eher menschlich gesetz-\nten, durch die jeweiligen gesellschaftlichen Priorit\u00e4ten 30gepr\u00e4gten Zwecken folgt. Im technologischen Deter -\nminismus wird eine insbesondere nach \u00f6konomischen \nVerh\u00e4ltnissen bestimmende Eigendynamik als ma\u00dfgeb-\nlich gesehen, der sich Mensch und Gesellschaft letztlich \nunterordnen und anpassen m\u00fcssen. Tats\u00e4chlich spielen \nbeide Ans\u00e4tze zusammen und unterliegt die Mensch-\nTechnik-Relation von Grund auf einem Ko-Konstruk-\ntionsverh\u00e4ltnis und kann als Ko-Evolution beschrieben \nwerden. Soziale Kontexte und normative Kriterien auf \nder einen und Technologien auf der anderen Seite entwi-\nckeln sich weiter in gegenseitiger Wechselwirkung.\n59) In ihrer Gesamtheit kann Technik dabei zu einer \u201ezwei-\nten Natur\u201c werden, die Rand- und Erfolgsbedingun-\ngen f\u00fcr weiteres menschliches Leben setzt und auch die \nWeltsicht und das Probleml\u00f6sen beeinflusst. Somit ist \nneue Technologie oft bereits das Ergebnis einer techno-\nlogischen Art und Weise, wie Menschen die Welt sehen \nund sich zu ihr in Beziehung setzen. Die zunehmende \nKomplexit\u00e4t der Mensch-Technik- bzw. Mensch-Ma-\nschine-Relation ver\u00e4ndert auch deren Wahrnehmung. \nIn KI-gesteuerten Systemen scheinen die vormals klaren \nUnterscheidungen von Mensch und Technik weniger \neindeutig zu werden. Auch in der Umgangssprache ist \ndie Anthropomorphisierung digitaler Technik weit fort-\ngeschritten, zum Beispiel in der Zuschreibung von F\u00e4hig-\nkeiten wie Denken, Lernen, Entscheiden oder Zeigen von \nEmotion an KI und Roboter.\n60) Subjekt-Objekt-Verh\u00e4ltnisse zwischen Mensch und \nTechnik ver\u00e4ndern sich ebenfalls. In vernetzten Systemen \nhaben Menschen teils die Subjekt-, teils aber auch die Ob-\njektrolle inne. Wenn beispielsweise Entscheidungen \u00fcber \nMenschen an Softwaresysteme delegiert werden, etwa \nhinsichtlich der Gew\u00e4hrung von Sozialleistungen, wer -\nden Menschen zu Objekten der \u201eEntscheidungen\u201c dieser \nSysteme, die hier auftreten, als ob sie Subjekte seien.3161) Verschiedene Ans\u00e4tze versuchen, diese Entwicklungen \nin Konzepten zu mehrstufigen Mensch-Technik-Wech-\nselwirkungen zu beschreiben.\n62) Die Zuschreibung von Verantwortung bleibt in diesen \nAns\u00e4tzen jeweils beim Menschen. Moralisch problema-\ntische Resultate k\u00f6nnen dennoch durch KI-Systeme ver -\nursacht werden und sie haben Einfluss auf menschliches \nHandeln. Dieses ist also weder v\u00f6llig autonom noch v\u00f6l-\nlig sozial oder technisch determiniert, sondern in zuneh-\nmendem Ma\u00dfe soziotechnisch situiert.\n63) KI zeigt in vielen F\u00e4llen eindeutig positive Folgen im \nSinne der Erweiterung der M\u00f6glichkeiten menschlicher \nAutorschaft. Im Rahmen der Diffusion von Technik und \nInnovationen in die Gesellschaft, ihrer Nutzung und Ver -\nallt\u00e4glichung kommt es jedoch auch zu Verminderungen \nmenschlicher Entfaltungsm\u00f6glichkeiten. Durch den Ein-\nsatz digitaler Technologien k\u00f6nnen Abh\u00e4ngigkeiten von \ndiesen oder Anpassungsdruck entstehen \u2013 und andere, \nbis dahin etablierte Optionen verschlossen werden.\n64) Solche Effekte k\u00f6nnen schleichend und teilweise unbe-\nwusst durch Verhaltens\u00e4nderungen entstehen, ohne dass \nIntentionen von Akteuren dahinterstehen. Das Ersetzen \nals Endpunkt des Delegierens vormals menschlich aus-\nge\u00fcbter T\u00e4tigkeiten an technische Systeme erfolgt jedoch \nintentional. Eine derartige \u00dcbertragung ist f\u00fcr sich ge-\nnommen ein Ausdruck der Wahrnehmung menschlicher \nAutorschaft. Die zentrale ethische Frage ist, ob und wie \ndiese \u00dcbertragung die M\u00f6glichkeiten anderer Menschen \nbeeinflusst, vor allem jener, \u00fcber die entschieden wird. \nDaraus ergibt sich ein Bedarf, die \u00dcbertragung mensch-\nlicher T\u00e4tigkeiten auf KI-Systeme auch gegen\u00fcber den \ndavon Betroffenen transparent zu gestalten und bei der \nBeurteilung von KI zu ber\u00fccksichtigen, f\u00fcr wen eine \nAnwendung jeweils Chancen oder Risiken und Erweite-\nrungen oder Verminderungen der Autorschaft mit sich 32bringt. Damit sind Aspekte sozialer Gerechtigkeit und \nMacht involviert.\n65) Weiterhin sind psychologische Effekte im Zusammen-\nhang mit KI-Systemen zu beachten, vor allem der Au-\ntomation Bias. Menschen vertrauen algorithmisch \nerzeugten Ergebnissen und automatisierten Entschei-\ndungsprozeduren h\u00e4ufig mehr als menschlichen Ent-\nscheidungen. Damit wird Verantwortung \u2013 zumindest \nunbewusst \u2013 an diese \u201eQuasi-Akteure\u201c delegiert. Selbst \nwenn ein KI-System normativ strikt auf die Rolle der \nEntscheidungsunterst\u00fctzung begrenzt wird, kann Auto-\nmation Bias dazu f\u00fchren, dass ein KI-System allm\u00e4hlich \nin die Rolle des eigentlichen \u201eEntscheiders\u201c ger\u00e4t und \nmenschliche Autorschaft und Verantwortung ausge-\nh\u00f6hlt werden.\nTEIL II: AUSGEW\u00c4HLTE ANWENDUNGEN UND \nSEKTORSPEZIFISCHE EMPFEHLUNGEN\nMedizin\n66) KI-gest\u00fctzte digitale Produkte kommen zunehmend im \nGesundheitssystem zum Einsatz. Die Betrachtung der \nmit ihnen verbundenen Chancen und Risiken bedarf ei-\nner wenigstens dreifachen Differenzierung. Erstens sind \nmehrere Akteursgruppen zu unterscheiden, die bez\u00fcg-\nlich eines KI-Einsatzes unterschiedliche Funktionen und \nVerantwortlichkeiten besitzen. Zweitens umfasst das \nGesundheitswesen von der Forschung bis zur konkreten \nPatientenversorgung unterschiedliche Anwendungsbe-\nreiche f\u00fcr KI-Produkte. Drittens sind unterschiedliche \nGrade der Ersetzung menschlicher Handlungssegmente \nzu beobachten.\n67) Bereits die Entwicklung geeigneter KI-Komponenten f\u00fcr \ndie medizinische Praxis erfordert enge interdisziplin\u00e4re \nZusammenarbeit verschiedener Sachverst\u00e4ndiger und 33stellt hohe Anforderungen an die Qualit\u00e4t der verwen-\ndeten Trainingsdaten, um vermeidbare Verzerrungen \nder Ergebnisse von vornherein zu minimieren. Systeme \nsind so zu konzipieren, dass sie Plausibilit\u00e4tspr\u00fcfungen \nin der Nutzungsphase vorsehen, um den Gefahren eines \nAutomation Bias zu entgehen. Mittels geeigneter Pr\u00fcf-, \nZertifizierungs- und Auditierungsma\u00dfnahmen soll-\nte gew\u00e4hrleistet werden, dass nur hinreichend gepr\u00fcfte \nKI-Produkte zum Einsatz kommen, deren grundlegende \nFunktionsweise zumindest bei Systemen, die Entschei-\ndungsvorschl\u00e4ge mit schwerwiegenden Konsequenzen \nf\u00fcr Betroffene unterbreiten, auch f\u00fcr diejenigen, die ein \nProdukt sp\u00e4ter verwenden, hinreichend erkl\u00e4r- sowie in-\nterpretierbar ist.\n68) In der medizinischen Forschung kann der Einsatz von \nKI in mehrfacher Hinsicht vorteilhaft sein, sofern der \nSchutz der an den Studien teilnehmenden Personen und \nihrer Daten gew\u00e4hrleistet ist. KI kann hier beispielsweise \nhilfreiche Vor- und Zuarbeiten bei Literaturrecherchen \noder der Durchsuchung gro\u00dfer Datenbanken leisten, \nneue Korrelationen zwischen bestimmten Ph\u00e4nomenen \nentdecken und auf dieser Grundlage treffsichere Vorher -\nsagen machen, etwa zur Ausbreitung eines Virus oder \nzur Struktur komplexer Molek\u00fcle.\n69) In der medizinischen Versorgung werden KI-Instru-\nmente zunehmend auch zur Diagnostik und Therapie \neingesetzt, beispielsweise bei Brust- und Prostatakrebser -\nkrankungen. Entscheidungsunterst\u00fctzungssysteme mo-\ndellieren und automatisieren hier Entscheidungsprozesse \nmittels Analyse verschiedener Parameter der Labordiag-\nnostik, der Bildbearbeitung sowie der automatisierten \nDurchsicht von Patientenakten und wissenschaftlichen \nDatenbanken. Gerade Fortschritte in der KI-gest\u00fctzten \nBilderkennung er\u00f6ffnen dabei neue M\u00f6glichkeiten einer \nfr\u00fchzeitigen Detektion, Lokalisation und Charakterisie-\nrung pathologischer Ver\u00e4nderungen. In der Therapie 34kommt KI beispielsweise in Operationsrobotern zum \nEinsatz.\n70) Wenn \u00e4rztliche T\u00e4tigkeiten in derart engem bis mittle-\nren Ausma\u00df an Technik delegiert werden, k\u00f6nnen bei-\nspielsweise Tumoren fr\u00fcher erkannt, Therapieroptionen \nerweitert und die Chancen auf eine erfolgreiche Therapie \nsomit erh\u00f6ht werden. F\u00fcr \u00e4rztliches Personal er\u00f6ffnet \ndie Technik zudem die Chance, von monotonen Rou-\ntinearbeiten entlastet zu werden und mehr Zeit f\u00fcr den \nAustausch mit Patientinnen und Patienten zu gewinnen. \nDiesen Chancen stehen aber auch Risiken gegen\u00fcber, \nbeispielweise wenn Fachkr\u00e4fte durch die fortschreitende \nDelegation bestimmter Aufgaben an technische Systeme \neigene Kompetenzen verlieren oder Sorgfaltspflichten im \nUmgang mit KI-gest\u00fctzter Technik aufgrund eines Au-\ntomation Bias vernachl\u00e4ssigen.\n71) Um die Chancen des KI-Einsatzes in klinischen Situatio-\nnen zu realisieren und Risiken zu minimieren, sind meh-\nrere Ebenen zu ber\u00fccksichtigen. So bedarf es unter ande-\nrem einer fl\u00e4chendeckenden und m\u00f6glichst einheitlichen \ntechnischen Ausr\u00fcstung, Personalschulung und konti-\nnuierlichen Qualit\u00e4tssicherung ebenso wie Strategien, \ndie gew\u00e4hrleisten, dass auch in KI-gest\u00fctzten Verfahren \nBefunde auf Plausibilit\u00e4t gepr\u00fcft werden, die pers\u00f6nliche \nLebenssituation von Erkrankten umfassend ber\u00fccksich-\ntigt und vertrauensvoll kommuniziert wird. Auch der \nbei den meisten medizinischen KI-Anwendungen gro\u00dfe \nDatenbedarf bringt Herausforderungen mit sich, sowohl \nhinsichtlich des Schutzes der Privatsph\u00e4re Betroffener als \nauch mit Blick auf eine teils sehr restriktive individuelle \nAuslegungspraxis geltender Datenschutzbestimmungen, \ndie der Realisierung von Potenzialen des KI-Einsatzes in \nder klinischen Praxis im Wege stehen kann.\n72) Einer der wenigen medizinischen Handlungsbereiche, in \ndenen KI-basierte Systeme f\u00fcr einzelne bereits \u00e4rztliches \nbzw. anderes Gesundheitspersonal \u2013 jedenfalls de facto 35\u2013 weitgehend oder vollst\u00e4ndig ersetzen, ist die Psychothe-\nrapie. Hier sind seit einigen Jahren Instrumente in Ent-\nwicklung und Nutzung, meist in Form von bildschirm-\nbasierten Apps, die auf algorithmischer Basis eine Art \nvon Therapie anbieten und vielfach frei erh\u00e4ltlich sind. \nSolche Apps k\u00f6nnen einerseits angesichts ihrer Niedrig-\nschwelligkeit und st\u00e4ndigen Verf\u00fcgbarkeit Menschen in \nErstkontakt mit therapeutischen Angeboten bringen, die \nsonst zu sp\u00e4t oder gar nicht eine Therapie erhalten. An-\ndererseits gibt es Bedenken etwa hinsichtlich mangelnder \nQualit\u00e4tskontrollen, dem Schutz der Privatsph\u00e4re oder \nwenn Menschen eine Art emotionale Beziehung zur the-\nrapeutischen App aufbauen. Kontrovers diskutiert wird \nauch, ob die zunehmende Nutzung solcher Apps weite-\nrem Abbau von therapeutischem Fachpersonal Vorschub \nleistet.\n73) Auf Grundlage dieser \u00dcberlegungen formuliert der \nDeutsche Ethikrat neun Empfehlungen f\u00fcr den Einsatz \nvon KI im Gesundheitssektor:\n>> Empfehlung Medizin 1: Bei der Entwicklung, Erpro-\nbung und Zertifizierung medizinischer KI-Produkte \nbedarf es einer engen Zusammenarbeit mit den re-\nlevanten Zulassungsbeh\u00f6rden sowie insbesondere \nmit den jeweils zust\u00e4ndigen medizinischen Fachge-\nsellschaften, um Schwachstellen der Produkte fr\u00fch-\nzeitig zu entdecken und hohe Qualit\u00e4tsstandards zu \netablieren.\n>> Empfehlung Medizin 2: Bei der Auswahl der Trai-\nnings-, Validierungs- und Testdatens\u00e4tze sollte \n\u00fcber bestehende Rechtsvorgaben hinaus mit ei-\nnem entsprechenden Monitoring sowie pr\u00e4zise und \nzugleich sinnvoll umsetzbaren Dokumentations-\npflichten sichergestellt werden, dass die f\u00fcr die be-\ntreffenden Patientengruppen relevanten Faktoren \n(z. B. Alter, Geschlecht, ethnische Einflussfaktoren, 36Vorerkrankungen und Komorbidit\u00e4ten) hinreichend \nber\u00fccksichtigt werden.\n>> Empfehlung Medizin 3: Bei der Gestaltung des Designs \nvon KI-Produkten zur Entscheidungsunterst\u00fctzung \nist sicherzustellen, dass die Ergebnisdarstellung in ei-\nner Form geschieht, die Gefahren etwa von Automa-\ntismen (Automation Bias) transparent macht, ihnen \nentgegenwirkt und die die Notwendigkeit einer refle-\nxiven Plausibilit\u00e4tspr\u00fcfung der jeweils vom KI-Sys-\ntem vorgeschlagenen Handlungsweise unterstreicht.\n>> Empfehlung Medizin 4: Bei der Sammlung, Verar -\nbeitung und Weitergabe von gesundheitsbezogenen \nDaten sind generell strenge Anforderungen und hohe \nStandards in Bezug auf Aufkl\u00e4rung, Datenschutz und \nSchutz der Privatheit zu beachten. In diesem Zusam-\nmenhang verweist der Deutsche Ethikrat auf seine \n2017 im Kontext von Big Data und Gesundheit for -\nmulierten Empfehlungen, die sich am Konzept der \nDatensouver\u00e4nit\u00e4t orientieren, das f\u00fcr den Bereich \nvon KI-Anwendungen im Gesundheitsbereich glei-\ncherma\u00dfen G\u00fcltigkeit entfaltet.\n>> Empfehlung Medizin 5: Bei durch empirische Studien \nsorgf\u00e4ltig belegter \u00dcberlegenheit von KI-Anwendun-\ngen gegen\u00fcber herk\u00f6mmlichen Behandlungsmetho-\nden ist sicherzustellen, dass diese allen einschl\u00e4gigen \nPatientengruppen zur Verf\u00fcgung stehen.\n>> Empfehlung Medizin 6: F\u00fcr erwiesen \u00fcberlegene KI-\nAnwendungen sollte eine rasche Integration in die \nklinische Ausbildung des \u00e4rztlichen Fachpersonals \nerfolgen, um eine breitere Nutzung vorzubereiten \nund verantwortlich so gestalten zu k\u00f6nnen, dass \nm\u00f6glichst alle Patientinnen und Patienten davon \nprofitieren und bestehende Zugangsbarrieren zu den \nneuen Behandlungsformen abgebaut werden. Dazu \nist die Entwicklung einschl\u00e4giger Curricula/Module \nin Aus-, Fort- und Weiterbildung notwendig. Auch 37die anderen Gesundheitsberufe sollten entsprechen-\nde Elemente in die Ausbildung aufnehmen, um die \nAnwendungskompetenz bei KI-Anwendungen im \nGesundheitsbereich zu st\u00e4rken.\n>> Empfehlung Medizin 7: Bei routinem\u00e4\u00dfiger Anwen-\ndung von KI-Komponenten sollte nicht nur gew\u00e4hr -\nleistet werden, dass bei denjenigen, die sie klinisch \nnutzen, eine hohe methodische Expertise zur Ein-\nordnung der Ergebnisse vorhanden ist, sondern auch \nstrenge Sorgfaltspflichten bei der Datenerhebung \nund -weitergabe sowie bei der Plausibilit\u00e4tspr\u00fcfung \nder maschinell gegebenen Handlungsempfehlungen \neingehalten werden. Besondere Aufmerksamkeit er -\nfordert die Gefahr eines Verlustes von theoretischem \nwie haptisch-praktischem Erfahrungswissen und ent-\nsprechenden F\u00e4higkeiten (Deskilling); dieser Gefahr \nsollte mit geeigneten, spezifischen Fortbildungsma\u00df-\nnahmen entgegengewirkt werden.\n>> Empfehlung Medizin 8: Bei fortschreitender Ersetzung \n\u00e4rztlicher, therapeutischer und pflegerischer Hand-\nlungssegmente durch KI-Komponenten ist nicht nur \nsicherzustellen, dass Patientinnen und Patienten \u00fcber \nalle entscheidungsrelevanten Umst\u00e4nde ihrer Be-\nhandlung vorab informiert werden. Dar\u00fcber hinaus \nsollten auch gezielte kommunikative Ma\u00dfnahmen \nergriffen werden, um dem drohenden Gef\u00fchl einer \nzunehmenden Verobjektivierung aktiv entgegenzu-\nwirken und das Vertrauensverh\u00e4ltnis zwischen den \nbeteiligten Personen zu sch\u00fctzen. Je h\u00f6her der Grad \nder technischen Substitution menschlicher Handlun-\ngen durch KI-Komponenten ist, desto st\u00e4rker w\u00e4chst \nder Aufkl\u00e4rungs- und Begleitungsbedarf der Patien-\ntinnen und Patienten. Die verst\u00e4rkte Nutzung von \nKI-Komponenten in der Versorgung darf nicht zu \neiner weiteren Abwertung der sprechenden Medizin \noder einem Abbau von Personal f\u00fchren.38>> Empfehlung Medizin 9: Eine vollst\u00e4ndige Ersetzung \nder \u00e4rztlichen Fachkraft durch ein KI-System gef\u00e4hr -\ndet das Patientenwohl und ist auch nicht dadurch zu \nrechtfertigen, dass schon heute in bestimmten Ver -\nsorgungsbereichen ein akuter Personalmangel be-\nsteht. Gerade in komplexen Behandlungssituationen \nbedarf es eines personalen Gegen\u00fcbers, das durch \ntechnische Komponenten zwar immer st\u00e4rker un-\nterst\u00fctzt werden kann, dadurch selbst als Verant-\nwortungstr\u00e4ger f\u00fcr die Planung, Durchf\u00fchrung und \n\u00dcberwachung des Behandlungsprozesses aber nicht \n\u00fcberfl\u00fcssig wird.\nBildung\n74) Auch in der schulischen Bildung kommen zunehmend \ndigitale Technologien und algorithmische Systeme zum \nEinsatz. Dies kann sowohl zur Standardisierung von \nLernprozessen f\u00fchren als auch mehr Personalisierung \nerm\u00f6glichen. Die Einsatzm\u00f6glichkeiten reichen von sehr \neng umrissenen punktuellen Angeboten bis hin zu Sze-\nnarien, in denen KI-gest\u00fctzte Lehr- und Lernsysteme \nzeitweise oder g\u00e4nzlich eine Lehrkraft ersetzen k\u00f6nnen.\n75) Das hier zugrunde gelegte Verst\u00e4ndnis von Bildung ori-\nentiert sich an der F\u00e4higkeit des Menschen zu freiem \nund vern\u00fcnftigem Handeln, das nicht auf behavioristi-\nsche oder funktionalistische Modelle zu reduzieren ist. \nBildung erfordert den Erwerb von Orientierungswissen \nals Bedingung von reflexiver Urteilskraft und Entschei-\ndungsst\u00e4rke. Dieser Prozess umfasst auch kulturelles \nLernen sowie emotionale und motivationale Aspekte. \nDas Lehr- und Lerngeschehen ist als dynamische Inter -\naktion mit anderen Personen zu begreifen. Der Einsatz \nvon KI-gest\u00fctzten Instrumenten in der Schule ist dar -\naufhin zu \u00fcberpr\u00fcfen, ob er einem solchen Verst\u00e4nd-\nnis des Menschen als einer zur Selbstbestimmung und 39Verantwortung f\u00e4higen Person entspricht und solche \nProzesse f\u00f6rdert oder ob er diesen entgegensteht.\n76) Ausgangspunkt der meisten KI-Anwendungen in der \nBildung ist die Sammlung und Auswertung vieler Daten \nder Lernenden und mitunter auch der Lehrkr\u00e4fte. Hier \nstellen sich Fragen nach dem sinnvollen Grad und Aus-\nma\u00df der Datenerhebung sowie deren w\u00fcnschenswerten \nVerwendungsweisen. Es geht darum, Lernende in ihrem \nindividuellen Lernprozess durch Datennutzung best-\nm\u00f6glich zu unterst\u00fctzen und gleichzeitig zu verhindern, \ndass diese Daten zur \u00dcberwachung oder Stigmatisierung \nvon einzelnen Lernenden missbraucht werden k\u00f6nnen.\n77) Auf Grundlage der erhobenen Daten k\u00f6nnen individua-\nlisierte R\u00fcckmeldungen \u00fcber Lehr- und Lernprozesse so-\nwie entsprechende Reaktionen oder Empfehlungen des \nSoftwaresystems erfolgen. Durch Auswertung von zum \nBeispiel Lerngeschwindigkeit, typischen Fehlern, St\u00e4r -\nken und Schw\u00e4chen kann die Software das Lernprofil der \nLernenden erkennen und die Lerninhalte entsprechend \nanpassen. Subjektive Eindr\u00fccke der Lehrkr\u00e4fte k\u00f6nnen \ndadurch datenbasiert untermauert, aber auch korrigiert \nwerden.\n78) Auch in der Schule kann es durch KI zu engen, mittleren \nund weiten Ersetzungen bestimmter Handlungssegmen-\nte und Interaktionen kommen. Eine enge Ersetzung liegt \netwa vor, wenn ein Softwaresystem f\u00fcr einen genau be-\nstimmten Lernabschnitt eingesetzt wird. Aufw\u00e4ndigere \nund datenintensivere intelligente Tutorsysteme k\u00f6nnen \nauch komplexere Lerninhalte in unterschiedlichen F\u00e4-\nchern im Zusammenwirken mit Lernenden vermitteln \nund so breitere Teilaspekte des Unterrichtsgeschehens \nersetzen oder im Einzelfall die Funktion einer Lehrkraft \nvollst\u00e4ndig \u00fcbernehmen.\n79) Dar\u00fcber hinaus gibt es mittlerweile auch Bestrebungen, \nKI zur Analyse des Verhaltens im Klassenraum einzu-\nsetzen (Classroom Analytics), um die Dynamik ganzer 40Lerngruppen umfassend zu dokumentieren und auszu-\nwerten. Solche Ans\u00e4tze sind aufgrund der f\u00fcr sie not-\nwendigen Erfassung vielf\u00e4ltiger Daten unter anderem \n\u00fcber das Verhalten von Sch\u00fclerinnen und Sch\u00fclern so-\nwie Lehrkr\u00e4ften umstritten. Chancen auf verbesserte \nP\u00e4dagogik und Didaktik stehen potenziell negative Aus-\nwirkungen umfangreicher Datensammlungen auf die \nPrivatsph\u00e4re und Autonomie aller Beteiligten gegen\u00fcber.\n80) Ein besonders kontrovers diskutierter Aspekt von Class-\nroom Analytics betrifft die m\u00f6gliche Erfassung von Auf-\nmerksamkeit (Attention Monitoring) oder emotionaler \nVerfasstheit (Affect Recognition) der im Unterricht in-\nteragierenden Personen, insbesondere basierend auf der \nAnalyse von Audio- oder Videodaten aus Klassenr\u00e4u-\nmen. Auch wenn dies durchaus mit dem Ziel einer Ver -\nbesserung von Lernergebnissen verbunden sein kann, \nwird bezweifelt, dass Aufmerksamkeit und Emotionen \njedenfalls mit aktueller Technik hinreichend genau, zu-\nverl\u00e4ssig und ohne systematische Verzerrung gemessen \nwerden k\u00f6nnen. Au\u00dferdem werden die vorstehend ge-\nnannten Risiken der notwendigen Datenerfassung hier \nals besonders gravierend eingesch\u00e4tzt.\n81) Zusammenfassend lassen sich aufseiten der Chancen \nvon KI in der Schule personalisiertes Lernen und Ent-\nlastung von Lehrkr\u00e4ften anf\u00fchren, ebenso eine potenziell \nobjektivere und fairere Bewertung von Lernergebnissen \nsowie mitunter verbesserte Zugangschancen und M\u00f6g-\nlichkeiten zur Inklusion von Lernenden mit besonderen \nBed\u00fcrfnissen. Zu den Risiken geh\u00f6ren neben den bereits \nerw\u00e4hnten Bedenken hinsichtlich Verzerrungen und Be-\neintr\u00e4chtigungen der Privatsph\u00e4re und der Autonomie \nauch Gefahren der Isolation und Vereinsamung von Ler -\nnenden sowie m\u00f6glicherweise qualitative Ver\u00e4nderun-\ngen des Lernverhaltens. So k\u00f6nnten sich etwa grunds\u00e4tz-\nliche Auswirkungen auf die Motivation und F\u00e4higkeit 41von Sch\u00fclerinnen und Sch\u00fclern zur L\u00f6sung komplexerer \nAufgaben ergeben.\n82) KI-gest\u00fctzte Lehr- und Lernsysteme k\u00f6nnen den jewei-\nligen Lernprozess unterst\u00fctzen, ersetzen aber nicht die \npersonale Vermittlung und die personalen Aspekte von \nBildung. Die Relevanz der Schule als Sozialraum der In-\nteraktion zwischen Menschen ist dabei nicht zu unter -\nsch\u00e4tzen. Da Bildung nicht nur in optimierbarer und be-\nrechenbarer Anh\u00e4ufung von Wissen, sondern vor allem \nin einem konstruktiven und verantwortlichen Umgang \nmit erlerntem Wissen besteht, ist bei der Delegation von \nElementen des Lehr- und Lerngeschehens an Maschinen \nbesonders darauf zu achten, dass Lernprozesse, die zen-\ntral f\u00fcr die Pers\u00f6nlichkeitsbildung des Menschen sind, \ndadurch nicht vermindert werden.\n83) Vor dem Hintergrund dieser \u00dcberlegungen legt der \nDeutsche Ethikrat elf Empfehlungen f\u00fcr den Einsatz von \nKI in der schulischen Bildung vor:\n>> Empfehlung Bildung 1: Digitalisierung ist kein Selbst-\nzweck. Der Einsatz sollte nicht von technologischen \nVisionen, sondern von grundlegenden Vorstellungen \nvon Bildung, die auch die Bildung der Pers\u00f6nlichkeit \numfassen, geleitet sein. Die vorgestellten Tools sollten \ndeshalb im Bildungsprozess kontrolliert und als ein \nElement innerhalb der Beziehung zwischen Lehren-\nden und Lernenden eingesetzt werden.\n>> Empfehlung Bildung 2: F\u00fcr jedes Einsatzgebiet gilt es, \neine angemessene Abw\u00e4gung von Chancen und Risi-\nken vorzunehmen. Insbesondere sollten Autonomie \nund Privatheit von Lehrenden und Lernenden hohen \nSchutz erfahren. Besondere Chancen ergeben sich \nim Bereich der Inklusion und Teilhabe, wo das Po-\ntenzial dieser Systeme genutzt werden sollte, um etwa \nsprachliche oder r\u00e4umliche Barrieren abzubauen.42>> Empfehlung Bildung 3: Tools, die einzelne Elemente \ndes Lehr- und Lernprozesses ersetzen bzw. erg\u00e4n-\nzen (enge Ersetzung) und nachweislich F\u00e4higkeiten, \nKompetenzen oder soziale Interaktion der Personen, \ndie sie nutzen, erweitern, wie etwa einige intelligen-\nte Tutorsysteme oder Telepr\u00e4senzroboter f\u00fcr externe \nLehrbeteiligung, sind prinzipiell weniger problema-\ntisch als solche, die umfassendere bzw. weitere Teile \ndes Bildungsprozesses ersetzen. Je h\u00f6her der Erset-\nzungsgrad, desto strenger m\u00fcssen Einsatzbereiche, \nUmgebungsfaktoren und Nutzenpotenziale evaluiert \nwerden.\n>> Empfehlung Bildung 4: Es gilt, standardisierte Zertifi-\nzierungssysteme zu entwickeln, die anhand transpa-\nrenter Kriterien des Gelingens von Lernprozessen im \ngenannten umfassenden Sinne Schul\u00e4mter, Schulen \nund Lehrkr\u00e4fte dabei unterst\u00fctzen k\u00f6nnen, sich f\u00fcr \noder gegen die Nutzung eines Produkts zu entschei-\nden. Hier kann sich auch der Empfehlung zur dau-\nerhaften Einrichtung l\u00e4nder\u00fcbergreifender Zentren \nf\u00fcr digitale Bildung, wie es im Gutachten \u201eDigitalisie-\nrung im Bildungssystem: Handlungsempfehlungen \nvon der Kita bis zur Hochschule\u201c der St\u00e4ndigen Wis-\nsenschaftlichen Kommission der Kultusministerkon-\nferenz angesprochen wurde, angeschlossen werden.\n>> Empfehlung Bildung 5: Bei der Entwicklung, Erpro-\nbung und Zertifizierung entsprechender KI-Produkte \nbedarf es einer engen Zusammenarbeit mit den rele-\nvanten Beh\u00f6rden, mit den jeweils zust\u00e4ndigen p\u00e4da-\ngogischen Fachgesellschaften sowie der Partizipation \nvon Beteiligten, um Schwachstellen der Produkte \nfr\u00fchzeitig zu entdecken und hohe Qualit\u00e4tsstandards \nzu etablieren. Bekannte Herausforderungen KI-getrie-\nbener Technologien wie beispielsweise Verzerrungen \nbzw. Bias oder Anthropomorphisierungstendenzen 43sollten bei der Entwicklung und Standardisierung be-\nr\u00fccksichtigt werden.\n>> Empfehlung Bildung 6: Um den verantwortlichen \nEinsatz von KI-Technologien im Bildungsprozess zu \ngew\u00e4hrleisten, muss die Nutzungskompetenz insbe-\nsondere der Lehrkr\u00e4fte erh\u00f6ht werden; es bedarf der \nEntwicklung und Etablierung entsprechender Mo-\ndule und Curricula in der Aus-, Fort- und Weiter -\nbildung. Insbesondere die Gefahren eines verengten \np\u00e4dagogischen Ansatzes und eines Deskillings in der \nLehre sollten dabei aktiv in den Blick genommen wer -\nden. Ebenso sollte die digitale Nutzungskompetenz \nvon Lernenden sowie Eltern gest\u00e4rkt und um KI-As-\npekte erweitert werden.\n>> Empfehlung Bildung 7: Im Sinne der Beteiligungs-\ngerechtigkeit sollten KI-basierte Tools Lernenden \ngrunds\u00e4tzlich auch f\u00fcr das Eigenstudium zur Verf\u00fc-\ngung stehen.\n>> Empfehlung Bildung 8: Die Einf\u00fchrung von KI-Tools \nim Bildungsbereich erfordert ferner den Ausbau ver -\nschiedener flankierender Forschungsbereiche. So-\nwohl theoretische Fundierung als auch empirische \nEvidenz zu Effekten, etwa auf die Kompetenzentwick-\nlung (z. B. Probleml\u00f6sen), oder zur Beeinflussung der \nPers\u00f6nlichkeitsentwicklung bei Kindern und Heran-\nwachsenden muss weiter ausgebaut werden. Dabei \nsollte nicht nur st\u00e4rker in Forschung und entspre-\nchende Produktentwicklung investiert, sondern vor \nallen Dingen auch die praktische Erprobung und \nEvaluation im schulischen Alltag verst\u00e4rkt werden.\n>> Empfehlung Bildung 9: Des Weiteren stellt sich hier \ndie Problematik der Datensouver\u00e4nit\u00e4t. Zum einen \nsind bei der Sammlung, Verarbeitung und Weiter -\ngabe von bildungsbezogenen Daten strenge Anfor -\nderungen an den Schutz der Privatsph\u00e4re zu beach-\nten. Zum anderen sollte die gemeinwohlorientierte, 44verantwortliche Sammlung und Nutzung von gro\u00dfen \nDaten, etwa in der prognostischen lehrunterst\u00fctzen-\nden Anwendung, erm\u00f6glicht werden.\n>> Empfehlung Bildung 10: Eine vollst\u00e4ndige Ersetzung \nvon Lehrkr\u00e4ften l\u00e4uft dem hier skizzierten Verst\u00e4nd-\nnis von Bildung zuwider und ist auch nicht dadurch \nzu rechtfertigen, dass schon heute in bestimmten Be-\nreichen ein akuter Personalmangel und eine schlechte \n(Aus-)Bildungssituation herrschen. In der komple-\nxen Situation der schulischen Bildung bedarf es ei-\nnes personalen Gegen\u00fcbers, das mithilfe technischer \nKomponenten zwar immer st\u00e4rker unterst\u00fctzt wer -\nden kann, dadurch selbst als Verantwortungstr\u00e4ger \nf\u00fcr die p\u00e4dagogische Begleitung und Evaluation des \nBildungsprozesses aber nicht \u00fcberfl\u00fcssig wird.\n>> Empfehlung Bildung 11: In Anbetracht der erkennt-\nnistheoretischen und ethischen Herausforderungen \nund unter Abw\u00e4gung potenzieller Nutzen und Sch\u00e4-\nden stehen die Mitglieder des Deutschen Ethikrates \ndem Einsatz von Audio- und Videomonitoring im \nKlassenzimmer insgesamt skeptisch gegen\u00fcber. Ins-\nbesondere erscheint die Analyse von Aufmerksam-\nkeit und Emotionen per Audio- und Video\u00fcberwa-\nchung des Klassenraums mittels aktuell verf\u00fcgbarer \nTechnologien nicht vertretbar. Ein Teil des Ethikrates \nschlie\u00dft den Einsatz von Technologien zur Aufmerk-\nsamkeits- und Affekterkennung zuk\u00fcnftig jedoch \nnicht vollst\u00e4ndig aus, sofern sichergestellt ist, dass \ndie erfassten Daten eine wissenschaftlich nachweis-\nbare Verbesserung des Lernprozesses bieten und das \nhierf\u00fcr notwendige Monitoring von Lernenden und \nLehrkr\u00e4ften keine inakzeptablen Auswirkungen auf \nderen Privatsph\u00e4re und Autonomie hat. Ein anderer \nTeil des Ethikrates hingegen h\u00e4lt die Auswirkungen \nauf Privatsph\u00e4re, Autonomie und Gerechtigkeit hin-\ngegen generell f\u00fcr nicht akzeptabel und bef\u00fcrwortet 45daher ein Verbot von Technologien zu Aufmerksam-\nkeitsmonitoring und Affekterkennung in Schulen.\n\u00d6ffentliche Kommunikation und Meinungsbildung\n84) Durch die digitale Transformation ver\u00e4ndern sich auch \npolitisch relevante Kommunikationsprozesse. Die rasan-\nte Verbreitung digitaler Plattformen und sozialer Medien \nmit ihren algorithmisch vermittelten Informations- und \nKommunikationsangeboten wirkt sich nicht nur auf ein-\nzelne gesellschaftliche Sph\u00e4ren aus, sondern potenziell \nauch auf gro\u00dfe Teile der \u00f6ffentlichen Kommunikation \nund Meinungsbildung \u2013 mit Konsequenzen f\u00fcr das de-\nmokratische Legitimationsgef\u00fcge.\n85) Viele Plattformen bieten inzwischen sich \u00e4hnelnde M\u00f6g-\nlichkeiten an, multimediale Inhalte zu erstellen und zu \nverbreiten, auf die Inhalte anderer zu reagieren, sich \nmit anderen Personen auszutauschen und die Plattform \nnach Inhalten zu durchsuchen oder diese zu abonnieren. \nAuch Optionen, eigene Inhalte gezielt zu bewerben und \nProdukte und Dienstleistungen direkt anzubieten oder \nzu kaufen, sind vielfach vorhanden. Fast alle weiter ver -\nbreiteten Plattformen und Dienste werden von privaten \nUnternehmen aus den USA oder China betrieben und \ndie gr\u00f6\u00dften sozialen Netzwerke geh\u00f6ren nur wenigen \nFirmen. Aufgrund dieser Marktmacht sowie der Vielsei-\ntigkeit und Integration der Dienste funktionieren viele \nAngebote inzwischen als reichhaltige soziotechnische \nInfrastrukturen, in denen sich ein Gro\u00dfteil des Online-\nNutzungsverhaltens nach den Vorgaben weniger Kon-\nzerne abspielt.\n86) Mit der F\u00fclle der Informationen und Interaktionsm\u00f6g-\nlichkeiten in sozialen Medien gehen technische Heraus-\nforderungen und \u00f6konomische Potenziale einher, die \ngemeinsam zur Gestaltung aktueller Funktionsweisen \nund Gesch\u00e4ftsmodelle beigetragen haben. Die F\u00fclle der \nInhalte stellt Plattformen wie auch Kundschaft vor das 46Problem der Informationsauswahl. Diese wird aktuell \n\u00fcberwiegend an Algorithmen delegiert, die daf\u00fcr sorgen, \ndass jeder Person beim Besuch einer Plattform auf sie \npers\u00f6nlich zugeschnittene Inhalte in einer bestimmten \nReihenfolge angezeigt werden.\n87) Die Kriterien, nach denen solche Algorithmen ihre \nAuswahl treffen, sind eng mit \u00f6konomischen Faktoren \nverkn\u00fcpft. Die meisten Plattformen und Dienste folgen \neinem werbebasierten Gesch\u00e4ftsmodell, das am besten \nfunktioniert, wenn die Interessen der einzelnen Nutze-\nrinnen und Nutzer erstens m\u00f6glichst pr\u00e4zise bekannt \nsind und Menschen zweitens m\u00f6glichst viel Zeit auf der \nPlattform verbringen, w\u00e4hrend derer ihnen auf pers\u00f6nli-\nche Interessen zugeschnittene Werbung pr\u00e4sentiert wird. \nDaher lohnt es sich f\u00fcr Plattformen, so viele Datenspu-\nren wie m\u00f6glich \u00fcber den pers\u00f6nlichen Hintergrund, \ndie Interessen, das Nutzungsverhalten und das soziale \nNetzwerk der Personen, die es nutzen, zu sammeln und \nf\u00fcr die Auswahl personalisierter Inhalte zu verwenden \n(Profiling).\n88) Eine algorithmisch gesteuerte personalisierte Informa-\ntionsauswahl, in der \u00f6konomische und aufmerksam-\nkeitsbasierte Faktoren derart eng verbunden sind und \ndie sich anhand des Nutzungsverhaltens st\u00e4ndig weiter -\nentwickelt, f\u00fchrt dazu, dass Inhalte, die besonders sen-\nsationell erscheinen oder intensive emotionale Reakti-\nonen ausl\u00f6sen, sich \u00fcberproportional schnell und weit \nverbreiten. Dies beg\u00fcnstigt unter anderem Falschnach-\nrichten und Inhalte wie Hassrede, Beleidigungen und \nVolksverhetzungen.\n89) In Reaktion auf die Herausforderung, wie mit solchen \npotenziell problematischen und gleichzeitig verbrei-\ntungsstarken Inhalte umzugehen ist, bem\u00fchen sich Platt-\nformen darum, ihre Inhalte nach verschiedenen Kriterien \nzu moderieren (Content-Moderation). Hierbei kommen \nsowohl Menschen als auch algorithmische Systeme zum 47Einsatz. Grundlage f\u00fcr die Moderation sind rechtliche \nVorgaben sowie plattformeigene Kommunikationsre-\ngeln, auf deren Grundlage auch rechtlich zul\u00e4ssige In-\nhalte gel\u00f6scht, gesperrt oder in ihrer Reichweite einge-\nschr\u00e4nkt werden k\u00f6nnen.\n90) Menschliche Moderation erfolgt typischerweise durch \nPersonen, die bei Drittanbietern angestellt sind, mit de-\nnen eine Plattform vertraglich zusammenarbeitet. Diese \nPersonen werden bei oftmals prek\u00e4ren Arbeitsbedin-\ngungen mit h\u00e4ufig extrem belastendem Material wie \nT\u00f6tungen, Kindesmissbrauch, Tierqu\u00e4lerei und Suizid \nkonfrontiert. Zudem m\u00fcssen sie innerhalb weniger Se-\nkunden sprachlich und kulturell komplexe Nuancen be-\nr\u00fccksichtigen, von denen die Zul\u00e4ssigkeit eines Beitrags \nentscheidend abh\u00e4ngen kann.\n91) Algorithmen k\u00f6nnen im Gegensatz dazu anst\u00f6\u00dfige In-\nhalte herausfiltern, ohne dass diese durch Menschen an-\ngesehen werden m\u00fcssen, und dar\u00fcber hinaus mit der un-\n\u00fcbersichtlichen Menge an Daten und Inhalten im Netz \nbesser umgehen. Allerdings sind automatisierte Metho-\nden jedenfalls bislang h\u00e4ufig unzureichend, um den kul-\nturellen und sozialen Zusammenhang einer \u00c4u\u00dferung \neinzubeziehen und diese damit ad\u00e4quat zu beurteilen. \nAufgrund der aktuellen rechtlichen Anreizstruktur be-\nsteht die Gefahr, dass systematisch auch Inhalte gel\u00f6scht \noder unzug\u00e4nglich gemacht werden, die nicht gegen Re-\ngeln versto\u00dfen (Overblocking).\n92) Durch die beschriebenen Funktionsweisen von Plattfor -\nmen und die sich dabei entfaltenden soziotechnischen \nVerquickungen k\u00f6nnen menschliche Handlungsf\u00e4hig-\nkeiten in unterschiedlicher Weise erweitert oder ver -\nmindert werden. Die Delegation von Kuratierungs- und \nModerationsprozessen an Algorithmen ist mit Komfort- \nund Effizienzgewinnen verbunden und kann eine Erwei-\nterung von Handlungsm\u00f6glichkeiten bedeuten, wenn \nbeispielsweise Informationen und pers\u00f6nliche Ziele 48besser oder schneller erreicht werden k\u00f6nnen oder wenn \naufgrund der effektiven Delegation der Inhaltsauswahl \nan Algorithmen Entlastungseffekte auftreten, die Frei-\nr\u00e4ume f\u00fcr andere Aktivit\u00e4ten schaffen.\n93) Eine Verminderung menschlicher Handlungsspielr\u00e4ume \nund pers\u00f6nlicher Freiheit kann sich ergeben, wo es Men-\nschen schwerf\u00e4llt, sich dem Sog von Plattformangeboten \nzu entziehen und ihre Nutzung dieser Angebote auf ein \nf\u00fcr sie gesundes Ma\u00df zu beschr\u00e4nken. Zudem kann eine \nalgorithmische Kuratierung Autorschaft vermindern, \nwenn eine rationale Auseinandersetzung mit Alternati-\nven durch die algorithmische Vorwegnahme bestimmter \nRelevanzentscheidungen nur noch eingeschr\u00e4nkt statt-\nfinden kann.\n94) Neben diesen allgemeinen Auswirkungen der Funkti-\nonsweisen von Plattformen und sozialen Medien ver -\n\u00e4ndern sich durch sie auch die Informations- und die \nDiskursqualit\u00e4t, welche wichtige Grundlagen der \u00f6f-\nfentlichen Meinungsbildung sind \u2013 mit potenziell weit-\nreichenden Konsequenzen f\u00fcr Prozesse der politischen \nWillensbildung. Wie weit verbreitet und wirkm\u00e4chtig \ndie nachfolgend genannten Effekte sind, l\u00e4sst sich aktuell \nzwar noch nicht abschlie\u00dfend beurteilen, auch weil die \nDatenlage mitunter unklar oder widerspr\u00fcchlich ist. Ein \ngenauerer Blick auf die postulierten Mechanismen lohnt \njedoch schon deswegen, weil die von ihnen ber\u00fchrten \nProzesse grundlegend f\u00fcr unsere Demokratie sind.\n95) Mit Blick auf die Informationsqualit\u00e4t ist zun\u00e4chst auf \ndie positive Erweiterung vieler Informationsm\u00f6glichkei-\nten zu verweisen. Demgegen\u00fcber wird vielfach die Sorge \nge\u00e4u\u00dfert, dass die derzeit g\u00e4ngigen Praktiken algorithmi-\nscher Kuratierung auch negative Auswirkungen haben, \nindem sie die Verbreitung von Falschnachrichten und \nVerschw\u00f6rungstheorien f\u00f6rdern, zur Entstehung von \nFilterblasen und Echokammern beitragen und Inhalte 49priorisieren, die negative emotionale und moralische Re-\naktionen und Interaktionen provozieren.\n96) Trotz der genannten Unsicherheiten \u00fcber das Ausma\u00df \nder beschriebenen Effekte erscheint es plausibel, dass \nFalschnachrichten, Filterblasen und Echokammern so-\nwie eine emotional-moralische Zuspitzung vieler Inhalte \nnegative Auswirkung auf die Informationsqualit\u00e4t ent-\nfalten k\u00f6nnen. Die Freiheit, qualitativ hochwertige Infor -\nmationen zu finden, wird unter diesen Umst\u00e4nden durch \ndie Wirkmacht der zum Einsatz kommenden Algorith-\nmen praktisch vermindert.\n97) \u00c4nderungen in der Qualit\u00e4t, Darbietung und Verbrei-\ntung algorithmisch vermittelter Informationen betreffen \nauch die Diskursqualit\u00e4t in ethisch wie politisch rele-\nvanter Hinsicht. Auch hier sind zun\u00e4chst wieder positi-\nve Entwicklungen und Potenziale zu benennen, die sich \ninsbesondere aus den auf Plattformen und in sozialen \nMedien wesentlich erh\u00f6hten M\u00f6glichkeiten zu Teilhabe \nund direkter Vernetzung ergeben. Gegen\u00fcber den ge-\nnannten Chancen werden jedoch auch mit Blick auf die \nDiskursqualit\u00e4t negative Entwicklungen diskutiert. Da-\nbei geht es vor allem um drei Themen: politische Pola-\nrisierung \u00f6ffentlicher Diskurse, politische Werbung und \nManipulation sowie das Spannungsfeld von Diskursver -\nrohungen und \u00fcberbordenden Eingriffen in die \u00c4u\u00dfe-\nrungs- und Meinungsfreiheit.\n98) Es gibt viele Hinweise, dass die beschriebene Verbrei-\ntungsf\u00e4higkeit emotional und moralisch aufgeladener \nInhalte zu Tonfallverschiebungen gef\u00fchrt hat, auch und \ninsbesondere auf Kan\u00e4len, die aktiv zur Gestaltung des \npolitischen Diskurses beitragen. Nachdem beispiels-\nweise ge\u00e4nderte Auswahlkriterien auf Facebook dazu \nf\u00fchrten, dass sich k\u00fcnftig vor allem solche Inhalte er -\nfolgreich verbreiteten, auf die Menschen besonders \naufgebracht reagieren, versch\u00e4rften viele politische 50Kommunikationsteams den Tonfall ihrer Beitr\u00e4ge, um \ndiesen Kriterien gerecht zu werden.\n99) Auf Plattformen ergibt sich zudem viel Potenzial f\u00fcr \nbesonders wirkm\u00e4chtige Kommunikationskampagnen, \ndie eingebettet in den digitalen Alltag ablaufen, ohne \ndass Nutzerinnen und Nutzer sich dessen gewahr wer -\nden. Die reichhaltigen datenbasierten Profile, die sich \naus dem Nutzungsverhalten auf Plattformen erstellen \nlassen, k\u00f6nnen auch genutzt werden, um zielgenaue po-\nlitische Werbung zu schalten (Targeted Advertisement) \noder um Menschen strategisch zu desinformieren oder \nvon der Wahl abzuhalten. Wie erfolgreich solche auch \nals Microtargeting bezeichneten Ans\u00e4tze sind, ist zwar \nnoch nicht hinreichend erforscht, doch allein das Wissen \ndarum, dass versucht wird, auf Grundlage sehr pers\u00f6n-\nlicher psychologischer Merkmale politische Pr\u00e4ferenzen \nzu manipulieren, kann plausibel negative Effekte auf den \npolitischen Diskurs und das Vertrauen in politische Mei-\nnungsbildungsprozesse entfalten.\n100) Vertrauenssch\u00e4digend kann sich weiterhin der Umstand \nauswirken, dass zur strategischen Beeinflussung des \u00f6f-\nfentlichen politischen Diskurses auch vielfach unechte \nProfile (Fake-Accounts) eingesetzt werden, die teilweise \nautomatisiert betriebenen werden (Bots). Kommunikati-\nonskampagnen, die solche unechten Profile nutzen, k\u00f6n-\nnen damit Botschaften effektiv verst\u00e4rken, ihnen somit \nmehr \u00dcberzeugungskraft verleihen und Diskurse mitun-\nter problematisch verzerren.\n101) Der bereits beschriebene Trend zur Versch\u00e4rfung von \nTonlagen auf Plattformen und in sozialen Medien geht \nmit der Sorge einher, dass eine Zunahme stark negativ \nund aggressiv gepr\u00e4gter Kommunikationsstile bis hin zu \nHassrede, Drohungen und Gewaltaufforderungen zu ei-\nner Verrohung des politischen Diskurses beitragen kann. \nSelbst wenn online verbreitete Hetze nicht in Handlun-\ngen in der realen Welt umschl\u00e4gt, kann es auch hier zu 51Chilling-Effekten kommen. Wo n\u00e4mlich solche \u00c4u\u00dfe-\nrungen so viel Unbehagen und Angst sch\u00fcren, dass dies \nPersonen davon abh\u00e4lt, sich am \u00f6ffentlichen Diskurs zu \nbeteiligen, wirkt dies auf die Freiheit und Handlungs-\nm\u00f6glichkeiten Betroffener in der Onlinekommunikation \nvermindernd.\n102) Andererseits werden auch Bem\u00fchungen, potenziell pro-\nblematische Inhalte mit Moderationsma\u00dfnahmen einzu-\nd\u00e4mmen, teils kritisch beurteilt, denn solche Reaktionen \nwerfen ihrerseits demokratietheoretische Fragen auf. \n\u00dcberm\u00e4\u00dfige L\u00f6schungen und Sperrungen k\u00f6nnen einen \nEingriff in die Meinungs- und Pressefreiheit darstellen \nund selbst zu Chilling-Effekten beitragen, n\u00e4mlich dann, \nwenn Menschen bestimmte Inhalte gar nicht erst ver\u00f6f-\nfentlichen, weil sie bef\u00fcrchten, dass diese Inhalte gleich \nwieder gel\u00f6scht oder gar ihre Accounts (zeitweise) ge-\nsperrt werden k\u00f6nnten.\n103) In der Zusammenschau k\u00f6nnen die hier aufgezeigten \nPh\u00e4nomene und Entwicklungen, die sich in den so-\nziotechnischen Infrastrukturen digitaler Netzwerke \nvollziehen, erhebliche Auswirkungen auf Prozesse der \n\u00f6ffentlichen Kommunikation sowie der politischen Mei-\nnungs- und Willensbildung entfalten, auch und vielleicht \ninsbesondere in demokratischen Gesellschaften. Vor die-\nsem Hintergrund legt der Deutsche Ethikrat zu diesem \nAnwendungsfeld von KI zehn Empfehlungen vor:\n>> Empfehlung Kommunikation 1: Regulierung sozia-\nler Medien: Es bedarf klarer rechtlicher Vorgaben, \nin welcher Form und in welchem Ausma\u00df soziale \nMedien und Plattformen \u00fcber ihre Funktions- und \nVorgehensweisen zur Kuratierung und Moderation \nvon Inhalten informieren m\u00fcssen und wie dies auf \nder Grundlage institutioneller Regelungen umgesetzt \nwird. Dies muss durch externe Kontrollen \u00fcberpr\u00fcf-\nbar sein; rein freiwillige Ans\u00e4tze privater Handelnder, 52insbesondere die unverbindliche \u00dcberpr\u00fcfung durch \nvon diesen selbst besetzten Aufsichtsgremien, sind \nnicht ausreichend. Hier gibt es auf Ebene der Europ\u00e4-\nischen Union im Digital Services Act bereits Ans\u00e4tze, \ndie aber noch nicht weit genug gehen.\n>> Empfehlung Kommunikation 2: Transparenz \u00fcber \nModerations- und Kuratierungspraktiken: Anstelle \nallgemeiner Moderations- und L\u00f6schungsrichtlinien \nund wenig aussagekr\u00e4ftiger Zahlen \u00fcber L\u00f6schungen \nmuss f\u00fcr externe Kontrollen nachvollziehbar sein, \nwie, unter welchen Umst\u00e4nden und anhand welcher \nKriterien solche Entscheidungen gef\u00e4llt und umge-\nsetzt werden und welche Rolle hierbei Algorithmen \nbzw. menschliche Moderierende \u00fcbernommen ha-\nben. Dar\u00fcber hinaus m\u00fcssen auch die grundlegen-\nden Funktionsweisen der Kuratierung von Inhalten \nsozialer Medien und Plattformen in dem Ausma\u00df \noffengelegt werden, das n\u00f6tig ist, um systemische \nVerzerrungen und m\u00f6glicherweise resultierende in-\nformationelle Dysfunktionen erkennen zu k\u00f6nnen. \nDie Berichtspflichten und Transparenzvorgaben im \nMedienstaatsvertrag, im Netzwerkdurchsetzungs-\ngesetz und im Digital Services Act stellen dies noch \nnicht hinreichend sicher. Die datenschutzrechtlichen \nAuskunftspflichten gem\u00e4\u00df Art. 12 ff. DSGVO sind \nzum Teil auf nationalstaatliche Ebene beschr\u00e4nkt \nworden und erfassen oftmals diese weiter gehenden \nAspekte nicht.\n>> Empfehlung Kommunikation 3: Zugriff auf wissen-\nschaftsrelevante Daten von Plattformen: Um die \nWirkungsweisen von Plattformen und sozialen Me-\ndien, ihren Einfluss auf \u00f6ffentliche Diskurse, aber \nauch weitere Themen von hoher gesellschaftlicher \nRelevanz zu untersuchen, sollte sichergestellt wer -\nden, dass unabh\u00e4ngigen Forschenden der Zugriff auf \nwissenschaftsrelevante Daten von Plattformen nicht 53mit dem pauschalen Verweis auf Betriebs- oder Ge-\nsch\u00e4ftsgeheimnisse verweigert werden kann. F\u00fcr den \nZugang m\u00fcssen sichere, datenschutzkonforme sowie \nforschungsethisch integre Wege gefunden werden. \nNetzwerkdurchsetzungsgesetz und Digital Services \nAct enthalten bereits Reglungen zum Datenzugang, \ndie aber in ihrem Anwendungsbereich sehr begrenzt \nsind; auch der Data Act sieht vergleichbare Regelun-\ngen vor.\n>> Empfehlung Kommunikation 4: Ber\u00fccksichtigung von \nSicherheit, Datenschutz und Geheimhaltungsinteres-\nsen: Anforderungen an Offenlegungen und Daten-\nzugang m\u00fcssen kontextsensitiv spezifiziert werden, \nwobei Anforderungen an Sicherheit und Schutz vor \nMissbrauch, Datenschutz sowie dem Schutz von in-\ntellektuellem Eigentum und Gesch\u00e4ftsgeheimnissen \nangemessen Rechnung zu tragen ist. Je nach Kontext \nmuss zwischen unterschiedlich klar definierten Zeit-\npunkten der Pr\u00fcfung und Graden der Offenlegung \nunterschieden werden.\n>> Empfehlung Kommunikation 5: Personalisierte Wer -\nbung, Profiling und Microtargeting: Personalisierte \nWerbung ist das zentrale Gesch\u00e4ftsmodell sozialer \nMedien und Plattformen. Die Praktiken des Profi-\nlings und Microtargetings k\u00f6nnen jedoch problema-\ntische Auswirkungen auf \u00f6ffentliche Kommunikation \nund Meinungsbildung entfalten, insbesondere im \nKontext politischer Werbung. Um solche negativen \nAuswirkungen durch effektive Regelungen zu ver -\nhindern, ist es zun\u00e4chst notwendig, die Bedingungen \nf\u00fcr eine Erforschung und \u00dcberpr\u00fcfung der Zusam-\nmenh\u00e4nge zwischen Gesch\u00e4ftsmodellen und Prakti-\nken algorithmischer Kuratierung in ihren Wirkungs-\nweisen und Effekten zu schaffen. Der auf Ebene der \nEurop\u00e4ischen Union diskutierte Vorschlag f\u00fcr eine \nVerordnung \u00fcber die Transparenz und das Targeting 54politischer Werbung adressiert diesen Bedarf. Hierbei \nzeigen sich allerdings auch die Herausforderungen, \nRegeln so zuzuschneiden, dass sie einerseits wirksam \nsind, andererseits aber die Freiheit der politischen \nKommunikation nicht \u00fcberm\u00e4\u00dfig beschr\u00e4nken.\n>> Empfehlung Kommunikation 6: Bessere Regulierung \nvon Onlinemarketing und Datenhandel: Ursache vie-\nler informationeller und kommunikativer Dysfunkti-\nonen haben ihre Ursache im Onlinemarketing, wel-\nches das grundlegende Gesch\u00e4ftsmodell vieler sozialer \nMedien und Plattformen ist und auf der Sammlung, \nAnalyse und dem Verkauf vielf\u00e4ltiger Daten \u00fcber die \nPersonen, die diese Angebote nutzen, beruht. Das \nProblem ist hierbei nicht die Werbefinanzierung per \nse, sondern der invasive Umgang mit diesen Daten. \nHier gilt es einerseits, die Auswirkungen dieses Ge-\nsch\u00e4ftsmodells auf \u00f6ffentliche Diskurse besser zu er -\nforschen. Andererseits bedarf es besserer gesetzlicher \nRegelungen, um sowohl Individuen in ihren Grund-\nrechten online effektiver zu sch\u00fctzen als auch negati-\nve systemische Effekte auf den \u00f6ffentlichen Diskurs \nzu minimieren. In diese Richtung gehende Vorschl\u00e4-\nge hat der Deutsche Ethikrat 2017 unter dem Stich-\nwort \u201eDatensouver\u00e4nit\u00e4t\u201c in seiner Stellungnahme zu \nBig Data und Gesundheit vorgestellt. Europ\u00e4ische Re-\ngelungen wie der Digital Markets Act adressieren das \nProblem der Datenmacht gro\u00dfer Plattformen, aber \u2013 \nschon aus Gr\u00fcnden der Regelungskompetenz \u2013 nicht \nmit Blick auf die Folgen f\u00fcr den \u00f6ffentlichen Diskurs.\n>> Empfehlung Kommunikation 7: Machtbeschr\u00e4nkung \nund Kontrolle: Unternehmen, die im Bereich der \n\u00f6ffentlichen Vorstellung von Daten bzw. Tatsachen \nde facto monopolartige Machtm\u00f6glichkeiten haben, \nsind durch rechtliche Vorgaben und entsprechende \nKontrolle auf Pluralismus, Minderheiten- und Dis-\nkriminierungsschutz zu verpflichten. Ein Teil der 55Mitglieder des Deutschen Ethikrates ist der Auf-\nfassung, dass medienrechtliche Regelungen zur Si-\ncherung von Pluralit\u00e4t, Neutralit\u00e4t und Objektivit\u00e4t \ngenerell auf Nachrichtenfunktionen von sozialen \nMedien und Plattformen ausgedehnt werden sollten, \nsofern sie denen traditioneller Medien \u00e4hneln.\n>> Empfehlung Kommunikation 8: Erweiterung der Nut-\nzerautonomie: Plattformen und soziale Medien soll-\nten ihre Inhalte auch ohne eine personalisierte Kura-\ntierung verf\u00fcgbar machen. Dar\u00fcber hinaus sollten sie \nf\u00fcr die Kriterien, nach denen Inhalte auf Plattformen \nund in sozialen Medien algorithmisch ausgew\u00e4hlt \nund priorit\u00e4r pr\u00e4sentiert werden, weitere Wahlm\u00f6g-\nlichkeiten anbieten. Dazu sollte auch die M\u00f6glich-\nkeit geh\u00f6ren, bewusst Gegenpositionen angezeigt zu \nbekommen, die den bisher ge\u00e4u\u00dferten eigenen Pr\u00e4-\nferenzen zuwiderlaufen. Solche Wahlm\u00f6glichkeiten \nsollten gut sichtbar und leicht zug\u00e4nglich sein.\n>> Empfehlung Kommunikation 9: F\u00f6rderung kritischer \nRezeption von Inhalten: Zur Eind\u00e4mmung unreflek-\ntierter Verbreitung fragw\u00fcrdiger Inhalte sollten di-\nverse Hinweisfunktionen entwickelt und eingesetzt \nwerden, die eine kritische Auseinandersetzung mit \nMaterial f\u00f6rdern, bevor man sich daf\u00fcr entscheidet, \nes zu teilen oder \u00f6ffentlich darauf zu reagieren. Dies \nk\u00f6nnten etwa R\u00fcckfragen sein, ob Texte gelesen und \nVideos geschaut wurden, bevor man sie teilt, oder \nAngaben zur Seriosit\u00e4t von Quellen.\n>> Empfehlung Kommunikation 10: Alternative Informa-\ntions- und Kommunikationsinfrastruktur: Zu erw\u00e4-\ngen w\u00e4re, den privaten Social-Media-Angeboten im \neurop\u00e4ischen Rahmen eine digitale Kommunikati-\nonsinfrastruktur in \u00f6ffentlich-rechtlicher Verant-\nwortung zur Seite zu stellen, deren Betrieb sich nicht \nam Unternehmensinteresse eines m\u00f6glichst langen \nVerweilens von Menschen auf der Plattform oder an 56anderen kommerziellen Interessen orientiert. Damit \nsollte nicht etwa der \u00f6ffentlich-rechtliche Rundfunk \n(TV und Radio) auf eine weitere digitale Plattform \nausgedehnt, sondern eine digitale Infrastruktur be-\nreitgestellt werden, die eine Alternative zu den kom-\nmerzbetriebenen, stark oligopolartigen Angeboten \nbietet. Um eine hinreichende Staatsferne zu garantie-\nren, k\u00f6nnte auch an eine Tr\u00e4gerschaft in Gestalt einer \n\u00f6ffentlichen Stiftung gedacht werden.\n\u00d6ffentliche Verwaltung\n104) F\u00fcr viele Menschen und Organisationen stellt die \u00f6ffent-\nliche Verwaltung, so etwa im Finanz-, Steuer -, Melde- \nund Sozialwesen und in der Straff\u00e4lligen- und Jugendge-\nrichtshilfe, die unmittelbar erfahrbare Staatsgewalt dar. \nFunktionierende, transparente, als legitim anerkannte \nund b\u00fcrgernahe Verwaltung ist f\u00fcr ein funktionierendes \nGemeinwesen und die Akzeptanz von Demokratie und \nStaat wesentlich. Mit Digitalisierungsstrategien in diesem \nBereich verbinden sich Hoffnungen auf eine Rationalisie-\nrung und Beschleunigung staatlichen Verwaltungshan-\ndelns, eine effektivere und koh\u00e4rentere Datennutzung \nsowie eine Ausweitung der Einbeziehung wissenschaftli-\nchen und b\u00fcrgerschaftlichen Sachverstandes. Dem steht \ndie dystopische Schreckensvision einer sogenannten \u201eAl-\ngokratie\u201c gegen\u00fcber, in der autonome Softwaresysteme \ndie staatliche Herrschaft \u00fcber Menschen aus\u00fcben.\n105) Vielfach und zunehmend werden in der \u00f6ffentlichen \nVerwaltung automatisierte Entscheidungssysteme \n(Automated/Algorithmic Decision Making Systems, \nADM-Systeme) eingesetzt, etwa zur Bewertung von Ar -\nbeitsmarktchancen, bei der Pr\u00fcfung und Vergabe von \nSozialleistungen oder f\u00fcr Vorhersagen im Bereich der \nPolizeiarbeit. Von besonderem Interesse ist hier, inwie-\nweit der Einsatz von KI-Systemen menschliche Hand-\nlungsf\u00e4higkeiten und Autorschaft beeinflusst. Angesichts 57der h\u00e4ufig beobachteten Tendenz, sich maschinellen \nEmpfehlungen vorbehaltslos anzuschlie\u00dfen (Automa-\ntion Bias), kann bereits die Nutzung von Software zur \nEntscheidungsunterst\u00fctzung in der Verwaltung weitrei-\nchende Wirkung entfalten.\n106) Andere Fragen betreffen vor allem Aspekte von Gerech-\ntigkeit, beispielsweise wenn es darum geht, ob und in \nwelchem Umfang die verwendeten Systeme Diagnosen \nund Prognosen tats\u00e4chlich verbessern, ob die Genauig-\nkeit f\u00fcr verschiedene Anwendungskontexte oder Perso-\nnengruppen gleich ist oder ob es systematische Verzer -\nrungen oder Diskriminierungen gibt (Algorithmic Bias). \nEbenso k\u00f6nnen datenbasierte Systeme jedoch historische \nUngerechtigkeiten oder menschliche Vorurteile aufde-\ncken und sie damit f\u00fcr Gegenma\u00dfnahmen zug\u00e4nglich \nmachen.\n107) Eine grunds\u00e4tzliche Grenze f\u00fcr die Anwendung von au-\ntomatisierten Entscheidungssystemen liegt in nicht eli-\nminierbaren normativen Ziel- oder Regelkonflikten im \ndeutschen, deontologisch verfassten Rechtssystem, in \ndem die Folgenabw\u00e4gung nie allein das Rechtm\u00e4\u00dfige be-\nstimmt, sondern unbedingte Anspr\u00fcche auf Schutz der \nPerson zu wahren sind und der Algorithmisierung ethi-\nscher und rechtlicher Entscheidungsprozesse Grenzen \nsetzen.\n108) Das Sozialwesen ist ein Bereich der Verwaltung, in dem \nEntscheidungen mit weitreichenden Folgen f\u00fcr die Be-\ntroffenen fallen, etwa \u00fcber die Gew\u00e4hrung von Hilfen, bei \nMa\u00dfnahmen im Kontext einer Kindeswohlgef\u00e4hrdung \noder bei der Absch\u00e4tzung von Gef\u00e4hrdungspotenzialen \nvon Straff\u00e4lligen in der Bew\u00e4hrungshilfe. Algorithmen-\nbasierte Entscheidungshilfen kommen hier zunehmend \nzum Einsatz und k\u00f6nnen professionelle Handlungs-\nkompetenz erweitern, wenn sie Fachkr\u00e4ften helfen, ihre \nsonst oft intuitiven Einsch\u00e4tzungen auf eine solidere Da-\ntengrundlage zu stellen, bei Bedarf zu korrigieren und 58Entscheidungen so evidenzbasiert zu standardisieren. \nDies ist besonders wichtig bei der Absch\u00e4tzung von Ge-\nf\u00e4hrdungspotenzialen, beispielsweise bei Verdacht auf \nKindeswohlgef\u00e4hrdung oder in der Bew\u00e4hrungshilfe.\n109) Menschliche Autorschaft kann unter Zuhilfenahme \nsachdienlicher Ergebnisse von KI-Algorithmen aller -\ndings auch vermindert werden. Auf der professionellen \nSeite kann dies beispielsweise dann der Fall sein, wenn \nes zu einer ungepr\u00fcften \u00dcbernahme algorithmisch vor -\ngeschlagener Ergebnisse kommt (Automation Bias). \nAuch f\u00fcr die von den Entscheidungen betroffenen Per -\nsonen sind negative Effekte m\u00f6glich, etwa wenn ihnen \naufgrund von durch Verzerrungen gepr\u00e4gten algorith-\nmisch unterst\u00fctzten Entscheidungen Handlungs- oder \nEntwicklungsm\u00f6glichkeiten ungerechtfertigterweise ge-\nnommen werden.\n110) Gerade bei der Erfassung von Hilfebedarfen birgt der \nEinsatz algorithmischer Systeme zudem das Risiko der \nEntkopplung aus einer dialogischen Beziehungsarbeit, \ndie entscheidend f\u00fcr die Erfahrung von Selbstwirksam-\nkeit Betroffener sein kann. Wird diese pers\u00f6nliche Ebe-\nne bei der Ermittlung des individuellen Hilfebedarfs \nim Zuge einer algorithmenbasierten Informatisierung \ndes Sozialwesens vernachl\u00e4ssigt, k\u00f6nnen positive Effek-\nte selbst materieller Hilfeleistungen schnell verpuffen \nund damit kaum nachhaltig wirken. Das \u00f6sterreichische \nArbeitsmarktchancen-Assistenzsystem beispielsweise, \ndas f\u00fcr Arbeitssuchende Erfolgsprognosen f\u00fcr eine Wie-\ndereingliederung in den Arbeitsmarkt berechnet, ist f\u00fcr \nseine Ausrichtung an den Werten, Normen und Zielen \neiner restriktiven Fiskalpolitik kritisiert worden, die den \nZielen eines personenorientierten Hilfesystems, welches \nindividuelle Hilfebedarfe betroffener Personen fokussie-\nren muss, diametral zuwiderl\u00e4uft.\n111) Ein anderer Bereich, in dem algorithmenbasierte Risi-\nkoanalysen zunehmend zum Einsatz kommen, ist die 59Kriminalit\u00e4tsbek\u00e4mpfung. Im Predictive Policing un-\nterst\u00fctzen entsprechende Anwendungen pr\u00e4ventive \nPolizeiarbeit mittels Prognosen k\u00fcnftiger Straftaten, \nstraff\u00e4lliger Personen und Tatorte, um Verbrechen zu \nverhindern. Vor allem personenbezogene Verfahren \nwerden in diesem Zusammenhang kontrovers diskutiert. \nEinerseits geht damit die Hoffnung auf eine bessere po-\nlizeiliche Arbeit und einen besseren Schutz m\u00f6glicher \nOpfer einher. Andererseits k\u00f6nnen Fehler und Verzer -\nrungen in algorithmenbasierter Verbrechensbek\u00e4mp-\nfung mit besonders folgenschweren Konsequenzen f\u00fcr \nungerechtfertigt klassifizierte Personen verbunden sein \nund zudem in der Software systembedingt besondere \nBreitenwirkung entfalten.\n112) Ein weiteres Problem ist der Schutz der Privatsph\u00e4re im \nKontext von Predictive Policing. Die f\u00fcr die Polizeiarbeit \nherangezogenen Daten sind in aller Regel besonders sen-\nsibel. Insbesondere bei sogenannten Chatkontrollen zur \nPr\u00e4vention und Bek\u00e4mpfung des sexuellen Missbrauchs \nvon Kindern, zu denen die Europ\u00e4ische Kommission im \nMai 2022 einen Verordnungsvorschlag vorgelegt hat, \nwird hinterfragt, ob eine anlasslose und fl\u00e4chendecken-\nde \u00dcberwachung privater Kommunikation gerechtfertigt \nwerden kann oder einen unverh\u00e4ltnism\u00e4\u00dfig intensiven \nEingriff in die Grundrechte darstellt.\n113) Nicht zuletzt wird die Sorge ge\u00e4u\u00dfert, dass mit algorith-\nmengesteuerter Polizeiarbeit das Risiko der Verfestigung \neines mechanischen Menschenbildes einhergehen k\u00f6n-\nne, welches den einzelnen Menschen verobjektiviere, sei-\nne Individualit\u00e4t auf eine datengetriebene Klassifikation \nreduziere, jedoch die gesamtgesellschaftlichen Ursachen \nvon Kriminalit\u00e4t unber\u00fccksichtigt lasse.\n114) In der Zusammenschau f\u00fchren automatisierte Entschei-\ndungsverfahren in der \u00f6ffentlichen Verwaltung zu neuen \nM\u00f6glichkeiten und Herausforderungen, die erheblich \nweiter reichende ethische und demokratietheoretische 60Fragen aufwerfen, etwa in Bezug auf Nachvollziehbar -\nkeit, Erkl\u00e4rbarkeit und Vertrauensw\u00fcrdigkeit im Ver -\nwaltungshandeln, aber auch in Bezug auf Sorgen um \nDiskriminierung und Technokratie, in der menschliche \nKommunikation und Abw\u00e4gung hinter anonymen Da-\ntenmengen und standardisierten Bedienoberfl\u00e4chen \nverschwinden.\n115) Insofern der R\u00fcckgriff auf gro\u00dfe Datenmengen und ihre \nzielgerichtete Auswertung bessere Entscheidungsgrund-\nlagen schaffen, kann der Einsatz algorithmischer Systeme \nzu diesem Zweck menschliche Autorschaft unterst\u00fctzen \nund ist in ethischer Hinsicht grunds\u00e4tzlich zu begr\u00fc\u00dfen. \nEine unkritische \u00dcbernahme von Systemempfehlungen \ndroht menschliche Autorschaft allerdings zu vermin-\ndern, bis im ung\u00fcnstigen Fall nur noch ein automatisier -\ntes Geschehen verbleibt, in dem technische Systeme f\u00fcr \nBetroffene weitreichende, teils existenzielle Festlegungen \ntreffen und systemimmanente Fehler oder Verzerrungen \nm\u00f6glicherweise nicht mehr erkannt werden.\n116) Beim Einsatz von KI in der \u00f6ffentlichen Verwaltung \nmuss daher kontextbezogen im Detail eingesch\u00e4tzt und \nabgewogen werden, welche Auswirkungen eine entspre-\nchende Ma\u00dfnahme auf die Autorschaft unterschied-\nlichster Beteiligter und Betroffener hat, welche Konflikte \nauftreten und wie mit ihnen umgegangen werden kann \noder soll. Hierzu legt der Deutsche Ethikrat neun Emp-\nfehlungen vor:\n>> Empfehlung Verwaltung 1: Die mit automatisierten \nEntscheidungshilfen (ADM-Systeme) einhergehende \nverst\u00e4rkte Standardisierung und pauschale Katego-\nrisierung von Einzelf\u00e4llen m\u00fcssen umso st\u00e4rker hin-\nterfragt und um spezifisch einzelfallbezogene Erw\u00e4-\ngungen erg\u00e4nzt werden, je intensiver die betroffene \nEntscheidung individuelle Rechtspositionen ber\u00fchrt.61>> Empfehlung Verwaltung 2: Es m\u00fcssen geeignete tech-\nnische und organisatorische Instrumente zur Vor -\nkehrung gegen die manifeste Gefahr eines Automati-\non Bias bereitgestellt werden, die es den Fachkr\u00e4ften \nerschweren, selbst bei einer Letztentscheidungskom-\npetenz der algorithmischen Entscheidungsempfeh-\nlung unbesehen zu folgen. Es ist zu pr\u00fcfen, ob eine \nUmkehrung der Begr\u00fcndungspflicht (nicht eine Ab-\nweichung, sondern ein Befolgen ist zu rechtfertigen) \nhier eine geeignete Vorkehrung sein kann.\n>> Empfehlung Verwaltung 3: Aufgrund ihrer Grund-\nrechtsbindung sind an staatliche Einrichtungen bei \nder Entwicklung und Nutzung algorithmischer Sys-\nteme hohe Anforderungen in Bezug auf Transparenz \nund Nachvollziehbarkeit zu stellen, um den Schutz \nvor Diskriminierung zu gew\u00e4hrleisten sowie Begr\u00fcn-\ndungspflichten erf\u00fcllen zu k\u00f6nnen.\n>> Empfehlung Verwaltung 4: F\u00fcr Softwaresysteme in der \n\u00f6ffentlichen Verwaltung m\u00fcssen Qualit\u00e4tskriterien \nverbindlich und transparent festgelegt werden (z. B. \nin Bezug auf Genauigkeit, Fehlervermeidung und \nUnverzerrtheit). Ebenso bedarf es einer Dokumenta-\ntion der jeweils eingesetzten Methoden. Diesbez\u00fcg-\nlich sollten auch aktuelle Beschaffungspraktiken, in \nderen Verlauf staatliche Beh\u00f6rden Softwarel\u00f6sungen \nkaufen, einer kritischen Pr\u00fcfung unterzogen werden.\n>> Empfehlung Verwaltung 5: \u00dcberall dort, wo algorith-\nmische Systeme Einsatz in der \u00f6ffentlichen Verwal-\ntung finden, gilt es, Sorge zu tragen, dass die Personen, \ndie diese Systeme anwenden, \u00fcber die erforderlichen \nKompetenzen im Umgang damit verf\u00fcgen. Dazu ge-\nh\u00f6rt neben der Kenntnis der Verwendungsweisen \nauch das Wissen um die Limitationen und m\u00f6glichen \nVerzerrungen, um Systeme angemessen einsetzen zu \nk\u00f6nnen.62>> Empfehlung Verwaltung 6: Die Einsichts- und Ein-\nspruchsrechte Betroffener m\u00fcssen auch beim Einsatz \nalgorithmischer Systeme effektiv gew\u00e4hrleistet wer -\nden. Dazu bedarf es gegebenenfalls weiterer wirksa-\nmer Verfahren und Institutionen.\n>> Empfehlung Verwaltung 7: In \u00d6ffentlichkeit, Politik \nund Verwaltung sollte eine Sensibilisierung gegen-\n\u00fcber m\u00f6glichen Gefahren von Automatisierungssys-\ntemen, wie etwa Verletzungen der Privatsph\u00e4re oder \nFormen systematisierter Diskriminierung, erfolgen. \nDazu geh\u00f6rt eine \u00f6ffentliche Debatte dar\u00fcber, ob es in \nbestimmten Kontexten \u00fcberhaupt einer technischen \nL\u00f6sung bedarf.\n>> Empfehlung Verwaltung 8: Im Bereich des Sozialwe-\nsens ist sicherzustellen, dass ADM-Systeme elemen-\ntare fachliche Standards von sozialprofessionellen \nInteraktionen (z. B. gemeinsame Sozialdiagnose oder \nHilfeplanung als Teil  therapeutischer bzw. unterst\u00fct-\nzender Hilfeleistung) nicht unterlaufen oder verdr\u00e4n-\ngen. Dies beinhaltet insbesondere Ma\u00dfnahmen, die \nVergr\u00f6berungen individueller Fallkonstellationen \nund -prognosen durch die ADM-induzierte grobklas-\nsifizierende Einteilung von Fall- und/oder Leistungs-\nberechtigtengruppen verhindern. Dabei ist Sorge zu \ntragen, dass die Feststellung individueller Hilfebe-\ndarfe nicht erschwert wird und es zu keiner schlei-\nchenden Aush\u00f6hlung der sozialrechtlich gebotenen \nIdentifizierung individueller Hilfebedarfe zugunsten \neinseitiger externer Interessen an Gefahrenminimie-\nrung oder Kostenersparnis kommt.\n>> Empfehlung Verwaltung 9: Die Arbeit von Gefahren-\nabwehrbeh\u00f6rden einschlie\u00dflich der Polizei betrifft \nbesonders grundrechtssensible Bereiche. Dies wirkt \nsich auf die Reichweite eines zul\u00e4ssigen Einsatzes von \nalgorithmischen Systemen in der pr\u00e4diktiven Polizei-\narbeit aus. Risiken wie Verletzungen der Privatsph\u00e4re 63oder potenziell unzul\u00e4ssige Diskriminierungen der \nvon dem Einsatz betroffenen Personen m\u00fcssen mit \nChancen auf erhebliche Verbesserungen der staatli-\nchen Gefahrenabwehr sorgf\u00e4ltig abgewogen und in \nein angemessenes Verh\u00e4ltnis gebracht werden. Hier -\nf\u00fcr erforderliche gesellschaftliche Aushandlungs-\nprozesse sollten umfangreich gef\u00fchrt werden. Dabei \nist der diffizilen Bestimmung des Verh\u00e4ltnisses von \nFreiheit und Sicherheit Rechnung zu tragen. Jegliche \nGesetzes\u00fcbertretung zu verhindern, w\u00e4re mit rechts-\nstaatlichen Mitteln nicht m\u00f6glich.\nTEIL III: QUERSCHNITTSTHEMEN UND \u00dcBERGREIFENDE \nEMPFEHLUNGEN\nZusammenfassung der bisherigen Analyse\n117) Der Begriff der K\u00fcnstlichen Intelligenz hat in der \u00f6ffent-\nlichen Debatte zunehmend an Aufmerksamkeit gewon-\nnen und wird teils mit \u00fcberzogenen Hoffnungen, teils \naber auch mit fehlgeleiteten Bef\u00fcrchtungen verkn\u00fcpft. \nDer Deutsche Ethikrat geht von einem normativ grund-\nlegenden Unterschied zwischen Mensch und Maschine \naus. Softwaresysteme verf\u00fcgen weder \u00fcber theoretische \nnoch \u00fcber praktische Vernunft. Sie handeln oder ent-\nscheiden nicht selbst und k\u00f6nnen keine Verantwortung \n\u00fcbernehmen. Sie sind kein personales Gegen\u00fcber, auch \ndann nicht, wenn sie Anteilnahme, Kooperationsbereit-\nschaft oder Einsichtsf\u00e4higkeit simulieren.\n118) Menschliche Vernunft ist immer zugleich eingebunden \nin die konkrete soziale Mit- und Umwelt. Nur so ist zu \nerkl\u00e4ren, dass sie handlungswirksam wird. Vern\u00fcnf-\ntig handelt der einzelne Mensch als Teil einer sozialen \nMitwelt und einer kulturellen Umgebung. Schon des-\nhalb kann den in dieser Stellungnahme besprochenen 64Softwaresystemen weder theoretische noch praktische \nVernunft zugeschrieben werden.\n119) Menschen entwickeln digitale Technik und nutzen sie als \nMittel zu menschlichen Zwecken. Jedoch wirken diese \nTechnologien zur\u00fcck auf menschliche Handlungsm\u00f6g-\nlichkeiten. Sie k\u00f6nnen einerseits neue Optionen er\u00f6ff-\nnen, aber andererseits auch Anpassungen erforderlich \nmachen, die nicht w\u00fcnschenswert sind. Auch wenn \nMaschinen also nicht selbst handeln, so ver\u00e4ndern sie \ndie Handlungsf\u00e4higkeit von Menschen tiefgreifend und \nk\u00f6nnen Handlungsm\u00f6glichkeiten erheblich erweitern \noder vermindern.\n120) Ziel der Delegation menschlicher T\u00e4tigkeiten an Ma-\nschinen sollte prinzipiell die Erweiterung menschlicher \nHandlungsf\u00e4higkeit und Autorschaft sein. Ihre Vermin-\nderung sowie eine Diffusion oder Evasion von Verant-\nwortung gilt es hingegen zu verhindern. Daf\u00fcr muss die \n\u00dcbertragung menschlicher T\u00e4tigkeiten auf KI-Systeme \ngegen\u00fcber den Betroffenen hinreichend transparent er -\nfolgen, sodass wichtige Entscheidungselemente, -para-\nmeter oder -bedingungen nachvollziehbar bleiben.\n121) Um \u00fcber Wert und Nutzen der Delegation vormals \nmenschlichen Handelns an Maschinen ethisch zu befin-\nden, bedarf es daher immer eines kontextspezifischen \nBlicks, der die Perspektiven unterschiedlicher Beteiligter \nund Betroffener ebenso ber\u00fccksichtigt wie die langfristi-\ngen Auswirkungen solcher \u00dcbertragungen. Die Heraus-\nforderungen stecken also wie so oft im Detail, genauer: in \nden Details der Technik, der Einsatzkontexte sowie der \ninstitutionellen und soziotechnischen Umgebung.\n122) Um diesen kontextspezifischen Blick zu erm\u00f6glichen, \nhat sich der Deutsche Ethikrat in dieser Stellungnahme \nexemplarisch mit Anwendungen in der Medizin, der \nschulischen Bildung, der \u00f6ffentlichen Kommunikation \nsowie der Verwaltung besch\u00e4ftigt. Es wurden bewusst \nSektoren ausgew\u00e4hlt, in denen die Durchdringung 65durch KI-basierte Technologien sehr unterschiedlich \nausf\u00e4llt und sich jeweils unterschiedliche Ausma\u00dfe des \nErsetzens vormals menschlicher Handlungen durch \nKI veranschaulichen lassen. In allen vier Sektoren sind \nEinsatzszenarien durch teils erhebliche Beziehungs- und \nMachtasymmetrien gekennzeichnet, was einen verant-\nwortungsvollen Einsatz von KI und die Ber\u00fccksichtigung \nder Interessen und des Wohls insbesondere vulnerabler \nPersonengruppen umso wichtiger macht. Diese Unter -\nschiedlichkeit der Art und Weise des KI-Einsatzes sowie \ndes Ausma\u00dfes der Delegation an Maschinen in den Blick \nzu nehmen, erlaubt es nuancierte ethische Betrachtungen \nanzustellen.\nEntfaltung von Querschnittsthemen und Empfehlungen\n123) Die Darstellung der soziotechnischen Entwicklungen \nund deren ethische Analyse in den vier Anwendungs-\nbereichen zeigen, dass es eine Reihe von Querschnitts-\nthemen und -herausforderungen gibt, die sich durch alle \nvier Bereiche ziehen, wenn auch teils in unterschiedlicher \nWeise und Auspr\u00e4gung. Um im Hinblick auf die Erwei-\nterung menschlicher Handlungsf\u00e4higkeit und Autor -\nschaft zuk\u00fcnftig einen guten gesellschaftlichen Umgang \nmit KI zu gew\u00e4hrleisten, m\u00fcssen solche Querschnittsfra-\ngen nicht nur innerhalb einzelner Bereiche angegangen \nwerden, sondern dar\u00fcber hinaus auch in vernetzten, be-\nreichs\u00fcbergreifenden Ans\u00e4tzen.\n124) Solches gleicherma\u00dfen horizontale wie vertikale gestal-\ntende Denken stellt eine Herausforderung insbesondere \nf\u00fcr die Politikgestaltung und etwaige zuk\u00fcnftige Regu-\nlierung dar. Die Darstellung der Querschnittsthemen in \ndieser Stellungnahme, die f\u00fcr jedes Thema in einer Emp-\nfehlung m\u00fcnden, soll daher als Anregung f\u00fcr eine breite-\nre Debatte dienen, wie f\u00fcr zuk\u00fcnftige Politik- und Tech-\nnikgestaltung gleichzeitig und im Zusammenspiel mit 66sektoralen Aspekten immer auch \u00fcbergreifende Fragen \nin den Blick genommen werden k\u00f6nnen und m\u00fcssen.\n125) Im ersten Querschnittsthema geht es noch einmal um das \nin dieser Stellungnahme zentrale Konzept der Erwei-\nterung und Verminderung menschlicher Handlungs-\nm\u00f6glichkeiten. Zwar besteht eine sektor\u00fcbergreifende \nGemeinsamkeit hinsichtlich der angestrebten Erweite-\nrung menschlicher Handlungspotenziale darin, dass die \nkomplette Ersetzung menschlicher Akteure durch KI-\nSysteme sich \u00fcberall dort verbietet, wo die konkrete zwi-\nschenmenschliche Begegnung eine notwendige Voraus-\nsetzung f\u00fcr die Erreichung der jeweiligen Handlungsziele \ndarstellt. Dar\u00fcber hinaus besteht jedoch die Notwendig-\nkeit, die Unterschiede beim KI-Einsatz in den einzelnen \nHandlungsbereichen sorgf\u00e4ltig zu beachten.\n>> Empfehlung Querschnittsthema 1: Da die Vor- und \nNachteile von KI-Anwendungen f\u00fcr verschiedene \nPersonengruppen sowie die Gefahr des Verlustes be-\nstimmter Kompetenzen bei den Personen, die solche \nSysteme anwenden, erheblich variieren, bedarf es so-\nwohl einer differenzierten Planung des KI-Einsatzes \nin unterschiedlichen Handlungsfeldern, welche die \njeweiligen Zielsetzungen und Verantwortlichkeiten \npr\u00e4zise benennt, als auch einer zeitnahen Evaluation \nder tats\u00e4chlichen Folgen eines solchen Einsatzes, um \ndie Systeme besser an die spezifischen Handlungskon-\ntexte anzupassen und sie fortlaufend zu verbessern.\n126) Das zweite Querschnittsthema behandelt Wissenser -\nzeugung durch KI und den Umgang mit KI-gest\u00fctzten \nVoraussagen. Zentral ist dabei die Pr\u00e4misse, dass Kor -\nrelationen und Datenmuster nicht mit Erkl\u00e4rungen und \nBegr\u00fcndungen von Ursachen von Ereignissen gleichzu-\nsetzen sind, sondern auch qualitativ evaluiert und nor -\nmativ beurteilt werden m\u00fcssen. Bei probabilistischen 67Methoden bleiben immer Restunsicherheiten, \u00fcber de-\nren Akzeptabilit\u00e4t zu entscheiden ist. Ethisch positiv zu \nwerten ist, dass durch KI-Einsatz in allen vier hier be-\ntrachteten Anwendungsbereichen erhebliche funktionale \nVerbesserungen erreicht wurden und weiterhin erwart-\nbar sind. Es wird jedoch eine grunds\u00e4tzlich normativ \nproblematische Schwelle \u00fcberschritten, wenn funktiona-\nle Verbesserungen (eventuell sogar unbemerkt) in eine \nErsetzung moralischer Kompetenz und damit verbunde-\nner Verantwortung hin\u00fcbergleiten.\n>> Empfehlung Querschnittsthema 2: Der Einsatz KI-\ngest\u00fctzter digitaler Techniken ist im Sinne der Ent-\nscheidungsunterst\u00fctzung und nicht der Entschei-\ndungsersetzung zu gestalten, um Diffusion von \nVerantwortung zu verhindern. Er darf nicht zulasten \neffektiver Kontrolloptionen gehen. Den von algo-\nrithmisch gest\u00fctzten Entscheidungen Betroffenen ist \ninsbesondere in Bereichen mit hoher Eingriffstiefe \ndie M\u00f6glichkeit des Zugangs zu den Entscheidungs-\ngrundlagen zu gew\u00e4hren. Das setzt voraus, dass am \nEnde der technischen Prozeduren entscheidungsbe-\nfugte Personen sichtbar bleiben, die in der Lage und \nverpflichtet sind, Verantwortung zu \u00fcbernehmen.\n127) Das dritte Querschnittsthema betrachtet die Gef\u00e4hr -\ndung des Individuums durch statistische Stratifizierung. \nGrundlage vieler KI-Anwendungen sind Korrelationen, \ndie bei der Analyse gro\u00dfer Datenmengen entdeckt wer -\nden und anhand derer man Einzelpersonen Kohorten \nmit bestimmten Merkmalskombinationen zuordnen \nkann. Die Bildung solcher Kohorten und die auf ihrer \nBasis durch Algorithmen produzierten Voraussagen \nk\u00f6nnen die Qualit\u00e4t und Effektivit\u00e4t einer Anwendung \ninsgesamt verbessern. Sie k\u00f6nnen aber auch Probleme \nf\u00fcr Individuen bedeuten, welche von solchen kollektiven 68Schl\u00fcssen betroffen sind \u2013 insbesondere dann, wenn die \nstatistisch getroffene Diagnose oder Prognose in ihrem \nFall nicht zutrifft.\n>> Empfehlung Querschnittsthema 3: Neben einer Ana-\nlyse der konkreten und naheliegenden Probleme \ndatenbasierter Software, beispielsweise in Bezug auf \nden Schutz der Privatsph\u00e4re oder die Verhinderung \nvon Diskriminierung, gilt es, auch die langfristigen \nAuswirkungen dieser statistischen Pr\u00e4konfiguration \nvon Individuen sowie deren R\u00fcckwirkung \u2013 im Sin-\nne einer Erweiterung oder Verminderung der Hand-\nlungsm\u00f6glichkeiten \u2013 auf Individuen wie Kollektive \nf\u00fcr alle Sektoren sorgf\u00e4ltig zu beleuchten. Dar\u00fcber \nhinaus gilt, dass Einzelfallbeurteilungen grunds\u00e4tz-\nlich wichtig bleiben. KI-basierte Beurteilungen und \nVorhersagen k\u00f6nnen unter g\u00fcnstigen Bedingungen \nein Hilfsmittel sein, aber kein geeignetes Instrument \nder definitiven Lagebeurteilung und Entscheidung. \nPragmatische und heuristische Faktoren wie die Pr\u00fc-\nfung der Koh\u00e4renz mit anderen Evidenzquellen oder \nErfolgseinsch\u00e4tzungen spielen eine nicht zu vernach-\nl\u00e4ssigende Rolle.\n128) Im vierten Querschnittsthema geht es um die Auswirkun-\ngen von KI auf menschliche Kompetenzen und Fertig-\nkeiten. Deren Erwerb und Erhalt kann durch die Dele-\ngation menschlicher T\u00e4tigkeiten an Maschinen gef\u00e4hrdet \nwerden. Weil die Nutzung von KI-Anwendungen (wie \nauch bei anderen Technologien) dazu f\u00fchren kann, dass \nmenschliche F\u00e4higkeiten nachlassen bzw. ganz verk\u00fcm-\nmern, k\u00f6nnen Abh\u00e4ngigkeiten von diesen Technologien \nentstehen. Handelt es sich dabei um gesellschaftlich be-\nsonders bedeutsame oder kritische Einsatzbereiche, ist \nein Verlust von menschlichen Kompetenzen und Fertig-\nkeiten ein ernstzunehmendes Risiko.69>> Empfehlung Querschnittsthema 4: Ob und inwiefern \nbeim Einsatz von KI-Anwendungen Verluste mensch-\nlicher Kompetenz auftreten, die als unerw\u00fcnscht ein-\ngestuft werden, muss sorgf\u00e4ltig beobachtet werden. \nBei der Entwicklung und dem Einsatz neuer Techno-\nlogien sind solch unerw\u00fcnschte Kompetenzverluste \ndurch eine sinnvolle Gestaltung des Zusammenspiels \nvon Mensch und Technik, durch angemessene insti-\ntutionelle und organisatorische Rahmenbedingungen \nsowie durch gezielte Gegenma\u00dfnahmen wie etwa spe-\nzifische Trainingsprogramme zu minimieren bzw. zu \nkompensieren. Kompetenzverluste k\u00f6nnen sowohl \nindividueller als auch kollektiver Natur sein. So gilt \nes zu verhindern, dass die Delegation von Aufgaben \nan Technologien dazu f\u00fchrt, dass Gesellschaften \n\u00fcberm\u00e4\u00dfig anf\u00e4llig werden, wenn diese Technologi-\nen (zeitweise) ausfallen. Jenseits dieser systemischen \nAspekte m\u00fcssen negative Auswirkungen solcher De-\nlegation auf die individuelle Autonomie oder Selbst-\nwahrnehmung mitigiert werden.\n129) Das f\u00fcnfte Querschnittsthema befasst sich mit dem Schutz \nvon Privatsph\u00e4re und Autonomie versus Gefahren durch \n\u00dcberwachung und Chilling-Effekte. Die im Rahmen \nvieler KI-Anwendungen notwendige Erfassung gro\u00dfer \nMengen an personenbezogenen Daten sowie die M\u00f6g-\nlichkeit, auf ihrer Basis sensible Prognosen zu erstellen, \nbeeintr\u00e4chtigen nicht nur die Privatsph\u00e4re der Personen, \nvon denen diese Daten stammen, sondern machen sie \nauch vulnerabel gegen\u00fcber m\u00f6glichen Benachteiligun-\ngen oder Manipulation, welche aus der Verarbeitung der \nDaten resultieren k\u00f6nnen. Chilling-Effekte beschreiben \nin diesem Kontext R\u00fcckwirkungen auf das Verhalten \nvon Menschen, die Sorge haben, dass ihr Verhalten be-\nobachtet, aufgezeichnet oder ausgewertet wird.70>> Empfehlung Querschnittsthema 5: Die beschriebenen \nPh\u00e4nomene sollten in ihrer Entstehung, Auspr\u00e4gung \nund Entwicklung umfassend empirisch untersucht \nwerden. Um sowohl dem Problem der \u00dcberwachung \nsowie den parallelen Gefahren durch etwaige Chil-\nling-Effekte Rechnung zu tragen, m\u00fcssen angemesse-\nne und effektive rechtliche und technische (z. B. Pri-\nvacy by Design) Vorkehrungen getroffen werden, die \ndem \u00fcberm\u00e4\u00dfigen Tracking von Onlineverhalten und \ndem Handel mit personenbeziehbaren Daten Einhalt \ngebieten. Die Interessen der Datensubjekte m\u00fcssen \nhierbei im Mittelpunkt stehen. Insbesondere ist da-\nbei auf besonders vulnerable Gruppen zu achten, da \nviele der Einsatzkontexte zudem von asymmetrischen \nMachtverh\u00e4ltnissen gekennzeichnet sind. Es muss \nSorge getragen werden, dass die Erweiterung der \nHandlungsm\u00f6glichkeiten einiger nicht zulasten der \nVerminderung der Handlungsm\u00f6glichkeiten anderer, \ninsbesondere benachteiligter Gruppen stattfindet.\n130) Das sechste Querschnittsthema greift Konzepte von Daten-\nsouver\u00e4nit\u00e4t und gemeinwohlorientierter Datennutzung \nauf, die der Deutsche Ethikrat bereits 2017 in seiner Stel-\nlungnahme zu Big Data und Gesundheit entwickelt hat. \nDabei geht es um die Suche nach L\u00f6sungen, wie im Kon-\ntext von KI-Anwendungen Daten sinnvoll f\u00fcr verschie-\ndene wichtige Zwecke genutzt werden k\u00f6nnen, ohne zu-\ngleich den Schutz der Privatsph\u00e4re von Datensubjekten \nunzul\u00e4ssig zu beeintr\u00e4chtigen. Hier stellt sich die Frage, \nob das derzeitige Datenschutzrecht bzw. die herrschen-\nde Datenschutzpraxis diesen beiden Zielen gerecht wird. \nW\u00e4hrend in manchen Handlungsfeldern berechtigte Sor -\ngen vor unbemerkten und weitreichenden Verletzungen \nvon Privatsph\u00e4re und informationeller Selbstbestim-\nmung herrschen, werden in anderen Kontexten durch \nstrenge Auslegungen von Datenschutzregeln wichtige 71soziale G\u00fcter, etwa mit Blick auf Patientenversorgung \nund wissenschaftlichen Erkenntnisgewinn, aber auch die \nkommunale Daseinsvorsorge nicht oder nur sehr schwer \nerreicht.\n>> Empfehlung Querschnittsthema 6: Mit Blick auf KI-\nAnwendungen m\u00fcssen neue Wege gefunden wer -\nden, um innerhalb der jeweiligen Kontexte und be-\nz\u00fcglich der jeweils spezifischen Herausforderungen \nund Nutzenpotenziale die gemeinwohlorientierte \nDaten(sekund\u00e4r)nutzung zu vereinfachen bzw. zu \nerm\u00f6glichen und damit die Handlungsoptionen auf \ndiesem Gebiet zu erweitern. Zugleich ist es essenzi-\nell, einen Bewusstseinswandel sowohl in der \u00d6ffent-\nlichkeit als auch bei den praktisch t\u00e4tigen Personen, \ndie Datennutzung gestalten, herbeizuf\u00fchren \u2013 weg \nvon einer vornehmlich individualistisch gepr\u00e4gten \nund damit verk\u00fcrzten Perspektive hin zu einer Hal-\ntung, die auch systematische und gemeinwohlbasierte \n\u00dcberlegungen mit einbezieht und in einen Ausgleich \nbringt. Eine solche Haltung ist auch f\u00fcr die zuk\u00fcnftige \nPolitikgestaltung und Regulierung deutlich st\u00e4rker als \nbisher zugrunde zu legen. Nur so kann es gelingen, \nneben den Risiken, die sich aus breiterer KI-Anwen-\ndung ohne Zweifel ergeben, zugleich die wichtigen \nChancen einer verantwortlichen Nutzung nicht aus \ndem Blick zu verlieren.\n131) Das siebte Querschnittsthema betrachtet kritische Infra-\nstrukturen, Abh\u00e4ngigkeiten und Resilienz. Im Zuge der \nDigitalisierung werden Infrastrukturen wie beispiels-\nweise Stromnetze zunehmend digital \u00fcberwacht und \n\u00fcber das Internet gesteuert. Gleichzeitig werden digitale \nTechnologien selbst zu Infrastrukturen. Am Vorhan-\ndensein und Funktionieren von Infrastrukturen richten \nMenschen ihr Handeln aus, und im Zuge dieser sozialen 72Aneignung entstehen Abh\u00e4ngigkeiten, die menschliche \nAutonomie gef\u00e4hrden k\u00f6nnen. Wenn KI-gest\u00fctzte Sys-\nteme zusehends in die Steuerung von Infrastrukturen in-\ntegriert werden, kommt hinzu, dass solche Systeme nicht \nvollst\u00e4ndig transparent und nachvollziehbar sind, und \ndurch die fortw\u00e4hrende Komplexit\u00e4tssteigerung von Inf-\nrastruktursystemen und ihrer Steuerung steigt die gesell-\nschaftliche und institutionelle Vulnerabilit\u00e4t weiter an.\n>> Empfehlung Querschnittsthema 7: Um die Autorschaft \nmenschlicher Akteure und deren Handlungsm\u00f6glich-\nkeiten zu erweitern, m\u00fcssen die Resilienz soziotechni-\nscher Infrastrukturen gest\u00e4rkt und die Abh\u00e4ngigkeit \nvon individuellen Akteuren und Systemen minimiert \nwerden. Dies umfasst zun\u00e4chst die Notwendigkeit, \ndie infrastrukturelle Bedeutung digitaler Technolo-\ngien anzuerkennen und infolgedessen dem Schutz \nund der Resilienz kritischer digitaler Infrastrukturen \nmehr Aufmerksamkeit zuteilwerden zu lassen, auch \nim politischen Handeln. In allen Sektoren gilt es, \neinseitige Abh\u00e4ngigkeiten zu vermeiden, welche im \nKrisenfalle verletzlich und angreifbar machen. F\u00fcr \nNutzerinnen und Nutzer erfordert eine Verringerung \nder Abh\u00e4ngigkeit die M\u00f6glichkeit, zwischen Alterna-\ntiven zu w\u00e4hlen, ohne gro\u00dfe Teile der Funktionalit\u00e4t \neinzub\u00fc\u00dfen. Dies umfasst die Notwendigkeit von In-\nteroperabilit\u00e4t, um einfach zwischen Systemen wech-\nseln zu k\u00f6nnen. Hierf\u00fcr ist auch der Auf- und Ausbau \nalternativer Infrastrukturen von besonderer Bedeu-\ntung. Im Kontext der \u00f6ffentlichen Meinungsbildung \nerscheint die Etablierung unabh\u00e4ngiger, \u00f6ffentlicher \ndigital-kommunikativer Plattformen dringend gebo-\nten. Aber auch in anderen Sektoren wie der Verwal-\ntung, der Bildung oder der Medizin vermindert eine \nzu gro\u00dfe Abh\u00e4ngigkeit von wenigen Systemen oder 73Akteuren potenziell die individuelle wie kollektive \nHandlungsf\u00e4higkeit.\n132) Das achte Querschnittsthema dreht sich um Pfadabh\u00e4n-\ngigkeiten, Zweitverwertung und Missbrauchsgefahren. \nPfadabh\u00e4ngigkeiten entstehen, wenn Entscheidungen, \ndie zu Beginn einer bestimmten Entwicklung getroffen \nwurden, noch lange nachwirken und teils schwer wieder \naufzuheben sind, auch wenn sich der Kontext der Nut-\nzung m\u00f6glicherweise ge\u00e4ndert hat. Sind Technologien \neinmal eingef\u00fchrt, d\u00fcrfte zudem eine Tendenz auszu-\nmachen sein, deren M\u00f6glichkeiten voll auszusch\u00f6pfen \n\u2013 auch \u00fcber das urspr\u00fcngliche Anwendungsfeld hinaus. \nSolche Zweitverwertungen sind nicht prinzipiell proble-\nmatisch, doch sobald eine Technologie etabliert ist, kann \nes schwer sein, weitere, auch missbr\u00e4uchliche Nutzungs-\nszenarien auszuschlie\u00dfen. Gerade digitale Technologien \nund insbesondere Grundlagentechnologien wie das ma-\nschinelle Lernen er\u00f6ffnen oft sehr mannigfaltige Nut-\nzungsm\u00f6glichkeiten, in denen die Frage der Abgrenzung \nvon Ge- und Missbrauch zunehmend schwieriger wird.\n>> Empfehlung Querschnittsthema 8: Bei Technologi-\nen mit gro\u00dfen Auswirkungen oder hohem Verbrei-\ntungsgrad und vor allem dort, wo sich eine Nutzung \nvon Technologien kaum oder gar nicht vermeiden \nl\u00e4sst, m\u00fcssen bereits zu Beginn der Entwicklungs-\nplanung m\u00f6gliche Langzeitfolgen wie Pfadabh\u00e4ngig-\nkeiten im Allgemeinen sowie Dual-Use-Potenziale \nim Speziellen regelhaft und explizit mitgedacht und \nantizipiert werden. Dies gilt in besonderem Ma\u00dfe in \nder Anwendungsplanung. Dabei sind neben direkten, \nsektorspezifischen Schadenspotenzialen auch etwai-\nge \u2013 nat\u00fcrlich deutlich schwieriger fass- und antizi-\npierbare \u2013 sektor\u00fcbergreifende Effekte zu bedenken. \nHohe Standards f\u00fcr die Sicherheit und den Schutz der 74Privatsph\u00e4re (Security by Design, Privacy by Design) \nk\u00f6nnen ebenfalls dazu beitragen, sp\u00e4tere missbr\u00e4uch-\nliche Anwendungen einzuhegen bzw. m\u00f6glichst zu \nverhindern. Bei besonders invasiven Technologien \nbeispielsweise in der \u00f6ffentlichen Verwaltung, die \nB\u00fcrgerinnen und B\u00fcrger gegebenenfalls verpflich-\ntend nutzen m\u00fcssen, sind besonders hohe Standards \neinzuhalten. Um dies sicherzustellen und \u00fcberpr\u00fcfen \nzu k\u00f6nnen, sind gegebenenfalls Open-Source-Ans\u00e4t-\nze angezeigt.\n133) Im neunten Querschnittsthema geht es um Bias und Dis-\nkriminierung. Datenbasierte KI-Systeme lernen auf Basis \nvorhandener Daten. Resultierende Prognosen und Emp-\nfehlungen schreiben somit die Vergangenheit in die Zu-\nkunft fort, wodurch Stereotypen, aber auch bestehende \ngesellschaftliche Ungleichheiten und Ungerechtigkeiten \ndurch den Einbau in scheinbar neutrale Technologien re-\nproduziert und sogar verst\u00e4rkt werden k\u00f6nnen. Oft liegt \nbei der Entwicklung von KI-Systemen keine unmittel-\nbare Diskriminierungsabsicht vor, sondern diskriminie-\nrende Effekte entstehen aus gesellschaftlichen Realit\u00e4ten \noder Stereotypen in Kombination mit technisch-me-\nthodischen Entscheidungen. Es ist allerdings zumindest \ndenkbar, dass auch explizite Diskriminierungsabsichten \nin komplexen Systemen versteckt werden k\u00f6nnten.\n>> Empfehlung Querschnittsthema 9: Zum Schutz vor \nDiskriminierung in Anbetracht der zuvor dargelegten \nHerausforderungen bedarf es angemessener Aufsicht \nund Kontrolle von KI-Systemen. Besonders in sensib-\nlen Bereichen erfordert dies den Auf- oder Ausbau \ngut ausgestatteter Institutionen. Hier gilt: je gr\u00f6\u00dfer \ndie Eingriffstiefe und je unumg\u00e4nglicher die Systeme, \ndesto h\u00f6her die Anforderungen an Diskriminierungs-\nminimierung. Auch bereits bei der Entwicklung von 75Technologien gilt es, Diskriminierung zu minimieren \nbzw. Fairness, Transparenz und Nachvollziehbarkeit \nherzustellen. Dies sollte sowohl durch Anreize \u2013 etwa \nForschungsf\u00f6rderung \u2013 als auch durch entsprechen-\nde gesetzliche Anforderungen bef\u00f6rdert werden, \netwa hinsichtlich der Offenlegung, welche Ma\u00df-\nnahmen zur Diskriminierungsminimierung bei der \nSoftwareentwicklung ergriffen wurden. Allerdings \nhaben technische wie regulatorische Ma\u00dfnahmen \nzur Minimierung von Diskriminierung ihre Gren-\nzen, unter anderem weil unterschiedliche Fairness-\nziele technisch nicht gleichzeitig erf\u00fcllt werden k\u00f6n-\nnen. Es m\u00fcssen also zugleich ethische und politische \nEntscheidungen getroffen werden, welche Kriterien \nf\u00fcr Gerechtigkeit in welchem Kontext zum Tragen \nkommen sollen. Diese Entscheidungen d\u00fcrfen nicht \nden Personen, die Software entwickeln, und anderen \ndirekt Beteiligten \u00fcberlassen werden. Stattdessen be-\ndarf es der Entwicklung geeigneter Verfahren und In-\nstitutionen, um diese Kriterien kontextspezifisch und \ndemokratisch, gegebenenfalls immer wieder neu aus-\nzuhandeln. Je nach Anwendungskontext und Sensibi-\nlit\u00e4t des einzusetzenden Systems kann die Beteiligung \nder \u00d6ffentlichkeit erforderlich sein. Dabei sollte der \nSchutz der jeweils bed\u00fcrftigsten bzw. von Entschei-\ndungen besonders betroffenen Gruppen besonders \nber\u00fccksichtigt werden.\n134) Das zehnte Querschnittsthema greift Fragen von Transpa-\nrenz und Nachvollziehbarkeit sowie von Kontrolle und \nVerantwortung auf. Die h\u00e4ufige Undurchschaubarkeit \nvon KI-Systemen hat verschiedene Ursachen, die vom \nSchutz geistigen Eigentums \u00fcber die Komplexit\u00e4t und \nNichtnachvollziehbarkeit der Verfahren bis hin zur man-\ngelnden Durchsichtigkeit von Entscheidungsstrukturen, \nin die der Einsatz algorithmischer Systeme eingebettet 76ist, reichen. Transparenz und Nachvollziehbarkeit al-\ngorithmischer Systeme stehen zwar in Zusammenhang \nmit deren Kontrolle und der Verantwortung f\u00fcr ihren \nEinsatz, sind f\u00fcr beides aber weder zwingend notwendig \nnoch hinreichend.\n>> Empfehlung Querschnittsthema 10: Es bedarf der Ent-\nwicklung ausgewogener aufgaben-, adressaten- und \nkontextspezifischer Standards f\u00fcr Transparenz, Er -\nkl\u00e4rbarkeit und Nachvollziehbarkeit und ihrer Be-\ndeutung f\u00fcr Kontrolle und Verantwortung sowie f\u00fcr \nderen Umsetzung durch verbindliche technische und \norganisatorische Vorgaben. Dabei muss den Anfor -\nderungen an Sicherheit und Schutz vor Missbrauch, \nDatenschutz sowie dem Schutz von intellektuellem \nEigentum und Gesch\u00e4ftsgeheimnissen in angemesse-\nner Weise Rechnung getragen werden. Je nach Kon-\ntext sind hier unterschiedliche Zeitpunkte (ex ante, \nex post, Realtime) sowie unterschiedliche Verfahren \nund Grade der Offenlegung zu spezifizieren.\n135) Zusammenfassend geht es in dieser Stellungnahme \num die Auswirkungen einer zunehmenden Delegation \nmenschlicher T\u00e4tigkeiten an digitale Technologien, ins-\nbesondere KI-basierte Softwaresysteme. In zahlreichen \nBeispielen aus den Bereichen der Medizin, der schuli-\nschen Bildung, der \u00f6ffentlichen Kommunikation und \nMeinungsbildung sowie der \u00f6ffentlichen Verwaltung \nzeigt sich, dass dieses Delegieren sowohl mit Erweiterun-\ngen als auch mit Verminderungen menschlicher Hand-\nlungsm\u00f6glichkeiten einhergeht und sich dadurch so-\nwohl f\u00f6rderlich als auch hinderlich auf die Realisierung \nmenschlicher Autorschaft auswirken kann.\n136) Ziel und Richtschnur ethischer Bewertung muss da-\nbei immer die St\u00e4rkung menschlicher Autorschaft sein. \nDabei ist zu ber\u00fccksichtigen, dass die Erweiterung von 77Handlungsm\u00f6glichkeiten f\u00fcr eine Personengruppe mit \nderen Verminderung f\u00fcr andere einhergehen kann. \nDiesen unterschiedlichen Effekten ist Rechnung zu tra-\ngen, insbesondere im Hinblick auf den Schutz und die \nVerbesserung der Lebensbedingungen vulnerabler oder \nbenachteiligter Gruppen. Letztlich zeigt sich, dass die \nnormativen Anforderungen an die Gestaltung und den \nEinsatz solcher Technologien, zum Beispiel in Bezug auf \nAnforderungen hinsichtlich Transparenz und Nachvoll-\nziehbarkeit, den Schutz der Privatsph\u00e4re sowie die Ver -\nhinderung von Diskriminierung, zwar in allen Bereichen \nund f\u00fcr alle Betroffenen von hoher Bedeutung sind, sie \njedoch sektor -, kontext- und adressatenspezifisch kon-\nkretisiert werden m\u00fcssen, um angemessen zu sein und \nwirksam werden zu k\u00f6nnen.781\t \t EINLEITUNG\nDigitale Technologien im Allgemeinen und Systeme sogenann-\nter K\u00fcnstlicher Intelligenz (KI) im Speziellen durchdringen \nzunehmend unsere Lebenswelt. Dies reicht von der suchma-\nschinenbasierten Sortierung von Ergebnissen und Empfehlun-\ngen f\u00fcr Filme und Musik \u00fcber Navigationssoftware bis hin zur \nNutzung von Risikoprofilen und Software zur Entscheidungs-\nunterst\u00fctzung im Sozial- und Justizwesen oder bei der Polizei. \nWettervorhersagen und Klimamodellierung, Krebsdiagnostik \nin der Medizin und psychotherapeutische Erstversorgung mit-\ntels Chatbots, intelligente Tutorsysteme zum Vokabellernen \noder Emotionserkennung in Videoanalysen \u2013 datenbasierte \nAnalysen, Prognosen und das Delegieren von Entscheidungen \nan Softwaresysteme verdeutlichen, dass digitale Technologien \nund insbesondere auch KI in nahezu alle Bereiche des \u00f6ffent-\nlichen und privaten Lebens Einzug gehalten haben. Auch die \nDebatten um den im November 2022 vorgestellten Chatbot \nChatGPT und andere Anwendungen sogenannter generativer \nKI, welche automatisiert neue Inhalte in einer Qualit\u00e4t pro-\nduzieren, bei der oftmals nicht mehr erkennbar ist, dass diese \nrein maschinell erstellt wurden, zeigen, dass eine grundlegen-\nde Auseinandersetzung mit den Wechselwirkungen zwischen \nMensch und Maschine erforderlich ist.\nF\u00fcr die ethische Bewertung solcher Technologien und ihres \nEinsatzes in verschiedenen Bereichen ist es n\u00f6tig, nicht nur die \nTechnologien selbst zu verstehen. Es gilt dar\u00fcber hinaus, auch \nihre Wechselwirkungen mit den Personen, die sie verwenden \noder von ihrer Anwendung betroffen sind, zu analysieren und \nden Blick auf gesellschaftliche Effekte zu richten.\nHierbei stellen sich Fragen wie zum Beispiel: Welche \u2013 po-\nsitiven wie auch negativen \u2013 Auswirkungen hat das Delegie-\nren von T\u00e4tigkeiten, die zuvor Menschen vorbehalten waren, \nan Maschinen? Werden menschliche Autorschaft und die \nBedingungen f\u00fcr verantwortliches Handeln erweitert oder 79vermindert? Wie wirkt sich der Einbezug digitaler Technologi-\nen und KI auf die Handlungsoptionen verschiedener Beteilig-\nter und Betroffener aus? Wessen M\u00f6glichkeiten werden durch \nden Einsatz erweitert, wessen M\u00f6glichkeiten vermindert? Die-\nsen Fragen geht der Deutsche Ethikrat in der vorliegenden \nStellungnahme nach und schreibt damit Themen fort, die er \nbereits in seinen Stellungnahmen \u201eBig Data und Gesundheit \n\u2013 Datensouver\u00e4nit\u00e4t als informationelle Freiheitsgestaltung\u201c \n(2017) sowie \u201eRobotik f\u00fcr gute Pflege\u201c (2019) angeschnitten \nhat. Mit den aktuellen Ausf\u00fchrungen reagiert der Ethikrat \nzudem auf eine im Oktober 2020 vom Pr\u00e4sidenten des Deut-\nschen Bundestages formulierte Bitte, die Arbeit der Enquete-\nKommissionen \u201eK\u00fcnstliche Intelligenz \u2013 Gesellschaftliche \nVerantwortung und wirtschaftliche, soziale und \u00f6kologische \nPotenziale\u201c und \u201eBerufliche Bildung in der digitalen Arbeits-\nwelt\u201c um eine grundlegende Einbettung des politischen und \ngesellschaftlichen Diskurses zum Thema KI im Rahmen einer \nmultidisziplin\u00e4ren Stellungnahme zu den ethischen Fragen \ndes Verh\u00e4ltnisses von Mensch und Maschine zu erg\u00e4nzen.\nGrundfrage und Ma\u00dfstab der hier vorgelegten ethischen \nBewertung technologischer Entwicklungen und ihres Einsat-\nzes in verschiedenen Kontexten ist, ob durch die Delegation \nvon T\u00e4tigkeiten an Maschinen \u2013 bis hin zu einer m\u00f6glichen Er -\nsetzung \u2013 die Bedingungen f\u00fcr verantwortliches Handeln und \nmenschliche Autorschaft erweitert oder vermindert werden.\nDie Stellungnahme gliedert sich in drei Teile:\nTeil I dieser Stellungnahme liefert die technischen, theo-\nretischen und methodischen Grundlagen. In Kapitel 2 wer -\nden in knapper Form die technologischen Grundlagen der in \ndieser Stellungnahme behandelten Entwicklungen dargelegt. \nHierzu wird zun\u00e4chst ein kurzer historischer \u00dcberblick \u00fcber \ndie Entstehungsgeschichte des Forschungsfeldes der KI seit \nden 1950er-Jahren nachgezeichnet. Gerade in Anbetracht \nder oft schillernden \u00f6ffentlichen Debatte rund um sogenann-\nte starke oder generelle KI werden zentrale Begriffe und De-\nbatten eingeordnet. Im n\u00e4chsten Schritt werden bedeutsame 80Entwicklungen der letzten Jahre skizziert, in denen die Stei-\ngerung der Rechenleistung, die Miniaturisierung in der Com-\nputertechnik und die zunehmende Vernetzung von Ger\u00e4ten \ndazu gef\u00fchrt haben, dass unsere Lebenswelt immer st\u00e4rker \nvon digitalen Technologien durchdrungen ist, was wiederum \neine wachsende Datenflut und immer neue Einsatzm\u00f6glich-\nkeiten f\u00fcr algorithmische Systeme nach sich zieht. Das Kapitel \nendet mit einem knappen Verweis auf existierende ethische \nLeitlinien verschiedenster Akteursgruppen und den aktuellen \nRechtsrahmen.\nKapitel 3 widmet sich den zentralen Begriffen und philoso-\nphischen Grundlagen dieser Stellungnahme. Hierf\u00fcr werden \nzun\u00e4chst zentrale Begriffe beleuchtet, die f\u00fcr das Verst\u00e4ndnis \nsowohl der Unterschiede als auch der Wechselwirkungen zwi-\nschen Menschen und Maschinen bedeutsam sind. Dies um-\nfasst zun\u00e4chst den Begriff der Intelligenz selbst und sein Ver -\nh\u00e4ltnis zu Begriffen wie praktischer und theoretischer Vernunft. \nVon zentraler Bedeutung sind ferner die Begriffe der Handlung \nund der Verantwortung. Softwaresysteme werden zunehmend \nzur Unterst\u00fctzung von Handlungen und Entscheidungen he-\nrangezogen oder diese werden gar vollst\u00e4ndig an sie delegiert. \nIn der Folge stellt sich auch die Frage, welche Auswirkungen \ndiese Prozesse f\u00fcr Verantwortungs\u00fcbernahme und -zuschrei-\nbung haben. Das Kapitel endet mit einem Blick auf die anth-\nropologischen Aspekte des Mensch-Maschine-Verh\u00e4ltnisses \nund beleuchtet zentrale Differenzen zwischen Menschen und \nMaschinen.\nIn Kapitel 4 hingegen geht es weniger um die Unterschie-\nde zwischen Menschen und Maschinen als vielmehr um deren \nvielf\u00e4ltige und mehrstufige Relationen und Wechselwirkun-\ngen. Nach einer kurzen Einordnung des im Deutschen Ethikrat \nverwendeten Verst\u00e4ndnisses dieser Wechselwirkungen und \ndessen Einordnung zwischen den Polen des Technikdetermi-\nnismus und des Sozialkonstruktivismus wird mit den Begrif-\nfen des Erweiterns, Verminderns und Ersetzens eine Matrix zur \nBeschreibung und Bewertung von Technikentwicklung und 81Technikeinsatz entwickelt. Diese Matrix bildet die Grundlage \nf\u00fcr die Analysen im folgenden zweiten Teil der Stellungnahme, \nin dem die Auswirkungen des Delegierens von menschlichen \nHandlungssegmenten bis hin zu einem vollst\u00e4ndigen Ersetzen \nvon Menschen durch Maschinen in verschiedenen Kontexten \nund Sektoren auf menschliche Autorschaft und die Bedingun-\ngen f\u00fcr verantwortliches Handeln untersucht werden.\nTeil II dieser Stellungnahme werden die zuvor angestellten \n\u00dcberlegungen anhand von Analysen in vier ausgew\u00e4hlten An-\nwendungsfeldern exemplarisch konkretisiert: dem Bereich der \nMedizin (Kapitel 5), dem Bereich der schulischen Bildung (Ka -\npitel 6), dem Bereich der \u00f6ffentlichen Kommunikation und Mei-\nnungsbildung (Kapitel 7) sowie dem Bereich der \u00f6ffentlichen \nVerwaltung (Kapitel 8). In allen vier Sektoren werden daten-\nbasierte Softwaresysteme eingesetzt. Allerdings unterscheiden \nsich die Tiefe und Breite der Durchdringung deutlich.\nW\u00e4hrend die f\u00fcr den Bereich der \u00f6ffentlichen Kommuni-\nkation und Meinungsbildung so zentralen sozialen Medien \nals Paradebeispiel einer sehr umfassenden Delegation vormals \nmenschlicher T\u00e4tigkeiten an Algorithmen dienen k\u00f6nnen, bei-\nspielsweise hinsichtlich der Kuratierung und Moderation von \nInhalten, zeigt sich in Deutschland im Bereich der schulischen \nBildung noch eine vergleichsweise geringe Nutzung digitaler \nTechnologien im Allgemeinen und KI-basierter Systeme im \nSpeziellen. Eine vollst\u00e4ndige Ersetzung menschlicher T\u00e4tig-\nkeiten durch Maschinen scheint hier in weiter Ferne. In der \nMedizin stellt sich dies wiederum anders dar, werden doch \nzunehmend nicht nur einzelne Bearbeitungsschritte, sondern \nganze Funktionen an KI-basierte Softwaresysteme delegiert. \nDies reicht von der Nutzung von Softwaresystemen zur Mus-\ntererkennung in der Krebsdiagnostik bis zu Chatbots als ma-\nschinellen Ersatz von therapeutischem Fachpersonal. Auch in \nder \u00f6ffentlichen Verwaltung hat KI in Gestalt datenbasierter \nSoftware zur Erstellung von Risikoprofilen und zur Entschei-\ndungsunterst\u00fctzung Einzug gehalten.82Zentrale Einsicht dieser Analysen ist, dass Entscheidungen \n\u00fcber die beste Form und das richtige Ausma\u00df der Delegation \nvon T\u00e4tigkeiten und Funktionen an Softwaresysteme und KI \nnur kontext-, anwendungs- und personenbezogen spezifiziert \nwerden k\u00f6nnen. Entsprechend enden alle vier Kapitel mit sek-\ntorspezifischen Empfehlungen. Als Richtschnur der Bewer -\ntung gilt hierbei jedoch immer,\n>> ob die Delegation zu einer Erweiterung der Handlungs-\nm\u00f6glichkeiten, insbesondere zu einer Erh\u00f6hung der M\u00f6g-\nlichkeiten f\u00fcr verantwortliches Handeln und Autorschaft, \nder verschiedenen Beteiligten und Betroffenen f\u00fchrt oder\n>> ob es m\u00f6glicherweise zu einer Verminderung von Hand-\nlungsm\u00f6glichkeiten sowie negativen Auswirkungen auf \nM\u00f6glichkeiten der Autorschaft und Verantwortungs\u00fcber -\nnahme kommt.\nDer Vergleich der Analysen in den vier ausgew\u00e4hlten Anwen-\ndungsfeldern erlaubt es, auch \u00fcbergreifende Themen auszu-\nmachen, da es wiederkehrende Aspekte gibt, wenngleich sich \ndiese in den vier Anwendungsfeldern sehr unterschiedlich dar -\nstellen. Diese Querschnittsthemen und mit ihnen verbundene \n\u00fcbergreifende Empfehlungen werden in Teil III der Stellung-\nnahme dargelegt. Dieser letzte Teil beginnt zun\u00e4chst mit einer \nRekapitulation der anthropologischen und ethischen Orien-\ntierung, welche dieser Stellungnahme zugrunde liegt, und fasst \ndie Einsichten aus den vorausgehenden Kapiteln im zweiten \nTeil der Stellungnahme knapp zusammen. Sodann werden die \nzehn identifizierten Querschnittsthemen dargelegt, die jeweils \nauch \u00fcbergreifende Empfehlungen enthalten.\nDas erste Querschnittsthema besch\u00e4ftigt sich mit der f\u00fcr \ndiese Stellungnahme leitenden Grundfrage, welche Auswir -\nkungen das Delegieren von Handlungen an Maschinen auf die \nErweiterung oder Verminderung von Handlungsm\u00f6glichkei-\nten von Menschen hat. Hierbei wird deutlich, dass Vor- und \nNachteile einer solchen Delegation sich nicht nur zwischen 83verschiedenen Sektoren, sondern auch f\u00fcr verschiedene Per -\nsonengruppen stark unterscheiden. In der Folge muss ein ver -\nantwortungsvoller Einsatz von KI diese Nuancen reflektieren \nund ber\u00fccksichtigen.\nQuerschnittsthema 2 adressiert die Auswirkungen von KI \nauf Wissenserzeugung und den Umgang mit KI-gest\u00fctzten \nVoraussagen. Um eine Diffusion von Verantwortung zu ver -\nhindern, ist es hierbei von zentraler Bedeutung, KI-gest\u00fctzte \ndigitale Technologien zur Entscheidungsunterst\u00fctzung und \nnicht zur Entscheidungsersetzung einzusetzen.\nQuerschnittsthema 3 untersucht, inwieweit das Individu-\num durch statistische Stratifizierung gef\u00e4hrdet ist vor dem \nHintergrund, dass es bei datenbasierten Analysen und Prog-\nnosen oftmals als Teil eines statistischen Kollektivs behandelt \nund die Ber\u00fccksichtigung individueller Aspekte dadurch ver -\nnachl\u00e4ssigt wird.\nQuerschnittsthema 4 besch\u00e4ftigt sich mit der Frage, welche \nAuswirkungen das Delegieren von Handlungen an Maschinen \nauf menschliche Kompetenzen und Fertigkeiten hat und wie \nder Gefahr von Kompetenzverlusten und Deskilling entgegen-\ngewirkt werden kann.\nDie Querschnittsthemen 5 und 6 adressieren Chancen und \nRisiken im Umgang mit Daten. W\u00e4hrend es auf der einen Seite \ndarum geht, die Privatsph\u00e4re und Autonomie vor \u00fcberm\u00e4\u00dfi-\ngen Eingriffen und Gefahren durch \u00dcberwachung zu sch\u00fct-\nzen, geht es andererseits auch darum, Daten bestm\u00f6glich f\u00fcr \nsinnvolle und gemeinwohlorientierte Nutzung zug\u00e4nglich zu \nmachen. Hier wird diskutiert, wie Datenschutzrecht und -pra-\nxis gestaltet sein m\u00fcssten, um beiden Zielen optimal Rechnung \nzu tragen.\nIn Querschnittsthema 7 wird die Bedeutung digitaler Tech-\nnologien als kritische Infrastrukturen betont und die Frage ge-\nstellt, wie diese sicher und resilient gestaltet und Abh\u00e4ngigkei-\nten reduziert werden k\u00f6nnen.\nQuerschnittsthema 8 kn\u00fcpft an diese Fragen an und be-\nleuchtet Pfadabh\u00e4ngigkeiten in der Technologieentwicklung 84einerseits und Fragen von Missbrauch und Dual Use \nandererseits.\nDie letzten beiden Querschnittsthemen spannen den Bo-\ngen noch einmal zur\u00fcck zu zwei Problemfeldern, die sich in \nnahezu allen in Kapitel 2 erw\u00e4hnten ethischen Leitlinien zu KI \nwiederfinden. Dies betrifft einerseits Fragen rund um systema-\ntische Verzerrungen und Diskriminierung (Querschnittsthe-\nma 9) sowie andererseits Fragen zur Transparenz, Nachvoll-\nziehbarkeit, Kontrolle und Verantwortung im Kontext von \nKI-Systemen (Querschnittsthema 10). Hier gilt es, kontext-, \nsektoren- und adressatenspezifische Standards f\u00fcr Transpa-\nrenz, Nachvollziehbarkeit und die Vermeidung von Verzer -\nrungen zu entwickeln, deren Umsetzung durch verbindliche \ntechnische und organisationale Vorgaben gesichert wird.TEIL\tI:\t\t\nTECHNISCHE \tUND\t\nPHILOSOPHISCHE \t\nGRUNDLEGUNGEN862\t \t ZENTRALE \tENTWICKLUNGEN \t\nUND\tTECHNISCHE \tGRUNDLAGEN \t\nK\u00dcNSTLICHER \tINTELLIGENZ\n2.1\t\t Historischer\tKontext\nDie Erfindung von Maschinen und deren Einfluss auf die \nmenschliche Lebenswelt haben sich stets vor dem Hintergrund \nspezifischer gesellschaftlicher Wahrnehmungen und Erwar -\ntungen vollzogen, die R\u00fcckwirkungen auf die jeweilige tech-\nnologische Dynamik und die von ihr ausgehenden Entwick-\nlungen von einfachen Ger\u00e4ten \u00fcber komplexe Maschinen bis \nzu gro\u00dftechnischen Anlagen gehabt haben. Dies gilt auch f\u00fcr \ndie Entstehung immer leistungsf\u00e4higerer Softwaresysteme, die \nin vielf\u00e4ltigen intelligent und autonom anmutenden Formen \nmit Menschen interagieren k\u00f6nnen. Auch die dadurch aus-\ngel\u00f6sten philosophischen und ethischen Fragen und Heraus-\nforderungen, mit denen sich der Deutsche Ethikrat in dieser \nStellungnahme befasst, sind in diesem historischen Kontext zu \nbetrachten.\nDie Idee von Maschinen, deren F\u00e4higkeiten denen des \nMenschen \u00e4hneln oder diese sogar \u00fcbertreffen, l\u00e4sst sich \nJahrtausende vor Erfindung der ersten Softwaresysteme zu-\nr\u00fcckverfolgen. Schon in den Geschichten der antiken grie-\nchischen Mythologie erschufen G\u00f6tter und Helden animierte \nMaschinen wie die mechanischen Dienerinnen des Schmiede-\ngottes Hephaistos oder die animierten Statuen des Erfinders \nD\u00e4dalus.1\nMit der Erfindung der ersten Computer, also von Maschi-\nnen, deren besondere St\u00e4rke darin bestand, Programme mit \nkomplexen rechnerischen und logischen Operationen schnell \nund effizient auszuf\u00fchren, r\u00fcckte die Existenz maschineller \nIntelligenz erstmals in greifbare N\u00e4he. Konzeptionell schon \n1\t Mayor\t2018.87Mitte des 19. Jahrhunderts in den Entw\u00fcrfen einer \u201eanaly-\ntischen Maschine\u201c von Charles Babbage und Ada Lovelace \nerdacht, wurden die ersten programmierbaren digitalen Re-\nchenmaschinen erst hundert Jahre sp\u00e4ter gebaut, beginnend \nmit der von Konrad Zuse und Helmut Schreyer 1941 in Berlin \nvorgestellten \u201eZuse Z3\u201c. Parallel dazu entwickelte Alan Turing \ndas formelle mathematische Modell eines universell program-\nmierbaren Computers, sp\u00e4ter Turingmaschine genannt, das \nmithilfe von Algorithmen \u2013 knapp umrei\u00dfbar als eindeutig \ndefinierte Rechenvorschriften (vgl. Abschnitt 2.2) \u2013 aus einer \ncodierten Eingabe2 eine bestimmte Ausgabe ermittelt.3\nTuring erkannte fr\u00fch, dass die Potenziale der neuen Re-\nchenmaschinen auch die Frage aufwarfen, ob und wie es eines \nTages m\u00f6glich sein sollte, dass solche Ger\u00e4te eine dem Men-\nschen teilweise oder vollst\u00e4ndig gleichwertige oder sogar \u00fcber -\nlegene Intelligenz aufweisen k\u00f6nnten. 1950 formulierte er ein \nKriterium f\u00fcr KI, das sp\u00e4ter als Turing-Test bezeichnet wurde. \nDemnach sei dann von maschineller Intelligenz auszugehen, \nwenn das Verhalten einer Maschine f\u00fcr menschliche Beobach-\nter nicht von dem eines Menschen unterscheidbar erscheint.4 \nDer Turing-Test gilt als wichtige, wenngleich keineswegs un-\numstrittene Inspiration f\u00fcr das Forschungsfeld der KI. Der \nBegriff der K\u00fcnstlichen Intelligenz selbst wurde in Vorberei-\ntung der Dartmouth-Konferenz gepr\u00e4gt, die im Sommer 1956 \n\u00fcber zwei Monate am Dartmouth College im US-Bundesstaat \nNew Hampshire stattfand. Er diente als Sammelbegriff f\u00fcr alle \nVerhaltensweisen von Maschinen, die man als intelligent be-\nzeichnen w\u00fcrde, wenn Menschen sie zeigen. Dies basiert auf \nder Pr\u00e4misse, man k\u00f6nne \u201ejeden Aspekt des Lernens oder je-\ndes andere Merkmal von Intelligenz im Prinzip so genau be-\nschreiben, dass eine Maschine dazu gebracht werden kann, es \n2\t Zum\tBeispiel\tbin\u00e4r\tals\tFolge\tvon\t0\tund\t1.\n3\t Nilsson\t2010,\t55\u201359.\n4\t Turing\t1950.88zu simulieren\u201c.5 Im Rahmen der Dartmouth-Konferenz und \nnachfolgender Konferenzen in den 1950er-Jahren begann \nman, sich mit vielen Themen zu besch\u00e4ftigen, die bis heute in \nder Forschung eine gro\u00dfe Rolle spielen, darunter Mustererken-\nnung, Sprachverarbeitung, Abstraktionsf\u00e4higkeit, Kreativit\u00e4t, \nflexibles Probleml\u00f6sen (z. B. in Strategiespielen wie Schach) \nund die F\u00e4higkeit zu lernen und sich weiterzuentwickeln.6\nDie Pionierarbeiten zur KI f\u00fchrten gemeinsam mit rasan-\nten Fortschritten bei der Entwicklung von Computerhardware \nund Programmiersprachen bald zu gro\u00dfem Optimismus. Viele \nForschende gingen davon aus, dass maschinelle Intelligenz in \nvielen oder sogar allen Facetten innerhalb weniger Jahrzehn-\nte mit menschlicher Intelligenz gleichziehen oder diese sogar \n\u00fcbertreffen w\u00fcrde. Zus\u00e4tzliche Inspiration kam von parallelen \nFortschritten in der biologischen Forschung und insbesondere \nden Neurowissenschaften, deren Ergebnisse zunehmende Ein-\nblicke in kognitive Prozesse erm\u00f6glichten. Schon zu Beginn \nder 1970er-Jahre gab es jedoch auch erste Entt\u00e4uschungen, \nweil die in Aussicht gestellten praktischen Erfolge hinter den \nErwartungen zur\u00fcckblieben und F\u00f6rdermittel daher gek\u00fcrzt \nwurden.7\nDiese erste Skepsis f\u00fchrte dazu, dass der Schwerpunkt der \nAufmerksamkeit in den folgenden Jahren st\u00e4rker auf prakti-\nsche Anwendungen gerichtet wurde, die zudem dank zwi-\nschenzeitlich erfolgten Fortschritten in der theoretischen \nGrundlagenforschung und Computerentwicklung erstmals in \ngreifbare N\u00e4he r\u00fcckten. Neben Weiterentwicklungen einzel-\nner Kerngebiete entstanden Bem\u00fchungen, diese in anspruchs-\nvolleren Projekten zusammenzuf\u00fchren. Dazu geh\u00f6rten etwa \nerste Versuche, mit parallelen Datenverarbeitungsmethoden \n5\t Im\tenglischen\tOriginal:\t\u201e[The\tstudy\tis\tto\tproceed\ton\tthe\tbasis\tof\tthe\tcon-\njecture]\tthat\tevery\taspect\tof\tlearning\tor\tany\tother\tfeature\tof\tintelligence\t\ncan\tin\tprinciple\tbe\tso\tprecisely\tdescribed\tthat\ta\tmachine\tcan\tbe\tmade\tto\t\nsimulate\tit\u201c\t(McCarthy\tet\tal.\t2006,\t12).\n6\t Nilsson\t2010,\t73\u201388.\n7\t Lighthill\t1973.89Computer deutlich leistungsf\u00e4higer zu machen und sich \nselbstst\u00e4ndig fortbewegende Roboter und Fahrzeuge zu entwi-\nckeln. Die zunehmende Vernetzung von Forschenden in Fach-\ngesellschaften und von Computern in Vorl\u00e4ufern des Internets \nsowie das wachsende Engagement von Forschungsorganisati-\nonen, Milit\u00e4r und Industrie trugen dazu bei, dass das Interes-\nse an KI in den 1970er- und 1980er-Jahren erneut aufbl\u00fchte.8 \nAuch hier kam es allerdings zu \u00fcberzogenen Erwartungen und \nVoraussagen, denen so viele Entt\u00e4uschungen und Mittelk\u00fcr -\nzungen folgten, dass die Phase ab den sp\u00e4ten 1980er-Jahren \nauch als \u201eKI-Winter\u201c bezeichnet wird.9 Der anf\u00e4nglichen Eu-\nphorie \u00fcber viele Entwicklungen folgten Entt\u00e4uschungen, wo \ndiese an Grenzen stie\u00dfen, beispielsweise bei der Leistungs-, \nParallelisierungs- und Vernetzungsf\u00e4higkeit von Computern \nsowie der Flexibilit\u00e4t und Lern- bzw. Entwicklungsf\u00e4higkeit \nihrer Programme.10\nParallel zu dieser technischen Entwicklung entstand ein \nkritischer Diskurs, in dessen Zuge sich Computerethik zuneh-\nmend als eigene Disziplin etablierte.11 Aufbauend auf schon in \nden 1940ern angestellten Pionier\u00fcberlegungen von Norbert \nWiener zu gesellschaftlichen Auswirkungen von Interaktio-\nnen zwischen Menschen und intelligent agierenden Maschi-\nnen12 hatte in den 1970er-Jahren unter anderen Joseph Wei-\nzenbaum13 detailliertere ethische Analysen zur Einbeziehung \nvon Softwaresystemen und KI in menschliche Entscheidungs- \nund Lebensprozesse entwickelt. 1985 ver\u00f6ffentlichte Deborah \nJohnson das erste Lehrbuch zum Thema Computerethik14 und \nJames Moor betonte die breite Relevanz des Themas. Nach \nMoor brachte gerade die Flexibilit\u00e4t von Computern als uni-\nverselle Werkzeuge besondere und weitreichende ethische \n8\t Nilsson\t2010,\t343\u2013377.\n9\t Ebd.,\t381\u2013429.\n10\t Schwartz\t1986.\n11\t Bynum\t2015.\n12\t Wiener\t1950.\n13\t Weizenbaum\t1976.\n14\t Johnson\t1985.90Herausforderungen mit sich, da sie Menschen st\u00e4ndig neue \nHandlungsm\u00f6glichkeiten erschlossen, f\u00fcr die es oft noch keine \ngeeigneten Regeln oder ethischen Standards gab.15\nMit dem R\u00fcstzeug zur systematischen Pr\u00fcfung von Chan-\ncen, Risiken und fundamentalen ethischen Aspekten von KI \nkamen zunehmend auch philosophische Zweifel auf, ob ins-\nbesondere die von einigen Forschenden in Aussicht gestellten \nVisionen einer generellen oder starken KI jemals realisiert \nwerden k\u00f6nnten \u2013 oder sollten.16 Auch die unkritische \u00dcber -\ntragung bzw. Verwendung normativ bedeutsamer Begriffe wie \n\u201eIntelligenz\u201c im Zusammenhang mit Softwaresystemen geriet \nin Kritik. Viele Forschende konzentrierten sich fortan bewusst \nauf enger umrissene Teilbereiche des Felds wie beispielsweise \ndas maschinelle Lernen und versuchten, diese auch sprachlich \nals eigenst\u00e4ndig wahrgenommene Felder zu etablieren, um das \nmit dem KI-Begriff verbundene Stigma der Aussichtslosigkeit \noder moralischen Verwerflichkeit zu vermeiden.\nAb den 1990er-Jahren nahmen drei Entwicklungen Fahrt \nauf, die der Entwicklung von KI zu neuer Dynamik verhalfen:\nEs gab erstens gro\u00dfe Fortschritte beim Bau immer leis-\ntungsf\u00e4higerer, erschwinglicherer und handlicherer Compu-\nter, was zu einer massiven Ausweitung ihrer Verbreitung und \nNutzbarkeit auf allen Ebenen f\u00fchrte (vgl. Abschnitt 2.2.1). Pa-\nrallele Datenverarbeitung wurde nach der Jahrtausendwende \nselbst f\u00fcr viele Privatger\u00e4te Standard und umfasst bei Gro\u00df-\nrechnern inzwischen bis zu mehrere tausend Prozessoren. Die \nvoranschreitende Miniaturisierung in der Computertechnik \nund die Entwicklung entsprechend robuster und kleiner leis-\ntungsstarker Sensoren erlauben ihren Einsatz in immer mehr \nGer\u00e4ten, von denen viele, wie zum Beispiel Smartphones, Ta-\nblets, Smartwatches und weitere Wearables, mittlerweile auch \nmobil nutzbar sind. Viele solcher Ger\u00e4te k\u00f6nnen zudem \u00fcber \nvielf\u00e4ltige Sensoren Details \u00fcber Umwelt und die sie nutzenden \n15\t Moor\t1985.\n16\t Searle\t1980.91Personen wahrnehmen, etwa \u00fcber Kameras, Mikrofone, Be-\nwegungsdetektoren, Ortsdatenempf\u00e4nger, Thermometer oder \nPulsmesser.\nZweitens hat die dynamische Entwicklung des Internets \nund diverser, auch drahtloser Zug\u00e4nge die Vernetzungsm\u00f6g-\nlichkeiten zwischen Ger\u00e4ten revolutioniert, sodass gerade \ndort, wo viele Alltagsger\u00e4te am Austausch von Daten beteiligt \nsind, mitunter von einem \u201eInternet der Dinge\u201c die Rede ist.17 \nIm Zuge erweiterter Vernetzungsm\u00f6glichkeiten sind neue In-\nfrastrukturen zur parallelen und dezentralen Datenverarbei-\ntung entstanden, darunter das sogenannte Cloud-Computing, \nbei dem Daten aus vielen Quellen zentral verarbeitet und ge-\nspeichert werden, oder Edge-Computing, bei dem die Daten-\nverarbeitung zu gro\u00dfen Teilen dezentral auf den Endger\u00e4ten \nerfolgt. Gemeinsam erlaubten diese Entwicklungen immer \nschnellere, vielf\u00e4ltigere und umfangreichere Verkn\u00fcpfungen \nverschiedener, von unterschiedlichen Ger\u00e4ten erfassten, pro-\nduzierten und (vor-)verarbeiteten Daten, und zwar sowohl \nzwischen dezentralen Ger\u00e4ten als auch zwischen diesen Ger\u00e4-\nten und zentralen Hochleistungsrechnern.\nDies hat drittens eine beispiellose und noch immer anstei-\ngende Datenflut hervorgebracht. Der auch unter dem Stich-\nwort \u201eBig Data\u201c zusammengefasste Trend, gro\u00dfe Mengen viel-\nf\u00e4ltiger Daten mit hoher Geschwindigkeit18 zu generieren, zu \nerfassen, immer wieder neu zu verkn\u00fcpfen und zu analysieren, \nhat viele der im Folgenden vorgestellten j\u00fcngeren Entwick-\nlungen von Algorithmen vorangetrieben oder \u00fcberhaupt erst \nerm\u00f6glicht, insbesondere neuere statistische Methoden zur \nMustererkennung im Bereich des maschinellen Lernens und \nhier vor allem das sogenannte Deep Learning.19\n17\t Mattern/Fl\u00f6rkemeier\t2010.\n18\t Im\tEnglischen\twerden\tdie\tKernmerkmale\tvon\tBig\tData\tauch\tals\t\u201edie\tdrei\tV\u201c\t\n\u2013\tvolume\t(Menge),\t variety\t(Vielfalt)\t und\t velocity\t(Geschwindigkeit)\t \u2013\tzusam-\nmengefasst\t(Laney\t2001).\n19\t Deutscher\tEthikrat\t2017,\t54\u00a0f.92Gemeinsam haben diese drei noch andauernden Trends \nder Leistungssteigerung und Miniaturisierung von Compu-\ntern, der Vernetzung digitaler Systeme und der damit verbun-\ndenen neuen M\u00f6glichkeiten der Datenzusammenf\u00fchrung und \n-auswertung eine Reihe von nachfolgend n\u00e4her vorgestellten \nEntwicklungen angesto\u00dfen, deren gesellschaftliche und ethi-\nsche Analyse im Mittelpunkt dieser Stellungnahme steht.\n2.2\t\t KI\tim\t21.\tJahrhundert:\tBig\tData,\t\nAlgorithmen\tund\tsoziotechnische\t\n\u00d6kosysteme\n2.2.1 Digitale Durchdringung der menschlichen \nLebenswelt\nDie im vorigen Abschnitt beschriebene Dynamik der Entwick-\nlungen seit der Jahrtausendwende und insbesondere in den \nletzten Jahren hat zu einer intensivierten Durchdringung der \nAlltagswelt mit Computern gef\u00fchrt, die dazu beitr\u00e4gt, dass un-\nter dem Schlagwort \u201eK\u00fcnstliche Intelligenz\u201c inzwischen eine \nF\u00fclle unterschiedlicher, aber vielfach konvergierender Ph\u00e4-\nnomene diskutiert wird. Lag der Fokus angesichts der rasant \nwachsenden Datenmengen und der damit verbundenen neu-\nen Auswertungsm\u00f6glichkeiten zun\u00e4chst noch auf Big Data, \nstehen inzwischen vielfach die Leistungen allgegenw\u00e4rtiger \nalgorithmischer Systeme im Mittelpunkt, die auf breiten Da-\ntengrundlagen scheinbar selbst Entscheidungen treffen und so \nzumindest den Eindruck erwecken, sie w\u00fcrden eigenst\u00e4ndig \nund intelligent agieren.\nVernetzte Computertechnik in Alltagsbegleitern wie Mo-\nbiltelefonen, Uhren und Haushaltsger\u00e4ten wird nicht nur \nmit dem Attribut smart beworben, sondern wirkt tats\u00e4chlich \n\u201eklug\u201c, wenn sie \u00fcber Sensoren erfasste lokale Gegebenheiten \nmit online verf\u00fcgbaren Daten verkn\u00fcpft, um sich an indivi-\nduelle Besonderheiten und Bed\u00fcrfnisse der Menschen, die sie 93nutzen, anzupassen. Das gilt erst recht, wenn eine personali-\nsierte oder gar emotional wirkende Ansprache hinzukommt, \nzum Beispiel \u00fcber die Stimmen virtueller Assistenzsysteme wie \nAlexa oder Siri. Den Empfehlungssystemen zahlreicher Inter -\nnetangebote wie zum Beispiel Videostreamingdienste oder \nOnlineshops gelingen derweil mittels Analysen von Klicks und \nNutzungsprofilen immer treffsichere Vorhersagen \u00fcber die \nVorlieben von Einzelpersonen und auch Roboter und Fahr -\nzeuge k\u00f6nnen sich dank zunehmend leistungsf\u00e4higer Sensorik \nund Computertechnik immer besser unabh\u00e4ngig von mensch-\nlicher Steuerung fortbewegen.\nDurch diese vielf\u00e4ltige Verbreitung algorithmischer \nTechnik entstehen soziotechnische Daten\u00f6kosysteme, in de-\nnen \u00fcber die von Menschen verwendeten Ger\u00e4te und die sie \nverkn\u00fcpfenden Datennetzwerke zunehmend akkurate und \numfangreiche digitale Repr\u00e4sentationen der Bewegungen, \nHandlungen, Eigenschaften und Pr\u00e4ferenzen vieler Personen \nentstehen. Solche reichhaltigen digitalen Abbilder k\u00f6nnen \nnicht nur ausgewertet werden, sondern wirken auch unmittel-\nbar oder mittelbar auf die analogen Prozesse der menschlichen \nLebenswelt und menschliches Verhalten zur\u00fcck, indem auf ih-\nrer Grundlage Menschen Informationen oder Handlungsemp-\nfehlungen angeboten werden.\nHinter diesen und vielen weiteren Entwicklungen steht ein \nPortfolio technischer Entwicklungen, die im Folgenden kurz \nvorgestellt werden \u2013 wohl wissend, dass es sich dabei ange-\nsichts der schnellen Ver\u00e4nderungen in der Technikentwick-\nlung und der Einsatzpraxis nur um eine Momentaufnahme \nhandeln kann. Auch wenn in den folgenden Ausf\u00fchrungen \nDaten, technische Infrastrukturen und Algorithmen konseku-\ntiv beschrieben werden, so ist zu ber\u00fccksichtigen, dass diese \nin komplexen Systemen miteinander verbunden sind und ihre \nLeistungen erst im Zusammenwirken erbringen.942.2.2 Daten und digitale Infrastrukturen\nDas Fundament digitaler Operationen und Interaktionen bil-\nden Daten, die von h\u00f6chst unterschiedlicher Natur wie Quali-\nt\u00e4t sein k\u00f6nnen. Es gibt unterschiedliche Datentypen (z. B. bi-\nn\u00e4re, ordinale, metrische oder textliche Daten, Bilder, Musik, \nVideos) und Datenstrukturen (z. B. Listen, Tabellen), die aus \nvielf\u00e4ltigen Quellen (z. B. Sensoren, Nutzungsstatistiken, Um-\nfragen) in diversen thematischen Zusammenh\u00e4ngen (z. B. Ge-\nsundheitsbereich, Finanzsystem, Verkehr, soziale Netzwerke) \nstammen k\u00f6nnen. Daten k\u00f6nnen auch synthetisch generiert \nsein, wenn nicht gen\u00fcgend \u201eechte\u201c Daten in der gew\u00fcnschten \nQualit\u00e4t zur Verf\u00fcgung stehen. Dies erm\u00f6glicht es etwa, ein \nSystem im Umgang mit Daten zu trainieren, die in vorhande-\nnen Datens\u00e4tzen aufgrund von Verzerrungen unterrepr\u00e4sen-\ntiert sind, so beispielsweise Daten von Personen bestimmter \ndemografischer oder ethnischer Zugeh\u00f6rigkeit.\nDie Qualit\u00e4t eines Datensatzes h\u00e4ngt zum einen davon ab, \nwie genau, vollst\u00e4ndig, aktuell oder detailliert die Daten sind. \nZum anderen wird sie von den begleitenden Metadaten beein-\nflusst, die als Leseanleitung Auskunft \u00fcber den Kontext und \ndie Semantik (Bedeutung) der Daten geben. Metadaten infor -\nmieren zum Beispiel \u00fcber die Herkunft der Daten (Erhebungs-\nzeitpunkt und -ort, Art oder genaue Identifikation der Quelle \noder des Sensors), die Bedeutung konkreter Zahlencodes oder \nsonstiger Etiketten im konkreten Datensatz und die Zuord-\nnung zu bestimmten Personen oder Kategorien. Die Kombi-\nnation und Verkn\u00fcpfung verschiedener Daten kann nur dann \nsinnvoll gelingen, wenn Kontext und Semantik f\u00fcr den jewei-\nligen Zweck hinreichend klar und kompatibel und die Daten \nauf dieser Grundlage somit interoperabel sind. Besonders \ngute Interoperabilit\u00e4t kann durch eine klare Standardisierung \nvon Datenformaten und zu erfassenden Metadaten erreicht \nwerden. Dies erh\u00f6ht die Chancen, dass Daten beispielsweise \nim Gesundheitssystem institutionen\u00fcbergreifend analysiert 95werden k\u00f6nnen, selbst wenn sie in verschiedenen Praxen, Kli-\nniken oder Forschungseinrichtungen erhoben wurden.\nDie Datenqualit\u00e4t h\u00e4ngt dabei nicht nur von den zuvor \ngenannten Faktoren ab, sondern auch vom Verh\u00e4ltnis zwi-\nschen den Erhebungs- und den Anwendungskontexten. Selbst \nwenn jedes einzelne Datum \u201ekorrekt\u201c gem\u00e4\u00df der im vorigen \nAbsatz genannten Anforderungen erhoben wurde, haben \ndie Umst\u00e4nde und Zwecke der Datenerhebung wie auch der \nDatenauswertung Einfluss darauf, wie sehr bestimmte Daten \nden konkreten Qualit\u00e4tsanforderungen f\u00fcr einen bestimmten \nAuswertungszusammenhang gen\u00fcgen (Validit\u00e4t). So werden \nbeispielsweise Daten daf\u00fcr genutzt, um auf kognitive oder \nemotionale Zust\u00e4nde von Individuen zu schlie\u00dfen, die nicht \ndirekt beobachtbar sind, wie etwa Aufmerksamkeit, Stress, ko-\ngnitive Belastung oder Angst. Die Auswahl und Bewertung der \nAussagekraft der zu verwendenden Daten sind daher alles an-\ndere als trivial und m\u00fcssen sorgf\u00e4ltig gepr\u00fcft werden. Es geht \nalso darum, dass Daten nicht nur prinzipiell von hoher oder \nniedriger Qualit\u00e4t sind, sondern auch f\u00fcr eine jeweilige Frage \noder Aufgabenstellung mehr oder weniger angemessen sein \nk\u00f6nnen. Werden solche Fragen der Passung nicht rechtzeitig \nund hinreichend ber\u00fccksichtigt, sind Verzerrungen oder irre-\nf\u00fchrende Analysen m\u00f6glich.20\nEntscheidend f\u00fcr die Leistungsf\u00e4higkeit datengetriebener \nAnwendungen sind auch die Hardware und Infrastruktur, die \nf\u00fcr die Handhabung und Nutzung von Daten zur Verf\u00fcgung \nstehen. Das Herzst\u00fcck bildet hierbei die Rechenleistung der \nProzessorkerne, die mit den Daten arbeiten. Gerade f\u00fcr beson-\nders rechen- und datenintensive Anwendungen kommen in-\nzwischen hochparallelisierte Rechnersysteme zum Einsatz, in \ndenen viele Hunderte oder Tausende Prozessorkerne gleich-\nzeitig arbeiten. Inzwischen gibt es auch Prozessoren, die auf \nschnelles maschinelles Lernen auf Grundlage gro\u00dfer Daten-\nmengen spezialisiert sind, wie die von Google entwickelten \n20\t Barocas/Selbst\t2016.96Tensor-Prozessoren (Tensor Processing Units). Sie sind f\u00fcr \ndas hochparallele Addieren und Multiplizieren von Matrizen \nin neuronalen Netzen optimiert und werden beispielsweise \nin KI-Systemen wie dem Brettspielprogramm AlphaGo oder \nin den Algorithmen von Google Fotos, Google Maps, der Da-\ntenanalyseplattform Kaggle und der Google Cloud Platform \nverwendet.\nEin Gro\u00dfteil datenintensiver Operationen findet mittler -\nweile in Gro\u00dfeinrichtungen wie Datenlagern (Data Warehou-\nses, Data Lakes) und Serverfarmen statt, die auf Datenspei-\ncherung und/oder Datenanalyse spezialisiert und durch das \nInternet untereinander und mit Endger\u00e4ten vielf\u00e4ltig und \ndynamisch vernetzt sind. Der Austausch zwischen den vielen \nverschiedenen und oft weltweit verteilten Ger\u00e4ten in einem \nDatennetzwerk funktioniert mithilfe standardisierter Proto-\nkolle und Schnittstellen zur Anwendungsprogrammierung \n(Application Programming Interfaces). Sind Netzwerkknoten \nerst einmal \u00fcber solche Schnittstellen verkn\u00fcpft, flie\u00dfen Da-\nten entsprechend den vorgenommenen Einstellungen auto-\nmatisch und oft in Echtzeit. Dies erm\u00f6glicht es, Rechen- und \nSpeicherressourcen schnell und flexibel an die Anforderungen \nbestimmter Projekte und Kunden angepasst zur Verf\u00fcgung \nzu stellen. Als Sammelbegriff f\u00fcr solche \u00fcber das Internet zu-\ng\u00e4nglichen Datenspeicher und Datenanalysedienste hat sich \nder Begriff des Cloud-Computings etabliert. Der Markt wird \nim privaten wie im institutionellen Bereich von Angeboten \ngro\u00dfer Internetfirmen wie Amazon, Microsoft und Google \ndominiert.\nMit der Leistungssteigerung der Prozessoren in Endger\u00e4-\nten wie Heimcomputern, Mobiltelefonen und Smartwatches \nwachsen auch die M\u00f6glichkeiten, Daten zumindest teilweise \nbereits lokal in den Ger\u00e4ten, die sie erheben, zu verarbeiten. \nSolche erhebungsnahen, dezentralen Ans\u00e4tze zur Datenverar -\nbeitung an den \u201eR\u00e4ndern\u201c des Internets werden in Abgrenzung \nzum Cloud-Computing auch als Edge-Computing bezeichnet. \nSie bieten neben Ressourcenschonung beim Datentransfer 97auch datenschutzfreundlichere Gestaltungsm\u00f6glichkeiten, da \nzum Beispiel bestimmte sensible Daten gar nicht mehr weiter -\ngegeben werden m\u00fcssen, sondern nur die von ihnen abgeleite-\nten Ergebnisse der Vorverarbeitung.21\n2.2.3 Algorithmen und Datenverarbeitung\nMit der Menge und Vielfalt von Daten und der sie miteinander \nvernetzenden Infrastrukturen wachsen sowohl die Anspr\u00fcche \nan als auch die M\u00f6glichkeiten zur Datenverarbeitung. Herz-\nst\u00fcck jeglicher Datenverarbeitung sind Algorithmen: Verar -\nbeitungsanweisungen zur L\u00f6sung eines Problems. Algorith-\nmen geben vor, wie eingegebene Daten meist schrittweise nach \nklar definierten Regeln umgeformt werden, bis der gesuchte \nAusgabewert erreicht ist. In ihrer einfachsten Form k\u00f6nnen \nAlgorithmen Anleitungen zur klar festgelegten Verarbeitung \nvon Daten oder Informationen sein, zum Beispiel die Formel \nzur Berechnung des Body-Mass-Indexes22 oder eine Regel zum \nSortieren von Zahlen nach ihrer Gr\u00f6\u00dfe. Die meisten Algo-\nrithmen enthalten konditionale Elemente wie Wenn-dann-\nAnweisungen oder ineinander verschachtelte Befehlsschleifen, \ndie das Ausf\u00fchren komplexer Operationen unter Ber\u00fccksich-\ntigung der jeweiligen Situation erm\u00f6glichen. In Computerpro-\ngrammen sind Algorithmen in Programmiersprachen codiert.\nIm Mittelpunkt der Arbeit mit gro\u00dfen und vielf\u00e4ltigen Da-\ntenmengen, die kennzeichnend f\u00fcr moderne soziotechnische \n\u00d6kosysteme ist, stehen statistische Analysen, mit denen Regel-\nm\u00e4\u00dfigkeiten in Daten erkannt sowie Zusammenh\u00e4nge und po-\ntenzielle Wirkmechanismen zwischen einzelnen Merkmalen \n21\t Vgl.\tetwa\tdie\tAns\u00e4tze\tdes\tFederated\tLearnings\t(Kaissis\tet\tal.\t2021)\tund\t\nSwarm\tLearnings\t(Warnat-Herresthal\tet\tal.\t2021).\n22\t Der\tBody-Mass-Index\toder\tK\u00f6rpermasseindex\twird\tals\tRichtwert\tzur\t\nBeurteilung\tdes\tVerh\u00e4ltnisses\tzwischen\tK\u00f6pergr\u00f6\u00dfe\tund\tK\u00f6rpergewicht\t\nverwendet.\tEr\twird\tberechnet,\tindem\tman\tdie\tK\u00f6rpergr\u00f6\u00dfe\t(in\tMetern)\t\ndurch\tdas\tQuadrat\tdes\tK\u00f6rpergewichts\t(in\tKilogramm)\tteilt.98identifiziert werden, zum Beispiel Korrelationen zwischen der \nK\u00f6rpergr\u00f6\u00dfe eines Kindes und der Gr\u00f6\u00dfe der Eltern, den fi-\nnanziellen Ressourcen der Familie oder der Ern\u00e4hrung. Aus-\ngehend von solchen Korrelationen k\u00f6nnen Vorhersagen f\u00fcr \n\u00e4hnliche Datens\u00e4tze oder k\u00fcnftige Entwicklungen abgeleitet \nwerden. Dabei kommen unterschiedliche statistische Metho-\nden zum Einsatz, die von einfachen Regressionsverfahren bis \nzu Deep Learning reichen.\nGeht es darum, kausale Mechanismen nachzuweisen, sind \nin der Regel weitere \u00dcberlegungen und Untersuchungen n\u00f6-\ntig, die eine plausible Erkl\u00e4rung f\u00fcr den vermuteten Wirkzu-\nsammenhang zwischen Merkmalen anbieten, welche sich auch \nempirisch \u2013 beispielsweise in Experimenten \u2013 \u00fcberpr\u00fcfen \nl\u00e4sst. Eine plausible Hypothese und ein empirischer Nachweis \nf\u00fcr einen kausalen Zusammenhang zwischen der Anzahl von \nSt\u00f6rchen und Geburten wird sich wohl nicht etablieren lassen, \nder Wirkmechanismus eines potenziellen Arzneimittels hin-\ngegen schon. Ein solcher Nachweis ist etwa im medizinischen \nBereich besonders wichtig, da klinische Studien nur sinnvoll \nund sicher durchgef\u00fchrt werden k\u00f6nnen, wenn biologisch \nplausible Hypothesen und zumindest vorl\u00e4ufig gesicherte Er -\nkenntnisse zur Wirkweise neuer Therapeutika vorliegen. In \nanderen F\u00e4llen ist die Frage nach Kausalit\u00e4t m\u00f6glicherweise \nweniger bedeutsam und es gen\u00fcgt, wenn auf Grundlage vor -\nhandener Daten hinreichend zuverl\u00e4ssige Modelle berechnet \nwerden k\u00f6nnen. Wenn das Empfehlungssystem eines Online-\nshops treffsicher vorhersagt, dass Personen mit bestimmten \nMerkmalskombinationen unterschiedliche Produkte m\u00f6gen, \nreicht das vielleicht f\u00fcr den Einsatzzweck schon aus und die \nFrage, warum solche Zusammenh\u00e4nge bestehen, muss nicht \nbeantwortet werden.\nStatistische Analysen enthalten Unsicherheiten und geben \nin der Regel an, wie gro\u00df die jeweils zu erwartenden Fehler und \nUnsicherheiten sind, um Ergebnisse angemessen interpretieren \nzu k\u00f6nnen. Mit der Menge und Qualit\u00e4t der Daten w\u00e4chst da-\nbei f\u00fcr gew\u00f6hnlich die Verl\u00e4sslichkeit der Analyseergebnisse, 99da die Wahrscheinlichkeit sinkt, dass die beobachteten Muster \nrein zufallsbedingt sind. Ganz ausmerzen lassen sich Fehler \nund Unsicherheiten in der Regel allerdings nicht und mit der \nMinimierung bestimmter Fehlerquellen k\u00f6nnen andere Feh-\nlerquellen verst\u00e4rkt werden. Optimiert man beispielsweise ei-\nnen Test auf eine Virusinfektion dahingehend, dass er durch \nBer\u00fccksichtigung m\u00f6glichst vieler Merkmale wirklich keine \ninfizierte Person \u00fcbersieht, steigt das Risiko, auch Personen \nf\u00e4lschlich als infiziert zu identifizieren, bei denen vielleicht nur \nwenige dieser Merkmale in schwacher Auspr\u00e4gung vorliegen \n\u2013 es entstehen falsch-positive Ergebnisse. Optimiert man den \nTest hingegen so, dass solche Fehler vermieden werden, in-\ndem nur wenige und/oder starke Zusammenh\u00e4nge zwischen \nMerkmalen ber\u00fccksichtigt werden, steigt das Risiko, dass tat-\ns\u00e4chlich infizierte Personen \u00fcbersehen werden \u2013 es entstehen \nfalsch-negative Ergebnisse. Welche Fehler in statistischen Ana-\nlysen am ehesten in Kauf zu nehmen sind, h\u00e4ngt daher auch \nimmer von der konkreten Fragestellung und Zwecksetzung \nab und ist in zahlreichen Bereichen nicht nur eine technisch-\nmethodische, sondern eine ethische Frage. Dies zeigt sich \nbeispielsweise bei Entscheidungsunterst\u00fctzungssoftware im \nBereich der Prognose von Kindeswohlgef\u00e4hrdung. Schon im \nRahmen der Softwareentwicklung muss entschieden werden, \nwelcher Fehler schwerer wiegt: eine Kindeswohlgef\u00e4hrdung \n\u00fcbersehen oder ein Kind unbegr\u00fcndeterweise aus einer Fami-\nlie genommen zu haben.\nMaschinelles Lernen\nF\u00fcr algorithmische Verfahren und Systeme, die ihre Muster -\nsuche, Modellbildung und sonstige Funktionsweise datenba-\nsiert optimieren k\u00f6nnen, hat sich der Begriff des maschinellen \nLernens etabliert.23 Er umfasst unterschiedliche Ans\u00e4tze, die \nin verschiedenen Anwendungsfeldern zum Einsatz kommen \n23\t Zu\tDetails\tzu\tden\tin\tdiesem\tAbschnitt\tkurz\tvorgestellten\tAns\u00e4tzen\tmaschi-\nnellen\tLernens\tvgl.\tBauckhage\tet\tal.,\tin:\tG\u00f6rz/Schmid/Braun\t2021,\t429\u00a0ff.100und st\u00e4ndig weiterentwickelt werden. Gemeinsam ist diesen \nAns\u00e4tzen eine anf\u00e4ngliche Trainingsphase, in der ein Algo-\nrithmus sein Modell zur Mustererkennung durch wiederhol-\nte Analyse von Trainingsdaten aufbaut und verfeinert. In der \n\u00f6ffentlichen Debatte wird der Begriff h\u00e4ufig synonym mit KI \nverwendet. Allerdings beschreibt er lediglich eine Reihe sta-\ntistischer Verfahren zur Analyse gro\u00dfer Datenmengen, die \nvon gut interpretierbaren Ans\u00e4tzen wie Entscheidungsbau-\nmalgorithmen \u00fcber statistische Optimierungsmethoden wie \nSupport Vector Machines bis hin zu k\u00fcnstlichen neuronalen \nNetzen reichen.24 KI hingegen beschreibt \u2013 wie in Kapitel 2 \nbereits dargelegt \u2013 ein breites Forschungsfeld, in dem bereits \nseit den 1950er-Jahren ganz unterschiedliche Methoden einge-\nsetzt werden, um menschliche Kognition maschinell zu simu-\nlieren. Der aktuelle \u201eKI-Sommer\u201c geht wesentlich auf rasante \nWeiterentwicklungen beim maschinellen Lernen zur\u00fcck. Wa-\nren klassische Ans\u00e4tze noch stark auf passend vorverarbeitete \nDaten angewiesen, k\u00f6nnen moderne Methoden insbesondere \ndes Deep Learnings (siehe unten) flexibel auf verschiedenste \nDaten wie Bilder, Videos und Texte angewendet werden.25\nIm Kontext des maschinellen Lernens sind folgende Typen \nvon Lernverfahren zu unterscheiden: \u00fcberwachtes Lernen, un-\n\u00fcberwachtes Lernen und Verst\u00e4rkungslernen. Beim \u00fcberwach-\nten Lernen sind die Zuordnungen zwischen den Eingabe- und \nden gesuchten Ausgabedaten im Trainingsdatensatz bereits \nbekannt. In einem Trainingsdatensatz zur Erkennung von \nHautkrebs w\u00e4ren dies zum Beispiel Bilder von gesunder Haut \nund Hautkrebs, deren gesicherte Zuordnung zu einer dieser \nbeiden Kategorien in einem Etikett (Label) vermerkt ist. Der \ntrainierende Algorithmus kann seinen Zuordnungserfolg an-\nhand dieser Etiketten in jeder Trainingsrunde \u00fcberpr\u00fcfen und \nseine Rechenregeln anpassen, bis das System f\u00fcr die korrekte \n24\t Schmid\t2022.\n25\t Dazu\tgeh\u00f6ren\tbeispielsweise\tConvolutional\tNeural\tNetworks,\tLong\tShort-\nTerm\tMemory\tund\tgenerative\tAns\u00e4tze\t(Bauckhage\tet\tal.,\tin:\tG\u00f6rz/Schmid/\nBraun\t2021,\t509\u00a0ff.).101Erkennung von Hautkrebs optimiert ist. \u00dcberwachtes Lernen \neignet sich besonders f\u00fcr Algorithmen, die bestimmte Mus-\nter in Daten zuverl\u00e4ssig erkennen und kategorisieren k\u00f6nnen \nsollen, also zum Beispiel f\u00fcr Diagnostikwerkzeuge, die wie im \nobigen Beispiel in der Bilderkennung eingesetzt werden, aber \nauch f\u00fcr Ans\u00e4tze zur Sprach-, Text- oder Objekterkennung. \nAuch das Training von Algorithmen zur Vorhersage k\u00fcnftiger \nEntwicklungen, beispielsweise beim Wetter, im Finanzsektor \noder beim Wasser- oder Stromverbrauch, geschieht h\u00e4ufig mit \n\u00fcberwachtem Lernen, da Algorithmen hier Regressionsmo-\ndelle auf Grundlage bekannter und entsprechend etikettierter \nZusammenh\u00e4nge zwischen Merkmalen in Trainingsdaten aus \nder Vergangenheit erlernen.\nUn\u00fcberwachtes Lernen hingegen funktioniert ohne vor -\nherige Etikettierung der Trainingsdaten; stattdessen \u201esucht\u201c \nder Algorithmus eigenst\u00e4ndig nach Mustern. Auf diese Weise \nk\u00f6nnen neue Strukturen und Gruppierungen (Cluster) in Da-\nten entdeckt und weiterverwendet werden, zum Beispiel zur \nGenerierung neuer \u201ekreativer\u201c Inhalte durch den Algorith-\nmus oder zur Analyse von Marktsegmenten oder Zielgruppen, \num passgenaue Angebote zu liefern. Durch den Verzicht auf \neine vorherige Etikettierung lassen sich beim un\u00fcberwachten \nLernen zudem nicht nur die im Vorfeld notwendigen Vor -\nverarbeitungsschritte, sondern auch bestimmte Verzerrungen \n(Bias) reduzieren, so zum Beispiel jene, die bei einer h\u00e4ndi-\nschen Zuweisung von Merkmalen aufgrund von Vorurteilen \noder blo\u00dfen Intuitionen seitens des Entwicklungsteams ein-\nflie\u00dfen k\u00f6nnen. Andererseits sind un\u00fcberwachte Lernalgo-\nrithmen anf\u00e4llig f\u00fcr jene Verzerrungen, die bereits in den \nTrainingsdaten enthalten sind. Ein Algorithmus, der Vorher -\nsagen zur Medikamentenvertr\u00e4glichkeit mit Daten trainiert, \ndie \u00fcberwiegend von M\u00e4nnern stammen, ist so m\u00f6glicher -\nweise weniger pr\u00e4zise, wenn es um Vorhersagen f\u00fcr Frauen \ngeht, da relevante Faktoren f\u00fcr diese Gruppe beim Training \nnicht ber\u00fccksichtigt wurden. Au\u00dferdem steigt in dem Ma\u00dfe, \nin dem ein Algorithmus unabh\u00e4ngig von menschengemachten 102Etiketten und sonstigen Vorgaben seinen eigenen Weg zur \nProbleml\u00f6sung \u201esucht\u201c26, auch die potenzielle Undurchdring-\nbarkeit seiner L\u00f6sungsans\u00e4tze.\nBeim Verst\u00e4rkungslernen optimiert der Algorithmus seine \nOperationen auf bestimmte Ziele hin und erh\u00e4lt dabei in der \nTrainingsphase f\u00fcr jeden Versuch eine R\u00fcckmeldung, ob die-\nser Schritt das System dem Ziel n\u00e4hergebracht oder es davon \nentfernt hat. Schritte in die richtige Richtung werden mit einer \nBonusfunktion belohnt, solche in die falsche Richtung bestraft. \nDie Methoden sind in der Regel so aufgebaut, dass sich kurz-\nfristig auch Schritte in die falsche Richtung lohnen k\u00f6nnen, \nwenn sie einer langfristig g\u00fcnstigen Strategie dienen. Verst\u00e4r -\nkungslernen l\u00e4sst sich beispielsweise einsetzen, um Spielstrate-\ngien zu entwickeln, Verkehrsfl\u00fcsse zu optimieren oder Klicks \nund Verweildauer auf einer Plattform zu maximieren.\nDie algorithmischen Strategien, die im Laufe des Trainings \nzur Bew\u00e4ltigung der jeweiligen Aufgaben entwickelt werden, \nsind in der Regel selbst f\u00fcr geschultes Personal, das den Code \neinsehen kann, nicht vollst\u00e4ndig nachvollziehbar (Blackbox). \nDas gilt umso mehr, je dynamischer sich ein Algorithmus \nim Laufe seiner Arbeit weiterentwickelt, also insbesondere \nf\u00fcr Deep Learning. Es gibt verschiedene L\u00f6sungsans\u00e4tze, um \ntrotzdem eine f\u00fcr die jeweilige Zielgruppe angemessene Trans-\nparenz, Interpretierbarkeit oder Erkl\u00e4rbarkeit algorithmischer \nProzesse zu erreichen (Explainable AI); deren Auswahl und \nAnwendung ist jedoch technisch anspruchsvoll und stellt ein \nhochdynamisches Forschungsfeld dar.27\n26\t Wir\tverwenden\tgelegentlich\tmentale\tPr\u00e4dikate,\tum\tEigenschaften\tvon\t\nSoftware\tzu\tbeschreiben.\tDas\tentspricht\teiner\tetablierten\tRedeweise,\tdie\t\nnicht\tdahingehend\tmissverstanden\twerden\tdarf,\tdass\tdamit\tangenommen\t\nwird,\tSoftwaresysteme\th\u00e4tten\ttats\u00e4chlich\tdiese\tmentalen\tEigenschaften,\t\nw\u00fcrden\tzum\tBeispiel\tetwas\tsuchen.\n27\t Samek\tet\tal.\t2021;\tMiller\t2019;\tsiehe\tauch\thttps://facctconference.org\t\n[27.02.2023].103Der Begriff des maschinellen Lernens28 kommt nicht von \nungef\u00e4hr, dienen menschliche Lernprozesse doch als Analogie \n\u2013 \u00e4hnlich wie beim Begriff der K\u00fcnstlichen Intelligenz auch. \nSo lernen auch Menschen \u201e\u00fcberwacht\u201c, wenn sie beispielswei-\nse unterrichtet werden oder sich von anderen etwas abschau-\nen. Un\u00fcberwachtes maschinelles Lernen weist Parallelen zu \nSpiel und kreativen oder erkundenden Prozessen auf. Verst\u00e4r -\nkungslernen findet biologische Vorbilder in den gut erforsch-\nten Belohnungs- und Aversionssystemen von Gehirnen29, die \nunmittelbar auf Lernprozesse zur\u00fcckwirken, indem sie \u00fcber \ndie Aussch\u00fcttung diverser Neurotransmitter Verbindungen \nzwischen Nervenzellen st\u00e4rken oder schw\u00e4chen.\nBiologisch inspiriert ist auch ein Teilbereich des maschi-\nnellen Lernens, der besonders f\u00fcr den Umgang mit gro\u00dfen \nDatenmengen geeignet ist und in den letzten Jahren zu einem \nwichtigen Treiber f\u00fcr viele KI-Anwendungen geworden ist \n\u2013 Deep Learning. Hier kommen sogenannte neuronale Net-\nze zum Einsatz, deren Funktionsweise entfernt an Netzwerk-\nstrukturen im Gehirn angelehnt ist (siehe Infokasten 1).\nInfokasten\t1:\tNeuronale\tNetze\tim\tGehirn\nIm\tGehirn\term\u00f6glicht\t das\tZusammenspiel\t von\tNervenzellen\t in\tkomplexen\t\nund\thierarchischen\t Vernetzungen\t vielf\u00e4ltige\t und\tanpassungsf\u00e4hige\t Funkti-\nonen.\tEine\teinzelne\t Nervenzelle\t kann\t\u00fcber\tSynapsen\t mit\tmehreren\t tausend\t\nanderen\t Nervenzellen\t verschaltet\t sein,\tund\tzwar\tsowohl\tin\tihrem\t(postsyn-\naptischen)\t Eingabebereich,\t in\tdem\tsie\tSignale\tempf\u00e4ngt,\t als\tauch\tin\tihrem\t\n(pr\u00e4synaptischen)\t Ausgabebereich,\t \u00fcber\tden\tsie\tInformationen\t an\t\u201efluss-\nabw\u00e4rts\u201c\t liegende\t Zellen\tweitergibt.\t Bei\tder\tVerarbeitung\t der\tvielf\u00e4ltigen\t\nempfangenen\t Signale\tleistet\tschon\tdie\teinzelne\t Zelle\terstaunliche\t Integrati-\nonsarbeit,\t die\tzum\tBeispiel\t die\tQualit\u00e4t\t und\tdie\traumzeitlichen\t Muster\tder\t\neingehenden\t Informationen\t ber\u00fccksichtigt.\t Wesentlicher\t Bestandteil\t von\t\nLernprozessen\t sind\tplastische\t Ver\u00e4nderungen\t in\tder\tFunktion\t und\tStruktur\t\nvon\tSynapsen,\t die\tin\tReaktion\t auf\tneuronale\t Aktivit\u00e4t\t erfolgen.\t Eine\tgro\u00dfe\t\n28\t Gepr\u00e4gt\twurde\tder\tBegriff\t\u201eMachine\tLearning\u201c\tvon\tKI-Forschern,\tdie\tdie\t\nersten\tAns\u00e4tze\thierzu\tetabliert\thaben\t(Samuel\t1959;\tCarbonell/Michalski/\nMitchell\t1983).\tParallel\that\tsich\tim\tBereich\tder\tSignalverarbeitung\tdie\t\nMustererkennung\t(Pattern\tRecognition)\tals\tverwandtes\tForschungsgebiet\t\netabliert.\tBeides\twird\theute\tals\tmaschinelles\tLernen\tzusammengefasst.\n29\t Neftci/Averbeck\t2019.104Rolle\tspielt\tdabei\tdie\tModulation\t des\tVerh\u00e4ltnisses\t von\tsynaptischer\t Erre-\ngung\tund\tHemmung\t innerhalb\t der\tneuronalen\t Netzwerke.\t Die\tSt\u00e4rke\tder\t\nSynapsen\t wird\tdurch\tdie\tAnzahl\tverschiedener\t Rezeptoren\t bestimmt,\t die\t\nauf\tunterschiedliche\t chemische\t Botenstoffe\t (Neurotransmitter)\t reagieren.\t\nLernergebnisse\t und\tneue\tGed\u00e4chtnisinhalte\t schlagen\t sich\tin\tder\tSt\u00e4rkung\t\neinzelner\t Synapsen\t nieder,\twas\twiederum\t R\u00fcckwirkungen\t auf\tdie\tFunktion\t\nder\tbeteiligten\t Netzwerke\t und\tsogar\tauf\tdas\t\u00dcberleben\t einzelner\t Nerven-\nzellen\thaben\tkann.\nDie Bausteine eines maschinellen neuronalen Netzes sind \nk\u00fcnstliche \u201eNervenzellen\u201c \u2013 Recheneinheiten, die auch als \nPerzeptrone bezeichnet werden. Jedes Perzeptron ist mit an-\npassbaren Gewichtungen und einem Schwellenwert ausgestat-\ntet, die mitbestimmen, wie das Perzeptron auf eingehende Sig-\nnale reagiert und welchen Ausgabewert es produziert.\nDie Perzeptrone sind miteinander vernetzt, wobei die Ver -\nnetzung meist als vollst\u00e4ndige Verbindung aller Neuronen \neiner Schicht mit allen der n\u00e4chsten Schicht realisiert wird. \nJedes neuronale Netz besteht aus einer Eingabeschicht, ei-\nner Ausgabeschicht und dazwischenliegenden \u201eversteckten\u201c \nSchichten, in denen die Datenverarbeitung stattfindet. Es wur -\nden verschiedene Arten von Architekturen neuronaler Net-\nze entwickelt, die f\u00fcr die Bearbeitung bestimmter Arten von \nDaten besonders gut geeignet sind. Eine der einflussreichsten \nArchitekturen im Bereich des Deep Learnings sind Convolu-\ntional Neural Networks. W\u00e4hrend klassische neuronale Netze \nwie auch die meisten anderen Ans\u00e4tze des maschinellen Ler -\nnens Merkmale als Eingabe erwarten, k\u00f6nnen Convolutional \nNeural Networks Rohdaten wie Bilder direkt verarbeiten. Man \nspricht hier von Ende-zu-Ende-Lernen. Dies wird erm\u00f6glicht, \nindem spezielle, mit Filtern ausgestattete Schichten eingef\u00fchrt \nwerden, mittels derer eine bestimmte Information aus den Bil-\ndern herausgefiltert werden kann. Mathematisch entspricht \ndies der Operation der Faltung (convolution). Dabei werden \nnach und nach bessere Datenrepr\u00e4sentationen aufgebaut. In \nder Bilderkennung etwa entwickelt das Netzwerk zun\u00e4chst \nKontrastfilter, die helle und dunkle Bereiche voneinander 105unterscheiden, dann Filter, die beispielsweise Konturen oder \nEcken erkennen, und schlie\u00dflich Filter f\u00fcr komplexere visuelle \nKomponenten (ein Geb\u00e4ude oder ein Rad) und die komposi-\ntionelle Repr\u00e4sentation ganzer Gegenst\u00e4nde oder Szenen. F\u00fcr \nverschiedene Arten von Daten (Text, Bild, Messreihen) und \nProblemen (Klassifikation, Segmentierung, Generierung) gibt \nes verschiedene Netzwerkarchitekturen, die sich insbesondere \nin den letzten Jahren entwickelt oder weiterentwickelt haben.\nIm Unterschied zum menschlichen Gehirn sind k\u00fcnstli-\nche neuronale Netzwerke jedoch bislang trotz ihrer enormen \nKomplexit\u00e4t und ihrer beachtlichen Datenverarbeitungska-\npazit\u00e4ten auf vergleichsweise enge Aufgabenbereiche ausge-\nrichtet und auch nach wie vor deutlich schlichter. Der 2018 in \nBetrieb genommene SpiNNaker-Supercomputer hat \u00fcber eine \nMillion Rechenkerne, von denen jeder bis zu 256 Nervenzellen \nnachstellen soll.30 Im menschlichen Gehirn sind hingegen ca. \n86 Milliarden Nervenzellen vernetzt.\nLeistungsstarke, auf die Anforderungen neuronaler Netze \nspezialisierte Hardware zusammen mit neuen Methoden und \nArchitekturen erlaubt es, besser mit gro\u00dfen Datenmengen und \nmit unstrukturierten Daten umzugehen, da sie die damit ein-\nhergehenden Komplexit\u00e4ten aufgrund ihrer modularen und \nhierarchischen Struktur besonders gut handhaben und ab-\nbilden kann. Der aktuelle Boom bei vielen KI-Entwicklungen \ngeht entscheidend auf die durch Deep-Learning-Algorithmen \ner\u00f6ffneten M\u00f6glichkeiten zur\u00fcck und diese wiederum auf die \nenorm gestiegenen Datenmengen und Chipleistungen.\n2.2.4 Einsatzbereiche algorithmischer Systeme \nund\u00a0KI\nDie oben beschriebenen kombinierten Entwicklungen von \nHardware und Software, Vernetzung und Datenproduktion \n30\t Garside/Plana\t2020,\t46.106haben vielf\u00e4ltig einsetzbare Anwendungsm\u00f6glichkeiten von \nalgorithmischen Systemen hervorgebracht, die auch immer \nwieder auf gro\u00dfes \u00f6ffentliches Interesse treffen.\nSo gelingt es Computern inzwischen, Menschen in an-\nspruchsvollen Strategiespielen wie Schach und Go zu schla-\ngen. W\u00e4hrend der Schachcomputer Deep Blue den damaligen \nSchachweltmeister Garri Kasparow 1997 noch mithilfe eines \nAlgorithmus besiegte, der im Wesentlichen mittels schneller \nSuche in einer riesigen Datenbank m\u00f6glicher Spielz\u00fcge trium-\nphierte, meistert der 2019 vorgestellte Algorithmus MuZero \ninzwischen Spiele wie Go, Schach und Shogi ganz ohne die Be-\nr\u00fccksichtigung historischer Partien oder Kenntnis der Spiel-\nregeln. Dieser Algorithmus lernt vielmehr durch Versuch und \nIrrtum, indem er gegen sich selbst spielt und ausprobiert, was \ndabei am besten funktioniert.31\nIm Bereich der Sprachverarbeitung erregen derweil regel-\nm\u00e4\u00dfig Leistungsspr\u00fcnge in der Textproduktion Aufsehen. \nDas neuronale Netz des Generative Pre-trained Transformer \n3 (GPT-3) des US-amerikanischen Unternehmens OpenAI \netwa wurde auf Basis einer ausnehmend umfassenden Menge \nan Texten \u2013 darunter die komplette englischsprachige Wikipe-\ndia \u2013 trainiert, bis es ab 2020 selbst Texte produzieren konnte, \nderen maschineller Ursprung oftmals nicht mehr zu erkennen \nwar.32 Das auf GPT-3 aufbauende, im November 2022 ver -\n\u00f6ffentlichte Dialogsystem ChatGPT33 kann auf unterschied-\nlichste Fragen mitunter so \u00fcberzeugend und differenziert re-\nagieren, dass sich selbst Antworten auf komplexe Aufgaben, \nwie die Erstellung wissenschaftlicher Hausarbeiten, nicht von \nqualitativ hochwertigen menschlich verfassten Eingaben un-\nterscheiden lassen.34\nDer Deutsche Ethikrat nimmt in dieser Stellungnah-\nme vier Handlungsfelder in den Blick, in denen der Einsatz \n31\t Schrittwieser\tet\tal.\t2020.\n32\t Brown\tet\tal.\t2020.\n33\t https://openai.com/blog/chatgpt\t[10.02.2023].\n34\t Pretschner\tet\tal.\t2023.107algorithmischer Systeme und K\u00fcnstlicher Intelligenz entwe-\nder schon besonders weitreichende Ver\u00e4nderungen mit sich \ngebracht hat oder dies in n\u00e4herer Zukunft bewirken k\u00f6nnte. \nIm Gesundheitsbereich (vgl. Kapitel 5) beispielsweise stellt die \nAuswertung gro\u00dfer Datenmengen durch maschinelles Lernen \nFortschritte bei Diagnostik und individualisierten Pr\u00e4ven-\ntions- und Therapieempfehlungen in Aussicht35 und kommt \nKI-gest\u00fctzte Software auch in Robotern zunehmend zur An-\nwendung, etwa in der Pflege36, bei Operationen oder in der \nPsychotherapie. Im Bereich der Bildung (vgl. Kapitel 6) gibt \nes nicht erst seit der Coronapandemie vielf\u00e4ltige Ans\u00e4tze, die \nVermittlung von Wissen und Kompetenzen in der Schule mit-\nhilfe datenbasierter, KI-gest\u00fctzter Lehr- und Lernsysteme und \nKI-gest\u00fctztem Unterrichtsmanagement effektiver zu gestal-\nten und besser auf individuelle Belange von Lernenden ein-\nzugehen. Besonders weit in den Alltag vieler Menschen sind \nderweil Entwicklungen im Bereich der \u00f6ffentlichen Kommu-\nnikation und Meinungsbildung (vgl. Kapitel 7) vorgedrungen, \nwo ein Gro\u00dfteil des Informationsaustauschs inzwischen \u00fcber \nalgorithmisch gest\u00fctzte digitale Plattformen und soziale Me-\ndien abl\u00e4uft. Dabei k\u00f6nnen durch Verkn\u00fcpfung vielf\u00e4ltiger \nDaten zunehmend pr\u00e4zise Profile von Einzelpersonen erstellt \nund zur Entwicklung ma\u00dfgeschneiderter kommerziell, aber \nauch politisch motivierter Ansprachen und Angebote verwen-\ndet werden. Auch in der \u00f6ffentlichen Verwaltung (vgl. Kapitel \n8) kann der Einsatz algorithmischer Systeme das Leben vie-\nler Menschen ber\u00fchren, beispielsweise bei der Beurteilung \noder \u00dcberwachung von Personen im Bereich des Sozial- oder \nPolizeiwesens.\n35\t Deutscher\tEthikrat\t2017.\n36\t Deutscher\tEthikrat\t2020a.1082.2.5 Ethische Leitlinien und regulativer Rahmen \nf\u00fcr algorithmische Systeme und KI\nDie vorstehend beschriebenen Entwicklungen von Datenana-\nlysemethoden und Softwaresystemen sowie die damit ver -\nbundenen Ver\u00e4nderungen in vielen Bereichen menschlichen \nHandelns bringen auch Herausforderungen f\u00fcr die Ausgestal-\ntung von Regeln f\u00fcr das menschliche Miteinander mit sich. In \ndiesem Zusammenhang ist bereits eine Reihe von Regularien \nentstanden oder aktuell in der Entwicklung, die hier nur kurz \nbenannt werden.\nEthische Leitlinien\nDie potenziell weitreichenden R\u00fcckwirkungen datengest\u00fctz-\nter algorithmischer Anwendungen auf viele Bereiche der \nmenschlichen Lebenswelt haben in der Industrie wie auch im \nakademischen und zivilgesellschaftlichen Diskurs \u00dcberlegun-\ngen ausgel\u00f6st, wie ein ethisch vertretbarer und gesellschaftlich \nvertr\u00e4glicher Einsatz solcher neuen Technologien gestaltet \nwerden kann. Dieser Austausch hat eine F\u00fclle an Leitlinien \nhervorgebracht \u2013 84 allein nach einer \u00dcbersicht aus dem Jahr \n2019.37 Das Angebot reicht von Kodizes einzelner Unterneh-\nmen wie beispielsweise der Deutschen Telekom38, von SAP39, \nMicrosoft40 oder Google41 \u00fcber Richtlinien von Fachgesell-\nschaften wie dem Institute of Electrical and Electronics Engi-\nneers42 bis hin zu Werken auf nationaler oder internationaler \nEbene. In Deutschland sind hier insbesondere die Stellungnah-\nmen der Datenethikkommission der Bundesregierung43 und \n37\t Jobin/Ienca/Vayena\t2019.\n38\t https://www.telekom.com/en/company/digital-responsibility/details/\nartificial-intelligence-ai-guideline-524366\t[18.01.2023].\n39\t https://www.sap.com/products/artificial-intelligence/ai-ethics.html\t\n[18.01.2023].\n40\t https://www.microsoft.com/en-us/ai/our-approach\t[18.01.2023];\thttps://\nwww.microsoft.com/cms/api/am/binary/RE4pKH5\t[01.02.2023].\n41\t https://ai.google/principles\t[18.01.2023].\n42\t IEEE\t2019.\n43\t Datenethikkommission\tder\tBundesregierung\t2019.109der Enquete-Kommission K\u00fcnstliche Intelligenz des Deut-\nschen Bundestages44 zu nennen, auf internationaler Ebene die \n\u201eEthik-Leitlinien f\u00fcr eine vertrauensw\u00fcrdige KI\u201c der von der \nEurop\u00e4ischen Kommission eingesetzten Hochrangigen Exper -\ntengruppe f\u00fcr k\u00fcnstliche Intelligenz45 und die \u201eRecommenda-\ntion on the Ethics of Artificial Intelligence\u201c der UNESCO46. Es \ngibt inzwischen mehrere Ans\u00e4tze, solche Richtlinien zu kar -\ntieren und aus ihren \u00fcberlappenden Inhalten sowohl Gemein-\nsamkeiten als auch Unterschiede herauszuarbeiten, die sich \naus spezifischen Perspektiven und Interessen der beteiligten \nPersonen und Institutionen ergeben.47\nDabei wurden eine Reihe von Themen identifiziert, die \nweitgehend anwendungsbereichs\u00fcbergreifend bedeutsam er -\nscheinen und daher in den meisten ethischen Leitlinien zu al-\ngorithmischen Systemen und KI eine Rolle spielen. Zu diesen \ngeh\u00f6ren Bedenken hinsichtlich des Schutzes der Privatsph\u00e4re \nebenso wie Fragen, die sich im Zusammenhang mit der Ent-\nwicklung und Funktion von Algorithmen ergeben, beispiels-\nweise zu Voreingenommenheiten und Verzerrungen oder zu \nTransparenz und Verantwortung angesichts weitreichender \nUndurchschaubarkeiten von Ans\u00e4tzen maschinellen Lernens. \nVersuche, die in diesen Kontexten aufgestellten normativen \nForderungen \u00fcbergeordneten ethischen Prinzipien zuzuord-\nnen, ergeben teilweise eine enge Anlehnung an die etablierten \nvier Prinzipien der Medizinethik48 \u2013 Autonomie, Schadens-\nvermeidung, Wohlt\u00e4tigkeit, Gerechtigkeit \u2013, erg\u00e4nzen die-\nse aber h\u00e4ufig um weitere Prinzipien wie Erkl\u00e4rbarkeit und \nmenschliche Kontrolle, die sich auf spezifischere Aspekte von \nDigitalisierung und KI beziehen.\n44\t Deutscher\tBundestag\t2020.\n45\t Hochrangige\tExpertengruppe\tf\u00fcr\tk\u00fcnstliche\tIntelligenz\t2019.\n46\t UNESCO\t2021.\n47\t Fjeld\tet\tal.\t2020;\tFloridi\tet\tal.\t2018;\tHagendorff\t2020;\tJobin/Ienca/Vayena\t\n2019;\tRudschies/Schneider/Simon\t2021.\n48\t Beauchamp/Childress\t2001.110Regulativer Rahmen\nF\u00fcr das Verst\u00e4ndnis des regulativen Rahmens ist hilfreich zu \nsehen, dass Regeln neue Entwicklungen \u2013 auch Bereich des \nZusammenwirkens von Mensch und Maschine \u2013 auf unter -\nschiedliche Weise erfassen k\u00f6nnen. Abstrakte, generelle Re-\ngeln k\u00f6nnen auf ein neues Ph\u00e4nomen angewandt werden, \nohne dass es n\u00f6tig ist, sie in ihrem Wortlaut zu ver\u00e4ndern oder \nneue Regeln f\u00fcr das Ph\u00e4nomen zu schaffen. Bei gesetzlichen \nRegelungen ist es Aufgabe von Rechtswissenschaft und Recht-\nspraxis, die Regeln entsprechend zu interpretieren.\nVor diesem Hintergrund sind f\u00fcr die hier beschriebenen \nsoziotechnischen Entwicklungen beispielsweise Rechtsnor -\nmen relevant, die gar keinen expliziten Technikbezug haben. \nSo kann sich etwa aus den allgemeinen Regeln des Kartellrechts \nergeben, ob es eine verbotene Preisabsprache darstellt, wenn \nvon zwei Unternehmen eingesetzte Preisfindungsalgorithmen \nohne menschliche Steuerung so miteinander interagieren, dass \ndie Preise nicht mehr unabh\u00e4ngig festgelegt werden.49 Aus ge-\nnerellen Vorschriften des Arbeitsrechts k\u00f6nnen sich Grenzen \ndaf\u00fcr ergeben, inwieweit der Arbeitgeber die Leistung von \nMitarbeitenden mithilfe technischer Systeme erfassen darf.50 \nTechnikneutrale Arbeitsschutzbestimmungen sind auch auf \nden Einsatz von Robotern in der Produktion anwendbar.51 \nViele weitere Beispiele lie\u00dfen sich hier anf\u00fchren.52\nZu diesen technikunspezifischen, aber hoch relevanten \nNormen geh\u00f6ren Haftungsregelungen. Sie pr\u00e4gen die Ent-\nwicklungen im Bereich Mensch/Maschine entscheidend.53 \nHaftungsregeln legen fest, wer im Falle eines Schadens daf\u00fcr \n(finanziell) einzustehen hat, unter welchen Voraussetzungen \nund in welchem Umfang. Sie finden sich als bereichsspezifische \n49\t Truby/Brown\t2021.\n50\t Holthausen\t2021;\tWaas\t2022.\n51\t Kollmer,\tin:\tKollmer/Klindt/Schucht\t2021,\t\u00dcberblick\tvor\t\u00a7\u00a01\tRn.\t90\u00a0ff.;\tG\u00fcn-\nther/B\u00f6glm\u00fcller,\tin:\tArnold/G\u00fcnther\t2022,\t\u00a7\u00a04\tRn.\t125\u2013129.\n52\t Im\t\u00dcberblick:\tSchulz/Schmees\t2022.\n53\t Yeung\t2018.111und bereichs\u00fcbergreifende Haftungsregelungen. Auch wenn \nsie nur regeln, wer im Einzelfall nachtr\u00e4glich f\u00fcr Sch\u00e4den \naufkommen muss, wirken sie auf die Herstellung und auf die \nAnwendung technischer Systeme zur\u00fcck. Wenn eine Person \nwei\u00df, dass sie f\u00fcr die Sch\u00e4den haftet, die das System anrichtet, \nso hat sie beispielsweise einen Anreiz, das System intensiver zu \n\u00fcberwachen, seinen Aktionsradius einzuschr\u00e4nken oder eine \nmenschliche Letztentscheidung vorzusehen. Kn\u00fcpft die Haf-\ntung aber gerade an die menschliche Entscheidung an, kann \nder Anreiz andersherum auch gerade dahingehen, die Maschi-\nne selbstst\u00e4ndig \u201elaufen zu lassen\u201c. Es kommt also auf die Aus-\ngestaltung der Haftungsregelungen an.\nEine \u2013 bislang theoretische \u2013 Diskussion zur Haftung be-\ntrifft die Frage, ob nicht eine Situation eintreten kann, in \nder Maschinen so unabh\u00e4ngig von Menschen agieren, dass \nes unangemessen erscheint, den Menschen, der die Maschi-\nne entwickelt oder sie eingesetzt hat, f\u00fcr die Sch\u00e4den, die die \nMaschine anrichtet, haften zu lassen. Wenn die Maschine \nselbst nicht auf Schadenersatz in Anspruch genommen wer -\nden kann, entsteht eine Verantwortungs- und Haftungsl\u00fccke \n(Responsibility Gap) \u2013 Gesch\u00e4digte gingen also leer aus. Eine \nrechtliche Antwort darauf kann sein, den Maschinen selbst \u2013 \noder durch eine Versicherung \u2013 Verm\u00f6gen zuzuordnen, auf \ndas dann im Schadensfall zur\u00fcckgegriffen werden kann.54 Dies \nverweist auf eine noch grunds\u00e4tzliche rechtliche Diskussion, \nn\u00e4mlich ob es irgendwann sinnvoll erscheint, technischen Sys-\ntemen eine eigene Rechtspers\u00f6nlichkeit zuzuweisen, wie man \nes seit Langem bei Organisationen tut (sogenannte juristische \nPersonen).55\nNeben oder anstelle der Anwendung abstrakter, gene-\nreller Regeln k\u00f6nnen sich im politischen Prozess f\u00fcr neue \nPh\u00e4nomene spezielle Normen herausbilden. Als historisches \nBeispiel kann das Stra\u00dfenverkehrsrecht dienen, das auf die \n54\t Denga\t2018;\tBurchardi\t2022.\n55\t Riehm\t2020.112Herausforderungen reagierte, die durch Mobilit\u00e4t mit Kraft-\nfahrzeugen im Vergleich zu Pferdekutschen entstanden. \nDerartige Regeln unterscheiden sich im Hinblick darauf, wie \nexplizit sie an der Technik selbst ansetzen und wie bereichs-\nspezifisch sie sind. Die Regelungskonzepte sind vielf\u00e4ltig.\nNur verh\u00e4ltnism\u00e4\u00dfig wenige deutsche oder europ\u00e4ische \nRegelungen nehmen direkt auf Ph\u00e4nomene, wie sie in dieser \nStellungnahme beschrieben werden, Bezug. Zu den Ausnah-\nmen z\u00e4hlt die Spezialmaterie des deutschen Finanzmarkt-\nrechts, in der das selbstst\u00e4ndige Bieten durch algorithmische \nSysteme geregelt und begrenzt wird, auch um zu verhindern, \ndass es zu einem von Computern ausgel\u00f6sten Finanzcrash \nkommt.56 Ohne das Wort \u201eAlgorithmen\u201c zu erw\u00e4hnen, wur -\nden die Mediengesetze in Deutschland auf Vielfaltsrisiken bei \nder Auffindbarkeit von Medieninhalten erweitert, die durch \nSelektieren und Aggregieren durch sogenannte Intermedi\u00e4re \nausgehen \u2013 gemeint sind Plattformen wie Facebook oder Such-\nmaschinen wie Google (\u00a7 2 Abs. 2 Nr. 16, \u00a7\u00a7 91\u201396 MStV). \nDiese Intermedi\u00e4re m\u00fcssen unter anderem ihre zentralen \nKriterien der Sammlung, Auswahl und Darstellung von In-\nhalten und deren Gewichtung offenlegen (Transparenzgebot); \nzus\u00e4tzlich gilt ein Diskriminierungsverbot. Auch in anderen \nBereichen wurde und wird auf technische Entwicklungen und \nVer\u00e4nderungen durch Gesetzgebung reagiert.57\nDa die Gefahren oft von Akteuren wie international agie-\nrenden IT-Unternehmen ausgehen, gewinnt die Regelung auf \ntransnationaler und insbesondere europ\u00e4ischer Ebene zuneh-\nmend an Bedeutung. Relevanz hat vor allem die Datenschutz-\nGrundverordnung (DSGVO) erlangt, die seit 2018 einen \neinheitlichen europ\u00e4ischen Rahmen f\u00fcr den Schutz personen-\nbezogener Daten zur Verf\u00fcgung stellt. Art. 22 DSGVO enth\u00e4lt \ndas Recht, nicht einer Entscheidung unterworfen zu sein, die \nausschlie\u00dflich auf einer automatisierten Datenverarbeitung \n56\t Kurth,\tin:\tEbers\tet\tal.\t2020,\t\u00a7\u00a014.\n57\t Im\t\u00dcberblick:\tGuckelberger\t2019;\tHoffmann-Riem\t2022.113beruht; es gibt allerdings Ausnahmen.58 Diese Regelungen sind \nzu einem Referenzpunkt der Diskussion \u00fcber automatisiertes \nEntscheiden geworden, da auch grunds\u00e4tzliche Fragen wie das \nRecht auf Eingreifen durch einen Menschen (Human-in-the-\nLoop)59 und auf aussagekr\u00e4ftige Informationen zur involvier -\nten Logik60 vorgesehen sind.\nSpezifische Gefahren K\u00fcnstlicher Intelligenz will die Eu-\nrop\u00e4ische Union mit einem neuen Rechtsakt regeln, dem \nArtificial Intelligence Act.61 Der Gesetzgebungsprozess zeigt \nallerdings auch, wie schwer es ist, Ph\u00e4nomene wie KI f\u00fcr die \nRechtsanwendung handhabbar zu definieren und ad\u00e4quate \nSchutzkonzepte (etwa abgestuft nach Risiken) zu entwickeln. \nRechtlich nicht bindende Empfehlungen gibt es in diesem Be-\nreich bereits.62 Ein weiteres Gesetzgebungspaket hat Daten als \nReferenzpunkt: Der Data Governance Act trat im Juni 2022 \nin Kraft und schafft Prozesse, Strukturen und einen Rechts-\nrahmen f\u00fcr die gemeinsame Nutzung von personenbezogenen \nund nicht personenbezogenen Daten. Ein weiter gehender \nData Act ist in Vorbereitung. Auch das Gesetzespaket f\u00fcr di-\ngitale Dienste, das die Europ\u00e4ische Union 2022 erlassen hat, \nbestehend aus dem Digital Markets Act und dem Digital Ser -\nvices Act, hat im vorliegenden Zusammenhang Bedeutung. \nBeide Gesetze stellen Regeln f\u00fcr die gro\u00dfen Plattformen und \nGatekeeper der digitalen \u00d6konomie auf, die auch im Bereich \nder Entwicklung und Anwendung von technischen Systemen \nf\u00fchrend sind.63\nDer Regelungsrahmen wird zentral durch rechtliche Nor -\nmen wie die genannten (und zahlreiche weitere) bestimmt, \naber nicht vollst\u00e4ndig. Selbstregulierung vor allem durch \ndie Industrie (etwa durch oben bereits erw\u00e4hnte freiwillig \n58\t Laue\t2016.\n59\t Buckley\t2021.\n60\t Kumkar/Roth-Isigkeit\t2020.\n61\t Bomhard/Merkle\t2021;\tGeminn\t2021.\n62\t Kettemann\t2022;\tAd\tHoc\tCommittee\ton\tArtificial\tIntelligence\t2021;\tOECD\t\n2019.\n63\t Eifert\tet\tal.\t2021;\tGielen/Uphues\t2021.114erlassene Kodizes) ist ebenso Teil des Regelungsrahmens, wie \nes beispielsweise Vertr\u00e4ge etwa zwischen Plattformen und \nNutzenden sind, in denen wiederum Verhaltensregeln festge-\nlegt werden (etwa Community-Standards).64 Das normative \nSystem wird dadurch noch komplexer, dass etwa Grund- und \nMenschenrechte nicht nur staatliche Stellen binden, sondern \u2013 \njedenfalls nach deutschem Rechtsverst\u00e4ndnis \u2013 indirekt auch \nUnternehmen anhalten, etwa die Meinungsfreiheit der Perso-\nnen, die ihr Angebot nutzen, zu wahren. Zudem hat sich in der \nwissenschaftlichen Beobachtung die Erkenntnis durchgesetzt, \ndass die existierenden technischen Elemente ihrerseits eine \nnormative Wirkung entfalten, die die Entwicklung pr\u00e4gt. Erst \nin der Zusammenschau all dieser Elemente zeigt sich der rele-\nvante Regelungsrahmen f\u00fcr das Verh\u00e4ltnis von Mensch und \nMaschine.\nIn dieser Stellungnahme befasst sich der Deutsche Ethikrat \nnicht im Detail mit dem hier kurz umrissenen reichhaltigen \nFundus an ethischen Leitlinien und aktuellen wie noch in der \nErarbeitung befindlichen rechtlichen Regulierungsans\u00e4tzen, \nsondern kn\u00fcpft auf einer anderen Ebene an diesen Rahmen \nan. Die in den folgenden zwei Kapiteln vorgelegte Analyse der \nKonsequenzen digitaler Entwicklungen f\u00fcr das menschliche \nZusammenleben gr\u00fcndet auf einer philosophischen Ausei-\nnandersetzung mit den anthropologischen Grundbegriffen, \ndie im Mittelpunkt des menschlichen Selbstverst\u00e4ndnisses \nstehen (vgl. Kapitel 3), und entwickelt darauf aufbauend ein \nVerst\u00e4ndnis von Mensch-Technik-Relationen, demzufolge es \nentscheidend darauf ankommt, wie die Delegation menschli-\ncher T\u00e4tigkeiten an Maschinen und algorithmische Systeme \nauf zentrale anthropologische Konzepte zur\u00fcckwirkt und da-\nbei insbesondere menschliche Autorschaft erweitert oder ver -\nmindert (vgl. Kapitel 4). Im zweiten Teil der Stellungnahme \nwird dieses Konzept auf die vier ausgew\u00e4hlten Handlungsfel-\nder Gesundheit, Bildung, Kommunikation und Verwaltung \n64\t Wielsch\t2018;\tKumkar\t2022;\tMast\t2023.115angewendet und m\u00fcndet jeweils in bereichsspezifische Emp-\nfehlungen, bevor im dritten Teil die sektor\u00fcbergreifend identi-\nfizierten normativen Querschnittsthemen noch einmal n\u00e4her \nbeleuchtet werden.1163\t \t ZENTRALE \tBEGRIFFE \tUND\t\nPHILOSOPHISCHE \tGRUNDLAGEN\n3.1\t\t K\u00fcnstliche\tIntelligenz:\tbegriffliche\t\nAnalyse\nDer Begriff der K\u00fcnstlichen Intelligenz wurde und wird kei-\nneswegs immer einheitlich verwendet: Seine Bedeutung hat \nsich im Laufe der Jahre ver\u00e4ndert und unterscheidet sich so-\nwohl innerhalb als auch zwischen verschiedenen Berufsgrup-\npen und Disziplinen. Eine Unterscheidung, welche in der KI-\nForschung selbst, mehr noch aber in der Reflexion sowie der \nmedialen und \u00f6ffentlichen Debatte \u00fcber KI eine gro\u00dfe Rolle \nspielt, ist die Unterscheidung zwischen sogenannter schwa -\ncher und starker KI.65 W\u00e4hrend sich insbesondere die aktuelle \nForschung innerhalb der Informatik vorrangig mit Fragen der \nschwachen KI besch\u00e4ftigt, sind \u00f6ffentliche Debatten ebenso \nwie manche Fachdiskurse regelm\u00e4\u00dfig gepr\u00e4gt von Visionen \neiner starken \u2013 also menschen\u00e4hnlichen oder gar menschli-\nche F\u00e4higkeiten \u00fcbertreffenden \u2013 KI, die mit Sorgen ebenso \nwie mit Hoffnungen behaftet ist. Um die hinter den jeweiligen \nBegriffsverwendungen stehenden substanziellen Annahmen \n\u00fcber die Grundlagen menschlicher Intelligenz und KI her -\nauszuarbeiten, ist eine Kl\u00e4rung der Begriffe notwendig. Dabei \nzeigt sich, dass unterschiedliche Einsch\u00e4tzungen hinsichtlich \nder Wahrscheinlichkeit und dem Erw\u00fcnschtsein einer starken \nKI auch von unterschiedlichen Konzeptualisierungen des mit \nKI umschriebenen Ph\u00e4nomenbereichs abh\u00e4ngen.\nNeben der heute h\u00e4ufig im Kontext der Reflexion auf KI \nvornehmlich verwendeten Unterscheidung von starker versus \nschwacher KI, sind in der Geschichte der KI und auch in der \n65\t Nida-R\u00fcmelin\t2022a;\t2022b.117gegenw\u00e4rtigen internationalen Debatte andere Unterschei-\ndungen in Gebrauch, um unterschiedliche Formen oder Gra-\nde der Ann\u00e4herung von KI an menschliche Intelligenz zu be-\nschreiben. Dies sind insbesondere die nachfolgend noch n\u00e4her \nbetrachteten Unterscheidungen von spezieller versus allgemei-\nner/genereller KI sowie enger  versus breiter KI. Dar\u00fcber hinaus \nwerden in den letzten Jahren, vor allem im Kontext des Trans-\nhumanismus66 sowie der Diskussionen um Singularit\u00e4t67, die \nBegriffe Artificial General Intelligence oder Super-Intelligence \nverwendet, die im Folgenden allerdings keine Rolle spielen \nwerden.\nDen jeweiligen Unterscheidungen liegt trotz einzelner Be-\ndeutungsunterschiede das Bem\u00fchen zugrunde, menschliche \nIntelligenz als Ma\u00dfstab der Bestimmung von KI heranzuzie-\nhen. \u00dcber diesen Ma\u00dfstab glaubt man zu verf\u00fcgen, weil In-\ntelligenztests eine (wenn auch in Grenzen) erfolgreiche Ope-\nrationalisierung des Begriffs der Intelligenz erlauben (vgl. \nAbschnitt 3.2.1). Auf dieser Grundlage erscheint es m\u00f6glich, \nmenschliche Intelligenz zu simulieren bzw. das Vorliegen \nvon Intelligenz in Maschinen identifizieren und messen zu \nk\u00f6nnen. Eine Simulation menschlicher Intelligenz stand lan-\nge im Zentrum der Forschung zu KI und der Reflexion \u00fcber \nihre M\u00f6glichkeiten und Grenzen. Auch wenn Methoden der \nKI f\u00fcr ganz andere Zwecke verwendet werden, beispielsweise \ndie Nutzung zur Auswahl passender Werbung, so gilt seit der \nVer\u00f6ffentlichung von Turings \u201eCan machines think?\u201c im Jahr \n1950 und seiner Formulierung des ber\u00fchmten Turing-Tests \n66\t Unter\tTranshumanismus\twerden\tPositionen\tverstanden,\twonach\tdie\tdigita-\nlen\tTechnologien\tes\tuns\terlauben,\tdie\tBeschr\u00e4nktheiten\tder\tmenschlichen\t\nExistenzform\tzu\t\u00fcberwinden,\tund\twir\tdiese\tM\u00f6glichkeiten\tnutzen\tsollten,\t\num\talte\tMenschheitstr\u00e4ume\tzu\tverwirklichen,\twie\tdie\teiner\tdurch\tVerbin-\ndungen\tvon\tGehirn\tund\tComputer\t(Brain\tComputer\tInterfaces)\terzeugten\t\nVervielfachung\tder\tIntelligenz\toder\tder\tindividuellen\tFortexistenz\tin\tForm\t\neiner\tSoftwarekopie\tdes\teigenen\tGehirns.\n67\t Der\tBegriff\tder\tSingularit\u00e4t\tverweist\tauf\teinen\tm\u00f6glichen\tUmschlagpunkt\t\nin\tder\tZukunft,\tab\tdem\tK\u00fcnstliche\tIntelligenz\tmenschliche\tIntelligenz\tin\t\njeder\tHinsicht\t\u00fcbertreffen\tund\tsich\tfortan\tunkontrolliert\tselbst\tweiterent -\nwickeln\tk\u00f6nnte.118(vgl. Abschnitt 2.1) die \u00e4u\u00dfere Ununterscheidbarkeit zwischen \nmenschlichen und maschinellen kognitiven und operativen \nLeistungen weithin als \u201eLackmustest\u201c f\u00fcr das Vorliegen von \nKI.\nDie Unterscheidung zwischen spezieller und allgemeiner/\ngenereller KI wurde in den 1950er-Jahren eingef\u00fchrt, um die \ndamals aktuelle Forschung zu KI von der Vision einer men-\nschen\u00e4hnlichen KI abzugrenzen. W\u00e4hrend Maschinen zu-\nmeist f\u00fcr spezielle T\u00e4tigkeiten konstruiert sind, kennzeichnet \nmenschliche Intelligenz eine Vielfalt von Kompetenzen und \nein weites Spektrum unterschiedlicher Zwecksetzungen. Man \nerhoffte sich vom Computer von Anbeginn das Potenzial ei-\nner \u201euniversellen Maschine\u201c, die alle Aufgaben l\u00f6sen k\u00f6nne, \ndie sich bin\u00e4r, zum Beispiel als eine Abfolge von Nullen und \nEinsen, darstellen lie\u00dfen.68 Die Hoffnung war, dass der Com-\nputer eine generelle KI erreichen k\u00f6nnte, die \u00fcber das L\u00f6sen \nspezifischer Aufgaben weit hinausgeht. Ein Ziel der fr\u00fchen \nForschung war die Entwicklung des Computers zum General \nProblem Solver. Dieser sollte basierend auf menschlichen Heu-\nristiken Probleml\u00f6sestrategien f\u00fcr ausreichend formalisierba-\nre Probleme in verschiedenen Kontexten liefern. Er kann als \nVorl\u00e4ufer heutiger Expertensysteme gelten. Die Komplexit\u00e4t \nder Aufgaben, die mit ihm gel\u00f6st werden konnten, blieb aller -\ndings beschr\u00e4nkt. Die Vision einer allgemeinen KI jedoch hat \nbis heute Bestand.\nDas Begriffspaar speziell und allgemein enthielt zumeist \nsowohl explizite Annahmen \u00fcber die Breite des F\u00e4higkeiten-\nspektrums einer KI als auch Erwartungen zur grundlegenden \nQualit\u00e4t der zuk\u00fcnftig daraus resultierenden KI (bis hin zum \nontologischen Status). Entsprechend wurde im Verlauf weiter \ndifferenziert. Etabliert sind inzwischen die Unterscheidungen \nzwischen enger  und breiter KI sowie schwacher und starker KI. \nDie Forschung zu KI ist heute zumeist auf einen klar umris-\nsenen Anwendungsbereich begrenzt, etwa die Interpretation \n68\t Moor\t1985.119von R\u00f6ntgenaufnahmen, und somit ein Fall von enger KI. \nDoch auch hier besteht die Vision einer breiten Ausweitung \ndes Spektrums. Dabei ist zu betonen, dass die Unterscheidung \nzwischen engen und breiten Formen der KI, ebenso wie die \nBegriffe speziell und allgemein, nicht als Gegens\u00e4tze zu verste-\nhen sind, sondern jeweils Endpunkte eines F\u00e4higkeitenspekt-\nrums beschreiben.\nEin aktueller Bereich, in dem die Frage nach breiter KI \nverhandelt wird, umfasst Sprachverarbeitungssysteme wie das \nim vorherigen Kapitel bereits erw\u00e4hnte GPT-3 und ChatGPT. \nSolche Systeme produzieren Texte, bei denen oft schwer oder \nunm\u00f6glich zu erkennen ist, ob sie von einem Menschen oder \neiner Maschine verfasst wurden. Erste pr\u00e4gnante Beispiele \nentfachten eine intensive philosophische und auch \u00f6ffentli-\nche Debatte dazu, ob diese Form der Textproduktion nur eine \nVerbreiterung des F\u00e4higkeitenspektrums darstellt oder bereits \nals ein \u00dcbergang zur oder gar eine Manifestation einer gene-\nrellen oder starken KI gelten k\u00f6nne \u2013 wenn auch nur mit Blick \nauf das Sprachverm\u00f6gen.69\nDie Verwendung der verschiedenen Begriffe zur Charak-\nterisierung K\u00fcnstlicher Intelligenz als spezifischer, enger oder \nschwacher KI einerseits sowie allgemeiner, breiter oder star -\nker KI andererseits verweist nicht nur auf Differenzen zwi-\nschen den beiden jeweiligen Arten bzw. Polen von Intelligenz. \nDahinter verstecken sich, insbesondere beim Begriffspaar \nder schwachen und starken KI, vielmehr auch unterschied-\nliche Verst\u00e4ndnisse von Intelligenz sowie unterschiedliche \n69\t Der\tTitel\teines\tArtikels\tdes\tMIT\tTechnology\tReview\tfasst\tdiese\tDebatte\t\nmit\tBlick\tauf\tGPT-3\tzusammen:\t\u201eOpenAI\u2019s\tnew\tlanguage\tgenerator\t\nGPT-3\tis\tshockingly\tgood\t\u2013\tand\tcompletely\tmindless\u201c\t(https://www.\ntechnologyreview.com/2020/07/20/1005454/openai-machine-learning-\nlanguage-generator-gpt-3-nlp\t[22.12.2022]).\tDieser\tspielt\tauf\tdie\t\nKritik\tvon\tJohn\tSearle\tan\t(vgl.\tAbschnitte\t3.1\tund\t3.4.2).\tMit\tBlick\tauf\t\nj\u00fcngere\tChatbots\tl\u00f6ste\t2022\tzudem\tder\tehemalige\tGoogle-Mitarbeiter\t\nBlake\tLemoine\teine\tDebatte\taus,\tals\ter\tpostulierte,\tder\tvon\tGoogle\t\nentwickelte\tChatbot\tLaMDA\tsei\tbei\tBewusstsein\t\u2013\tein\tVorsto\u00df,\tder\t\nsp\u00e4ter\tzu\tseiner\tEntlassung\tf\u00fchrte\t(https://www.washingtonpost.com/\ntechnology/2022/06/11/google-ai-lamda-blake-lemoine\t[31.01.2023]).120Positionen hinsichtlich der Kernfrage, ob es qualitative und \nkategorische oder nur quantitative und prinzipiell \u00fcberwind-\nbare Unterschiede zwischen menschlicher Intelligenz und KI \ngibt.\nWichtig f\u00fcr die jeweilige Beantwortung dieser Frage ist \nzum einen die Differenz hinsichtlich der Breite bzw. Enge \ndes F\u00e4higkeitenspektrums der KI. Die meisten Anwendungen \nentfalten ihre jeweilige Leistung auf klar umrissenen, engen \nGebieten oder Dom\u00e4nen wie beispielsweise dem Spielen von \nSchach oder Go. Hier sind sie im direkten Vergleich Men-\nschen inzwischen klar \u00fcberlegen. Sprachproduktionssysteme \nwiederum sind zwar ebenfalls auf einen Kompetenzbereich \nbeschr\u00e4nkt (sprachliche Ein- und Ausgabe), jedoch mittler -\nweile nicht mehr auf eine Dom\u00e4ne, \u00fcber die gesprochen wird; \nhier erfolgt also eine jedenfalls funktionelle Verbreiterung des \nF\u00e4higkeitenspektrums. Dennoch fehlt auch ihnen jedwedes \nsprachliche Verst\u00e4ndnis \u00fcber die Bedeutung der rezipierten \noder produzierten Worte, operieren sie doch allein auf Basis \nder Wahrscheinlichkeit von Wortkombinationen.\nZum anderen hatte der Philosoph John Searle schon 1980 \ngegen den Turing-Test die These aufgestellt, dass die blo\u00dfe \nUnunterscheidbarkeit von menschlicher und maschineller \nSprachperformanz nicht ausreicht, um ein Textverst\u00e4ndnis an-\nzunehmen.70 Hier geht es also zus\u00e4tzlich darum, ob es jenseits \neiner quantitativen Differenz auch einen kategorialen Unter -\nschied zwischen Mensch und Maschine gibt, beziehungsweise \ndarum, ob Intelligenz an bestimmte mentale Voraussetzun-\ngen gekn\u00fcpft ist, welche \u00fcber die blo\u00dfe Simulation von Ver -\nst\u00e4ndnis hinausgehen. Anders formuliert ergibt sich also die \nFrage, ob Intelligenz in allgemeiner oder starker Form jemals \n70\t Searle\t1980.\tSearles\tGedankenexperiment\tund\tseine\tKritik\twerden\tausf\u00fchr -\nlicher\tim\tAbschnitt\t3.4\tbehandelt.121vollumf\u00e4nglich Maschinen zukommen kann oder ob daf\u00fcr \nspezifisch menschliche Eigenschaften Voraussetzung sind.71\nDie Differenzen hinter den Begriffspaaren schwache versus \nstarke, enge versus breite und spezielle versus allgemeine KI \nlassen sich vor diesem Hintergrund wie folgt zusammenfassen:\nZum einen geht es um die Breite der F\u00e4higkeiten, \u00fcber die \neine KI verf\u00fcgt, sowohl graduell innerhalb von Dom\u00e4nen (z. B. \nSprachverarbeitung) als auch bereichs\u00fcbergreifend (z. B. Spra-\nche und Motorik, Situationserfassung). Zum anderen geht es \num die Antwort auf die Frage, ob die Simulation von Intelli-\ngenz  mit Intelligenz gleichzusetzen ist oder ob es einen katego-\nrischen Unterschied zwischen der Simulation von Verst\u00e4ndnis \nund genuinem (z. B. sprachlichem) Verst\u00e4ndnis gibt, der f\u00fcr \n\u201eechte\u201c Intelligenz essenziell ist, \u00fcber die jedenfalls die in die-\nser Stellungnahme diskutierten Systeme nicht verf\u00fcgen.72\nAm Beispiel der Sprachproduktionssysteme lassen sich die \nvorgestellten unterschiedlichen Verst\u00e4ndnisse von KI noch \neinmal veranschaulichen. Bereits die Antwort auf die Frage, ob \nsie Beispiele f\u00fcr breite bzw. allgemeine KI sind, h\u00e4ngt von den \njeweiligen Annahmen ab: Zwar sind einzelne Sprachprodukti-\nonssysteme nicht auf eine Dom\u00e4ne beschr\u00e4nkt und haben so-\nmit ein durchaus breites Funktionenspektrum. Um allerdings \ndie Anforderungen an breite bzw. allgemeine KI zu erf\u00fcllen, \nw\u00fcrde gemeinhin verlangt, dass das System nicht nur im Be-\nreich der Sprache menschliche Kompetenz (nahezu) perfekt \nsimuliert, sondern dies eben auch zeitgleich in (allen) anderen \nBereichen vermag, die gemeinhin im menschlichen Kontext \nals intelligentes Verhalten klassifiziert werden, wie beispiels-\nweise koordinierte Bewegung im Raum. Tats\u00e4chlich deuten \nbestimmte, auch bei sehr guten Sprachproduktionssystemen \n71\t Die\tFrage\ttierlicher\tIntelligenz\twird\tim\tRahmen\tdieser\tStellungnahme\t\nausgeklammert;\tvgl.\tdazu\tHuber\t2021.\tZur\tgrunds\u00e4tzlicheren\tFrage\tnach\t\nmentalen\tZust\u00e4nde\tbei\tTieren\tvgl.\tDeutscher\tEthikrat\t2020b.\n72\t Umstritten\tblieb,\tob\tdiese\tAussage\tsich\tlediglich\tauf\tdie\taktuellen\tSysteme\t\nund\tdie\tder\tabsehbaren\tZukunft\tbezieht\toder\tgrunds\u00e4tzlich\tzu\tverstehen\t\nist.122auftretende Fehlleistungen darauf hin, dass die hohe Leis-\ntungsf\u00e4higkeit nicht auf einem inhaltlichen Verst\u00e4ndnis der \nTexte beruhen kann. Allgemein intelligentes Verhalten ist \nbei den gegenw\u00e4rtigen Systemen schon funktional noch in \nweiter Ferne und bed\u00fcrfte zudem auch noch des Einbaus in \neinen physischen humanoiden Roboter. In einem humanoi-\nden Roboter mit perfekten Bewegungsf\u00e4higkeiten und einer \nmenschen\u00e4hnlichen Mimik und Gestik w\u00fcrden manche ein \nBeispiel breiter oder gar starker KI sehen, wenn er in der Lage \nw\u00e4re, alle menschlichen kognitiven F\u00e4higkeiten perfekt zu si-\nmulieren. Andere w\u00fcrden hingegen bestreiten, dass damit eine \nForm starker KI vorliegt, da auch eine perfekte Simulation \nnicht garantiere, dass ein solcher humanoider Roboter menta-\nle Zust\u00e4nde aufweist, \u00fcber Einsichts- und Urteilsf\u00e4higkeit so-\nwie \u00fcber emotive Einstellungen wie Hoffnungen und \u00c4ngste \nverf\u00fcgt.\nDie unterschiedlichen Konzeptionen hinter den diversen \nBegrifflichkeiten zur KI gehen auch auf verschiedene grund-\nlegende anthropologische Theoriemodelle zur\u00fcck (vgl. Ab-\nschnitt 3.4). Aus behavioristischer Sicht ist die Unterscheidung \nzwischen Simulans und Simulandum nicht sinnvoll, da diese \nepistemisch nicht unterscheidbar seien. In anderen Konzep-\ntionen (z. B. ph\u00e4nomenologische Positionen oder solche der \nintentionalistischen Semantik) jedoch werden mentale Zu-\nst\u00e4nde realistisch, das hei\u00dft als Merkmale der ontologischen \nAusstattung der Welt interpretiert. In solchen Konzeptionen \nwird an einer kategorischen Unterscheidung zwischen Simula-\ntion und Realisierung festgehalten, auch wenn diese Differenz \nepistemisch nicht unmittelbar zug\u00e4nglich ist. Entscheidend \nf\u00fcr den Unterschied zwischen menschlicher Intelligenz und KI \nist demnach das Vorhandensein bestimmter mentaler Eigen-\nschaften wie beispielsweise Verst\u00e4ndnis oder Bewusstsein. In \ndieser Stellungnahme werden die Begriffe zur Charakterisie-\nrung der unterschiedlichen Formen K\u00fcnstlicher Intelligenz in \nder unten stehenden Weise verwendet. Es wird hierbei voraus-\ngesetzt, dass die Unterscheidung zwischen enger und breiter 123KI quantitativer bzw. gradueller Natur ist, die Entstehung einer \nstarken KI jedoch einen qualitativen Sprung bedeuten w\u00fcrde:\n>> Enge KI: KI-Anwendungen, die menschliche F\u00e4higkeiten in \neiner Dom\u00e4ne simulieren bzw. Verfahren wie maschinelles \nLernen verwenden, um spezifische Aufgaben zu erf\u00fcllen \noder spezifische Probleme zu l\u00f6sen. Nahezu alle derzeit \nverwendeten KI-Anwendungen fallen in diese Kategorie.\n>> Breite KI: Breite KI-Anwendungen erweitern das Spekt-\nrum ihrer Anwendbarkeit \u00fcber einzelne Dom\u00e4nen hin-\naus. Sprachproduktionssysteme wie etwa GPT-3 k\u00f6nnen \nals Beispiele f\u00fcr breiter werdende KI gelten, da sie zwar \nnicht dom\u00e4nenspezifisch, jedoch weiterhin auf sprachli-\nche Ein- und Ausgabe beschr\u00e4nkt sind. Eine m\u00f6gliche Zu-\nkunftsvision breiter KI w\u00e4ren Systeme, die solche Sprach-\nkompetenzen mit weiteren kognitiven oder motorischen \nKompetenzen zusammenf\u00fchren, etwa durch Einbau in \nweitentwickelte Roboter.\n>> Starke KI: Der Begriff der starken KI wird f\u00fcr die Vision \neiner K\u00fcnstlichen Intelligenz verwendet, die jenseits der \nm\u00f6glicherweise perfekten Simulation menschlicher Kogni-\ntion auch \u00fcber mentale Zust\u00e4nde, Einsichtsf\u00e4higkeit und \nEmotionen verf\u00fcgen w\u00fcrde.\n3.2\t\t Intelligenz\tund\tVernunft\n3.2.1 Intelligenz\nDie im vorigen Abschnitt vorgestellten unterschiedlichen \nDeutungen von KI werden seit mindestens den 1970er-Jah-\nren von kontroversen Diskussionen der Frage begleitet, was \nComputer k\u00f6nnen und nicht k\u00f6nnen bzw. demn\u00e4chst k\u00f6nnen \nund nicht k\u00f6nnen werden.73 Um diese Frage zu beantworten, \n73\t Dreyfus\t1992.124m\u00fcsste zun\u00e4chst gekl\u00e4rt werden, von welchen Vorstellungen \nhinsichtlich der menschlichen Intelligenz dabei ausgegangen \nwird. Dazu wird jedoch in den sich damit besch\u00e4ftigenden \nWissenschaften, insbesondere der Psychologie, Philosophie \nund Informatik, keine einheitliche Antwort angeboten.\nAus psychologischer Perspektive ist Intelligenz als ein hy-\npothetisches Konstrukt aufzufassen, das als solches zwar verbal \numschrieben werden kann, zum Beispiel im Sinne von Verste-\nhen, Urteilen und Schlussfolgern74 oder zielgerichtetem Han-\ndeln, rationalem Denken und effektiver Auseinandersetzung \nmit der Umwelt75, aber nicht beobachtbar ist, sondern anhand \nvon Indikatoren in relevanten Aspekten operationalisiert wer -\nden muss. In diesem Sinne sind Intelligenztests als Situationen \naufzufassen, in denen Menschen Verhalten zeigen k\u00f6nnen, das \nvor dem Hintergrund eines theoretischen Vorverst\u00e4ndnisses \noder einer zugrunde gelegten Definition als mehr oder weni-\nger \u201eintelligent\u201c bezeichnet werden kann. Dabei k\u00f6nnen die \ngew\u00e4hlten Operationalisierungen \u2013 auf der Ebene von Teil-\nkomponenten und Subskalen wie auf der Ebene von Testitems \n\u2013 sehr unterschiedlich sein. Sie bew\u00e4hren sich im Kontext der \nBestimmung von G\u00fctekriterien, auf deren Grundlage abge-\nsch\u00e4tzt werden kann, inwieweit die Durchf\u00fchrung, Auswer -\ntung und Interpretation der Testung als objektiv, verl\u00e4sslich \n(reliabel) und valide angesehen werden k\u00f6nnen.\nIntelligenz wird hier im Sinne eines Abweichungsquotien-\nten verstanden; der Mittelwert des (normalverteilten) Merk-\nmals liegt in der Grundgesamtheit per definitionem bei 100, \ndie Standardabweichung bei 15.76 Dies hat Auswirkungen auf \ndie Testkonstruktion, denn bei der Auswahl potenzieller Testi-\ntems muss ber\u00fccksichtigt (gesch\u00e4tzt) werden, wie sich diese in \nder Grundgesamtheit verteilen, mit anderen Items korrelieren \nund zwischen verschiedenen F\u00e4higkeitsniveaus unterscheiden. \n74\t Binet/Simon\t1905.\n75\t Wechsler\t1944.\n76\t Das\tbedeutet,\tdass\tca.\t68\tProzent\tder\tMenschen\teinen\tIQ\tzwischen\t85\tund\t\n115\tsowie\tca.\t95\tProzent\teinen\tIQ\tzwischen\t70\tund\t130\taufweisen.125Bei der Validierung von Intelligenztests interessieren Korrela-\ntionen mit anderen Verfahren und Merkmalen, die aus the-\noretischer Perspektive als Indikatoren der Auspr\u00e4gung ver -\nwandter und nicht verwandter Konstrukte betrachtet werden \nk\u00f6nnen und deshalb eine bestimmte H\u00f6he aufweisen bzw. \ndiese nicht \u00fcberschreiten sollten. Dar\u00fcber hinaus ist die M\u00f6g-\nlichkeit, auf der Grundlage aktueller Messwerte zuk\u00fcnftige \nLeistungen bzw. interindividuelle Unterschiede in relevanten \nMerkmalen (z. B. Erfolg versus Misserfolg in Schule oder Be-\nruf) zu prognostizieren, von gro\u00dfem Interesse.\nDie Wechsler Adult Intelligence Scale, auf der die bekann-\ntesten modernen Intelligenztests aufbauen, wurde 1955 von \nDavid Wechsler vorgestellt und bereits 1956 in einer deutsch-\nsprachigen Version, dem Hamburg-Wechsler-Intelligenztest \nf\u00fcr Erwachsene, ver\u00f6ffentlicht. Die aktuelle Version des Tests \nbesteht aus 15 Untertests (zehn Kerntests und f\u00fcnf optiona-\nle Untertests), welche unterschiedliche kognitive F\u00e4higkeiten \npr\u00fcfen, die in vier Indizes zusammengefasst werden: Sprach-\nverst\u00e4ndnis, wahrnehmungsgebundenes logisches Denken, \nArbeitsged\u00e4chtnis und Verarbeitungsgeschwindigkeit.77 Hier -\nbei ist wichtig festzuhalten, dass es keine Aufgaben gibt, die \ndiese Dimensionen direkt messen. Vielmehr sind die verwen-\ndeten Skalen induktiv aus den im Kontext der Testkonstrukti-\non und -normierung empirisch ermittelten Korrelationen zwi-\nschen Unterskalen und Au\u00dfenkriterien abgeleitet. Das hei\u00dft, \ndie Struktur der Intelligenz ergibt sich wesentlich induktiv aus \nder empirischen Erfassung und Validierung unterschiedlicher, \naus dem theoretischen Vorverst\u00e4ndnis der Testautorschaft ab-\ngeleiteten Aspekte bzw. Dimensionen kognitiver Leistungsf\u00e4-\nhigkeit (z. B. der Orientierung an einem Generalfaktormodell \nin der Tradition von Charles Spearman versus einem Modell \nvoneinander unabh\u00e4ngiger Prim\u00e4rfaktoren in der Tradition \nvon Louis Leon Thurstone).78\n77\t Petermann\t2012,\t21.\n78\t Sternberg\t2020.126Die Frage, ob Intelligenz eine einheitliche F\u00e4higkeit ist oder \nviele F\u00e4higkeiten umfasst, die gegebenenfalls auch voneinan-\nder unabh\u00e4ngig sein k\u00f6nnen, ist empirisch nicht eindeutig zu \nkl\u00e4ren \u2013 die dimensionale Struktur wird auf der Grundlage \nvon vorab festgelegten Modellannahmen bzw. Restriktionen \nermittelt, die ihrerseits nicht Gegenstand einer empirischen \n\u00dcberpr\u00fcfung werden k\u00f6nnen. Allerdings l\u00e4sst sich festhalten, \ndass empirisch durchweg positive Korrelationen zwischen den \nverschiedenen Untertests bzw. Indizes nachzuweisen sind. Im \nerw\u00e4hnten Wechsler-Intelligenztest bedeutet dies etwa, dass \nh\u00f6here Werte in den Untertests des Index Sprachverst\u00e4ndnis \nstatistisch mit h\u00f6heren Werten in den anderen drei Indizes \neinhergehen, auch wenn das Ausma\u00df der Korrelationen zwi-\nschen den verschiedenen Untertests je nach N\u00e4he der Aufga-\nben variiert.79 Diese durchweg positive Korrelation f\u00fchrte zur \nAnnahme des sogenannten Generalfaktors der Intelligenz, \nwelcher den Anteil der allgemeinen Intelligenz bzw. der kog-\nnitiven Leistungen zugrunde liegenden allgemeinen geistigen \nF\u00e4higkeit bezeichnet, deren Auspr\u00e4gung sich \u2013 weil unidimen-\nsional \u2013 in einem einzigen Wert ausdr\u00fccken l\u00e4sst, und ca. 40 \nProzent der in Leistungsmessungen beobachteten Varianz er -\nkl\u00e4rt. Die \u00fcbrigen 60 Prozent lassen sich demnach auf unter -\nschiedliche spezifische F\u00e4higkeiten zur\u00fcckf\u00fchren.\nInnerhalb der Allgemeinen Psychologie und insbeson-\ndere mit der Entwicklung der Kognitionspsychologie in den \n1970er-Jahren r\u00fcckte zunehmend die Analyse der Prozesse in \nden Fokus, die n\u00f6tig sind, um die Aufgaben der Intelligenztests \nzu l\u00f6sen. Umfangreiche Forschungen zur Bearbeitung infor -\nmationsverarbeitender Aufgaben wie Informationscodierung \nund geteiltes H\u00f6ren f\u00fchrten zu der Annahme, dass (verbale) \nIntelligenz durch die F\u00e4higkeit zur Auswahl und Benutzung \n79\t Die\tdurchschnittliche\tKorrelation\tzwischen\tallen\tUntertests\tliegt\tbei\t0,45.\t\nAufgrund\tihres\tstatistischen\tUrsprungs\tsind\tdie\tKorrelationen\tinnerhalb\t\nder\tvier\tIndizes\th\u00f6her\tals\tzwischen\tdiesen.\tDie\th\u00f6chste\tKorrelation\tvon\t\n0,74\tbesteht\tzwischen\tdem\tWortschatz-Test\tund\tdem\tTest\tf\u00fcr\tallgemeines\t\nVerst\u00e4ndnis\t(Deary\t2020,\t9).127von Informationsverarbeitungsmethoden bestimmt wird.80 \nDie Kernthemen der kognitionspsychologischen Forschung \njedoch, n\u00e4mlich Denken, Probleml\u00f6sung und Entscheidungs-\nfindung, die auch au\u00dferhalb der Disziplin der Psychologie \nh\u00e4ufig mit dem Begriff \u201eIntelligenz\u201c assoziiert werden und auf \ndie h\u00e4ufig in der Entwicklung von KI Bezug genommen wird, \nfallen in der Psychologie nicht unter den Intelligenzbegriff. \nDies mag mit der zunehmenden Spezialisierung innerhalb der \nPsychologie zusammenh\u00e4ngen. So ist die Erfassung menschli-\ncher Intelligenz ein Teilgebiet der Differentiellen Psychologie, \ndie sich mit Unterschieden zwischen Menschen befasst, wo-\nhingegen die Allgemeine Psychologie sich mit den Grundlagen \nvon Wahrnehmung, Lernen sowie insgesamt menschlicher \nKognition und Emotion besch\u00e4ftigt.\nVerwiesen sei in diesem Zusammenhang auch auf die Un-\nterscheidung zwischen Intelligenz und Kreativit\u00e4t81, wobei \nLetztere in Anlehnung an Joy Paul Guilford, den Begr\u00fcnder \nder modernen Kreativit\u00e4tsforschung, als fl\u00fcssige, flexible und \nurspr\u00fcngliche Erzeugung von Konzepten von L\u00f6sungen f\u00fcr \nneuartige Probleme definiert werden kann.82 Von Interesse ist \nhier seine Unterscheidung zwischen konvergentem und diver -\ngentem Denken.83 Im Unterschied zum konvergenten Denken, \ndas durch logische Schlussfolgerungen zu einer einzigen oder \nbesten L\u00f6sung gelangt (wobei das Ergebnis mehr oder weniger \nvollst\u00e4ndig durch die vorhandene Information determiniert \nist), liefert das f\u00fcr Kreativit\u00e4t charakteristische divergente \nDenken mehrere alternative L\u00f6sungen, die jeweils den gegebe-\nnen Anforderungen entsprechen. Dabei gelten die Anzahl der \ngenerierten L\u00f6sungen und deren Qualit\u00e4t als Ma\u00df f\u00fcr die Aus-\npr\u00e4gung des divergenten Denkens. Neben dem divergenten \nDenken wurden und werden auch weitere kognitive Prozes-\nse als zentrale Voraussetzungen f\u00fcr Kreativit\u00e4t diskutiert. Zu \n80\t Hunt/Lunneborg/Lewis\t1975.\n81\t Kruse/Schmitt\t2011;\tLubart\t2018.\n82\t Guilford\t1950.\n83\t de\tVries/Lubart\t2017.128nennen sind hier insbesondere F\u00e4higkeiten und Fertigkeiten \nim Bereich von Wahrnehmung, Problemdefinition, Einsicht, \nInduktion, Bildung von Analogien und ungew\u00f6hnlichen Asso-\nziationen, die Bewertung von Ideen und die Organisation von \nWissenssystemen.\nW\u00e4hrend der Begriff der Intelligenz urspr\u00fcnglich auf ein \nEnsemble menschlicher Leistungen verweist, wie sie in klassi-\nschen Intelligenztests gemessen werden84, hat sich der Blick auf \nIntelligenz in j\u00fcngerer Zeit sukzessive erweitert. So entstanden \nKonzepte wie die der sozialen bzw. emotionalen Intelligenz, \nwelche einerseits den Begriff der Intelligenz auf weitere F\u00e4hig-\nkeiten ausweiteten sowie andererseits die Wechselwirkungen \nzwischen Emotion und Kognition sowie den sozialen und \nkulturellen Aspekt von Intelligenz in den Blickpunkt r\u00fcckten. \nDar\u00fcber hinaus entwickelte sich rund um die Stichw\u00f6rter em -\nbodied, embedded, enactive und extended Kognition ein For -\nschungsfeld, das in Philosophie, Psychologie und Robotik die \nRolle des K\u00f6rpers einerseits und der Umwelt andererseits f\u00fcr \nIntelligenz und kognitive Leistungen erforscht.85\nSp\u00e4testens diese Erweiterungen werfen die Frage auf, wie \ndie \u00dcbertragung des Intelligenzbegriffs auf technische Arte-\nfakte zu verstehen ist. Bei einigen Merkmalen wie beispielswei-\nse der elementaren Rechenf\u00e4higkeit, dem logischen Schluss-\nfolgern oder Ged\u00e4chtnisleistungen entsteht der Eindruck, dass \nmenschliche F\u00e4higkeiten eindeutig auf technische Artefakte \n\u00fcbertragen werden k\u00f6nnen. Auch diesbez\u00fcglich sind schon \nkritische Fragen zu stellen, zum Beispiel ob die menschliche \nErinnerungsf\u00e4higkeit in gleicher Weise eine Ged\u00e4chtnis-\nleistung ist wie die Aktivierung eines technischen Speichers. \n84\t Verwiesen\tsei\thier\tauf\tdie\tvon\tLouis\tLeon\tThurstone\tfaktorenanalytisch\t\nermittelten\tsieben\tPrim\u00e4rfaktoren\tinduktives\tSchlie\u00dfen,\tr\u00e4umliches\tVor -\nstellungsverm\u00f6gen,\tWahrnehmungsgeschwindigkeit,\tRechenf\u00e4higkeit,\tver -\nbales\tVerst\u00e4ndnis,\tassoziatives\tGed\u00e4chtnis\tund\tWortfl\u00fcssigkeit\t(Thurstone\t\n1938;\tThurstone/Thurstone\t1941)\tsowie\tdie\tDifferenzierungen\tzwischen\t\nfluider\tversus\tkristalliner\tIntelligenz\t(Horn/Cattell\t1966)\tund\tkognitiver\t\nMechanik\tversus\tPragmatik\t(Baltes\t1987).\n85\t Clark\t2012.129Einerseits sind die quantitativen Leistungen technischer \nSpeicher der menschlichen Erinnerungsf\u00e4higkeit um Gr\u00f6\u00dfen-\nordnungen \u00fcberlegen. Andererseits sortiert der Mensch seine \nGed\u00e4chtnisleistungen beispielsweise nach der jeweils kontex-\ntuell bestimmten Bedeutung, w\u00e4hrend ein technischer Spei-\ncher unterschiedslos je nach den technischen Vorgaben Daten \naufnimmt oder nicht. Bei Intelligenzleistungen mit emotiven \nund kreativen Qualit\u00e4ten verst\u00e4rkt sich der Verdacht, dass es \nsich hierbei um anthropomorphe \u00dcbertragungen handelt. Die \nKl\u00e4rung solcher Vergleichbarkeitsprobleme h\u00e4ngt somit we-\nsentlich von den Kriterien ab, durch die man eine spezifisch \nmenschliche Intelligenzleistung bestimmt sieht. Man sollte da-\nher die Verwendung des Ausdrucks \u201eIntelligenz\u201c in der Wort-\nverbindung \u201eK\u00fcnstliche Intelligenz\u201c eher als eine Metapher \neinordnen, deren Beschreibungs- und Erkl\u00e4rungsfunktion ge-\nnauerer Aufkl\u00e4rung bedarf.\n3.2.2 Vernunft\nBereits lange vor der Einf\u00fchrung des Begriffs der Intelligenz \nwurde der Begriff der Vernunft verwendet, um die spezifische \nmenschliche F\u00e4higkeit zu kennzeichnen, sich in der Welt zu \norientieren, selbstverantwortlich zu handeln und so der eige-\nnen Lebenspraxis eine koh\u00e4rente Struktur zu geben. Intelli-\ngenz ist f\u00fcr Vernunft eine wichtige Voraussetzung, aber kei-\nne hinreichende Bedingung. Der Begriff der Vernunft geh\u00f6rt \nzu den basalen Grundkategorien menschlicher Selbst- und \nWeltdeutung, die unsere Kultur seit der Antike ma\u00dfgeblich \ngepr\u00e4gt haben. Schon das weite Wortfeld (griechisch: logos, \nnous, dianoia, phronesis; lateinisch: ratio, mens, intellectus, \nprudentia) deutet darauf hin, dass es sich um einen \u00fcberaus \nkomplexen Begriff handelt, der vielf\u00e4ltige Binnendifferenzie-\nrungen kennt und verschiedene (kognitive) Teilkompetenzen \numfasst. Strukturell geht es um ein mehrdimensionales Bezie-\nhungsgef\u00fcge von Denk-, Reflexions- und Operationsformen, 130das in seiner Gesamtheit im Dienste einer m\u00f6glichst ad\u00e4qua-\nten Wirklichkeitserschlie\u00dfung steht und in einen komplexen \nsozialen und kulturellen Kontext verwoben ist. Als Inbegriff \nbestimmter Anspr\u00fcche, denen wir uns im Denken, Sprechen, \nErleben und Handeln unterstellen, umfasst der Vernunft-\nbegriff unterschiedliche \u2013 propositionale und nicht propo-\nsitionale \u2013 Wissensformen und Rationalit\u00e4tstypen, die von \nmethodisch-prozeduralem Know-how \u00fcber \u00e4sthetische Wahr -\nnehmungsf\u00e4higkeit und Kreativit\u00e4t sowie verschiedene soziale \nInteraktionsf\u00e4higkeiten bis hin zu einer umfassenden Lebens-\nf\u00fchrungskompetenz reichen. Von grundlegender Bedeutung \nf\u00fcr die hier behandelte Thematik ist dabei die Gegen\u00fcberstel-\nlung von theoretischer Vernunft, die sich auf den Erkenntnis-\ngewinn richtet, um zu wahren empirischen oder apriorischen \nUrteilen zu gelangen, und praktischer Vernunft, die auf ein ko-\nh\u00e4rentes, verantwortliches Handeln abzielt, um ein gutes Le-\nben zu erm\u00f6glichen.\nVor allem im Blick auf den Gebrauch der theoretischen \nVernunft, der prim\u00e4r auf Erkenntnisgewinn durch die For -\nmulierung wahrer empirischer Urteile abzielt, scheinen sich \nzumindest prima facie einige Parallelen zur Arbeitsweise von \nKI-Systemen aufzudr\u00e4ngen. So spielen in beiden Bereichen \nF\u00e4higkeiten der Informationsverarbeitung, des Lernens, des \nlogischen Schlussfolgerns und konsistenten Regelfolgens so-\nwie der sinnvollen Verkn\u00fcpfung gespeicherter Daten eine \nzentrale Rolle. Bei n\u00e4herer Betrachtung zeigen sich jedoch in-\nsofern gravierende Differenzen, als sich nicht nur die Arbeits-\nweise des menschlichen Ged\u00e4chtnisses in mehrfacher Hinsicht \nvom technischen Speicher eines Computers unterscheidet, \nsondern auch die menschliche Urteilspraxis technisch nicht \nsubstituierbar ist. Auch wenn in diesem Zusammenhang die \nwahrheitstheoretischen Implikationen der Formulierung und \nBegr\u00fcndung deskriptiver Urteile nicht n\u00e4her entfaltet werden \nk\u00f6nnen86, ist doch darauf hinzuweisen, dass zumindest die \n86\t Bovens/Hartmann\t2003.131bislang verf\u00fcgbaren KI-Systeme die daf\u00fcr relevanten F\u00e4higkei-\nten des Sinnverstehens, der Intentionalit\u00e4t und der Referenz \nauf eine au\u00dfersprachliche Wirklichkeit nicht besitzen.\nDieser Befund best\u00e4tigt sich auch bez\u00fcglich der im Rahmen \ndieser Stellungnahme besonders interessierenden praktischen \nVernunft, die insofern noch weit komplexerer Natur ist, als ihr \nZiel nicht nur in wohlbegr\u00fcndeten praktischen Einzelurteilen, \nsondern in einem m\u00f6glichst richtigen und verantwortlichen \nHandeln besteht, das \u00fcber einen langen Zeitraum aufrechter -\nhalten wird, eine koh\u00e4rente Ordnung der Praxis garantiert und \ndamit ein insgesamt gutes Leben erm\u00f6glicht.87 Dazu bedarf es \nmehrerer Einzelkompetenzen, deren Simulationsm\u00f6glichkei-\nten durch technische Artefakte gegenw\u00e4rtig mit Blick auf die \nunterschiedlichen Relationen und Wechselwirkungen zwi-\nschen Mensch und Maschine (vgl. Abschnitt 4.3) kontrovers \ndiskutiert werden. Ohne Anspruch auf Vollst\u00e4ndigkeit seien \ndabei die folgenden acht Teilf\u00e4higkeiten exemplarisch beson-\nders hervorgehoben:\nErstens braucht es ein Verst\u00e4ndnis der f\u00fcr unsere Moral-\nsprache konstitutiven evaluativen und deontischen Pr\u00e4dika-\ntoren: Von einem vern\u00fcnftigen Wesen erwarten wir, dass es \n\u00fcber die F\u00e4higkeit verf\u00fcgt, die Bedeutung der verschiedenen, \nph\u00e4nomenologisch gehaltvollen Ausdr\u00fccke zur Bezeichnung \nmoralisch relevanter G\u00fcter, Werte und Haltungen sowie de-\nontischer Pr\u00e4dikate zur Qualifizierung von Handlungen (wie \nrichtig bzw. falsch) angemessen zu verstehen und situations-\nad\u00e4quat zu gebrauchen.\nZweitens wird ein Unterscheidungs- und Einf\u00fchlungsverm\u00f6-\ngen ben\u00f6tigt, um die moralisch relevanten Differenzen zwi-\nschen einzelnen moralischen G\u00fctern, Werten, Handlungsty-\npen und Lebensformen m\u00f6glichst pr\u00e4zise und realit\u00e4tsnah \nerfassen sowie anderen Menschen empathisch begegnen zu \nk\u00f6nnen.\n87\t Bormann\t2021,\t48\u201351.132Drittens muss die F\u00e4higkeit zur Abw\u00e4gung konfligierender \nG\u00fcter und Werte vorliegen: Die praktische Vernunft bein-\nhaltet auch ein deliberatives Verm\u00f6gen, das immer dann ins \nSpiel kommt, wenn komplexe Handlungsstrategien entwickelt \nwerden m\u00fcssen oder mehrere moralisch bedeutsame Ge-\nsichtspunkte aufgrund bestimmter ung\u00fcnstiger Umst\u00e4nde in \neiner konflikthaften Beziehung zueinanderstehen. Mittels des \nVerm\u00f6gens der G\u00fcterabw\u00e4gung vermag die handelnde Person \nnicht nur zu erkennen, welche G\u00fcter in zeitlicher Hinsicht pri-\norit\u00e4r erstrebt oder gesichert werden m\u00fcssen, um bestimmte \nZiele zu erreichen, sondern welchen G\u00fctern im Konfliktfall \nder Vorrang zuzuerkennen ist, um ein situativ richtiges Han-\ndeln zu erm\u00f6glichen.\nViertens bedarf es der Bef\u00e4higung zum reflektierten Um-\ngang mit Regeln unterschiedlicher Reichweite: Die praktische \nVernunft schlie\u00dft auch die F\u00e4higkeit ein, moralische Regeln \nwie zum Beispiel Normen und Prinzipien verstehen, korrekt \nanwenden und falls n\u00f6tig auch weiterentwickeln zu k\u00f6nnen, \num Probleme zu l\u00f6sen und ein realit\u00e4tsad\u00e4quates koh\u00e4rentes \nHandeln \u00fcber l\u00e4ngere Zeitr\u00e4ume zu erm\u00f6glichen. Obwohl ein \nGro\u00dfteil des menschlichen Handelns von Routinen und Kon-\nventionen bestimmt wird, gibt es auch vielf\u00e4ltige Herausforde-\nrungen und Konfliktsituationen, die durch ein konventionel-\nles oder gar starr deterministisches Regelfolgen allein gerade \nnicht zu bew\u00e4ltigen sind, sondern Kreativit\u00e4t und einen flexi-\nbleren Umgang mit regulatorischen Vorgaben auf der Grund-\nlage eines unvertretbaren Aktes der praktischen Urteilskraft \nerfordern.88\n88\t In\tdiesem\tZusammenhang\tist\tauf\teinen\tgrunds\u00e4tzlichen\tUnterschied\tzwi-\nschen\tdem\talgorithmischen\tgegen\u00fcber\teinem\theuristischen\tRegelverst\u00e4nd-\nnis\thinzuweisen.\tIn\teinem\talgorithmischen\tVerfahren\tbilden\tdie\tRegeln\tden\t\nAuswahlfilter,\tdurch\tden\tdie\tF\u00e4lle\tals\tKandidaten\t\u00fcberpr\u00fcft\tund\tverworfen\t\noder\tzur\t\u00dcberpr\u00fcfung\tim\tn\u00e4chsten\tSchritt\tangenommen\twerden.\tIn\talgo-\nrithmischen\tVerfahren\tsteht\tdamit\tdas\tVerh\u00e4ltnis\tvon\tRegel\tund\tFall\tfest.\t\nIn\teinem\theuristischen\tVerfahren\twerden\tdie\tRegeln\tdurch\tdie\tSubsumtion\t\neines\tFalles\tpragmatisch\tund\tsemantisch\tmit-konstituiert,\tsodass\tnicht\t\npr\u00e4-prozedural\tfeststeht,\tunter\twelche\tRegel\tder\tFall\tgeh\u00f6rt.133F\u00fcnftens wird die F\u00e4higkeit zum intuitiven Erfassen kom-\nplexer Handlungssituationen und Umst\u00e4nde ben\u00f6tigt: Men-\nschen m\u00fcssen oft unter gro\u00dfem Zeitdruck weitreichende \nEntscheidungen treffen und dabei vielf\u00e4ltige Merkmale eines \nHandlungskontextes ber\u00fccksichtigen.\nSechstens bedarf es eines Urteilsverm\u00f6gens, mittels dessen \nPersonen in der Lage sind, Entscheidungen zwischen verschie-\ndenen Handlungsalternativen zu treffen und singul\u00e4re Hand-\nlungskonstellationen bestimmten generellen Handlungstypen \nzuzuordnen.89\nSiebtens braucht es die F\u00e4higkeit zur Begr\u00fcndung der eige-\nnen moralischen Urteile und der ihnen korrespondierenden \nPraxis: Die F\u00e4higkeit, Gr\u00fcnde zu geben und zu nehmen (give \nand take reasons) und sich im Urteilen und Handeln daran aus-\nzurichten, schlie\u00dft neben der Bereitschaft zur kritischen Re-\nflexion eigener partikularer Interessen auch die F\u00e4higkeit ein, \neinen moralischen Standpunkt (moral point of view) einzuneh-\nmen, also die f\u00fcr die moralische Qualifikation einer Hand-\nlung relevanten Gr\u00fcnde aus der Dritte-Person-Perspektive zu \nbeurteilen.\nAchtens muss die F\u00e4higkeit zur Affekt- und Impulskontrol-\nle vorliegen, um die jeweils gef\u00e4llten praktischen Urteile auch \nhandlungswirksam werden zu lassen. Gerade bei der Verfol-\ngung anspruchsvoller Ziele, die vielf\u00e4ltige Vorarbeiten und \neinen langen Atem verlangen, ist es wichtig, die erforderliche \nWillensst\u00e4rke aufzubringen und zumindest solchen spontanen \nAffekten, Neigungen und Impulsen zu widerstehen, die den \nlangfristigen Erfolg der jeweiligen Bem\u00fchungen gef\u00e4hrden \noder sogar verunm\u00f6glichen k\u00f6nnen.\n89\t In\tAnspielung\tauf\tdie\tdurch\tdas\trichterliche\tJudiz\tzu\tleistende\tintellektu-\nelle\tAufgabe\that\tImmanuel\tKant\tf\u00fcr\theuristische\tVerfahren\tdieser\tArt\tden\t\nBegriff\tder\tUrteilskraft\tgepr\u00e4gt.\tDas\talgorithmische\tVerfahren\tordnet\tKant\t\n(1968a)\tder\tbestimmenden\tUrteilskraft\tzu,\tder\tDom\u00e4ne\tdes\tVerstandes\t\n(KrV,\tB\t360\u00a0f.).\tDas\tin\tden\tpraktischen\tDisziplinen\twie\tP\u00e4dagogik,\tJuris -\nprudenz\toder\t\u00d6konomik\tzugrunde\tzu\tlegende\tVerfahren\tder\tSuche\tnach\t\nder\tangemessenen\tPassung\tvon\tRegel\tund\tFall\tzeichnet\tKant\t(1968b)\tals\t\nreflektierende\tUrteilskraft\taus,\tdie\tzur\tDom\u00e4ne\tder\tpraktischen\tVernunft\t\ngeh\u00f6rt\t(KU,\tAA\tV,\t385).134Die Unterscheidung der verschiedenen Teilkompetenzen \nder Vernunft ist f\u00fcr die hier behandelte Thematik aus zwei \nGr\u00fcnden bedeutsam: Erstens ist es durchaus m\u00f6glich, dass es \npartielle \u00dcberschneidungen des Kompetenzprofils moderner \nKI-Systeme mit dem komplexen Ph\u00e4nomen menschlicher \nVernunft gibt, was insbesondere im Bereich des Regelfolgens \nund der Weiterentwicklung vorgegebener Algorithmen der \nFall sein d\u00fcrfte. Zweitens ist zu ber\u00fccksichtigen, dass die hier \ngenannten, f\u00fcr den B\u00fcndelbegriff der \u201epraktischen Vernunft\u201c \nkonstitutiven F\u00e4higkeiten nicht einfach im Sinne isolierter \nEinzelelemente beziehungslos nebeneinanderstehen. Viel-\nmehr ist von vielf\u00e4ltigen Wechselwirkungen, R\u00fcckkopplungen \nund Bedingungsverh\u00e4ltnissen zwischen ihnen auszugehen. Sie \nbilden einen integralen Bestandteil einer komplexen menschli-\nchen Natur, die im Sinne einer leibseelischen Einheit zu verste-\nhen ist. Menschliche Vernunft ist stets als verleiblichte Vernunft \nzu begreifen (vgl. Abschnitt 3.4.3). Nur so ist zu erkl\u00e4ren, dass \npraktische \u00dcberlegungen \u00fcberhaupt handlungswirksam wer -\nden k\u00f6nnen. Zur\u00fcckzuweisen ist eine Deutung, die versucht, \nvern\u00fcnftige Vollz\u00fcge aus einer rein individualistischen Pers-\npektive zu rekonstruieren. Da jeder Mensch Teil einer sozialen \nMitwelt und kulturellen Umgebung ist, die sich nachhaltig auf \nseine Sozialisation auswirken, m\u00fcssen auch \u00fcberindividuelle \nkulturelle Faktoren in die Deutung der praktischen Vernunft \neinbezogen werden. Ein angemessenes Verst\u00e4ndnis insbeson-\ndere des praktischen Vernunftgebrauchs ist eng mit unserem \nbasalen Selbstverst\u00e4ndnis als handlungsf\u00e4hige Personen ver -\nbunden. Da technische Artefakte in immer neuen Formen in \ndie Handlungswelt der Menschen integriert werden, mit Men-\nschen interagieren oder sogar Teilfunktionen menschlichen \nHandelns \u00fcbernehmen, ist es wichtig, zun\u00e4chst den Hand-\nlungs- und Verantwortungsbegriff zu kl\u00e4ren.1353.3\t\t Handlung\tund\tVerantwortung\n3.3.1 Handlung\nAuch wenn im Alltag gelegentlich alle m\u00f6glichen Ereignisse \nals Handlungen bezeichnet werden, fassen die Normwissen-\nschaften Ethik und Jurisprudenz und auch die Psychologie90 \nden Handlungsbegriff oft enger. Dabei wird angenommen, \ndass Menschen in der Lage sind, aktiv, zweckgerichtet und \nkontrolliert auf die Umwelt einzuwirken und dadurch Ver -\n\u00e4nderungen zu verursachen. Das bedeutet, dass nicht jedes \nmenschliche Tun, das auf die Umwelt einwirkt, als Handlung \nzu verstehen ist, sondern nur solches, das zweckgerichtet, be-\nabsichtigt und kontrolliert ist.91 Unterstellt man, dass Maschi-\nnen nicht zweckgerichtet operieren, also keine Absichten ha-\nben, dann ist die Zuschreibung von Handlungen in Bezug auf \nMaschinen in diesem engen Sinne nicht m\u00f6glich.\nF\u00fcr den Menschen, der im engen Sinn handelt, hat sich \nauf dem Hintergrund einer lang zur\u00fcckreichenden Begriffsge-\nschichte92 im Rahmen einer umfassenden Theorie praktischer \nVernunft der Begriff der Person  eingeb\u00fcrgert.93 Personen sind \nAkteure, die Verantwortung f\u00fcr ihr Verhalten tragen, die die \nkognitiven Bedingungen erf\u00fcllen, um Handlungsoptionen zu \nerkennen, und die Gr\u00fcnde deliberieren k\u00f6nnen, also \u00fcber ein \n90\t Vgl.\tetwa\tdie\tverschiedenen\t(etablierten)\tHandlungsphasenmodelle.\n91\t Hier\twird\teine\tForm\tder\tHandlungserkl\u00e4rung\tunterstellt,\tdie\tdie\tWarumfra-\nge\t(im\tSinne\tvon\t\u201eWarum\thast\tdu\tdas\tgetan?\u201c)\tdurch\tAngabe\tder\tAbsicht\t\nbzw.\tZwecke\tder\tHandlung\tbeantwortet\tsieht\t(intentionale,\tteleologische\t\nHandlungserkl\u00e4rung,\t\u201eIntentionalismus\u201c).\tIhr\tsteht\teine\tForm\tder\tHand-\nlungserkl\u00e4rung\tgegen\u00fcber,\tdie\tdie\tAngabe\tder\tdie\tHandlung\tausl\u00f6senden\t\nUrsachen\tals\tAntwort\tvorsieht\t(kausale\tHandlungserkl\u00e4rung,\t\u201eKausalis -\nmus\u201c).\tOb\teine\tHandlung\tintentionalistisch\toder\tkausalistisch\terkl\u00e4rt\twer -\nden\tsollte,\tist\tkeine\tFrage\tder\tWahrheit/Falschheit\tder\tErkl\u00e4rung,\tsondern\t\neine\tFrage\tder\tKontextad\u00e4quatheit\tder\tHandlungsdeutung.\tF\u00fcr\tdie\tNorm-\nwissenschaften\tsteht\tdie\tFrage\tder\tAbsicht\tbzw.\tder\tZweck\tder\tHandlung\t\nim\tVordergrund\tder\tBetrachtung,\tohne\tdass\tdie\tM\u00f6glichkeit\teiner\tkausalen\t\nHandlungserkl\u00e4rung\tin\tAbrede\tgestellt\twird\t(Horn/L\u00f6hrer\t2010).\n92\t Fuhrmann\t1989.\n93\t Quante\t2007.136hinreichendes Ma\u00df theoretischer und praktischer Vernunft \nverf\u00fcgen.\nDer Handlungsbegriff ist auch deswegen so bedeutsam in \nder Diskussion um maschinelle Fertigkeiten und KI, da dieser \nDiskurs sich etwa seit der Jahrtausendwende von der Konzent-\nration auf m\u00f6glicherweise kognitive Kompetenzen abgewandt \nhat und inzwischen zunehmend auf praktische Kompetenzen \nkonzentriert.94 Nicht in welcher Weise, wenn \u00fcberhaupt, Ma-\nschinen denken, sondern in welchem Sinne Maschinen han-\ndeln k\u00f6nnen, steht verst\u00e4rkt im Vordergrund. Diese Verschie-\nbung der Aufmerksamkeit geht Hand in Hand mit technischen \nEntwicklungen hin zu maschinellen Systemen, die nicht ledig-\nlich auf hohe Informationsverarbeitungskapazit\u00e4t setzen, um \nmenschliches Handeln zu unterst\u00fctzen, sondern jenes teilwei-\nse gar ersetzen k\u00f6nnen oder sollen.\nAutomatisierte oder algorithmische Entscheidungssysteme \n(Automated/Algorithmic Decision Making Systems, ADM-\nSysteme) zum Beispiel erstellen auf Basis von Berechnungen \nPrognosen dar\u00fcber, wie geeignet eine sich bewerbende Per -\nson f\u00fcr eine Stelle ist oder mit welcher Wahrscheinlichkeit \nMenschen Kredite zur\u00fcckzahlen oder straff\u00e4llig werden (vgl. \nKapitel 8). Auch wenn diese Systeme oftmals nur der Unter -\nst\u00fctzung der menschlichen Entscheidung dienen, so k\u00f6nnen \nEntscheidungen auch komplett an jene delegiert werden. Da-\nmit stellt sich die Frage, in welchem Sinne solche maschinellen \nVollz\u00fcge au\u00dferhalb des obigen engen Handlungsbegriffs doch \nin bestimmten Kontexten als Handlungen in einem weiteren \nSinne wahrgenommen werden k\u00f6nnen oder ber\u00fccksichtigt \nwerden m\u00fcssen. Daran ankn\u00fcpfend gibt es einen Diskurs, \nob und inwieweit zunehmend eigenst\u00e4ndige, das hei\u00dft ohne \nmenschliches Zutun funktionierende maschinelle Systeme \nals \u201eAgenten\u201c in der Folge f\u00fcr ihr \u201eHandeln\u201c verantwortlich \n94\t Dreyfus\t1992.137gemacht werden k\u00f6nnen, etwa mit Blick auf Fragen der Haf-\ntung (vgl. Abschnitt 2.2.5).95\nDen folgenden \u00dcberlegungen liegt mit Blick auf die oft \nschillernde Verwendung zentraler ethisch relevanter Begriffe \nwie Handlung oder Verantwortung im Kontext der zeitgen\u00f6s-\nsischen KI-Debatte die Annahme zugrunde, dass wenigstens \ndrei Klassen von Entit\u00e4ten terminologisch klar gegeneinander \nabzugrenzen sind. Dies w\u00e4ren erstens Pflanzen und Tiere, die \nzwar in vielf\u00e4ltiger Weise auf ihre Umwelt reagieren k\u00f6nnen, \nin ihrem jeweiligen Repertoire aber doch so begrenzt sind, dass \nder ausgef\u00fchrte enge Handlungsbegriff auf sie nicht anwend-\nbar ist.96 Zweitens sind Menschen in dem Ma\u00dfe im engen Sinn \nals handlungsf\u00e4hig zu bezeichnen, als sie dazu imstande sind, \nabsichtlich Ver\u00e4nderungen zu bewirken, wobei solche Hand-\nlungen nicht nur Taten, sondern auch deren bewusstes und \nabsichtliches Unterlassen umfassen k\u00f6nnen.97 Drittens gibt \nes technische Artefakte unterschiedlicher Komplexit\u00e4tsgrade, \nderen jeweilige Vollz\u00fcge oder Operationen zwar Ver\u00e4nderun-\ngen in der Welt bewirken und flexibel mit anspruchsvollen \nHerausforderungen der menschlichen Lebenswelt umgehen \nk\u00f6nnen.98 Da sie diese Ver\u00e4nderungen aber nicht absichtlich \nherbeif\u00fchren, haben sie selbige daher auch nicht in einem \nmoralischen und rechtlichen Sinne zu verantworten (vgl. Ab-\nschnitt 3.3.2).\nAuch wenn es zwischen diesen drei Klassen von Entit\u00e4ten \nunterschiedliche Arten von Wechselwirkungen (vgl. Abschnitt \n4.3) geben kann, scheint es sinnvoll, den Handlungsbegriff im \n95\t Hilgendorf\t2014;\t2020;\tEbers\tet\tal.\t2020.\n96\t Ausnahmen\twerden\tf\u00fcr\teinige\thochentwickelte\tTiere\tdiskutiert,\tdarunter\t\nzum\tBeispiel\tPrimaten\tund\tRabenv\u00f6gel\t(Huber\t2021).\n97\t F\u00fcr\tUnterlassungen,\tnicht\taber\tf\u00fcr\tNichthandeln,\tkann\tman\tgetadelt\t\noder\tverurteilt\twerden.\tDas\tUnterlassen\tbezieht\tsich\tdemgem\u00e4\u00df\tauf\tein\t\nbestimmtes\tHandlungsschema\t(z.\tB.\tdes\tHelfens)\tund\tist\tnicht\tnur\tdie\tun-\nbestimmte\tNegation\tder\tAusf\u00fchrung\teines\tHandlungsschemas.\tUnterlas -\nsungshandlungen\tsind\tsomit\t\u201eEreignisse\tin\tder\tWelt\u201c\tund\tals\tsolche\tohne\t\nWeiteres\tm\u00f6gliche\tUrsachen\tvon\tWirkungen\t(Folgen)\tin\tder\tWelt\t(Roxin/\nGreco\t2020,\t335\u00a0ff.;\tBottek\t2014).\n98\t Rammert/Schulz-Schaeffer\t2002.138engen Sinne Menschen vorzubehalten, um inflation\u00e4ren Aus-\nweitungen des Akteursstatus zu vermeiden und konzeptionel-\nle Grenzziehungen zu erm\u00f6glichen. Entscheidend ist demnach \ndas Konzept der Handlungsurheberschaft bzw. Autorschaft, \ndas auf die universelle menschliche Handlungserfahrung ver -\nweist, sich selbst und andere im Hinblick auf bestimmte Er -\neignisse und Zust\u00e4nde als Urheber anzusehen.99 Die F\u00e4higkeit \nzur Handlungsurheberschaft kann als Grundlage von Autono-\nmie betrachtet werden, also daf\u00fcr, dass handelnde Menschen \nihre Handlungen nach Maximen ausrichten k\u00f6nnen, die sie \nsich selbst setzen. Diese Konzeption schlie\u00dft jedoch nicht aus, \ndass Handlungen mitunter auch durch Befolgen von Autori-\nt\u00e4ten und Traditionen ausgef\u00fchrt werden. Wo dies geschieht, \nsetzt das Konzept der Handlungsurheberschaft jedoch voraus, \ndass Menschen ihr eigenes Dasein in ein Verh\u00e4ltnis zu solchen \nBestimmungen setzen k\u00f6nnen, etwa durch \u00dcberwindung, Wi-\nderstand oder Nachgeben.\nAus einer Handlung k\u00f6nnen neben den beabsichtigten \nFolgen auch nicht beabsichtigte, aber der handelnden Person \nerkennbare Folgen erwachsen. Auf diese Weise erscheint es \nm\u00f6glich, auch fahrl\u00e4ssiges Tun zu erfassen, das im Kontext von \nKI eine gro\u00dfe Rolle spielt.100 Des Weiteren finden Handlungen \numgeben von anderen raumzeitlichen Ereignissen statt, die \nals Umst\u00e4nde der Handlung f\u00fcr deren moralische und recht-\nliche Bewertung von Bedeutung sein k\u00f6nnen. Auch werden \nHandlungen zwar methodisch prim\u00e4r individuellen Akteuren \nzugesprochen; das schlie\u00dft aber kollektive Handlungen nicht \naus, bei denen die einzelnen Personen von vornherein in ei-\nnem Kontext der Koordination agieren, ihre Handlungen auf \n99\t Deutscher\tEthikrat\t2017,\t175\u00a0ff.;\tNida-R\u00fcmelin\t2020a,\t376\u2013408.\n100\tEin\tBeispiel\tliefert\tetwa\tder\tBereich\tdes\tautonomen\tFahrens:\tUnterl\u00e4uft\t\ndem\tProgrammierer\tein\tFehler,\tder\tsp\u00e4ter\tzur\tSch\u00e4digung\tvon\tVerkehrsteil-\nnehmern\tf\u00fchrt,\tund\twar\tdies\tf\u00fcr\tihn\tvorhersehbar\tund\tvermeidbar\tsowie\t\naus\tGr\u00fcnden\tdes\t\u00fcberwiegenden\tSchutzes\tder\tInteressen\tder\tanderen\t\nPersonen\tauch\tvon\tRechts\twegen\tzu\tvermeiden,\tliegt\thierin\tein\tfahrl\u00e4ssi-\nges\tFehlverhalten,\tf\u00fcr\tdas\ter\tzur\tVerantwortung\tzu\tziehen\tist\t(Hevelke/\nNida-R\u00fcmelin\t2015).139Kooperation bezogen sind und durch Kommunikation ge-\nst\u00fctzt werden.\nDer hier verwendete, eng gefasste Handlungsbegriff \nschlie\u00dft nicht aus, dass Technologie erheblichen Einfluss auf \nmenschliches Handeln oder die menschliche Handlungser -\nfahrung haben kann. Technik beeinflusst und ver\u00e4ndert Ge-\nsellschaft; gleichzeitig beeinflusst Gesellschaft die Technikent-\nwicklung und den Technikeinsatz. Gerade die in den letzten \nJahren stark zunehmende Durchdringung der menschlichen \nLebenswelt mit informationstechnisch immer leistungsf\u00e4hige-\nren Maschinen, die mit anspruchsvoller Sensorik und Motorik \nsowie vernetzt arbeiten, f\u00fchrt zu hybriden, soziotechnischen \nKonstellationen, in denen Menschen und Maschinen eng ver -\nwoben sind und auf komplexe Weise interagieren. Dies kann \ndas Verhalten und die Handlungen von Menschen stark be-\neinflussen und ihre individuellen Freiheitsspielr\u00e4ume und \nKontrollm\u00f6glichkeiten einschr\u00e4nken. Zudem k\u00f6nnen fortge-\nschrittene und mit flexiblen, selbstlernenden Algorithmen ar -\nbeitende maschinelle Systeme menschliches Tun zum Teil so \ngut imitieren, dass sie wie intentionales menschliches Handeln \nerscheinen, was weitere ethische Fragen aufwirft (vgl. Kapitel \n4).\nAuch mit Blick auf diese soziotechnische Komplexit\u00e4t bis \nhin zu Unterscheidungsschwierigkeiten erscheint es sinnvoll, \nan einem engen Handlungsbegriff, der an das zentrale Kri-\nterium der Intentionalit\u00e4t gebunden ist, festzuhalten. Dieses \nIntentionalit\u00e4tskriterium ist zudem entscheidend f\u00fcr die M\u00f6g-\nlichkeit der Zuschreibung von Verantwortung im Kontext von \nMensch-Maschine-Interaktionen in zunehmend komplexer \nsoziotechnischer Vernetzung. Im Hinblick auf digitale Tech-\nniken handeln Menschen nicht jederzeit in vollem Ma\u00dfe au-\ntonom, sondern verstehen oft weder die technischen Zusam-\nmenh\u00e4nge noch haben sie immer umfassende Informationen \noder hinreichende Wahlfreiheit, um bewusste Entscheidun-\ngen im Umgang mit der Technik treffen zu k\u00f6nnen. Solche 140Konstellationen k\u00f6nnen vielf\u00e4ltig ethische Bedeutung entfal-\nten, wenn es um Fragen der Verantwortung geht.\n3.3.2 Verantwortung\nFragen der Verantwortung und Verantwortlichkeiten kn\u00fcpfen \nan den Handlungsbegriff an. Die Rolle menschlicher Verant-\nwortung f\u00fcr die kausale Verursachung von Handlungsfolgen \nkann in vielfacher Weise thematisiert, reflektiert, diskutiert \nund modifiziert werden. Bei der Verantwortung f\u00fcr die Re-\nsultate von Zuschreibungshandlungen in sozialen Kontexten \ngeht es vor allem darum zu kl\u00e4ren, welche Verantwortung von \nwelchen Akteuren \u00fcbernommen werden soll , um einer zuneh-\nmenden Verantwortungsdiffusion entgegenzuwirken.101 Ver -\nantwortungszuschreibung und -verteilung erfolgen zu dem \nZweck, Praxisfelder wie den Stra\u00dfenverkehr, den Schulbetrieb \noder den Umgang mit KI in verschiedenen Anwendungsberei-\nchen so zu strukturieren und gegebenenfalls rechtlich zu regu-\nlieren, dass sich dadurch eine m\u00f6glichst \u201egute Praxis\u201c entfalten \nkann.\nIn den Zuschreibungen wird der Kreis der verantwor -\ntungsf\u00e4higen Individuen abgegrenzt, der Stellenwert der kau-\nsalen Verursachung geregelt und es werden Kriterien festge-\nlegt, welche Voraussetzungen Menschen erf\u00fcllen m\u00fcssen, um \nihnen Verantwortung zuschreiben zu k\u00f6nnen. Somit stellt \nsich die Frage, wer f\u00fcr was direkt oder indirekt Verantwor -\ntung \u00fcbernehmen kann oder soll, wenn Individuen, Gruppen \nund Institutionen aus und in verschiedenen Bereichen wie im \nPrivatleben, in der Forschung, Wirtschaft und Politik sowohl \nmiteinander als auch mit maschinellen Systemen und insbe-\nsondere KI-Systemen zusammenwirken.\nVerantwortung kann als Konzept einer vielfachen Relati-\non rekonstruiert werden. Im Kontext dieser Stellungnahme \n101\t Grunwald\t2021.141erscheint eine f\u00fcnfstellige Relation angemessen: Wer ist f\u00fcr \nwas, gegen\u00fcber wem, vor wem und unter welcher Norm \nverantwortlich?102 Allerdings sprechen wir auch von einer \nverantwortlichen Person; in diesem Falle ist der Begriff ein-\nstellig und der Zusammenhang zwischen dem einstelligen \nmoralischen Begriff der verantwortlichen Person und den \nunterschiedlichen, meist mehrstelligen Kriterien der Verant-\nwortungszuschreibung ist eine eigene philosophische und \nrechtstheoretische Thematik. Ohne die genuine individuelle \nmoralische Verantwortung w\u00e4ren auch die weiter gehenden \nAusdifferenzierungen gegenstandslos.103\nDemnach kann man erstens ganz grunds\u00e4tzlich beim \nVerantwortungssubjekt (wer ) ansetzen, das Verantwortung \n\u00fcbernehmen kann. Verantwortungssubjekte tragen Verant-\nwortung, als Einzelperson oder Mitglieder eines Kollektivs, \nbeispielsweise einer Institution. Davon zu unterscheiden ist \nzweitens das Verantwortungsobjekt (was ), f\u00fcr das Verant-\nwortung \u00fcbernommen wird, zum Beispiel Handlungen so-\nwie deren Gr\u00fcnde und Folgen.104 Als drittes Relationselement \nwerden die vom Handeln des Verantwortungssubjektes (di-\nrekt oder indirekt) Betroffenen benannt (gegen\u00fcber wem). Das \nvierte Relationselement bildet die Instanz, vor der die Verant-\nwortung \u00fcbernommen wird (vor wem). Das Gewissen als In-\nbegriff der praktischen Vernunft, andere Personen oder auch \neine staatliche Rechtsgemeinschaft sind hier denkbar. F\u00fcr eine \nnormative Stellungnahme ist zudem ein f\u00fcnftes Relationsele-\nment bedeutsam, n\u00e4mlich die Regel oder das Prinzip, dem eine \n102\tLoh\t2017.\n103\t Nida-R\u00fcmelin\t2011.\n104\tPersonen\tk\u00f6nnen\tauch\tf\u00fcr\tein\tUnterlassen\tverantwortlich\tsein.\tAuch\tdurch\t\nein\tUnterlassen\twird\tein\tEreignis\tin\tder\tWelt\tverursacht.\tDie\tVerantwor -\ntung\tkann\taus\teiner\tSonderbeziehung\tdes\tUnterlassenden\tim\tHinblick\tauf\t\ndas\tdadurch\tbeeintr\u00e4chtigte\tRechtsgut\terwachsen\t(\u201eGarantenstellung\u201c)\t\n(Freund\t1992).\tEin\t\u201eJedermannsunterlassen\u201c,\tf\u00fcr\tdas\tes\tauf\tkeine\tsolche\t\nSonderbeziehung\tankommt,\tl\u00e4sst\tsich\tdar\u00fcber\thinaus\tauf\tallgemeine\tSoli-\ndarit\u00e4tspflichten\tst\u00fctzen\t(Frisch\t2016).142verantwortliche Praxis gerecht werden sollte, zum Beispiel das \nPrinzip, andere nicht zu sch\u00e4digen (unter welcher Norm).105\nVor allem das dritte Relationselement \u2013 die Betroffenen \u2013 \nist nicht immer leicht einzugrenzen. Ungeachtet dessen sind \nderen Ber\u00fccksichtigung und Einbezug gerade in Anbetracht \ndes steigenden Einsatzes von KI-Systemen in vielen Gesell-\nschafts- und Lebensbereichen von zentraler Bedeutung. An \ndieses Desiderat kn\u00fcpfen sich auch Forderungen nach Trans-\nparenz und Nachvollziehbarkeit, welche eine Voraussetzung \nf\u00fcr die Beteiligung und Ber\u00fccksichtigung von Betroffenen \ndarstellen.\n\u00dcber diese Konstellation hinaus ist in der Verantwor -\ntungsdiskussion zum wissenschaftlich-technischen Fortschritt \ndie epistemologische Dimension zu bedenken. Denn Hand-\nlungsfolgen sind oft nur unter hohen und nicht eliminierbaren \nUnsicherheiten des Wissens antizipierbar.106 Verantwortungs-\nzuschreibung muss daher die Dimension des Handelns unter \nUnsicherheit und damit die Risikothematik107 ber\u00fccksichti-\ngen. Dies l\u00e4sst auch noch einmal zwischen retrospektiver und \nprospektiver Verantwortung unterscheiden. Beim Blick auf \nvergangene Handlungen kann eine nachtr\u00e4gliche Verantwor -\ntungs\u00fcbernahme unter Umst\u00e4nden angezeigt sein. Vor allem \ndie prospektive Verantwortung unterliegt den gerade konsta-\ntierten Unsicherheiten.\nUm Verantwortung im Zusammenspiel von Menschen \nund maschinellen Systemen n\u00e4her zu betrachten, kann das \nf\u00fcnfstellige Verantwortungskonzept technikspezifisch ge-\nrahmt werden. Ausgangspunkt ist hier, dass eine Verantwor -\ntungs\u00fcbernahme (als Verantwortungssubjekt) nur Personen \nals verantwortlichen Wesen m\u00f6glich ist, beispielsweise den \n105\t Damit\tbildet\tder\tVersto\u00df\tgegen\teine\tNorm\tden\tAnkn\u00fcpfungspunkt\tvon\t\nVerantwortung.\tNormen\tschr\u00e4nken\tdie\tFreiheit\tdes\tEinzelnen\tein\tund\tbe-\nd\u00fcrfen\tdaher\tder\tLegitimation.\tIm\tRecht\tkann\tinsoweit\tauf\tden\tGrundsatz\t\nder\tVerh\u00e4ltnism\u00e4\u00dfigkeit\t(i.w.S.)\tzur\u00fcckgegriffen\twerden\t(Dechsling\t1989).\n106\tGrunwald\t2014.\n107\tNida-R\u00fcmelin/Schulenburg/Rath\t2012.143Individuen, die Technik entwickeln und herstellen, die ihren \nEinsatz etwa in der Politik oder Unternehmen erm\u00f6glichen \nund f\u00f6rdern, oder denjenigen, die Technologien einsetzen. \nDas Verantwortungsobjekt ist dann je nach Rolle der Verant-\nwortungssubjekte und ihrer Handlungen zu beschreiben: \nzum Beispiel Planen, Erfinden, Entwickeln oder Anwenden. \nZu den Betroffenen k\u00f6nnen sowohl die von dem technischen \nAngebot direkt angesprochenen Personen(gruppen) geh\u00f6ren, \nzum Beispiel Angestellte in einem Krankenhaus, die mithilfe \nKI-gest\u00fctzter Software Entscheidungen treffen, als auch wei-\ntere Personen wie zum Beispiel diejenigen, die auf Grundlage \nsolcher Entscheidungen Diagnosen, Therapieempfehlungen \noder sonstigen medizinischen Rat erhalten. Relevante Instan-\nzen und relevante Normen sind hierbei verkn\u00fcpft. Rechtliche \nVerantwortung besteht in letzter Instanz gegen\u00fcber der staat-\nlich verfassten Gemeinschaft.\nMoralische Verantwortung k\u00f6nnen nur nat\u00fcrliche Perso-\nnen \u00fcbernehmen, insofern sie \u00fcber Handlungsf\u00e4higkeit ver -\nf\u00fcgen, das hei\u00dft in der Lage sind, aktiv, zweckgerichtet und \nkontrolliert auf die Umwelt einzuwirken und dadurch Ver -\n\u00e4nderungen zu verursachen. Tr\u00e4fe dies auch auf Maschinen \nzu, w\u00e4ren auch diese verantwortungsf\u00e4hig. Dann m\u00fcsste Ma-\nschinen der Personenstatus zugeschrieben werden, was jedoch \nweder aktuell noch angesichts der in absehbarer Zukunft er -\nwartbaren qualitativen Entwicklungen maschineller Systeme \nangemessen w\u00e4re. Verantwortung kann daher nicht direkt von \nmaschinellen Systemen \u00fcbernommen werden, sondern nur \nvon den Menschen, die in je unterschiedlichen Funktionen \nhinter diesen Systemen stehen, gegebenenfalls im Rahmen in-\nstitutioneller Verantwortung. Auch wenn ein technisches Sys-\ntem eingesetzt wird, um im Rahmen einer automatisierten Da-\ntenauswertung Schlussfolgerungen wie die Gew\u00e4hrung eines \nKredites anzuwenden, ist es die Verantwortung des Menschen, 144dieses System in einer ethisch vertretbaren Weise zu entwi-\nckeln und einzusetzen.108\nWer nun konkret als Verantwortungstr\u00e4ger fungiert, kann \nmit dem Konzept der Multiakteursverantwortung umrissen \nwerden.109 Kommt es bereits zu facettenreichen Verantwor -\ntungsgef\u00fcgen, wenn man von nur drei prinzipiellen Ebenen \nm\u00f6glicher Verantwortungszuschreibung ausgeht \u2013 Individu-\nen, Organisationen und Staat \u2013, so entsteht ein noch komple-\nxeres Bild, wenn man Wechselwirkungen zwischen verschie-\ndenen Akteuren aus diesen drei Ebenen ber\u00fccksichtigt. Dies \ngilt erst recht, wenn diese Interaktionen zumindest teilweise \nvon algorithmischen Systemen gest\u00fctzt oder vermittelt wer -\nden, die mitunter f\u00fcr andere Beteiligte selbst autonom und \nkaum durchschaubar zu agieren scheinen.\nHier stellt sich die Frage, wie Verantwortung sinnvoll \nzwischen unterschiedlichen Beteiligten geteilt werden kann, \nzum Beispiel zwischen denjenigen, die maschinelle Systeme \nkonzipieren und entwickeln, die ihre Nutzung beauftragen \noder vorantreiben, die in Nutzungsprozesse oder ihre \u00dcber -\nwachung direkt eingebunden sind, die Ergebnisse solcher \nProzesse verwenden oder von ihnen direkt oder indirekt be-\ntroffen sind oder die ihre Auswirkungen auf unterschiedlichen \ngesellschaftlichen Ebenen beobachten und eventuell regulie-\nrend eingreifen k\u00f6nnen. In Anlehnung an das Konzept der \nDatensouver\u00e4nit\u00e4t110 ist die geeignete Gestaltung von Multi-\nakteursverantwortung demnach zentral f\u00fcr eine angemessene \ninformationelle Freiheitsgestaltung, die den Chancen und Ri-\nsiken einer zunehmend digital vernetzten und algorithmisch \ngest\u00fctzten Welt gerecht wird. Eine solche Freiheitsgestaltung \nkann nur dann verantwortlich sein, wenn sie sich gleichzeitig \nan den gesellschaftlichen Anforderungen von Solidarit\u00e4t und \nGerechtigkeit orientiert.\n108\tDatenethikkommission\tder\tBundesregierung\t2019.\n109\tDeutscher\tEthikrat\t2017,\t249\u00a0f.\n110\t Ebd.145Auch f\u00fcr die Diskursf\u00fchrung \u00fcber die zahlreichen Wech-\nselwirkungen von Menschen und Maschinen und die gesell-\nschaftlichen Auswirkungen einer zunehmenden Durchdrin-\ngung der menschlichen Gesellschaft mit algorithmischen \nSystemen muss Verantwortung \u00fcbernommen werden. War -\nnungen vor unkritischem Vertrauen in maschinelle Systeme, \ninsbesondere im Falle K\u00fcnstlicher Intelligenz, sollten einen \nPlatz haben und sind Ausdruck wahrgenommener Verant-\nwortung. Ebenso sind die Auswahl und Gewichtung bestimm-\nter normativer Kriterien und Prinzipien im Diskurs zur Ethik \nvon maschinellen Systemen, Algorithmen und KI selbst Ge-\ngenstand von Kontroversen.111 Wer hat die Deutungshoheit, \nWerte und Normen, die im Umgang mit KI relevant sind, zu \nbestimmen? Wer pr\u00fcft, welche Betroffenen vornehmlich in \nden Blick genommen werden oder wie die Lasten und Nutzen \nbestimmter Anwendungen verteilt sind? Es stellt sich also all-\ngemein die Frage, wer f\u00fcr das f\u00fcnfte Relationselement, die Be-\nstimmung normativer pr\u00e4skriptiver Prinzipien, zust\u00e4ndig ist.\n3.4\t\t Anthropologische\tAspekte\tdes\t\nMensch-Maschine-Verh\u00e4ltnisses\n3.4.1 Philosophische Grundbestimmung des \nMenschseins\nHandlung, Vernunft und Verantwortung stehen im Zent-\nrum humanistischer112 Philosophie. Menschen sind bef\u00e4higt \nzur Handlungsurheberschaft und somit zur Autorschaft ihres \nLebens. Sie sind frei und tragen daher Verantwortung f\u00fcr die \nGestaltung ihres Handelns. Freiheit und Verantwortung sind \n111\t Jobin/Ienca/Vayena\t2019;\tRudschies/Schneider/Simon\t2021.\n112\t Die\tunterschiedlichen\tVerwendungsweisen\tdes\tHumanismusbegriffs\tin\tder\t\nPhilosophie\tstimmen\tin\teinigen\tnormativen\tKernelementen\t\u00fcberein,\tdie\t\nzur\tKl\u00e4rung\tanthropologischer\tAspekte\tdes\tMensch-Maschine-Verh\u00e4ltnis -\nses\twichtig\tsind\tund\tnachfolgend\tn\u00e4her\tentfaltet\twerden.146zwei einander wechselseitig bedingende Aspekte menschlicher \nAutorschaft. Autorschaft ist wiederum an Vernunftf\u00e4higkeit \ngebunden. Die strafrechtlichen Kriterien f\u00fcr Schuldf\u00e4higkeit \nkonvergieren mit der lebensweltlichen Praxis moralischer Zu-\nschreibungen. Personen sind jedenfalls in wichtigen sozialen \nKontexten moralisch verantwortlich. Das hei\u00dft, man erwartet \nvon ihnen, dass sie zurechnungsf\u00e4hig handeln und urteilen.113\nDiese Trias aus Vernunft, Freiheit und Verantwortung \npr\u00e4gt heute sowohl die lebensweltliche Moral als auch die \nRechtsordnung in hohem Ma\u00dfe. Im Mittelpunkt steht dabei \ndas Ph\u00e4nomen der Affektion durch Gr\u00fcnde. Praktische Gr\u00fcn-\nde sprechen f\u00fcr Handlungen, sie sind per se normativ, nicht \nerst \u00fcber den Umweg eigener W\u00fcnsche. Ein Grund spricht \ndaf\u00fcr, das zu tun, was diesen Grund erf\u00fcllt, wenn nicht an-\ndere Gr\u00fcnde dem entgegenstehen.114 Theoretische Gr\u00fcnde \nsprechen f\u00fcr \u00dcberzeugungen; auch diese sind normativ. In der \nRegel gibt es Gr\u00fcnde, das eine zu tun und das andere zu lassen, \ndie gegeneinander abgewogen werden m\u00fcssen. Der Konflikt \nvon Gr\u00fcnden zwingt dann zur Abw\u00e4gung und zur Systemati-\nsierung dieser Abw\u00e4gung in Gestalt ethischer Theoriebildung.\nDie menschliche Lebensform ist von reaktiven Einstellun-\ngen und moralischen Gef\u00fchlen gepr\u00e4gt, die von normativen \nGr\u00fcnden begleitet sind. Wir vergeben einer Person, die uns \nUnrecht getan hat, wenn wir den Eindruck haben, sie habe das \nUnrechte ihres Tuns eingesehen und werde diese Praxis nicht \nfortsetzen. Wir sind dankbar, wenn wir meinen, dass eine Per -\nson etwas Gutes getan hat, ohne daraus Vorteile zu ziehen; wir \nnehmen etwas \u00fcbel nur dann, wenn wir die betreffende Person \n113\t In\tder\tTechnikanthropologie,\tdie\tsich\tmit\tanthropologischen\tAspekten\t\ndes\tTechnischen\tund\tder\tTechnik\tbefasst,\tvor\tallem\tmit\tMensch-Technik-\t\noder\tMensch-Maschine-Konstellationen,\twird\teine\tVielzahl\tauch\tanderer\t\nPerspektiven\tverfolgt\t(He\u00dfler/Liggieri\t2020).\tHierzu\tgeh\u00f6ren\tetwa\tHomo\t\nFaber\tund\tHomo\tCreator,\ttrans-\tund\tposthumanistische\tPositionen\tsowie\t\ndie\tAkteur-Netzwerk-Theorie.\tDie\tenge\tVerbindung\tethischer\tFragen\tzu\t\nden\tKonzepten\tvon\tFreiheit\tund\tVerantwortung\timpliziert,\tdiese\tin\tden\t\nBetrachtungen\tnicht\teigens\tzu\tber\u00fccksichtigen,\tsondern\tdie\thumanistische\t\nPerspektive\tin\tdie\tMitte\tzu\tstellen.\n114\t Scanlon\t1998;\t2014;\tHalbig\t2007.147f\u00fcr voll zurechnungsf\u00e4hig und in ihrem Handeln frei halten.115 \nDie verobjektivierende Einstellung gegen\u00fcber anderen Men-\nschen, die diese zum blo\u00dfen Gegenstand der Beeinflussung \nmacht, sie gewisserma\u00dfen zu einem Teil der Umwelt degra-\ndiert, l\u00e4sst sich nur f\u00fcr ganz spezifische Situationen \u2013 wenn \n\u00fcberhaupt \u2013 durchhalten. Aber wenn diese verobjektivierende \nEinstellung ohne moralische Empfindungen zur allgemeinen \nPraxis w\u00fcrde, g\u00e4be es die menschliche Lebensform nicht mehr. \nDiese ist gerade dadurch gepr\u00e4gt, dass wir ein Verhalten \u00fcbel \nnehmen, wenn es uns inakzeptabel erscheint, dass wir zum \nBeispiel in der Lage sind zu verzeihen, wenn wir daf\u00fcr Gr\u00fcnde \nhaben, oder dass wir Dankbarkeit empfinden.\nFreiheit kommt insofern ins Spiel, als wir rationaliter be-\nstimmte moralische Gef\u00fchle und reaktive Einstellungen zu-\nr\u00fcckstellen, wenn wir erfahren, dass die betreffende Person \nin ihrem Handeln nicht frei war, was immer die Ursachen \ndieser Unfreiheit sind, wie beispielsweise \u00e4u\u00dferer Zwang, psy-\nchische Erkrankung oder \u00fcberw\u00e4ltigende Angst. Diese Praxis \nder Zuschreibung von Freiheit und Verantwortung ist essen-\nziell f\u00fcr die Grundlegung moralischer Beurteilung wie auch \nf\u00fcr moralische Gef\u00fchle und reaktive Einstellungen. Daher ist \nes ausgeschlossen, diese aufzugeben, wie \u00fcberzeugend auch \nimmer wissenschaftliche Theorien, die prima facie dagegen \nsprechen, sein m\u00f6gen.116 Es macht unsere Zugeh\u00f6rigkeit zur \nmenschlichen Lebensform aus, dass solche moralischen Be-\nurteilungen, Gef\u00fchle und Einstellungen unsere soziale Praxis \npr\u00e4gen. Die Normen von Moral und Recht sind ohne die An-\nnahme menschlicher Verantwortlichkeit und damit von Frei-\nheits- und Vernunftf\u00e4higkeit unbegr\u00fcndet. Sie w\u00fcrden in blo-\n\u00dfe Instrumente der Verhaltenssteuerung transformiert117 und \nparadoxerweise w\u00e4re es gerade diese Transformation, die ihre \n115\t Vgl.\tden\teinflussreichen\tAnsatz\tvon\tPeter\tStrawson\t(1974).\n116\t Siehe\tbeispielsweise\tdie\tDebatte\trund\tum\tdie\tExperimente\tvon\tBenjamin\t\nLibet\t(2004).\n117\t Vgl.\tdazu\tMoritz\tSchlick\t(1930),\tder\texemplarisch\tf\u00fcr\tdiese\tantihumanisti-\nsche\tAuffassung\tsteht.148Wirksamkeit f\u00fcr die Verhaltenssteuerung zugleich gef\u00e4hrden \nw\u00fcrde.\nWenn menschliche Freiheit im Sinne des Andersk\u00f6nnens \nbestritten wird, kann an der Verantwortlichkeit menschlicher \nPersonen nicht festgehalten werden.118 In \u00a7 20 StGB werden \ndie praktischen und epistemischen Bedingungen von Schuld-\nf\u00e4higkeit dargestellt, die ohne diese anthropologischen Vo-\nraussetzungen von Freiheit und Vernunft nicht aufrechtzu-\nerhalten w\u00e4ren. Ohne die F\u00e4higkeit, sich anders entscheiden \nzu k\u00f6nnen, gibt es keine Handlungsurheberschaft und keine \nVerantwortung.\nObwohl die humanistische Perspektive nicht nur die lebens-\nweltliche Normativit\u00e4t, sondern auch die juridische Delibera-\ntion von den Menschenrechten bis zum Strafrecht impr\u00e4gniert \nund das kulturelle Fundament demokratischer Ordnungen \nausmacht, wird sie doch immer wieder infrage gestellt. Zwei \nj\u00fcngere Formen der Kritik, die sich teilweise \u00fcberlagern, st\u00fct-\nzen sich einerseits auf neurowissenschaftliche Begriffe und Pa-\nradigmen sowie andererseits auf solche aus Debatten um das \nThema KI. In den Neurowissenschaften wurden bestimmte \nempirische Studien, nach denen zum Beispiel das motorische \nZentrum des Gehirns schon mit der Vorbereitung einer Bewe-\ngung beginnt, bevor man sich bewusst f\u00fcr die Ausf\u00fchrung der \nBewegung entschieden hat119, als Beleg daf\u00fcr interpretiert, dass \nes Freiheit und damit menschliche Verantwortlichkeit nicht \ngebe. Stattdessen handele es sich dabei lediglich um \u2013 m\u00f6g-\nlicherweise sozial n\u00fctzliche \u2013 Illusionen. Tats\u00e4chlich lassen \nsolche Befunde jedoch unterschiedliche Interpretationen zu \nund eignen sich nicht als Widerlegung menschlicher Freiheit \nund Verantwortlichkeit. Auch wenn alle mentalen Prozesse \nneurophysiologisch realisiert sind, sprechen die empirischen \n118\t Es\tgibt\tallerdings\tin\tder\tzeitgen\u00f6ssischen\tPhilosophie\tebenso\tdie\tAuffas -\nsung,\tVerantwortlichkeit\tk\u00f6nnte\tauch\tohne\tdie\tBedingung\tder\tFreiheit\t\npostuliert\twerden\t\u2013\tbesonders\tprominent\tbei\tHarry\tFrankfurt\t(Kane\t2011,\t\nKap.\t5;\tsiehe\tauch\tFrankfurt\t1971).\n119\t Libet\t2004.149Befunde aus den Neurowissenschaften nicht gegen das Ph\u00e4-\nnomen normativer Gr\u00fcnde und ihrer Rolle f\u00fcr menschliche \nHandlungsmotivation, da wir es hier mit zwei Sprachebenen \nzu tun haben, die sich wechselseitig nicht in die Quere kom-\nmen k\u00f6nnen.120\nDie zweite, von der KI-Debatte inspirierte Kritik der hu-\nmanistischen Anthropologie changiert zwischen einer \u00dcber -\nwindung des Menschen in Gestalt des Transhumanismus, \nder mit neuen Mensch-Maschine-Symbiosen die Reichweite \nmenschlichen Wirkens in neue Dimensionen heben m\u00f6chte, \nund einem Maschinenparadigma, das den menschlichen Geist \nauf das Modell eines algorithmischen Systems reduziert. Ge-\nrade Letzteres entfaltet besondere Relevanz im Kontext dieser \nStellungnahme, da es gro\u00dfen Einfluss auf die Interpretation \nder Wechselwirkungen zwischen Mensch und Maschine und \nderen R\u00fcckwirkungen auf das menschliche Selbstverst\u00e4ndnis \nhat.\n3.4.2 Der Mensch als Maschine \u2013 die Maschine als \nMensch?\nDer Mensch als Maschine ist eine alte Metapher, deren Ur -\nspr\u00fcnge bis in die fr\u00fche Neuzeit zur\u00fcckreichen. Der mechanis-\ntische Materialismus des rationalistischen Zeitalters l\u00e4sst die \nWelt als Uhrwerk erscheinen und den Menschen als R\u00e4dchen \nim Getriebe. Der gro\u00dfe Uhrmacher ist dann der Sch\u00f6pfer, der \ndaf\u00fcr gesorgt hat, dass nichts dem Zufall \u00fcberlassen ist und ein \nR\u00e4dchen ins andere greift. F\u00fcr menschliche Freiheit, Verant-\nwortung und Vernunft ist in diesem Bild kein Platz.\nDie vielleicht aktuell gr\u00f6\u00dfte Herausforderung f\u00fcr das hu-\nmanistische Menschenbild stellt das digital erneuerte Maschi-\nnenparadigma des Menschen dar. Das digitale Weltmodell, die \n120\tStrawson\t1974;\tNida-R\u00fcmelin\t2005;\tKorsgaard\t1996.150Welt als umfassender Algorithmus121, scheint als zeitgen\u00f6ssi-\nsche Variante des Maschinenparadigmas einer Deutung der \nWelt als Maschine eine attraktive Interpretation anzubieten. \nDiese beruht auf der Unterscheidung zwischen Software und \nHardware. Es handelt sich dabei um zwei Beschreibungsebe-\nnen: die der Hardware, die lediglich auf physikalische und \ntechnische Begriffe zur\u00fcckgreifen muss, und die der Software, \ndie sich wiederum in eine syntaktische und eine semantische \nEbene aufteilen l\u00e4sst. Die syntaktische Beschreibung beruht \nauf der Zeichenverarbeitung, genauer dem Vokabular und \nden Regeln der Zeichenverarbeitung. Die Semantik unterlegt \nden Zeichen und den Regeln, nach denen sie verarbeitet wer -\nden, eine Bedeutung. Im Falle von Behauptungss\u00e4tzen f\u00fchrt \ndiese Unterlegung zu einer Wahrheitswertverteilung; die S\u00e4t-\nze werden dann als wahr oder falsch markiert; im Falle einer \narithmetischen Semantik folgt die Wahrheitswertverteilung \nmathematischen Regeln.\nDie Beschreibung (und Erkl\u00e4rung) von Softwaresystemen \nals Hardware ist geschlossen: Jeder Vorgang (Ereignis, Pro-\nzess, Zustand) l\u00e4sst sich als kausal determiniert durch den vo-\nrausgegangenen Zustand der Hardware eindeutig bestimmen. \nAls Modell auf den Menschen \u00fcbertragen hei\u00dft dies, dass die \nphysikalisch-physiologische \u201eHardware\u201c wie ein algorithmi-\nsches System mit einer durch Genetik, Epigenetik und senso-\nrische Stimuli eindeutig festgelegten zeitlichen Zustandsfolge \nvon Eigenschaften funktioniert, die durch mentale Termini \nbeschrieben wird und damit bedeutungsvolles Reden und \nHandeln erm\u00f6glicht. Das humanistische Menschenbild und \ndamit die normativen Grundlagen von Moral und Recht er -\nweisen sich dann als pure Illusion bzw. kollektive menschliche \nSelbstt\u00e4uschung.122\nSchon in der ersten Digitalisierungswelle nach dem Zwei-\nten Weltkrieg erwies sich interessanterweise nicht das eben \n121\t Nida-R\u00fcmelin/Weidenfeld\t2018.\n122\t Singer\t2004;\tBennett\tet\tal.\t2007.151geschilderte materialistische Maschinenparadigma, sondern \neine animistische Variante als wirkungsm\u00e4chtiger. Das ani-\nmistische Paradigma geht gewisserma\u00dfen den umgekehrten \nWeg der Interpretation: Anstatt den menschlichen Geist und \nmentale Zust\u00e4nde als Epiph\u00e4nomene materieller Prozesse in \neiner physikalisch geschlossenen Welt zu interpretieren und \ndas Materielle mechanistisch zu beschreiben, wird nun im \nKontext des Turing-Tests (vgl. Abschnitt 2.1) das algorithmi-\nsche System mit mentalen Eigenschaften ausgestattet, sofern \nes in seinem \u00e4u\u00dferen (Ausgabe-)Verhalten demjenigen von \nMenschen hinreichend (das hei\u00dft verwechselbar) \u00e4hnelt.\nEntsprechend war in der ersten Phase der Diskussion um \nKI ab den 1970er-Jahren die Frage, ob Computer denken k\u00f6n-\nnen, leitend. F\u00fcr die Fragerichtung ist die kontroverse Diskus-\nsion um die Interpretation des von Turing vorgeschlagenen \nKriteriums paradigmatisch.123 Wie zuvor bereits dargelegt, \nkann nach Turing die Frage, ob technische Artefakte \u201edenken\u201c \nk\u00f6nnen, dadurch entschieden werden, dass eine Person (f\u00fcr \nsie verdeckten) Menschen und Ger\u00e4ten beliebige Fragen stellt. \nWenn in einer gr\u00f6\u00dferen Zahl von Durchg\u00e4ngen mit wech-\nselnden Fragenden und wechselnden Menschen/Ger\u00e4ten die \nAntworten zu einem hinreichend gro\u00dfen Anteil (z. B. 50 Pro-\nzent) nicht eindeutig Mensch oder Ger\u00e4t zugeordnet werden \nk\u00f6nnen, gibt es nach Turing keinen Grund, technischen Arte-\nfakten weniger Denkverm\u00f6gen zuzuschreiben als Menschen.\nDie in Diskursen rund um KI teilweise verbreitete Ten-\ndenz, im Anschluss an den Turing-Test eine \u00e4u\u00dferliche Un-\nunterscheidbarkeit von menschlicher und maschineller Per -\nformanz pauschal mit der Annahme von Intelligenz und \nDenkverm\u00f6gen solcher Maschinen gleichzusetzen, auf diese \nWeise die Differenz zwischen dem Simulierten und dem Si-\nmulierenden einzuebnen und die menschliche Vernunft damit \ntendenziell f\u00fcr maschinell ersetzbar zu halten, ist kein Zufall, \nsondern das Ergebnis bestimmter theoretischer Vorannahmen \n123\t Turing\t1950;\tvgl.\tdie\tkritische\tDarstellung\tbei\tMainzer\t1995,\t113\u00a0f.152insbesondere behavioristischer und funktionalistischer Art.124 \nSchon der klassische Behaviorismus125 hatte sich zu Beginn des \n20. Jahrhunderts in dem Bem\u00fchen, das menschliche Verhal-\nten auf der Grundlage pr\u00e4zise beschreibbarer Reiz-Reaktion-\nSchemata zu erkl\u00e4ren und die Psychologie damit in eine exakte \nWissenschaft zu verwandeln, im Grunde einer Blackbox-Me-\nthode bedient, die das Innenleben derart beschriebener Orga-\nnismen komplett ausblendet.\nDer Text von Turing ist zweifellos vom logischen Behavi-\norismus inspiriert, der in den Nachkriegsjahren die zeitgen\u00f6s-\nsischen Debatten insbesondere in der britischen Philosophie \nzunehmend pr\u00e4gte126 und nach dem sich mentale Zust\u00e4nde on-\ntologisch auf Verhaltensdispositionen reduzieren lassen, also \nauf die Neigung eines Organismus, sich unter bestimmten Be-\ndingungen auf eine bestimmte Weise zu verhalten. Ein men-\ntaler Zustand wie Schmerz ist demnach lediglich ein Verhal-\ntensmuster, etwa die Veranlagung zu schreien oder zu weinen, \nwenn man sich verletzt hat. Auch Turings Text identifiziert \nden Sinn eines sprachlichen Ausdrucks nicht etwa mit der In-\ntention der sprechenden Person, sondern mit den empirischen \nVerhaltensmustern, die mit einer \u00c4u\u00dferung \u00fcblicherweise \neinhergehen. Die Paradoxa, die den logischen Behaviorismus \nunglaubw\u00fcrdig machen, gelten auch f\u00fcr die Turing\u2019sche Va-\nriante: Auch wenn wir die Bedeutung eines Satzes wie \u201eDiese \nPerson hat Schmerzen\u201c lernen, indem wir darauf achten, wel-\nches Verhalten jeweils darauf hinweist, dass sie Schmerzen hat, \nso kann schon deshalb die Bedeutung von \u201eSchmerzen haben\u201c \nnicht lediglich ein Verhaltensmuster sein, weil \u201eSupersparta-\nner\u201c, die keine Schmerzen zeigen, dann auch keine Schmerzen \nhaben k\u00f6nnten.127 Obwohl sich der behavioristische Theorie-\nansatz schon bald als zu eng erweisen sollte und in den \n124\tBormann\t2021,\t51\u00a0ff.\n125\t Watson\t1930.\n126\t Wittgenstein\t1953;\tRyle\t1949.\tEinen\tguten\tZugang\tzur\tdamaligen\tOrdinary\t\nLanguage\tPhilosophy\tvermittelt\tvon\tSavigny\t1974.\n127\t Putnam\t1965.153folgenden Jahrzehnten verschiedene Transformationen er -\nfuhr, fand er mit dem sich seit den 1950er-Jahren ausbreiten-\nden Funktionalismus, nach dem mentale Zust\u00e4nde funktio-\nnal vollst\u00e4ndig erfasst werden, eine Nachfolgetheorie, die der \naufkeimenden Kognitionspsychologie und Computerwissen-\nschaft noch besser entsprach, weil Computer in dieser Lesart \nein geeignetes Modell f\u00fcr mentale Prozesse sein k\u00f6nnen.128\nDer Reiz funktionalistischer Ans\u00e4tze besteht zun\u00e4chst da-\nrin, dass sie sich gegen\u00fcber den ontologischen Implikationen \ndes Leib-Seele-Problems neutral verhalten, das hei\u00dft, sie um-\ngehen die Frage nach der Beziehung zwischen K\u00f6rper und \nGeist sowie die Frage, wo und wie sich in diesen das denken-\nde und f\u00fchlende Subjekt verorten l\u00e4sst. Der Funktionalismus \npl\u00e4diert daf\u00fcr, die Frage nach der Seinsart mentaler Zust\u00e4nde \nzugunsten der genauen Beschreibung ihrer Funktion aufzuhe-\nben. Durch die These der multiplen Realisierung129, nach der \nbestimmte mentale Ereignisse, Eigenschaften oder Zust\u00e4nde \ndurch ganz unterschiedliche physikalische Ereignisse, Eigen-\nschaften oder Zust\u00e4nde realisiert werden k\u00f6nnen, schien es \nzudem m\u00f6glich, auch Computern mentale Zust\u00e4nde zuzu-\nschreiben, obwohl sie keine biologischen Strukturen besit-\nzen.130 Indem der Funktionalismus durch die ausdr\u00fcckliche \nAnerkennung theorierelevanter innerer Zust\u00e4nde eines Sys-\ntems nicht nur das Blackbox-Prinzip des Behaviorismus \u00fcber -\nwand, sondern mit der funktionalen Interpretation solcher \nZust\u00e4nde auch die Integration biologischer und maschineller \nEntit\u00e4ten in eine umfassende einheitliche Theorie zu erm\u00f6gli-\nchen schien, bahnte er insofern auch einer animistischen Deu-\ntung von KI-Systemen den Weg, als diese nun umso leichter \nals handlungsf\u00e4hige Agenten mit einem mentalen Innenleben \n128\t Putnam\t1975.\tVon\tdieser\tPosition\tdistanziert\ter\tsich\tzu\tsp\u00e4terer\tZeit,\tsiehe\t\ndazu\tPutnam\t1992.\n129\t F\u00fcr\tdie\tunterschiedlichen\tEntwicklungsstufen\tdieser\tThese\tvgl.\tBickle\t\n2020;\tPolger/Shapiro\t2016.\n130\tPutnam\t1967;\tFodor\t1974.154vorgestellt werden konnten, denen man zutraute, die mensch-\nliche Vernunft irgendwann einmal ersetzen zu k\u00f6nnen.\nObwohl der Funktionalismus aufgrund dieser Vorteile zu-\nn\u00e4chst viel Zuspruch sowohl in der analytischen Philosophie \ndes Geistes als auch in der KI-Forschung fand, wurden schon \nbald Einw\u00e4nde gegen dieses Theoriemodell vorgetragen. Eine \nerste gewichtige Kritik einer funktionalistischen Betrachtung \ndes Mentalen, die den menschlichen Geist als Rechenmaschi-\nne131 fasst, deren innere Zust\u00e4nde allein von ihrer Funktion im \nSinne einer kausalen Verkn\u00fcpfung von Eingabe und Ausgabe \nbestimmt werden, stammt von Thomas Nagel. Seines Erach-\ntens l\u00e4sst unsere gew\u00f6hnliche Auffassung mentaler Ph\u00e4no-\nmene eine solche reduktionistische Sichtweise allein schon \ndeswegen nicht zu, weil das Mentale neben seiner blo\u00dfen \nFunktion auch durch ein bestimmtes ph\u00e4nomenales Bewusst-\nsein132 gepr\u00e4gt sei, das in dieser Beschreibung verloren gehe. \nNagel leugnet weder, \u201eda\u00df bewu\u00dfte mentale Zust\u00e4nde und Er -\neignisse Verhalten verursachen, noch, da\u00df man sie funktional \ncharakterisieren k\u00f6nnte\u201c, sondern bestreitet lediglich, \u201eda\u00df \nderartiges eine vollst\u00e4ndige Analyse ergibt\u201c.133\nEin Wesen kann nur als dieses Wesen mentale Zust\u00e4nde \nhaben. Daher kann von den Empfindungsqualit\u00e4ten des ph\u00e4no-\nmenalen Bewusstseins nicht abgesehen werden, die allein auf-\ngrund \u00e4u\u00dferen Verhaltens nicht zug\u00e4nglich sind. Es f\u00fchlt sich \nf\u00fcr uns immer auf eine ganz bestimmte Art und Weise an, ein \nerlebendes, denkendes und handelndes Subjekt zu sein. Diese \nbesonderen Qualit\u00e4ten sind kein fl\u00fcchtiges Beiwerk mentaler \nZust\u00e4nde, sie geh\u00f6ren vielmehr insofern konstitutiv zu allen \nunseren Erfahrungen, als wir die uns umgebende Welt prin-\nzipiell gar nicht anders erleben k\u00f6nnen als aus der Perspektive \neines solchen ph\u00e4nomenalen Bewusstseins.\n131\t Oder\t\u2013\tum\teine\tKritik\tvon\tNed\tBlock\t(1978)\taufzugreifen\t\u2013\twie\teinen\tGe-\ntr\u00e4nkeautomaten\t(\u201eCoke\tmachine\u201c).\n132\t Zur\tDebatte\tum\tdie\tBedeutung\tdes\tph\u00e4nomenalen\tBewusstseins\tvgl.\tauch\t\nHeckmann/Walter\t2006;\tMetzinger\t2009.\n133\t Nagel\t1981,\t262.155Dieses ph\u00e4nomenale Bewusstsein setzt dem Verm\u00f6gen, die \nQualit\u00e4t des Erlebens oder die mentalen Zust\u00e4nde anderer Le-\nbewesen zu beurteilen, gewisse Grenzen. Dies illustriert Nagel \nam Beispiel des Empfindens einer Fledermaus, deren Orientie-\nrung aufgrund spezifischer sensorischer Besonderheiten (wie \nRadar oder Echolotortung) ganz anders strukturiert ist als \nbeim Menschen. Als Menschen k\u00f6nnen wir zwar versuchen, \nuns vorzustellen, wie es ist, sich auf g\u00e4nzlich andere Weise im \nRaum zu orientieren, wir bleiben dabei aber immer unserer ei-\ngenen, spezifisch menschlichen Weise des Erlebens verhaftet, \nohne jemals Zugang zu den besonderen Qualit\u00e4ten der menta-\nlen Zust\u00e4nde einer Fledermaus zu erhalten. Unsere subjektive \nPerspektive bleibt un\u00fcberwindlich.134 Vor diesem Hintergrund \ndieses auch als Qualia-Argument135 bezeichneten Gedanken-\ngangs basiert die funktionalistisch inspirierte Mensch-Com-\nputer-Analogie auf einer fragw\u00fcrdigen Reduktion, die nur ge-\nlingen kann, \u201ewenn die artspezifische Betrachtungsweise von \ndem, was reduziert werden soll, ausgeklammert wird\u201c.136\nGegen eine funktionalistische Interpretation K\u00fcnstlicher \nIntelligenz hat John Searle ein Argument entwickelt, das als \ndas meistdiskutierte in der zeitgen\u00f6ssischen Philosophie gilt: \ndas Chinese-Room-Argument.137 Es verweist auf ein Gedan-\nkenexperiment, in dem eine Person in einem Zimmer sitzt, in \ndas durch einen Schlitz jeweils Fragen in chinesischer Schrift \ngereicht werden. Die Person reicht Antworten auf diese Fra-\ngen ebenfalls durch den Schlitz heraus. Wenn die Antworten \nhinreichend plausibel erscheinen, mag man vermuten, dass die \nPerson im chinesischen Zimmer des Chinesischen m\u00e4chtig ist. \nNun stellt sich aber heraus, dass jede der eingereichten Fragen \neine Ziffer tr\u00e4gt und die Person \u00fcber vorgefertigte Antworten \nund eine Tabelle mit Zuordnungen verf\u00fcgt, sodass sie lediglich \n134\t Ebd.\n135\t Von\tlat.\tqualis\t=\twie\tbeschaffen.\n136\t Nagel\t1981,\t269.\n137\t Searle\t1980.\tEine\tfr\u00fchere\tZur\u00fcckweisung\tdes\tFunktionalismus\tstammt\tvon\t\nBlock\t1978.156eine Antwort heraussuchen muss, die eine Ziffer tr\u00e4gt, die der \nZiffer der Fragestellung zugeordnet ist. Die Person beherrscht \ndie chinesische Sprache nicht, auch nicht das Zimmer als Gan-\nzes mit einer Eingabe- und Ausgabefunktion. Aber zweifellos \nmuss es irgendjemanden geben, der des Chinesischen m\u00e4chtig \nist und daher in der Lage war, den Fragen mithilfe der Ziffern \nAntworten so zuzuordnen, sodass der Eindruck entsteht, dass \ndie Person im chinesischen Zimmer Chinesisch versteht. Die \nAnalogien zu Softwaresystemen liegen auf der Hand. Es han-\ndelt sich um Zuordnungsregeln (genauer um Algorithmen), \ndie lediglich f\u00fcr die Programmierung und den Gebrauch der \ndigitalen Maschine Bedeutung haben, aber nicht das Soft-\nwaresystem selbst zu einer semantischen Maschine machen. \nDieses verf\u00fcgt nicht \u00fcber Bedeutungen, es versteht nichts, es \nentscheidet nichts. Softwaresysteme verf\u00fcgen nicht \u00fcber eine \nSemantik, es handelt sich nicht um semantische Maschinen.\n3.4.3 Verleiblichte Vernunft\nDie Zur\u00fcckweisung funktionalistischer Maschinenparadig-\nmen lenkt den Blick auf die bereits im Qualia-Argument an-\ngedeutete besondere Qualit\u00e4t menschlicher Vernunft und \nderen Bedeutung f\u00fcr das menschliche Selbstverst\u00e4ndnis. \nMenschliche Vernunft ist leibliche Vernunft. Diese Einsicht \nwendet sich gegen den in der abendl\u00e4ndischen Tradition lan-\nge herrschenden Gedanken eines Dualismus zwischen Natur \nund Vernunft, K\u00f6rper und Geist, der den Menschen als Na-\nturwesen auf der einen und als Vernunftwesen auf der anderen \nSeite begreift. Solch dualistische Vorstellungen wurden sowohl \ndurch Erkenntnisse in der Evolutionsbiologie als auch in der \nHirnforschung und in den Kognitionswissenschaften infrage \ngestellt, die stattdessen auf die Relevanz des Leiblichen f\u00fcr die \nBestimmung menschlicher Intelligenz und auf die Bedeutung \nunbewusster Prozesse f\u00fcr die Entwicklung h\u00f6herer geistiger \nLeistungen verweisen.157Mit Maurice Merleau-Pontys Unterscheidung von zwei-\nerlei Arten des K\u00f6rpers kann dies veranschaulicht werden.138 \nEr unterscheidet den lebendigen handelnden Leib  vom rein \nphysikalischen K\u00f6rper. Die F\u00e4higkeit, soziale Bindungen ein-\nzugehen, sich in andere hineinzuversetzen, wird erm\u00f6glicht \ndadurch, dass der Mensch Leib ist und nicht nur einen K\u00f6rper \nhat. Mit dem Leib ist der empfindende Organismus gemeint, \nmit seinem Verm\u00f6gen, zu f\u00fchlen und sich zu bewegen. Wir \nsind an diesen Leib gebunden, in allem, was wir denken und \ntun. Er ist daher Ausgangspunkt und Bestandteil jeder Wahr -\nnehmung und Empfindung. Als solcher ist er Voraussetzung \nf\u00fcr unser In-der-Welt-Sein und zugleich daf\u00fcr, eine Welt zu \nhaben und eine Beziehung zu anderen herzustellen.\nKognitive F\u00e4higkeiten sind in ihrem Entstehungs- und \nVollzugsprozess also an Sinnlichkeit und Leiblichkeit gebun-\nden. Dies hat Konsequenzen f\u00fcr unser Verst\u00e4ndnis vom Ge-\nhirn als Erkenntnisorgan und von der Vernunft als Erkennt-\nnisverm\u00f6gen \u2013 und damit auch f\u00fcr das Verst\u00e4ndnis unseres \nZugangs zur Realit\u00e4t. Wesentlich ist dabei, dass das in der \nVerk\u00f6rperung des Gehirns eingeschlossene Naturverh\u00e4ltnis \neiner leiblichen Vernunft des Menschen seine Sozialit\u00e4t impli-\nziert und seine Kulturalit\u00e4t bestimmt. Im menschlichen Leib \nsind Sozialit\u00e4t und Kulturalit\u00e4t von Anfang an angelegt, vor \naller Entwicklung eines reflexiven und sprachlich vermittel-\nten Bewusstseins.139 Denn leibliche Vernunft vollzieht nicht \nnur einen kognitiven Informationsaustausch, sondern mit ihr \nspielen auch Kommunikation und Kooperation eine Rolle.140 \n138\t Merleau-Ponty\t1966.\n139\t Fuchs\t2013,\t11\u00a0ff.\tVier\tErscheinungsformen\tdes\tLeibes\tk\u00f6nnen\tdiese\tAnlage\t\nder\tVermittlung\tzwischen\tder\tNatur-\tund\tder\tKulturseite\tdes\tMenschen\t\nplausibel\tmachen:\t(i)\tein\tmit\tder\tUmwelt\tvertrauter\tLeib,\tder\tsich\tvor\tallem\t\nim\tUmgang\tmit\tkulturellen\tGegenst\u00e4nden\tentwickelt,\t(ii)\tein\t\u201epassiv-affi-\nzierbarer\u201c\tLeib,\tder\taffektiv\tmit\tanderen\tverbunden\tist,\t(iii)\tein\t\u201emimetisch-\nresonanter\u201c\tLeib,\tder\tdurch\tNachahmung\tin\tgrundlegende\tKommunikation\t\nmit\tanderen\teingebunden\tist,\tbis\ter\tso\tals\t(iv)\tkooperativ\tkultivierter\tLeib\t\nzum\tK\u00f6rper\tf\u00fcr\tandere\twird,\tindem\ter\tHaltungen\tund\tRollen\t\u00fcbernimmt,\t\ndie\tihm\tsomit\tzur\t\u201ezweiten\tNatur\u201c\twerden\t(ebd.,\t26\u00a0f.).\n140\tSchmitz\t1990.158Beides sind Faktoren, die von Kindheit an entscheidend sind \nf\u00fcr jene bewussten Prozesse, in denen sich die Kulturf\u00e4hig-\nkeit bildet, die dem Menschen als sozusagen \u201ezweite Natur\u201c141 \nzuw\u00e4chst. F\u00fcr das menschliche Gehirn bedeutet das, dass es \nmit all seinen sich entfaltenden F\u00e4higkeiten von Anfang an in \nbiologisch-organische wie in sozial-kulturelle Entwicklungs-\nprozesse eingebunden ist.\nEin solches Verst\u00e4ndnis des Menschen geht nicht von ei-\nner blutleeren \u201ereinen\u201c Vernunft aus, sondern begreift auch \ndie Vernunft als immer schon leiblich eingebunden und so-\nzial wirksam. Damit ist die Frage nach dem Praktischwerden \nder Vernunft, das hei\u00dft nach den normativen Orientierungen \nund nach der Motivation moralischen Handelns, keine zweite \nFrage, sondern sie begleitet alles Denken, das als solches Le-\nbensgestaltung nicht nur erm\u00f6glicht, sondern immer bereits \nvollzieht.\nBereits die praktische Einsicht, dass bestimmte normative \nGr\u00fcnde f\u00fcr eine Handlung sprechen, wird damit handlungs-\nwirksam. Damit w\u00e4re der entscheidende Aspekt einer umfas-\nsenden Theorie praktischer Vernunft, n\u00e4mlich die Frage, wie \nsich moralische \u00dcberzeugungen in Handlungen \u00fcberf\u00fchren \nlassen, ber\u00fchrt. Bez\u00fcglich dieser Frage pl\u00e4diert der Philosoph \nJohn McDowell daf\u00fcr, in diesem Kontext nicht entweder die \nVernunft oder aber die subjektiven Einstellungen und Stre-\nbungen zum alles beherrschenden Faktor der Handlungsver -\nursachung zu stilisieren, sondern zu akzeptieren, dass in der \nmenschlichen moralischen Erfahrung diese beiden (das hei\u00dft \ndie kognitive und die appetitive Dimension) immer schon un-\naufl\u00f6slich miteinander verschr\u00e4nkt seien.142\nEntscheidend ist dabei, dass leibliche Erfahrungsstrukturen \neinhergehen mit der F\u00e4higkeit, sich in andere hineinversetzen \nund sich mitteilen zu k\u00f6nnen, das hei\u00dft mit einer Prosozialit\u00e4t, \n141\t McDowell\t2001,\t109;\t2002a.\n142\tMcDowell\t2002b,\t177.159auf deren Grundlage sich die F\u00e4higkeit zu geteilter Intention \nentwickeln und Empathie und Motivation initiieren kann.\nInsofern nun das Gehirn kein isolierter Gegenstand ist, \nsondern eingelassen ist in Erfahrungen gemeinsamer Praxis, \nin der sich k\u00f6rperlich-biologisches und kulturell-soziologi-\nsches Erleben verschr\u00e4nken, entwickeln sich in solch sozialer \nPraxis ein Bedeutungswissen und ein Wissen um die Perspek-\ntivit\u00e4t von Erkenntnis, die reflexiv auf die Relationalit\u00e4t von \nWissen und Erkenntnis verweist. Denn diese Perspektivit\u00e4t \ndes Wissens erschlie\u00dft sich insbesondere durch dessen In-Re-\nlation-Stehen zum eigenen Leib, durch die sogenannte \u201eEigen-\nleiberfahrung\u201c. So wird mit dem Rekurs auf die verleiblichte \nVernunft deutlich, dass zur menschlichen Intelligenz unab-\ndingbar Reflexivit\u00e4t hinzugeh\u00f6rt. Diese setzt menschliche Er -\nkenntnis instand, zu unterschiedlichen Perspektiven Stellung \nnehmen und urteilen zu k\u00f6nnen.\nGrenzen der Formalisierbarkeit und Simulierbarkeit \nmenschlicher Vernunft\nMit der Reflexivit\u00e4t des Bewusstseins ist das Verstehen- und \nVermittelnk\u00f6nnen angesprochen, mit anderen Worten die \nhermeneutische Dimension, die sich auch in der Unterschei-\ndung und Anwendung verschiedener Wissensformen darstellt \nund die ein besonderes Charakteristikum menschlicher Intel-\nligenz bildet. Diese hermeneutische Dimension von Wissen ist \naber nur begrenzt formalisierbar oder simulierbar und bezieht \nsich auf den Sinn und die Bedeutung menschlichen Erkennens \nund Handelns. Die Aneignung menschlicher Erfahrung ist im-\nmer mit Deutungsprozessen verbunden und setzt immer ein \nBeteiligtsein, ein Engagement voraus.143 Die Art und Weise, \nwie wir wissen (knowing how), ist eine eigene Kompetenz, die \nsich nicht durch blo\u00dfes Sachwissen (knowing that) abbilden \nl\u00e4sst.\n143\t Meyer-Drawe\t2001.160Auch hier spielt der Leib eine wichtige Rolle, denn er er -\nm\u00f6glicht ein Handeln, das allein mittels bewusster Planung \nund Berechnung so nicht m\u00f6glich w\u00e4re. In der leiblichen \nVerfasstheit gr\u00fcndet daher auch die Nichtsimulierbarkeit des \nDenkens. Mit der leiblichen Verankerung des Bewusstseins, \ndie eine Komplexit\u00e4t von Hintergrunderfahrungen mit sich \nf\u00fchrt, die Voraussetzung f\u00fcr alle bewussten Prozesse der Pla-\nnung und Entscheidung sowie deren Begr\u00fcndung bilden, st\u00f6\u00dft \ndie Entwicklung von KI an ihre Grenzen.\nDer Sachverhalt solch leiblich verfassten Hintergrundwis-\nsens bedeutet mithin eine Grenze des rationalistischen Ver -\nsuchs, Wissen vollst\u00e4ndig in formalisierte Regeln zu \u00fcberf\u00fch-\nren und k\u00fcnstlich nachzubilden. Es zeigt sich in der leiblichen \nVerschr\u00e4nkung von kognitiven und emotional appetitiven Mo-\nmenten im Vernunftvollzug dann vielmehr die Relevanz des \nNichtformalisierbaren. Es geht im Begreifen nicht mehr nur \ndarum, das Was  \u2013 die Fakten \u2013 zu begreifen, sondern darum, \nwie wir verstehen. Und dies wird entscheidend durch unsere \nleiblichen Vollz\u00fcge und F\u00e4higkeiten bestimmt, die vorbegriff-\nlich und unausgesprochenen unser Verhalten mitbestimmen.\nMenschliches Wissen ist insofern eingebettet in einen Ho-\nrizont des Nichtwissens. Im Raum individueller und soziokul-\ntureller Erfahrung wird deutlich, dass nicht nur die Klarheit \nlogischen Schlie\u00dfens, sondern auch die Vagheit und Offenheit \nmenschliches Denken auszeichnet. Gerade Vagheit und Un-\nbestimmtheit des Wissens sind Voraussetzung f\u00fcr Kreativit\u00e4t \nund Intuition, die ein Handeln unter der Bedingung von Unge-\nwissheit erm\u00f6glichen, mit der Menschen situativ auf konkrete \nHerausforderungen reagieren und Verantwortung \u00fcberneh-\nmen k\u00f6nnen. F\u00fcr menschliche Intelligenz ist kennzeichnend, \ndass sie sich auf pl\u00f6tzliche Situationen einstellen kann, um in \nErlebnisgegenwart Entscheidungen f\u00fcr oder gegen Zukunfts-\nszenarien zu treffen.\nWesentlich ist daher f\u00fcr menschliche Intelligenz und deren \nVerantwortungsf\u00e4higkeit auch das Erleben von und der Um-\ngang mit Zeit. Entscheidungen werden in Gegenwart erlebt 161und in solchem Gegenwartserleben bewusst gehalten. Auch \ndieses Gegenwartserleben ist in der Leiblichkeit der Vernunft \nverankert. Veranschaulicht werden kann dies an der Bedeu-\ntung des menschlichen Ged\u00e4chtnisses. Das menschliche Ge-\nd\u00e4chtnis funktioniert nicht wie ein Speicher, der einen gedank-\nlichen Bestand bildet und abrufbar w\u00e4re. Vielmehr ist es durch \nProzesse des Erinnerns und Vergessens ausgezeichnet. Was \njeweils im Moment erinnert \u2013 oder vergessen \u2013 wird, h\u00e4ngt \nvon der je konkreten leiblichen Verfasstheit und den sozialen \nBez\u00fcgen, in denen der Mensch steht, ab. Erinnern ist damit \nnicht gleichbedeutend mit dem Abrufen einer Information. Es \nist vielmehr ein hermeneutischer Akt, mit dem sich ein Erfah-\nrungsraum144 vergegenw\u00e4rtigt.\n3.5\t\t Fazit\nAus den vorherigen \u00dcberlegungen lassen sich einige entschei-\ndende Aspekte kognitiver Leistungen und Operationen von \nMenschen und Maschinen zusammenfassen. Das Kognitive \nist im Falle menschlicher Intelligenz unaufl\u00f6slich mit den ko-\ngnitiven und emotiven, \u00e4sthetischen und ethischen, techni-\nschen und gestalterischen, sozialen und individuellen sowie \nzeitlichen Dimensionen der menschlichen Lebenswelt ver -\nbunden. Menschliche Intelligenz zeigt sich nicht nur in einem \nkognitiv koh\u00e4renten Urteil, sondern auch in einer koh\u00e4renten \nPraxis. Diese ist gr\u00fcndegeleitet und Ausdruck von akzeptier -\nten Werten und Normen, die nicht beliebig zur Disposition \nstehen. Der Mensch ist durch die F\u00e4higkeit, Gr\u00fcnde zu geben \nund zu nehmen und sich im Urteil und im Handeln an diesen \nzu orientieren, als Spezies charakterisiert. Ver\u00e4nderungen im \nnormativen Gef\u00fcge der eigenen Praxis bed\u00fcrfen der Begr\u00fcn-\ndung und bedrohen im Grenzfall die pers\u00f6nliche Integrit\u00e4t \nund Identit\u00e4t. Ein hinreichend entwickeltes lebensweltliches \n144\tEbd.162Orientierungswissen ist Voraussetzung f\u00fcr eine intelligente \nPraxis. Damit sich dieses aufbaut, muss die betreffende Person \ndie F\u00e4higkeit haben, Wichtiges von Unwichtigem zu unter -\nscheiden und normative Grenzen zu akzeptieren.\nMenschliche Intelligenz ergibt sich zudem nicht allein \naus dem Orientierungsbedarf des Individuums in einer na-\nt\u00fcrlichen Welt, sondern ist das Ergebnis sozialer Interaktion. \nVon Geburt an h\u00e4ngt das Wohlbefinden menschlicher We-\nsen und h\u00e4ngen deren Entwicklungschancen vom Austausch \nmit anderen Menschen ab. Der intelligente Umgang mit den \nHerausforderungen der Welt ist nicht das Ergebnis eines fort-\ngesetzten Puzzlespiels, sondern im Wesentlichen Folge der \nEinbettung der eigenen individuellen Praxis in den gr\u00f6\u00dferen \nsozialen und kulturellen Zusammenhang. Mit dem Erwerb der \nSprache k\u00f6nnen Kinder auf Gr\u00fcnde reagieren, sich von Gr\u00fcn-\nden affizieren lassen und diese selbst auf ihr eigenes Handeln \napplizieren. Das kulturelle Wissen wird \u00fcber diese Praxis von \neiner Generation auf die n\u00e4chste \u00fcbertragen, immer wieder \nver\u00e4nderten Bedingungen angepasst und bettet das einzelne \nIndividuum in die menschliche Lebensform ein. Im Ergebnis \nverwebt sich dann die Einheit der Person mit der Einheit des \nWissens und der Einheit der menschlichen Lebensform. Die \neinzelne Person zerf\u00e4llt nicht in Funktionalit\u00e4ten, sondern \nwird zusammengehalten durch Gr\u00fcnde, die ihre theoretische \nund praktische Lebensorientierung bestimmen. Das Individu-\num wird zur Person und zum Handelnden. Die Identit\u00e4t der \nPerson \u00e4u\u00dfert sich in einer koh\u00e4renten Praxis, die von stabilen \nGr\u00fcnden geleitet ist. Diese integriert unterschiedliche Aspekte \nmenschlicher Existenz \u2013 kognitive, emotive, soziale, ethische, \n\u00e4sthetische, technische und gestalterische.\nEs ist fraglich, ob eine derart gr\u00fcndegeleitete, multidimen-\nsional bestimmte und soziokulturell eingebettete koh\u00e4rente \nPraxis selbst f\u00fcr komplexe maschinelle Systeme jemals plau-\nsibel sein k\u00f6nnte. Softwaresysteme leisten Beachtliches. In \nvielen Bereichen sind sie menschlichen F\u00e4higkeiten bei Wei-\ntem \u00fcberlegen. Aber sie verf\u00fcgen nicht \u00fcber ein Analogon zu 163menschlicher Intelligenz. Es wird der Softwareentwicklung \nder Zukunft vermutlich in wachsendem Umfang gelingen, \nmenschliche F\u00e4higkeiten zu simulieren und in vielen F\u00e4llen \nzu \u00fcbertreffen. Das sollte uns aber nicht dazu verf\u00fchren, ih-\nnen personale Eigenschaften zuzuschreiben, die f\u00fcr genuine \nmenschliche Existenz essenziell sind.\nTrotz dieser kategorialen Unterschiede von Mensch und \nMaschine beeinflussen Mensch und Maschine einander fort-\nw\u00e4hrend. Menschen entwickeln zu bestimmten Zwecken \nTechnologien, die auf die Handlungsm\u00f6glichkeiten von Men-\nschen zur\u00fcckwirken, indem sie jene ver\u00e4ndern, erweitern oder \nvermindern. Diese Mensch-Technik-Relationen und ihre ethi-\nsche Relevanz genauer zu bestimmen, ist Gegenstand des fol-\ngenden Kapitels.1644\t \t MENSCH-TECHNIK-RELATIONEN\n4.1\t\t Einleitung\nDas Verh\u00e4ltnis zwischen menschlichem Handeln, der Ver -\nf\u00fcgbarkeit von Technik und technischen Prozessen ist f\u00fcr die \nEthik hoch relevant, denn in diesem Verh\u00e4ltnis k\u00f6nnen sich \nEinfluss- und Randbedingungen f\u00fcr Autonomie und Freiheit \ndes Menschen und damit die M\u00f6glichkeit der Zuschreibung \nvon Verantwortung auf durchaus komplexe Weise \u00e4ndern. \nDies gilt vor allem und auf spezifische Weise bei KI-Systemen. \nEs ist daher im Rahmen einer ethischen Analyse und Beurtei-\nlung relevant, das Zusammenspiel von Mensch und Technik \nbzw. von menschlichem Handeln und technischen Prozessen \ndifferenziert zu erfassen. Menschen entwickeln und gestalten \nTechnik und nutzen technische Produkte und Systeme oder \ndarauf aufbauende Dienstleistungen als Mittel zum Zweck. \nGleichzeitig wirken diese h\u00e4ufig zur\u00fcck und beeinflussen \nmenschliche Handlungsm\u00f6glichkeiten, von der Er\u00f6ffnung \nneuer Optionen und der Vergr\u00f6\u00dferung von Freiheitsgra-\nden bis hin zur Anpassungserzwingung. In diesem Kapitel \nsoll es darum gehen, in welcher Art und Weise verschiedene \nMensch-Technik-Relationen die Handlungsm\u00f6glichkeiten des \nMenschen erweitern oder vermindern k\u00f6nnen, bis hin zur Er -\nsetzung menschlicher Handlungen durch maschinelle Vollz\u00fc-\nge. Damit verbunden ist die Frage, wie sich die Spielr\u00e4ume f\u00fcr \ndie Entfaltung menschlicher Autorschaft und die \u00dcbernahme \nvon Verantwortung jeweils ver\u00e4ndern.\nZum einen geht es darum, dass T\u00e4tigkeiten, die vormals \n(allein) von Menschen durchgef\u00fchrt wurden, graduell an tech-\nnische Systeme delegiert werden. Dies reicht vom Delegieren \neinfacher T\u00e4tigkeiten \u00fcber das Automatisieren komplexer \nT\u00e4tigkeiten oder ganzer Funktionen bis hin zur vollst\u00e4ndigen \nErsetzung des Menschen durch Technik. Der Begriff \u201eerset -\nzen\u201c beschreibt hier also den Endpunkt einer vollst\u00e4ndigen 165Delegation. Zum anderen geht es um R\u00fcckwirkungen dieses \nmehr oder minder umfassenden Delegierens auf menschli-\nche Akteure, das hei\u00dft um Fragen, inwiefern jenes Delegieren \nHandlungsf\u00e4higkeit, M\u00f6glichkeiten, Fertigkeiten und Kompe-\ntenzen von Menschen erweitert  oder vermindert.\nDie drei Begriffe des Erweiterns, Verminderns und Erset-\nzens dienen in diesem Kapitel als analytische Matrix. Sie wer -\nden in den folgenden Kapiteln auf ausgew\u00e4hlte Sektoren bezo-\ngen, um ein differenziertes Bild der Ver\u00e4nderungen durch KI \nund ihrer ethisch relevanten Aspekte zu gewinnen.\n4.2\t Technikdeterminismus\tversus\t\nSozialkonstruktivismus\nMensch-Technik-Relationen sind Gegenstand vieler Diszipli-\nnen. Verortet zwischen Informatik und Psychologie, besch\u00e4f-\ntigt sich insbesondere das Feld der Human-Computer Interac-\ntion bzw. Computer-Human Interaction mit dem Verst\u00e4ndnis \nund der Gestaltung von Mensch-Maschine-Schnittstellen. In \nden Geistes- und Sozialwissenschaften haben insbesondere die \nWissenschafts- und Technikforschung, die Science and Tech-\nnology Studies, die Techniksoziologie und die Technikphilo-\nsophie Konzepte und Theorien zur begrifflichen Analyse von \nMensch-Technik-Relationen bereitgestellt. Das Verh\u00e4ltnis \nvon Menschen und Gesellschaft zur Technik wurde vielfach \nentlang der Deutungslinie zwischen sozialem Konstruktivis-\nmus und technologischem Determinismus beschrieben.145 Da-\nhinter steht die Frage nach dem letztlich treibenden Faktor: \nFolgen Technikgestaltung im Einzelnen und damit auch der \ntechnische Fortschritt als Prozess eher menschlich gesetzten \nZwecken oder eher einer Eigendynamik, der sich Mensch und \nGesellschaft letztlich unterordnen und anpassen m\u00fcssen. Auch \nwenn es keine einheitliche Verwendungsweise dieser beiden \n145\t Grunwald\t2007.166Deutungen gibt und auch wenn viele Ans\u00e4tze keine der Ex-\ntrempositionen vertreten, sondern sich an unterschiedlichen \nStellen zwischen Sozial- und Technikdeterminismus verorten, \nist eine kurze Erl\u00e4uterung illustrativ und inhaltlich f\u00fcr diese \nStellungnahme wichtig.\nIn der bereits seit den 1920er-Jahren vertretenen tech-\nnikdeterministischen Sichtweise wird eine Eigenlogik im \ntechnischen Wandel vermutet, die Mensch und Gesellschaft \nzur Anpassung n\u00f6tigt. W\u00e4hrend sich einzelne Techniken auf \nmenschliche Zwecke zur\u00fcckf\u00fchren lassen, folge die gesamte \nTechnologieentwicklung einer inneren und damit nicht oder \nkaum beeinflussbaren Dynamik. Als Treiber hinter dieser ver -\nmuteten Eigendynamik wird immer wieder auf \u00f6konomische \nVerh\u00e4ltnisse und insbesondere den wirtschaftlichen Wett-\nbewerb zwischen Unternehmen, aber auch den Wettbewerb \nzwischen Staaten und Weltregionen um vordere Pl\u00e4tze in der \ntechnologischen Forschung und Entwicklung hingewiesen. \nDer auf diese Weise zustande kommende, sozusagen blinde \ntechnische Wandel wirke sodann mit seinen Produkten auf \ndie Gesellschaft ein und f\u00fchre zu Anpassungsnotwendigkei-\nten, die von konkreter Akzeptanz einzelner Techniken bis hin \nzur Adaptation an letztlich technologisches Denken reichen.146\nIn der sozialkonstruktivistischen Sichtweise dagegen treten \nTechnologien nicht eigendynamisch oder zwangsl\u00e4ufig auf \nden Plan, sondern sind das Ergebnis komplexer und sozial situ-\nierter Entwicklungs- und Gestaltungspraktiken bzw. von Ko-\nKonstruktionsprozessen unter Mitwirkung zahlreicher Akteu-\nre. Die Technikgeneseforschung147 hat herausgearbeitet, nach \nwelchen Mechanismen Technik durch Entscheidungsprozesse \naus ersten Ideen \u00fcber Entwicklungsprogramme, Experimente \nund Prototypen bis zum letztendlichen Ergebnis entsteht. Bei-\nspielsweise wurde die Rolle von gesellschaftlichen Leitbildern \n146\tRapp\t1978;\tRopohl\t1982;\tGrunwald\t2019.\n147\tBijker/Hughes/Pinch\t1987;\tWeyer\tet\tal.\t1997;\tWeingart\t1989.167in diesen Prozessen untersucht.148 Sozialkonstruktivistisch ge-\nsehen werden Algorithmen, Roboter, digitale Dienstleistungen \noder Gesch\u00e4ftsmodelle f\u00fcr digitale Plattformen von Menschen \nin m\u00f6glicherweise langwierigen Entscheidungsprozessen und \nHandlungsstr\u00e4ngen erfunden, entworfen, hergestellt und ein-\ngesetzt sowie weiterentwickelt und an neue Umgebungen an-\ngepasst. Die \u201eMacher\u201c der Digitalisierung arbeiten in der Regel \nin Unternehmen, Forschungsinstitutionen oder Geheimdiens-\nten mit bestimmten Agenden, Interessen und Gesch\u00e4ftsmo-\ndellen. Wenn andere Personen und Institutionen mit anderen \nWerten, Perspektiven und Interessen mitgestalten k\u00f6nnten, \nw\u00fcrden beispielsweise KI-Systeme mit anderen Eigenschaften \nentstehen, als wenn man diese den einschl\u00e4gigen Konzernen \nmit deren Interessen und Gesch\u00e4ftsmodellen \u00fcberl\u00e4sst. Diese \nSicht er\u00f6ffnete Gestaltungsm\u00f6glichkeiten und motivierte par -\ntizipative Ans\u00e4tze in der Technikgestaltung wie beispielsweise \ndas Constructive Technology Assessment.149\nDie grobe Skizze dieser beiden Positionen macht die je-\nweiligen blinden Flecken deutlich. Weder darf die Bedeutung \ngesellschaftlicher Hintergr\u00fcnde oder spezifischer Entschei-\ndungen bei der Entwicklung von Technik ignoriert werden, \nso etwa in Unternehmen oder der \u00f6ffentlich gef\u00f6rderten For -\nschung, noch kann abgestritten werden, dass Technologien auf \ngesellschaftliche Realit\u00e4ten und menschliche Handlungsm\u00f6g-\nlichkeiten zur\u00fcckwirken. Daher erscheint es ratsam, Tech-\nnikdeterminismus und Sozialkonstruktivismus als Pole eines \nempirisch vielf\u00e4ltigen und differenzierten Spektrums zu be-\ngreifen, die den Blick auf unterschiedliche Aspekte von Tech-\nnikentwicklung und Mensch-Technik-Relationen werfen.150 \nEntsprechend sind weder die technikdeterministische noch \ndie konstruktivistische Betrachtung der Mensch-Technik-\nRelation falsch, beide sind jedoch unterkomplex. Sie werden \n148\tDierkes/Hoffmann/Marz\t1992.\n149\tRip/Misa/Schot\t1995.\n150\t Dolata/Werle\t2007.168empirisch unzutreffend, wenn sie in ihrer jeweiligen Pers-\npektive verabsolutiert werden. Die Mensch-Technik-Relation \nunterliegt vielmehr von Grund auf einem Ko-Konstruktions-\nverh\u00e4ltnis und kann als Ko-Evolution beschrieben werden.151 \nSoziale Kontexte und normative Kriterien auf der einen und \nTechnologien auf der anderen Seite entwickeln sich weiter in \ngegenseitiger Wechselwirkung. Die Verf\u00fcgbarkeit von Technik \nbeeinflusst Handlungsm\u00f6glichkeiten und deren Realisierung, \naber auch die Bedingungen und M\u00f6glichkeiten menschlicher \nWeltwahrnehmung, wodurch sich Lebensstile und Einstel-\nlungen ver\u00e4ndern k\u00f6nnen. Umgekehrt entstehen, wie dies die \nTechnikgeneseforschung in vielen empirischen Studien belegt \nhat, neue Techniken vor dem Hintergrund von sozialen Be-\nfindlichkeiten, normativen Kriterien und Zukunftsentw\u00fcrfen.\nGerade im Kontext der KI sind die Arbeiten der Anth-\nropologin Lucy Suchman von gro\u00dfer Bedeutung. Ihr Buch \n\u201eHuman-Machine Reconfigurations\u201c152 liefert eine Reflexion \nund Kontextualisierung ihrer Studien der KI-Forschung in \nden 1980er-Jahren, welche 1987 unter dem Titel \u201ePlans and \nSituated Actions\u201c153 ver\u00f6ffentlicht wurden. Suchman kritisiert \ndas Planungsmodell von Interaktion, das einem Gro\u00dfteil der \ndamaligen Forschung zugrunde liegt, und schl\u00e4gt einen Per -\nspektivenwechsel in der Betrachtung der Mensch-Maschine-\nRelation vor, der Einsichten aus den Sozialwissenschaften \nRechnung tr\u00e4gt. Danach ist menschliches Handeln auf vielf\u00e4l-\ntige Weise sozial situiert und beeinflusst, ohne vollst\u00e4ndig de-\nterminiert zu sein. Sie argumentiert, dass Menschen sinnvoll \nhandeln, indem sie auf der Grundlage ihrer sozialen und \u00f6ko-\nlogischen Ressourcen h\u00e4ufig weniger planen als improvisieren. \nSie kritisiert also die theoretisch-konzeptionellen Grundlagen \ndes Designs interaktiver technischer Systeme als aus anthro-\npologischer Sicht unangemessen, weil menschliches Handeln \n151\t Rip\t2007.\n152\t Suchman\t2007.\n153\t Suchman\t1987.169st\u00e4ndig aus dynamischen Interaktionen mit der materiellen, \ninsbesondere technischen und der sozialen Welt konstruiert \nund rekonstruiert werde.\nTechnikphilosophie und -soziologie haben die zuneh-\nmende Komplexit\u00e4t der Mensch-Maschine-Relation in unter -\nschiedlichen Theorien gedeutet und zugespitzt. In der Tech-\nnikphilosophie wird Technik h\u00e4ufig nicht mehr als Ensemble \ntechnischer Objekte verstanden, sondern als Medium, mit dem \nsich menschliches Handeln und Verhalten vollzieht. W\u00e4hrend \ndie einzelnen Elemente dieses Mediums instrumentellem \nZweck-Mittel-Denken entstammen, stelle ihre Gesamtheit \neine \u201ezweite Natur\u201c dar, die Rand- und Erfolgsbedingungen \nf\u00fcr weiteres menschliches Leben setzt und auch die Weltsicht \nund das Probleml\u00f6sen beeinflusst.154 Als die bereits technolo-\ngisch orientierten Menschen, zu denen sie im Rahmen vieler \nTechnisierungsprozesse geworden sind, werden sie zum Bei-\nspiel dazu neigen, Herausforderungen von Kommunikation \noder Sicherheit als Probleme anzusehen, die prim\u00e4r technolo-\ngisch zu l\u00f6sen sind. Somit ist neue Technologie oft bereits das \nErgebnis einer technologischen Art und Weise, wie Menschen \ndie Welt sehen und sich zu ihr in Beziehung setzen.\nTechniksoziologisch sind hier vor allem Ans\u00e4tze der Ko-\nEvolution von Technik und Gesellschaft zu nennen.155 In ih-\nnen sind die sozialkonstruktivistischen Motive der Gestaltung \naufgenommen, jedoch wird ihnen die vielf\u00e4ltige R\u00fcckwirkung \neinmal entwickelter und verf\u00fcgbarer Technik auf Mensch \nund Gesellschaft zur Seite gestellt, zu denen beispielsweise die \ngro\u00dfen Infrastruktursysteme \u2013 wie jene der Mobilit\u00e4t \u2013 ge-\neignetes Illustrationsmaterial liefern. Zun\u00e4chst gestaltet nach \nZweck-Mittel-Erw\u00e4gungen unter Ber\u00fccksichtigung vielf\u00e4lti-\nger gesellschaftlicher Belange beispielsweise aus Wirtschaft, \nB\u00fcrgerschaft und Umweltschutz, werden sie nach Fertigstel-\nlung zu Randbedingungen menschlicher Entscheidungen, \n154\t Hubig\t2006.\n155\t Rip\t2007.170zum Beispiel in Bezug auf die Wahl des Wohnortes oder die \nAnsiedlung von Betrieben. Die Akteur-Netzwerk-Theorie156 \nsowie unterschiedliche Sichtweisen innerhalb der Technik-\nphilosophie157 haben die Gedanken von Ko-Konstruktion und \nKo-Evolution erweitert und teils die technischen Objekte auf-\ngrund ihres Einflusses auf den Menschen als Ko-Akteure (Ak-\ntanten) definiert.\n4.3\t\t Mehrstufige\tMensch-Technik-\nWechselwirkungen\nDie zunehmende Komplexit\u00e4t der Mensch-Technik- bzw. \nMensch-Maschine-Relation ver\u00e4ndert auch deren Wahrneh-\nmung. Insbesondere KI-gesteuerte Systeme wie Produktions-\nroboter, \u201eautonome\u201c Fahrzeuge, Therapieprogramme oder \nSchachcomputer sind Beispiele digitaler Technik, in denen die \nvormals klaren Unterscheidungen von Mensch und Technik \nweniger eindeutig zu werden scheinen. Androide Roboter er -\nscheinen menschen\u00e4hnlich, Hilfesuchende interagieren mit \nTherapieprogrammen, als ob es sich um menschliche The-\nrapiekr\u00e4fte handeln w\u00fcrde, und der Schachcomputer scheint \ndie Partie gewinnen \u201ezu wollen\u201c. Die Anthropomorphisierung \ndigitaler Technik ist in der Umgangssprache weit fortgeschrit-\nten. Sie zeigt sich darin, dass KI und Robotern F\u00e4higkeiten wie \nDenken, Lernen, Entscheiden oder Emotionalit\u00e4t zugeschrie-\nben werden, wodurch sie scheinbar in die Gemeinschaft der \ndenkenden, lernenden, entscheidenden und f\u00fchlenden Men-\nschen aufgenommen werden.\nPh\u00e4nomenologisch geht damit einher, dass sich durch \n\u201eautonom\u201c werdende KI-gest\u00fctzte Technik Subjekt-Objekt-\nVerh\u00e4ltnisse zwischen Mensch und Technik ver\u00e4ndern. Im \ntraditionellen Bild gestalten und nutzen menschliche Subjekte \n156\t Latour\t2007.\n157\t Hubig\t2006;\tIhde\t1990.171technische Objekte. Bereits mit traditioneller Software, mehr \nnoch mit KI, kommt es jedoch zu neuen Konstellationen. In \nvernetzten Systemen haben Menschen teils die Subjekt-, teils \naber auch die Objektrolle inne. Wenn einerseits Entscheidun-\ngen \u00fcber Menschen an Softwaresysteme delegiert werden, \nbeispielsweise hinsichtlich der Gew\u00e4hrung von Krediten oder \nSozialleistungen, werden Menschen zu Objekten der \u201eEnt-\nscheidungen\u201c dieser Systeme, die hier auftreten, als ob sie Sub-\njekte seien. Andererseits kann die Subjektrolle von Menschen \ndurch gute Software zur Entscheidungsunterst\u00fctzung erh\u00f6ht \nwerden, beispielsweise wenn diese qualitativ hochwertige, dis-\nkriminierungsfreie und nachvollziehbare Informationen lie-\nfern, welche die Qualit\u00e4t menschlicher Entscheidungen und \nderen Begr\u00fcndbarkeit verbessern. Verschiebungen in den \nSubjekt-Objekt-Rollen zwischen Mensch und Technik m\u00fcssen \ndaher differenziert betrachtet werden. Sie h\u00e4ngen einerseits \nvom Ausma\u00df und diversen technischen und organisationalen \nDetails ab; andererseits \u2013 und dies ist von besonderer ethischer \nRelevanz \u2013 manifestieren sie sich bei verschiedenen Personen-\ngruppen auf unterschiedliche Weise.\nDie Gestaltung der Software und der damit operierenden \nMaschinen gibt jeweils die Alternativen vor, innerhalb derer \nMenschen handeln k\u00f6nnen. Optionen, die in dem Design nicht \nvorgesehen sind, werden ausgeschlossen. Algorithmen und \nMaschinen regulieren somit menschliches Handeln.158 Der -\nartige Prozesse finden in der Digitalisierung seit Jahrzehnten \nstatt, werden aber durch KI-Systeme versch\u00e4rft. Menschliche \nAkteure erleben dadurch einerseits eine Verminderung ihrer \nAutorschaft \u00fcber das eigene Handeln und f\u00fchlen sich zuneh-\nmend eingeschr\u00e4nkt und fremdbestimmt. Andererseits wer -\nden KI-Systeme zielgerichtet von Akteuren eingesetzt, um die \neigenen Handlungsm\u00f6glichkeiten zu erweitern. Ein Beispiel \nhierf\u00fcr sind ADM-Systeme, die Klassifikationen und Progno-\nsen vornehmen und beispielsweise durch das Errechnen von \n158\t Orwat\tet\tal.\t2010.172Risikoscores Menschen bei der Entscheidungsfindung unter -\nst\u00fctzen (vgl. Beispiele in Teil II). Es ist immer wieder ein er -\nw\u00fcnschter Effekt erweiterter Autorschaft, wenn menschliche \nEntscheidungen dadurch auf eine sachlichere Grundlage ge-\nstellt werden. Auf der anderen Seite jedoch droht das Risiko, \ndass Menschen den Ergebnissen der KI-Systeme, auch wenn \ndiese nur als Vorschl\u00e4ge unterbreitet werden, einfach blind \nfolgen. Dann w\u00fcrde die Person, die eine Entscheidung trifft, \neher reagieren als aus eigener Einsicht heraus agieren, was \nihre Autorschaft vermindern w\u00fcrde (Automation Bias). Ne-\nben den bereits vielfach diskutierten Herausforderungen an \neine transparente und rechtssichere Zuschreibung von Ver -\nantwortung in komplexen Mensch-Technik-Systemen, etwa \nbeim \u201eautonomen\u201c Fahren159, ist von anthropologischer und \nethischer Relevanz, inwieweit die digitalen Systeme Menschen \nunterst\u00fctzen und dadurch die M\u00f6glichkeit der Entfaltung der \nmenschlichen F\u00e4higkeiten erweitern oder durch technische, \nvon den Herstellern der Systeme vorgegebene Handlungssche-\nmata diese Entfaltung behindern und vermindern.\nDie angedeutete Komplexit\u00e4t neuer Mensch-Maschine-\nWechselwirkungen und die erw\u00e4hnten Verschiebungen in \nSubjekt-Objekt-Rollen haben nicht nur in der \u00f6ffentlichen De-\nbatte, sondern auch in der Wissenschaft zu einer Aufweichung \neines strikten Dualismus zwischen Mensch und Maschine ge-\nf\u00fchrt. So wird vor allem in der Wissenschafts- und Technikfor -\nschung (Science and Technology Studies) sowie der Technik-\nsoziologie seit Jahrzehnten \u00fcber die \u201eHandlungstr\u00e4gerschaft\u201c \nvon technischen Systemen diskutiert. Einige dieser Positionen, \ninsbesondere die Akteur-Netzwerk-Theorie160, die einen sehr \nschwachen Handlungsbegriff propagiert und diesen auf viele \nEntit\u00e4ten ausweitet, stehen dabei in deutlicher Spannung mit \nder im vorigen Kapitel ausf\u00fchrten philosophischen Hand-\nlungstheorie, die einen anspruchsvollen Handlungsbegriff \n159\t Ethik-Kommission\tAutomatisiertes\tund\tvernetztes\tFahren\t2017.\n160\tLatour\t2007;\tLaw/Hassard\t1999.173beschreibt und diesen auf menschliche Akteure beschr\u00e4nkt. \nJenseits disziplin\u00e4rer Einzelperspektiven stellen sich in Anbe-\ntracht der zunehmenden Verschr\u00e4nkung und wechselseitigen \nBeeinflussung von Menschen und Maschinen unter anderem \nfolgende Fragen:\n>> Reicht das technische Vokabular zur Beschreibung von KI-\nSystemen noch aus, um Ph\u00e4nomene komplexer Interaktio-\nnen von Mensch und Maschine zu beschreiben?\n>> Inwiefern kann bzw. sollte davon gesprochen werden, dass \nMaschinen handeln oder mithandeln k\u00f6nnen? Sollte also \nMaschinen die Rolle von Akteuren zugesprochen werden \nund wenn ja, unter welchen Bedingungen und mit welchen \nImplikationen?\n>> Kommt es zu Verschiebungen in den M\u00f6glichkei-\nten menschlicher Autorschaft und wenn ja, in welchen \nRichtungen?\nDie Akteur-Netzwerk-Theorie beantwortet diese Fragen, in-\ndem sie technischen Systemen den Status von Akteuren mit \neigenen Dynamiken zuspricht und von hybriden Handlungs-\nzusammenh\u00e4ngen zwischen Mensch und Maschine ausgeht.161 \nAls Beobachtungstheorie ohne spezifische normativ-anthro-\npologische Pr\u00e4missen hilft sie, vermeintlich autonome Wir -\nkungen von Techniken, Artefakten oder Sachen und deren \ngesellschaftsver\u00e4nderndes Potenzial zu erkennen. So kann es \ngelingen, Ph\u00e4nomene aus der Beobachterperspektive in den \nBlick zu nehmen, die mit einem starken, die Autonomie be-\ntonenden Handlungsbegriff tendenziell ausgeblendet werden. \nFreilich bleibt die Frage nach dem Zusammenhang zwischen \nHandlung und Verantwortung hier offen.\nDer Soziologe Werner Rammert, einer der Pioniere der \nThematisierung m\u00f6glicher Handlungstr\u00e4gerschaft von Tech-\nnik, schl\u00e4gt einen Mittelweg zwischen einer anspruchsvoll \n161\t Latour\t2007.174normativen Vorstellung von Handeln und der Vorstellung ei-\ngenm\u00e4chtigen maschinellen Agierens vor. Stattdessen soll von \neiner verteilten Handlungstr\u00e4gerschaft zwischen Mensch und \nMaschine gesprochen werden, um die Vorstellung zu vermei-\nden, Technik sei etwas au\u00dferhalb des Sozialen Stehendes.162 \nSo geht Rammert wie die Akteur-Netzwerk-Theorie von hy-\nbriden, soziotechnischen Konstellationen aus, in denen Men-\nschen und Maschinen auf komplexe Weise wechselwirken. \nDas Handeln des Menschen in dieser Perspektive sieht er zwar \nvon technischen Prozessen beeinflusst, jedoch nicht als deter -\nminiert an. Der Einfluss der Technik kann sich in beiden Rich-\ntungen auswirken: Individuelle Freiheitsspielr\u00e4ume und die \nEntfaltung der menschlichen Autorschaft des eigenen Lebens \nk\u00f6nnen sowohl erweitert als auch vermindert werden.\nVor diesem Hintergrund schl\u00e4gt Rammert vor, die Wech-\nselwirkung von Mensch und Technik dreistufig zu beschrei-\nben, um sowohl die Komplexit\u00e4t dieser Wechselwirkungen \nempirisch zu erfassen als auch die Zuschreibung von Verant-\nwortung auf Menschen zu begrenzen. Als Stufe 1 nennt er Kau -\nsalit\u00e4t im Sinne von, Ver\u00e4nderung bewirken zu k\u00f6nnen. Stufe \n2 beschreibt er als Kontingenz mit der Bedeutung, auch anders \nagieren zu k\u00f6nnen. Stufe 3 schlie\u00dflich ist durch Intentionalit\u00e4t \ngekennzeichnet, was beinhaltet, das eigene Verhalten deuten \nund steuern zu k\u00f6nnen. Kausalit\u00e4t und Kontingenz charakteri-\nsieren nach Rammert nicht nur die menschliche Intervention, \nsondern auch die von Technologien. Algorithmen \u201ew\u00e4hlen\u201c \nzwischen Alternativen; automatisierte Entscheidungssysteme \n\u201ebestimmen\u201c einen Risikoscore, auf dessen Basis entweder \nein Mensch eine Entscheidung trifft, beispielsweise \u00fcber eine \nKreditvergabe, oder die Software \u201eentscheidet\u201c sogar selbst, \nwelche Bewerbungen bereits vorab aussortiert und der Per -\nsonalabteilung erst gar nicht angezeigt werden. Algorithmen \nwirken hier auf mannigfaltige und h\u00f6chst komplexe Weise, \nohne dass ihnen daf\u00fcr Intentionalit\u00e4t unterstellt werden kann. \n162\t Rammert/Schulz-Schaeffer\t2002.175Intentionalit\u00e4t n\u00e4mlich, die h\u00f6chste Stufe des \u201eAgierens\u201c, ist \ndem Handeln von Menschen vorbehalten. Daher kann nach \nRammert nur ihnen Verantwortung zugeschrieben werden.\nDie genannten Schwierigkeiten bei der Zuschreibung von \nVerantwortung haben auch den Philosophen Luciano Flori-\ndi motiviert, eine Theorie \u201everteilter Moralit\u00e4t\u201c163 zu entwi-\nckeln, die auf die Komplexit\u00e4t digitaler Mensch-Maschine-\nSysteme zugeschnitten ist. Basierend auf fr\u00fcheren Arbeiten164 \nunterscheidet er zwischen moralischer Handlungsf\u00e4higkeit \n(moral agency) und moralischer Verantwortlichkeit (moral \nresponsibility).165 W\u00e4hrend er \u2013 wie Rammert \u2013 Intentionali-\nt\u00e4t als notwendig f\u00fcr Verantwortlichkeit erachtet, ist sie keine \nBedingung f\u00fcr Handlungsf\u00e4higkeit. F\u00fcr Letzteres reichen In-\nteraktivit\u00e4t, Autonomie und Adaptivit\u00e4t aus. KI-Algorithmen \nbzw. verteilte Mensch-KI-Systeme k\u00f6nnen demnach f\u00fcr ihre \n\u201eHandlungen\u201c zwar accountable, aber nicht responsible sein, da \nihnen die Intentionalit\u00e4t fehle. Die moralischen Eigenschaften \nder Ergebnisse verteilter Handlungstr\u00e4gerschaft emergieren \naus den einzelnen Elementen, ohne dass ihnen eine Intention \nzugrunde liegt.\nAuch der Versuch von Floridi, die Interaktionen von \nMensch und Maschine angemessen zu beschreiben, l\u00e4sst die \nFrage der Zuschreibung von Verantwortung offen.166 Es gibt \nmoralisch bedeutsame Aktionen von KI-Systemen, insofern \nals moralisch problematische Resultate durch KI-Systeme ver -\nursacht werden. Den Systemen kann daf\u00fcr aber keine Verant-\nwortung zugeschrieben werden. Verantwortung muss daher \nanders geregelt werden, zum Beispiel durch Zuschreibung von \nVerantwortung an relevante Institutionen bzw. Organisati-\nonen. Dies k\u00f6nnen beispielsweise die Betreiber dieser Syste-\nme sein, da sie aufgrund ihrer intentionalen Entscheidung zu \n163\t Floridi\t2013.\n164\tFloridi/Sanders\t2004.\n165\t Da\tdie\t\u00fcblichen\tdeutschen\t\u00dcbersetzungen\tnicht\timmer\tgenau\tzu\tpassen\t\nscheinen,\tsind\thier\tdie\tenglischen\tOriginalbegriffe\terhalten.\n166\tFloridi\t2016.176deren Einsatz einschlie\u00dflich der diffusen Verteilung von agen -\ncy zugestimmt haben und damit \u2013 auch im Sinne von Floridi \n\u2013 verantwortlich sind. Der von der Europ\u00e4ischen Union ge-\nplante Artificial Intelligence Act wird folglich die Verantwort-\nlichkeit konkret zuweisen m\u00fcssen, um wirksam zu regulieren.\nDie hier vorgestellten techniksoziologischen und -philo-\nsophischen Ans\u00e4tze, die sich um ein differenziertes Verst\u00e4nd-\nnis der zunehmend komplexen Mensch-Technik-Wechsel-\nwirkungen in Bezug auf KI-Systeme bem\u00fchen, k\u00f6nnen mit \nden anthropologischen Positionen, die in Kapitel 3 dargelegt \nwurden, durchaus in Konflikt geraten. Entsprechend der dort \nausgef\u00fchrten anspruchsvollen philosophischen Handlungs-\ntheorie k\u00f6nnen Maschinen nicht handeln, weil sie nicht \u00fcber \nIntentionen verf\u00fcgen, und kommen daher als genuine Akteure \nnicht infrage, jedenfalls nicht nach gegenw\u00e4rtigem Stand der \nEntwicklung. Aber auch wenn technischen Systemen keine \nHandlungsf\u00e4higkeit und damit Verantwortung zugeschrieben \nwerden kann, haben sie Einfluss auf menschliches Handeln. \nMenschliches Handeln ist weder v\u00f6llig autonom noch v\u00f6llig \nsozial oder technisch determiniert, sondern in zunehmendem \nMa\u00dfe soziotechnisch situiert. Auch in der Digitalisierung und \nder KI ist dies empirisch durch zahlreiche Studien belegt, ins-\nbesondere zum Automation Bias bzw. zu den Effekten von \nNudging.167 Diese Effekte sind h\u00f6chst bedeutsam f\u00fcr ethische \nFragen, zeigen sie doch, dass technologische Entwicklungen \nmenschliche Handlungsf\u00e4higkeit beeinflussen und mensch-\nliche Autonomie und Autorschaft sowohl erweitern als auch \nvermindern k\u00f6nnen.\n167\t Unter\tNudging\tversteht\tman\tdie\tFormatierung\teiner\tEntscheidungssi-\ntuation\tohne\tan\tden\tHandlungsalternativen\tetwas\tzu\tver\u00e4ndern,\tsodass\t\nerw\u00fcnschtes\tVerhalten\twahrscheinlicher\twird\t(Thaler/Sunstein\t2011).1774.4\t Erweiterung\tund\tVerminderung\t\nmenschlicher\tAutonomie\tund\t\nAutorschaft\nAngesichts der konstatierten intensiven und komplexen \nWechselwirkungen zwischen Mensch und Technik stellt sich \ndie Frage nach den Folgen des digital-technischen Fortschritts \nf\u00fcr die Bedingungen gelingenden Handelns und die M\u00f6glich-\nkeiten, menschliche Autorschaft zu entfalten. Bisherige Erfah-\nrungen zeigen Ambivalenzen und Dialektiken von ethischer \nRelevanz.168 Neue Technologien sollen einerseits und vor al-\nlem, so die Erz\u00e4hlung sp\u00e4testens seit Francis Bacon und der \neurop\u00e4ischen Aufkl\u00e4rung, die Menschen von den Zw\u00e4ngen der \nNatur und der Tradition emanzipieren, Freiheitsr\u00e4ume durch \nneue Handlungsoptionen er\u00f6ffnen und damit die Entfaltungs-\nm\u00f6glichkeiten menschlichen Handelns erweitern. Entspre-\nchende Effekte zeigen sich in der Tat im raschen Fortschritt \nder digitalen Technologien: globale Kommunikation in Echt-\nzeit, schnelle Information, Mustererkennung durch Big Data, \nEffizienzsteigerung und Beschleunigung der Produktion, neue \nDienstleistungen und Gesch\u00e4ftsmodelle, bessere medizini-\nsche Diagnosen und Therapien, Roboter und Algorithmen als \nk\u00fcnstliche Assistenten, selbstfahrende Autos, Minenr\u00e4umro-\nboter und vieles mehr. Speziell die KI er\u00f6ffnet M\u00f6glichkeiten, \nmenschliches Handeln zu verbessern, so etwa durch Muste-\nrerkennung in gro\u00dfen Datenmengen f\u00fcr medizinische oder \nbeh\u00f6rdliche Zwecke, durch darauf aufbauende verbesserte \nVorhersagen zum Beispiel zur Ausbreitung von Infektions-\nkrankheiten oder f\u00fcr Prognosen in der Polizeiarbeit (Predic-\ntive Policing), durch neue M\u00f6glichkeiten individualisierter \nInformation und Werbung, aber auch durch Anwendungen \nim Bildungsbereich. Technik ist zentraler Teil menschlichen \nLebens und gesellschaftlicher Vollz\u00fcge zumindest in den in-\ndustrialisierten Regionen der Welt geworden und hat in vielen \n168\tGrunwald\t2022.178F\u00e4llen eindeutig positive Folgen in dem Sinne gezeitigt, dass \ndie M\u00f6glichkeiten menschlicher Autorschaft erweitert wurden \n\u2013 jedenfalls f\u00fcr den Teil der Erdbev\u00f6lkerung, der, vor allem im \nglobalen Norden, Zugang zu ihren Vorteilen hat.\nIm Rahmen der Diffusion von Technik und Innovatio-\nnen in die Gesellschaft, ihrer Nutzung und Verallt\u00e4glichung \nkommt es jedoch h\u00e4ufig zu Sekund\u00e4reffekten, die als negativ \nwahrgenommen werden. Zu den nicht intendierten Folgen \nwie Umweltproblemen und sozialen Verwerfungen z\u00e4hlen \nauch Begrenzungen menschlicher Entfaltungsm\u00f6glichkeiten. \nIn die Erweiterung menschlicher Autonomie und Autorschaft \nim technischen Fortschritt ist ihre simultane Verminderung \noft entweder bereits eingeschrieben oder entwickelt sich em-\npirisch kontingent. Erweiterung und Verminderung sind \nh\u00e4ufig ineinander verschr\u00e4nkt, betreffen jedoch meist unter -\nschiedliche Beteiligte in unterschiedlicher Weise, so etwa die-\njenigen, die Entscheidungen treffen, und diejenigen, die von \ndiesen Entscheidungen betroffen sind. W\u00e4hrend die Facetten \nder Erweiterung offensiv kommuniziert werden und oft auch \ndeutlich sichtbar sind, etwa aufgrund neuer F\u00e4higkeiten von \nIT-Systemen, ist ihre Kehrseite, die nicht immer aber immer \nwieder auftretende simultane Verminderung menschlicher \nEntfaltungsm\u00f6glichkeiten, oft nicht gut erkennbar.\nVerminderungen qualifizierter Handlungsformen und \nEntfaltungsm\u00f6glichkeiten im Rahmen der Nutzung von Tech-\nnik k\u00f6nnen etwa in folgenden Richtungen auftreten:\n(1) Entstehende Abh\u00e4ngigkeiten: Mit dem Erfolg von Tech-\nnik sind moderne Gesellschaften von ihrem reibungslosen \nFunktionieren abh\u00e4ngig geworden. Dies beginnt individuell \nmit der Abh\u00e4ngigkeit von Computer und Auto und reicht \ngesellschaftlich bis hin zur vollst\u00e4ndigen Abh\u00e4ngigkeit vom \nFunktionieren der Energieversorgung und der weltweiten \nDatenkommunikationsnetze. Die individuelle wie kollektive \nAbh\u00e4ngigkeit von digitalen Technologien, insbesondere vom \nInternet, durchzieht s\u00e4mtliche gesellschaftlichen Prozesse: \nohne Internet keine funktionierende Weltwirtschaft, keine 179Finanztransaktionen, Kollaps internationaler Logistikketten, \nZusammenbruch der \u00f6ffentlichen wie privaten Kommunikati-\non. Entsprechend f\u00fchrt jede \u00dcbertragung von Zust\u00e4ndigkeiten \nbeispielsweise durch den Einsatz von Software zur Entschei-\ndungsunterst\u00fctzung zu einer gewissen Abh\u00e4ngigkeit. Abh\u00e4n-\ngigkeit jedoch vermindert menschliche Entfaltungsm\u00f6glich-\nkeit, da sie Sachzw\u00e4nge zum Weiterbetrieb der technischen \nSysteme nach sich zieht und die Vulnerabilit\u00e4t der Gesellschaft \ngegen\u00fcber technischem Versagen und intendierten St\u00f6rungen \n(z. B. Hacking) steigert.\n(2) Anpassungsdruck: Technik n\u00f6tigt zur Anpassung. Das \nist auf der Ebene konkreter technischer Objekte wie Maschi-\nnen trivial; es m\u00fcssen beispielsweise Bedienungsanleitun-\ngen beachtet werden, um die Technik sachgerecht nutzen zu \nk\u00f6nnen. Digitale Technik jedoch reguliert und \u00e4ndert subtil \nmenschliches Handeln und Verhalten. Softwaresysteme steu-\nern vielfach explizit oder implizit Verhalten.169 So struktu-\nrieren privat gef\u00fchrte digitale Infrastrukturen die politische \nKommunikation, sortieren Suchmaschinen die Welt mithilfe \nder von ihnen gesetzten Filter und strukturieren Onlineplatt-\nformen Gesch\u00e4ftsprozesse. Dahinter steht beispielsweise die \nschlecht durch Daten belegbare Bef\u00fcrchtung, dass menschli-\nches Denken und Handeln durch fortschreitende Anpassung \nan Softwaresysteme allm\u00e4hlich nach deren Anforderungen \nund Vorgaben reguliert und immer st\u00e4rker im technischen \nSinn normiert werden k\u00f6nnte. Menschliche Autorschaft w\u00fcr -\nde leise und unbemerkt, sozusagen durch allm\u00e4hliche Gew\u00f6h-\nnung, unkritische \u00dcbernahme algorithmischer Vorschl\u00e4ge \n(Automation Bias) und Anpassung an technische Voreinstel-\nlungen, ausgeh\u00f6hlt.\n(3) Verschlie\u00dfen von Optionen: Immer wieder werden mit \ndem Er\u00f6ffnen neuer Handlungsspielr\u00e4ume andere, bis dato \netablierte Optionen abgewertet oder ganz verschlossen. In der \n169\tBowker/Star\t1999;\tNguyen\t2021.180Innovationstheorie gilt dies als \u201esch\u00f6pferische Zerst\u00f6rung\u201c.170 \nDies ist einerseits der normale Gang von Transformation und \nWandel. Andererseits aber st\u00fcrzen Innovationen vorhandene \nAnerkennungs- und Wertstrukturen durch disruptive Effekte \num und ziehen Gewinner wie auch Verlierer nach sich. Von \nden neuen Optionen profitieren h\u00e4ufig andere Personen und \nGruppen als die, die dann im Verschlie\u00dfen der traditionellen \nOptionen zu Verlierern des Wandels werden. Zum Verschlie-\n\u00dfen von Optionen menschlicher Entfaltung durch technischen \nFortschritt f\u00fchren unterschiedliche Mechanismen. So werden \nInfrastruktursysteme h\u00e4ufig faktisch machtf\u00f6rmig, indem sie \nLebensformen au\u00dferhalb dieser Systeme benachteiligen oder \nunm\u00f6glich machen. Beispielsweise wird mittlerweile h\u00e4ufig die \nNutzung eines Smartphones vorausgesetzt, um an bestimmten \nLebensvollz\u00fcgen teilnehmen zu k\u00f6nnen. Diese Form der Ver -\nschlie\u00dfung von Optionen kann verschiedene Bev\u00f6lkerungs-\ngruppen unterschiedlich treffen und Gerechtigkeitsprobleme \nmit sich bringen, wie dies zum Beispiel unter dem Stichwort \n\u201edigitale Spaltung\u201c (digital divide) diskutiert wird. Ein anderer \nMechanismus besteht in allm\u00e4hlicher Gew\u00f6hnung als Folge \nder oben erw\u00e4hnten Anpassung. Technik, gerade die Digital-\ntechnik, macht vielfach das Leben angenehm und komforta-\nbel. Sobald Routinehandlungen in Beruf oder Freizeit daran \nadaptiert wurden, geh\u00f6rt diese Technik so zum Leben, dass es \nohne diese Technik oft kaum noch vorstellbar ist. Alternative \nOptionen verschlie\u00dfen sich, vermeintliche Sachzwang-Argu-\nmente erwecken den Anschein der Alternativlosigkeit, sind \njedoch nur Ausdruck der schleichend eingetretenen Pfadab-\nh\u00e4ngigkeit durch allm\u00e4hliche Anpassung und Gew\u00f6hnung.\nDiese Mechanismen, in denen Optionen menschlichen \nHandelns sich verschlie\u00dfen, k\u00f6nnen im Rahmen der Diffusion \nneuer Technologien in die Anwendung auftreten, ohne dass \nIntentionen von Akteuren dahinterstehen. Es geht nicht um \neine Verminderung menschlicher Autorschaft durch bewusste \n170\t Schumpeter\t2018,\t113\u00a0ff.181Delegation vormals menschlicher Handlungsvollz\u00fcge an KI-\nSysteme, sondern um Effekte, die schleichend und teilweise \nunbewusst durch Verhaltens\u00e4nderungen entstehen. Das Erset-\nzen als Endpunkt des Delegierens vormals menschlich ausge-\n\u00fcbter T\u00e4tigkeiten an technische Systeme erfolgt jedoch intenti-\nonal. Es betrifft Funktionen und T\u00e4tigkeiten, die technomorph \nbeschrieben und sodann von KI-gesteuerten Systemen \u00fcber -\nnommen werden k\u00f6nnen, im Idealfall funktions\u00e4quivalent \noder \u201ebesser\u201c.171 Motivationen, menschliche T\u00e4tigkeiten durch \nKI-Systeme zu ersetzen, sind zum Beispiel die Effizienzstei-\ngerung beh\u00f6rdlicher Funktionen, die Kostensenkung in der \nindustriellen Produktion, die Routinisierung diagnostischer \nAuswertungen in der Medizin oder die Erm\u00f6glichung auto-\nmatisierter \u00dcberwachung in Echtzeit.\nBezogen auf die M\u00f6glichkeit menschlicher Autorschaft \nstellt sich die Ersetzung menschlicher T\u00e4tigkeiten zun\u00e4chst als \nResultat menschlicher Entscheidungen dar. So wird beispiels-\nweise in Unternehmen oder Beh\u00f6rden aus unterschiedlichen \nGr\u00fcnden die Entscheidung getroffen, bestimmte T\u00e4tigkei-\nten, die zuvor von Menschen durchgef\u00fchrt wurden, an ma-\nschinelle Systeme zu \u00fcbertragen. Dies k\u00f6nnen beispielsweise \nADM-Systeme in unterschiedlichen Anwendungen sein, etwa \nin der Medizin, im Sicherheitsbereich oder im Sozialwesen. \nDiese \u00dcbertragung ist f\u00fcr sich genommen ein Ausdruck der \nWahrnehmung menschlicher Autorschaft in bestimmten in-\nstitutionellen Kontexten und unter entsprechenden Randbe-\ndingungen. Die zentrale ethische Frage ist, ob und wie diese \n\u00dcbertragung die M\u00f6glichkeiten anderer Menschen beeinflusst, \nvor allem jener, \u00fcber die entschieden wird. Es stellt sich hier \nalso die Frage, wie die Delegation von T\u00e4tigkeiten an Technik \ndie Handlungsm\u00f6glichkeit und Autorschaft der Betroffenen \n171\t Das\tWort\t\u201ebesser\u201c\tsuggeriert,\tdass\tes\tVerbesserung\t\u201eals\tsolche\u201c\tgebe,\tund\t\nignoriert,\tdass\t\u201ebesser\u201c\tsemantisch\tgrunds\u00e4tzlich\tnur\tim\tZusammenhang\t\nmit\tnormativen\tKriterien\tdes\t\u201ebesser\u201c\tsinnvoll\tist\t\u2013\tund\tdiese\tKriterien\t\nk\u00f6nnen\tumstritten\tund\tkontrovers\tsein.182beeinflusst. Dies stellt sich in unterschiedlichen Anwendungs-\nfeldern auf je andere Weise dar.\nBereits mehrfach hat sich damit gezeigt, dass mit einer er -\nw\u00fcnschten Erweiterung der M\u00f6glichkeiten menschlicher Au-\ntorschaft oft simultan eine Verminderung verbunden ist, h\u00e4u-\nfig in Bezug auf andere Aspekte und Felder von Autorschaft \nbzw. andere Menschen. Auf jeden Fall verschieben KI-Systeme \ndie M\u00f6glichkeiten der Wahrnehmung menschlicher Autor -\nschaft. Dies betrifft unterschiedliche Bev\u00f6lkerungsgruppen auf \nunterschiedliche Weise und weist daher eine soziale Dimensi-\non mit ethischen Fragen auf. Bei der Betrachtung von Chancen \nund Risiken etwa von Entscheidungsunterst\u00fctzungssystemen \nim Sicherheitsbereich ist zu ber\u00fccksichtigen, f\u00fcr wen es sich \nhier jeweils um Chancen oder Risiken, um Erweiterungen \noder Verminderungen der Autorschaft handelt. Damit sind \nhier Aspekte sozialer Gerechtigkeit und Macht involviert. In \nder Digitalisierung und speziell bei der Entwicklung und Nut-\nzung von KI ist grunds\u00e4tzlich zu fragen, wer die entsprechen-\nden Prozesse bzw. die konkreten Softwareapplikationen und \nKI-Algorithmen jeweils gestaltet und ob \u2013 und wenn ja mit \nwelcher Legitimation \u2013 sie in die Autonomie und Autorschaft \nderjenigen, die diese Produkte nutzen, oder weiterer Betroffe-\nner eingreifen. Auch jenseits der intentionalen Manipulation \ndurch die Gestalter sind Effekte von Beeinflussung, Gew\u00f6h-\nnung und Abh\u00e4ngigkeiten bis hin zu digitalem Mediensucht-\nverhalten zu beobachten, in denen offenkundig menschliche \nAutorschaft eingeengt wird.\nDie sich hier andeutenden ethischen Herausforderungen \nsind mit epistemologischen Herausforderungen verbunden. \nAllm\u00e4hliche Verschiebungen, wie etwa die erw\u00e4hnten Gew\u00f6h-\nnungsprozesse an technisch normierte Handlungsmuster (Au-\ntomation Bias), sind oft nur schwer aufzudecken und empi-\nrisch zu belegen. Es besteht das Risiko versp\u00e4teter Entdeckung, \nzu einem Zeitpunkt, zu dem m\u00f6glicherweise nur noch schwer \nbeeinflussbare Pfadabh\u00e4ngigkeiten bereits eingetreten sind, \nschlimmstenfalls ein Point of no Return \u00fcberschritten wurde. 183Zwischen der hohen Relevanz dieser an die Dialektik von Herr \nund Knecht gemahnenden Situation und der epistemologisch \nschwierigen Nachweislage ist die Bewusstmachung m\u00f6glicher \nethisch bedenklicher Zukunftsentwicklungen dieses Typs eine \nHerausforderung. Denn angesichts starker Gegenwartspr\u00e4fe-\nrenzen vieler Akteure ist sie mit den bekannten Problemen \nvorsorgeorientierter Kommunikation konfrontiert. Von der \neinen Seite droht der Vorwurf der \u00dcbertreibung, Dramati-\nsierung oder gar Technikfeindlichkeit, von der anderen der \nVorwurf der Verharmlosung. Hohe epistemologische Unsi-\ncherheit macht vorsorgeorientierte Kommunikation anf\u00e4llig \nf\u00fcr Ideologie, interessengeleitete Statements und Spekulation.\n4.5\t\t Fazit\nDie ethische Analyse und Beurteilung des Einsatzes von KI-\nSystemen bed\u00fcrfen \u00fcber die begriffliche, anthropologische und \nhandlungstheoretische Vergewisserung (vgl. Kapitel 3) hinaus \neines genaueren Blicks auf die sich mit der Digitalisierung ver -\n\u00e4ndernden Konstellationen zwischen Mensch und Technik. \nIm Rahmen der philosophischen Handlungstheorie k\u00f6nnen \nMaschinen nicht handeln und kommen als genuine Akteure \nmit Verantwortung nicht infrage. Dennoch haben sie Einfluss \nauf menschliches Handeln, das in modernen Gesellschaften \nin zunehmendem Ma\u00dfe soziotechnisch situiert ist. Erfahrung \nund empirische Forschung zeigen, dass Technik einerseits von \nMenschen als Mittel nach Zwecken gestaltet wird, dass aber \nandererseits neue Technik und darauf aufbauende Innovati-\nonen oder Dienstleistungen menschliches Handeln und Ver -\nhalten beeinflussen. Ethisch relevant ist insbesondere, wie sich \ndiese Wechselwirkungen auf die M\u00f6glichkeiten menschlicher \nAutorschaft und Verantwortungs\u00fcbernahme auswirken und \nwie diese sich angesichts der zunehmenden Verbreitung von \nKI-Systemen ver\u00e4ndern.184KI-Systeme k\u00f6nnen in vielen Feldern menschliche Hand-\nlungen und Entscheidungen unterst\u00fctzen, dadurch zu besse-\nren Ergebnissen beitragen und damit menschliche Autorschaft \nerweitern. Vor allem die durch Algorithmen er\u00f6ffnete M\u00f6g-\nlichkeit, in gro\u00dfen Datenmengen (Big Data) Muster zu erken-\nnen, die den Menschen ansonsten verborgen w\u00e4ren, ist die \nBasis f\u00fcr den unterst\u00fctzenden Einsatz der KI zum Beispiel in \nder medizinischen Diagnostik, im Bildungsbereich, aber auch \nim Medienbereich und in der Verwaltung. Gerade im Bereich \nder sozialen Medien zeigt sich hier ein Ph\u00e4nomen, das als Hy-\npernudge172 beschrieben wurde: Datenbasierte algorithmische \nSysteme kuratieren dynamisch hochgradig personalisierte In-\nformationsumgebungen, denen man sich nur schwer entzie-\nhen kann. Menschliche Autorschaft kann also durch KI nicht \nnur erweitert, sondern auch vermindert werden, entweder \ndurch intendierte Delegation von Entscheidungen an auto-\nmatische Systeme oder durch allm\u00e4hliche Effekte der Gew\u00f6h-\nnung und Anpassung an datengenerierte Empfehlungen von \nKI-Systemen.\nKI-Systeme verschieben die M\u00f6glichkeiten der Wahrneh-\nmung menschlicher Autorschaft. Die grunds\u00e4tzlich erw\u00fcnsch-\nte Erweiterung von Autorschaft ist h\u00e4ufig simultan mit einer \nVerminderung in Bezug auf andere Aspekte von Autorschaft \nbzw. andere Akteure verbunden. Insbesondere sind verschie-\ndene Akteursgruppen in unterschiedlicher Weise betroffen. \nDie ethische Analyse von Chancen und Risiken etwa von \nADM-Systemen in der \u00f6ffentlichen Verwaltung (vgl. Kapitel \n8) muss darauf achten, f\u00fcr wen es zu Erweiterungen oder Ver -\nminderungen der Autorschaft kommt, etwa in der Differenz \nvon Entscheidenden und Betroffenen. Es sind also mit dem \nEinsatz von KI-Systemen auch Fragen von Gerechtigkeit und \nAutonomie- bzw. Machtverteilung involviert. Speziell ist zu \nfragen, ob und wie die jeweiligen Gestalter der entsprechen-\nden Prozesse bzw. der konkreten Softwareapplikationen und \n172\t Yeung\t2017.185KI-Algorithmen in die Autonomie und Autorschaft derjeni-\ngen eingreifen, die diese Produkte nutzen oder anderweitig \nvon ihnen betroffen sind.\nWeiterhin sind psychologische Effekte zu beachten, die \nspezifisch f\u00fcr digitale Instrumente und insbesondere f\u00fcr KI-\nSysteme sind. Hier ist vor allem der Automation Bias zu nen-\nnen. Menschen vertrauen, so empirische Untersuchungen, \nalgorithmisch erzeugten Ergebnissen und automatisierten \nEntscheidungsprozeduren h\u00e4ufig mehr als menschlichen Ent-\nscheidungen. Vermutlich spielen dabei verbreitete Objektivi-\nt\u00e4tsunterstellungen gegen\u00fcber Daten und Rechenverfahren \neine Rolle, w\u00e4hrend menschliche Urteile tendenziell als sub-\njektiv wahrgenommen werden. Gerade bei Entscheidungen, \ndie mit einer gro\u00dfen prognostischen Unsicherheit konfron-\ntiert sind und zugleich gravierende Auswirkungen haben, be-\nsteht die latente Tendenz, den datenbasierten algorithmischen \nAuswertungen mehr zu vertrauen. Damit wird Verantwortung \n\u2013 zumindest unbewusst \u2013 auf diese \u201eQuasi-Akteure\u201c delegiert. \nDieser Bias zugunsten der algorithmischen Verfahren kann \nbeispielsweise dazu f\u00fchren, dass auch bei einer handlungs-\ntheoretisch korrekten Organisation von Entscheidungspro-\nzessen, in denen ein KI-System normativ strikt auf die Rolle \nder Entscheidungsunterst\u00fctzung begrenzt und dem Mensch, \nder die Entscheidung trifft, die Verantwortung zugeschrie-\nben wird, das KI-System allm\u00e4hlich in die Rolle des eigentli-\nchen \u201eEntscheiders\u201c ger\u00e4t und menschliche Autorschaft und \nVerantwortung ausgeh\u00f6hlt werden. Bisweilen wird versucht, \ndieser Gefahr vorzubeugen, indem bei Verwendung eines Ent-\nscheidungsunterst\u00fctzungstools ein entsprechender Warnhin-\nweis gegeben wird. Eine weitere denkbare Vorkehrung w\u00e4re \ndie Verpflichtung der entscheidenden Fachkr\u00e4fte, die etwaige \n\u00dcbernahme des algorithmischen Entscheidungsvorschlages \u2013 \netwa mit Verweis auf die eigene erfahrungsbezogen intuitive \noder kollegial er\u00f6rterte Prognose \u2013 ausdr\u00fccklich zu begr\u00fcn-\nden. Auf jeden Fall bedarf dieser \u00dcberlappungsbereich nor -\nmativer Regulierung und empirisch-psychologischer Effekte 186besonderer Aufmerksamkeit in den ethischen Analysen zu den \nAnwendungsfeldern in den folgenden Kapiteln.\nMenschen, die Entscheidungen treffen, haben kaum eine \nM\u00f6glichkeit, die epistemische Evidenz der Korrelationen und \nMuster kritisch zu beurteilen, sondern sind vielfach darauf \nangewiesen, sie so zu nehmen, wie sie von den Systemen be-\nreitgestellt werden. Sie unterliegen damit einem verborgenen \nNudging durch die Art und Weise, wie die KI-Systeme zu ih-\nren Ergebnissen kommen, und werden in bestimmte Richtun-\ngen des Entscheidens gedr\u00e4ngt. M\u00f6gliche Einseitigkeiten, etwa \nauf Basis der Datenlage, sowie daraus m\u00f6glicherweise resultie-\nrende Diskriminierungen geraten aus dem Blick und mensch-\nliche Autorschaft wird entleert.\nIn den Abw\u00e4gungen zwischen Erweiterung und Vermin-\nderung menschlicher Autorschaft in ihrer sozialen Verteilung \nsind bereits auf einer abstrakten ethischen Ebene mehrere Di-\nmensionen zu ber\u00fccksichtigen. Erstens bedarf die \u00dcbertragung \nmenschlicher T\u00e4tigkeiten auf KI-Systeme der Transparenz ge-\ngen\u00fcber den Betroffenen. Sie sollten dar\u00fcber informiert sein, \nauf welche Weise Entscheidungen zustande kommen, von de-\nnen sie dann betroffen sind. Dies hat zweitens mit der Klarstel-\nlung von Verantwortungszuschreibungen zu tun. Um ein Ver -\nantwortungs- und gegebenenfalls auch Haftungsvakuum zu \nverhindern, muss die Verantwortungszuschreibung etwa \u00fcber \ndie Betreiber der Systeme oder die menschlichen Akteure, die \ndie \u00dcbertragung an sie beschlossen haben, geregelt werden. \nDrittens bedarf es der Sicherstellung der Nachvollziehbarkeit \nin Bezug auf das zweckhafte Funktionieren der KI-Systeme. \nViertens m\u00fcssen m\u00f6gliche nicht intendierte Folgen wie bei-\nspielsweise schleichend einkehrende Abh\u00e4ngigkeiten von \nden KI-Systemen oder allm\u00e4hliche Aush\u00f6hlung menschlicher \nAutorschaft sorgf\u00e4ltig beobachtet werden, um gegebenenfalls \nrechtzeitig korrigierend eingreifen zu k\u00f6nnen.TEIL\tII:\t\t\nAUSGEW\u00c4HLTE \t\nANWENDUNGEN \tUND\t\nSEKTORSPEZIFISCHE \t\nEMPFEHLUNGEN188In den folgenden Kapiteln des zweiten Teils dieser Stellung-\nnahme sollen die zuvor angestellten \u00dcberlegungen anhand \nvon Analysen in vier verschiedenen Sektoren vertieft werden: \nder Medizin (Kapitel 5), der (schulischen) Bildung (Kapitel 6), \nder \u00f6ffentlichen Kommunikation und Meinungsbildung (Ka-\npitel 7) sowie der \u00f6ffentlichen Verwaltung (Kapitel 8).\nKI-basierte Softwaresysteme werden in allen vier Sektoren \neingesetzt, wobei sich die Durchdringungsbreite und -tiefe \ndurchaus unterscheiden. So liefern die f\u00fcr den Bereich der \u00f6f-\nfentlichen Kommunikation und Meinungsbildung zentralen \nsozialen Medien ein Paradebeispiel einer sehr umfassenden \nDelegation vormals menschlicher T\u00e4tigkeiten an Algorith-\nmen, beispielsweise zu Zwecken der Kuratierung und Mo-\nderation von Inhalten. Der Bereich der schulischen Bildung \nbildet den anderen Pol, gibt es hier doch eine vergleichsweise \ngeringe Nutzung digitaler Technologien im Allgemeinen und \nvon KI-Systemen im Speziellen, eine vollst\u00e4ndige Ersetzung \nmenschlicher T\u00e4tigkeiten scheint in weiter Ferne. Im Bereich \nder Medizin hingegen werden zunehmend einzelne T\u00e4tigkei-\nten oder gar ganze Funktionen an KI-basierte Softwaresysteme \ndelegiert. Dies reicht vom Einsatz von KI-basierter Musterer -\nkennung zu Zwecken der Krebsdiagnostik bis hin zur Verwen-\ndung von Chatbots in der Therapie, die schon einen m\u00f6gli-\nchen Ersatz menschlichen Fachpersonals suggerieren. Auch in \ndie \u00f6ffentliche Verwaltung haben KI-basierte Softwaresysteme \nEinzug gehalten, insbesondere in Form von datenbasierter \nSoftware, die zur Erstellung von Risikoprofilen und zur Ent-\nscheidungsunterst\u00fctzung herangezogen wird.\nDie folgenden Analysen werden zeigen, dass Fragen des \nrichtigen Ausma\u00dfes der Delegation von T\u00e4tigkeiten und \nFunktionen an Softwaresysteme nur kontext-, anwendungs- \nund personenbezogen spezifiziert werden k\u00f6nnen. Dabei \ngilt als Richtschnur der Bewertung, ob die Delegation zu ei-\nner Erweiterung der Handlungsm\u00f6glichkeiten, insbesondere \nder M\u00f6glichkeiten f\u00fcr verantwortliches Handeln und Autor -\nschaft, der verschiedenen betroffenen Akteure f\u00fchrt oder ob 189es in der Folge m\u00f6glicherweise zu einer Verminderung solcher \nHandlungsm\u00f6glichkeiten sowie zu negativen Auswirkungen \nauf M\u00f6glichkeiten der Autorschaft und Verantwortungs-\n\u00fcbernahme kommt. Die Analyse des Einsatzes von KI-Syste-\nmen in den vier Sektoren endet jeweils in sektorspezifischen \nEmpfehlungen. Unabh\u00e4ngig davon lassen sich aus dem Ver -\ngleich der Sektoren auch \u00fcbergreifende Themen ausmachen, \nAspekte, die sich in den vier Sektoren mal \u00e4hnlich, mal aber \nsehr unterschiedlich darstellen. Diese Themen werden in Teil \nIII \u201eQuerschnittsthemen und \u00fcbergreifende Empfehlungen\u201c \naufgegriffen.1905\t \t MEDIZIN\n5.1\t\t Einleitung\nDie zunehmende Durchdringung unserer Lebenswelt mit digi-\ntalen Produkten, die \u00fcber KI-Komponenten verf\u00fcgen, breitet \nsich auch im Gesundheitssystem immer weiter aus. Angesichts \nder Dynamik der technischen Entwicklung und der \u00f6konomi-\nschen Triebkr\u00e4fte dieses Transformationsprozesses ist es aus \nethischer Perspektive erforderlich, die damit verbundenen He-\nrausforderungen m\u00f6glichst pr\u00e4zise wahrzunehmen, die jewei-\nligen Vor- und Nachteile des Einsatzes von KI-Instrumenten \ndifferenziert abzuw\u00e4gen und einer problematischen Verselbst-\nst\u00e4ndigungstendenz des Technikeinsatzes fr\u00fchzeitig entge-\ngenzuwirken. Zwar gibt es bereits eine Vielzahl wertvoller \nethischer Empfehlungen und Richtlinien, die sich auf unter -\nschiedlichen Ebenen mit den Bedingungen eines verantwort-\nbaren KI-Einsatzes besch\u00e4ftigen173, doch wird dabei entweder \nein sehr genereller \u00dcberblick \u00fcber mehrere Handlungsfelder \ngegeben, um die Chancen und Risiken der Schaffung und Be-\nwirtschaftung integrierter Datenr\u00e4ume mit neuen KI-Techno-\nlogien auszuloten, oder es werden die einschl\u00e4gigen Heraus-\nforderungen im Gesundheitsbereich nur aus einer begrenzten \n\u2013 etwa \u00e4rztlichen \u2013 Perspektive reflektiert, um die Handlungs-\nsicherheit einer bestimmten Personengruppe im Umgang mit \nden neuen Instrumenten zu verbessern.174\nDie vorliegende Stellungnahme kn\u00fcpft an diese Vorarbei-\nten an, indem sie nicht nur die vielfach erhobene Forderung \nnach einem \u201eVorrang menschlichen Handelns\u201c mit Blick auf \ndie verschiedenen Formen der Mensch-Maschine-Relation auf \ndiesem besonders sensiblen Handlungsfeld n\u00e4her spezifiziert \n173\t Europ\u00e4ische\tKommission\t2020;\tHochrangige\tExpertengruppe\tf\u00fcr\tk\u00fcnstli-\nche\tIntelligenz\t2019.\n174\t Zentrale\tEthikkommission\tbei\tder\tBundes\u00e4rztekammer\t2021.191und in Bezug setzt zu den bekannten sektor\u00fcbergreifenden \nHerausforderungen (z. B. des Datenschutzes, der Qualit\u00e4t, \nRobustheit und Sicherheit der eingesetzten Instrumente an-\ngesichts verschiedener Manipulationsm\u00f6glichkeiten, der Bias- \nbzw. Diskriminierungsgefahren infolge einseitiger Trainings-\ndaten, der Nachvollziehbarkeits- bzw. Opazit\u00e4tsprobleme \nbesonders komplexer Algorithmen \u2013 siehe Kapitel 2).\nAufgrund der Komplexit\u00e4t des medizinischen Versor -\ngungssystems bedarf es auch mit Blick auf die folgende genau-\nere Betrachtung von KI-Anwendungen im Gesundheitswesen \neiner wenigstens dreifachen Differenzierung:\nErstens sind mehrere Akteursgruppen zu unterscheiden, \ndie bez\u00fcglich eines KI-Einsatzes unterschiedliche Funktionen \nund Verantwortlichkeiten besitzen, wie zum Beispiel Perso-\nnen in der Softwareentwicklung, Kontroll- und Zertifizie-\nrungsinstanzen, medizinische Forschungsgruppen, klinisch \nt\u00e4tige Personen, die von ihnen versorgten Menschen, medi-\nzinische Fachgesellschaften sowie Tr\u00e4ger von medizinischen \nVersorgungseinrichtungen.\nZweitens umfasst das Gesundheitswesen mit der Grund-\nlagen- und (pr\u00e4-)klinischen Forschung sowie der konkreten \nmedizinischen Versorgung durch Pr\u00e4vention, Kuration und \nPalliation, denen wiederum verschiedene diagnostische, thera-\npeutische und prognostische Einzelma\u00dfnahmen zuzuordnen \nsind, ganz unterschiedliche Anwendungsbereiche f\u00fcr KI-Pro-\ndukte, deren jeweilige Chancen und Risiken kontextsensitiv zu \nbeurteilen sind.175\nDrittens sind hinsichtlich der derzeit verf\u00fcgbaren KI-\nbasierten Instrumente unterschiedliche Grade der Ersetzung \nmenschlicher Handlungssegmente zu beobachten, die im Kern-\nbereich medizinischer Behandlungen ganz verschiedene Aus-\nwirkungen auf die Arzt-Patienten-Beziehung haben k\u00f6nnen \nund dadurch die Handlungsm\u00f6glichkeiten der verschiedenen \n175\t Der\tBereich\tder\tprivaten\tNutzung\tentsprechender\tProdukte\tim\tRahmen\t\neiner\tdigital self-care\tbleibt\thier\tausgeklammert.192Akteure sowohl erweitern als auch vermindern k\u00f6nnen.176 Das \nSpektrum der Einsatzm\u00f6glichkeiten dieser Instrumente reicht \ndabei von einer engen Nutzung, bei der lediglich ein einzel-\nnes Segment \u00e4rztlichen Handelns technisch substituiert wird, \n\u00fcber komplexere KI-Anwendungen, die mehrere \u00e4rztliche \nHandlungsschritte begleiten und unterst\u00fctzen, bis hin zu einer \nvollst\u00e4ndigen Ersetzung des Behandlers durch ein KI-System. \nLetztere tr\u00e4gt zwar gegenw\u00e4rtig noch weithin fiktionale Z\u00fcge, \nist aber in einzelnen Sektoren der medizinischen Versorgung \nbereits Realit\u00e4t geworden.\nNachfolgend werden anhand exemplarischer Beispiele die \njeweiligen Chancen und Risiken eines KI-Einsatzes in unter -\nschiedlichen Bereichen des medizinischen Systems analysiert.\n5.2\t\t Einsatz\tvon\tKI-Systemen\tin\tder\t\nMedizin\nEine verantwortliche Verwendung von KI-Systemen im Be-\nreich der Medizin setzt voraus, dass die gesamte Handlungs-\nkette \u2013 von der Entwicklung entsprechender Produkte \u00fcber ih-\nren Einsatz in der Forschung bis hin zu ihrer Implementierung \nin den verschiedenen Sektoren der medizinischen Versorgung \n\u2013 ethischen Standards gen\u00fcgt, kontinuierlich \u00fcberwacht und \ngezielt so weiterentwickelt wird, dass Vorteile sukzessive im-\nmer besser genutzt und Gefahren vermieden werden.\n5.2.1 Entwicklung von KI-Systemen\nBereits die Entwicklung geeigneter KI-Komponenten f\u00fcr die \nmedizinische Praxis, die hier als erster, dem klinischen Einsatz \nsolcher Systeme notwendig vorausgehender, ethisch relevanter \n176\t Zum\tEinsatz\tKI-gest\u00fctzter\trobotischer\tSysteme\tim\tRahmen\tder\tPflege\tvgl.\t\nDeutscher\tEthikrat\t2020a.193Teilbereich erw\u00e4hnt werden soll, stellt eine anspruchsvolle \nAufgabe dar. Sie erfordert nicht nur eine enge interdiszipli-\nn\u00e4re Zusammenarbeit verschiedener Sachverst\u00e4ndiger aus \nunterschiedlichen Fachgebieten (z. B. Informatik, Ingenieur -\nwissenschaft, Medizin, Recht), um geeignete Algorithmen f\u00fcr \ndie zuverl\u00e4ssige Bew\u00e4ltigung bestimmter Aufgaben definieren \nzu k\u00f6nnen, sondern stellt auch hohe Anforderungen an die \nQualit\u00e4t der verwendeten Trainingsdaten, um vermeidbare \nVerzerrungen der Ergebnisse von vornherein auszuschlie\u00dfen \noder zumindest zu minimieren.\nEine Besonderheit von KI-Systemen, die auf mit maschinel-\nlem Lernen aus Daten gewonnenen Modellen basieren, besteht \ndarin, dass bei manchen Systemen selbst diejenigen, die diese \nInstrumente entwickeln, aufgrund der enormen Komplexit\u00e4t \nder Datenverarbeitungsprozesse nicht mehr rekonstruieren \nk\u00f6nnen, wie bestimmte Resultate zustande gekommen sind, \nda die Eingaben mit hochgradig nichtlinearen und verteilten \nProzessen verarbeitet werden. Der Prozess wird zur Blackbox. \nZwar kann eine solche Opazit\u00e4t auch darin ihren Ursprung \nhaben, dass bestimmte Algorithmen urheberrechtlich ge-\nsch\u00fctzt sind, doch gibt es neben dieser von \u00e4u\u00dferen Faktoren \nbedingten und insofern kontingenten Unzug\u00e4nglichkeit auch \neine rein technisch bedingte Opazit\u00e4t, die sich je nach Kontext \nunterschiedlich auswirken kann. W\u00e4hrend es in manchen Be-\nreichen sinnvoll oder sogar notwendig sein kann, ein H\u00f6chst-\nma\u00df an Erkl\u00e4rbarkeit der jeweiligen Resultate anzustreben \n(Explainable AI), wof\u00fcr gegebenenfalls ein hoher technischer \nund finanzieller Aufwand erforderlich ist, d\u00fcrfte es in anderen \nBereichen ausreichen sicherzustellen, dass die Personen, die \ndiese Systeme anwenden, deren Resultate stets einer eigenen \nPlausibilit\u00e4tspr\u00fcfung unterziehen, um den Gefahren eines un-\ngerechtfertigten blinden Vertrauens in die Technik (Automa-\ntion Bias) zu entgehen.\nDie Forderung nach Transparenz l\u00e4sst verschiedene Gra-\nde zu, sodass je nach Anwendungsbereich zu pr\u00fcfen ist, was \naus welchen Gr\u00fcnden f\u00fcr wen in welchem Umfang und zu 194welchem Zweck erkl\u00e4rbar sein muss. Tats\u00e4chlich gibt es in der \nMedizin viele Beispiele nicht nur f\u00fcr den Einsatz technischer \nGer\u00e4te, deren genaue Wirkmechanismen denjenigen, die sie in \nihrer Berufspraxis anwenden, allenfalls ansatzweise durchsich-\ntig sind, sondern auch daf\u00fcr, dass bestimmte Interventionen \nauch dann sinnvoll geplant und durchgef\u00fchrt werden k\u00f6nnen, \nwenn das kausale Wissen um konkrete Wirkmechanismen be-\ngrenzt ist. Angesichts des Technisierungsgrades der modernen \nMedizin ist es weder m\u00f6glich noch erforderlich, dass die be-\nhandelnden Personen die internen Prozesse der von ihnen ge-\nnutzten technischen Hilfsmittel stets im Detail durchschauen, \nsolange diese Prozesse in ausreichendem Umfang zumindest \ndurch geeignete Stellen nachvollzogen und damit \u00fcberpr\u00fcft \nwerden k\u00f6nnen.\nIn derart gelagerten F\u00e4llen ist es umso wichtiger, \u201emittels \ngeeigneter Pr\u00fcf-, Zertifizier- und Auditierungsma\u00dfnahmen \nsicherzustellen\u201c177, dass die jeweiligen Systeme technisch ein-\nwandfrei funktionieren und verantwortungsvoll eingesetzt \nwerden. Die Zertifizierung vertrauensw\u00fcrdiger KI-Systeme er -\nstreckt sich insbesondere auf die Wahrung von Mindest- und \nanwendungsbezogenen Spezialanforderungen bez\u00fcglich der \nAutonomie und Kontrolle, der Fairness, der Transparenz, der \nVerl\u00e4sslichkeit, der Sicherheit und des Datenschutzes.178\nSowohl die medizinischen Fachleute, die solche \u201eintelli-\ngenten\u201c Medizinprodukte verwenden, als auch die von ih-\nnen behandelten Personen m\u00fcssen darauf vertrauen k\u00f6nnen, \ndass nur hinreichend gepr\u00fcfte und nach m\u00f6glichst internati-\nonal konsentierten Ma\u00dfst\u00e4ben zertifizierte KI-Produkte zum \nEinsatz kommen und von der jeweiligen Gesundheitsein-\nrichtung vorschriftm\u00e4\u00dfig gewartet und gegen Manipulation \ngesch\u00fctzt werden. Dies gilt umso mehr, als die Lebensdauer \nvon Softwareprodukten oft relativ kurz ist und die Systeme \n177\t Zentrale\tEthikkommission\tbei\tder\tBundes\u00e4rztekammer\t2021,\tA5.\n178\t Vgl.\tbeispielsweise\tdas\tWhitepaper\tdes\tProjekts\t\u201eZertifizierte\tKI\u201c\tder\tKom-\npetenzplattform\tKI.NRW\t(Cremers\tet\tal.\t2019).195durch h\u00e4ufige Updates einen insgesamt flie\u00dfenden Charakter \naufweisen.\nAngesichts der Dynamik der technischen Entwicklung und \nder wirtschaftlichen Interessen derjenigen \u2013 nicht selten als \nStart-up aus universit\u00e4ren Forschungseinrichtungen heraus \ngegr\u00fcndeten \u2013 Unternehmen, die solche Produkte entwickeln \nund vertreiben, bedarf es eines geordneten Zusammenwir -\nkens von staatlichen Aufsichts- und Kontrollbeh\u00f6rden, der \nEntwicklung neuer bzw. erg\u00e4nzter Leitlinien f\u00fcr deren Einsatz \ndurch die jeweils zust\u00e4ndigen medizinischen Fachgesellschaf-\nten sowie kontinuierlicher Anstrengungen zur weiteren Aus-, \nFort- und Weiterbildung des medizinischen Personals, um ei-\nnen verantwortlichen Umgang mit den neuen Techniken zu \ngew\u00e4hrleisten.\nVon besonderer ethischer Brisanz sind jene KI-Systeme, \nbei denen selbst von den Personen, die das System entwickeln \nund programmieren, nicht mehr vollst\u00e4ndig nachvollzogen \nwerden kann, wie ein bestimmtes Ergebnis zustande kommt. \nZumindest insofern KI-Systeme medizinische Entscheidungs-\nvorschl\u00e4ge mit schwerwiegenden Konsequenzen f\u00fcr das \u00dcber -\nleben und grundlegende Aspekte der Lebensqualit\u00e4t unter -\nbreiten, m\u00fcssen deren grundlegende Funktionsweisen und \nArbeitsprozesse erkl\u00e4r- sowie interpretierbar sein, um einen \nselbstbestimmten Einsatz zu gew\u00e4hrleisten. Lassen sich die an-\nwendungsbezogenen Transparenzanforderungen \u2013 selbst un-\nter R\u00fcckgriff auf Erkenntnisse der Explainable-AI-Forschung \n\u2013 nicht erf\u00fcllen, verbietet sich jedenfalls ein Einsatz in diesem \nBereich der medizinischen Versorgung. Die Festlegung derar -\ntiger Bereiche erfordert einen breiten gesellschaftlichen Dis-\nkurs, in den insbesondere die sektorbezogenen Chancen und \nRisiken des Einsatzes intransparenter KI-Systeme einzubezie-\nhen sind.1965.2.2 KI in der medizinischen Forschung\nDa die Planung und Durchf\u00fchrung medizinischer Forschung \nbesonders hohe Anforderungen an den reflektierten Umgang \nmit unterschiedlichen Wissensformen und die methodischen \nFertigkeiten derer stellt, die konkrete Forschungsfragen ent-\nwickeln und sie durch geeignete Experimente auf empirisch \n\u00fcberpr\u00fcfbare Weise zu beantworten suchen, sind die in dieser \nWeise am Forschungsprozess beteiligten Personen grunds\u00e4tz-\nlich nicht durch KI-Systeme ersetzbar. Trotz dieser prinzi-\npiellen Grenzen kann die gezielte Implementierung von KI-\nElementen auch im Kontext der medizinischen Forschung in \nmehrfacher Hinsicht vorteilhaft sein, sofern der Schutz derje-\nnigen, die an den Studien teilnehmen, und ihrer personenbe-\nzogenen (Gesundheits-)Daten gew\u00e4hrleistet ist. Dazu bedarf es \ngerade in kollaborativen Forschungsprojekten nicht nur pr\u00e4zi-\nser Bestimmungen, \u201ewer unter welchen Bedingungen Zugang \nzu den Daten erh\u00e4lt, um einen transparenten Austausch bei \ngleichzeitiger Gew\u00e4hrleistung hoher Datenschutzstandards zu \nerm\u00f6glichen\u201c, sondern auch \u201eklarer Vorgaben, unter welchen \nUmst\u00e4nden Probanden und Patienten Zugang zu ihren Daten \nhaben k\u00f6nnen, wie sie modular und dynamisch in ihre Nut-\nzung einwilligen k\u00f6nnen [\u2026] und wie die Daten langfristig \nerhalten bleiben\u201c.179\nDas Spektrum eines sinnvollen KI-Einsatzes in der medi-\nzinischen Forschung ist weit: Neben hilfreichen Vor- und Zu-\narbeiten etwa bei Literaturrecherchen oder der Durchsuchung \ngro\u00dfer Datenbanken k\u00f6nnen KI-Instrumente einen Beitrag \ndazu leisten, neue Korrelationen zwischen bestimmten Ph\u00e4-\nnomenen zu entdecken, deren Bedeutung f\u00fcr die medizinische \nPraxis jedoch durch gezielte Analysen \u00fcberpr\u00fcft werden muss. \nDrei Beispiele m\u00f6gen dies verdeutlichen:\nDas erste Beispiel betrifft den Einsatz von KI bei der Vor -\nhersage raum- und zeitabh\u00e4ngiger medizinrelevanter Prozesse, \n179\t Deutscher\tEthikrat\t2017,\t97.197wie etwa der Ausbreitung eines Virus, in der Epidemiologie. \nIn diesen F\u00e4llen ist die Anwendung mathematischer Algorith-\nmen180 h\u00e4ufig die einzig effiziente Methode, um prospektiv zu \nrelevanten Erkenntnissen zu gelangen. Da man meist nicht alle \nrelevanten Parameter kennt, sind die Vorhersagen mit einem \nUnsicherheitsfaktor verbunden, der \u2013 \u00e4hnlich einer Wetter -\nvorhersage \u2013 umso gr\u00f6\u00dfer wird, je weiter die Vorhersage in der \nZukunft liegt und je feiner die zeitliche und r\u00e4umliche Auf-\nl\u00f6sung ist. Es k\u00f6nnen jedoch Szenarien unter verschiedenen \nAnnahmen berechnet werden, sodass ein Bereich wahrschein-\nlicher Entwicklungen sinnvoll eingegrenzt werden kann.\nAls zweites Beispiel sei der KI-Einsatz in der Vorhersage \nkomplexer Molek\u00fclstrukturen genannt, der bei der Erfor -\nschung von Krankheitsmechanismen und der Entwicklung \nvieler Therapeutika eine gro\u00dfe Rolle spielt. Hier werden Algo-\nrithmen genutzt, die vor allem auf der von DeepMind (einer \nTochter des Google-Mutterkonzerns Alphabet) entwickel-\nten Software AlphaFold basieren, um beispielsweise effizient \nKandidaten f\u00fcr Impfstoffe gegen Infektionskrankheiten (wie \nCOVID-19, aber auch dar\u00fcber hinaus181) zu identifizieren. Die \nAlgorithmen sagen die Struktur von Proteinen vorher und \nerm\u00f6glichen so einen deutlich schnelleren Fortschritt in der \nEntwicklung bestimmter Substanzen, als dies \u00fcber traditionel-\nle labortechnische Verfahren m\u00f6glich ist. Selbstverst\u00e4ndlich \nm\u00fcssen die identifizierten Therapeutika-Kandidaten weiter -\nhin im Labor und in der Klinik getestet werden. Damit ist trotz \ndes zeitlichen Gewinns die Sicherheit im Vergleich zu traditio-\nnellen Methoden nicht eingeschr\u00e4nkt.\nDas dritte Beispiel stammt aus der Krebsforschung, in der \ndie Verarbeitung gro\u00dfer Datenmengen etwa aus der Ana-\nlyse des Genoms, des Transkriptoms und des Epigenoms \nvon immer gr\u00f6\u00dferer Bedeutung wird. Einerseits bietet die \n180\tDies\tbezieht\tdie\tModellierung\t\u00fcber\tDifferentialgleichungen\tmit\tein,\twelche\t\nnicht\tin\tklassischem\tSinne\tals\tK\u00fcnstliche\tIntelligenz\tbezeichnet\twird.\n181\t Higgins\t2021.198systematische Verkn\u00fcpfung und Integration unterschiedlicher \nDaten die Chance, Zusammenh\u00e4nge zwischen einer Vielzahl \nvon Variablen zu erfassen und im Blick auf m\u00f6gliche kausale \nEinflussfaktoren zu analysieren, um zum Beispiel eine bessere \nAufteilung gro\u00dfer Personenkollektive in relevante Subgrup-\npen (Stratifizierung) zu erm\u00f6glichen \u2013 und damit letztlich \ngegebenenfalls eine besser auf diese Gruppen zugeschnittene \nBehandlung. Andererseits stellen die gesteigerte Komplexit\u00e4t \nund Heterogenit\u00e4t der Datenbasis neue Anforderungen an die \nmethodische Kompetenz der Forschenden. Auch in der pr\u00e4-\nklinischen und klinischen Forschung steht und f\u00e4llt der m\u00f6g-\nliche Nutzen von KI-Anwendungen daher \u201emit der Expertise \nund Integrit\u00e4t der Personen oder Institutionen, die Daten ge-\nnerieren, ausw\u00e4hlen, verkn\u00fcpfen und interpretieren\u201c.182\nZwar hat die automatisierte Bearbeitung gro\u00dfer Daten-\nmengen durch KI-Komponenten aufgrund ihrer gesteiger -\nten Rechenleistung das Potenzial, \u201eKorrelationen zwischen \nwesentlich mehr Faktoren schneller und besser zu entdecken \nund dabei auch neue Hypothesen \u00fcber Wirkzusammenh\u00e4nge \nzu entwickeln\u201c183, doch w\u00e4re es \u201eein Missverst\u00e4ndnis zu glau-\nben, dass mehr Daten auch automatisch zu mehr Wissen \u00fcber \nkausale Effekte f\u00fchren\u201c184. Aufgrund der Differenz zwischen \nKorrelation und Kausalit\u00e4t bed\u00fcrfen Ergebnisse maschinel-\nler Datenanalyse daher stets der unabh\u00e4ngigen \u00dcberpr\u00fcfung \nund Validierung, um in der F\u00fclle der gefundenen Korrelatio-\nnen die jeweils relevanten Kausaleffekte zu identifizieren und \ndamit den Umfang des therapierelevanten Kausalwissens zu \nerweitern.\nTrotz aller gebotenen Vorsicht gegen\u00fcber manchen allzu \neuphorischen Heilsversprechen einer KI-gest\u00fctzten Forschung \nbietet gerade der Bereich der Onkologie inzwischen reich-\nhaltiges Anschauungsmaterial daf\u00fcr, wie in der Forschung \n182\t Deutscher\tEthikrat\t2017,\t67.\n183\t Ebd.,\t71.\n184\tEbd.,\t70.199entwickelte KI-Instrumente sukzessive auch in der medizini-\nschen Versorgung von Patientinnen und Patienten zur Dia-\ngnostik und Therapie eingesetzt werden k\u00f6nnen; dies zeigen \nauch einige der nachfolgend vorgestellten Beispiele.\n5.2.3 KI in der medizinischen Versorgung\nObwohl sich viele der KI-basierten Systeme momentan noch \nin der Entwicklungs- und Erprobungsphase befinden, gibt es \nin den verschiedenen Bereichen der medizinischen Versor -\ngung bereits erste Erfahrungen mit dem Einsatz dieser neu-\nen Instrumente, die sich unter anderem durch den Grad der \ntechnischen Ersetzung einzelner oder mehrerer Handlungsse-\nquenzen voneinander unterscheiden lassen.\nEnge Ersetzung\nGrunds\u00e4tzlich k\u00f6nnen KI-Systeme in allen Segmenten me-\ndizinischer Versorgung eingesetzt werden. Die gr\u00f6\u00dfte prak-\ntische Verbreitung d\u00fcrften derzeit Entscheidungsunterst\u00fct-\nzungssysteme in der Diagnostik haben, die versuchen, mittels \ncomputergest\u00fctzter Analyse verschiedener Parameter der \nLabordiagnostik, der Bildbearbeitung sowie der automatisier -\nten Durchsicht von Patientenakten und wissenschaftlichen \nDatenbanken Entscheidungsprozesse zu modellieren und zu \nautomatisieren. Da die Entwicklung und Nutzung von Ent-\nscheidungsb\u00e4umen dem medizinischen Personal schon seit \nLangem dabei hilft, \u201ediagnostische Informationen vollst\u00e4n-\ndig zu erheben, Therapieentscheidungen pr\u00e4zise zu treffen \nund damit insgesamt die bestm\u00f6gliche Behandlung sicher -\nzustellen\u201c, scheint dieses algorithmische Vorgehen geradezu \n\u201epr\u00e4destiniert f\u00fcr KI-Anwendungen\u201c185 zu sein. Ihr Einsatz \nsteht daher in struktureller Kontinuit\u00e4t zur Nutzung fr\u00fcherer \n185\t Schlemmer/Hohenfellner\t2021,\t318.200technischer Hilfsmittel der Entscheidungsfindung (z. B. be-\nstimmter Expertensysteme).\nNeu ist der Umstand, dass die KI-basierten Systeme auf-\ngrund der gesteigerten Rechenkapazit\u00e4ten sehr gro\u00dfe Da-\ntenmengen und eine Vielzahl relevanter Parameter ber\u00fcck-\nsichtigen k\u00f6nnen und die einzelnen Rechenoperationen den \nAnwenderinnen und Anwendern nur begrenzt zug\u00e4nglich \nsind. So bieten vor allem Fortschritte in der Bilderkennung \ngro\u00dfe diagnostische Potenziale, da durch sie zum Beispiel neue \nM\u00f6glichkeiten einer fr\u00fchzeitigen Detektion, Lokalisation und \nCharakterisierung verschiedener pathologischer Ver\u00e4nderun-\ngen in der Gewebestruktur er\u00f6ffnet werden. Das Spektrum der \nderzeitigen Nutzung reicht von der Untersuchung des Augen-\nhintergrundes \u00fcber die Analyse von Hautl\u00e4sionen in der Der -\nmatologie bis hin zu verschiedenen Bereichen der Onkologie, \ndie insofern von besonderer medizinischer Bedeutung sind, als \ndie Fr\u00fcherkennung maligner Tumoren essenziell f\u00fcr eine er -\nfolgreiche Therapie ist. Ein Beispiel bildet hier der KI-Einsatz \nin der Brustkrebsdiagnostik (Infokasten 2).\nInfokasten\t2:\tEnge\tErsetzung\tam\tBeispiel\tBrustkrebsdiagnostik\nBrustkrebs\t (Mammakarzinom)\t ist\tmit\tj\u00e4hrlich\trund\t71\t400\tNeuerkrankun-\ngen\tdie\th\u00e4ufigste\t Krebserkrankung\t der\tFrau;\tnur\trund\tein\tProzent\tder\tBrust-\nkrebserkrankungen\t treten\tbeim\tMann\tauf.186\tNeben\tden\tvielen\tEinzelschick -\nsalen,\tdie\thinter\tdiesen\tZahlen\tstehen,\tist\tdie\tkollektive\t Betrachtung\t des\t\nBrustkrebses\t wegen\tseiner\tH\u00e4ufigkeit\t sowie\tder\thohen\tTherapiekosten,\t der\t\nresultierenden\t Arbeitsausf\u00e4lle\t sowie\tschlechter\t Heilungschancen\t bei\tder\t\nErkennung\t des\tTumors\tin\teinem\tsp\u00e4ten\tStadium\t von\tallgemeiner\t gesell-\nschaftlicher\t Relevanz\t und\tsozio\u00f6konomischer\t Bedeutung.\t Eine\tfr\u00fchzeitige\t\nErkennung\t und\tdie\trichtige\tDiagnose\t sind\tentscheidende\t Faktoren,\t um\tdie\t\n\u00dcberlebenschancen\tzu\terh\u00f6hen.\nUm\tdie\tFr\u00fcherkennung\t zu\tunterst\u00fctzen,\t wurden\tin\tvielen\tL\u00e4ndern,\t so\tauch\t\nin\tDeutschland,\t Mammografie-Screening-Programme\t implementiert.\t F\u00fcr\t\ndie\tMammografie\t werden\tR\u00f6ntgenstrahlen\t eingesetzt,\t die\tmittels\tdigitaler\t\nDetektoren\t nachgewiesen\t werden.\t Diese\tInformation\t wird\tzur\tRekonstruk -\ntion\tzweidimensionaler\t Bilder\tgenutzt,\t die\tdirekt\tf\u00fcr\tdie\tAuswertung\t zur\t\n186\thttps://www.krebsdaten.de/Krebs/DE/Content/Krebsarten/Brustkrebs/\nbrustkrebs_node.html\t[03.03.2023].201Verf\u00fcgung\t stehen.\t\u00dcblicherweise\t \u00fcbernimmt\t dies\terfahrenes,\t radiologisch\t\nqualifiziertes\t Personal,\t aber\tschon\t seit\tL\u00e4ngerem\twird\t daran\tgearbeitet,\tdie\t\nfach\u00e4rztliche\t radiologische\t Beurteilung\t mittels\tcomputergest\u00fctzter\t Verfah-\nren\tzu\tunterst\u00fctzen.\t Die\tersten\tsogenannten\t CADe-\tund\tCADx-Algorithmen\t\n(computer-aided detection\t \u2013\tCADe,\t computer-aided diagnosis\t \u2013\tCADx)\tkonn-\nten\tsich\tzwar\tnicht\tdurchsetzen,\t da\tdie\tAnzahl\tan\tfalsch-positiven\t Ergeb-\nnissen\tzu\thoch\twar.187\tDurch\tden\tEinsatz\tvon\tKI\tin\tForm\tvon\tmaschinellem\t\nLernen,\tinsbesondere\t von\tDeep\tConvolutional\t Neural\tNetworks\t zur\tErken-\nnung\tvon\tL\u00e4sionen,\t konnten\t die\tErgebnisse\t allerdings\t deutlich\t verbessert\t\nwerden.\t Besondere\t Herausforderungen\t sind\thierbei,\tdass\tsehr\tgro\u00dfe\tDaten-\ns\u00e4tze\tf\u00fcr\tdas\tTrainieren\t der\tNetzwerkmodelle\t ben\u00f6tigt\t werden\tund\toft\teine\t\nAnpassung\t an\tlokale\tGegebenheiten\t notwendig\t ist.\tInternationale\t Studien\t\nzeigen,\tdass\tdurch\tden\tEinsatz\tvon\tKI\tdie\tAnzahl\tfalsch-positiver\t Ergebnisse\t\num\t5,7\tProzent\t (USA)\tbzw.\tum\t1,2\tProzent\t (Gro\u00dfbritannien)\t gesenkt\t wer-\nden\tkonnte\tund\tbessere\tErgebnisse\terzielt\twurden\tals\tbei\teiner\tBeurteilung\t\ndurch\tmedizinisches\tFachpersonal\tallein.188\nEinige\tkommerzielle\t Anbieter\t haben\tbereits\tProgramme\t auf\tden\tMarkt\t\ngebracht,\t wie\tbeispielsweise\t Siemens\t Healthineers\t mit\tder\tinteraktiven\t\nEntscheidungsunterst\u00fctzung\t syngo.Breast\t Care\tbei\tder\tMammografie.\t Die\t\nkommerziell\t angebotenen\t Programme,\t wie\tzum\tBeispiel\tdie\tSoftware\t Trans-\npara,\tbieten\tinsbesondere\t eine\tScoringfunktion,\t welche\tdie\tMammografie-\nbilder\tin\tBezug\tauf\tdas\tVorliegen\t verd\u00e4chtiger\t L\u00e4sionen\t stratifiziert.\t Dies\t\nerm\u00f6glicht\t es\tdem\tradiologischen\t Fachpersonal,\t in\tk\u00fcrzerer\t Zeit\tkomplexe\t\nDatens\u00e4tze\t zu\tanalysieren,\t und\tunterst\u00fctzt\t die\tEntscheidungsfindung\t mit\t\nBlick\tauf\tweitere\tBehandlungsschritte.\t Insbesondere\t bei\tunklaren\t Befunden\t\nbleibt\tdas\tEinholen\t einer\tZweitmeinung\t einer\tweiteren\t Expertin\u00a0/\t eines\twei-\nteren\tExperten\t allerdings\t unerl\u00e4sslich.\t Insgesamt\t befinden\t sich\tKI-gest\u00fctzte\t\nSysteme\tauch\tf\u00fcr\tdie\tDiagnostik\tvon\tBrustkrebs\tnoch\tin\tder\tEntwicklung.\nEin verantwortlicher Umgang mit solchen Diagnosetools er -\nfordert eine sorgf\u00e4ltige Abw\u00e4gung der verschiedenen Chancen \nund Risiken, die mit ihrem Einsatz sowohl f\u00fcr die behandeln-\nden \u00c4rztinnen und \u00c4rzte selbst als auch f\u00fcr die Betroffenen \nverbunden sind.\nAus \u00e4rztlicher Sicht wie auch aus Betroffenenperspektive \nd\u00fcrfte der gr\u00f6\u00dfte Vorteil einer Nutzung dieser Instrumente \ndarin bestehen, pathologische Ver\u00e4nderungen der Zell- und \nGewebestrukturen fr\u00fcher als bisher erkennen zu k\u00f6nnen und \ndamit die M\u00f6glichkeiten einer erfolgreichen, an die individu-\nellen Gegebenheiten der jeweiligen Betroffenen angepassten \nTherapie zu verbessern. Der aus der fr\u00fcheren Detektion des \n187\t Sechopoulos/Teuwen/Mann\t2021.\n188\tMcKinney\tet\tal.\t2020.202Tumors resultierende Zeitgewinn steigert nicht nur generell \ndie Erfolgsaussichten der Behandlung, sie erweitert auch inso-\nfern die Therapieoptionen, als bestimmte Behandlungsmetho-\nden (z. B. die operative Entfernung des Tumors) nur so lange \nm\u00f6glich sind, wie eine Metastasierung noch nicht stattgefun-\nden hat.\nEin weiterer Vorteil besteht darin, dass KI-gest\u00fctzte Sys-\nteme die Auswertung digitaler Bilder beschleunigen und das \n\u00e4rztliche Personal von monotonen Routinearbeiten entlasten \nk\u00f6nnen, sodass diesem idealtypischerweise mehr Zeit f\u00fcr die \nVermittlung der Befunde im pers\u00f6nlichen Gespr\u00e4ch zur Ver -\nf\u00fcgung steht.189\nDiesen Chancen stehen aber auch Risiken gegen\u00fcber. So \nk\u00f6nnen \u00c4rztinnen und \u00c4rzte infolge der fortschreitenden \nDelegation bestimmter Aufgaben an technische Systeme zum \neinen eigene Kompetenzen schleichend verlieren, da sie die-\nse immer seltener selbst anwenden. Zum anderen k\u00f6nnten sie \ngerade aufgrund des verlorengegangenen eigenen Erfahrungs-\nwissens dazu neigen, ihre Sorgfaltspflichten im Umgang mit \nderartigen Instrumenten dadurch zu verletzen, dass sie deren \nEmpfehlungen blind folgen (Automation Bias). Da auch KI-\nbasierte Instrumente nicht fehlerfrei arbeiten, sondern mit-\nunter nur andere Fehler als Menschen begehen und die Nich-\ntentdeckung dieser Fehler fatale Konsequenzen haben kann, \nsollten KI-gest\u00fctzte Entscheidungssysteme immer so gestaltet \nwerden, dass die konkrete Art der \u00dcbermittlung ihrer Analy-\nseergebnisse (etwa in Gestalt einer Wahrscheinlichkeitsangabe \nf\u00fcr das Vorliegen einer pathologischen Ver\u00e4nderung190) deut-\nlich macht, dass hier noch eine \u00e4rztliche Plausibilit\u00e4tspr\u00fcfung \nerforderlich ist. Da die Behandelnden moralisch und rechtlich \n189\tBaltzer\t2021.\n190\tEin\tBespiel\tf\u00fcr\tdieses\tProblem\tist\tein\tAlgorithmus,\tder\tin\tder\tNotfallauf -\nnahme\tzur\tDetektion\teiner\tHirnblutung\teingesetzt\twird\tund\tdessen\tAus -\ngabe\tlediglich\tein\t\u201eJa\u201c\toder\t\u201eNein\u201c\tumfasst.\tHier\tliegt\tdas\tProblem\tnicht\t\nin\tder\tNutzung\tder\tKI\tals\tsolcher,\tsondern\tin\tder\tundifferenzierten\tArt\tder\t\nPr\u00e4sentation\tdes\tAnalyseergebnisses.203daf\u00fcr verantwortlich sind, den Betroffenen die aus ihrer Sicht \nbeste Behandlung anzubieten, geh\u00f6rt auch die kritische \u00dcber -\npr\u00fcfung der Ergebnisse der von ihnen eingesetzten techni-\nschen Instrumente zu den \u00e4rztlichen Sorgfaltspflichten, die als \nsolche nicht delegierbar ist.\nEin weiteres Beispiel aus der Praxis im Krankenhaus soll \ndie angesprochene Problematik illustrieren.191 Ein KI-Ger\u00e4t in \nder Radiologie unterst\u00fctzt das Erkennen von Hirnblutungen \nbei Patientinnen und Patienten, indem es eine bin\u00e4re Klassi-\nfikation anzeigt (ja, Blutung liegt vor, bzw. nein, Blutung liegt \nnicht vor). Es stellt sich dabei die Frage, ob eine derart grobe \nKlassifikation ohne zus\u00e4tzliche, differenziertere Angaben aus \nder Anwendungsperspektive eine sinnvolle Entscheidungs-\nunterst\u00fctzung darstellt. Sowohl zur Einsch\u00e4tzung der Sicher -\nheit des bin\u00e4ren Klassifikationsergebnisses durch das \u00e4rztliche \nPersonal als auch mit Blick auf die weitere Behandlungspla-\nnung w\u00e4ren komplexere Aussagen w\u00fcnschenswert, etwa zur \nWahrscheinlichkeit der (verschiedenen) Diagnosen, zur Loka-\nlisation der Blutung im Gehirn oder zu m\u00f6glichen Ursachen. \nGrunds\u00e4tzlich erscheint ein Einsatz des Ger\u00e4tes als maschinel-\nler \u201eZweitgutachter\u201c aber durchaus sinnvoll.\nDer Einsatz dieser KI-gest\u00fctzten Klassifizierung stellt auch \nf\u00fcr erfahrene Fachkr\u00e4fte trotz eines potenziellen Mehraufwan-\ndes eine Unterst\u00fctzung dar, die zur besseren Urteilsbildung \nbeitr\u00e4gt. Praxisrelevant sind dabei technische Umsetzungs-\ndetails wie beispielsweise eine direkte Integration im Scanner \nund eine schnelle Auswertung ohne gesonderte Einwilligung \nin den Datentransfer an anderer Stelle. Es sollte dabei sicher -\ngestellt werden, dass die KI-basierte Analyse das diagnostische \nPotenzial auf Grundlage der erhobenen Daten aussch\u00f6pft und \nden Behandelnden nachvollziehbar pr\u00e4sentiert und gegebe-\nnenfalls mit weiteren Daten (wie etwa typischen Vergleichsf\u00e4l-\nlen und m\u00f6glichen Konsequenzen der L\u00e4sion) in Verbindung \nbringt.\n191\t Kiefer/May\t2022.204F\u00fcr die Patientenperspektive ergeben sich noch weitere \nAspekte. Denn obwohl die Chance einer verbesserten Fr\u00fcher -\nkennung patientenseitig uneingeschr\u00e4nkt zu begr\u00fc\u00dfen ist, weil \nsie die Aussichten auf eine m\u00f6glichst schonende Therapie und \nHeilung erh\u00f6ht, bleibt die fortschreitende Technisierung ein-\nzelner Behandlungsschritte f\u00fcr die Arzt-Patienten-Beziehung \nkeineswegs folgenlos. Personen, die im Rahmen ihrer medi-\nzinischen Behandlung mit neuen Diagnostikinstrumenten \nkonfrontiert werden, haben erfahrungsgem\u00e4\u00df Fragen, etwa \nzur Sicherheit und Genauigkeit oder zum Datenschutz, und \nBef\u00fcrchtungen, beispielsweise nicht mehr als Person wahrge-\nnommen, sondern auf ihre Daten reduziert zu werden. Diese \nFragen und Bef\u00fcrchtungen sind ernst zu nehmen und in einer \numfassenden Aufkl\u00e4rung gezielt zu thematisieren, um den Pa-\ntientinnen und Patienten auch die M\u00f6glichkeit zur Einholung \neiner Zweitmeinung zu er\u00f6ffnen. Dieser Aufkl\u00e4rungsbedarf \nsteigt zwangsl\u00e4ufig an, wenn nicht nur ein einzelnes Segment \nder \u00e4rztlichen Handlungssequenz technisch ersetzt wird, son-\ndern weitere Ersetzungen m\u00f6glich werden.\nDa das Vertrauen in die Behandlung patientenseitig ma\u00df-\ngeblich von der personalen Zuwendung der Behandelnden \nabh\u00e4ngt, d\u00fcrfte nicht davon auszugehen sein, dass diese mit \nder fortschreitenden Implementierung von KI-Systemen in \nverschiedene Schritte des komplexen Behandlungsprozesses \n\u00fcberfl\u00fcssig werden. Vielmehr besteht teilweise die Hoffnung, \ndie schon heute bestehende Tendenz der Anonymisierung \npartiell zu korrigieren und den \u00c4rztinnen und \u00c4rzten wieder \nmehr Freir\u00e4ume zur Erbringung ihrer eigentlichen Aufgaben \nzu schaffen.192\nErsetzungen mittleren Ausma\u00dfes\nDa sich die digitale Transformation der Medizin dynamisch \nentwickelt/vollzieht, gibt es bereits heute eine Reihe von Ph\u00e4-\nnomenen, bei denen die Grenze zwischen einer engen und \n192\t Health\tEducation\tEngland\t2019.205einer mittleren Ersetzung einzelner Handlungsschritte durch \nKI-Komponenten zunehmend verschwimmt und die darauf \nhindeuten, dass es sich hierbei insgesamt um ein Kontinuum \nunterschiedlicher Nutzungsm\u00f6glichkeiten solcher Tools han-\ndelt, die zum gegenw\u00e4rtigen Zeitpunkt erst teilweise realisiert \nsind.\nEin Beispiel hierf\u00fcr ist ein Algorithmus zur Unterst\u00fct-\nzung des an\u00e4sthesiologischen Fachpersonals zur Berechnung \ndes Risikos, w\u00e4hrend einer Operation zu versterben. In einem \nersten Schritt kann man die Nutzung solcher Instrumente als \neine begr\u00fc\u00dfenswerte Erweiterung des \u00e4rztlichen F\u00e4higkeiten-\nspektrums deuten, da das bisherige operationsbegleitende Mo-\nnitoring der Vitalparameter der operierten Person durch die \nFachleute hier technisch so substituiert wird, dass eine fr\u00fch-\nzeitige Prognose kritischer Zust\u00e4nde m\u00f6glich ist und eine ent-\nsprechende \u00e4rztliche Reaktion eingeleitet werden kann. Es ist \naber in einem zweiten Schritt auch denkbar, dass der Algorith-\nmus k\u00fcnftig nicht nur das Sterblichkeitsrisiko der behandelten \nPerson in Echtzeit berechnet, sondern zus\u00e4tzlich auch noch \nautomatisiert die jeweils situativ angezeigten, bislang dem an-\n\u00e4sthesiologischen Personal vorbehaltenen Ver\u00e4nderungen der \nOperationsbedingungen (z. B. die Dosierung des Narkosemit-\ntels oder die zus\u00e4tzliche Gabe von Katecholaminen) ausl\u00f6sen \nk\u00f6nnte.\nIn der Folge k\u00f6nnte sich das \u00e4rztliche Aufgabenspektrum \nk\u00fcnftig zunehmend auf die Wahrnehmung pr\u00e4- und postope-\nrativer Aufgaben (z. B. die Aufkl\u00e4rung der Patientinnen und \nPatienten) konzentrieren. Unabh\u00e4ngig davon, wie realistisch \ndieses Szenario ist, zeigen solche Beispiele, dass es eine Reihe \nvon Misch- und \u00dcbergangsph\u00e4nomenen gibt, die unter ande-\nrem auch daraus resultieren, dass die verschiedenen funktio-\nnal differenzierbaren Segmente \u00e4rztlichen Handelns Teile ei-\nnes einheitlichen Handlungszusammenhangs bilden.\nDoch ist es nicht nur die innere Einheit von Diagnostik \nund Therapie, die solche \u00dcberg\u00e4nge beg\u00fcnstigt. Auch ex-\nterne Rahmenbedingungen und Effizienz\u00fcberlegungen zur 206Optimierung der Prozessqualit\u00e4t komplexer Behandlungsab-\nl\u00e4ufe k\u00f6nnen Treiber einer fortscheitenden Ersetzungsdyna-\nmik sein (siehe Infokasten 3).\nInfokasten\t3:\tMittlere\tErsetzung\tam\tBeispiel\tvon\tProstatakrebs\nProstatakrebs\t (Prostatakarzinom)\t ist\tmit\trund\t68\t600\tNeuerkrankungen\t\nj\u00e4hrlich\tdie\th\u00e4ufigste\t Krebserkrankung\t beim\tMann.193\tDie\tUrsache\t dieser\t\nKrebserkrankung\t ist\tnoch\tweitgehend\t unbekannt,\t allerdings\t ist\teiner\tder\t\nwichtigsten\t Risikofaktoren\t das\tAlter.\tAufgrund\t des\tdemografischen\t Wan-\ndels\that\tdie\tAnzahl\tan\tProstatakrebserkrankungen\t deutlich\t zugenommen;\t\ngleichzeitig\t haben\tsich\tdie\t\u00dcberlebensaussichten\t aber\terheblich\t verbessert,\t\nda\tetwa\tzwei\tDrittel\tder\tF\u00e4lle\tbereits\tim\tAnfangsstadium\t diagnostiziert\t wer-\nden.\tIn\tScreeningverfahren\t zur\tFr\u00fcherkennung\t wird\tdas\tvon\tden\tKarzinom-\nzellen\tverst\u00e4rkt\tgebildete\tprostataspezifische\tAntigen\t(PSA)\tgemessen.\nErhebliche\t Fortschritte\t in\tder\tProstatakrebsdiagnostik\t wurden\t zudem\tim\t\nBereich\tder\tmultiparametrischen\t Magnetresonanztomografie\t (mpMRT)\t in\t\nKombination\t mit\tultraschallgesteuerter\t Biopsie\terzielt.\tDer\tKI-Einsatz\t un-\nterst\u00fctzt\t die\tFusion\tder\tumfangreichen\t Datens\u00e4tze\t und\tverbessert\t mittels\t\nAnwendung\t von\tDeep\tConvolutional\t Neural\tNetworks\t als\tFaltungsnetz -\nwerk\tzur\tBildsegmentierung,\t sogenannten\t U-Nets,\t die\tErkennung\t und\tLo-\nkalisation\t von\tsuspekten\t L\u00e4sionen.\t Automatisierte\t Bildfusionsverfahren\t\nunterst\u00fctzen\t die\tGewebeentnahme,\t indem\tzuvor\terstellte\t mpMRT-Aufnah-\nmen\tin\tEchtzeit\t mit\tUltraschallaufnahmen\t bei\tder\tGewebeentnahme\t \u00fcber-\nlagert\twerden.\t Mit\tdieser\tMethode\t konnte\tdurch\teine\tpr\u00e4zise\tBiopsie\tdie\t\nEntdeckung\t behandlungsbed\u00fcrftiger\t Prostatakarzinome\t von\tca.\t50\tProzent\t\nauf\t\u00fcber\t90\tProzent\t erh\u00f6ht\twerden.194\tF\u00fcr\teine\tTherapieentscheidung\t ist\t\nletztlich\t jedoch\teine\tpathologische\t Diagnose\t unerl\u00e4sslich,\t die\tsich\tbisher\t\nweitgehend\t auf\tmikroskopische\t Untersuchungen\t st\u00fctzt.\tZunehmend\t wer-\nden\taber,\t\u00e4hnlich\tder\tAuswertung\t von\tbildgebenden\t Verfahren\t wie\tMagne-\ntresonanztomografie\t und\tUltraschall,\t auch\tmikroskopische\t Bilder\tvon\tGe-\nwebeschnitten\t digitalisiert\t und\tautomatisiert\t mit\tUnterst\u00fctzung\t von\tKI-Al-\ngorithmen\t ausgewertet.\t Insbesondere\t bei\tder\tintegrativen\t Auswertung\t aller\t\nBefunde\t kann\tKI\tdar\u00fcber\t hinaus\thelfen,\trichtige\tEntscheidungen\t zu\ttreffen,\t\nindem\tzun\u00e4chst\t anhand\teines\t\u201edigitalen\t Zwillings\u201c\t Therapieoptionen\t getes-\ntet\twerden,\tum\tm\u00f6glichst\terfolgversprechende\tAns\u00e4tze\tauszuw\u00e4hlen.\nIn\tder\tbildgef\u00fchrten\t Therapie\t des\tProstatakarzinoms\t kommen\t weitere\t(teil-)\nautomatisierte\t Verfahren\t der\tChirurgie\t und\tStrahlentherapie\t hinzu.\tInzwi-\nschen\twerden\tin\tDeutschland\t an\t\u00fcber\t140\tKliniken\t Operationen\t mit\tdem\tDa-\nVinci-Operationssystem\t durchgef\u00fchrt.195\tDas\troboterassistierte\t Operieren\t\nerweitert\t das\tSpektrum\t minimalinvasiver\t Operationen\t im\tBauchraum.\t Die\t\n193\t https://www.krebsdaten.de/Krebs/DE/Content/Krebsarten/Prostatakrebs/\nprostatakrebs_node.html\t[03.03.2023].\n194\tAhmed\tet\tal.\t2017;\tSchelb\tet\tal.\t2019.\tVgl.\tSchlemmer/Hohenfellner\t2021;\t\nGigerenzer/Mata/Frank\t2009.\n195\t https://klinikradar.de/da-vinci-op-roboter/kliniken\t[11.01.2023];\thttps://\nwww.klinikkompass.com/kliniken-mit-einem-da-vinci-roboter\t[11.01.2023].207Ger\u00e4te\twerden\tvom\t\u00e4rztlichen\t Personal\t gesteuert,\t das\tam\tMonitor\t die\tGe-\nf\u00e4\u00df-\tund\tGewebestrukturen\t deutlich\t besser\terkennen\t kann\tals\tmit\tblo\u00dfem\t\nAuge;\tdie\tSchnitte\t werden\tvon\tRoboterarmen\t ausgef\u00fchrt.\t So\twird\tdie\tPr\u00e4-\nzision\tbei\tminimalinvasiven\t Operationen\t deutlich\t erh\u00f6ht.\tDies\term\u00f6glicht\t\neine\tradikale\t und\tdoch\tschonende\t und\tnervenerhaltende\t Prostataoperation\t\n(Prostatektomie).196\tEine\tTherapiealternative\t bei\tProstataoperationen,\t die\t\nsich\tnoch\tin\tder\tErprobungsphase\t befindet,\t ist\tdie\tCyberknife-Methode,\t\neine\tvergleichsweise\t neue\tradiochirurgische\t Methode\t zur\tBestrahlung\t von\t\nkleinen,\t gut\tlokalisierten\t Tumoren.\t Dabei\twerden\tR\u00f6ntgenstrahlen\t geb\u00fcn-\ndelt\tund\th\u00f6chst\tpr\u00e4zise\tauf\tden\tTumor\tgelenkt,\t sodass\tdas\tStrahlenb\u00fcndel\t\nmit\tenormer\t Kraft\tdie\tFunktion\t eines\tOperationsmessers\t \u00fcbernimmt.\t W\u00e4h-\nrend\tdie\toperierende\t Person\tdie\tStrahlung\t reguliert,\t wird\tdie\tPosition\t in\t\nEchtzeit\tangepasst,\twas\teine\tpr\u00e4zise\tBehandlung\term\u00f6glicht.197\nEine ethische Reflexion hat zun\u00e4chst zu ber\u00fccksichtigen, dass \ndie angemessene Versorgung einer steigenden Anzahl von \nProstatakrebspatienten vor einer doppelten strukturellen He-\nrausforderung steht. Einerseits m\u00fcssen die Arbeitsabl\u00e4ufe von \nDiagnostik und Therapie mit dem Ziel einer besseren Vernet-\nzung aller beteiligten Akteure auf den unterschiedlichen Ver -\nsorgungsebenen und eines beschleunigten Datenaustauschs \nweiter standardisiert werden. Andererseits soll die Behand-\nlung f\u00fcr die einzelne Person durch eine bessere Stratifizierung \nrelevanter Subgruppen personalisiert werden, um nutzlose \noder sogar sch\u00e4dliche Therapieversuche zu vermeiden.\nNach Einsch\u00e4tzung vieler Sachverst\u00e4ndiger198 kann die \nverst\u00e4rkte Nutzung von KI-Instrumenten die notwendigen \nEntscheidungen w\u00e4hrend des gesamten Behandlungspro-\nzesses positiv unterst\u00fctzen, da sich die einzelnen Segmente \u2013 \nvon der klinischen Untersuchung und Labordiagnostik \u00fcber \nBildgebung und Biopsie bis hin zu Therapie und Nachsorge \n\u2013 in Gestalt von Entscheidungsb\u00e4umen strukturieren und da-\nmit prinzipiell einer Bearbeitung durch KI-Instrumente zu-\ng\u00e4nglich machen lassen. Dabei sind es keineswegs nur reine \n196\thttps://www.leading-medicine-guide.de/behandlung/da-vinci-\nprostatektomie\t[11.01.2023].\n197\t https://www.leading-medicine-guide.com/de/behandlung/cyberknife\t\n[11.01.2023].\n198\tZentrale\tEthikkommission\tbei\tder\tBundes\u00e4rztekammer\t2021,\tA2\u00a0ff.208Effizienz\u00fcberlegungen, die f\u00fcr den verst\u00e4rkten Einsatz von KI-\nSystemen in diesem Bereich sprechen, sondern vor allem die \ndadurch erm\u00f6glichte Verbesserung der Behandlungsqualit\u00e4t, \nvon der letztlich alle Beteiligten profitieren.\nMit den empirisch nachweisbaren Vorteilen \u2013 sowohl bei \nder Fr\u00fcherkennung von Prostatakrebs als auch bei der The-\nrapie durch neue KI-gesteuerte Operationsroboter, die mitt-\nlerweile eigenst\u00e4ndig nicht nur die R\u00e4nder von Tumorgewebe \npr\u00e4ziser als ein Mensch identifizieren, sondern auch beson-\nders gewebeschonend innerhalb des Organismus man\u00f6vrieren \nk\u00f6nnen \u2013 gehen aber auch verschiedene Herausforderungen \neinher, die f\u00fcr das hier vorgestellte Beispiel ebenso gelten wie \nf\u00fcr viele \u00e4hnliche Anwendungsszenarien von KI im Gesund-\nheitsbereich, bei denen menschliche T\u00e4tigkeiten in engem bis \nmittlerem Ausma\u00df durch KI-gest\u00fctzte Technik ersetzt werden.\nErstens ist f\u00fcr eine verl\u00e4ssliche Unterst\u00fctzung der Diagno-\nse und Therapie durch KI eine fl\u00e4chendeckende und einheit-\nliche \u2013 oder zumindest qualitativ vergleichbare \u2013 technische \nAusr\u00fcstung sowie entsprechend geschultes Personal und eine \nkontinuierliche Qualit\u00e4tssicherung unabdingbar.\nZweitens ist aufgrund der immanenten Grenzen von KI-\nSystemen davon auszugehen, dass \u00c4rztinnen und \u00c4rzte bei \nder Diagnose und Behandlung von Prostatakarzinomen auch \nlangfristig unverzichtbare Funktionen zu erf\u00fcllen haben, die \nnicht maschinell substituierbar sind. Beispielsweise m\u00fcssen \nBefunde auf Plausibilit\u00e4t gepr\u00fcft werden.\nDrittens bedarf die konkrete Diagnose- und Therapiepla-\nnung einer Ber\u00fccksichtigung der umfassenden Lebenssituati-\non jedes einzelnen Betroffenen, seiner jeweiligen Vorerkran-\nkungen, individuellen Interessen und Wertpr\u00e4ferenzen, zu der \nauch fortschrittliche KI-Systeme nicht in der Lage sind.\nViertens scheint es \u00e4rztlicherseits erforderlich, eine alle \nVersorgungsebenen und Behandlungsschritte einbeziehende \nKommunikationsstrategie zu entwickeln, um der Gefahr zu \nwehren, dass die jeweiligen Behandelnden immer mehr hinter \nder Technik verschwinden und sich die von ihnen behandelten 209Personen mit ihren Fragen und \u00c4ngsten zunehmend allein ge-\nlassen f\u00fchlen. Da \u00fcber den Einsatz solcher Systeme im Vor -\nfeld aufgekl\u00e4rt werden muss und auch w\u00e4hrend der Nutzung \nauftauchende Fragen zum Beispiel zur verantwortlichen Da-\ntennutzung, zum Datenschutz oder zur Zuverl\u00e4ssigkeit der \nmaschinell produzierten Empfehlungen beantwortet werden \nm\u00fcssen, d\u00fcrfte damit zu rechnen sein, dass die kommunika-\ntiven Anforderungen an eine vertrauensvolle Arzt-Patienten-\nBeziehung in der Zukunft sogar noch weiter zunehmen.\nF\u00fcnftens ist damit zu rechnen, dass sich bestimmte Per -\nsonen dem Einsatz dieser technischen Systeme selbst dann \nverweigern werden, wenn sie bisherigen Behandlungsformen \naus medizinischer Sicht \u00fcberlegen sind, sodass es im Rahmen \nder Interaktion zwischen \u00e4rztlichem Personal und den ihnen \nanvertrauten Personen klarer Regeln bedarf, die nicht nur die \nPatientenautonomie, sondern auch die \u00e4rztliche Therapiefrei-\nheit sch\u00fctzen.\nSechstens ist zu pr\u00fcfen, wie sich die immer st\u00e4rkere Imple-\nmentierung von KI-Systemen auf die Kostenentwicklung im \nGesundheitswesen auswirkt.\nSiebtens sind Herausforderungen zu beachten, die sich bei \nder f\u00fcr die (Weiter-)Entwicklung und Evaluierung solcher Sys-\nteme notwendigen Sammlung, Verarbeitung und Weitergabe \nvon gesundheitsbezogenen Daten ergeben. Im Bereich der KI-\nNutzung ist das vom Deutschen Ethikrat schon 2017 mit Blick \nauf die gesundheitsbezogene Datennutzung formulierte, \u00fcber -\ngreifende Ziel der Datensouver\u00e4nit\u00e4t besonders schwierig zu \nerreichen.199 Zum einen erfordern nahezu alle KI-Nutzungen \nim Gesundheitsbereich enorm gro\u00dfe Big-Data-Datens\u00e4tze. Die \nmitunter sehr restriktive individuelle Auslegungspraxis gelten-\nder Datenschutzbestimmungen und einzelne teils \u00fcberholte \n199\tDeutscher\tEthikrat\t2017,\t251\u2013280.\tDatensouver\u00e4nit\u00e4t\twird\thier\tverstanden\t\n\u201eals\teine\tden\tChancen\tund\tRisiken\tvon\tBig\tData\tangemessene\tverantwort -\nliche\tinformationelle\tFreiheitsgestaltung\u201c\t(ebd.,\t252).210Datenschutzregeln200 k\u00f6nnen deren Gewinnung und damit \nauch sinnvollen Entwicklungen entgegenstehen. Zum anderen \nerlauben die Anwendungen oft noch unmittelbareren Zugriff \nauf die Privatsph\u00e4re von Betroffenen als andere Anwendungen \nder datenreichen Medizin. Dar\u00fcber hinaus besteht das Prob-\nlem der Verwendung solcher Daten f\u00fcr andere Zwecke. Ent-\nsprechend entbindet das Ziel, neue Erkenntnisse f\u00fcr bessere \nzuk\u00fcnftige Behandlungsmethoden im Bereich der \u00f6ffentlichen \nForschung zu generieren, keinesfalls davon, die Personen, die \nihre Daten f\u00fcr die Forschung zur Verf\u00fcgung stellen, m\u00f6glichst \numfassend (gegebenenfalls auch \u00fcber den Grad der Fremd-\nn\u00fctzigkeit des jeweiligen Forschungsprojektes) aufzukl\u00e4ren. \nErschwerend kommt hinzu, dass etwa die Sekund\u00e4rnutzung \nvon klinischen Daten f\u00fcr KI-getriebene klinische Forschung in \neinem komplexen Forschungsfeld erfolgt, in dem die Grenzen \nzwischen der im Gesundheitswesen verbreiteten, rein \u00f6ffent-\nlichen oder kooperativen \u00f6ffentlich-privaten Forschung mit \nGemeinwohlorientierung einerseits und der Forschung von \nAkteuren ganz au\u00dferhalb dieses insgesamt stark regulierten \nSystems andererseits zunehmend verschwimmen.\nWeitreichende Ersetzung\nEiner der wenigen medizinischen Handlungsbereiche, in de-\nnen KI-basierte Systeme zum Teil \u00e4rztliches bzw. anderes Ge-\nsundheitspersonal jedenfalls in bestimmten Kontexten und \nGruppen bereits weitgehend oder sogar vollst\u00e4ndig ersetzen, \nist die Psychotherapie. In den letzten Jahren ist eine F\u00fclle von \nInstrumenten zur (Teil-)Diagnose und Behandlung verschie-\ndener psychischer Probleme entstanden, meist in Form von \nfrei erh\u00e4ltlichen bildschirmbasierten Apps, etwa Chatbots, \nmit denen auf algorithmischer Basis eine Art von Therapie \n200\tEin\tBeispiel\thierf\u00fcr\tist\tArt.\t27\tAbs.\t4\tSatz\t6\tdes\tBayerischen\tKrankenh-\nausgesetzes,\tder\terst\tim\tJuni\t2022\taufgehoben\twurde\tund\tes\tbis\tdahin\t\nbayerischen\tKliniken\tnicht\terlaubte,\tdass\tPatientendaten\tdas\tKrankenhaus\t\nverlassen.211\u2013 zumeist kognitive Verhaltenstherapie \u2013 mit den Betroffenen \nabl\u00e4uft.201\nVielfach werden solche Instrumente als Elemente einer \n\u00e4rztlich bzw. therapeutisch gef\u00fchrten Behandlung eingesetzt, \netwa um durch ein kontinuierliches Monitoring Klarheit \u00fcber \ndie (auch kontextspezifische) Auspr\u00e4gung, Variabilit\u00e4t und \nH\u00e4ufigkeit von Symptomen zu gewinnen (sogenanntes Ecolo-\ngical Momentary Assessment als Alternative zu retrospektiven \nSelbstberichten), Aspekte bestimmter Therapien zu verst\u00e4rken \n(z. B. Biofeedback oder Virtual Reality als imagin\u00e4re Konfron-\ntationstherapie), Verhaltensweisen zu \u00fcben oder therapeutisch \nwirksame Aufgaben zu erledigen (z. B. Entspannungs\u00fcbungen \noder Selbstinstruktionen).202 In dieser Form bleiben diese An-\nwendungen also unter einer gewissen professionellen Aufsicht \nund unterscheiden sich wenig von den bereits seit einigen \nJahrzehnten bekannten therapeutischen Begleitinstrumenten, \nwie etwa papier- oder bildschirmbasierten psychotherapeuti-\nschen Aufgaben auf Fragebogen- oder Entscheidungsbaumba-\nsis. Hier werden also allenfalls einzelne Elemente im Sinne ei-\nner engen Ersetzung auf algorithmischer Basis \u00fcbernommen, \ngegebenenfalls mit etwas mehr Benutzungsfreundlichkeit und \neiner Menge (ihrerseits ethisch nicht immer unproblemati-\nschen) M\u00f6glichkeiten der Datensammlung203, ohne dass die \ntherapeutische Beziehung notwendigerweise grundlegend ver -\n\u00e4ndert w\u00fcrde.\nAllerdings sind viele dieser Apps frei in App-Stores er -\nh\u00e4ltlich und werden daher auch au\u00dferhalb des medizinisch-\ntherapeutischen Kontextes eingesetzt. In dieser Form erfolgt \n\u2013 wenn Betroffene solche Apps nicht nur als einen niedrig-\nschwelligen Einstieg in eine therapeutische Behandlung durch \n201\t\u00dcbersichten\tin\tFiske/Henningsen/Buyx\t2019;\tGratzer/Goldbloom\t2020.\n202\tVan\tDaele\tet\tal.\t2021.\n203\tBei\tverschiedenen\tin\tApp-Stores\terh\u00e4ltlichen\tApps\tist\tunklar,\tob\tund\tgege-\nbenenfalls\twie\tNutzungsdaten\tweiterverwendet\twerden.\tDa\tAnwendungen\t\nwie\tetwa\tder\tChatbot\tWoebot\tkostenlos\tsind,\tist\tanzunehmen,\tdass\tDaten\t\nweiterverkauft\toder\tjedenfalls\teiner\tkommerziellen\tNutzung\tzugef\u00fchrt\t\nwerden.212medizinisches Fachpersonal nutzen \u2013 tats\u00e4chlich eine Thera-\npie, ganz ohne dass menschliches Personal hinzuk\u00e4me.204 Die \nChatbots treten dabei in \u201eGespr\u00e4chskontakt\u201c und \u201ediagnos-\ntizieren\u201c den psychischen Zustand, in dem sich eine Person \nbefindet. Sie bieten verschiedene therapeutische Wege sowie \n\u00dcbungen an und interagieren regelm\u00e4\u00dfig und aufsuchend \nmit den sie nutzenden Personen (es sei denn, diese haben die \nentsprechende Funktion ausgestellt).205 Die meisten dieser \nChatbots weisen darauf hin, dass etwa suizidale Gedanken un-\nmittelbare, intensivere Behandlung erfordern, und \u201eschlagen \nvor\u201c, Krisentelefon-Services in Anspruch zu nehmen. Sie sind \njedoch nicht mit Notdiensten oder \u00c4hnlichem verbunden und \nfungieren daher nicht als eigenst\u00e4ndiges Warnsystem.\nHier ergibt sich also tats\u00e4chlich eine weite Ersetzung inso-\nfern, als die Chatbots und diejenigen, die mit ihnen interagie-\nren, in einer Art direkten, therapeutischen Beziehung stehen. \nBisher gibt es wenige empirische Studien oder theoretische \nAbhandlungen, die dieses Ph\u00e4nomen untersuchen.206 Den-\nnoch liegen ethische Vorteile und Bedenken auf der Hand. Po-\nsitiv diskutiert wird insbesondere, dass solche Apps angesichts \nihrer Niedrigschwelligkeit und st\u00e4ndigen Verf\u00fcgbarkeit Men-\nschen in Erstkontakt mit therapeutischen Angeboten bringen \nk\u00f6nnen, die sonst oft zu sp\u00e4t oder gar keine Therapie erhal-\nten. Dies gilt insbesondere f\u00fcr Gruppen, die oft schwer (z. B. \nwohnortbedingt) mit anderen Angeboten erreicht werden \n(Gateway-Ph\u00e4nomen).207\nHinzu kommt ein weithin f\u00fcr die Nutzung etwa von Auf-\nkl\u00e4rungsalgorithmen in Krankenh\u00e4usern beschriebenes Ph\u00e4-\nnomen208, dass Menschen maschinellen \u201eTherapeuten\u201c mehr \nvon sich berichten und ihnen gegen\u00fcber weniger Scham \nversp\u00fcren als im Gespr\u00e4ch von Mensch zu Mensch. Gerade \n204\tEbert\tet\tal.\t2018.\n205\tMehta\tet\tal.\t2021.\n206\tHolohan/Fiske\t2021.\n207\tParviainen/Rantala\t2022.\n208\tPugh\t2018;\tDennis\tet\tal.\t2020.213Scham oder die Sorge vor Stigmatisierung h\u00e4lt bekannterma-\n\u00dfen viele Menschen davon ab, fr\u00fchzeitig Therapieangebote \naufzusuchen. Diesbez\u00fcglich k\u00f6nnte also gerade die Ersetzung \nmenschlichen Fachpersonals dazu f\u00fchren, dass \u00fcberhaupt ein \ntherapie\u00e4hnliches Angebot in Anspruch genommen wird. \nHier ist allerdings zu ber\u00fccksichtigen, dass die Frage, ob und \nwieweit sich Menschen \u00f6ffnen \u2013 und welche Effekte dies hat \u2013, \nnicht nur von der Anonymit\u00e4t der Interaktion, sondern auch \nvom Vertrauen in die Kontaktperson abh\u00e4ngt. Der anonyme \nChatbot ersetzt nicht ohne Weiteres das als vertrauensw\u00fcrdig \nwahrgenommene therapeutische Fachpersonal, denn die Wir -\nkung von Psychotherapie entfaltet sich in vielen F\u00e4llen erst \nauf der Grundlage der Therapeut-Klienten-Beziehung.209 Und \nschlie\u00dflich wird insbesondere mit Blick auf Regionen, in de-\nnen nicht ausreichend Therapiepl\u00e4tze zur Verf\u00fcgung stehen, \nargumentiert, dass angesichts des immer weiter steigenden \nVersorgungsbedarfs210 gerade milder psychischer Probleme \nChatbot-Apps jedenfalls \u201ebesser als nichts\u201c sind.211\nAllerdings ergeben sich insbesondere im Falle einer Erset-\nzung therapeutischer Fachkr\u00e4fte durch Maschinen aus ethi-\nscher Sicht wichtige Bedenken und Probleme. Offenkundig \nsind Probleme wie die mangelnde Qualit\u00e4tskontrolle der Bots \n(vor allem wenn sie nicht als digitale Gesundheitsanwendun-\ngen212 zugelassen sind), Fragen zur Datensammlung und -wei-\nterverwendung, Fragen zum Schutz der Privatsph\u00e4re sowie \ndie erw\u00e4hnte fehlende Warnfunktion etwa bei eindeutiger \nSuizidalit\u00e4t.\nHinsichtlich der Betroffenenperspektive kann zudem an-\ngenommen werden, dass gerade vulnerable Personen, die \nohnehin schlecht versorgt sind, den Eindruck gewinnen, \nmit vermeintlich zweitklassigen therapeutischen Surrogaten \n209\tCroes/Antheunis\t2021;\tGerhardinger\t2020,\t225\u00a0ff.\n210\tVgl.\tauch\tDeutscher\tEthikrat\t2022a.\n211\t Fiske/Henningsen/Buyx\t2019,\t5.\n212\t https://www.bfarm.de/DE/Medizinprodukte/Aufgaben/DiGA-und-DiPA/\nDiGA/_node.html\t[22.02.2023].214abgespeist zu werden. Weiterhin kann nicht unterstellt wer -\nden, dass alle, die solche Apps verwenden, umfassend \u00fcber \nderen Charakter informiert sind. Es ist m\u00f6glich, dass manche \ndie App mit einer Art telemedizinischem Angebot verwech-\nseln und davon ausgehen, dass auf der anderen Seite doch ein \nMensch therapeutisch agiert. Hier w\u00fcrde also die Ersetzung \nals solche verkannt \u2013 mit potenziell problematischen Folgen.\nSchlie\u00dflich ist noch so gut wie gar nicht untersucht, ob in-\nnerhalb der therapeutischen Beziehung zwischen einer App \nund denjenigen, die sie nutzen, Ph\u00e4nomena von \u00dcbertra-\ngung \u2013 ein wesentliches Element bei vielen therapeutischen, \ninsbesondere psychoanalytischen Ans\u00e4tzen \u2013 erfolgen. Es ist \nzumindest anzunehmen, dass Menschen eine Art emotiona-\nle Beziehung zur therapeutischen App aufbauen k\u00f6nnten, die \nvon Zuneigung, Sich-Verlassen bis hin zu Abh\u00e4ngigkeitsas-\npekten reichen k\u00f6nnte. Daraus ergibt sich nicht nur die Fra-\nge, ob und inwieweit hier Empathie und Verstehen technisch \nsubstituiert werden k\u00f6nnen oder sollen, sondern auch, ob dies \nauf Dauer Effekte auf die Beziehungsf\u00e4higkeiten der Betroffe-\nnen haben k\u00f6nnte. Therapiebeg\u00fcnstigende (weil reflektierte) \nGegen\u00fcbertragungen seitens der therapeutischen Fachkraft \nk\u00f6nnen von KI-Anwendungen hingegen nicht erwartet wer -\nden. Dies verdeutlicht, dass digitale Anwendungen auf dem \nGebiet der Psychotherapie nicht unabh\u00e4ngig von der jeweili-\ngen Therapieform betrachtet werden k\u00f6nnen \u2013 ebenso wenig, \nwie die Therapieformen unabh\u00e4ngig von der Pers\u00f6nlichkeit \nderjenigen, die sie nutzen, und der jeweils infrage stehenden \nProblematik sowie ihrem unmittelbaren Bedrohungspotenzial \nbetrachtet werden k\u00f6nnen.\nAuch aus gesellschaftlicher Perspektive ergeben sich Fra-\ngen. Kontrovers diskutiert wird etwa, ob die zunehmende \nNutzung solcher Apps einem weiteren Abbau von therapeuti-\nschem Fachpersonal Vorschub leistet und damit die Reduktion \nvon Versorgungsbereichen beschleunigt. Ebenso werden eine \nVerst\u00e4rkung von gesundheitlichen Ungleichheiten und digital \ndivides sowie auch ein m\u00f6glicher weiterer Prestigeverlust der 215sprechenden Medizin, die in ungerechtfertigter Weise als durch \nAlgorithmen einfach ersetzbar erscheinen k\u00f6nnte, angemahnt.\n5.3\t\t Fazit\tund\tEmpfehlungen\nDie Erfahrung, dass sich die digitale Transformation unseres \nGesundheitssystems auf verschiedene Bereiche des medizini-\nschen Handelns bislang sehr unterschiedlich auswirkt, best\u00e4tigt \nsich auch im Blick auf den speziellen Bereich von KI-Anwen-\ndungen. Dies gilt nicht allein f\u00fcr den Grad der Durchdringung \neines Handlungsfeldes mit den neuen technischen M\u00f6glich-\nkeiten und die Dynamik der daraus resultierenden Ver\u00e4nde-\nrungen f\u00fcr die Arzt-Patienten-Beziehung, sondern auch f\u00fcr \ndie Gr\u00fcnde, die diese Entwicklung jeweils vorantreiben.\nNeben naheliegenden immanenten Faktoren wie der Exis-\ntenz immer gr\u00f6\u00dferer Datenmengen, die einer maschinellen \nBearbeitung zug\u00e4nglich sind, k\u00f6nnen auch kontingente Fak-\ntoren die Nutzung von KI-Anwendungen beg\u00fcnstigen. Dazu \ngeh\u00f6ren beispielsweise Versorgungsengp\u00e4sse aufgrund von \nPersonalmangel, aber auch die M\u00f6glichkeit bzw. Erwartung \npr\u00e4ziserer Diagnostik oder neuerer, gegebenenfalls niedrig-\nschwelligerer therapeutischer Anwendungen in einzelnen \nBereichen.\nDie in den vorigen Abschnitten vorgestellten Beispiele \nmachen deutlich, dass es dabei sehr auf die jeweils konkreten \nBedingungen des Einsatzes von KI-basierten Tools ankommt, \nob diese beispielsweise innerhalb oder au\u00dferhalb einer etab-\nlierten Arzt-Patienten-Beziehungen zum Einsatz kommen. Bei \nder Zertifizierung zuk\u00fcnftiger Anwendungen sind solche kon-\ntextspezifischen Fragen zu ber\u00fccksichtigen.\nUngeachtet der daraus resultierenden Notwendigkeit ei-\nner Binnendifferenzierung des weiten Handlungsfeldes der \nMedizin liegen einige \u00fcbergreifenden Empfehlungen f\u00fcr den \nGesundheitssektor nahe.216Empfehlungen\n>> Empfehlung Medizin 1: Bei der Entwicklung, Erprobung \nund Zertifizierung medizinischer KI-Produkte bedarf es ei-\nner engen Zusammenarbeit mit den relevanten Zulassungs-\nbeh\u00f6rden sowie insbesondere mit den jeweils zust\u00e4ndigen \nmedizinischen Fachgesellschaften, um Schwachstellen der \nProdukte fr\u00fchzeitig zu entdecken und hohe Qualit\u00e4tsstan-\ndards zu etablieren.\n>> Empfehlung Medizin 2: Bei der Auswahl der Trainings-, \nValidierungs- und Testdatens\u00e4tze sollte \u00fcber bestehende \nRechtsvorgaben hinaus mit einem entsprechenden Mo-\nnitoring sowie pr\u00e4zise und zugleich sinnvoll umsetzbaren \nDokumentationspflichten sichergestellt werden, dass die \nf\u00fcr die betreffenden Patientengruppen relevanten Faktoren \n(z. B. Alter, Geschlecht, ethnische Einflussfaktoren, Vorer -\nkrankungen und Komorbidit\u00e4ten) hinreichend ber\u00fcck-\nsichtigt werden.\n>> Empfehlung Medizin 3: Bei der Gestaltung des Designs von \nKI-Produkten zur Entscheidungsunterst\u00fctzung ist sicher -\nzustellen, dass die Ergebnisdarstellung in einer Form ge-\nschieht, die Gefahren etwa von Automatismen (Automa-\ntion Bias) transparent macht, ihnen entgegenwirkt und die \ndie Notwendigkeit einer reflexiven Plausibilit\u00e4tspr\u00fcfung \nder jeweils vom KI-System vorgeschlagenen Handlungs-\nweise unterstreicht.\n>> Empfehlung Medizin 4: Bei der Sammlung, Verarbeitung \nund Weitergabe von gesundheitsbezogenen Daten sind ge-\nnerell strenge Anforderungen und hohe Standards in Be-\nzug auf Aufkl\u00e4rung, Datenschutz und Schutz der Privatheit \nzu beachten. In diesem Zusammenhang verweist der Deut-\nsche Ethikrat auf seine 2017 im Kontext von Big Data und \nGesundheit formulierten Empfehlungen, die sich am Kon-\nzept der Datensouver\u00e4nit\u00e4t orientieren, das f\u00fcr den Bereich \nvon KI-Anwendungen im Gesundheitsbereich gleicherma-\n\u00dfen G\u00fcltigkeit entfaltet.217>> Empfehlung Medizin 5: Bei durch empirische Studien sorg-\nf\u00e4ltig belegter \u00dcberlegenheit von KI-Anwendungen gegen-\n\u00fcber herk\u00f6mmlichen Behandlungsmethoden ist sicherzu-\nstellen, dass diese allen einschl\u00e4gigen Patientengruppen zur \nVerf\u00fcgung stehen.\n>> Empfehlung Medizin 6: F\u00fcr erwiesen \u00fcberlegene KI-An-\nwendungen sollte eine rasche Integration in die klinische \nAusbildung des \u00e4rztlichen Fachpersonals erfolgen, um eine \nbreitere Nutzung vorzubereiten und verantwortlich so ge-\nstalten zu k\u00f6nnen, dass m\u00f6glichst alle Patientinnen und \nPatienten davon profitieren und bestehende Zugangsbarri-\neren zu den neuen Behandlungsformen abgebaut werden. \nDazu ist die Entwicklung einschl\u00e4giger Curricula/Module \nin Aus-, Fort- und Weiterbildung notwendig. Auch die an-\nderen Gesundheitsberufe sollten entsprechende Elemente \nin die Ausbildung aufnehmen, um die Anwendungskom-\npetenz bei KI-Anwendungen im Gesundheitsbereich zu \nst\u00e4rken.\n>> Empfehlung Medizin 7: Bei routinem\u00e4\u00dfiger Anwendung \nvon KI-Komponenten sollte nicht nur gew\u00e4hrleistet wer -\nden, dass bei denjenigen, die sie klinisch nutzen, eine hohe \nmethodische Expertise zur Einordnung der Ergebnisse \nvorhanden ist, sondern auch strenge Sorgfaltspflichten bei \nder Datenerhebung und -weitergabe sowie bei der Plausi-\nbilit\u00e4tspr\u00fcfung der maschinell gegebenen Handlungsemp-\nfehlungen eingehalten werden. Besondere Aufmerksam-\nkeit erfordert die Gefahr eines Verlustes von theoretischem \nwie haptisch-praktischem Erfahrungswissen und entspre-\nchenden F\u00e4higkeiten (Deskilling); dieser Gefahr sollte mit \ngeeigneten, spezifischen Fortbildungsma\u00dfnahmen entge-\ngengewirkt werden.\n>> Empfehlung Medizin 8: Bei fortschreitender Ersetzung \n\u00e4rztlicher, therapeutischer und pflegerischer Handlungs-\nsegmente durch KI-Komponenten ist nicht nur sicher -\nzustellen, dass Patientinnen und Patienten \u00fcber alle ent-\nscheidungsrelevanten Umst\u00e4nde ihrer Behandlung vorab 218informiert werden. Dar\u00fcber hinaus sollten auch gezielte \nkommunikative Ma\u00dfnahmen ergriffen werden, um dem \ndrohenden Gef\u00fchl einer zunehmenden Verobjektivierung \naktiv entgegenzuwirken und das Vertrauensverh\u00e4ltnis zwi-\nschen den beteiligten Personen zu sch\u00fctzen. Je h\u00f6her der \nGrad der technischen Substitution menschlicher Handlun-\ngen durch KI-Komponenten ist, desto st\u00e4rker w\u00e4chst der \nAufkl\u00e4rungs- und Begleitungsbedarf der Patientinnen und \nPatienten. Die verst\u00e4rkte Nutzung von KI-Komponenten \nin der Versorgung darf nicht zu einer weiteren Abwertung \nder sprechenden Medizin oder einem Abbau von Personal \nf\u00fchren.\n>> Empfehlung Medizin 9: Eine vollst\u00e4ndige Ersetzung der \n\u00e4rztlichen Fachkraft durch ein KI-System gef\u00e4hrdet das Pa-\ntientenwohl und ist auch nicht dadurch zu rechtfertigen, \ndass schon heute in bestimmten Versorgungsbereichen \nein akuter Personalmangel besteht. Gerade in komplexen \nBehandlungssituationen bedarf es eines personalen Gegen-\n\u00fcbers, das durch technische Komponenten zwar immer \nst\u00e4rker unterst\u00fctzt werden kann, dadurch selbst als Verant-\nwortungstr\u00e4ger f\u00fcr die Planung, Durchf\u00fchrung und \u00dcber -\nwachung des Behandlungsprozesses aber nicht \u00fcberfl\u00fcssig \nwird.2196\t \t BILDUNG\n6.1\t\t Einleitung\nAuch im Bildungsbereich kommen zunehmend digitale Tech-\nnologien und algorithmische Systeme zum Einsatz.213 Dies \nkann sowohl zur Standardisierung von Lernprozessen f\u00fchren \nals auch im Falle von stark datenbasierten KI-Systemen \u2013 \u00e4hn-\nlich wie in der Medizin \u2013 mehr Personalisierung erm\u00f6glichen, \ndas hei\u00dft einen st\u00e4rkeren Zuschnitt auf individuelle Bedin-\ngungen und Neigungen der Lernenden. Personalisiertes Ler -\nnen und Lehren werden dabei unter anderem dadurch m\u00f6g-\nlich, dass durch umfangreiche maschinelle Datenerfassung \nund -auswertung ein Vielfaches an Informationen zum Lern-\ngeschehen im Vergleich zu fr\u00fcheren M\u00f6glichkeiten zur Ver -\nf\u00fcgung steht und von Lehrkr\u00e4ften, Lernenden und weiteren \nBeteiligten zur Personalisierung von Lehr- und Lernprozessen \nverwendet werden kann.214 Wie auch im Anwendungsfeld Me-\ndizin reichen die Einsatzm\u00f6glichkeiten von sehr eng umrisse-\nnen punktuellen Angeboten f\u00fcr Lernende und Lehrkr\u00e4fte bis \nhin zu Szenarien, in denen digitale Werkzeuge umfassend ein-\ngesetzt werden und beispielsweise datenbasierte, KI-gest\u00fctzte \nLehr- und Lernsysteme zeitweise oder g\u00e4nzlich eine Lehrkraft \nersetzen k\u00f6nnen.215 Die damit verbundenen Ver\u00e4nderungspo-\ntenziale, Chancen und Risiken werden hier f\u00fcr die Schule als \n213\t OECD\t2021.\n214\tDies\tist\tnat\u00fcrlich\tnur\tunter\tder\tVoraussetzung\tgegeben,\tdass\tsowohl\tmobi-\nle\tEndger\u00e4te\tals\tauch\tkostenloses\tWLAN\tf\u00fcr\tdie\tSch\u00fclerinnen\tund\tSch\u00fcler\t\nvon\tstaatlicher\tSeite\tzur\tVerf\u00fcgung\tgestellt\twerden.\tBildungsungleichheit\t\nbei\tden\tStartchancen\tdarf\tdabei\tnicht\tweiter\tvertieft,\tsondern\tk\u00f6nnte\t\ndurch\tdas\tspezifische\tEingehen\tauf\tdie\tHeterogenit\u00e4t\tder\tSch\u00fclerschaft\t\nm\u00f6glicherweise\tgrundlegend\tangegangen\twerden.\n215\t https://www.egovernment-computing.de/ki-als-helfende-lehrkraft-\nwaehrend-des-lockdowns-a-926866\t[11.01.2023].220exemplarischem Lernort und Ort der Pers\u00f6nlichkeitsbildung \nvorgestellt.216\nJenseits der auch anderweitig thematisierten technischen \nHerausforderungen rund um die Nutzung digitaler und al-\ngorithmischer Systeme in der Schule217 gilt das Interesse in \ndieser Stellungnahme vor allem den anthropologischen und \nethischen Fragen. Im Mittelpunkt steht hierbei die Auseinan-\ndersetzung damit, wie die maschinelle Ersetzung bestimmter \nmenschlicher Handlungssegmente Lehr- und Lernprozesse \nver\u00e4ndert, Handlungsm\u00f6glichkeiten aller Akteure erweitert \noder auch vermindert. Zudem ist die Frage bedeutsam, wie \ndies das Selbstverst\u00e4ndnis und Miteinander der verschiedenen \nBeteiligten am Lernort Schule und dem Zuhause der Schul-\npflichtigen beeinflusst und gegebenenfalls dar\u00fcber hinaus ge-\nsellschaftliche Auswirkungen entfaltet.\nWie in Kapitel 3 ausgef\u00fchrt, orientiert sich das hier zu-\ngrunde gelegte Verst\u00e4ndnis von Bildung an der F\u00e4higkeit des \nMenschen zu freiem und vern\u00fcnftigem Handeln, das nicht auf \nbehavioristische oder funktionalistische Modelle zu reduzie-\nren ist. Die vielf\u00e4ltigen M\u00f6glichkeiten des Einsatzes digitaler \nund algorithmischer Angebote in der Bildung sind auf diese \ngrundlegende Ausrichtung von Bildung zu beziehen. Wenn \ndaher von Chancen und Risiken datenbasierter, KI-gest\u00fctzter \nLehr- und Lernsysteme die Rede ist, sind diese nicht einfach \nan technologischen Optimierungsvorstellungen zu orientie-\nren. Alle technologischen M\u00f6glichkeiten der Gestaltung der \nBildungsprozesse sind vielmehr daraufhin zu \u00fcberpr\u00fcfen, ob \nsie dem eingangs entwickelten Verst\u00e4ndnis des Menschen als \neiner zur Selbstbestimmung und Verantwortung f\u00e4higen Per -\nson entsprechen oder ob sie diesem Verst\u00e4ndnis entgegenste-\nhen. Die Notwendigkeit einer solch grundlegende Betrach-\ntung wird auch in den aktuellen Debatten rund um ChatGPT \n216\t Somit\tsind\tandere\tOrte\tder\tBildung\tund\tdes\tLernens\twie\tHochschulen,\t\nKindertagesst\u00e4tten\toder\tandere\tFormen\tder\tAus-\tund\tWeiterbildung\tnicht\t\nexplizit\tber\u00fccksichtigt.\n217\t Vgl.\tzum\t\u00dcberblick\tOECD\t2021.221sichtbar.218 Unmittelbar nachdem dieser KI-basierte und hoch \nperformante Textgenerator frei zug\u00e4nglich gemacht wurde, \nwurden disruptive Entwicklungen nicht zuletzt f\u00fcr den Bil-\ndungsbereich diskutiert. Ging es vordergr\u00fcndig zun\u00e4chst um \ndie Frage, wie Pr\u00fcfungen fair gestaltet werden k\u00f6nnen, wenn \nman nicht wei\u00df, ob Sch\u00fclerinnen und Sch\u00fcler ihre Hausarbei-\nten selbst geschrieben haben oder von ChatGPT haben pro-\nduzieren lassen, so erfordert ChatGPT dar\u00fcber hinaus eine \nerneute Auseinandersetzung damit, was Bildung ist und sein \nsoll. Es geht um eine Vergewisserung und Neubestimmung \ndessen, was Ziel und Wert von Bildung sind, was relevantes \nWissen ist und welche Fertigkeiten und F\u00e4higkeiten Lernende \nweiterhin ben\u00f6tigen und welche vielleicht an Relevanz verlo-\nren haben.\n6.2\t\t Zum\tBildungsbegriff\nOberstes Ziel von Bildung ist es, den Menschen zu einer m\u00fcn-\ndigen und freien, das hei\u00dft einer zur Verantwortung f\u00e4higen \nPerson heranzubilden. Bildungsbegriffe und -konzepte sind \nzwar immer auch vom jeweiligen Kulturkreis abh\u00e4ngig, inso-\nfern die Sicht auf den Menschen, seine Sozialit\u00e4t und damit die \nVerh\u00e4ltnisbestimmung von Individuum und Gesellschaft auch \ndas Verst\u00e4ndnis von Bildung pr\u00e4gt. Die folgenden \u00dcberlegun-\ngen gehen davon aus, dass Bildung sich an einem Verst\u00e4ndnis \ndes humanum orientiert, das auf eine umfassende Pers\u00f6nlich-\nkeitsbildung zielt, die auf Urteilsf\u00e4higkeit und verantwortliche \nTeilhabe an der Gesellschaft angelegt ist.\nSolche Bildung erfordert den Erwerb von Orientierungs-\nwissen als Bedingung reflexiver Urteilskraft und Entschei-\ndungsst\u00e4rke. Orientierungswissen entsteht einerseits aus der \n218\t Da\tdie\tinhaltliche\tBefassung\tmit\tder\tStellungnahme\tzum\tZeitpunkt\tder\t\nVer\u00f6ffentlichung\tvon\tChatGPT\tbereits\tabgeschlossen\twar,\twird\thier\tnicht\t\ndetaillierter\tauf\tChatGPT\tund\tdie\tdamit\tverbundenen\tFolgen\tf\u00fcr\tschulische\t\nBildung\teingegangen.222kritischen Rezeption empirischer Inhalte \u2013 von Alltagserfah-\nrungen bis zu Ergebnissen wissenschaftlicher Forschung \u2013 und \nandererseits aus der Wahrnehmung normativer Inhalte \u2013 von \nsozialen \u00dcblichkeiten bis zur reflektierten moralischen Ur -\nteilsbildung. Aus beiden Quellen bildet sich die F\u00e4higkeit zur \n\u00dcbernahme von Verantwortung des Menschen gegen\u00fcber sei-\nner sozialen Umgebung und sich selbst.\nSo umfasst Bildung neben der Vermittlung von Informati-\nonen ebenso Kontextwissen, das technische Kompetenzen vor \ndem Hintergrund verschiedener Erfahrungen zu beurteilen \nund einzusetzen vermag. Zu diesen Erfahrungen geh\u00f6ren po-\nlitische, kulturelle oder existenzielle Erfahrungen, die in einem \nkulturellen Lernen intergenerationell weitergegeben und an-\ngeeignet werden k\u00f6nnen. Wenn \u00fcber die Kriterien der Bildung \nangesichts voranschreitender Digitalisierung auch im schuli-\nschen Unterricht nachgedacht wird, ist das aus empirischen \nwie normativen Aspekten zusammengesetzte Orientierungs-\nwissens als Grundlage kulturellen Lernens zu ber\u00fccksichti-\ngen.219 Es ist als Kriterium von Bildung auch f\u00fcr die Chancen \nund Risiken digitaler Bildung relevant.\nDie Digitalisierung ist nicht Selbstzweck und die mit der \ndigitalen Bildung oft einhergehende Vorstellung der Optimie-\nrung von Lernprozessen (oder des Lehr- und Lerngeschehens) \nist kritisch auf das grundlegende Bildungsziel urteilsf\u00e4higer \nSelbstbestimmung des Menschen und seiner Handlungsver -\nantwortung zu \u00fcberpr\u00fcfen.\nBildung, die auch im Rahmen von digitaler Bildung als \nBildung zum Humanum zu begreifen ist, geht einher mit \nIdentit\u00e4tsstiftung. Aus den \u00dcberlegungen der vorangegange-\nnen Kapitel ergibt sich, dass in diesem Feld der KI m\u00f6gliche \nLehrroboter eine Bildung, die sich als Kompetenz zur Selbst-\nbestimmung und Urteilsf\u00e4higkeit auszeichnet, nicht ersetzen \nk\u00f6nnen. Sie k\u00f6nnen dem Kompetenzerwerb sogar abtr\u00e4glich \nsein, denn zum hier vertretenen Bildungsverst\u00e4ndnis geh\u00f6rt \n219\t Nicht\tweiter\teingegangen\twird\tauf\tinterkulturelles\tLernen.223es, Ideen zu entwickeln, Geschichten zu entwerfen, Kunstwer -\nke zu entdecken, aber auch Kritikf\u00e4higkeiten auszubilden, um \nIdeologien zu durchschauen. Das abw\u00e4gende und kompetente \nUrteil der m\u00fcndigen Person bildet hier die Voraussetzung f\u00fcr \ndie Beurteilung der digitalen Prozesse.\nZu beachten ist daher ferner: Bildung ersch\u00f6pft sich nicht \nin einer kognitiven Vermittlung von Information, sondern \nsie schlie\u00dft affektive Dimensionen und soziale Kontakte ein. \nSchulisches Lernen ist daher nicht auf kognitiv-technische \nOperationen zu reduzieren, sondern beinhaltet auch emotio-\nnale und motivationale Aspekte. F\u00fcr die Lehrkr\u00e4fte ist es von \nBedeutung, sich klarzumachen, dass das Lehr- und Lernge-\nschehen als dynamische Interaktion mit anderen Personen zu \nbegreifen ist, als Interaktion mit Lehrenden wie auch mit an-\nderen Lernenden. Lehrkr\u00e4fte k\u00f6nnen im besten Fall als Iden-\ntifikationsfiguren ein motivierendes und identit\u00e4tsstiftendes \nPotenzial entfalten, das den Wissensdurst in Sch\u00fclerinnen und \nSch\u00fclern wecken und Begeisterungsf\u00e4higkeit entfachen kann. \nDer Informationsgewinn durch Vermittlung von Sachwissen \nwird damit reflexiv auf die eigene Lebenswirklichkeit bezogen. \nSolches reflexive Lernen ist entscheidend f\u00fcr die Vorg\u00e4nge des \nVerstehens und Aneignens.\nDigitale Bildung ist daraufhin zu \u00fcberpr\u00fcfen, ob sie solch \nreflexives Lernen in der Interaktion zwischen Lehrkr\u00e4ften und \nLernenden f\u00f6rdert oder behindert. Denn erst in diesem reflexi-\nven Aneignen von Wissen werden die Potenziale jener Bildung \nfreigesetzt, die den Menschen als freie und selbstverantwort-\nliche Person ansprechbar werden lassen. Diese Kompetenzen \nreflexiven Verstehens und Aneignens sind daher Vorausset-\nzung f\u00fcr einen urteilsf\u00e4higen Umgang mit den M\u00f6glichkeiten \ndigitalen Lernens.\nBildung umfasst damit mehr als Informationszuwachs \nund logisches Schlie\u00dfen. Dazu z\u00e4hlt die immer mitlaufende \nBezogenheit auf soziale und kommunikative Verst\u00e4ndigung. \nWerden Teile der Interaktion zwischen Lernenden und Leh-\nrenden oder auch der Lernenden untereinander durch digitale 224Angebote ersetzt oder vermittelt, stellt sich die Frage, was dies \nf\u00fcr individuelle und soziale Lernprozesse bedeutet. Einer Au-\ntomatisierung von Lernprozessen, die den reflexiven Bezug \nder Aneignung von Wissen und des Verst\u00e4ndnisses erschwert \noder gar unterbindet, w\u00e4re daher eine Absage zu erteilen. Da-\nmit w\u00fcrde das Lernen nicht mehr im vorgestellten umfassen-\nden Sinne der Bildung der Person erfolgen. Ob Bildung sich \nohne ein nicht zu vernachl\u00e4ssigendes personales Gegen\u00fcber \nvollziehen kann, ist fraglich. Denn f\u00fcr den Aneignungs- und \nVerstehensprozess ist der kommunikative Aspekt des Lernens, \nder ein personales Gegen\u00fcber voraussetzt, unverzichtbar.\nDer Eingang der Digitalisierung in den Bereich der Bil-\ndung muss hinsichtlich der Ver\u00e4nderungsprozesse, die er f\u00fcr \ndie Bildung als solche einleitet, daher genau reflektiert wer -\nden. Das gilt sowohl f\u00fcr Prozesse aufseiten der Lehrenden wie \naufseiten der Lernenden. Daf\u00fcr ist es zum Beispiel n\u00f6tig, dass \nLehrkr\u00e4fte auch in der Lage sind, die Funktionsweise daten-\nbasierter, KI-gest\u00fctzter Lehr- und Lernsoftware hinsichtlich \nihrer didaktischen Leistungsf\u00e4higkeit einzuordnen, um ihren \nEinsatz konstruktiv vornehmen, aber auch kritisch begleiten \nzu k\u00f6nnen. Es geht mit Blick auf die Zukunft darum, den Ein-\nsatz der neuen Techniken an den Entwicklungspotenzialen \nder Lernenden zu orientieren. Das Ziel muss sein, die Bildung \nzur Verantwortungsf\u00e4higkeit nicht zu vermindern, sondern zu \nerweitern. Aufgrund der Dynamik und Komplexit\u00e4t der Ent-\nwicklung solcher digitalen Lerntechniken ist es daher erfor -\nderlich, m\u00f6glichst bald entsprechend der Zertifizierung klassi-\nscher Lehr- und Lernmaterialien auch deren digitale Pendants \nzu zertifizieren.220\n220\tF\u00fcr\tdie\t\u00f6sterreichischen\tBem\u00fchungen\tvgl.\tBundesministerium\tf\u00fcr\tKlima-\nschutz,\tUmwelt,\tEnergie,\tMobilit\u00e4t,\tInnovation\tund\tTechnologie\t2021,\t30.\t\nEs\twerden\tallgemeine\tZertifizierungskriterien\tentwickelt,\tdie\tdann\tauch\tf\u00fcr\t\ndie\tZertifizierung\tdes\tEinsatzes\tim\tschulischen\tAlltag\tAnwendung\tfinden\t\nk\u00f6nnten\t(Heesen\tet\tal.\t2020).2256.3\t\t Einsatzm\u00f6glichkeiten\tdatenbasierter,\t\nKI-gest\u00fctzter\tLehr-\tund\tLernsysteme\nGrunds\u00e4tzlich er\u00f6ffnet die Entwicklung zunehmend leistungs-\nf\u00e4higer und kosteng\u00fcnstiger Ger\u00e4te, die mobil verwendet, ver -\nnetzt und mit potenziell vielf\u00e4ltigen Sensoren ausgestattet oder \nverkn\u00fcpft werden k\u00f6nnen, eine F\u00fclle an (neuen) Einsatzm\u00f6g-\nlichkeiten im Lernraum Schule. Sie decken ein Spektrum ab, \ndas von der Erfassung relevanter Daten und dem Erkennen von \nMustern \u00fcber deren Analyse zur Diagnostik von zum Beispiel \nWissensst\u00e4nden und Lernfortschritten bis hin zu didaktischen \nInterventionen reicht.221 Ausgangspunkt ist immer die Samm-\nlung und Auswertung vieler Daten der Lernenden und mitun-\nter auch der Lehrenden. Qualit\u00e4t und Umfang der verf\u00fcgbaren \nDaten haben einen zentralen Einfluss auf die Leistungsf\u00e4hig-\nkeit von KI-Systemen.222 F\u00fcr Lehr- und Lernsysteme bedeutet \ndas, dass die Genauigkeit von Prognosen \u00fcber den Lernverlauf \nmit der Menge der verf\u00fcgbaren Daten steigt.223 Jede intensive \n\u2013 und mitunter auch invasive \u2013 Datenerhebung f\u00fcr den Ein-\nsatz von KI-gest\u00fctzter Lehr- und Lernsoftware sollte je nach \nZweck und Ziel des Einsatzes beurteilt und auf ihr sachlich \nangemessenes und ethisch vertretbares Ma\u00df \u00fcberpr\u00fcft wer -\nden. Hier stellen sich Fragen nach dem sinnvollen Grad und \nAusma\u00df der Datenerhebung sowie deren w\u00fcnschenswerten \nVerwendungsweisen. Dabei geht es beispielsweise darum, wie \nDatenerfassung die Lernenden in ihrem individuellen Lern-\nprozess bestm\u00f6glich unterst\u00fctzt, ohne dass diese Daten zur \n\u00dcberwachung oder Stigmatisierung von einzelnen Lernenden \nmissbraucht werden k\u00f6nnen. Hier ist ein ethischer Umgang \n221\t Molenaar\t2021,\t62.\n222\tBitkom\t2017,\t66\u00a0ff.\n223\tMartini\tet\tal.\t2020,\t23.226mit Daten auch im schulischen Bereich gefordert, der gr\u00f6\u00dft-\nm\u00f6gliche Datensouver\u00e4nit\u00e4t auch f\u00fcr Sch\u00fclerinnen und Sch\u00fc-\nler erm\u00f6glicht.224\nAuf Grundlage der erhobenen Daten k\u00f6nnen individuali-\nsierte R\u00fcckmeldungen \u00fcber Lehr- und Lernprozesse sowie ent-\nsprechende Reaktionen oder Empfehlungen des Softwaresys-\ntems erfolgen, die in der Folge die Grundlage f\u00fcr didaktische \nwie auch p\u00e4dagogische Interventionen und auch Innovation \nbilden k\u00f6nnen. Dabei kommen zunehmend Elemente maschi-\nnellen Lernens zum Einsatz, bei denen die fortlaufende Ana-\nlyse der Eingabedaten daf\u00fcr genutzt wird, die diagnostischen \nund gegebenenfalls pr\u00e4diktiven Ausgaben des Softwaresys-\ntems wie auch seine Empfehlungen dynamisch anzupassen. \nSo k\u00f6nnen die Systeme durch Auswertung von beispielsweise \nLerngeschwindigkeit, typischen Fehlern, St\u00e4rken und Schw\u00e4-\nchen das Lernprofil der Lernenden erkennen und die Lernin-\nhalte entsprechend anpassen.225 Die subjektiven Eindr\u00fccke der \nLehrkr\u00e4fte zu Lernfortschritt und Aufmerksamkeitsspanne \nindividueller Lernender k\u00f6nnen dadurch datenbasiert unter -\nmauert, aber auch korrigiert werden.\nDer Einsatz dieser Systeme kann dabei je nach Ziel, Ge-\nstaltung und technischen Grundlagen sehr unterschied-\nlich ausfallen. Er reicht beispielsweise von Programmen f\u00fcr \n224\tUm\tden\tDatenumgang\tverantwortlich\tzu\tgestalten,\tsind\tGrundkenntnisse\t\n\u00fcber\tdie\tBedeutung\tund\tden\tWert\tvon\tBig\tData\tund\tdie\tdamit\tverbunde-\nnen\tRisiken\tvorausgesetzt.\tDas\thei\u00dft,\tder\tkritische\tUmgang\tmit\tDaten\ter -\nfordert\tDatensouver\u00e4nit\u00e4t.\tDies\that\tder\tDeutsche\tEthikrat\tbereits\tin\tseiner\t\nStellungnahme\tzu\tBig\tData\tvon\t2017\t(271\u00a0f.)\tfestgehalten:\t\u201eDa\tbereits\tKin-\nder\tdigitale\tAnwendungen\tnutzen\tund\tdabei\tDaten\tgenerieren,\tsollte\teine\t\nentsprechende\tNutzerkompetenz\tschon\tin\tder\tSchule\tvermittelt\twerden.\t\n\u00dcber\tdie\trein\ttechnischen\tAspekte\tder\tg\u00e4ngigen\tDigitalisierungsstrategien\t\nschulischen\tUnterrichts\thinaus\tsollte\tdies\tals\tQuerschnittsaufgabe\tf\u00fcr\talle\t\nF\u00e4cher\tdes\tschulischen\tCurriculums\tausgestaltet\tsein,\tum\tder\tgerade\tbei\t\nKindern\tund\tJugendlichen\tvirulenten\tinformationellen\tSelbstgef\u00e4hrdung\t\nentgegenzuwirken\tund\tschon\tfr\u00fch\tein\tBewusstsein\tf\u00fcr\tdie\trechtlichen,\t\nsozialen\tund\tethischen\tImplikationen\tzu\tschaffen.\tDie\tVermittlung\tsolcher\t\nNutzerkompetenz\tsollte\tdaher\tzuk\u00fcnftig\tTeil\tder\tLehreraus-\tund\t-fortbil-\ndung\twerden.\u201c\n225\thttps://www.zeit.de/digital/internet/2016-03/babbel-sprachkurs-start-up-\nberlin\t[11.01.2023].227personalisiertes Lernen auf individuellen Endger\u00e4ten, die den \nLernenden Wissen vermitteln oder bestimmte F\u00e4higkeiten \ntrainieren (adaptive Lernprogramme), \u00fcber die Erfassung und \nR\u00fcckmeldung bestimmter Fortschritte, Schw\u00e4chen und St\u00e4r -\nken der Lernenden an Lehrkr\u00e4fte, um individuelle F\u00f6rderung \nzu erleichtern (Lernstandkontrolle), bis hin zur \u00dcberwachung \nder Aufmerksamkeit oder gar der Emotionen der Lernenden \nund Lehrenden durch Sensoren und Kameras. Hinzu kommen \nAnwendungen aus dem Bereich der Robotik, Virtual Reality \noder Augmented Reality. Zu manchen Entwicklungen in die-\nsen Bereichen gibt es erhebliche Kontroversen (vgl. Abschnitt \n6.4).\nH\u00e4ufig enthalten Lernprogramme spielerische Elemente \n(sogenannte Gamification), um die Motivation zur Nutzung \nund damit zum Lernen zu steigern.226 Durch Nudging sol-\nlen die Lernenden angeregt werden, das Richtige zu tun, das \nhei\u00dft das gew\u00fcnschte Lernverhalten auszu\u00fcben. Die Frage \nnach dem richtigen Lernen hat bereits Anlass zu Diskussionen \ndahingehend gegeben, ob Kinder und Jugendliche dadurch \nm\u00f6glicherweise in ein \u201ebehavioristisches Dressursetting\u201c hin-\neingezogen werden.227 Auch stellt sich die Frage, wer festlegt, \nwas als richtig gelten darf. Im hier verwendeten Menschen- wie \nBildungsbegriff ist bereits angelegt, an dieser Stelle kritisch ge-\ngen\u00fcber einem hohen Ma\u00df an Gamification und Nudging im \nBildungsprozess zu sein. Auch hier sollte die Zielrichtung jed-\nweden Einsatzes in der Erweiterung menschlicher Handlungs-\nm\u00f6glichkeiten und Autorschaft liegen.\nAuch wenn soziale Lernprozesse nicht durch KI ersetzt \nwerden, werden soziale Beziehungen in Lernkontexten zuneh-\nmend durch KI vermittelt, beispielsweise durch die Messung \nvon Leistung oder aber auch von Aufmerksamkeit oder Emo-\ntionen, deren Ergebnisse dann an Lehrkr\u00e4fte und Lernende \nzur\u00fcckgespiegelt wird. So k\u00f6nnen einerseits Informationen \n226\tRachels/Rockinson-Szapkiw\t2018.\n227\tHartong\t2019,\t12.228\u00fcber die Gruppe, zum Beispiel eine Schulklasse, ausgewertet \nwerden, um daraus Hinweise auf die Lerngeschwindigkeit und \ninhaltlichen Schw\u00e4chen abzuleiten, mittels derer die Lehrkr\u00e4f-\nte ihre kurz-, mittel- und langfristigen Strategien besser an \ndie jeweilige Gruppe anpassen k\u00f6nnen. Auf der individuellen \nEbene k\u00f6nnen KI-gest\u00fctzte Systeme dazu beitragen, individu-\nelle Schw\u00e4chen oder R\u00fcckst\u00e4nde zu identifizieren oder gar die \nGefahr des Schulabbruchs fr\u00fchzeitig anhand von Mustern zu \nerkennen und gezielte Unterst\u00fctzungsangebote zu unterbrei-\nten. Auf die Risiken solcher Ans\u00e4tze wird im Folgenden noch \neingegangen.\n6.4\t Mensch-Maschine-Relationen\tin\t\nder\tschulischen\tBildung:\tErweitern,\t\nVermindern,\tErsetzen\n\u00c4hnlich wie im Medizinbereich muss auch im Bildungsprozess \nvon unterschiedlichen Beziehungen ausgegangen werden, die \ndurch den KI-Einsatz betroffen sind: Interaktionen zwischen \nLehrenden und Lernenden wie auch der Lernenden unterei-\nnander im Klassenraum, im weiteren Sozialraum Schule, aber \nauch dar\u00fcber hinaus. Hinzu kommen mitunter spezifische \nUntergruppen wie Lernende mit besonderen Bed\u00fcrfnissen \nund gegebenenfalls weitere Beteiligte wie zus\u00e4tzliches (sozi-\nal-)p\u00e4dagogisches Personal, Eltern, Personen in der Schulver -\nwaltung sowie jene, die an der Entwicklung und Planung von \nCurricula und dem Einsatz digitaler Techniken beteiligt sind. \nParallelen zum Handlungsfeld Medizin lassen sich auch inso-\nfern feststellen, als es in der Schulbildung ebenfalls zu engen, \nmittleren und weitgehenden Ersetzungen bestimmter Hand-\nlungssegmente und Interaktionen kommen kann, die sich je-\nweils situationsabh\u00e4ngig erweiternd oder vermindernd auf die \nHandlungsm\u00f6glichkeiten der Beteiligten auswirken k\u00f6nnen.\nIm Folgenden werden exemplarisch einige KI-basierte Lehr- \nund Lernsysteme f\u00fcr den schulischen Kontext dargestellt. Die 229genannten M\u00f6glichkeiten durch KI im System Schule sollten \nvor dem Hintergrund des zuvor dargelegten Menschenbildes \nund Bildungsbegriffs bewertet werden. Hier gilt insbesondere, \ndass die f\u00fcr Bildungsprozesse und Pers\u00f6nlichkeitsentwicklung \ngrundlegenden Aspekte der direkten Ansprache sowie der per -\nsonalen Beziehungen nicht vernachl\u00e4ssigt werden d\u00fcrfen. Mit \nBlick auf sehr weitreichende Ersetzungen ist dabei auch auf die \nsich stellende Gefahr des Animismus, das hei\u00dft der Zuschrei-\nbung mentaler Eigenschaften an Maschinen zu verweisen, die \nbei sich noch entwickelnden Kindern und Jugendlichen umso \nschwerer wiegt. Engere und gegebenenfalls mittlere Ersetzun-\ngen k\u00f6nnen aber durchaus mit den normativen Weichenstel-\nlungen vereinbar sein und den Bildungsprozess unterst\u00fctzen.\nEine enge Ersetzung liegt etwa vor, wenn ein Softwaresys-\ntem f\u00fcr einen genau bestimmten Lernabschnitt wie das Voka-\nbellernen im Fremdsprachenunterricht oder das Formellernen \nin der Mathematik eingesetzt wird. Ein Beispiel f\u00fcr solch ein \neng umrissenes algorithmisches System, dass beim Erlernen \neiner ganz spezifischen Kompetenz zum schulischen Einsatz \nkommt, ist das intelligente Tutorsystem Subkraki228, mit des-\nsen Hilfe die Lernenden in der Grundschule das schriftliche \nSubtrahieren \u00fcben k\u00f6nnen. Das Programm stellt \u00dcbungsauf-\ngaben, erkennt, welche Art von Fehlern die Lernenden bei der \nL\u00f6sung der gestellten Aufgabe machen, und gibt dann konst-\nruktives Feedback, indem es beispielsweise spezifisch auf das \neinem beobachteten Fehler zugrundeliegende Verst\u00e4ndnis-\nproblem reagiert. Fehlerhafte L\u00f6sungen werden nicht einfach \nvom System korrigiert. Stattdessen werden die L\u00f6sungsschrit-\nte anhand einer \u00e4hnlichen Rechenaufgabe erl\u00e4utert und den \nLernenden damit die M\u00f6glichkeit gegeben, Fehler eigenst\u00e4n-\ndig zu korrigieren, daraus zu lernen und Selbstwirksamkeit zu \nentwickeln.\n228\tZeller/Schmid\t2017.\tF\u00fcr\teine\tDemo-Version\tvon\tSubkraki\tsiehe\thttps://\ncogsys.uni-bamberg.de/ITS\t[02.03.2023].230Aufwendigere und datenintensivere intelligente Tutor -\nsysteme (siehe Infokasten 4) k\u00f6nnen auch komplexere Lern-\ninhalte in verschiedenen F\u00e4chern im Zusammenwirken mit \nLernenden vermitteln und so breitere Teilaspekte des Unter -\nrichtsgeschehens ersetzen (mittlere Ersetzung) oder im Ein-\nzelfall die Funktion einer Lehrkraft vollst\u00e4ndig \u00fcbernehmen \n(vollst\u00e4ndige Ersetzung). Eine weitgehende Ersetzung kann \nnoch zugespitzt werden, wenn ein als Software realisiertes KI-\nSystem in bestimmten Situationen nicht nur als eigenst\u00e4ndige \nLehrkraft auftritt, sondern \u00fcber einen virtuellen Avatar oder \nin einem Roboter mit besonders personalen Eigenschaften wie \nMimik oder nat\u00fcrlicher Sprache in Erscheinung tritt.\nInfokasten\t4:\tIntelligente\tTutorsysteme\nSchon\tin\tden\t1970er-Jahren\t wurden\tintelligente\t Tutorsysteme\t (ITS)\tzur\tUn-\nterst\u00fctzung\t individueller\t Lernprozesse\t entwickelt.\t Aktuelle\t Fortschritte\t bei\t\ndatengetriebenen,\t KI-gest\u00fctzten\t Ans\u00e4tzen\t haben\tdie\tM\u00f6glichkeiten\t solcher\t\nSoftwaresysteme\t deutlich\t erweitert.\t Ziel\tvon\tITS\tist\tes,\tInhalte\tauf\teine\tArt\t\nund\tWeise\tzu\tvermitteln,\tdie\tsich\tdynamisch\tan\tdie\tindividuellen\tBesonder -\nheiten\tund\tBed\u00fcrfnisse\tder\tLernenden\tanpasst.\nITS\tbestehen\t typischerweise\t aus\tvier\tKomponenten229:\tSein\tKern\tist\t(1)\tein\t\nWissensmodell,\t das\ts\u00e4mtliche\t Konzepte,\t Regeln\tund\tProbleml\u00f6sungsstrate-\ngien\tf\u00fcr\tdas\tzu\tvermittelnde\t Wissen\tumfasst.\t Aufgabenstellungen\t k\u00f6nnen\t\nvom\tWissensmodell\t eigenst\u00e4ndig\t gel\u00f6st\twerden.\t Es\tentspricht\t also\teinem\t\nExpertensystem\t f\u00fcr\tden\tzu\tvermittelnden\t Wissensbereich\t \u2013\tsei\tes\tanalyti-\nsche\tGeometrie,\t Hebelgesetze\t oder\tdie\tEntstehung\t von\tRegen.\tDas\tCompu-\nterprogramm\t gleicht\tdieses\tWissensmodell\t fortlaufend\t mit\tden\tverf\u00fcgbaren\t\nDaten\tder\tLernenden\t ab,\tdie\tes\tin\t(2)\teinem\tStudierendenmodell\t zusam-\nmenfasst.\t Dabei\tanalysiert\t das\tSystem,\twie\tLernende\t sich\tzum\tWissensmo-\ndell\tverhalten\t \u2013\twelche\tFortschritte\t oder\tFehler\tsie\tbeispielsweise\t machen\t\n\u2013\tund\taktualisiert\t das\tStudierendenmodell\t immer\twieder\tentsprechend.\t Im\t\neinfachsten\t Fall\tist\tdies\tein\tFortschrittsprofil.\t Es\tk\u00f6nnen\taber\tauch\tkomplexe\t\nintelligente\t Methoden\t zum\tEinsatz\tkommen,\t die\tdie\tIdentifikation\t von\tFehl-\nkonzepten\t erm\u00f6glichen.\t In\t(3)\tder\tDidaktikkomponente\t w\u00e4hlt\tdas\tSystem\t\nauf\tGrundlage\t dieses\tAbgleichs\t bestimmte\t R\u00fcckmeldungen\t an\tdie\tLernen-\nden\t(sowie\tgegebenenfalls\t auch\tan\tLehrkr\u00e4fte)\t aus,\tetwa\tEinsch\u00e4tzungen\t\nzum\tFortschritt,\t Hinweise\t auf\tFehler\tund\tHilfestellungen\t zu\tihrer\t\u00dcberwin-\ndung\toder\teine\tAuswahl\t weiterf\u00fchrender\t Schritte\t oder\tAufgaben.\t An\t(4)\t\nder\tInteraktionsschnittstelle\t schlie\u00dflich\t findet\tder\tAustausch\t zwischen\t dem\t\nTutorsystem\t und\tden\tLernenden\t statt,\tbeispielsweise\t in\tForm\tvon\tTextein-\ngaben\tund\t-ausgaben.\n229\tNkambou/Bourdeau/Mizoguchi\t2010,\t3\u00a0ff.231W\u00e4hrend\t in\tfr\u00fchen\tITS\ts\u00e4mtliche\t m\u00f6glichen\t Bez\u00fcge\tzwischen\t dem\tWissens-\t\nund\tdem\tStudierendenmodell\t ebenso\twie\talle\tAusgabem\u00f6glichkeiten\t vorab\t\nbestimmt\t und\tprogrammiert\t werden\tmussten,\t zum\tBeispiel\t in\tForm\tvon\t\nEntscheidungsb\u00e4umen,\t erlauben\t moderne\t datenintensive\t und\tKI-gest\u00fctzte\t\nAns\u00e4tze\t flexiblere\t und\tdifferenziertere\t Funktionen.\t Je\tnach\tMenge\tund\tViel-\nfalt\tder\tDaten,\tdie\tLernende\tin\tdas\tSystem\teinspeisen,\tk\u00f6nnen\tder\tindividu-\nelle\tWissensstand\t sowie\tFortschritte\t und\tgegebenenfalls\t auch\tPr\u00e4ferenzen\t\nbeim\tLernen\tgenauer\t analysiert\t werden.\t Dadurch\t kann\tdas\tProgramm\t pr\u00e4zi-\nsere\tVorhersagen\t f\u00fcr\tden\tweiteren\t Lernprozess\t treffen\tund\tseine\tAusgaben\t\nentsprechend\tindividualisieren.\nMit\tihren\tvier\tKomponenten\t bilden\tITS\teinige\tKernfunktionen\t nach,\tdie\t\nsonst\tvon\tmenschlichen\t Lehrkr\u00e4ften\t \u00fcbernommen\t werden:\t (1)\tdie\tBereit-\nhaltung\t von\tFachwissen,\t (2)\tdie\tEinsch\u00e4tzung\t des\tLernstands\t und\tF\u00f6rder-\nbedarfs\t von\tLernenden,\t (3)\teine\tdaran\tangepasste\t Selektion\t didaktischer\t\nStrategien\t und\t(4)\tdie\tInteraktion\t mit\tden\tLernenden.\t ITS\tk\u00f6nnen\tdaher\tmit\t\ndem\tAnspruch\t eingesetzt\t werden,\t die\tFunktion\t einer\tLehrkraft\t f\u00fcr\tden\tin-\nhaltlich\tabgedeckten\t Bereich\tganz\toder\tteilweise\t zu\tersetzen.\t Genauso\t ist\t\njedoch\tein\tEinsatz\tin\thybriden\t Formaten\t und/oder\t mit\tSchwerpunkten\t bei\t\nder\tUnterst\u00fctzung\tder\tLehrkraft\tm\u00f6glich.\nAls\tBeispiel\t f\u00fcr\tein\tSystem\tmit\tweitreichendem\t Ersetzungspotenzial\t kann\t\nAutoTutor\t genannt\t werden.\t Es\twurde\tvon\tArthur\tGraesser\t am\tInstitute\t for\t\nIntelligent\t Systems\t der\tUniversity\t of\tMemphis\t entwickelt.\t Das\tProgramm\t\nsimuliert\t eine\tmenschliche\t Lehrkraft,\t indem\tes\tmit\tden\tLernenden\t ein\tna-\nt\u00fcrliches\t Gespr\u00e4ch\t f\u00fchrt.230\tDabei\terfolgt\teine\tAnpassung\t an\tdie\tLernenden,\t\nindem\tihre\tEmotionen\t und\tReaktionen\t (z.\u00a0B.\tDialogmuster,\t Mimik,\tK\u00f6rper-\nhaltung)\t erfasst\twerden.\t Bisher\tmit\tdieser\tMethode\t unterst\u00fctzte\t Inhalte\taus\t\ndem\tschulischen\t und\tau\u00dferschulischen\t Bereich\t stammen\t dabei\tunter\tan-\nderem\taus\tder\tInformatik,\t Physik,\tMathematik,\t Elektronik,\t Philosophie\t und\t\nBiologie.\t AutoTutor\t bietet\tdar\u00fcber\thinaus\tdie\tM\u00f6glichkeit,\t jeweils\tdie\t\u00dcber-\t\nund\tUnterforderung\t der\tLernenden\t zu\tregistrieren\t und\tdarauf\tzu\treagieren.\t\nAuf\tdiese\tWeise\teingesetzt,\t k\u00f6nnen\tITS\tdazu\tbeitragen,\t positive\t Lernumge-\nbungen\tzu\tschaffen.\t ITS\tbieten\tdie\tM\u00f6glichkeit,\t Lerninhalte\t von\tMathematik\t\nbis\tFremdsprachenerwerb\t in\tspezifischen\t Aufgabenkontexten\t zu\t\u00fcben\tund\t\ndabei\tunmittelbares\t und\tindividualisiertes\t Feedback\t zu\terhalten.\t Somit\tsind\t\nsie\tgeeignet,\t den\tUnterricht\t mit\teiner\tLehrkraft\t im\tKlassenverband\t gezielt\t\num\tPhasen\tdes\tindividualisierten\t Lernens\t zu\terg\u00e4nzen.\t Kompetenzen\t wer-\nden\tkonstruktiv\t (Learning\t by\tDoing)\terworben\t und\terg\u00e4nzen\t das\tlearning by \nbeing told\tdes\t\u00fcblichen\tUnterrichts.\nIntelligente Tutorsysteme und verwandte daten- und KI-ge-\nst\u00fctzte adaptive Lerntechnologien werden zunehmend we-\nniger mit dem Ziel entwickelt, eine menschliche Lehrkraft \nm\u00f6glichst weitgehend zu ersetzen, sondern immer st\u00e4rker f\u00fcr \nden Einsatz in hybriden Lehr- und Lernsystemen konzipiert.231 \n230\tGraesser\tet\tal.\t2012.\n231\t Molenaar\t2021.232Solche Systeme werden in zahlreichen L\u00e4ndern bereits mit gut \ndokumentierten Beitr\u00e4gen zur Verbesserung von Lernerfolgen \nbei unterschiedlichen Altersgruppen eingesetzt. Das 2012 aus \neiner Elterninitiative in den Niederlanden hervorgegangene \nAngebot Snappet beispielsweise wird inzwischen in mehre-\nren L\u00e4ndern, darunter auch Deutschland, zur Unterst\u00fctzung \ndes Unterrichts in der Grundschule verwendet. Die Software \nwird von Lernenden im Pr\u00e4senz-, Distanz- oder Wechselun-\nterricht zur Bearbeitung von Aufgaben eingesetzt, die auf die \nLehrpl\u00e4ne und den individuellen Lernfortschritt in allen F\u00e4-\nchern zugeschnitten sind. Sie spielt die Auswertung der dabei \ngesammelten Daten an die Lehrkr\u00e4fte zur\u00fcck, um diese bei der \nweiteren Unterrichtsplanung und differenzierten F\u00f6rderung \nder Kinder zu unterst\u00fctzen. In einer Studie an 79 Grundschu-\nlen konnten mit dem Einsatz von Snappet nach f\u00fcnf Monaten \nunter anderem in einer standardisierten Pr\u00fcfung verbesserte \nErgebnisse und eine h\u00f6here intrinsische Motivation der Ler -\nnenden nachgewiesen werden.232\nAuch eine weiter reichende Nutzung von Technik zur er -\nfolgreichen Teilhabe am Schulunterricht kann im Einzelfall \nsinnvoll sein. Dies kann mit einem Szenario veranschaulicht \nwerden, in dem ein Telepr\u00e4senzroboter Lernenden, die nur \nvon zu Hause am Unterricht teilnehmen k\u00f6nnen, mehr Inter -\naktion mit der Lerngruppe erm\u00f6glicht (siehe Infokasten 5).\nInfokasten\t5:\tTeilnahme\tam\tUnterricht\tmittels\teines\t\nTelepr\u00e4senzroboters\nMittels\teines\tTelepr\u00e4senzroboters\t (z.\u00a0B.\tAV1\tAvatar\tdes\tnorwegischen\t Start-\nups\tNo\tIsolation)\t k\u00f6nnen\tLernende\t im\tFalle\tl\u00e4ngerer\t Abwesenheiten,\t bei-\nspielsweise\t aufgrund\t von\tKrankheit,\t ihre\tKlasse\tvirtuell\tbesuchen.\t Der\tRo-\nboter\t\u00fcbernimmt\t den\tPlatz\tdes\tLernenden\t in\tder\tKlasse,\tausgestattet\t mit\tIn-\nternetverbindung,\t Kamera,\t Lautsprecher,\t Mikrofon.\t Die\tLernenden\t k\u00f6nnen\t\ndamit\tim\tKlassenzimmer\t in\tEchtzeit\t h\u00f6ren,\tsehen\tund\tsprechen\t (via\tApp\tam\t\nSmartphone\t oder\tTablet\tvon\tzu\tHause\taus,\tohne\tDatenspeicherung).\t Die\t\nFunktionen\t des\tRoboters\t umfassen\t das\tHerumblicken\t im\tKlassenzimmer,\t\n232\tFaber/Luyten/Visscher\t2017.233das\tHandheben\t und\tSprechen\t oder\tauch\tMimik,\tum\tzum\tBeispiel\t Unver-\nst\u00e4ndnis\tauszudr\u00fccken.233\nSoziale\tIsolation\t zum\tBeispiel\t infolge\teiner\tchronischen\t Erkrankung\t kann\t\ndurch\tdiesen\tTelepr\u00e4senzroboter\t abgemildert,\t eine\tWiedereingliederung\t\nunterst\u00fctzt\t beziehungsweise\t der\tPlatz\tim\tKlassenzimmer\t symbolisch\t vom\t\nTelepr\u00e4senzroboter\t besetzt\tgehalten\t werden.\t Der\tTelepr\u00e4senzroboter\t un-\nterst\u00fctzt\t so\tnicht\tnur\tkognitive,\t sondern\t in\tbeschr\u00e4nktem\t Ausma\u00df\t auch\t\nemotionale\t und\tsoziale\tFunktionen,\t indem\ter\tbeispielsweise\t das\tTuscheln\t\nmit\tanderen\t Kindern\t aus\tder\tKlasse\term\u00f6glicht.\t Es\tgeht\talso\tnicht\tnur\tda-\nrum,\tim\tLernpensum\t nicht\tzur\u00fcckzubleiben,\t sondern\t auch\tdarum,\tweiter-\nhin\tals\tTeil\tder\tKlassengemeinschaft\t wahrgenommen\t zu\twerden.\t W\u00e4hrend\t\nder\tAV1-Roboter\t menschen\u00e4hnliche\t Z\u00fcge\taufweist,\t wird\thierauf\tin\tanderen\t\nProjekten\t explizit\t verzichtet,\t um\tanthropomorphen\t Fehlverst\u00e4ndnissen\t\nvorzubeugen.\nNeben den zuvor beschriebenen M\u00f6glichkeiten f\u00fcr den Ein-\nsatz datenbasierter, KI-gest\u00fctzter Technologien in der perso-\nnalisierten Gestaltung und Auswertung konkreter Lerninhalte \nund -prozesse gibt es mittlerweile auch Bestrebungen, KI zur \nAnalyse des Verhaltens im Klassenraum oder ganzer Einrich-\ntungen einzusetzen. Wie umfassend dies geschehen kann, zei-\ngen Beispiele aus China (siehe Infokasten 6).\nInfokasten\t6:\tBesonders\tweitreichender\tEinsatz\tdigitaler\tTechnologien\t\nim\tSchulunterricht\nTeilweise\t kann\tein\tbesonders\t weitreichender\t Einsatz\tvon\tdatenintensiven\t\nund\tKI-gest\u00fctzten\t Tools\tim\tSchulunterricht\t beobachtet\t werden,\t der\t\u00fcber\t\ndie\tVerwendung\t einer\tgeschlossenen\t Lehr-\tund\tLernsoftware\t hinausgeht.234 \nSo\twerden\tbeispielsweise\t an\tmanchen\t chinesischen\t Schulen\t mithilfe\t zahl-\nreicher\tund\tvielf\u00e4ltiger\t Sensoren\t umfangreiche\t Daten\tauf\tdem\tCampus\t ge-\nsammelt.\t Dies\tgeschieht\t einerseits,\t um\tdie\tRessourcen\t auf\tdem\tGel\u00e4nde\t\nzu\tverwalten.\t Dazu\tgeh\u00f6ren\t unter\tanderem\t die\tSicherheitseinrichtungen,\t\ndie\tBeleuchtung,\t die\tRegelung\t der\tWasser-\t und\tLuftqualit\u00e4t,\t aber\tauch\tdas\t\nSammeln\t von\tBewegungsdaten.\t Im\tKlassenzimmer\t erfolgt\teine\t\u00e4hnlich\t\numfassende\t Datensammlung,\t beispielsweise\t \u00fcber\tKameras\t und\tMikrofone\t\nund\tteilweise\t erg\u00e4nzt\tum\tindividuelle,\t von\tden\tLernenden\t getragene\t Ger\u00e4te\t\n(Wearables),\t um\tein\tm\u00f6glichst\t umfassendes\t Bild\teines\tjeden\tIndividuums\t\nzu\terstellen.\t Es\twerden\tK\u00f6rperdaten\t (z.\u00a0B.\tHerzfrequenz,\t K\u00f6rpertemperatur)\t\nermittelt,\t aber\tauch\tDaten\tzum\tSozialverhalten,\t zur\temotionalen\t und\tpsy-\nchischen\t Gesundheit\t anhand\tvon\tAnalysen\t der\tMimik,\tK\u00f6rperhaltung\t und\t\n233\t Belpaeme/Tanaka\t2021,\t148.\n234\tVincent-Lancrin\t2021,\t24\u00a0f.234Sprache\t sowie\tnat\u00fcrlich\t zu\tschulischen\t Leistungen.\t Genannte\t Ziele\tdieser\t\nMa\u00dfnahmen\t umfassen\t die\tSicherstellung\t der\tAufmerksamkeit\t der\tSch\u00fc-\nlerinnen\t und\tSch\u00fcler,\t die\tindividuelle\t F\u00f6rderung\t der\tLernenden\t sowie\tdie\t\nUnterst\u00fctzung\t der\tLehrkr\u00e4fte,\t beispielsweise\t bei\tAufgaben\t wie\tder\tUnter-\nrichtsvorbereitung,\t dem\tVergeben\t von\tHausaufgaben\t und\tder\tAuswertung\t\nvon\tLernprozessen.\nEin Schwerpunkt solcher Ans\u00e4tze wird mit der Bezeichnung \n\u201eClassroom Analytics\u201c beschrieben. Damit sind Konzepte ge-\nmeint, welche die Dynamik ganzer Lerngruppen umfassend \nzu dokumentieren und auszuwerten versuchen, unter Ber\u00fcck-\nsichtigung des Verhaltens und der Interaktion der Lernenden \nund Lehrkr\u00e4fte im Klassenraum235, einschlie\u00dflich der r\u00e4um-\nlichen Gegebenheiten und Prozesse vor Ort236. Classroom-\nAnalytics-Ans\u00e4tze sind aufgrund der f\u00fcr sie notwendigen Er -\nfassung vielf\u00e4ltiger Daten unter anderem \u00fcber das Verhalten \nvon Sch\u00fclerinnen und Sch\u00fclern sowie Lehrkr\u00e4ften umstritten \n(siehe unten). Bef\u00fcrworter solcher Ans\u00e4tze verweisen auf die \nChancen, die sich durch Classroom Analytics hinsichtlich ei-\nner Verbesserung von P\u00e4dagogik und Didaktik ergeben k\u00f6n-\nnen. Beispielsweise k\u00f6nne Classroom Analytics die Kapazit\u00e4t \nvon Lehrkr\u00e4ften steigern, alle Lernenden gleichzeitig im Blick \nzu haben und sie so im gesamten Management ihrer Lehrkon-\nzeption zu unterst\u00fctzen, etwa bei der Bildung von Lerngrup-\npen oder bei der Frage, wann in die Lernprozesse der Sch\u00fcle-\nrinnen und Sch\u00fcler eingegriffen werden soll.\nMittels Classroom Analytics k\u00f6nnen der Lehrkraft Infor -\nmationen an die Hand gegeben werden, die auch zur kriti-\nschen Selbstreflexion des Lehrverhaltens genutzt werden k\u00f6n-\nnen. F\u00fcr computergest\u00fctzte Analysen ist beispielsweise das \nVerhalten des lehrenden Fachpersonals schwierig zu erfassen, \nwenn nur die verbale Kommunikation zugrunde gelegt wird. \nIndem jedoch mittels Classroom Analytics auch das Verhalten \nim Klassenraum beobachtet wird, zu dem auch die H\u00e4ufigkeit \n235\t Dillenbourg\t2021.\n236\tMartinez-Maldonado\tet\tal.\t2022.235der pers\u00f6nlichen Kontakte mit den Sch\u00fclerinnen und Sch\u00fc-\nlern geh\u00f6rt, kommen zus\u00e4tzliche Parameter ins Spiel, die p\u00e4-\ndagogische Ans\u00e4tze und Lehrstrategien messbarer werden las-\nsen. Damit kann den Lehrkr\u00e4ften in konstruktiver Weise ein \nFeedback gegeben werden. Ein solches Instrument ist etwa das \nTeachActive-Dashboard. Es kann die p\u00e4dagogischen Bem\u00fc-\nhungen durch visuelle Unterst\u00fctzung verbessern. Den Lehr -\nkr\u00e4ften wird mit den Analysen gespiegelt, ob und wie ihre p\u00e4-\ndagogischen Praktiken zum aktiven Lernerfolg der Lernenden \nbeitragen.237 Classroom Analytics er\u00f6ffnen Lehrkr\u00e4ften zudem \nChancen auf eine objektivere Wahrnehmung der Lernenden \nund k\u00f6nnen es erm\u00f6glichen, implizite Vorurteile der Lehr -\nkr\u00e4fte gegen\u00fcber Lernenden, etwa zu Herkunft und Gender, \naufzudecken.238 Wenn solches Feedback den Lehrkr\u00e4ften zu-\nr\u00fcckgespiegelt wird, kann dies als kritisches Korrektiv f\u00fcr das \neigene Handeln dienen.\nIn diesem Zusammenhang sind unterschiedliche ethische \nFragen relevant. Da im Rahmen von Classroom Analytics mit-\nunter besonders umfangreiche Daten erfasst und ausgewertet \nwerden, sind zum einen negative Auswirkungen solcher Mes-\nsungen auf die Privatsph\u00e4re und Autonomie aller Beteiligten \nzu diskutieren. Neben den direkten Auswirkungen der Daten-\nerfassung und Prognostik auf die Privatsph\u00e4re und Autonomie \nder Beobachteten ist hier insbesondere auch auf sogenannte \nChilling-Effekte hinzuweisen. Im Kontext von \u00dcberwachung \nbeschreiben Chilling-Effekte das Ph\u00e4nomen, dass bereits die \nSorge, bestimmte Daten \u00fcber Personen k\u00f6nnten erfasst und \nihr Verhalten analysiert werden, negative R\u00fcckwirkungen auf \nihr Befinden und Verhalten haben kann. Dies k\u00f6nnte eine \nVerminderung von Handlungsfreiheit, Motivation und an-\nderen f\u00fcr gute Bildung wichtigen Bedingungen mit sich brin-\ngen. Dar\u00fcber hinaus k\u00f6nnen Daten in unangemessener Weise \nzweck- und kontextentfremdet genutzt werden, wenn zum \n237\tAlzoubi\tet\tal.\t2021.\n238\tReinholz/Stone-Johnstone/Shah\t2020.236Beispiel Informationen \u00fcber mangelhafte Schulleistungen \noder Lehrkraftevaluierungen zu Strafen oder anderweitigen \nSanktionen f\u00fchren. Ein weiteres Problem stellen systematische \nVerzerrungen (Bias-Problematik) sowohl in der Datenanalyse \nals auch in der Interpretation von Daten und Prognosen dar, \nwelche zu ungerechten Urteilen \u00fcber die Leistung von Lernen-\nden oder Lehrenden f\u00fchren k\u00f6nnen.\nUm diesen Herausforderungen zu begegnen, bedarf es ei-\nnes verantwortlichen Umgangs mit Daten und Analysen, der \ndie Bed\u00fcrfnisse von Lernenden und Lehrenden stets im Blick \nhat. Diese Personengruppen sollten bereits w\u00e4hrend der Ent-\nwicklung digitaler Bildungsinstrumente mit einbezogen wer -\nden. Die ethische Angemessenheit von L\u00f6sungen h\u00e4ngt dabei \nauch immer von technischen und institutionellen Details ab: \nwelche Daten \u00fcber wen in welcher Granularit\u00e4t erfasst werden \n(z. B. individuell, gruppen- oder aufgabenbezogen) und wer in \nwelcher Granularit\u00e4t und f\u00fcr welche Zwecke Zugang zu den \nDaten, Analysen oder Prognosen erh\u00e4lt.\nEin besonders kontrovers diskutierter Aspekt von Class-\nroom Analytics betrifft in diesem Zusammenhang die m\u00f6g-\nliche Erfassung der Aufmerksamkeit (Attention Monitoring) \noder der emotionalen Verfasstheit (Affect Recognition) der \nim Klassenraum interagierenden Personen, insbesondere ba-\nsierend auf der Analyse von Audio- oder Videodaten. Die Be-\ndeutung von Emotionen f\u00fcr Lernprozesse wurde in den letzten \nJahrzehnten immer st\u00e4rker ber\u00fccksichtigt und entsprechend \nist es nicht verwunderlich, dass nicht nur die Messung von \nAufmerksamkeit, sondern auch von Emotionen in schulischen \nKontexten voranschreitet. Die Verf\u00fcgbarkeit von Sensoren wie \nKameras und Mikrofonen in Laptops und Tablets, aber auch \nderen Einbau in Schulr\u00e4umen scheinen die M\u00f6glichkeit der \nErfassung von Aufmerksamkeit und Emotionen nahezulegen, \num neben der Erfassung von Leistung zus\u00e4tzliche Einsichten \nin das Lerngeschehen zu gewinnen. Auch wenn dies durchaus \nmit dem Ziel einer Verbesserung von Lernergebnissen ver -\nbunden sein kann, so ist der Einsatz solcher Technologien in 237schulischen Kontexten aufgrund erkenntnistheoretischer und \nethischer Herausforderungen kritisch zu betrachten.\nDie erkenntnistheoretische Kritik insbesondere an Techno-\nlogien zur Affekterkennung bezieht sich hier vor allem auf das \nvorherrschende reduktionistische Modell menschlicher Emo-\ntionen, nach dem es sechs Grundemotionen gibt, die als uni-\nversell stabil gelten und die zuverl\u00e4ssig aus \u00e4u\u00dferem Verhalten \nwie insbesondere der Mimik erschlossen werden k\u00f6nnen. Der \nKritik an diesem Modell wird mittlerweile in der Forschung \ndurchaus Rechnung getragen, etwa mit der Erfassung situati-\nver Kontexte oder der Zusammenf\u00fchrung verschiedener Da-\ntentypen, beispielsweise visueller und verbaler Daten mit dem \nZiel, die Validit\u00e4t der Affektmessung zu erh\u00f6hen. Aber selbst \nwenn Emotionen in Zukunft zuverl\u00e4ssig durch KI-Systeme \nerfasst werden k\u00f6nnten, so sind dennoch ethische Bedenken \nhinsichtlich ihres Einsatzes in schulischen Kontexten zu be-\nr\u00fccksichtigen, da das hierf\u00fcr notwendige Monitoring von Ler -\nnenden und Lehrenden Auswirkungen auf deren Privatsph\u00e4re \nund Autonomie haben kann und Fragen der Gerechtigkeit \nber\u00fchrt.\nDie Bewertung des Einsatzes von Technologien zur Affekt- \nund Aufmerksamkeitserkennung in schulischen Kontexten \nh\u00e4ngt daher von der Beantwortung folgender Frage ab: K\u00f6n-\nnen und sollten Aufmerksamkeit und Emotionen genau, zu-\nverl\u00e4ssig und ohne systematische Verzerrung gemessen wer -\nden? Ob sie messbar sind, h\u00e4ngt von der wissenschaftlichen \nund technologischen Basis der eingesetzten Systeme ab.\nOb solche Instrumente eingesetzt werden sollen , h\u00e4ngt je-\ndoch von einer zus\u00e4tzlichen Bewertung des potenziellen Nut-\nzens und Schadens f\u00fcr alle Beteiligten ab. Erstens m\u00fcsste nach-\ngewiesen werden, dass das Monitoring von Aufmerksamkeit \nund Emotionen insbesondere den Sch\u00fclerinnen und Sch\u00fclern \nn\u00fctzt, zum Beispiel indem es ihre Lernprozesse oder Lern-\nergebnisse verbessert. Zweitens m\u00fcsste bewertet werden, ob \ndiese potenziellen Vorteile die potenziellen Nachteile \u00fcberwie-\ngen, wie etwa die negativen Auswirkungen der notwendigen 238Datenerfassung auf die Privatsph\u00e4re, Autonomie und Freiheit \nder Lernenden. Dazu geh\u00f6ren auch Fragen zu Chilling-Effek-\nten und den langfristigen Folgen des Messens und Spiegelns \ninsbesondere von Emotionen f\u00fcr Lernende und Lehrende. \nDrittens ist es nicht nur ein erkenntnistheoretisches, sondern \nauch ein ethisches Problem, wenn Technologien zur Auf-\nmerksamkeits- und Emotionserfassung ungenau oder verzerrt \narbeiten. Denn sobald ihr Einsatz zu weiteren Handlungen \nbeziehungsweise zur Bewertung der Leistung f\u00fchrt, werfen \nsolche Ungenauigkeiten und Verzerrungen auch Fragen der \nGerechtigkeit auf.\nDer Kontext von Schulen bringt zwei zus\u00e4tzliche Heraus-\nforderungen mit sich. Zum einen sind Schulkontexte durch \nHierarchien und asymmetrische Machtverh\u00e4ltnisse gekenn-\nzeichnet. Zum anderen sind Kinder beteiligt, die besonders \nvulnerabel sind, weshalb h\u00f6here Anforderungen an den m\u00f6g-\nlichen Nutzen solcher Technologien f\u00fcr die beteiligten Kinder \nzu stellen sind.\nAuch wenn ein Einsatz aktuell verf\u00fcgbarer Technologien \nim schulischen Kontext in Anbetracht der oben genannten \nKriterien nicht empfehlenswert erscheint, ist nicht prinzipiell \nauszuschlie\u00dfen, dass zuk\u00fcnftige Entwicklungen zu einer di-\ndaktisch sinnvollen Verbesserung des Lernprozesses beitragen.\nIn Anbetracht der erkenntnistheoretischen und ethischen \nHerausforderungen und unter Abw\u00e4gung potenzieller Nut-\nzen und Sch\u00e4den stehen die Mitglieder des Deutschen Ethi-\nkrates dem Einsatz von Audio- und Videomonitoring im \nKlassenzimmer insgesamt skeptisch gegen\u00fcber. Insbesondere \nerscheint die Analyse von Aufmerksamkeit und Emotionen \nper Audio- und Video\u00fcberwachung des Klassenraums mittels \naktuell verf\u00fcgbarer Technologien nicht vertretbar. Ein Teil \ndes Ethikrates schlie\u00dft den Einsatz von Technologien zur Auf-\nmerksamkeits- und Affekterkennung zuk\u00fcnftig jedoch nicht \nvollst\u00e4ndig aus, sofern sichergestellt ist, dass die erfassten \nDaten eine wissenschaftlich nachweisbare Verbesserung des \nLernprozesses bieten und das hierf\u00fcr notwendige Monitoring 239von Sch\u00fclerinnen und Sch\u00fclern sowie Lehrkr\u00e4ften keine inak-\nzeptablen Auswirkungen auf deren Privatsph\u00e4re und Autono-\nmie hat. Ein anderer Teil des Ethikrates hingegen bef\u00fcrwortet \nein Verbot von Technologien zu Aufmerksamkeitsmonitoring \nund Affekterkennung in Schulen.\n6.5\t\t Grunds\u00e4tzliche\tDiskussion:\tKI\tim\t\nschulischen\tBildungsprozess\nDie \u00f6ffentliche Debatte zu KI in der Bildung hat sich in den \nletzten Jahren intensiviert und wird haupts\u00e4chlich in den \nFach-Communitys und von Stakeholdern betrieben. So hat \nsich die Gewerkschaft Erziehung und Wissenschaft im Pro-\njekt \u201eBildung in der digitalen Welt\u201c mit dem Thema Learning \nAnalytics auseinandergesetzt.239 Auch im Abschlussbericht der \nEnquete-Kommission K\u00fcnstliche Intelligenz des Deutschen \nBundestages wird das Potenzial von Learning-Analytics-Sys-\ntemen hervorgehoben.240\nAufseiten der Chancen ist das personalisierte Lernen anzu-\nf\u00fchren, das im Sinne des hier skizzierten Feldes bedeutet, dass \ndurch personalisierte Abstimmung auf Einzelne Lernchancen \nerh\u00f6ht werden k\u00f6nnen. So k\u00f6nnen auf unterschiedliche Weise \nSt\u00e4rken wie Schw\u00e4chen des je einzelnen Lernenden wie auch \neiner Lerngruppe erkannt und auf existierende Schwierigkei-\nten beim Aufgabenl\u00f6sen eingegangen werden. Dies kann ei-\nnerseits Lernende unterst\u00fctzen, sowohl in Bezug auf individu-\nelle St\u00e4rken als auch besondere Bed\u00fcrfnisse, da sie fokussiert \nin ihren Bedarfen von einem nicht m\u00fcde oder ungeduldig \nwerdenden System begleitet werden. Mithilfe dieser Prozesse \nwerden auch Lehrkr\u00e4fte unterst\u00fctzt, die ihre Ressourcen dann \nsinnvoll im Gesamtlehrprozess einsetzen k\u00f6nnen. Als Beispiel \nsei das schon erw\u00e4hnte Subkraki angef\u00fchrt, das als eine Form \n239\tHartong\t2019.\n240\tDeutscher\tBundestag\t2020,\t306.240der engen Ersetzung der Lehrenden das Lehr- und Lernge-\nschehen punktuell unterst\u00fctzen kann und daher eine Entlas-\ntung der analogen Lehre f\u00fcr alle Beteiligten bietet. Eine weitere \nChance besteht darin, dass KI-gest\u00fctzte Lehr- und Lernsyste-\nme f\u00fcr bestimmte Bev\u00f6lkerungsgruppen die Zugangschancen \nzu Bildung verbessern k\u00f6nnen, selbst wenn sie nicht als Teil \ndes Unterrichtsprogramms von der Schule angeboten werden. \nAuch wenn derartige Programme, etwa zum Spracherwerb \noder zur Nachhilfe, meist nicht kostenfrei verf\u00fcgbar sind, lie-\ngen die Kosten in der Regel weit unterhalb der Kosten f\u00fcr pri-\nvate Nachhilfe oder Sprachkurse.\nSoweit mit dem Einsatz KI-gest\u00fctzter Lehr- und Lernsys-\nteme einzelne Lernende in den Fokus ger\u00fcckt werden, ist ihr \nEinsatz im Besonderen auch unter dem Gesichtspunkt der \nInklusion bedenkenswert. So k\u00f6nnen KI-basierte Lehr- und \nLernsysteme f\u00fcr Lernende mit besonderen Bed\u00fcrfnissen, de-\nren individuelle Lerngeschichten adaptiver begleitet werden \nm\u00fcssen, Chancen bieten.241 KI kann bei der Entwicklung so-\nzialer F\u00e4higkeiten von autistischen Kindern helfen, Lernende \nmit Dysgrafie diagnostizieren und unterst\u00fctzen sowie die Teil-\nhabe f\u00fcr blinde oder sehbehinderte Kinder durch Bereitstel-\nlung grafischen Materials f\u00f6rdern.\nEs bleibt deshalb grunds\u00e4tzlich festzuhalten: Die neuen \nSysteme k\u00f6nnen hilfreiche, auf das Individuum zugeschnittene \nEinzeltools darstellen, sind aber nicht die generelle L\u00f6sung f\u00fcr \nFragen von Inklusion, und sie m\u00fcssen unter Ber\u00fccksichtigung \nm\u00f6glichen Missbrauchs und m\u00f6glicher Risiken angewendet \nwerden. Um diese zu erkennen und im Blick zu behalten, ist \nes wichtig, das digitale Lehr- und Lerngeschehen permanent \nzu evaluieren.\nEine weitere Chance, die der Einsatz technischer Systeme \nf\u00fcr Inklusion mit sich bringt, liegt in der Flexibilit\u00e4t und ei-\nnem erweiterbaren Aktionsradius. Vor allem das Beispiel mit \ndem Telepr\u00e4senzroboter zeigt, wie Technik Inklusion erh\u00f6hen \n241\tGood\t2021.241kann, indem sie es beispielsweise chronisch kranken Lernen-\nden erm\u00f6glicht, sich von zu Hause aus am Unterrichtsgesche-\nhen zu beteiligen.\nDie Verwendung von Lehr- und Lerntechnologien ist also \nmit gro\u00dfen Chancen verbunden. Dazu geh\u00f6rt auch der berech-\ntigte Wunsch nach einer objektiveren und faireren Bewertung \nder Lernergebnisse. Da Software nicht die m\u00f6glichen Vorur -\nteile der Lehrkr\u00e4fte \u201ehegt\u201c, sei es bez\u00fcglich der Intelligenz der \nLernenden, seien es emotionale Vorbehalte, die eine Gleich-\nbehandlung tr\u00fcben k\u00f6nnen, steigt die Chance, dass Lernende \nmithilfe von KI-Anwendungen neutraler unterrichtet werden \nk\u00f6nnen. Allerdings darf auch hier eine solch vorgebliche Neu-\ntralit\u00e4t oder Objektivit\u00e4t nicht als gegeben angenommen wer -\nden, sondern bedarf der \u00dcberpr\u00fcfung. Ein besonderes Risiko \nbei datenbasierten KI-Systemen besteht n\u00e4mlich in systemati-\nschen Verzerrungen (Bias), woraus sich hohe Anforderungen \nan die Validit\u00e4t und Qualit\u00e4t der verwendeten Trainingsdaten \nund die Angemessenheit der verwendeten Methoden ergeben. \nAuch weitere allgemeine Risiken wie beispielsweise Fragen der \nSicherheit, Privatheit und Transparenz zeigen sich nat\u00fcrlich \nebenso beim Einsatz von KI in der Bildung.\nDar\u00fcber hinaus ergeben sich im Kontext der (schulischen) \nBildung weitere sektorspezifische Herausforderungen. Hier \nsind in besonderer Weise die sozialen Aspekte hervorzuhe-\nben, die beim Ersatz des Lehrpersonals eintreten k\u00f6nnen, \ninsbesondere Gefahren der Isolation und Vereinsamung von \nLernenden.\nAu\u00dferdem ist zu ber\u00fccksichtigen, dass bereits der Einsatz \ndigitaler Medien das qualitative Ergebnis des Lernprozes-\nses ver\u00e4ndern kann. So werden Texte, die \u00fcber elektronische \nMedien rezipiert werden, anders durchdrungen als Texte, die \nmittels analoger Medien (auf Papier) gelesen werden.242 Auch \nbeim Einsatz von KI muss in Betracht gezogen werden, dass \nsich Lernverhalten qualitativ ver\u00e4ndert. So k\u00f6nnten sich etwa \n242\tE-READ\t2019.242grunds\u00e4tzliche Auswirkungen auf die Motivation und F\u00e4hig-\nkeit von Sch\u00fclerinnen und Sch\u00fclern, komplexere Aufgaben \nzu l\u00f6sen, ergeben. Wenn KI vor allem auf die L\u00f6sung kleiner, \n\u00fcberschaubarer Aufgaben und schnelle Erfolgserlebnisse aus-\ngerichtet ist, k\u00f6nnte langfristig die Bereitschaft vermindert \nwerden, komplexere Probleme anzugehen, deren L\u00f6sung in \nder Regel nicht innerhalb kurzer Zeit gefunden werden kann.\nDie Erforschung der Auswirkungen des Einsatzes digitaler \nMedien wie auch KI-basierter Methoden muss daher vielf\u00e4lti-\nge, auch indirekte Dimensionen erfassen und darf sich nicht \nnur an wenigen offensichtlichen Markern schulischen Erfolgs \n(wie etwa den Schulnoten oder dem Abfragen von Fakten) ori-\nentieren. Sind diese Aspekte jedoch erst einmal hinreichend \nverstanden, so bieten sich gerade Methoden der KI an, um spe-\nzifische Defizite eines st\u00e4rker digitalisierten Lernens zu kom-\npensieren und etwa die individuelle Kompetenz zum L\u00f6sen \nkomplexerer Aufgaben zu f\u00f6rdern.\nAuch die Messung von Aufmerksamkeit und Emotionen \nkann ein Mittel sein, Lernprozesse und Lernerfolge besser zu \nverstehen. Allerdings sind Technologien der Aufmerksam-\nkeits- und Emotionserkennung beispielsweise durch Kameras \noder andere Instrumente wissenschaftlich umstritten243 und \ngreifen in invasiver Weise in die Autonomie und Privatheit der \nLernenden ein. Eine solche invasive Form der Datenerfassung \nist mit dem hier leitenden Bildungsbegriff, der sich am freien \nund urteilsf\u00e4higen Menschsein orientiert, nicht kompatibel \nund muss daher abgelehnt werden.244\n243\tTcherkassof/Dupr\u00e9\t2022;\tMohammad\t2022.\n244\tHansen\tet\tal.\t2020;\tHartong\t2019.\tDer\tEinsatz\tumfangreicher\tDatenerhe-\nbungen\tund\t-auswertungen\tbringt\tvielfache\tHerausforderungen\tmit\tsich.\t\nEntsprechend\tspielen\tDatenschutzfragen\tund\tSorgen\tvor\teinem\tm\u00f6glichen\t\nMissbrauch\tvon\tKI-gest\u00fctzten\tLehr-\tund\tLernsystemen,\tvor\tallem\tbei\t\nfl\u00e4chendeckender\tEinf\u00fchrung,\teine\tgro\u00dfe\tRolle\tim\tFachdiskurs,\tebenso\t\nwie\teine\tm\u00f6gliche\tRegulierung\tzur\tVerhinderung\tsolcher\tProbleme.\tIm\t\nVorschlag\tf\u00fcr\teinen\tVerhaltenskodex\tf\u00fcr\tTrusted\tLearning\tAnalytics\twird\t\nauf\tKompetenzaufbau\tals\tVoraussetzung\tf\u00fcr\teinen\tverantwortungsvollen\t\nUmgang\tmit\tKI-gest\u00fctzten\tTechnologien\tgesetzt\tstatt\tauf\tRegulierung.243Neben Fragen des Zugriffs auf Daten (z. B. durch Lehr -\nkr\u00e4fte, Eltern, Beh\u00f6rden) und dessen Auswirkungen auf Fra-\ngen der Privatsph\u00e4re m\u00fcssen auch die Auswirkungen einer so \nengmaschigen \u00dcberwachung f\u00fcr die Lernatmosph\u00e4re und die \nSelbstwahrnehmung der Lernenden ber\u00fccksichtigt werden. \nHier spielen auch Fragen der Arbeitsplatz\u00fcberwachung eine \nRolle, wenn auch Lehrpersonen in den Fokus der Technolo-\ngie geraten. Hinzu kommen Zweifel an der Validit\u00e4t bestimm-\nter Daten und Analysen. Diskutiert wird etwa, ob der Einsatz \nvon EEG-Headsets und anderen Technologien zur Messung \nvon Aufmerksamkeit oder emotionalem Engagement \u00fcber -\nhaupt aussagekr\u00e4ftige Daten generiert.245 Insbesondere Bem\u00fc-\nhungen, den individuellen Lernerfolg auf Grundlage solcher \nDaten vorherzusagen246, sind kritisch zu beurteilen. Lernver -\nhalten und -erfolg d\u00fcrfen nicht auf einfach erfassbare Daten \nreduziert werden. Einem solchen Reduktionismus liegt eine \nbehavioristische Betrachtungsweise des Menschen zugrunde. \nKognitive Verstehensprozesse und konstruktive Lernszenari-\nen werden dabei unter Umst\u00e4nden zur\u00fcckgedr\u00e4ngt. Wenn es \njedoch um die Reichweite von Bildung geht, die auch der Per -\ns\u00f6nlichkeitsentwicklung und der Bildung junger Menschen zu \nverantwortlichen Personen mit Urteilskraft dienen soll, dann \nsind die personale Vermittlung und die personalen Aspekte \nvon Bildung nicht zu vernachl\u00e4ssigen.\nDatengetriebene, KI-gest\u00fctzte Lehr- und Lernsysteme \nk\u00f6nnen den jeweiligen Lernprozess unterst\u00fctzen. Die Bil-\ndungsvorteile hinsichtlich der Wissens- und Informations-\nvermittlung durch den Einsatz digitaler Werkzeuge sind \nnicht zu untersch\u00e4tzen. Sie ersetzen aber nicht die personale \nVermittlung und die personalen Aspekte von Bildung. Das \nanaloge Gespr\u00e4ch ist unverzichtbar f\u00fcr das motivations- und \nidentit\u00e4tsstiftende Potenzial, das der Unterricht bereitstellen \n245\thttps://www.eetasia.com/orwellian-nonsense-or-innovation-in-the-\nclassroom\t[12.01.2023].\n246\tGray/Perkins\t2019.244sollte. Verstehensprozesse, deren \u00dcberpr\u00fcfung ein personales \nGegen\u00fcber braucht, k\u00f6nnen von digitalem Lernen allein nicht \nangesto\u00dfen werden. Die Verantwortung f\u00fcr die Lernprozesse \nliegt bei den Menschen, die die Wahrung und F\u00f6rderung der \nSelbstbestimmung auch aufseiten der Lernenden im Blick ha-\nben sollten.247 Wenn Bildung als Beitrag zu einem m\u00fcndigen \nPersonsein Bestand haben soll, kann sie nicht vollst\u00e4ndig au-\ntomatisiert und an Maschinen delegiert werden, da personale \nBildung (stets auch) auf interpersonale und p\u00e4dagogische Akti-\non und Interaktion angewiesen ist. Die Relevanz der Schule als \nSozialraum der Interaktion zwischen Menschen ist dabei nicht \nzu untersch\u00e4tzen. All diese Aspekte in ihrer Bedeutung f\u00fcr den \nBildungsbereich hat die Coronapandemie unterstrichen, vor \nallem die Notwendigkeit des sozialen Miteinanders.248\n6.6\t\t Fazit\tund\tEmpfehlungen\nIn dieser Stellungnahme wird das Schulsystem als ein wesent-\nlicher Ort von Bildung in den Fokus genommen. Ausgeklam-\nmert wurden die enormen praktischen Herausforderungen in \ndiesem System, die ganz offenkundig nicht einfach durch den \nEinsatz von KI-Technologien gel\u00f6st werden k\u00f6nnen, dennoch \naber den Kontext der zuk\u00fcnftigen Gestaltung mitbestimmen. \nPersonalmangel, sich versch\u00e4rfende Lerndefizite bei den Sch\u00fc-\nlerinnen und Sch\u00fclern \u2013 auch verst\u00e4rkt infolge der Corona-\npandemie \u2013 sowie verschiedene infrastrukturelle Schw\u00e4chen \nsind gut bekannt und gleichwohl noch immer nicht ad\u00e4quat \ngel\u00f6st. Sie bilden den Hintergrund f\u00fcr jede Debatte, ob und \n247\tWeiterf\u00fchrende\tFragen\tstellen\tsich\tin\tdiesem\tFeld,\tdie\tvor\tallem\tauf\tder\t\nMakroebene\tangesiedelt\tsind:\tWer\tist\tder\tIndustriepartner\toder\t\u00fcber -\nnimmt\tdies\tdie\t\u00f6ffentliche\tHand,\tvor\tallem\tda\tes\tsich\tum\tkostenintensive\t\nEntwicklungen\tund\tteilweise\tauch\tAnwendungen\thandelt?\tSind\tvor\tallem\t\nbei\tdieser\tEntwicklung\tauch\tLernende\tmit\tbesonderen\tBed\u00fcrfnissen\tim\t\nBlick?\n248\tDeutscher\tEthikrat\t2022b.245gegebenenfalls wie sich KI-Technologien in ethisch verant-\nwortlicher Weise in das deutsche Schulwesen integrieren \nlassen.\n\u00dcbergreifend l\u00e4sst sich diese Situation dabei sowohl f\u00fcr als \nauch gegen einen verst\u00e4rkten Einsatz solcher neuen Systeme \nins Feld f\u00fchren: daf\u00fcr, weil durch solche Technologien gege-\nbenenfalls einige Defizite und M\u00e4ngel zumindest partiell ge-\nmildert bzw. aufgefangen werden k\u00f6nnten. Ebenso l\u00e4sst sich \nangesichts des teils schlechten Zustandes des Schulwesens in \nDeutschland auch gegen den Einsatz argumentieren, vor allem \nwenn dieser dazu dient, das grunds\u00e4tzliche Ziel, Bildung per -\nsonell, finanziell und strukturell besser zu gestalten, zu umge-\nhen bzw. von der Agenda zu nehmen. Entsprechend gilt es zu \nbetonen, dass die infrastrukturellen und personellen Heraus-\nforderungen des Schulsystems weiter \u2013 und schon sehr lange \n\u2013 ihrer Verbesserung harren und priorit\u00e4r angegangen werden \nsollten; ein Thema, das weit \u00fcber den Fokus dieser Stellungah-\nme hinausreicht. Zugleich sollten technologische Entwicklun-\ngen realistisch und mit Blick darauf untersucht und erwogen \nwerden, ob und gegebenenfalls inwieweit sie auch in dieser \nHinsicht Abhilfe schaffen k\u00f6nnten. Potenziale sollten nicht \ndeswegen verschenkt werden, weil sie eventuell nur sympto-\nmatische, aber keine tiefgreifenden L\u00f6sungen bieten. Einfa-\nche Ersatzoptionen oder leichte L\u00f6sungen der strukturellen \nHerausforderungen sind wiederum von den hier diskutierten \nTechnologien nicht zu erwarten und sollten nicht zum Nach-\nlassen eines Reformdrucks im Schulsystem f\u00fchren.\nEingedenk des hier verwendeten Verst\u00e4ndnisses des Bil-\ndungsbegriffs sowie der Analyse zur Erweiterung und zum \nVermindern menschlicher F\u00e4higkeiten durch Delegation von \nvormals menschlichen T\u00e4tigkeiten an Technologien sollte im \nschulischen Kontext zudem unterstrichen werden, dass die \ngrundlegende p\u00e4dagogische Arbeit von den vorgestellten Sys-\ntemen nicht ersetzt werden kann und sollte. Die Relevanz der \nSchule als Sozialraum der Interaktion zwischen Lehrenden \nund Lernenden sollte unbedingt erhalten bleiben. Allerdings 246bieten sich durchaus Potenziale, diese Interaktionen zu erwei-\ntern. Das Hauptziel beim Einsatz von KI-Systemen im schuli-\nschen Unterricht sollte immer die F\u00f6rderung der Lernenden \nauf der einen Seite und die Unterst\u00fctzung wie auch Entlastung \nder Lehrenden auf der anderen Seite sein.\nWie in anderen Anwendungsbereichen auch l\u00e4sst sich also \nnicht pauschal beantworten, welche der vorgestellten Tools \n\u2013 die von Vokabeltrainern und intelligenten Tutorsystemen \n\u00fcber Classroom Analytics bis hin zu Telepr\u00e4senzrobotern rei-\nchen \u2013 wann, von wem und in welchem Fach eingesetzt wer -\nden sollten. Gesellschaftliche Bildungsvorstellungen, die sich \nin den Institutionen und ihren Lernzielen niederschlagen, \nunterschiedliche Verantwortlichkeiten, aber auch die (in der \nAus- und Weiterbildung erworbene) Kompetenz der Lehr -\nkr\u00e4fte, die Methoden gem\u00e4\u00df den Lernzielen festzulegen und \ndie digitalen Techniken in ihrer Ambivalenz wahrzunehmen, \nsowie die Bedarfe aufseiten der Lernenden \u2013 all dies sind wich-\ntige Einflussfaktoren, die auf die Notwendigkeit einer einzel-\nfallbezogenen bzw. auf einzelne Anwendungsbereiche bezoge-\nnen Abw\u00e4gung verweisen.\nDa das hier angelegte Verst\u00e4ndnis der Bildung des Men-\nschen davon ausgeht, dass diese nicht nur in optimierbarer \nund berechenbarer Anh\u00e4ufung von Wissen, sondern vor allem \nin einem konstruktiven und verantwortlichen Umgang mit \nerlerntem Wissen besteht, ist besondere Aufmerksamkeit ge-\nboten, die Lernprozesse, die zentral f\u00fcr die Pers\u00f6nlichkeitsbil-\ndung des Menschen sind, nicht auszulagern. Entscheidungen \n\u00fcber das Setting des genauen Einsatzes des jeweiligen Tools \nsollten daher letztendlich immer beim Menschen liegen. Zu-\ndem muss eine Beeintr\u00e4chtigung der Privatsph\u00e4re der Lernen-\nden (und der Lehrenden) ausgeschlossen werden.\nEmpfehlungen\n>> Empfehlung Bildung 1: Digitalisierung ist kein Selbstzweck. \nDer Einsatz sollte nicht von technologischen Visionen, son-\ndern von grundlegenden Vorstellungen von Bildung, die 247auch die Bildung der Pers\u00f6nlichkeit umfassen, geleitet sein. \nDie vorgestellten Tools sollten deshalb im Bildungsprozess \nkontrolliert und als ein Element innerhalb der Beziehung \nzwischen Lehrenden und Lernenden eingesetzt werden.\n>> Empfehlung Bildung 2: F\u00fcr jedes Einsatzgebiet gilt es, eine \nangemessene Abw\u00e4gung von Chancen und Risiken vorzu-\nnehmen. Insbesondere sollten Autonomie und Privatheit \nvon Lehrenden und Lernenden hohen Schutz erfahren. \nBesondere Chancen ergeben sich im Bereich der Inklusi-\non und Teilhabe, wo das Potenzial dieser Systeme genutzt \nwerden sollte, um etwa sprachliche oder r\u00e4umliche Barrie-\nren abzubauen.\n>> Empfehlung Bildung 3: Tools, die einzelne Elemente des \nLehr- und Lernprozesses ersetzen bzw. erg\u00e4nzen (enge \nErsetzung) und nachweislich F\u00e4higkeiten, Kompetenzen \noder soziale Interaktion der Personen, die sie nutzen, er -\nweitern, wie etwa einige intelligente Tutorsysteme oder \nTelepr\u00e4senzroboter f\u00fcr externe Lehrbeteiligung, sind prin-\nzipiell weniger problematisch als solche, die umfassendere \nbzw. weitere Teile des Bildungsprozesses ersetzen. Je h\u00f6her \nder Ersetzungsgrad, desto strenger m\u00fcssen Einsatzberei-\nche, Umgebungsfaktoren und Nutzenpotenziale evaluiert \nwerden.\n>> Empfehlung Bildung 4: Es gilt, standardisierte Zertifizie-\nrungssysteme zu entwickeln, die anhand transparenter \nKriterien des Gelingens von Lernprozessen im genannten \numfassenden Sinne Schul\u00e4mter, Schulen und Lehrkr\u00e4fte \ndabei unterst\u00fctzen k\u00f6nnen, sich f\u00fcr oder gegen die Nut-\nzung eines Produkts zu entscheiden. Hier kann sich auch \nder Empfehlung zur dauerhaften Einrichtung l\u00e4nder\u00fcber -\ngreifender Zentren f\u00fcr digitale Bildung, wie es im Gutach-\nten \u201eDigitalisierung im Bildungssystem: Handlungsemp-\nfehlungen von der Kita bis zur Hochschule\u201c der St\u00e4ndigen \nWissenschaftlichen Kommission der Kultusministerkonfe-\nrenz angesprochen wurde, angeschlossen werden.248>> Empfehlung Bildung 5: Bei der Entwicklung, Erprobung und \nZertifizierung entsprechender KI-Produkte bedarf es einer \nengen Zusammenarbeit mit den relevanten Beh\u00f6rden, mit \nden jeweils zust\u00e4ndigen p\u00e4dagogischen Fachgesellschaften \nsowie der Partizipation von Beteiligten, um Schwachstellen \nder Produkte fr\u00fchzeitig zu entdecken und hohe Qualit\u00e4ts-\nstandards zu etablieren. Bekannte Herausforderungen KI-\ngetriebener Technologien wie beispielsweise Verzerrungen \nbzw. Bias oder Anthropomorphisierungstendenzen sollten \nbei der Entwicklung und Standardisierung ber\u00fccksichtigt \nwerden.\n>> Empfehlung Bildung 6: Um den verantwortlichen Einsatz \nvon KI-Technologien im Bildungsprozess zu gew\u00e4hrleis-\nten, muss die Nutzungskompetenz insbesondere der Lehr -\nkr\u00e4fte erh\u00f6ht werden; es bedarf der Entwicklung und Etab-\nlierung entsprechender Module und Curricula in der Aus-, \nFort- und Weiterbildung. Insbesondere die Gefahren eines \nverengten p\u00e4dagogischen Ansatzes und eines Deskillings \nin der Lehre sollten dabei aktiv in den Blick genommen \nwerden. Ebenso sollte die digitale Nutzungskompetenz von \nLernenden sowie Eltern gest\u00e4rkt und um KI-Aspekte er -\nweitert werden.\n>> Empfehlung Bildung 7: Im Sinne der Beteiligungsgerech-\ntigkeit sollten KI-basierte Tools Lernenden grunds\u00e4tzlich \nauch f\u00fcr das Eigenstudium zur Verf\u00fcgung stehen.\n>> Empfehlung Bildung 8: Die Einf\u00fchrung von KI-Tools im \nBildungsbereich erfordert ferner den Ausbau verschiede-\nner flankierender Forschungsbereiche. Sowohl theoreti-\nsche Fundierung als auch empirische Evidenz zu Effekten, \netwa auf die Kompetenzentwicklung (z. B. Probleml\u00f6sen), \noder zur Beeinflussung der Pers\u00f6nlichkeitsentwicklung bei \nKindern und Heranwachsenden muss weiter ausgebaut \nwerden. Dabei sollte nicht nur st\u00e4rker in Forschung und \nentsprechende Produktentwicklung investiert, sondern vor \nallen Dingen auch die praktische Erprobung und Evaluati-\non im schulischen Alltag verst\u00e4rkt werden.249>> Empfehlung Bildung 9: Des Weiteren stellt sich hier die Pro-\nblematik der Datensouver\u00e4nit\u00e4t. Zum einen sind bei der \nSammlung, Verarbeitung und Weitergabe von bildungsbe-\nzogenen Daten strenge Anforderungen an den Schutz der \nPrivatsph\u00e4re zu beachten. Zum anderen sollte die gemein-\nwohlorientierte, verantwortliche Sammlung und Nutzung \nvon gro\u00dfen Daten, etwa in der prognostischen lehrunter -\nst\u00fctzenden Anwendung, erm\u00f6glicht werden.\n>> Empfehlung Bildung 10: Eine vollst\u00e4ndige Ersetzung von \nLehrkr\u00e4ften l\u00e4uft dem hier skizzierten Verst\u00e4ndnis von Bil-\ndung zuwider und ist auch nicht dadurch zu rechtfertigen, \ndass schon heute in bestimmten Bereichen ein akuter Per -\nsonalmangel und eine schlechte (Aus-)Bildungssituation \nherrschen. In der komplexen Situation der schulischen Bil-\ndung bedarf es eines personalen Gegen\u00fcbers, das mithilfe \ntechnischer Komponenten zwar immer st\u00e4rker unterst\u00fctzt \nwerden kann, dadurch selbst als Verantwortungstr\u00e4ger f\u00fcr \ndie p\u00e4dagogische Begleitung und Evaluation des Bildungs-\nprozesses aber nicht \u00fcberfl\u00fcssig wird.\n>> Empfehlung Bildung 11: In Anbetracht der erkenntnisthe-\noretischen und ethischen Herausforderungen und unter \nAbw\u00e4gung potenzieller Nutzen und Sch\u00e4den stehen die \nMitglieder des Deutschen Ethikrates dem Einsatz von Au-\ndio- und Videomonitoring im Klassenzimmer insgesamt \nskeptisch gegen\u00fcber. Insbesondere erscheint die Analy-\nse von Aufmerksamkeit und Emotionen per Audio- und \nVideo\u00fcberwachung des Klassenraums mittels aktuell ver -\nf\u00fcgbarer Technologien nicht vertretbar. Ein Teil des Ethik-\nrates schlie\u00dft den Einsatz von Technologien zur Aufmerk-\nsamkeits- und Affekterkennung zuk\u00fcnftig jedoch nicht \nvollst\u00e4ndig aus, sofern sichergestellt ist, dass die erfassten \nDaten eine wissenschaftlich nachweisbare Verbesserung \ndes Lernprozesses bieten und das hierf\u00fcr notwendige Mo-\nnitoring von Lernenden und Lehrkr\u00e4ften keine inakzepta-\nblen Auswirkungen auf deren Privatsph\u00e4re und Autono-\nmie hat. Ein anderer Teil des Ethikrates hingegen h\u00e4lt die 250Auswirkungen auf Privatsph\u00e4re, Autonomie und Gerech-\ntigkeit hingegen generell f\u00fcr nicht akzeptabel und bef\u00fcr -\nwortet daher ein Verbot von Technologien zu Aufmerk-\nsamkeitsmonitoring und Affekterkennung in Schulen.2517\t \t \u00d6FFENTLICHE \tKOMMUNIKATION \t\nUND\tMEINUNGSBILDUNG\n7.1\t\t Einleitung\nDurch die digitale Transformation und die in der Folge ver -\n\u00e4nderten politisch relevanten Kommunikationsprozesse wird \ndie Demokratie als Herrschafts- und als Lebensform ver\u00e4n-\ndert.249 Die rasante Verbreitung digitaler Plattformen und so-\nzialer Medien mit ihren algorithmisch vermittelten Informa-\ntions- und Kommunikationsangeboten wirkt sich nicht nur \nauf einzelne gesellschaftliche Sph\u00e4ren aus, sondern potenziell \nauch auf gro\u00dfe Teile der \u00f6ffentlichen Kommunikation und \nMeinungsbildung \u2013 mit Konsequenzen f\u00fcr das demokratische \nLegitimationsgef\u00fcge, im Positiven wie im Negativen.\n\u00dcber die seit der Pionierzeit der Digitalisierung bestehen-\nden hohen Erwartungen, durch mehr Beteiligung, weitrei-\nchende Transparenz, bessere Kommunikation und schnellere \nBew\u00e4ltigung hoheitlicher Aufgaben die Verwandlung demo-\nkratischer Strukturen zum Besseren oder gar demokratische \nUmbr\u00fcche erst anzusto\u00dfen oder zu erm\u00f6glichen, hat sich ein \nSchatten gelegt: die immer deutlicher zutage tretende systemi-\nsche Verletzlichkeit politischer Institutionen durch Desinfor -\nmations- und Manipulationsversuche und Polarisierungsten-\ndenzen. Was zu Beginn durch mehr Partizipation, erhebliche \nVergr\u00f6\u00dferungen der Zug\u00e4nge zu Informationen und Abbau \nvon Hierarchien vor allem als Ausweitung und Vertiefung der \nM\u00f6glichkeiten eines demokratischen Gemeinwesens und sei-\nner miteinander agierenden B\u00fcrgerinnen und B\u00fcrger angelegt \nzu sein schien, erweist sich in Teilen schon jetzt als gef\u00e4hr -\ndend. Zunehmende Diskursverrohung und Vertrauensero-\nsion k\u00f6nnen dazu f\u00fchren, dass sich die realen Freir\u00e4ume zur \n249\tNationale\tAkademie\tder\tWissenschaften\tLeopoldina\t2021.252Partizipation und zum gemeinsamen Ringen um das bessere \nArgument eher verringern.\nNimmt man die Chancen wie Risiken zusammen, erscheint \ndie Algorithmisierung politischer Kommunikationsprozes-\nse oder gar demokratisch legitimierter Verfahren als gestal-\ntungsbed\u00fcrftig. Dabei sind die vielfach als gr\u00f6\u00dfte Bedrohung \nwahrgenommenen Gef\u00e4hrdungen nicht die M\u00f6glichkeiten \npolitisch motivierter Manipulation oder Angriffe auf digitale \nInfrastrukturen. Die Herausforderung liegt tiefer. Sie ber\u00fchrt \ndas Selbstverst\u00e4ndnis m\u00fcndiger, in ihren politischen Entschei-\ndungen grunds\u00e4tzlich freier Personen. Es geht also um die \nGefahr einer Verminderung menschlicher Autorschaft. Vor \nallem die Informations- und die Diskursqualit\u00e4t, die f\u00fcr die je \neigene Willensbildung eminent wichtig sind, werden von den \nsozialen Medien herausgefordert.\n7.2\t\t Das\tInternet\tals\tsoziotechnisches\t\nSystem:\tFunktionsweise\tsozialer\t\nMedien\n7.2.1 Neue soziotechnische Infrastrukturen\nDie M\u00f6glichkeiten zur Informationsbeschaffung und Kom-\nmunikation im Internet haben sich in den vergangenen Jahr -\nzehnten drastisch ver\u00e4ndert, insbesondere durch die rasch \nangestiegene Verbreitung und Marktmacht interaktiver Platt-\nformen, \u00fcber die inzwischen gro\u00dfe Teile des digitalen Infor -\nmationsaustauschs ablaufen. Hierzu geh\u00f6ren nicht nur soziale \nNetzwerke wie Facebook, Instagram, Twitter, YouTube, Tik-\nTok oder LinkedIn, sondern auch Suchmaschinen, allen voran \nGoogle, und Messengerdienste zum Austausch von Sofort-\nnachrichten wie WhatsApp, Signal, Telegram oder WeChat.\nDie \u00dcberg\u00e4nge zwischen sozialen Netzwerkplattformen, \nSuchmaschinen und Messengerdiensten entwickeln sich dabei \nflie\u00dfend und es kommt auch bei inhaltlichen und funktionalen 253Merkmalen zunehmend zu Konvergenzen. Viele Plattformen \nbieten inzwischen einander \u00e4hnelnde M\u00f6glichkeiten dahin-\ngehend an, multimediale Inhalte zu erstellen und zu ver\u00f6f-\nfentlichen oder live zu verbreiten, auf die Inhalte anderer \nzu reagieren, sie zu bewerten, zu kommentieren und \u2013 auch \nplattform\u00fcbergreifend \u2013 weiterzuverbreiten, sich \u00fcber direk-\nte Nachrichten und Konferenzschaltungen mit anderen Per -\nsonen auf der Plattform auszutauschen, die Plattform nach \nInhalten, Profilen, Gruppen oder sonstigen Angeboten zu \ndurchsuchen und bestimmte Inhalte zu abonnieren. Auch Op-\ntionen, eigene Inhalte gezielt zu bewerben und Produkte und \nDienstleistungen direkt anzubieten oder zu kaufen, sind viel-\nfach vorhanden.\nFast alle weiter verbreiteten Plattformen und Dienste wer -\nden von privaten Unternehmen aus den USA oder China be-\ntrieben und die gr\u00f6\u00dften sozialen Netzwerke geh\u00f6ren nur weni-\ngen Firmen. Von den zehn am meisten genutzten Angeboten \nwerden vier \u2013 Facebook, WhatsApp, Instagram und Mes-\nsenger \u2013 vom US-Konzern Meta betrieben. Das zweitgr\u00f6\u00dfte \nsoziale Netzwerk, die Videoplattform YouTube, geh\u00f6rt zum \nUS-Konzern Google, der gleichzeitig mit seiner Web-Suchma-\nschine und Onlinediensten wie Google Fotos, Gmail, Google \nMaps, Google Cloud und Google Drive gro\u00dfe Teile des Inter -\nnets dominiert. Drei weitere der zehn meistgenutzten Dienste \nAngebote werden von den chinesischen Unternehmen Ten-\ncent (WeChat) und ByteDance (TikTok und seine chinesische \nVersion Douyin) angeboten.250\nAufgrund dieser Marktmacht sowie der Vielseitigkeit und \nIntegration der von einzelnen Konzernen bereitgehaltenen \nDienste funktionieren die Angebote der gro\u00dfen Konzerne in-\nzwischen als reichhaltige soziotechnische Infrastrukturen, in \ndenen sich ein Gro\u00dfteil des Online-Nutzungsverhaltens nach \nden Vorgaben weniger Konzerne abspielt. Zahlreiche Ein-\nbindungsm\u00f6glichkeiten f\u00fcr externe Webseiten und Dienste \n250\tKemp\t2023,\tAbb.\t182.254verst\u00e4rken diesen Effekt noch, wie beispielsweise das Teilen \nvon Inhalten anderer Webseiten auf der Plattform, die direk-\nte Verkn\u00fcpfung externer Dienste mit einer Plattform und die \nOption, sich per Einmalanmeldung (Single Sign-on) mit den \nAnmeldedaten gro\u00dfer Portale wie Google oder Facebook auch \nbei anderen Seiten zu authentifizieren. Wie weitumfassend \neinzelne Plattformen die Interneterfahrung pr\u00e4gen k\u00f6nnen, \nzeigt sich beispielsweise an Facebooks Initiative internet.org, \ndie seit 2014 in ausgew\u00e4hlten L\u00e4ndern \u00fcber Mobilger\u00e4te kos-\ntenlosen Zugang zum Internet anbietet, aber die Registrierung \nbei Facebook voraussetzt. Ebenso ist die chinesische App We-\nChat aufgrund ihres gro\u00dfen Funktionsumfangs einschlie\u00dflich \nBezahlfunktion f\u00fcr viele Menschen in China zum Zentrum \nfast all ihrer Onlineaktivit\u00e4ten geworden.\n7.2.2 Informationsauswahl und Kuratierung\nMit der F\u00fclle der Informationen und Interaktionsm\u00f6glichkei-\nten in sozialen Medien gehen technische Herausforderungen \nund \u00f6konomische Potenziale einher, die gemeinsam zur Ge-\nstaltung aktueller Funktionsweisen und Gesch\u00e4ftsmodelle bei-\ngetragen haben. Im Gegensatz zu klassischen Medien, die In-\nhalte mit einer begrenzten Zahl mitarbeitender Personen nach \neinem bestimmten Konzept erstellen, ausw\u00e4hlen, pr\u00fcfen und \nver\u00f6ffentlichen, produzieren in sozialen Medien neben pro-\nfessionellen Akteuren auch die Nutzerinnen und Nutzer selbst \ndie dort zirkulierenden Beitr\u00e4ge. So entstehen schnell riesige \nMengen an Inhalten von h\u00f6chst unterschiedlicher Qualit\u00e4t. \nDies stellt die Plattformen wie auch ihre Kundschaft vor das \nProblem der Informationsauswahl, das sich mit traditionellen \nredaktionellen Strukturen, in denen Profis Inhalte aussuchen \nund qualitativ pr\u00fcfen, nicht mehr bew\u00e4ltigen l\u00e4sst. Aktuelle \nAns\u00e4tze zur L\u00f6sung dieses Problems delegieren daher einen \nGro\u00dfteil der redaktionellen Arbeit, vor allem die Kuratierung, \ndas hei\u00dft die Auswahl von Inhalten, an maschinelle Systeme. 255Insbesondere die personalisierte Kuratierung, die dazu f\u00fchrt, \ndass jeder Person beim Besuch einer Plattform auf sie pers\u00f6n-\nlich zugeschnittene Inhalte in einer bestimmten Reihenfolge \nangezeigt werden, erfolgt inzwischen weitgehend durch Algo-\nrithmen, die menschliche Redaktionsarbeit auf dieser Ebene \nsomit nahezu vollst\u00e4ndig ersetzen und unsichtbar im Hinter -\ngrund arbeiten.\nDie Kriterien, nach denen solche Algorithmen ihre Aus-\nwahl treffen, sind eng mit \u00f6konomischen Faktoren verkn\u00fcpft. \nDie meisten Plattformen und Dienste folgen einem werbeba-\nsierten Gesch\u00e4ftsmodell, bei dem Werbetreibende daf\u00fcr be-\nzahlen, m\u00f6glichst viele Menschen zu erreichen, die an ihren \nProdukten interessiert sein k\u00f6nnten. Dies gelingt am besten, \nwenn die Interessen der einzelnen Nutzerinnen und Nutzer \nerstens m\u00f6glichst pr\u00e4zise bekannt sind und Menschen zwei-\ntens m\u00f6glichst viel Zeit auf der Plattform verbringen. Je mehr \nZeit und Aufmerksamkeit eine Person der Plattform widmet, \ndesto besser sind die Voraussetzungen, ihr auf pers\u00f6nliche \nInteressen zugeschnittene Werbung zu pr\u00e4sentieren. Dies ge-\nschieht auf Basis der Annahme, dass derart ma\u00dfgeschneiderte \nWerbung gr\u00f6\u00dfere Erfolgsaussichten hat als Werbung, die we-\nniger eng orientiert an der Aufmerksamkeit und den Interes-\nsen ihrer Zielgruppe pr\u00e4sentiert wird.\nVor diesem Hintergrund lohnt es sich f\u00fcr Plattformen, so \nviele Datenspuren wie m\u00f6glich \u00fcber den pers\u00f6nlichen Hinter -\ngrund, die Interessen, das Nutzungsverhalten und das soziale \nNetzwerk der Personen, die es nutzen, zu sammeln und die-\nse Daten dazu zu verwenden, deren Aufmerksamkeit mithilfe \npersonalisierter Inhalte m\u00f6glichst lange zu fesseln und dabei \nauf ebenfalls personalisierte Werbeinhalte zu lenken. Dies ge-\nlingt technisch mithilfe von Empfehlungsdiensten (Collabo-\nrative Filtering Recommender Systems), das hei\u00dft Systemen, \ndie neben den eigenen Informationen und nutzungsbasierten \nVorlieben jeder Person zus\u00e4tzlich die entsprechenden Da-\nten von Menschen aus deren Netzwerk oder mit \u00e4hnlichem \nProfil sowie die jeweiligen Interaktionen ber\u00fccksichtigen 256(siehe Infokasten 7). Auf Grundlage dieser wechselseitigen In-\nteressenanalyse k\u00f6nnen solche Algorithmen mit hoher und im \nZuge der Nutzungsdauer st\u00e4ndig wachsender Pr\u00e4zision vor -\nhersagen, welche Inhalte jemand angeboten bekommen sollte, \num das weitere Verweilen dieser Person auf der Plattform zu \nmaximieren. Weitere Mechanismen, die von Plattformen ein-\ngesetzt werden, um die Zeit, die Menschen auf eine Plattform \nverbringen, auszudehnen, sind das st\u00e4ndige Nachladen neuer \nInhalte am Ende einer Seite (Infinite Scroll) und der Einsatz \nvon Benachrichtigungen, die auf neue abonnierte Inhalte, \nKommentare oder sonstige Reaktionen hinweisen und so dazu \nmotivieren, die Plattform erneut aufzurufen.\nDie \u00dcberg\u00e4nge zwischen Werbung und regul\u00e4ren Inhal-\nten und Interaktion (sogenannte organische Inhalte) sind oft \nflie\u00dfend. Viele Firmen, Organisationen und sonstige Anbieter, \ndie Werbung auf Plattformen schalten, betreiben gleichzeitig \nProfile, auf denen sie auch regul\u00e4re Beitr\u00e4ge ver\u00f6ffentlichen \nund mit anderen im Netzwerk interagieren. Regul\u00e4re Beitr\u00e4ge \nk\u00f6nnen auch nachtr\u00e4glich gegen Geld eine gr\u00f6\u00dfere Reichwei-\nte erhalten und erscheinen dann ebenfalls als Anzeige. Hinzu \nkommt, dass Privatpersonen, die mit erfolgreichen Inhalten \nauf einer Plattform eine gro\u00dfe Zahl an Profilen, die ihre Neu-\nigkeiten abonnieren (Follower), und somit viel Reichweite er -\nlangt haben, zunehmend in Kooperationen mit Werbetreiben-\nden als Influencer agieren, die Produkte und Dienstleistungen \ngegen\u00fcber ihrem Publikum gezielt rezensieren und bewerben.\nInfokasten\t7:\tFacebook-Algorithmus\nDie\tAuswahlkriterien\t von\tEmpfehlungsalgorithmen\t auf\tsozialen\t Plattfor-\nmen\twerden\tin\tder\tRegel\tnicht\tvollumf\u00e4nglich\t ver\u00f6ffentlicht,\t wohl\tjedoch\t\nbestimmte\t Akzentuierungen\t und\t\u00c4nderungen,\t wie\tfolgendes\t Beispiel\t zeigt.\nNachdem\t Facebook\t 2006\tin\tder\tUrsprungsversion\t ihres\tNewsfeeds\t nur\t\nInhalte\taus\tunmittelbar\t vernetzten\t Profilen\t in\tchronologischer\t Reihenfol-\nge\tangezeigt\t hatte,\twurde\tmit\tder\tEinf\u00fchrung\t des\t\u201eGef\u00e4llt-mir\u201c-Buttons\t257ab\t2009\terstmals\t die\tM\u00f6glichkeit\t angeboten,\t Inhalte\tzu\tbewerten.251\tDie-\nse\tInteraktionen\t wurden\tfortan\tdaf\u00fcr\tgenutzt,\t Beitr\u00e4ge\t mit\tvielen\tLikes\tim\t\nNewsfeed\t nach\toben\tzu\tsp\u00fclen.\tIm\tLaufe\tder\tfolgenden\t Jahre\tkamen\tdiverse\t\nweitere\tKriterien\tdazu,\tdarunter:\n\u2022 h\u00f6here\tPriorit\u00e4t\t f\u00fcr\tBeitr\u00e4ge\t aus\tProfilen,\t mit\tdem\tman\tviel\tinteragiert\t\n(2013)252\n\u2022 weniger\t Reichweite\t f\u00fcr\tProfile,\tdie\tin\tihren\tnicht\tals\tAnzeigen\t geschalte-\nten\tBeitr\u00e4gen\tWerbung\tverbreiten\t(2015)253\n\u2022 weniger\t Reichweite\t f\u00fcr\tBeitr\u00e4ge,\t die\tvon\tvielen\tals\tunwahr\tmarkiert\t wer-\nden\t(2015)254\n\u2022 h\u00f6here\tPriorit\u00e4t\t f\u00fcr\tBeitr\u00e4ge,\t die\t\u00c4hnlichkeit\t mit\tInhalten\t haben,\tmit\tde-\nnen\tjemand\tzuvor\tviel\tZeit\tverbracht\that\t(2016)255\n\u2022 h\u00f6here\tPriorit\u00e4t\t f\u00fcr\tBeitr\u00e4ge,\t die\t\u00c4hnlichkeit\t mit\tInhalten\t haben,\tauf\tdie\t\njemand\tnicht\tmit\tdem\tklassischen\t \u201eGef\u00e4llt\tmir\u201c\treagiert\that,\tsondern\t mit\t\neinem\tder\t2016\teingef\u00fchrten\t Emojis\t\u201eLiebe\u201c,\t \u201eHaha\u201c,\t \u201eWow\u201c,\t\u201eTraurig\u201c\t\nund\t\u201eW\u00fctend\u201c\t(2017)256\n\u2022 mehr\tReichweite\t f\u00fcr\tBeitr\u00e4ge,\t die\tbesonders\t h\u00e4ufig\tgeteilt\twerden\t\nund\tviele\tReaktionen\t und\tDiskussionen\t in\tden\tKommentaren\t ausl\u00f6sen\t\n(2018)257\nLaut\tAngaben\t von\tFacebook258\tsind\tdie\t\u201edrei\thaupts\u00e4chlichen\t Signale\u201c,\t die\t\nder\tAlgorithmus\t aktuell\tbei\tder\tpersonalisierten\t Priorisierung\t von\tInhalten\t\nverwendet:\n(1)\twie\th\u00e4ufig\teine\tPerson\tmit\tder\tQuelle,\taus\tder\tein\tBeitrag\tstammt,\t zuvor\t\ninteragiert\that\n(2)\twelche\tArt\tvon\tInhalten\t eine\tPerson\tzuvor\tam\th\u00e4ufigsten\t genutzt\t hat\t\n(z.\u00a0B.\tFotos,\tVideos\toder\tLinks)\n(3)\twie\tviele\tInteraktionen\t ein\tBeitrag\terhalten\t hat,\tinsbesondere\t von\tande-\nren\tim\tpers\u00f6nlichen\tNetzwerk\nZus\u00e4tzlich\t zu\tdiesen\talgorithmisch\t vorgenommenen\t Gewichtungen\t k\u00f6nnen\t\nNutzerinnen\t und\tNutzer\teinige\tKriterien\t auch\tselbst\tfestlegen,\t wie\tbei-\nspielsweise\t eine\tFavoritenliste\t der\tProfile\tund\tSeiten,\tdenen\tsie\tfolgen\tund\t\nderen\tInhalte\tsie\tpriorit\u00e4r\tsehen\tm\u00f6chten.\n251\t http://web.archive.org/web/20090212011228/http://blog.facebook.com/\nblog.php?post=53024537130\t[12.01.2023].\n252\thttps://www.facebook.com/business/news/News-Feed-FYI-A-Window-\nInto-News-Feed\t[12.01.2023];\thttps://martech.org/facebook-story-bumping-\nlast-actor\t[12.01.2023].\n253\t https://about.fb.com/news/2014/11/news-feed-fyi-reducing-overly-\npromotional-page-posts-in-news-feed\t[12.01.2023].\n254\thttps://about.fb.com/news/2015/01/news-feed-fyi-showing-fewer-hoaxes\t\n[12.01.2023].\n255\t https://about.fb.com/news/2016/08/news-feed-fyi-showing-you-more-\npersonally-informative-stories\t[12.01.2023].\n256\thttps://about.fb.com/news/2016/02/reactions-now-available-globally\t\n[12.01.2023];\thttps://mashable.com/article/facebook-reactions-news-feed\t\n[12.01.2023].\n257\thttps://about.fb.com/news/2018/01/news-feed-fyi-bringing-people-closer-\ntogether\t[12.01.2023].\n258\thttps://www.facebook.com/formedia/tools/feed\t[12.01.2023].258Insgesamt kommt es so auf Plattformen und in sozialen Netz-\nwerken zu einer ausgepr\u00e4gten Verquickung technisch wie \nmenschlich vermittelter Stimuli und Strukturen, die gro\u00dfe \nsoziale und psychologische Wirkmacht entfalten und gemein-\nsam dazu beitragen, Aufmerksamkeit zu erregen und zu fes-\nseln, die Verweildauer von Menschen auf der Plattform zu ma-\nximieren und so letztlich die Rezeption von Werbehinhalten \nzu optimieren.\n7.2.3 Moderation von Inhalten\nEine algorithmisch gesteuerte personalisierte Informations-\nauswahl, in der \u00f6konomische und aufmerksamkeitsbasierte \nFaktoren derart eng verbunden sind und die sich anhand des \nNutzungsverhaltens st\u00e4ndig weiterentwickelt, f\u00fchrt dazu, dass \nInhalte, die besonders sensationell erscheinen oder intensi-\nve emotionale Reaktionen ausl\u00f6sen, sich \u00fcberproportional \nschnell und weit verbreiten. Dies beg\u00fcnstigt unter anderem \nFalschnachrichten259 und Beitr\u00e4ge, auf die mit Wut reagiert \nwird260, so zum Beispiel Inhalte wie Hassreden, Beleidigun-\ngen und Volksverhetzungen. Das stellt Plattformen vor die \nHerausforderung, wie solche potenziell problematischen und \ngleichzeitig verbreitungsstarken Inhalte erkannt werden k\u00f6n-\nnen und wie mit ihnen umzugehen ist.\nIn Reaktion auf diese Herausforderung bem\u00fchen sich \nPlattformen darum, ihre Inhalte nach verschiedenen Krite-\nrien zu moderieren (Content-Moderation). Hierbei sind ei-\nnerseits Menschen beteiligt \u2013 sowohl Angestellte der Firmen \nselbst als auch Personen, die f\u00fcr externe Dienstleister arbeiten, \nund die Menschen, die das Plattformangebot nutzen und In-\nhalte melden, die ihnen unangenehm auffallen. Andererseits \nkommen auch algorithmische Systeme zum Einsatz. In diesem \n259\tVosoughi/Roy/Aral\t2018.\n260\tFan\tet\tal.\t2014.259soziotechnischen Zusammenspiel geht es zum einen um die \nGestaltung und Umsetzung von Regeln, die bestimmen, wel-\nche Inhalte erlaubt sind und welche gel\u00f6scht werden m\u00fcssen, \nzum anderen aber auch darum, welche Inhalte im Rahmen \neiner algorithmischen Kuratierung gegebenenfalls lediglich in \nihrer Verbreitung und Sichtbarkeit eingeschr\u00e4nkt werden.\nGrundlage f\u00fcr die Moderation sind zun\u00e4chst rechtliche \nVorgaben, die bestimmte Inhalte als unzul\u00e4ssig einstufen, vor \nallem solche des Strafrechts; aber auch zivilrechtlich gesch\u00fctz-\nte Pers\u00f6nlichkeitsrechte setzen der Kommunikation Gren-\nzen. Auch die Anforderungen f\u00fcr die Meldung, Pr\u00fcfung und \nEntfernung solcher Inhalte wie auch f\u00fcr Beschwerden gegen \nsolche Eingriffe ergeben sich zun\u00e4chst aus den allgemeinen \nrechtlichen Regelungen f\u00fcr rechtswidrige \u00c4u\u00dferungen. Im \ndeutschen Kontext ist dar\u00fcber hinaus insbesondere auf das \nGesetz zur Verbesserung der Rechtsdurchsetzung in sozialen \nNetzwerken (Netzwerkdurchsetzungsgesetz) hinzuweisen, \nwelches Plattformbetreiber verpflichtet, offensichtlich illegale \nInhalte innerhalb von 24 Stunden nach Eingang der Beschwer -\nde zu l\u00f6schen oder den Zugang zu ihnen zu sperren (\u00a7 3 Abs. \n2 Nr. 2). Das Gesetz selbst definiert nicht, was illegal ist, son-\ndern verweist auf strafrechtliche Normen. An das Konzept \ndes Netzwerkdurchsetzungsgesetzes kn\u00fcpft der 2022 von der \nEurop\u00e4ischen Union erlassene Digital Services Act an, der das \nNetzwerkdurchsetzungsgesetz wohl jedenfalls teilweise erset-\nzen wird.261\nHinzu kommen in der Regel Kommunikationsregeln, die \nvon Plattformbetreibern selbst entwickelt werden (Communi-\nty-Standards), auf deren Grundlage auch rechtlich zul\u00e4ssige In-\nhalte gel\u00f6scht, gesperrt oder in ihrer Reichweite eingeschr\u00e4nkt \nwerden k\u00f6nnen. Hierzu gibt es eine kontroverse Diskussion, \nob und wann solche Praktiken die Meinungsfreiheit auf unzu-\nl\u00e4ssige Weise beschr\u00e4nken.262\n261\t Weiden\t2022.\n262\tRaue\t2018.260Moderationsvorg\u00e4nge k\u00f6nnen sowohl durch die Meldung \nanst\u00f6\u00dfiger Inhalte, die Einzelpersonen bei der Nutzung des \nPlattformangebots auffallen, als auch durch Algorithmen, \ndie beispielsweise nach bestimmten Schl\u00fcsselw\u00f6rtern suchen, \nausgel\u00f6st werden. Bei Inhalten, die als potenziell problema-\ntisch markiert werden, muss anschlie\u00dfend gepr\u00fcft werden, \nob sie die aktuell geltenden Regeln verletzen. Auch an diesen \nPr\u00fcfaufgaben sind Menschen und Maschinen gemeinsam be-\nteiligt. Menschliche Moderation erfolgt typischerweise durch \nPersonen, die h\u00e4ufig unter \u00e4u\u00dferst prek\u00e4ren Arbeitsbedingun-\ngen bei Drittanbietern angestellt sind, mit denen eine Platt-\nform vertraglich zusammenarbeitet.263 Sie sichten gemeldete \nInhalte und gleichen sie mit den jeweils geltenden Regeln ab. \nDabei werden sie h\u00e4ufig mit extrem belastendem Material wie \nT\u00f6tungen, Kindesmissbrauch, Tierqu\u00e4lerei und Suizid kon-\nfrontiert. Zudem m\u00fcssen sie innerhalb weniger Sekunden \nsprachlich und kulturell komplexe Nuancen ber\u00fccksichtigen, \nvon denen die Zul\u00e4ssigkeit eines Beitrags entscheidend abh\u00e4n-\ngen kann. So kann es zum Beispiel einen gro\u00dfen Unterschied \nmachen, ob ein Beitrag als Satire gewertet wird oder nicht oder \nob eine anst\u00f6\u00dfige Botschaft im Kontext des Beitrags nur zitiert \nund gegebenenfalls kritisch reflektiert oder sich zu eigen ge-\nmacht wird.\nDer Einsatz von Algorithmen zur Moderation wirkt viel-\nversprechend, da er zum einen anst\u00f6\u00dfige, beispielsweise bru-\ntale Inhalte herausfiltern kann, ohne dass diese von Menschen \nangesehen werden m\u00fcssen, und zum anderen mit der un\u00fcber -\nsichtlichen Menge an Daten und Inhalten im Netz besser umge-\nhen kann. Allerdings sind automatisierte Methoden jedenfalls \nbislang h\u00e4ufig unzureichend, um den kulturellen und sozia-\nlen Zusammenhang einer \u00c4u\u00dferung einzubeziehen und diese \ndamit ad\u00e4quat zu beurteilen, da aufgrund der beschriebenen \n263\tSiehe\tdazu\tetwa\tden\tDokumentarfilm\t\u201eThe\tCleaners\u201c\taus\tdem\tJahr\t2018\t\n(www.thecleaners-film.de);\thttps://time.com/6253180/meta-kenya-lawsuit-\nmotaung\t [28.02.2023].\t Die\tgleiche\tProblematik\t zeigt\tsich\tauch\tbei\tChatGTP\t\n(https://time.com/6247678/openai-chatgpt-kenya-workers\t[06.02.2023]).261komplexen Kontexte und Nuancen sowie durch absichtlich \nverwendete Stilmittel wie Ironie und Sarkasmus Unsch\u00e4rfen \nentstehen, die sich algorithmisch noch nicht immer zuverl\u00e4s-\nsig zuordnen lassen.264 Genau solche kontextuellen Faktoren \nspielen bei der juristischen sowie moralischen Beurteilung von \n\u00c4u\u00dferungen jedoch eine sehr gro\u00dfe Rolle.\nSo kommt es zum Beispiel darauf an, wer gegen\u00fcber wem \nin welchem Kontext einen Begriff verwendet, um zu beurteilen, \nob es sich hier um eine (rassistische) Beleidigung handelt. Im \namerikanischen Raum konnte etwa gezeigt werden, dass der \nEinsatz automatisierter Content-Moderation-Techniken ver -\nschiedene gesellschaftliche Gruppen unterschiedlich betrifft, \nda bestimmte Sprachformen beispielsweise eher markiert wer -\nden. Facebooks Ansatz, allgemeing\u00fcltige und \u201eblinde\u201c Regeln \nzu erschaffen, f\u00fchrte hier dazu, dass Gruppen wie \u201ewhite men\u201c \neher vor Hassrede gesch\u00fctzt wurden als vulnerablere Gruppen \nwie \u201eblack children\u201c.265\nEine Sorge bei der Content-Moderation liegt in der Gefahr, \ndass systematisch auch Inhalte gel\u00f6scht oder unzug\u00e4nglich ge-\nmacht werden, die nicht gegen (vom Staat oder von Plattfor -\nmen gesetzte) Regeln versto\u00dfen (sogenanntes Overblocking). \nDass es dazu kommt, ist jedenfalls dann plausibel, wenn der \nRechtsrahmen Anreize setzt, Inhalte im Zweifel zu l\u00f6schen, \netwa wenn Sanktionen f\u00fcr den Fall der Nichtl\u00f6schung vorge-\nsehen sind, nicht aber f\u00fcr die fehlerhafte L\u00f6schung. Dies wird \nbeispielsweise in kritischen Betrachtungen des Netzwerk-\ndurchsetzungsgesetzes von Kritikern angenommen.266 Ob \nes tats\u00e4chlich zu Overblocking kommt, ist schwer empi-\nrisch zu pr\u00fcfen, nicht nur weil dazu Datenzugang ben\u00f6-\ntigt wird, sondern auch weil eine angemessene Pr\u00fcfung von \n264\tAlgorithmische\tMethoden\tzur\tSentiment\tAnalysis,\tdie\tauch\tStilmittel\twie\t\nzum\tBeispiel\tIronie\tund\tSarkasmus\terkennen\tk\u00f6nnen,\twerden\tst\u00e4ndig\t\nweiterentwickelt\t(Sarsam\tet\tal.\t2020).\n265\thttps://www.propublica.org/article/facebook-hate-speech-censorship-\ninternal-documents-algorithms\t[12.01.2023];\tDavidson/Bhattacharya/\nWeber\t2019.\n266\t\u00dcberblick\tbei\tLiesching\tet\tal.\t2021;\tvgl.\tFichtner\t2022.262Kommunikationsinhalten eine Auslegung der \u00c4u\u00dferung und \neine Ber\u00fccksichtigung des Kontextes erfordert, was jedenfalls \nden Aufwand erh\u00f6ht.\n7.2.4 Auswirkungen auf die Erweiterung \nund Verminderung menschlicher \nHandlungsf\u00e4higkeiten\nDie beschriebenen Funktionsweisen von Plattformen und \nsozialen Medien sind dadurch gekennzeichnet, dass erstens \ngro\u00dfe Teile der Auswahl und Moderation von Inhalten an Al-\ngorithmen delegiert werden, dass es dabei zweitens zu kom-\nplexen Wechselwirkungen zwischen diesen technisch vermit-\ntelten Prozessen und den in diesen Netzwerken agierenden \nMenschen kommt und dass hier drittens ganz \u00fcberwiegend \nkommerziell motivierte Gestaltungsparameter eingesetzt wer -\nden, die dazu dienen, die Aufmerksamkeit und Verweildauer \nvon Menschen auf der jeweiligen Plattform zu maximieren. \nMithilfe dieser soziotechnischen Verquickungen k\u00f6nnen \nmenschliche Handlungsf\u00e4higkeiten in unterschiedlicher Wei-\nse erweitert oder vermindert werden.\nDie Delegation von Kuratierungsprozessen an Algorith-\nmen, die aufgrund datenreicher Profile ein \u00fcberaus effektives \npersonalisiertes Angebot von Inhalten zusammenstellen, er -\nweitert zun\u00e4chst die M\u00f6glichkeiten von Plattformbetreibern \nund Werbetreibenden, ein gro\u00dfes Publikum erfolgreich zu \nerreichen. F\u00fcr einzelne Nutzerinnen und Nutzer ist die Per -\nsonalisierung des Angebots mit Komfort- und Effizienzge-\nwinnen verbunden, weil gew\u00fcnschte beziehungsweise zu den \neigenen Interessen passende Inhalte schnell auffindbar sind \noder proaktiv angeboten werden. Auch dies kann eine Erwei-\nterung von Handlungsm\u00f6glichkeiten bedeuten, zum Beispiel \nwenn pers\u00f6nliche Ziele so besser oder schneller erreicht wer -\nden k\u00f6nnen oder wenn aufgrund der effektiven Delegation der 263Inhaltsauswahl an Algorithmen Entlastungseffekte auftreten, \ndie Freir\u00e4ume f\u00fcr andere Aktivit\u00e4ten schaffen.\nDie soziotechnisch hybride Moderation von Inhalten er -\nweitert zudem die M\u00f6glichkeiten aller Beteiligten, eine sehr \ngro\u00dfe Inhaltsf\u00fclle und -vielfalt verbreiten und rezipieren zu \nk\u00f6nnen, ohne dabei ein \u00dcberma\u00df problematischen Materials \nin Kauf nehmen zu m\u00fcssen. Die beschriebenen, hierbei beste-\nhenden Unzul\u00e4nglichkeiten und Abw\u00e4gungsschwierigkeiten \nk\u00f6nnen jedoch, wie in Abschnitt 7.4 noch n\u00e4her beleuchtet \nwird, auch vermindernd auf die Diskursqualit\u00e4t wirken.\nEine Verminderung menschlicher Handlungsspielr\u00e4u-\nme kann sich ebenso ergeben, wo es Menschen schwerf\u00e4llt, \nsich dem Sog von Plattformangeboten zu entziehen und die \nNutzung dieser Angebote auf ein f\u00fcr sie gesundes Ma\u00df zu \nbeschr\u00e4nken. Die soziotechnische Optimierung von Platt-\nformangeboten zur Maximierung von Aufmerksamkeit und \nVerweildauer entwickelt hier gro\u00dfe Wirkmacht; sogar regel-\nrechte Abh\u00e4ngigkeiten k\u00f6nnen entstehen.267 Pers\u00f6nliche Frei-\nheit wird zum Beispiel dann vermindert, wenn das selbstbe-\nstimmte Verfolgen eigentlich gesetzter Ziele erschwert wird, \nweil eine Losl\u00f6sung vom Plattformangebot nicht rechtzeitig \nhinreichend gelingt.\nAuch die Delegation der Inhaltsauswahl an eine algorith-\nmische Kuratierung kann Autorschaft vermindern, insbeson-\ndere wenn eine rationale Auseinandersetzung mit Alternati-\nven aufgrund der algorithmischen Vorwegnahme bestimmter \nRelevanzentscheidungen nur noch eingeschr\u00e4nkt stattfinden \nkann. Die auf Grundlage solcher Vorwegnahmen entstehen-\nden personalisierten und soziotechnisch komplexen Struktu-\nren, innerhalb derer Inhalte zur Auswahl angeboten werden \n(Choice Architectures), k\u00f6nnen ausgepr\u00e4gte Nudging-Effekte \nentfalten, die menschliche Entscheidungen wirkm\u00e4chtig be-\neinflussen, ohne dass dies f\u00fcr die Betroffenen erkenntlich \nist (vgl. Abschnitt 4.5). Dies ist als besonders problematisch \n267\tCheng\tet\tal.\t2021.264einzustufen, wenn die algorithmischen Auswahlkriterien \nkommerziell motiviert oder von anderen Interessen privater \nKonzerne bestimmt werden, die von au\u00dfen kaum nachvoll-\nziehbar sind und deren Ausrichtung am Gemeinwohl nicht \nvorausgesetzt werden kann.268\nNeben diesen allgemeinen Auswirkungen der Funktions-\nweisen von Plattformen und sozialen Medien ver\u00e4ndern sich \nauch die Informations- und die Diskursqualit\u00e4t, die wichtige \nGrundlagen der \u00f6ffentlichen Meinungsbildung sind \u2013 mit po-\ntenziell weitreichenden Konsequenzen f\u00fcr Prozesse der politi-\nschen Willensbildung. Hier steht eine Reihe von Ph\u00e4nomenen \nin der Diskussion, die in den n\u00e4chsten beiden Abschnitten n\u00e4-\nher betrachtet werden. Wie weit verbreitet und wirkm\u00e4chtig \ndiese Effekte sind, l\u00e4sst sich aktuell zwar noch nicht abschlie-\n\u00dfend beurteilen, auch weil die Datenlage mitunter unklar oder \nwiderspr\u00fcchlich ist. Manche Fragen lassen sich nur schwer \nuntersuchen, da zum Beispiel Daten zur Plattformnutzung \nund den dort verwendeten Algorithmen auch f\u00fcr die For -\nschung nur teilweise oder in einigen F\u00e4llen wie beispielswei-\nse bei verschl\u00fcsselten Messengerdiensten gar nicht \u00f6ffentlich \nzug\u00e4nglich sind. Ein genauerer Blick auf die postulierten Me-\nchanismen lohnt jedoch schon deswegen, weil die von ihnen \nber\u00fchrten Prozesse grundlegend f\u00fcr unsere Demokratie sind.\n7.3\t\t Informationsqualit\u00e4t\nMit Blick auf die Informationsqualit\u00e4t ist zun\u00e4chst auf die \nvielen positiven Ver\u00e4nderungen zu verweisen, die sich trotz \nder oben beschriebenen Herausforderungen bei der Auswahl, \nKuratierung und Moderation von Plattforminhalten aus dem \nim Internet verf\u00fcgbaren Informationsangebot ergeben. Platt-\nformen und soziale Medien erweitern die M\u00f6glichkeiten vieler \nMenschen, sich zu informieren, sich Geh\u00f6r zu verschaffen und \n268\tHildebrandt\t2022;\tYeung\t2017.265sich mit anderen auszutauschen und zu vernetzen, ganz er -\nheblich.269 Zweifelsohne er\u00f6ffnet die Quellenvielfalt und -f\u00fcl-\nle auf vielen Plattformen wie auch im Internet insgesamt im \nVergleich mit klassischen Informationskan\u00e4len wie Massen-\nmedien, Bibliotheken oder dem direkten pers\u00f6nlichen Aus-\ntausch wesentlich umfangreichere M\u00f6glichkeiten, sich schnell \nund einfach zu informieren. Dies gilt erst recht f\u00fcr Menschen, \ndie offline keinen guten Zugang zu Informationsangeboten \nhaben, wie zum Beispiel in strukturschwachen oder sich erst \nentwickelnden Regionen, oder f\u00fcr Menschen, die in ihrer Mo-\nbilit\u00e4t eingeschr\u00e4nkt sind.\nEs ist wie noch nie zuvor m\u00f6glich, dass Menschen Infor -\nmationen und Einsch\u00e4tzungen von unterschiedlichsten Seiten \nund in hoher Detailgenauigkeit einholen k\u00f6nnen. Dazu tragen \nzum Beispiel Projekte wie die gemeinn\u00fctzige, umfassende und \nst\u00e4ndig wachsende Online-Enzyklop\u00e4die Wikipedia bei. Auch \nwissenschaftliche Erkenntnisse werden durch Open-Access-\nModelle leichter zug\u00e4nglich. Des Weiteren k\u00f6nnen sich an \nspeziellen Themen Interessierte auf Plattformen, in Gruppen \noder Foren oder \u00fcber die Verwendung relevanter Markierun-\ngen von Beitr\u00e4gen beispielsweise mit Hashtags zielgerichtet \naustauschen.270 Es steht online jeder Person frei, die eigene \nInformationsnutzung eigenst\u00e4ndig zu diversifizieren und bei-\nspielsweise gezielt nach Quellen und Stimmen zu suchen, die \nden eigenen Horizont erweitern. Gemeinsam er\u00f6ffnen diese \nOptionen erhebliche Chancen, menschliche Handlungsspiel-\nr\u00e4ume, Teilhabem\u00f6glichkeiten und R\u00e4ume f\u00fcr den gemeinsa-\nmen \u00f6ffentlichen Vernunftgebrauch zu erweitern.271\nDemgegen\u00fcber wird vielfach die Sorge ge\u00e4u\u00dfert, dass sich \ninsbesondere aus den derzeit g\u00e4ngigen Kriterien der algo-\nrithmischen Kuratierung mit ihrer Priorisierung fesselnder \n269\tOrtiz\tet\tal.\t2019;\tDonelan\t2016.\n270\thttps://crutchesandspice.com/2022/11/16/with-twitter-crumbling-it-feels-\nlike-the-world-is-collapsing-on-disabled-people\t[12.01.2023].\n271\t https://www.theguardian.com/technology/2022/nov/30/twitter-\njournalism-elon-musk\t[12.01.2023].266Inhalte auch negative Auswirkungen auf die Informations-\nqualit\u00e4t ergeben. In der Diskussion stehen hier vor allem die \nVerbreitung von Falschnachrichten, die Entstehung von Fil-\nterblasen und Echokammern und ein Trend zu Inhalten, die \nnegative emotionale und moralische Reaktionen und Interak-\ntionen provozieren und so m\u00f6glicherweise zu den in Abschnitt \n7.4 n\u00e4her beleuchteten gesellschaftlichen Polarisierungs- oder \nFragmentierungstendenzen beitragen.\n7.3.1 Falschnachrichten und \nVerschw\u00f6rungstheorien\nDie bereits erw\u00e4hnte Tendenz, dass sich unter den aktuellen \nKuratierungskriterien vieler Plattformen sensationell wirkende \nFalschinformationen, insbesondere bei politischen Themen272, \nbesonders schnell verbreiten, ist mit der Sorge verbunden, dass \ndies selbst dann nachhaltige Effekte auf die Informationsqua-\nlit\u00e4t haben kann, wenn solche Inhalte im Rahmen von Mo-\nderationsbem\u00fchungen erkannt, entfernt, in ihrer Verbreitung \ngehemmt oder mit einordnenden Hinweisen versehen werden.\nIn diesem Zusammenhang wird h\u00e4ufig auch die Annahme \nvorgebracht, dass populistische Str\u00f6mungen, Verschw\u00f6rungs-\ntheorien273 und weitere politisch motivierte Bewegungen, bei \ndenen die Erzeugung und Verst\u00e4rkung bestimmter Stim-\nmungslagen in der Bev\u00f6lkerung eine wichtige Rolle spielen, \nin den vergangenen Jahren zugenommen beziehungsweise \nan Zulauf und/oder Bedeutung gewonnen haben und dass \nFalschnachrichten in diesem Rahmen gezielt f\u00fcr politische \nZwecke eingesetzt werden.274 Dieser Eindruck wird unter an-\nderem dadurch beg\u00fcnstigt, dass populistische und \n272\tVosoughi/Roy/Aral\t2018.\n273\tDer\tBegriff\tder\tVerschw\u00f6rungstheorie\that\tsich\teingeb\u00fcrgert,\tobwohl\tder\t\nAusdruck\t\u201eTheorie\u201c\tangesichts\tder\tFragw\u00fcrdigkeit\tbzw.\tWiderspr\u00fcchlich-\nkeit\tder\tpostulierten\tInhalte\toftmals\tnicht\tangemessen\tist.\n274\tMuirhead/Rosenblum\t2019.267verschw\u00f6rerische Elemente bei vielen Ereignissen und The-\nmen Hand in Hand gehen275 und in j\u00fcngerer Zeit eine gro\u00dfe \nRolle im \u00f6ffentlichen Diskurs haben.\nEs ist nicht von der Hand zu weisen, dass populistische \nund von verschw\u00f6rungstheoretischen Ideen gepr\u00e4gte Inhal-\nte demokratiegef\u00e4hrdend wirken k\u00f6nnen, da sie h\u00e4ufig aus-\ndr\u00fccklich darauf abzielen, Vertrauen in demokratisch legiti-\nmierte Prozesse und Institutionen zu untergraben, schuldige \nPersonen ausfindig zu machen, die Welt in Gut und B\u00f6se auf-\nzuteilen und vermeintliche Gegenseiten zu identifizieren und \nzu diskreditieren (vgl. Abschnitt 7.4.1).276 So gibt es beispiels-\nweise empirische Hinweise darauf, dass Menschen, die mit \nVerschw\u00f6rungstheorien konfrontiert werden, danach weniger \nVertrauen in etablierte Fakten haben und auch weniger Hilfs-\nbereitschaft zeigen.277\nOb der Glaube an Verschw\u00f6rungstheorien in den letz-\nten Jahren tats\u00e4chlich zugenommen hat, ist umstritten, auch \nweil der Definitionsgegenstand oft schwer zu fassen ist und \neindeutige empirische Belege fehlen.278 Die These, dass die \nin Abschnitt 7.2 beschriebenen Selektionskriterien auf Platt-\nformen auch zur einfachen und schnellen Verbreitung von \nVerschw\u00f6rungstheorien und populistischen Inhalten beitra-\ngen, erscheint jedoch zumindest plausibel. Falschnachrichten \nverbreiten sich beispielsweise unter anderem dann besonders \nerfolgreich, wenn sie Emp\u00f6rung und Wut sch\u00fcren.279 Es l\u00e4sst \nsich zudem nachweisen, dass Menschen, die soziale Medi-\nen intensiv als Informationsquelle nutzen, empf\u00e4nglicher f\u00fcr \nkonspiratives Gedankengut sind.280 Zudem l\u00e4sst die wieder -\nholte Konfrontation mit Falschnachrichten selbige bereits als \n275\t Castanho\tSilva/Vegetti/Littvay\t2017.\n276\thttps://www.deutschland.de/de/topic/politik/verschwoerungstheorien-\nund-demokratie-experte-michael-butter\t[12.01.2023].\n277\tvan\tder\tLinden\t2015.\n278\tUscinski\tet\tal.\t2022;\tsiehe\tauch\thttps://www.sciencemediacenter.de/alle-\nangebote/research-in-context/details/news/glaube-an-verschwoerungs -\ntheorien-nahm-im-laufe-der-zeit-nicht-zu\t[18.01.2023].\n279\tChuai/Zhao\t2022.\n280\tEnder\tet\tal.\t2023.268glaubw\u00fcrdig erscheinen281 und besonders einpr\u00e4gsam wir -\nken282, selbst wenn sie sp\u00e4ter diskreditiert oder als umstritten \nmarkiert werden. Dies gilt erst recht, wenn Inhalte innerhalb \neines pers\u00f6nlichen Netzwerks verbreitet werden, dessen Quel-\nlen aufgrund gemeinsamer Interessen und \u00dcberzeugungen \nvon vornherein als besonders vertrauensw\u00fcrdig gelten (vgl. \nAbschnitt 7.3.2).283\nModerationsversuche k\u00f6nnen bei der Eind\u00e4mmung von \nFalschnachrichten oft kaum mithalten. Inhalte, die aus ver -\ntrauten oder als wirkm\u00e4chtig wahrgenommenen Quellen \nstammen oder bereits weit verbreitet wurden und daher als \nbesonders beliebt erscheinen, werden unabh\u00e4ngig vom Wahr -\nheitsgehalt vorzugsweise konsumiert284 und geteilt285. Die \ngezielte und massenhafte Verbreitung von Falschinformatio-\nnen \u00fcber eigens hierf\u00fcr eingerichtete gef\u00e4lschte und teilwei-\nse automatisch betriebene Konten (Fake-Accounts, Bots286) \nsorgt derweil daf\u00fcr, dass fragw\u00fcrdige Inhalte schnell kritische \nVerbreitungsschwellen erreichen. Beispielsweise werden einer \nSch\u00e4tzung zufolge auf Twitter zwei Drittel aller Verweise auf \nbeliebte Webseiten durch Bots verbreitet.287\n7.3.2 Filterblasen und Echokammern\nFilterblasen und Echokammern sind Metaphern, die auf der \nHypothese gr\u00fcnden, dass der starke Fokus der algorithmischen \nKuratierung auf individuelle Pr\u00e4ferenzen dazu f\u00fchren kann, \ndass die individuell wahrnehmbare Informationsauswahl \n281\t Pennycook/Cannon/Rand\t2018.\n282\tMurphy\tet\tal.\t2019.\n283\tDel\tVicario\tet\tal.\t2016.\n284\tF\u00fcr\tJugendliche\tin\tden\tUSA\tvgl.\tetwa\tRobb\t2020.\n285\tAllem\t2020.\n286\tUnter\teinem\tBot\t(von\tengl.\trobot \t=\tRoboter)\tversteht\tman\tein\tComputer -\nprogramm,\tdas\tweitgehend\tautomatisch\tsich\twiederholende\tAufgaben\tab-\narbeitet,\tohne\tdabei\tauf\teine\tInteraktion\tmit\teinem\tMenschen\tangewiesen\t\nzu\tsein.\n287\tWojcik\tet\tal.\t2018.269zunehmend homogener wird. Das Ph\u00e4nomen der Filterbla-\nse beschreibt eine potenzielle Verarmung des Themen- und \nMeinungsspektrums im personalisierten Angebot.288 Dahin-\nter steht die Vermutung, dass Empfehlungssoftware, sobald \nsie pers\u00f6nliche Interessen und Vorlieben erkannt hat, vor -\nnehmlich Inhalte pr\u00e4sentiert, die dem Material \u00e4hneln, auf \ndas man zuvor bereits mit erh\u00f6hter Aufmerksamkeit oder \nInteraktionen reagiert hat, w\u00e4hrend andere Inhalte, die weni-\nger offensichtlich in das ermittelte Profil passen, immer st\u00e4r -\nker ausgeschlossen werden. Eine Untersuchung auf Facebook \nzeigte beispielsweise, dass von pers\u00f6nlichen Kontakten geteil-\nte Nachrichten, die von der politischen Position einer Person \nabweichen, nachrangig platziert wurden, sodass sie seltener \nprominent im Newsfeed erschienen, und Inhalte von den im \npers\u00f6nlichen Netzwerk durchaus vorhandenen Menschen mit \nabweichender politischer Auffassung somit benachteiligt dar -\ngestellt wurden.289 In einer Untersuchung von Google-Such-\nergebnissen zu Parteien im Vorfeld der Bundestagswahl 2017 \nkonnten hingegen kaum Personalisierungseffekte bei den Er -\ngebnissen festgestellt werden.290\nEng mit der Metapher der Filterblase verbunden ist das \nKonzept der Echokammer, nach dem die algorithmisch gef\u00f6r -\nderte Homogenisierung des personalisierten Angebots dazu \nf\u00fchrt, dass \u00dcberzeugungen und Meinungen zu kontroversen \nThemen durch st\u00e4ndige Wiederholungen und gegenseitige Be-\nst\u00e4tigung innerhalb eines Netzwerks Gleichgesinnter verst\u00e4rkt \nund verfestigt werden. Dieser Effekt konnte zum Beispiel in \neiner Studie auf den algorithmisch kuratierten Plattformen \nTwitter (zum Thema Schwangerschaftsabbr\u00fcche) und Face-\nbook (zum Thema Impfen und beim Nachrichtenkonsum) \nnachgewiesen werden, nicht jedoch beim Nachrichtenkonsum \nauf der Plattform Reddit, auf der die Reihenfolge von Inhalten \n288\tPariser\t2011.\n289\tBakshy/Messing/Adamic\t2015.\n290\tKrafft/Gamer/Zweig\t2018.270nicht algorithmisch personalisiert wird, sondern davon ab-\nh\u00e4ngt, wie viele Stimmen ein Beitrag von anderen Teilneh-\nmenden einer Diskussion erhalten hat.291\nDas Ausma\u00df und die Wirkung von Filterblasen und Echo-\nkammern sind umstritten und d\u00fcrften sich zwischen verschie-\ndenen Anwendungen und Regionen stark unterscheiden.292 Es \nist also Vorsicht geboten bei zu schnellen Verallgemeinerun-\ngen. Ob und in welchem Ausma\u00df Filterblasen oder Echokam-\nmern entstehen oder verst\u00e4rkt werden, h\u00e4ngt von der verwen-\ndeten Technologie, dem Kontext und den Nutzungsweisen \nab. Ebenso tr\u00e4gt vermutlich die Wahl der jeweiligen metho-\ndischen Ans\u00e4tze bei der Untersuchung solcher Ph\u00e4nomene \ndazu bei, dass es zu unterschiedlichen Einsch\u00e4tzungen kommt. \nAuch der bereits erw\u00e4hnte mangelnde Zugang zu Plattform-\ndaten f\u00fcr die Forschung erschwert solche wissenschaftlichen \nAnalysen zus\u00e4tzlich. Allerdings sind die potenziellen Gefahren \nsolcher informationellen Defizite derart essenziell f\u00fcr demo-\nkratische Meinungs- und Willensbildungsprozesse, dass ihnen \nauch bereits bei unklarer Datenlage entschieden entgegenge-\nwirkt werden sollte.\n7.3.3 Moralische und emotionale Aufladung\nKlarer nachweisen l\u00e4sst sich die zunehmende moralische und \nemotionale Aufladung des Informationsangebots auf vielen \nPlattformen. Sie ist zum einen deshalb zu verzeichnen, weil \nemotionsbehaftete Inhalte grunds\u00e4tzlich mehr Aufmerksam-\nkeit und Reaktionen ausl\u00f6sen und sich so nach aktuell \u00fcblichen \nKuratierungskriterien gut verbreiten. Gerade \u00c4rger und Wut \nverbreiten sich besonders schnell und weit und beziehen sich \nbei \u00f6ffentlichen Plattformen h\u00e4ufig auf politische Inhalte.293 \n291\t Cinelli\tet\tal.\t2021.\n292\tStark/Magin/J\u00fcrgens\t2021;\tDubois/Blank\t2018;\tRau/Stier\t2019.\n293\tFan\tet\tal.\t2014.271Auf Twitter wurde beispielsweise anhand kontroverser, den \nUS-amerikanischen politischen Diskurs pr\u00e4gender Themen \ngezeigt, das Tweets umso h\u00e4ufiger geteilt wurden, je mehr \nmoralisch-emotionale W\u00f6rter wie zum Beispiel \u201eangreifen\u201c, \n\u201eschlecht\u201c oder \u201ebeschuldigen\u201c enthalten waren, und schon \nein einziges solches Wort die Verbreitung um 20 Prozent er -\nh\u00f6hte.294 Mit Blick auf die Videoplattform YouTube konnte \nderweil nachgewiesen werden, dass deren Empfehlungsalgo-\nrithmen im Lauf der Zeit zunehmend extreme Inhalte vor -\nschlagen und der Medienkonsum sich auch entsprechend \nver\u00e4ndert.295\nHinzu kommt, dass besonders gef\u00fchlsbetonte oder inten-\nsive Reaktionen wie beispielsweise ein mehrfaches Hin-und-\nher-Kommentieren von Algorithmen mitunter auch noch \nzus\u00e4tzlich ausdr\u00fccklich positiv gewichtet werden. Die 2018 \nvon Facebook eingef\u00fchrten Neuerungen seiner Gewichtungs-\nkriterien, die laut eigenen Angaben dazu gedacht waren, \u201eGe-\nspr\u00e4che und bedeutungsvolle Interaktionen anzuregen\u201c und \n\u201eMenschen n\u00e4her zusammenzubringen\u201c296, f\u00fchrten beispiels-\nweise dazu, dass fortan Inhalte priorisiert wurden, zu denen \nes besonders viele emotionale Reaktionen und Kommentare \ngab und die h\u00e4ufig geteilt wurden. Nach der Einf\u00fchrung der \n\u00c4nderung stieg die Zahl der Reaktionen und Interaktionen auf \nFacebook schnell erheblich an. Am besten verbreiteten sich al-\nlerdings kontroverse Beitr\u00e4ge, auf die mit dem \u201eWut\u201c-Emoji \nreagiert wurde oder die hitzige Diskussionen ausl\u00f6sten. Die-\nser Trend wurde von Personen und Organisationen, die Face-\nbook zur Kommunikation nutzen, schnell erkannt und f\u00fchr -\nte zu einem teilweise bewussten Wechsel hin zur Produktion \n294\tBrady\tet\tal.\t2017.\tDie\t15\twirkungsvollsten\tmoralisch-emotional\taufgelade-\nnen\tWorte\twaren:\tattack,\tbad,\tblame,\tcare ,\tdestroy,\tfight,\thate ,\tkill,\tmurder,\t\npeace,\tsafe ,\tshame,\tterrorism,\twar \tund\twrong\t(ebd.,\tAppendix\tTabelle\tS3).\n295\tRibeiro\tet\tal.\t2020.\n296\thttps://about.fb.com/news/2018/01/news-feed-fyi-bringing-people-closer-\ntogether\t[12.01.2023].272provokanterer Inhalte, gerade auch im politischen Bereich, \nda sich nur noch so Reichweite erzielen lie\u00df (vgl. Abschnitt \n7.4.1).297\n7.3.4 Relevanz der beobachteten Effekte\nWie weit verbreitet die hier postulierten Effekte auf die Infor -\nmationsqualit\u00e4t sind und welche Relevanz dies f\u00fcr politische \nProzesse hat, kann derzeit nicht abschlie\u00dfend beantwortet \nwerden. Die Bedeutung von Filterblasen und Echokammern \nwird, wie bereits angedeutet, kontrovers diskutiert und mit \nBlick auf Falschinformationen gibt es zahlreiche und teilweise \nvon Plattformen selbst bereitgestellte Werkzeuge und Ange-\nbote, um den Wahrheitsgehalt und die Seriosit\u00e4t von Inhalten \neigenst\u00e4ndig zu pr\u00fcfen. Dem stehen selbstverst\u00e4ndlich zahlrei-\nche positive Auswirkungen der digitalen Transformation f\u00fcr \nden \u00f6ffentlichen Meinungsbildungsprozess entgegen, etwa die \nM\u00f6glichkeit, aus einem weitaus gr\u00f6\u00dferen und diversen, ide-\nalerweise hochwertigen informationellen Angebot zu w\u00e4hlen.\nGleichzeitig erscheint plausibel, dass Falschnachrichten, \nFilterblasen und Echokammern sowie eine emotional-mora-\nlische Zuspitzung vieler Inhalte im regul\u00e4ren Nutzungsalltag \nauf algorithmisch kuratierten Plattformen negative Auswir -\nkungen auf die Informationsqualit\u00e4t haben k\u00f6nnen. Dies gilt \nvor allem in Situationen, in denen Menschen kein spezielles \nErkenntnisinteresse verfolgen, sondern vorwiegend die von \nder Empfehlungssoftware zuvorderst pr\u00e4sentierten Inhalte \nkonsumieren \u2013 erst recht, wenn die Kuratierungsmechanis-\nmen nicht bekannt sind oder nicht aktiv reflektiert werden.\nHinzu kommt, dass selbst wo ein Bewusstsein f\u00fcr potenzi-\nell problematische Effekte vorhanden ist und der Wille besteht, \ndiesen mit dem eigenen Nutzungsverhalten vorzubeugen, die \n297\thttps://www.wsj.com/articles/facebook-algorithm-change-\nzuckerberg-11631654215\t[11.01.2023].273Umsetzung solcher Vors\u00e4tze angesichts der psychologischen \nWirkmacht vieler Plattformangebote sehr schwierig sein kann. \nDie Personalisierung des Informationsangebots, seine soziale \nEinbettung durch Likes, Follower, Kommentare und sonsti-\ngen Reaktionen wie auch die beschriebene Priorisierung von \nInhalten, die besonders \u00fcberraschend oder emotional anre-\ngend sind, sorgen f\u00fcr die fortlaufende Bereitstellung h\u00f6chst \nattraktiver Stimuli f\u00fcr das menschliche Belohnungssystem298, \ndenen man sich nur schwer entziehen kann299 und die unsere \nAufmerksamkeit \u00fcberaus erfolgreich300 und nachhaltig301 be-\nanspruchen. Die Freiheit, qualitativ hochwertige Informatio-\nnen zu finden, wird unter diesen Umst\u00e4nden durch die Wirk-\nmacht der zum Einsatz kommenden Algorithmen praktisch \nvermindert.\n7.4\t\t Diskursqualit\u00e4t\nDie beschriebenen \u00c4nderungen in der Qualit\u00e4t, Darbietung \nund Verbreitung algorithmisch vermittelter Informationen \nver\u00e4ndern auch die Qualit\u00e4t vieler online stattfindender Dis-\nkurse in ethisch wie politisch relevanter Hinsicht. Auch hier \nsind zun\u00e4chst wieder positive Entwicklungen und Potenziale \nzu benennen, die sich insbesondere aus den auf Plattformen \nund in sozialen Medien wesentlich erh\u00f6hten M\u00f6glichkeiten \nzu Teilhabe und direkter Vernetzung ergeben. Angesichts der \nweltweit zunehmenden Verf\u00fcgbarkeit von Onlinezug\u00e4ngen \nund internetf\u00e4higen Endger\u00e4ten ist die Schwelle zur Beteili-\ngung an \u00f6ffentlichen Diskursen f\u00fcr viele Menschen deutlich \ngesunken. Die Kuratierungskriterien auf Plattformen und in \nsozialen Medien geben im Gegensatz zu traditionellen Medi-\nen auch weniger etablierten Akteuren und Institutionen die \n298\tBurhan/Moradzadeh\t2020.\n299\tHe/Turel/Bechara\t2017.\n300\tWard\tet\tal.\t2017.\n301\tMickes\tet\tal.\t2013.274Chance, mit gut formulierten Beitr\u00e4gen sehr viele Personen \ndirekt zu erreichen und \u2013 je nach Plattform \u2013 auch von ein-\nflussreichen Individuen und Organisationen direkt beachtet \nzu werden. Im Journalismus beispielsweise wurden aufgrund \nder erweiterten M\u00f6glichkeiten zur direkten Kontaktaufnahme \nmitunter wesentliche Verbesserungen in der Diskursqualit\u00e4t \nwahrgenommen.302\nManche Diskurse erhalten durch die auf Plattformen und \nsozialen Medien geschaffenen soziotechnischen Infrastruktu-\nren \u00fcberhaupt erst einen Raum, weil es \u00fcber diese Onlinean-\ngebote m\u00f6glich wird, sich mit Menschen mit \u00e4hnlichen Inter -\nessen oder Problemen ortsunabh\u00e4ngig auszutauschen und zu \nvernetzen, auch zu sehr speziellen Themen, zu denen sich lokal \nund offline vielleicht kaum Gelegenheiten zum Diskurs erg\u00e4-\nben. Durch solche Zusammenschl\u00fcsse k\u00f6nnen zudem Anlie-\ngen, die sonst wohl wenig Chancen auf Wahrnehmung h\u00e4tten, \nauch in der breiteren \u00d6ffentlichkeit Beachtung finden. Auch \nPotenziale f\u00fcr die Auseinandersetzung mit Argumenten und \nanderen Positionen werden durch die neuen Diskursm\u00f6glich-\nkeiten zun\u00e4chst einmal erweitert. Wer dies m\u00f6chte, kann mit \nentsprechenden Suchanfragen und Interaktionen auf Plattfor -\nmen und in sozialen Medien die eigenen Horizonte erweitern, \nPotenziale f\u00fcr Perspektivenwechsel entdecken und mehr Ver -\nst\u00e4ndnis und Empathie f\u00fcr Andersdenkende entwickeln.\nInwieweit solche M\u00f6glichkeiten sich in der Praxis entfalten \nk\u00f6nnen, wird allerdings kontrovers beurteilt, denn gegen\u00fcber \nden genannten Chancen werden auch mit Blick auf die Dis-\nkursqualit\u00e4t negative Entwicklungen diskutiert. Dabei geht \nes vor allem um drei Themen. Das erste betrifft die Frage, ob \nund inwieweit Plattformen und soziale Medien zu einer in den \nletzten Jahren beobachteten zunehmenden politischen Pola-\nrisierung \u00f6ffentlicher Diskurse beitragen. Das zweite Thema \nber\u00fchrt Praktiken der politischen Werbung und Manipulation \n302\thttps://www.theguardian.com/technology/2022/nov/30/twitter-\njournalism-elon-musk\t[12.01.2023].275und wie diese sich aufgrund der neuen, algorithmisch vermit-\ntelten Kommunikationsm\u00f6glichkeiten ver\u00e4ndern. Ein dritter \nDiskussionsschwerpunkt gilt Kontroversen um Diskursverro-\nhungen mit Hassrede und \u00e4hnlichen Integrationsverletzungen \nauf der einen und \u00fcberbordenden Eingriffen in die \u00c4u\u00dfe-\nrungs- und Meinungsfreiheit auf der anderen Seite.\nAlle drei Themen beschreiben komplexe Ph\u00e4nomene, die \nes zweifelsohne nicht erst seit Beginn der digitalen Transfor -\nmation des \u00f6ffentlichen Diskurses gibt und die sowohl mul-\ntifaktoriell bedingt als auch in ihrem Facettenreichtum oft \nschwer einheitlich fassbar sind. Indizien, dass sich aktuelle \nTrends in der technisch mediierten \u00f6ffentlichen Kommunika-\ntion \u00fcber Plattformen und soziale Medien in diesen Bereichen \nauf die Diskursqualit\u00e4t auswirken, sind vor dem Hintergrund \ndieser Komplexit\u00e4t zu betrachten und sollten daher nicht zu \nvorschnellen Schl\u00fcssen \u00fcber urs\u00e4chliche Zusammenh\u00e4nge \nverleiten.\n7.4.1 Politische Polarisierung\nEs gibt zahlreiche Hinweise, dass der in Abschnitt 7.3.1 be-\nschriebene Umstand, dass emotional und moralisch aufgela-\ndene Inhalte sich auf Plattformen besonders schnell und weit \nverbreiten, zu Tonfallverschiebungen gef\u00fchrt hat, auch und \ninsbesondere auf vielen Kan\u00e4len, die aktiv zur Gestaltung des \npolitischen Diskurses beitragen. Im Zuge der Enth\u00fcllungen \nder \u201eFacebook Files\u201c durch das Wall Street Journal wurde ab \nSeptember 2021 eine Reihe von Belegen ver\u00f6ffentlicht303, dass \nKommunikationsteams im Bereich Politik sich nach den 2018 \neingef\u00fchrten \u00c4nderungen im Facebook-Algorithmus auch ge-\nzielt zunehmend provokanteren und negativen Inhalten und \nKommunikationsstilen zuwandten und dass Facebook sich \ndessen bewusst war (siehe Infokasten 8).\n303\thttps://www.wsj.com/articles/the-facebook-files-11631713039\t[11.01.2023].276Infokasten\t8:\t\u201eThe\tFacebook\tFiles\u201c\t\u2013\tVerminderung\tder\t\nKommunikationsfreiheit\tdurch\talgorithmische\tFormatierung\nAb\tSeptember\t 2021\tver\u00f6ffentlichte\t das\tWall\tStreet\tJournal\teine\tArtikelserie,\t\ndie\tsogenannten\t \u201eFacebook\t Files\u201c,\tin\tder\tauf\tGrundlage\t von\tInformationen\t\nder\tWhistleblowerin\t Frances\t Haugen\t zahlreiche\t Details\tdar\u00fcber\t enth\u00fcllt\t\nwurden,\t in\twelchem\t Ausma\u00df\t Facebook\t gesellschaftlich\t bedenkliche\t Auswir-\nkungen\tseiner\tProdukte\t bekannt\t waren.\tDabei\tging\tes\tauch\tdarum,\twie\tdie\t\nim\tJahr\t2018\tvorgenommenen\t \u00c4nderungen\t der\tFacebook-Algorithmen\t dazu\t\nbeigetragen\thaben,\tden\tpolitischen\tDiskurs\tzu\tpolarisieren.304\nNach\tder\tEinf\u00fchrung\t neuer\tGewichtungskriterien,\t die\turspr\u00fcnglich\t zur\tF\u00f6r-\nderung\t\u201ebedeutungsvoller\t Interaktionen\u201c\t konzipiert\t worden\twaren,\tstellte\t\nsich\tbald\theraus,\tdass\tfortan\tvor\tallem\tsolche\tInhalte\terfolgreich\t waren,\tauf\t\ndie\tMenschen\t besonders\t aufgebracht\t reagierten,\t etwa\tweil\tsie\tbesonders\t\nprovokant\t oder\tschockierend\t wirkten\toder\tThemen\t behandelten,\t zu\tdenen\t\nes\tausgepr\u00e4gte\t emotionale\t Kontroversen\t gab\t(vgl.\tAbschnitt\t 7.3.3).\tDiese\t\nVerschiebung\t fiel\tbald\tauch\tdenjenigen\t auf,\tdie\t\u00fcber\tFacebook\t einen\tGro\u00df-\nteil\tihrer\t\u00f6ffentlichen\t Kommunikation\t abwickelten\t und\tdaher\tdarauf\tange-\nwiesen\twaren,\t\u00fcber\tdie\tPlattform\tReichweite\tzu\terzielen.\nGerade\tim\tpolitischen\t Bereich\tgab\tes\tlaut\tdem\tinternen\t Facebook-Bericht\t\n\u201ePolitical\t Party\tResponse\t to\t\u201918\tAlgorithm\t Change\u201c\t entsprechende\t Beob-\nachtungen\t und\tdaran\tangepasste\t \u00c4nderungen\t in\tder\tKommunikationsstra-\ntegie\thin\tzu\t\u201eprovokativen\t Inhalten\t von\tniedriger\t Qualit\u00e4t\u201c\t (im\tenglischen\t\nOriginal:\t \u201eprovocative,\t low-quality\t content\u201c).\t Die\tReichweite\t positiver\t\nund\tsachlicher\t Beitr\u00e4ge\t hatte\tsich\tnach\tAngaben\t aus\tden\tKommunikati-\nonsteams\t politischer\t Parteien\t aus\tverschiedenen\t L\u00e4ndern\t deutlich\t redu-\nziert,\tw\u00e4hrend\t hetzerische\t Inhalte\tund\tdirekte\tAngriffe\t auf\tdie\tpolitische\t\nKonkurrenz\t erfolgreich\t liefen.\tDas\tSocial-Media-Team\t einer\tpolnischen\t\nPartei\tbeispielsweise\t sch\u00e4tzte,\t dass\tes\tden\tTenor\tseiner\tInhalte\tvon\teiner\t\nzuvor\tausgewogenen\t Balance\t zwischen\t positiven\t und\tnegativen\t Beitr\u00e4-\ngen\tinfolge\tder\tneuen\talgorithmischen\t Auswahlkriterien\t zu\t80\tProzent\t in\t\nRichtung\t negative\t Beitr\u00e4ge\t ver\u00e4ndert\t hatte,\tum\tweiterhin\t Reichweite\t zu\t\nerzielen.\t \u00c4hnliche\t Angaben\t machten\t dem\tBericht\tzufolge\tunter\tanderem\t\nParteien\t aus\tSpanien,\t Taiwan\tund\tIndien,\tverbunden\t mit\tBeschwerden\t aus\t\nden\tKommunikationsteams,\t die\tdiese\tEntwicklung\t als\tnegativ\tund\tdemo-\nkratiegef\u00e4hrdend\t einsch\u00e4tzten\t \u2013\tsich\taber\tgleichwohl\t au\u00dferstande\t sahen,\t\nsich\tihr\tzu\tentziehen.\nErw\u00e4hnenswert\t ist\tweiterhin,\t dass\tdie\tGesch\u00e4ftsleitung\t einschlie\u00dflich\t Mark\t\nZuckerberg\t nach\tden\tBelegen\t der\tWhistleblower\t auch\tnach\tOffenlegung\t\nder\tbedenklichen\t Zusammenh\u00e4nge\t Ma\u00dfnahmen\t zu\tderen\tEntsch\u00e4rfung\t mit\t\nVerweis\tauf\tdie\tPriorisierung\t\u00f6konomischer\tInteressen\tablehnte.\nHieran\tkn\u00fcpfen\t sich\tzahlreiche\t Fragen\tzur\tVerantwortung\t von\tInternet-\nfirmen\tf\u00fcr\tdas\tGemeinwohl,\t die\tim\tweiteren\t Text\tnoch\tn\u00e4her\tbeleuchtet\t\nwerden.\n304\thttps://www.wsj.com/articles/facebook-algorithm-change-\nzuckerberg-11631654215\t[11.01.2023].\tAlle\tweiteren\tAngaben\tin\tdiesem\t\nInfokasten\tstammen\taus\tdiesem\tArtikel.277Durch die algorithmische Konfigurierung und die sich dar -\naus ergebenden Wechselwirkungen zwischen Menschen und \nalgorithmischen Systemen ergaben sich hier also f\u00fcr die am \nDiskurs teilnehmenden Personen und Organisationen ver -\nminderte Handlungsspielr\u00e4ume mit negativen Auswirkungen \nauf die Diskursqualit\u00e4t. Aus den Facebook-Dokumenten geht \nzudem hervor, dass die Auswirkungen von \u00c4nderungen in \nden Algorithmen auch f\u00fcr die intern bei Facebook an den Pro-\ngrammier- und Entscheidungsprozessen Beteiligten mitunter \nschwer abzusch\u00e4tzen waren. Dies unterstreicht die Komplexi-\nt\u00e4t der online entstandenen soziotechnischen Systeme, die zu \n\u00fcberraschenden R\u00fcckwirkungen auf menschliches Handeln \nf\u00fchren kann.\nDie Beobachtung, dass auf Polarisierung ausgelegte Inhalte \nerfolgreicher sind, sendet deutliche Signale an alle, die poli-\ntisch kommunizieren. Erh\u00f6hte Chancen auf virale Verbrei-\ntung durch die Verwendung einer moralisierenden Sprache, \ndie Emp\u00f6rung \u00fcber die politische Gegenseite ausl\u00f6st305, fallen \nauch denjenigen auf, die f\u00fcr Kommunikationsstrategien ver -\nantwortlich sind und den Erfolg ihrer Kampagnen analysieren. \nDie M\u00f6glichkeit, mithilfe der von den Plattformen bereitge-\nstellten Analysetools sehr schnell R\u00fcckmeldung zur Effektivi-\nt\u00e4t der eigenen Kommunikation zu erhalten, f\u00f6rdert die st\u00e4n-\ndige Optimierung dieser Effektivit\u00e4t nach den Kriterien der \nPlattform und treibt selbst nach Einsch\u00e4tzung von Personen, \ndie aktiv an solchen Optimierungsversuchen mitwirken, eine \nung\u00fcnstige Polarisierung des politischen Diskurses voran.306\nEine postulierte Spaltung der \u00d6ffentlichkeit findet ange-\nsichts dieser Beobachtungen wom\u00f6glich weniger deswegen \nstatt, weil m\u00f6gliche Filterblaseneffekte Inhalte und Argumente \nvon au\u00dferhalb des personalisierten Pr\u00e4ferenzenprofils aus-\nschlie\u00dfen und zu fragmentierten Diskursen f\u00fchren; vielmehr \n305\tF\u00fcr\tTwitter\tvgl.\tetwa\tBrady\tet\tal.\t2017.\n306\thttps://www.humanetech.com/podcast/53-how-political-language-is-\nengineered\t[11.01.2023].278f\u00fchrt nach dieser Deutung die Priorisierung emotional und \nmoralisch aufgeladener Kommunikation gerade zu einer st\u00e4n-\ndigen Konfrontation mit Inhalten und Argumenten von als \ngegnerisch wahrgenommenen Gruppen, die auf Grundlage \ndes eigenen personalisierten Pr\u00e4ferenzenprofils als bedroh-\nlich, verwerflich oder anderweitig abzulehnend pr\u00e4sentiert \nwerden.307 Eine versch\u00e4rfte Polarisierung und Radikalisierung \nvon Positionen und Befindlichkeiten geht demnach vor allem \nauf diese andauernde Reibung zur\u00fcck, mit dem Ergebnis, dass \ndie Bereitschaft zum offenen, rationalen und wohlwollenden \nDiskurs stark eingeschr\u00e4nkt wird und die Spielr\u00e4ume f\u00fcr de-\nmokratisches Zusammenwirken im Sinne eines gemeinsamen \n\u00f6ffentlichen Vernunftgebrauchs sich damit vermindern.\nSolche unterschiedlichen Erkl\u00e4rungsans\u00e4tze k\u00f6nnen auch \nauf der empirischen Ebene zu unterschiedlichen und mitunter \nwiderspr\u00fcchlichen Resultaten f\u00fchren. Um m\u00f6glichen Mecha-\nnismen genauer auf den Grund zu gehen, erscheint daher auch \nin diesem Kontext mehr multimethodische Forschung emp-\nfehlenswert, f\u00fcr die auch in diesem Fall wiederum ein besserer \nZugang zu Plattformen und ihren Daten notwendig w\u00e4re.\nVorerst bleibt aufgrund der noch unzureichenden Stu-\ndienlage umstritten, welche Rolle algorithmisch mediierte \nKommunikationsprozesse f\u00fcr eine beobachtete oder vermu-\ntete gesellschaftliche Diskursversch\u00e4rfung spielen. Angesichts \nvielf\u00e4ltiger weiterer Einfluss- und \u00c4nderungsfaktoren, die auf \npolitisch relevante Situationen, Prozesse und Befindlichkeiten \nwirken k\u00f6nnen, gibt es sicherlich zahlreiche weitere Ursachen \nhierf\u00fcr, die nicht prim\u00e4r an der besonderen Qualit\u00e4t technisch \nvermittelter Diskurse liegen. Sie k\u00f6nnen jedoch im Rahmen \nsolcher Diskurse aufgegriffen werden und Verst\u00e4rkereffekte \nerfahren.\n307\tT\u00f6rnberg\t2022.2797.4.2 Politische Werbung und Manipulation\nAngesichts der zunehmenden Bedeutung von sozialen Medien \nund Plattformen bei politischen Auseinandersetzungen stehen \nneben den beschriebenen Polarisierungstendenzen auf offiziel-\nlen Kan\u00e4len auch weitere, mitunter im Verborgenen laufende \nAktivit\u00e4ten zur Beeinflussung politischer Prozesse in der Dis-\nkussion. Nun sind Versuche, die \u00f6ffentliche Meinung durch \nwahrhaftige und unwahrhaftige, wahre und falsche Behaup-\ntungen und Stellungnahmen zu ver\u00e4ndern, ein uraltes Ph\u00e4no-\nmen der Politik, das schon f\u00fcr die antiken Vorformen der mo-\ndernen Demokratie in Griechenland und Rom eine wichtige \nRolle spielte. Auch damals war nicht immer klar, wer mit wel-\nchen Absichten welche Behauptungen in die Welt gesetzt hatte \nund warum sich diese und nicht jene zu einer umfassenden \nVerleumdungskampagne auswuchs. Durch die Digitalisierung \nder Kommunikation versch\u00e4rft sich die Problematik allerdings \ninsofern, als die Zahl kommunikativer Akte nicht begrenzt ist \nund ihre Kosten minimal sind. So erweitern sich einerseits die \nHandlungs- und Gestaltungsm\u00f6glichkeiten f\u00fcr diejenigen, die \nan politischen Kommunikationskampagnen mitwirken. Kom-\nbiniert mit der Funktionsweise sozialer Medien und Plattfor -\nmen, die sowohl eine besonders genaue Personalisierung von \nInhalten und \u00dcberpr\u00fcfung ihrer Effektivit\u00e4t erm\u00f6glicht als \nauch die Verbreitung polarisierender, persuasiver, emotions-\nbetonter und moralisierender Botschaften f\u00f6rdert, ergibt sich \nzudem viel Potenzial f\u00fcr besonders wirkm\u00e4chtige Kommu-\nnikationskampagnen, die eingebettet in den digitalen Alltag \nablaufen, ohne dass die von solchen Kampagnen erreichten \nPersonen sich dessen gewahr werden. Dies vermindert jedoch \nandererseits die Freiheit der von diesen Kampagnen adressier -\nten Personen, politische Werbung zu erkennen und sich be-\nwusst damit auseinanderzusetzen.\nDie in diesem Zusammenhang relevanten Entwicklungen \ngehen auf die gleichen Mechanismen zur\u00fcck, die bereits in \nAbschnitt 7.2 als grundlegend f\u00fcr die Funktionsweise und das 280Gesch\u00e4ftsmodell sozialer Medien beschrieben wurden. Auf \nBasis der reichhaltigen datenbasierten Profile, die sich aus den \ndigitalen Spuren, die man bei der Nutzung von Plattformen \nhinterl\u00e4sst, erstellen lassen, kann man nicht nur konsumrele-\nvante Interessen extrahieren, um das Schalten personalisierter \nkommerzieller Werbung zu erm\u00f6glichen, sondern auch psy-\nchologische Merkmale und politische Neigungen sehr pr\u00e4zise \nableiten.308 Hier besteht die Gefahr, dass solche Informationen \nmanipulativ eingesetzt werden, um beispielweise zielgenaue \npolitische Werbung zu schalten (Targeted Advertisement) \noder um die W\u00e4hlerschaft, deren Interessen der politischen \nKonkurrenz zuneigen, strategisch zu desinformieren oder von \nder Wahl abzuhalten. Unternehmen wie die bis 2018 operie-\nrende Datenanalyse- und Beraterfirma Cambridge Analytica \nverfolgen ausdr\u00fccklich das Ziel, aus dem Nutzungsverhalten \nund sonstigen Datenspuren politische Pers\u00f6nlichkeits- und \nInteressenprofile zu erstellen und mit deren Hilfe f\u00fcr bestimm-\nte Gruppen oder Individuen ma\u00dfgeschneiderte Botschaften zu \nverbreiten (Microtargeting), um politische Meinungsbildungs-\nprozesse und Wahlen zu beeinflussen (siehe Infokasten 9).\nInfokasten\t9:\tCambridge\tAnalytica\nDas\tUnternehmen\t Cambridge\t Analytica\t wurde\t2013\tgegr\u00fcndet,\t um\tpoli-\ntische\tKampagnen\t mit\teiner\tMischung\t aus\tdatenbasierter\t Verhaltensfor -\nschung\tund\tstrategischer\t Kommunikation\t zu\tunterst\u00fctzten.\t Seine\tKund-\nschaft\tkam\tvornehmlich\t aus\tdem\tkonservativen\t Spektrum,\t darunter\t die\t\ndamaligen\t US-Pr\u00e4sidentschaftskandidaten\t Donald\t Trump\tund\tTed\tCruz.\t\nDie\tFirma\tbeanspruchte,\t mit\tihren\tAlgorithmen\t besonders\t pr\u00e4zise\tpsycho-\nlogische\t Einsch\u00e4tzungen\t von\tEinzelpersonen\t aus\tderen\tNutzungsdaten\t\nableiten\t zu\tk\u00f6nnen\t und\tdiese\tf\u00fcr\teinen\tpsychografisch\t personalisierten\t\nZuschnitt\t politischer\t Botschaften\t nutzbar\tzu\tmachen\t \u2013\tein\tAnsatz,\tdessen\t\nWirksamkeit\t nie\teindeutig\t nachgewiesen\t und\tvon\tCambridge\t Analytica\t ver-\nmutlich\t \u00fcberspitzt\t dargestellt\t wurde,\tum\tdas\tInteresse\t am\tUnternehmen\t\nzu\tsch\u00fcren.\nDie\tFirma\tverwendete\t in\tihren\tKampagnen\t aber\tauch\tMethoden,\t die\tohne\t\ndie\tBer\u00fccksichtigung\t aufwendiger\t psychografischer\t Profile\tauskommen,\t\nsondern\t stattdessen\t schlicht\t die\tWahlmotivation\t bestimmter\t ethnischer\t\n308\tKosinski/Stillwell/Graepel\t2013;\tMatz/Appel/Kosinski\t2020.281oder\tdemografischer\t Gruppen\t zu\tsenken\tversuchten.\t Im\tUS-Pr\u00e4sident -\nschaftswahlkampf\t 2016\tbeispielsweise\t nutzte\tCambridge\t Analytica\t Infor-\nmationen\t aus\tFacebook-Profilen,\t um\tafroamerikanischen\t Menschen,\t von\t\ndenen\tauf\tGrundlage\t vorheriger\t Wahlergebnisse\t zu\terwarten\t war,\tdass\tsie\t\nihre\tStimme\tmit\thoher\tWahrscheinlichkeit\t den\tDemokraten\t geben,\tgezielt\t\nnegative\t Inhalte\t\u00fcber\tTrumps\t Konkurrentin\t Hillary\tClinton\t anzuzeigen,\t\nbeispielsweise\t ein\tVideoclip\t aus\tdem\tJahr\t1996,\tin\tdem\tsie\tkriminelle\t afro-\namerikanische\t Jugendliche\t angeblich\t als\t\u201eSuperraubtiere\u201c\t bezeichnete.309 \nBesonders\t der\tUmstand,\t dass\tdiese\tKampagnen\t oft\tganz\toder\tteilweise\t im\t\nVerborgenen\t abliefen,\t ohne\tdass\tAuftraggebende\t die\tBeauftragung\t offen-\nlegten\toder\tBetroffene\t wussten,\t dass\tsie\tZiele\tpersonalisierter\t politischer\t\nWerbung\twaren,\twird\tals\tdemokratiegef\u00e4hrdend\tgewertet.310\n2018\tgab\tder\tWhistleblower\t Chris\tWylie\tin\tInterviews\t bekannt,\t dass\tgro-\n\u00dfe\tTeile\tder\tDatenbasis\t von\tCambridge\t Analytica\t missbr\u00e4uchlich\t ohne\t\nEinwilligung\t der\tNutzenden\t beschafft\t worden\t waren.\tHierf\u00fcr\t war\teine\t\nFragebogen-App\t f\u00fcr\tFacebook-Nutzende\t entwickelt\t worden,\t die\tnicht\tnur\t\ndie\tDaten\tvon\tTeilnehmenden\t sammelte,\t sondern\t unbekannterweise\t auch\t\nvon\tden\tProfilen\t aus\tihrem\tpers\u00f6nlichen\t Netzwerk.311\tDies\tl\u00f6ste\teine\tbreite\t\n\u00f6ffentliche\t Diskussion\t \u00fcber\tSicherheit\t und\tZugang\tzu\tden\tDaten\tin\tsozialen\t\nNetzwerken\t sowie\tdie\tLegitimit\u00e4t\t personalisierter\t politischer\t Werbung\t aus.\t\n2020\tfolgten\tweitere\t Enth\u00fcllungen\t von\tder\tehemaligen\t Cambridge-Ana-\nlytica-Mitarbeiterin\t Brittany\t Kaiser,\tdie\t\u00fcber\tTwitter\tzahlreiche\t Dokumente\t\nver\u00f6ffentlichte,\t die\teine\tEinflussnahme\t des\tUnternehmens\t auf\tWahlen\tund\t\nPolitik\tin\t68\tL\u00e4ndern\tbelegten.312\nWie erfolgreich personalisierte politische Werbung mit Mi-\ncrotargeting-Ans\u00e4tzen tats\u00e4chlich sein kann, ist zwar umstrit-\nten bzw. noch nicht hinreichend erforscht.313 Es gibt jedoch \ndeutliche Hinweise darauf, dass schon die akzentuierte Kon-\nfrontation mit bestimmten Inhalten politische Meinungen \nbeeinflussen kann. In Experimenten konnte beispielsweise \ngezeigt werden, dass die Reihenfolge, in der Suchmaschinen \nErgebnisse pr\u00e4sentieren, wenn politisch noch unentschiede-\nne Personen online Informationen \u00fcber Kandidatinnen und \nKandidaten suchen, entscheidend auf die Meinungsbildung \n309\thttps://www.channel4.com/news/revealed-trump-campaign-strategy-to-\ndeter-millions-of-black-americans-from-voting-in-2016\t[11.01.2023].\n310\tKaiser\t2020.\n311\t https://www.theguardian.com/news/2018/mar/17/data-war-whistleblower-\nchristopher-wylie-faceook-nix-bannon-trump\t[11.01.2023].\n312\t https://www.theguardian.com/uk-news/2020/jan/04/cambridge-analytica-\ndata-leak-global-election-manipulation\t[16.01.2023].\n313\t Bod\u00f3/Helberger/de\tVreese\t2017.282auswirkt, da weiter oben platzierte Ergebnisse als bedeutsamer \neingestuft werden.314 Allein das Wissen darum, dass versucht \nwird, auf Grundlage sehr pers\u00f6nlicher psychologischer Merk-\nmale politische Pr\u00e4ferenzen zu manipulieren, kann zudem \nplausibel negative Effekte auf den politischen Diskurs und das \nVertrauen in politische Meinungsbildungsprozesse entfalten.\nVertrauenssch\u00e4digend kann sich weiterhin der Umstand \nauswirken, dass zur strategischen Beeinflussung des \u00f6ffent-\nlichen politischen Diskurses auch vielfach unechte Profile \n(Fake-Accounts) eingesetzt werden, die teilweise automatisiert \nbetrieben werden (Bots). In einer investigativen Recherche \ntrug die New York Times hierzu vielf\u00e4ltige Daten zusammen, \nnach denen beispielsweise bis zu 27 Prozent der Beitr\u00e4ge auf \nFacebook und Twitter im Zusammenhang mit den Wahlen \nin Mexiko im Jahr 2018 von Bots und Fake-Accounts stamm-\nten315 und Chinas staatliche Nachrichtenagentur Xinhua hun-\nderttausende falsche Profile und Retweets bezahlte, die In-\nhalte gezielt an westliche Twitter-Konten schicken316. In einer \nAnh\u00f6rung vor dem US-Senat zum Einfluss Russlands auf die \nPr\u00e4sidentschaftswahl im Jahr 2016 legten die Vertreter von \nFacebook, Twitter und Google offen, dass etliche Personen in \nden USA \u00fcber k\u00fcnstliche Profile mit Inhalten der russischen \n\u201eAgentur f\u00fcr Internetforschung\u201c Glavset konfrontiert worden \nwaren, darunter ca. 150 Millionen Personen allein \u00fcber Inhalte \nauf Facebook und Instagram.317\nAuch die Wirkmacht von Fake-Accounts und Bots auf po-\nlitische Prozesse ist umstritten und l\u00e4sst sich oft schwer pr\u00e4zise \nfassen. Schon die Identifikation unechter Profile stellt eine sich \nst\u00e4ndig fortentwickelnde Herausforderung dar.318 Es gibt je-\ndoch zahlreiche Hinweise, dass Kommunikationskampagnen \n314\t Epstein/Robertson\t2015.\n315\t https://www.nytimes.com/2018/05/01/world/americas/mexico-election-\nfake-news.html\t[12.01.2023].\n316\t https://www.nytimes.com/interactive/2018/01/27/technology/social-\nmedia-bots.html\t[12.01.2023].\n317\t Stretch,\tin:\tUnited\tStates\tSenate\t2018,\t58.\n318\t Ferrara\tet\tal.\t2016.283\u00fcber Fake-Accounts zumindest das Potenzial f\u00fcr eine hohe \nEffektivit\u00e4t haben. So demonstrierte eine experimentelle Stu-\ndie, dass wenige strategisch gut platzierte Bots, die extreme \nBotschaften verbreiten, nach aktuellen Kuratierungskriterien \n\u00fcberdurchschnittlich erfolgreich auf Entscheidungen Einfluss \nnehmen k\u00f6nnen.319 In einer Untersuchung von \u00fcber 240 Mil-\nlionen Tweets zur US-Pr\u00e4sidentschaftswahl im Jahr 2020 wur -\nde deutlich, dass wenige tausend Bots genauso viele Spitzen \nim Kommunikationsgeschehen zu aktuellen politischen The-\nmen verursachten wie die Konten echter Menschen, und das \nvorwiegend, indem sie lediglich \u00fcber Retweets als Verst\u00e4rker \nbestimmter Botschaften wirkten und ihnen somit mehr \u00dcber -\nzeugungskraft verliehen.320 Mit solchen Verst\u00e4rkereffekten \nk\u00f6nnen Diskurse problematisch verzerrt werden, sodass sie \nnicht mehr das Interesse oder die Ansichten der an ihnen be-\nteiligten Menschen spiegeln. Verunsicherungen und der Ver -\nlust des Vertrauens in den Diskursprozess selbst k\u00f6nnen die \nFolge sein, wenn die Legitimit\u00e4t der Diskurse und die Identit\u00e4t \nder Teilnehmenden zunehmend bezweifelt werden.\nDass solche Zweifel berechtigt sein k\u00f6nnen, zeigen Analy-\nsen, die nachweisen, dass mit unechten Profilen im Rahmen \nder Funktionsweise eines sozialen Netzwerks auch langfris-\ntige Strategien zur subtilen Beeinflussung verfolgt werden. \nHier werden beispielsweise zun\u00e4chst \u00fcber l\u00e4ngere Zeitr\u00e4ume \nReichweite und Netzwerke mit unpolitischen Inhalten wie \nhumorvollen Memes (Text- und Bildmontagen) zu identi-\nt\u00e4tsstiftenden Themen wie Familie, Mode oder lokale Kultur \naufgebaut. Erst sp\u00e4ter oder nur punktuell werden Botschaf-\nten solcher Konten um politische Inhalte angereichert, in \noft subtiler Weise und stark aufbauend auf zuvor etablierten \nGruppenidentit\u00e4ten.321\n319\t Stewart\tet\tal.\t2019.\n320\tFerrara\tet\tal.\t2020.\n321\t DiResta\tet\tal.\t2019;\tBradshaw/DiResta/Miller\t2022;\tBradshaw/Henle\t2021.2847.4.3 Spannungsfeld Diskursverrohung und \n\u00c4u\u00dferungsfreiheit\nIm Zusammenhang mit den beschriebenen Beobachtungen \nzur Versch\u00e4rfung von Tonlagen auf Plattformen und in sozi-\nalen Medien wird h\u00e4ufig die Annahme vorgebracht, dass die-\nser Trend auch zu einer Verrohung des politischen Diskurses \nbeitragen kann. Besorgniserregend ist hier insbesondere die \nZunahme stark negativ und aggressiv gepr\u00e4gter Kommunika-\ntionsstile bis hin zu Hassrede, Drohungen und Aufforderung \nzu Gewalt. Regelm\u00e4\u00dfige Untersuchungen der Landesanstalt \nf\u00fcr Medien NRW zur Hassrede im Internet zeigen, dass die \nWahrnehmung von Hasskommentaren seit 2016 zugenom-\nmen hat und seit 2018 auf unver\u00e4ndert hohem Niveau ver -\nharrt.322 Ans\u00e4tze zur Moderation von Inhalten hinken dieser \nEntwicklung h\u00e4ufig hinterher. Laut den vom Wall Street Jour -\nnal in den \u201eFacebook Files\u201c dargestellten Enth\u00fcllungen sch\u00e4t-\nzen Facebook-Angestellte beispielsweise den Erfolg ihrer Be-\nm\u00fchungen, Hassbotschaften mit algorithmischen Methoden \nzu identifizieren und einzud\u00e4mmen, als \u00fcberaus unzureichend \nein, mit Erfolgsquoten im niedrigen einstelligen Bereich.323\nDie blo\u00dfe Existenz solcher Inhalte ist bereits f\u00fcr sich ge-\nnommen problematisch, da Geh\u00e4ssigkeit, Verleumdungen \nund Einsch\u00fcchterungen auf sozialen Medien so viel Unbeha-\ngen und Angst sch\u00fcren k\u00f6nnen, dass dies Personen davon ab-\nh\u00e4lt, ihre Meinung zu \u00e4u\u00dfern, im Internet pr\u00e4sent zu sein oder \nsich am \u00f6ffentlichen Diskurs zu beteiligen. Man spricht auch \nhier von Chilling-Effekten, die diskriminierend auf Betroffe-\nne wirken und deren Freiheit und Handlungsm\u00f6glichkeiten \nin der Onlinekommunikation erheblich vermindern k\u00f6nnen \n(vgl. Abschnitt 6.4).\n322\tLandesanstalt\tf\u00fcr\tMedien\tNRW\t2020;\t2022.\n323\thttps://www.wsj.com/articles/facebook-ai-enforce-rules-engineers-\ndoubtful-artificial-intelligence-11634338184\t[12.01.2023].285Hinzu kommt die Gefahr, dass online verbreitete Hetze in \nbedrohliche Handlungen in der realen Welt umschl\u00e4gt. Auch \nwenn kausale Zusammenh\u00e4nge im Einzelfall schwer nach-\nweisbar sein m\u00f6gen, gibt es gen\u00fcgend Korrelationen zwischen \nsolchen Vorf\u00e4llen, sodass diese Sorge gerechtfertigt erscheint \nund jedenfalls plausibel zu den genannten Chilling-Effekten \nbeitr\u00e4gt. So wurden die 2017 an den Rohingya in Myanmar \nver\u00fcbten Massaker durch zahlreiche Hassbotschaften und Ge-\nwaltaufrufe auf Facebook befeuert, das zu diesem Zeitpunkt \naufgrund seiner kostenlosen Nutzbarkeit \u00fcber die Mobilfunk-\nnetze monopolartig den Zugang der Bev\u00f6lkerung zum Internet \ndarstellte. Die Bem\u00fchungen des Konzerns, diese problemati-\nschen Inhalte zu moderieren, wurden auch hier weitgehend als \nunzureichend eingestuft.324 \u00c4hnliche Vorw\u00fcrfe \u00fcber die Rolle \nFacebooks bei ethnisch motivierter Gewalt werden beispiels-\nweise im Zusammenhang mit dem B\u00fcrgerkrieg in \u00c4thiopien325 \nund religi\u00f6s motivierter Gewalt in Indien326 diskutiert.\nIn einer westlichen Demokratie wurde das demokratiege-\nf\u00e4hrdende Potenzial von online verbreiteten Entr\u00fcstungsst\u00fcr -\nmen am deutlichsten augenf\u00e4llig, als in den USA im Januar \n2021 zahlreiche Personen, die die Niederlage des abgew\u00e4hl-\nten Pr\u00e4sidenten Donald Trump nicht anerkennen wollten, \nnach Befeuerung in den sozialen Medien \u2013 unter anderem \ndurch Trump selbst \u2013 das Kapitol st\u00fcrmten, um den Senat und \ndas Repr\u00e4sentantenhaus an der f\u00f6rmlichen Best\u00e4tigung des \nWahlsieges von Joe Biden bei der Pr\u00e4sidentschaftswahl 2020 \nzu hindern. Eine Reaktion auf dieses Ereignis, bei dem f\u00fcnf \nMenschen starben und zahlreiche weitere verletzt wurden, \nwar die Deaktivierung von Trumps Accounts auf Facebook \nund Twitter durch die entsprechenden Plattformbetreiber. Die \n324\thttps://www.reuters.com/investigates/special-report/myanmar-facebook-\nhate\t[12.01.2023].\n325\thttps://www.theguardian.com/technology/2022/feb/20/facebook-lets-\nvigilantes-in-ethiopia-incite-ethnic-killing\t[12.01.2023].\n326\thttps://www.wsj.com/articles/facebook-services-are-used-to-spread-\nreligious-hatred-in-india-internal-documents-show-11635016354\t[12.01.2023].286internen Entscheidungsprozesse bei Twitter zur Moderation \nvon Inhalten und Konten im Umfeld dieser Ereignisse wur -\nden nach der \u00dcbernahme des Konzerns durch Elon Musk im \nRahmen der \u201eTwitter Files\u201c ab Dezember 2022 ver\u00f6ffentlicht \nund teils kritisch beurteilt.327 Solche Reaktionen werfen ihrer -\nseits demokratietheoretische Fragen auf. M\u00fcssen und sollen \nwir es hinnehmen, dass gro\u00dfe private Anbieter, die teilweise \neine monopolistische Stellung auf den Medienm\u00e4rkten haben, \nentscheiden, wer in den sozialen Medien zu Wort kommen \nkann und wer nicht? Wollen wir, dass Community-Standards, \ndie von privaten Medien intern festgelegt werden, die For -\nmen der Kommunikation auch jenseits rechtlicher Vorgaben \nbestimmen?\nDer Umgang mit solchen Fragen gestaltet sich schwierig, da \nhier zwei normativ relevante Gesichtspunkte einander gegen-\n\u00fcberstehen. Auf der einen Seite k\u00f6nnen \u00fcberm\u00e4\u00dfige L\u00f6schun-\ngen und Sperrungen (Overblocking) einen Eingriff in die Mei-\nnungs- und Pressefreiheit darstellen. Overblocking kann selbst \nzu Chilling-Effekten beitragen, n\u00e4mlich dann, wenn Menschen \nbestimmte Inhalte gar nicht erst ver\u00f6ffentlichen, weil sie be-\nf\u00fcrchten, dass diese gleich wieder gel\u00f6scht werden und ihrem \nKonto Einschr\u00e4nkungen drohen. Bei solchen Eingriffen wird \nauch die Frage relevant, wer  \u00fcber L\u00f6schungen bzw. deren Kri-\nterien entscheidet. Bereits die L\u00f6schpraktiken sozialer Medi-\nen sind solche Einschnitte. Meinungs- und Pressefreiheit sind \nverfassungsrechtlich in erster Linie Abwehrrechte gegen\u00fcber \ndem Staat, denen das Hausrecht privater Plattformen nicht \nunterworfen ist. Das bedeutet, dass Plattformen durchaus \nmehr l\u00f6schen d\u00fcrfen und k\u00f6nnen als nur illegale Inhalte. Nach \nAuffassung des Bundesgerichtshofs sind die Plattformen aber \nauch bei der Anwendung der eigenen Regeln, die sie \u00fcber die \nVertragsbeziehungen mit ihrer Kundschaft vermitteln, an die \nGrundrechte der Personen gebunden, die ihr Angebot nutzen, \n327\thttps://www.racket.news/p/capsule-summaries-of-all-twitter\t[31.01.2023].287etwa deren Freiheit zur Meinungs\u00e4u\u00dferung.328 Mit Inkraft-\ntreten des Netzwerkdurchsetzungsgesetzes sind sie allerdings \nseit Januar 2018 verpflichtet, solche illegalen Inhalte nach Mel-\ndung durch Dritte zu l\u00f6schen.329 Auf der anderen Seite stellt \nsich jedoch die Frage, wie man, wenn man solche Eingriffe in \ndie Meinungsfreiheit durch L\u00f6schungen und Sperrungen ab-\nlehnt, verhindern will, dass Hassbotschaften, Aufrufe zu Ge-\nwalt, Verleumdungen und sonstige Einsch\u00fcchterungen die \noben beschriebenen Chilling-Effekte aus Angst vor \u00dcbergrif-\nfen ausl\u00f6sen, Gewalt bef\u00f6rdern und weitere demokratiegef\u00e4hr -\ndende Wirkung entfalten. Die gebotene Pluralismussicherung \nwiderstreitet jedoch ebenso vorschnellen algorithmenbasier -\nten Exklusionsmechanismen unter einseitiger Berufung auf \nangeblich vertrauensw\u00fcrdige Quellen. An sich ungewollten \nChilling-Effekten, die sich aus unter anderem durch gesetzli-\nche Regelungen (vor allem das Netzwerkdurchsetzungsgesetz) \nbedingten, zu weit reichenden Blockierpraktiken ergeben, ist \nkonsequent entgegenzuwirken.\nEin m\u00f6glicher L\u00f6sungsansatz sieht vor, soziale Medien und \nPlattformen, soweit diese rundfunkartige Funktionen \u00fcber -\nnehmen (z. B. der Newsfeed von Facebook), in diesen Funk-\ntionen anderen Rundfunkanbietern gleichzustellen, sie also an \ndie einschl\u00e4gigen gesetzlichen Bestimmungen f\u00fcr den Rund-\nfunk zu binden. Die Kuratierung von Inhalten w\u00fcrde dann \nauf Grundlage einer rechtlichen Regelung erfolgen, die sicher -\nstellt, dass das Recht auf Meinungsfreiheit gewahrt wird, ohne \ndie demokratische Zivilkultur zu gef\u00e4hrden. Zudem k\u00f6nnte \ndie Etablierung einer \u00f6ffentlich verantworteten Infrastruktur \ndigitaler Kommunikation in der Europ\u00e4ischen Union als Al-\nternative zu privaten und ausschlie\u00dflich kommerzgetriebenen \n328\tUrteile\tvom\t29.\tJuli\t2021\t\u2013\tIII\tZR\t179/20\tund\tIII\tZR\t192/20\t(NJW\t2021,\t3179).\n329\tDie\tEurop\u00e4ische\tUnion\that\t2022\tden\tDigital\tServices\tAct\terlassen;\tAnbieter\t\nm\u00fcssen\tdie\tneuen\tReglungen\tbis\tzum\t17.\tFebruar\t2024\tschrittweise\tumge-\nsetzt\thaben.\tDerzeit\tpr\u00fcft\tdie\tBundesregierung,\tinwieweit\tdas\tNetzwerk -\ndurchsetzungsgesetz\tmit\tGeltung\tdes\tDigital\tServices\tAct\tunanwendbar\t\nwird,\tund\tplant,\tMaterien,\tdie\tweiterhin\tnationalstaatlich\tgeregelt\twerden\t\nk\u00f6nnen,\tin\teinem\tneuen\tDigitale-Dienste-Gesetz\tzu\tb\u00fcndeln.288Angeboten einen Beitrag zur demokratischen Zivilkultur in \nZeiten der digitalen Transformation leisten.\n7.4.4 Erweiternde und vermindernde \nR\u00fcckwirkungen auf den \u00f6ffentlichen \nVernunftgebrauch\nDie genaue Wirkmacht der hier vorgestellten Ver\u00e4nderungen \nin der Diskursqualit\u00e4t, die sich aus den spezifischen soziotech-\nnischen Merkmalen und M\u00f6glichkeiten \u00f6ffentlicher Kommu-\nnikation auf Plattformen und in sozialen Medien ergeben, ist \naktuell noch nicht vollst\u00e4ndig absch\u00e4tzbar. Die vielf\u00e4ltig er -\nweiterten M\u00f6glichkeiten zur Teilhabe und Vernetzung sowie \ngrenz\u00fcberschreitend wirksamen Kommunikation er\u00f6ffnen \nzahlreiche Chancen zur Verbesserung der Diskursqualit\u00e4t und \nzur St\u00e4rkung demokratischer Prozesse.\nDie Entfaltung dieser Potenziale scheint in der Praxis je-\ndoch oft schwer planbar zu sein oder wird durch negative \nAspekte der Onlinekommunikation behindert. Aufgrund der \nkomplexen Vernetzung von Kommunikation im Internet sind \nviele politische Diskursprozesse von Einzelnen, aber auch \nvon gro\u00dfen Gruppen nur begrenzt beeinflussbar. Manipula-\ntionen und Gegenmanipulationen, die strategischen Formen \nder Kommunikation330, schaukeln sich zu chaotischen Prozes-\nsen hoch. Diese lassen der politischen Deliberation, der Ab-\nw\u00e4gung von Gr\u00fcnden pro und kontra, wom\u00f6glich nur noch \nwenig Spielraum und vermindern so die M\u00f6glichkeiten des \n\u00f6ffentlichen Vernunftgebrauchs. Extremere und emotionalere \nAussagen haben unabh\u00e4ngig von ihrem Wahrheitsgehalt gute \n330\tVgl.\tdazu\tJ\u00fcrgen\tHabermas\t(1981),\tder\tin\tseiner\t\u201eTheorie\tdes\tkommunika-\ntiven\tHandelns\u201c\tdrei\tTypen\trationalen\tHandelns\tvorstellt:\tinstrumentelles\t\nHandeln,\tstrategisches\tHandeln\tund\tkommunikatives\tHandeln,\tsowie\tdas\t\nGibbard-Satterthwaite-Theorem\t(Gibbard\t1973;\tSatterthwaite\t1975;\tNida-\nR\u00fcmelin\t2020b,\t140\u00a0ff.,\t149\u00a0ff.).289Chancen, sich gegen\u00fcber abgewogenen Argumenten durchzu-\nsetzen oder diese sogar zu marginalisieren.\nSpeziell mit Blick auf Fake-Accounts und Bots kommt hin-\nzu, dass die hier eingesetzte kalkulierte Verzerrung und be-\nwusste T\u00e4uschung selbst R\u00fcckwirkungen auf die Diskursqua-\nlit\u00e4t und Prozesse politischer Willensbildung haben k\u00f6nnen, \nindem sie zu Vertrauensverlusten f\u00fchren. Wenn gef\u00e4lschten \nIdentit\u00e4ten in die menschliche Interaktion eintreten, agieren \nsie auch als Substitute f\u00fcr menschliche Subjekte. Die Zurechen-\nbarkeit einer Botschaft zu einem personalen Gegen\u00fcber ist in \nder Folge nicht mehr gegeben und insbesondere die Delegati-\non kommunikativer Akte an Software kann zu Verunsicherun-\ngen f\u00fchren, wenn man nicht unterscheiden kann, ob man mit \nMenschen oder Bots kommuniziert. Sowohl das Vertrauen in \nden Diskurs und die m\u00f6gliche Einigung auf Kompromisse als \nauch das Vertrauen in demokratische Prozesse insgesamt, die \neigene Urteilskraft sowie die individuellen Wirkm\u00f6glichkeiten \nk\u00f6nnen auf diese Weise vermindert werden.\n7.5\t\t Fazit\tund\tEmpfehlungen\nDie hier aufgezeigten Ph\u00e4nomene und Entwicklungen, die \nsich in den jungen soziotechnischen Infrastrukturen digita-\nler Netzwerke vollziehen, haben erhebliche Auswirkungen \nauf Prozesse der \u00f6ffentlichen Kommunikation sowie der po-\nlitischen Meinungs- und Willensbildung, auch und vielleicht \ninsbesondere in demokratischen Gesellschaften. Demokratie \nals kollektive Selbstbestimmung der Freien und Gleichen setzt \nindividuelle Autonomie voraus. Sie gr\u00fcndet auf dem in Kapitel \n3 entwickelten Gedanken, dass Freiheit und Vernunft eng ver -\nbunden sind. Praktische Vernunft, die F\u00e4higkeit, das eigene Le-\nben, seine Einstellungen und Handlungen von Gr\u00fcnden leiten \nzu lassen, ist eine Grundlage von Autorschaft und Vorausset-\nzung f\u00fcr gelingende demokratische Prozesse, die auf rationa-\nlen Austausch mit anderen und die freie Auseinandersetzung 290unterschiedlicher Auffassungen setzen, um auf dieser Grund-\nlage gute Entscheidungen gemeinsam und wohlbegr\u00fcndet \ntreffen zu k\u00f6nnen.\nDiese Diskurs- und Entscheidungskultur hat im moder -\nnen \u00f6ffentlichen Raum der Plattformen und sozialen Medien \nvielf\u00e4ltige Entwicklungen erfahren. Durch den enorm ver -\nbesserten Zugang zu vielf\u00e4ltigen und auch qualitativ hoch-\nwertigen Informationen wie auch durch die stark erh\u00f6hten \nVernetzungsm\u00f6glichkeiten haben sich viele erweiternde Po-\ntenziale f\u00fcr einen umfassenderen, sachlich gest\u00fctzten und \ndynamischen Austausch ergeben. Menschen, die vorher nur \nwenig oder keinen Zugriff auf Informationen und Expertise \nhatten und kaum \u00fcber M\u00f6glichkeiten verf\u00fcgten, sich \u00fcber ihr \nlokales Umfeld hinaus Geh\u00f6r zu verschaffen, k\u00f6nnen mit den \nvon Plattformen und sozialen Netzwerken angebotenen Infra-\nstrukturen und Mitteln gleichberechtigt am Informationsaus-\ntausch teilnehmen, Sichtbarkeit f\u00fcr ihre Anliegen erreichen \nund Zusammenschluss mit Gleichgesinnten finden.\nTrotz dieser auf den ersten Blick erheblich erweiterten \nM\u00f6glichkeiten zu Informationsgewinnung, Teilhabe an Kom-\nmunikations- und Entscheidungsprozessen und sozialer Ver -\nnetzung \u2013 auch mit Menschen, die anderer Auffassung sind \n\u2013 werden diese Potenziale unter den aktuellen Bedingun-\ngen h\u00e4ufig nicht realisiert oder verdeckt von Prozessen, die \nmenschliche Handlungsspielr\u00e4ume und M\u00f6glichkeiten f\u00fcr \nden \u00f6ffentlichen Vernunftgebrauch und demokratische Ver -\nst\u00e4ndigungsprozesse eher vermindern. So werden beispiels-\nweise viele Prozesse der Onlinekommunikation durch die be-\nschriebenen algorithmischen Formatierungen immer wieder \neingeschr\u00e4nkt und verzerrt.\nDie auf eine Maximierung der Aufmerksamkeit und Ver -\nweildauer ausgerichtete Kuratierung erh\u00f6hen so zwar einer -\nseits den Komfort f\u00fcr Nutzende, wenn diese automatisch zu \nihren Pr\u00e4ferenzen passende und unterhaltsame bzw. spannen-\nde Inhalte erhalten oder in Onlinesuchen schnell und leicht die \ngew\u00fcnschten Informationen finden. Andererseits laufen aber 291gerade die nach aktuellen Kuratierungskriterien gef\u00f6rder -\nten schnelllebigen und verbreitungsstarken, polarisierenden, \nemotional und moralisch aufgeladenen Inhalte und Reaktio-\nnen in vielerlei Hinsicht den Grundgedanken demokratischer \nKommunikation und Willensbildung zuwider. Insbesondere \neine stark von negativen Emotionen gepr\u00e4gte Polarisierung \nvermindert die Handlungsspielr\u00e4ume f\u00fcr den freien und sach-\nlichen Austausch von Gr\u00fcnden und Argumenten. Wo alterna-\ntiv oder zus\u00e4tzlich Effekte wie Filterblasen und Echokammern \nhinzukommen \u2013 Ph\u00e4nomene, deren Verbreitung nach wie \nvor unklar ist \u2013, vermindern sich die M\u00f6glichkeiten f\u00fcr kon-\nstruktive Auseinandersetzungen gegebenenfalls noch zus\u00e4tz-\nlich, da man dann kontr\u00e4ren Auffassungen und Argumenten \nim Rahmen eines personalisierten Feeds mitunter kaum noch \nbegegnet.\nDer Einsatz von persuasiver personalisierter politischer \nWerbung, oft jenseits klar kenntlich gemachter Kampagnen \nund unter Einsatz von Fake-Accounts und Bots, gef\u00e4hrdet de-\nmokratische Prozesse nicht nur, indem sie den individuellen \nVernunftgebrauch mit manipulativen Techniken erschwert, \nsondern auch, indem durch den t\u00e4uschenden und verzerren-\nden Charakter solcher Aktionen das Vertrauen in den demo-\nkratischen Prozess selbst untergraben wird. Derartige Vertrau-\nensverluste wiederum beg\u00fcnstigen gemeinsam mit der bereits \nerw\u00e4hnten algorithmischen Favorisierung aufmerksamkeits-\nerregender und negativer emotional wie moralisch aufgelade-\nner Inhalte Verschw\u00f6rungsmythen und andere kollektive Er -\nregungen, die wiederum den \u00f6ffentlichen Vernunftgebrauch \nerschweren, der f\u00fcr eine funktionierende Demokratie uner -\nl\u00e4sslich ist.\nHinzu kommt die problematische Konzentration digita-\nler Kommunikationsinfrastrukturen in den H\u00e4nden weniger \nKonzerne mit vielfach als unzureichend betrachteten Verant-\nwortlichkeiten, Rechenschaftspflichten und \u00f6ffentlichen Kon-\ntrollm\u00f6glichkeiten ebenso wie die aktuell zu beobachtenden 292Defizite in der Moderation problematischer Inhalte.331 Letztere \nbetreffen sowohl die technische Umsetzung als auch die Frage, \nwie eine angemessene Balance zwischen zu wenig und zu viel \nKontrolle in das digitale Kommunikationsgeschehen gelingen \nkann. Die aktuelle Aufstellung, in der die auf kommerziellen \nPlattformen zum Einsatz kommenden soziotechnischen Me-\nchanismen f\u00fcr die \u00d6ffentlichkeit weitgehend opak bleiben und \nselbst Forschung keinen Zugang zu den propriet\u00e4ren Algo-\nrithmen hat, geht f\u00fcr die Gesellschaft mit stark verminderten \nHandlungs- sowie Kontrollm\u00f6glichkeiten einher.\nIn diesem Rahmen stellt sich auch die Frage, ob eine digitale \nKommunikationsinfrastruktur in \u00f6ffentlicher Verantwortung \nL\u00f6sungsans\u00e4tze f\u00fcr diese Probleme bieten k\u00f6nnte. Das Ziel \nw\u00e4re nicht nur, Menschen eine Alternative zu kommerziellen \nPlattformen anzubieten, sondern dar\u00fcber hinaus durch Mei-\nnungsvielfalt, kommunikatives Ethos, Minderheitenschutz \nund Seriosit\u00e4t auch die privaten Anbieter zu einem h\u00f6heren \nMa\u00df an Demokratievertr\u00e4glichkeit zu veranlassen. Der Demo-\nkratieentwicklung unter den Bedingungen einer dynamischen \ndigitalen Transformation k\u00e4me das zugute.\nOnlineplattformen und soziale Medien bilden die zentra-\nlen Infrastrukturen f\u00fcr Information und Kommunikation und \nsind somit von entscheidender Bedeutung f\u00fcr die \u00f6ffentliche \nMeinungsbildung. Gleichzeitig liegen sie jedoch in der Hand \nweniger globaler Akteure, die prim\u00e4r \u00f6konomische Zwecke \nverfolgen, wodurch deren soziotechnische Praktiken der Se-\nlektion und Moderation einerseits erheblichen Einfluss auf \nProzesse der Information, Kommunikation und der \u00f6ffentli-\nchen Meinungsbildung haben, andererseits sich jedoch effek-\ntiver Kontrolle der Rechtm\u00e4\u00dfigkeit h\u00e4ufig entziehen.\n331\t Diesen\tProblemen\tsoll\t\u2013\tund\twird\tteilweise\tauch\tschon\t\u2013\tmit\teurop\u00e4ischen\t\nund\tnationalen\tGesetzen\tentgegengewirkt\twerden\t(z.\tB.\tNetzwerkdurch-\nsetzungsgesetz,\tDigital\tServices\tAct,\tDigital\tMarkets\tAct).\tAuch\tder\t\nMedienstaatsvertrag\tsieht\tsolche\tRegelungen\tvor.293Empfehlungen\n>> Empfehlung Kommunikation 1: Regulierung sozialer Medi-\nen: Es bedarf klarer rechtlicher Vorgaben, in welcher Form \nund in welchem Ausma\u00df soziale Medien und Plattformen \n\u00fcber ihre Funktions- und Vorgehensweisen zur Kuratie-\nrung und Moderation von Inhalten informieren m\u00fcssen \nund wie dies auf der Grundlage institutioneller Regelungen \numgesetzt wird. Dies muss durch externe Kontrollen \u00fcber -\npr\u00fcfbar sein; rein freiwillige Ans\u00e4tze privater Handelnder, \ninsbesondere die unverbindliche \u00dcberpr\u00fcfung durch von \ndiesen selbst besetzten Aufsichtsgremien, sind nicht aus-\nreichend. Hier gibt es auf Ebene der Europ\u00e4ischen Union \nim Digital Services Act bereits Ans\u00e4tze, die aber noch nicht \nweit genug gehen.\n>> Empfehlung Kommunikation 2: Transparenz \u00fcber Mode-\nrations- und Kuratierungspraktiken: Anstelle allgemeiner \nModerations- und L\u00f6schungsrichtlinien und wenig aussa-\ngekr\u00e4ftiger Zahlen \u00fcber L\u00f6schungen muss f\u00fcr externe Kon-\ntrollen nachvollziehbar sein, wie, unter welchen Umst\u00e4n-\nden und anhand welcher Kriterien solche Entscheidungen \ngef\u00e4llt und umgesetzt werden und welche Rolle hierbei Al-\ngorithmen bzw. menschliche Moderierende \u00fcbernommen \nhaben. Dar\u00fcber hinaus m\u00fcssen auch die grundlegenden \nFunktionsweisen der Kuratierung von Inhalten sozialer \nMedien und Plattformen in dem Ausma\u00df offengelegt wer -\nden, das n\u00f6tig ist, um systemische Verzerrungen und m\u00f6g-\nlicherweise resultierende informationelle Dysfunktionen \nerkennen zu k\u00f6nnen. Die Berichtspflichten und Transpa-\nrenzvorgaben im Medienstaatsvertrag, im Netzwerkdurch-\nsetzungsgesetz und im Digital Services Act stellen dies \nnoch nicht hinreichend sicher. Die datenschutzrechtlichen \nAuskunftspflichten gem\u00e4\u00df Art. 12 ff. DSGVO sind zum \nTeil auf nationalstaatliche Ebene beschr\u00e4nkt worden und \nerfassen oftmals diese weiter gehenden Aspekte nicht.\n>> Empfehlung Kommunikation 3: Zugriff auf wissenschaftsre-\nlevante Daten von Plattformen: Um die Wirkungsweisen 294von Plattformen und sozialen Medien, ihren Einfluss auf \n\u00f6ffentliche Diskurse, aber auch weitere Themen von hoher \ngesellschaftlicher Relevanz zu untersuchen, sollte sicherge-\nstellt werden, dass unabh\u00e4ngigen Forschenden der Zugriff \nauf wissenschaftsrelevante Daten von Plattformen nicht \nmit dem pauschalen Verweis auf Betriebs- oder Gesch\u00e4fts-\ngeheimnisse verweigert werden kann. F\u00fcr den Zugang m\u00fcs-\nsen sichere, datenschutzkonforme sowie forschungsethisch \nintegre Wege gefunden werden. Netzwerkdurchsetzungs-\ngesetz und Digital Services Act enthalten bereits Reglungen \nzum Datenzugang, die aber in ihrem Anwendungsbereich \nsehr begrenzt sind; auch der Data Act sieht vergleichbare \nRegelungen vor.\n>> Empfehlung Kommunikation 4: Ber\u00fccksichtigung von Si-\ncherheit, Datenschutz und Geheimhaltungsinteressen: An-\nforderungen an Offenlegungen und Datenzugang m\u00fcssen \nkontextsensitiv spezifiziert werden, wobei Anforderungen \nan Sicherheit und Schutz vor Missbrauch, Datenschutz \nsowie dem Schutz von intellektuellem Eigentum und Ge-\nsch\u00e4ftsgeheimnissen angemessen Rechnung zu tragen ist. \nJe nach Kontext muss zwischen unterschiedlich klar defi-\nnierten Zeitpunkten der Pr\u00fcfung und Graden der Offenle-\ngung unterschieden werden.\n>> Empfehlung Kommunikation 5: Personalisierte Werbung, \nProfiling und Microtargeting: Personalisierte Werbung ist \ndas zentrale Gesch\u00e4ftsmodell sozialer Medien und Platt-\nformen. Die Praktiken des Profilings und Microtargetings \nk\u00f6nnen jedoch problematische Auswirkungen auf \u00f6ffent-\nliche Kommunikation und Meinungsbildung entfalten, \ninsbesondere im Kontext politischer Werbung. Um solche \nnegativen Auswirkungen durch effektive Regelungen zu \nverhindern, ist es zun\u00e4chst notwendig, die Bedingungen \nf\u00fcr eine Erforschung und \u00dcberpr\u00fcfung der Zusammen-\nh\u00e4nge zwischen Gesch\u00e4ftsmodellen und Praktiken algo-\nrithmischer Kuratierung in ihren Wirkungsweisen und Ef-\nfekten zu schaffen. Der auf Ebene der Europ\u00e4ischen Union 295diskutierte Vorschlag f\u00fcr eine Verordnung \u00fcber die Trans-\nparenz und das Targeting politischer Werbung adressiert \ndiesen Bedarf. Hierbei zeigen sich allerdings auch die He-\nrausforderungen, Regeln so zuzuschneiden, dass sie einer -\nseits wirksam sind, andererseits aber die Freiheit der politi-\nschen Kommunikation nicht \u00fcberm\u00e4\u00dfig beschr\u00e4nken.\n>> Empfehlung Kommunikation 6: Bessere Regulierung von \nOnlinemarketing und Datenhandel: Ursache vieler infor -\nmationeller und kommunikativer Dysfunktionen haben \nihre Ursache im Onlinemarketing, welches das grundle-\ngende Gesch\u00e4ftsmodell vieler sozialer Medien und Platt-\nformen ist und auf der Sammlung, Analyse und dem \nVerkauf vielf\u00e4ltiger Daten \u00fcber die Personen, die diese \nAngebote nutzen, beruht. Das Problem ist hierbei nicht die \nWerbefinanzierung per se, sondern der invasive Umgang \nmit diesen Daten. Hier gilt es einerseits, die Auswirkungen \ndieses Gesch\u00e4ftsmodells auf \u00f6ffentliche Diskurse besser zu \nerforschen. Andererseits bedarf es besserer gesetzlicher Re-\ngelungen, um sowohl Individuen in ihren Grundrechten \nonline effektiver zu sch\u00fctzen als auch negative systemische \nEffekte auf den \u00f6ffentlichen Diskurs zu minimieren. In die-\nse Richtung gehende Vorschl\u00e4ge hat der Deutsche Ethikrat \n2017 unter dem Stichwort \u201eDatensouver\u00e4nit\u00e4t\u201c in seiner \nStellungnahme zu Big Data und Gesundheit vorgestellt. \nEurop\u00e4ische Regelungen wie der Digital Markets Act ad-\nressieren das Problem der Datenmacht gro\u00dfer Plattformen, \naber \u2013 schon aus Gr\u00fcnden der Regelungskompetenz \u2013 nicht \nmit Blick auf die Folgen f\u00fcr den \u00f6ffentlichen Diskurs.\n>> Empfehlung Kommunikation 7: Machtbeschr\u00e4nkung und \nKontrolle: Unternehmen, die im Bereich der \u00f6ffentlichen \nVorstellung von Daten bzw. Tatsachen de facto monopo-\nlartige Machtm\u00f6glichkeiten haben, sind durch rechtliche \nVorgaben und entsprechende Kontrolle auf Pluralismus, \nMinderheiten- und Diskriminierungsschutz zu verpflich-\nten. Ein Teil der Mitglieder des Deutschen Ethikrates ist \nder Auffassung, dass medienrechtliche Regelungen zur 296Sicherung von Pluralit\u00e4t, Neutralit\u00e4t und Objektivit\u00e4t ge-\nnerell auf Nachrichtenfunktionen von sozialen Medien \nund Plattformen ausgedehnt werden sollten, sofern sie de-\nnen traditioneller Medien \u00e4hneln.\n>> Empfehlung Kommunikation 8: Erweiterung der Nutzerau-\ntonomie: Plattformen und soziale Medien sollten ihre In-\nhalte auch ohne eine personalisierte Kuratierung verf\u00fcgbar \nmachen. Dar\u00fcber hinaus sollten sie f\u00fcr die Kriterien, nach \ndenen Inhalte auf Plattformen und in sozialen Medien al-\ngorithmisch ausgew\u00e4hlt und priorit\u00e4r pr\u00e4sentiert werden, \nweitere Wahlm\u00f6glichkeiten anbieten. Dazu sollte auch die \nM\u00f6glichkeit geh\u00f6ren, bewusst Gegenpositionen angezeigt \nzu bekommen, die den bisher ge\u00e4u\u00dferten eigenen Pr\u00e4fe-\nrenzen zuwiderlaufen. Solche Wahlm\u00f6glichkeiten sollten \ngut sichtbar und leicht zug\u00e4nglich sein.\n>> Empfehlung Kommunikation 9: F\u00f6rderung kritischer Re-\nzeption von Inhalten: Zur Eind\u00e4mmung unreflektierter \nVerbreitung fragw\u00fcrdiger Inhalte sollten diverse Hinweis-\nfunktionen entwickelt und eingesetzt werden, die eine \nkritische Auseinandersetzung mit Material f\u00f6rdern, bevor \nman sich daf\u00fcr entscheidet, es zu teilen oder \u00f6ffentlich da-\nrauf zu reagieren. Dies k\u00f6nnten etwa R\u00fcckfragen sein, ob \nTexte gelesen und Videos geschaut wurden, bevor man sie \nteilt, oder Angaben zur Seriosit\u00e4t von Quellen.\n>> Empfehlung Kommunikation 10: Alternative Informations- \nund Kommunikationsinfrastruktur: Zu erw\u00e4gen w\u00e4re, \nden privaten Social-Media-Angeboten im europ\u00e4ischen \nRahmen eine digitale Kommunikationsinfrastruktur in \n\u00f6ffentlich-rechtlicher Verantwortung zur Seite zu stellen, \nderen Betrieb sich nicht am Unternehmensinteresse eines \nm\u00f6glichst langen Verweilens von Menschen auf der Platt-\nform oder an anderen kommerziellen Interessen orientiert. \nDamit sollte nicht etwa der \u00f6ffentlich-rechtliche Rundfunk \n(TV und Radio) auf eine weitere digitale Plattform aus-\ngedehnt, sondern eine digitale Infrastruktur bereitgestellt \nwerden, die eine Alternative zu den kommerzbetriebenen, 297stark oligopolartigen Angeboten bietet. Um eine hinrei-\nchende Staatsferne zu garantieren, k\u00f6nnte auch an eine \nTr\u00e4gerschaft in Gestalt einer \u00f6ffentlichen Stiftung gedacht \nwerden.2988\t \t \u00d6FFENTLICHE \tVERWALTUNG\n8.1\t\t Einleitung\nDie \u00f6ffentliche Verwaltung stellt die exekutive Ebene der Um-\nsetzung der in demokratischen Meinungsbildungs- und Ent-\nscheidungsverfahren gefassten Beschl\u00fcsse dar. Sie versteht \nsich als vollziehende Gewalt des Staates332 und l\u00e4sst sich syste-\nmatisieren in die Ordnungsverwaltung (Vollzug und Kontrol-\nle von Gesetzen), die Dienstleistungsverwaltung (Umsetzung \nder gesetzlich begr\u00fcndeten, technischen oder pers\u00f6nlichen \nDienstleistungsanspr\u00fcche aller B\u00fcrgerinnen und B\u00fcrger), die \nWirtschaftsverwaltung (Bewirtschaftung aller Einnahmen, \nAusgaben und Verm\u00f6gen der \u00f6ffentlichen Hand), die Orga-\nnisationsverwaltung (Personalwesen einschlie\u00dflich Personal-\nrekrutierung, Fort- und Weiterbildung) und die politische \nVerwaltung (insbesondere Zuarbeit f\u00fcr die politische F\u00fchrung \nsowie Entscheidungstragende in der Legislative).333\nF\u00fcr Menschen, aber auch viele Organisationen stellt die \u00f6f-\nfentliche Verwaltung, so etwa im Finanz-, Steuer -, Melde- und \nSozialwesen oder in der Straff\u00e4lligen- und Jugendgerichtshilfe, \ndie unmittelbar erfahrbare Staatsgewalt dar. Ihre Exekutiv-\nfunktion darf dabei nicht als blo\u00df ausf\u00fchrende Vollstreckung \nbereits anderweitig getroffener Entscheidungen verstanden \nwerden. Zwar m\u00fcssen \u00fcbergeordnete und direkt demokratisch \nlegitimierte Entscheidungen, etwa im Sozialrecht oder Steuer -\nrecht, eingehalten und umgesetzt werden; dennoch verbleiben \nauf der Ebene der Verwaltung weitreichende Beurteilungs- \nund Entscheidungsspielr\u00e4ume in der einzelfallbezogenen Ad-\naptation allgemein formulierter Gesetze und Verordnungen, \nso zum Beispiel unter dem Begriff der Verh\u00e4ltnism\u00e4\u00dfigkeit, bei \nunbestimmten Rechtsbegriffen oder Risikoentscheidungen.\n332\tSchmidt-A\u00dfmann\t1998,\t148\u00a0ff.\n333\t Schmidt\t2010,\t859\u00a0f.;\tHesse/Ellwein,\t308\u00a0ff.299Zudem sind der \u00f6ffentlichen Verwaltung von Gesetzes \nwegen mitunter unmittelbare Entscheidungsbefugnisse zu-\ngewiesen \u2013 auch in der Dienstleistungsverwaltung etwa des \nGesundheits- und Sozialwesens. Gerade hier unterliegen die \nMitarbeitenden der \u00f6ffentlichen Verwaltung einer spezifi-\nschen Professionsethik.334 Funktionierende, transparente, als \nlegitim anerkannte und b\u00fcrgernahe Verwaltung ist daher f\u00fcr \nein funktionierendes Gemeinwesen und die Akzeptanz von \nDemokratie und Staat wesentlich.\n8.2\t\t Ethische\tFragen\talgorithmischer\t\nAutomatisierung\tim\t\nVerwaltungshandeln\nSeit den 1970er-Jahren werden Konzepte f\u00fcr eine gleichzeitig \neffizientere wie auch b\u00fcrgern\u00e4here \u00f6ffentliche Verwaltung im \nRahmen von Digitalisierungsstrategien entwickelt, erprobt \nund teils umgesetzt.335 Damit verbinden sich unter anderem \nHoffnungen auf eine Rationalisierung und Beschleunigung \nstaatlichen Verwaltungshandelns, eine effektivere und ko-\nh\u00e4rentere Datennutzung sowie eine Ausweitung der Einbe-\nziehung wissenschaftlichen und b\u00fcrgerschaftlichen Sachver -\nstandes. Dem steht die Schreckensvision einer sogenannten \n\u201eAlgokratie\u201c gegen\u00fcber, in der autonome Softwaresysteme die \nstaatliche Herrschaft \u00fcber Menschen aus\u00fcben, B\u00fcrgerinnen \nund B\u00fcrgern durchgehend Entscheidungen unterworfen sind, \nderen Algorithmen intransparent sind und keinen Wider -\nspruch dulden.336 Werden in den positiven Stimmen die Po-\ntenziale der B\u00fcrgern\u00e4he und der niedrigschwelligen digitalen \nErreichbarkeit von Verwaltungsleistungen vom Wohnzimmer \n334\tLob-H\u00fcdepohl\t2002;\tTrappe\t2013.\n335\t Simitis/Hornung/Spiecker\tgen.\tD\u00f6hmann\t2019,\tEinleitung\tRn.\t6;\tzu\tden\t\nver\u00e4nderten\tVorstellungen\tvon\tVerwaltung\tin\tdiesem\tZuge\tRn.\t7.\n336\tDer\tBegriff\tder\tAlgokratie\tgeht\tzur\u00fcck\tauf\tAneesh\t2009;\tvgl.\tauch\tDanaher\t\n2016.300aus betont, so sehen kritische Stimmen digitale Technologi-\nen als weiteren Schritt zu einer technokratischen B\u00fcrokra-\ntie, in der Kommunikation hinter anonymen Datenmengen \nund standardisierten, noch dazu schwer verst\u00e4ndlichen Be-\ndienoberfl\u00e4chen verschwindet.\nTats\u00e4chlich l\u00e4sst sich in den vergangenen Jahren in vielen \nL\u00e4ndern in und au\u00dferhalb Europas ein zunehmender Einsatz \nvon automatisierten Entscheidungssystemen in der \u00f6ffentli-\nchen Verwaltung beobachten. Beispiele reichen von der Be-\nwertung von Arbeitsmarktchancen Jobsuchender in \u00d6ster -\nreich337 und Polen338 \u00fcber die Verwendung von Software f\u00fcr \ndie Pr\u00fcfung und Vergabe von Sozialleistungen in England339, \nFrankreich340 und den Niederlanden341 bis hin zu pr\u00e4diktiven \nAnalysen im Betreuungs- und F\u00fcrsorgebereich in Finnland342 \nund Spanien343, aber auch im Bereich der Polizei. Auch wenn \nin Deutschland der Einsatz von automatisierten Entschei-\ndungssystemen in der \u00f6ffentlichen Verwaltung noch selten \nist344, finden sich auch hier einzelne Projekte wie etwa die au-\ntomatische Berechnung des Arbeitslosengelds durch das IT-\nSystem ALLEGRO der Bundesagentur f\u00fcr Arbeit345 oder die \nin Hamburg zum Einsatz kommende Fachanwendung JUS-IT \nf\u00fcr die Koordination und Abrechnung von Sozialdiensten346.\nVielen Vorteilen solcher Systeme, wie der Steigerung der \nEffizienz von Verwaltungsvorg\u00e4ngen und der besseren Ab-\nsicherung von Entscheidungen angesichts h\u00e4ufig komplexer \n337\t https://www.derstandard.at/story/2000122684131/gericht-macht-weg-fuer-\numstrittenen-ams-algorithmus-frei\t[22.02.2023].\n338\tPanoptykon\tFoundation\t2015.\n339\thttps://www.theguardian.com/technology/2019/oct/14/fears-rise-in-\nbenefits-system-automation-could-plunge-claimants-deeper-into-poverty\t\n[22.02.2023].\n340\thttps://algorithmwatch.org/en/robo-debt-france\t[22.02.2023].\n341\t https://algorithmwatch.org/de/risikobuerger\t[22.02.2023].\n342\tAlgorithmWatch\t2020,\t84\u00a0ff.\n343\tAlgorithmWatch\t2019,\t117\u00a0ff.\n344\thttps://netzpolitik.org/2020/automating-society-report-2020-\nautomatisierung-schreitet-auch-in-deutschland-voran\t[22.02.2023].\n345\thttps://algorithmwatch.org/de/hartz-iv-algorithmen-diskriminierung\t\n[30.01.2023].\n346\thttps://www.hamburg.de/jus-it\t[30.01.2023].301Datenlagen, stehen Risiken an anderen Stellen gegen\u00fcber. Hier \nist zun\u00e4chst einmal die Qualit\u00e4t der verwendeten Systeme zu \nbewerten und die Frage zu stellen, ob und in welchem Umfang \ndie verwendeten Systeme Diagnosen und Prognosen tats\u00e4ch-\nlich verbessern. Es stellt sich in diesem Kontext auch die Fra-\nge, ob die Genauigkeit f\u00fcr verschiedene Anwendungskontexte \noder Personengruppen gleich ist oder ob es m\u00f6glicherweise sys-\ntematische Verzerrungen oder Diskriminierungen gibt (Algo-\nrithmic Bias). In ethischer Hinsicht sind hierbei insbesondere \nzwei Themenkomplexe von besonderer Bedeutung, die einer -\nseits Fragen von Autonomie, Autorschaft und Verantwortung \nsowie andererseits Fragen der Gerechtigkeit ber\u00fchren.\nIm ersten Fall geht es um die Frage, ob und wie die Nut-\nzung von KI zur Unterst\u00fctzung von Entscheidungen oder \ngar das vollst\u00e4ndige Delegieren von Entscheidungen an KI-\nSysteme menschliche Handlungsf\u00e4higkeiten und Autorschaft \nbeeinflusst. Bereits in den Bezeichnungen f\u00fcr solche Systeme \nwird diese Problematik deutlich. Der h\u00e4ufig verwendete Be-\ngriff \u201eADM-System\u201c wird teils in algorithmic decision making, \nteils in automated decision making aufgel\u00f6st. In beiden F\u00e4llen \nwird nahegelegt, dass die Entscheidungen vollst\u00e4ndig auto-\nmatisiert erfolgen oder aber Entscheidungen vollst\u00e4ndig an \nMaschinen delegiert werden. Demgegen\u00fcber steht beispiels-\nweise der Begriff \u201eDecision Support System\u201c, der nahelegt, \ndass KI-Systeme menschliche Entscheidungen lediglich un-\nterst\u00fctzen sollen. Diese Unterscheidung kommt auch in der \nDatenschutz-Grundverordnung zum Tragen, wenn in Artikel \n22 postuliert wird, dass niemand zum Objekt einer allein auf \nAlgorithmen basierenden Bewertung gemacht werden soll-\nte, sondern belastende Wertungsentscheidungen von einem \nMenschen verantwortet werden sollten. Mit Blick auf den Au-\ntomation Bias, das hei\u00dft die menschliche Tendenz, sich ma-\nschinellen Empfehlungen vorbehaltslos anzuschlie\u00dfen, stellt \nsich allerdings die Frage, ob dieses Problem nur bei Entschei-\ndungen ohne jedes menschliche Eingreifen und nicht bereits \nim Falle der Entscheidungsunterst\u00fctzung relevant wird.302Schon bei der Nutzung von Software zur Entscheidungs-\nunterst\u00fctzung, beispielsweise mithilfe von Risikoscores, \u00e4n-\ndert sich die Rolle der menschlichen Verantwortungs- und \nEntscheidungstr\u00e4ger grundlegend. Nach einer Phase der Be-\nw\u00e4hrung dieser Systeme kann es leicht zur Dominanz einer \nDefault-Praxis des Verwaltungshandelns in diesem Bereich \nkommen: Es treten Gew\u00f6hnung und Routine ein. Die maschi-\nnelle Interpretation der Daten gibt im Regelfall eine Entschei-\ndung vor, von der nur in besonderen Einzelf\u00e4llen, f\u00fcr die es \ndann Gr\u00fcnde geben muss, abgewichen wird. Die Entscheidung \ngegen eine maschinell vorbereitete Empfehlung, wenn der \nSoftwareeinsatz etabliert und im Ganzen bew\u00e4hrt ist, legt der \nverantwortlichen Person Recherche- und Begr\u00fcndungspflich-\nten auf, die bei komplexen Sachverhalten einen erheblichen \nAufwand nach sich ziehen. Daher k\u00f6nnen auch bei formaler \nBeschr\u00e4nkung von ADM-Systemen auf Entscheidungsvorbe-\nreitung und -unterst\u00fctzung die Verantwortungsspielr\u00e4ume \nvon Verwaltungspersonal de facto eingeschr\u00e4nkt werden. Um-\ngekehrt und angesichts der Tatsache, dass auch das traditionel-\nle Verwaltungshandeln von Routinen und Mustern gepr\u00e4gt ist, \nwas im Einzelfall immer wieder zu Fehlentscheidungen f\u00fchrt \nund der notwendigen Flexibilit\u00e4t bei komplexeren Sachverhal-\nten entgegensteht, kann die Ausweitung der Entscheidungs-\nunterst\u00fctzung durch ADM-Systeme jedoch auch helfen, starre \nRoutinen aufzubrechen, komplexere Entscheidungssituatio-\nnen rechtzeitig zu diagnostizieren und eine angemessene Re-\naktion erst zu erm\u00f6glichen.\nWenn Entscheidungen von Softwaresystemen unterst\u00fctzt \noder gar vollst\u00e4ndig an diese delegiert werden, stellen sich \nauch Fragen der Verantwortungszuschreibung. Auch beim \nvollautomatisierten Verwaltungshandeln muss das Recht der \nB\u00fcrgerschaft gewahrt werden, sich mit den in der Verwaltung \nVerantwortlichen auseinanderzusetzen, Einspruch zu erhe-\nben und letztlich, wenn keine Einigung erzielt werden kann, \nzu versuchen, ihr Recht vor dem Verwaltungsgericht durch-\nzusetzen. Daher muss es eine klare und f\u00fcr sie erkennbare 303Verantwortungszuweisung an eine daf\u00fcr zust\u00e4ndige und so-\nmit verantwortliche Beh\u00f6rde geben.\nDas zweite Problem betrifft Fragen der Gerechtigkeit und \nder Verhinderung von Diskriminierung. Auch hier wird der \nBegriff des Bias verwendet, jedoch mit einer v\u00f6llig anderen \nBedeutung: Im Gegensatz zum zuvor geschilderten Fall des \nAutomation Bias geht es hier nicht um kognitive Verzerrun-\ngen menschlicher Akteure, sondern um systematische Verzer -\nrungen im Output der KI-Systeme, die zuweilen als Technical \nBias347 oder Algorithmic Bias beschrieben werden. Ein viel dis-\nkutiertes Beispiel hierf\u00fcr ist die Software COMPAS, die in den \nUSA zur Ermittlung von Risikoprofilen f\u00fcr ehemalige straff\u00e4l-\nlige Personen eingesetzt wird. Hier konnte nachgewiesen wer -\nden, dass die Prognosen insofern diskriminierend waren, als \ndunkelh\u00e4utige Menschen deutlich h\u00e4ufiger eine f\u00e4lschlicher -\nweise zu negative Prognose erhielten als hellh\u00e4utige Menschen, \ndie im Gegensatz dazu f\u00e4lschlicherweise zu positive Prognosen \nbekamen. H\u00e4ufige Ursache solch diskriminierender Systeme \nsind Verzerrungen in den Trainingsdaten, aber auch verschie-\ndene methodische Entscheidungen348. Das Resultat ist, dass \n347\tFriedman/Nissenbaum\t1996.\n348\tBarocas/Selbst\t(2016)\tliefern\thier\teine\tausgesprochen\thilfreiche\t\u00dcber -\nsicht\tm\u00f6glicher\tQuellen\tvon\tBias\tund\tDiskriminierung\tin\tdatenbasierten\t\nSystemen.\tNeben\tder\tAuswahl\tvon\tZielvariablen,\tLabels\toder\trelevanten\t\nMerkmalen\tsind\thier\tvor\tallem\tdie\tverwendeten\tDaten\tvon\tentscheidender\t\nBedeutung.\tHierbei\tkann\tes\tnicht\tnur\tdurch\tFehlerhaftigkeit\tder\tDaten\t\nselbst,\tsondern\tauch\tdurch\t\u00dcber-\tund\tUnterrepr\u00e4sentativit\u00e4t\tzu\tProblemen\t\nkommen,\tdas\thei\u00dft,\twenn\tzum\tBeispiel\tPersonen\tin\tDatens\u00e4tzen\t\u00fcber -\nproportional\toder\tunterproportional\trepr\u00e4sentiert\tsind.\tDar\u00fcber\thinaus\t\nbesteht\tdas\tProblem\tsogenannter\tProxyvariablen:\tSensible\tKategorien\t\nwie\tbeispielsweise\tGeschlecht,\treligi\u00f6se\tZugeh\u00f6rigkeit\toder\tsexuelle\t\nOrientierung\tlassen\tsich\tteilweise\taus\tanderen\tDatenpunkten\twie\tetwa\t\nHobbies,\tEinkaufsverhalten\toder\tWohnort\terschlie\u00dfen.\tAufgrund\tdieser\t\nsogenannten\tredundanten\tEncodierung\tk\u00f6nnen\tPersonen\taufgrund\tihres\t\nGeschlechts\toder\tihrer\tsexuellen\toder\treligi\u00f6sen\tOrientierung\tdurch\tSoft -\nware\tauch\tdann\tsystematisch\tdiskriminiert\twerden,\twenn\tdiese\tAngaben\t\ngar\tnicht\terhoben\twurden\t\u2013\teben\tweil\tdiese\tKategorien\taus\tanderen\tDaten\t\nableitbar\tsind.\tDie\tmeisten\tder\tzuvor\tgeschilderten\tQuellen\tvon\tBias\tund\t\nDiskriminierung\tsind\tnicht\tbeabsichtigt,\tsondern\tdas\tResultat\tmethodi-\nscher\tEntscheidungen\tbzw.\tFehler.\tEs\tist\tjedoch\tprinzipiell\tauch\tm\u00f6glich,\t\nabsichtlich\tdiskriminierende\tEffekt\tin\tSoftwaresysteme\teinzubauen\t\u2013\tein\t\nProblem,\twelches\tBarocas/Selbst\tVerschleierung\t(masking)\tnennen.304insbesondere datenbasierte Systeme Stereotypen, aber auch \ngesellschaftliche Ungleichheit in scheinbar neutrale Systeme \n\u00fcbersetzen und verschleiern und somit existierende soziale \nUngleichheit weiter in die Zukunft fortschreiben. Dies ist je-\ndoch keine zwangsl\u00e4ufige Entwicklung. Im Gegenteil k\u00f6nnen \ndatenbasierte Systeme solche historischen Ungerechtigkeiten \nauch zuvorderst aufdecken und sie damit f\u00fcr Gegenma\u00dfnah-\nmen zug\u00e4nglich machen.\nEine grunds\u00e4tzliche Grenze f\u00fcr die Anwendung von ADM-\nSystemen liegt in nicht eliminierbaren normativen Ziel- oder \nRegelkonflikten im deutschen, deontologisch verfassten \nRechtssystem. Folgenabw\u00e4gung allein bestimmt in der deonto-\nlogisch orientierten Ordnung in Deutschland nicht das Recht-\nm\u00e4\u00dfige. Sie kommt zwar zum Einsatz, zum Beispiel im Zusam-\nmenhang mit der Verh\u00e4ltnism\u00e4\u00dfigkeit, wenn es darum geht, \ndas mildeste Mittel im Sinne eines Eingriffs in Grundrechte \nzu bestimmen, das dennoch f\u00fcr die Zielerreichung effektiv ist. \nAber in der Bestimmung des deontologisch Rechtm\u00e4\u00dfigen geht \nes nicht um das mehr oder weniger Vorteilhafte und nicht um \nNutzenoptimierung in Bezug auf die Folgen, sondern um die \nFrage, wer welche Rechte hat und wie diese im Konfliktfall so \nabzuw\u00e4gen und zu gewichten sind, dass unbedingte Anspr\u00fc-\nche auf Schutz der Person gewahrt und ihre Verrechenbarkeit \n(im Sinne einer reinen Nutzenoptimierung) verhindert werden \nkann.349 Insoweit sind der quantitativen Berechnung Grenzen \ngesetzt; vielmehr es geht um eine nur menschlicher Urteilskraft \nzug\u00e4ngliche Bewertung. So m\u00fcssen in menschlicher Delibe-\nration Argumente und Gegenargumente vorgebracht werden, \nauf deren Grundlage am Ende entschieden wird (vgl. Abschnitt \n3.2.2). Hier zeigt sich eine ultimative Grenze der Algorithmisie-\nrung ethischer und rechtlicher Entscheidungsprozesse.\nDiese grunds\u00e4tzlichen \u00dcberlegungen sprechen nicht da-\ngegen, Teilbereiche der Entscheidungsprozesse zu algorith-\nmisieren und die rechtliche und moralische Deliberation mit \n349\tRoss\t1930.305Softwaresystemen zu unterst\u00fctzen. Im Gegenteil geht es dar -\num, auch im Verwaltungshandeln die Vorteile von digitalen \nund insbesondere KI-gest\u00fctzten Systemen zu nutzen, ohne je-\ndoch in die genannten technokratischen Fallen zu tappen. Die \nGestaltung entsprechender Systeme kann proaktiv von Beginn \nan so angelegt werden, dass ethische Werte und Normen be-\nr\u00fccksichtigt werden, wie dies beispielsweise im Ansatz des Va-\nlue Sensitive Design angestrebt wird.350 Dies kann der Unter -\nst\u00fctzung und Erweiterung menschlicher Autorschaft dienen.\nIm Folgenden werden diese Fragen anhand von Beispielen \naus den Bereichen des Sozialwesens (vgl. Abschnitt 8.3) und des \nPolizeiwesens (vgl. Abschnitt 8.4) exemplarisch illustriert und \nvertieft. Die beiden Felder wurden ausgew\u00e4hlt, weil in ihnen \nh\u00e4ufig Entscheidungen von gro\u00dfer Tragweite und m\u00f6glicher -\nweise gro\u00dfer Eingriffstiefe vorgenommen werden. Daher er -\nscheint es einerseits geboten, Technologien zu nutzen, welche \ndie Qualit\u00e4t dieser Entscheidungen verbessern k\u00f6nnen, indem \nsie beispielsweise genauere Vorhersagen liefern und Fehlent-\nscheidungen verringern. Ob KI-Technologien die Entschei-\ndungsqualit\u00e4t jedoch verbessern, h\u00e4ngt von deren Qualit\u00e4t ab. \nSo gilt es einerseits zu pr\u00fcfen, ob und in welchem Ausma\u00df es \ndurch den Einsatz von Software zur Entscheidungsunterst\u00fct-\nzung tats\u00e4chlich zu weniger Fehlern in beide Richtungen, das \nhei\u00dft weniger falsch-positiven und weniger falsch-negativen \nResultaten kommt. Zum anderen ist zu pr\u00fcfen, ob sich Ge-\nnauigkeit und Fehleranf\u00e4lligkeit f\u00fcr unterschiedliche Perso-\nnengruppen unterscheiden, um m\u00f6gliche diskriminierende \nEffekte zu vermeiden.\n350\tFriedman/Hendry\t2019.3068.3\t\t Automatische\tEntscheidungssysteme\t\nam\tBeispiel\tdes\tSozialwesens\nIm Sozialwesen sind auf der Grundlage einschl\u00e4giger (sozial-)\nrechtlicher Gesetze bzw. Ausf\u00fchrungsbestimmungen Ent-\nscheidungen mit weitreichenden Folgen f\u00fcr die Betroffenen \nzu treffen, so etwa \u00fcber die Gew\u00e4hrung von Hilfen, bei Ma\u00df-\nnahmen im Kontext einer Kindeswohlgef\u00e4hrdung oder bei der \nAbsch\u00e4tzung von Gef\u00e4hrdungspotenzialen straff\u00e4lliger Perso-\nnen in der Bew\u00e4hrungshilfe. Solche Entscheidungen werden \nvon den involvierten Fachkr\u00e4ften der Sozialverwaltungen \nf\u00fcr gew\u00f6hnlich unter enger Einbindung der Betroffenen und \nLeistungsberechtigten getroffen. So umfasst der Schutzauftrag \ndes Jugendamtes bei Kindeswohlgef\u00e4hrdung nicht nur die Er -\nhebung des Gef\u00e4hrdungsrisikos unter Einbeziehung aller re-\nlevanten Fachkr\u00e4fte, die mit dem betroffenen Kind und/oder \nden Personensorgeberechtigten beruflich in Kontakt stehen, \nsondern auch die unmittelbare Einbindung der Erziehungsbe-\nrechtigten sowie des betroffenen Kindes (\u00a7 8a SGB VIII). Oft-\nmals m\u00fcnden Entscheidungen der \u00f6ffentlichen Verwaltung in \nkonkrete Hilfeplanungen, die auf der Basis von Hilfeplanbe-\nsprechungen oder sogar f\u00f6rmlichen Hilfeplankonferenzen ge-\nmeinsam mit den Betroffenen erstellt und verbindlich verein-\nbart werden, nachdem ebenfalls gemeinsam auf der Basis einer \nRessourcen- und Potenzialanalyse der entsprechende Hilfebe-\ndarf erhoben wurde. Im Zentrum der Entscheidungsprozesse \nstehen deshalb Gespr\u00e4che, in denen die lebensweltliche Exper -\ntise der Betroffenen bzw. der Leistungsberechtigten mit der \nprofessionellen Expertise der Fachkr\u00e4fte verkn\u00fcpft werden.351 \nDies dient nicht nur der besseren Ergebnissicherung der pro-\nfessionellen Entscheidung, sondern unmittelbar auch der \nSteigerung der Lebensf\u00fchrungskompetenz der Betroffenen, \n351\t Schwabe\t2008;\tMoch\t2018.\tZur\t(verdr\u00e4ngten)\tFehlerhaftigkeit\tintuitions -\ngest\u00fctzten\tEntscheidens\tund\tder\tdringenden\tNotwendigkeit\tverbesserter\t\nEntscheidungsgrundlagen\tvgl.\tausf\u00fchrlich\tauch\tSchwabe\t2022.307insofern sie durch die gemeinsame Problemdiagnose auch der \neigenen Ressourcen gewahr werden k\u00f6nnen.\nDie Implementierung algorithmenbasierter Entschei-\ndungshilfen in die unterschiedlichen Arbeitsbereiche des So-\nzialwesens352 steht in Deutschland erst am Anfang.353 Andere \neurop\u00e4ische oder transatlantische L\u00e4nder weisen bereits ein \nerheblich h\u00f6heres Implementierungsniveau auf. Gleichwohl \nbefinden sich auch in Deutschland eine Reihe von Systemen \nin der Einf\u00fchrungs-, Erprobungs- oder Vorbereitungsphase.354 \nEine ethische Einordnung, die auch die internationale Ent-\nwicklung im Blick hat, ist deshalb auch f\u00fcr Deutschland von \ngro\u00dfem Interesse. Diese soll in den n\u00e4chsten Schritten entlang \nder Unterscheidung von Erweiterung und Verminderung pro-\nfessioneller Handlungsoptionen erfolgen, wobei es gerade im \nSozialwesen von Bedeutung ist, die Erweiterungs- bzw. Ver -\nminderungsdimensionen gerade auch aus der Perspektive der \nvon den Entscheidungen jeweils betroffenen Personen in den \nBlick zu nehmen.\n8.3.1 Erweiterung professioneller \nHandlungskompetenz\nUnbeschadet der fachlichen Bedeutsamkeit je spezifischer Per -\nsonenorientierung im Rahmen von Entscheidungsprozessen \nbieten Verfahren der Entscheidungsfindung, die auf einem \ngewissen Ma\u00df an Standardisierung \u2013 auch und gerade unter \nEinbeziehung algorithmenbasierter Erfassung und Steuerung \n\u2013 beruhen, gegen\u00fcber herk\u00f6mmlichen Verfahren wichtige \nVorteile. H\u00e4ufig h\u00e4ngen Entscheidungen \u00fcber die Gew\u00e4hrung \nvon Hilfen und anderen Interventionen im Sozialwesen im \nWesentlichen von intuitiven Einsch\u00e4tzungen der Fachkr\u00e4fte \n352\tSchneider\t2020.\n353\t Vgl.\tentsprechende\tBeitr\u00e4ge\tin\tKutscher\tet\tal.\t2020\t\u2013\tinsbesondere\t\u201eTeil\tVI:\t\nDigitalisierung\tin\tHandlungsfeldern\tder\tSozialen\tArbeit\u201c.\n354\tAlgorithmWatch\t2020,\t114\u00a0ff.308ab, selbst da, wo eine st\u00e4rkere Standardisierung von Entschei-\ndungsfindungen m\u00f6glich w\u00e4re. Solche intuitiven Einsch\u00e4t-\nzungen profitieren zwar von der beruflichen Erfahrung und \ndem in den relevanten Bereichen des Sozialwesens durchaus \nstark verbreiteten innerkollegialen Austausch. Wie eine hohe \nZahl empirischer Studien gleichwohl belegt, bleiben sie aber \nhinsichtlich ihrer Sachangemessenheit unter dem Qualit\u00e4ts-\nniveau \u201estatistisch-aktuarischer\u201c355 oder sogar \u201emustererken-\nnend-statistischer\u201c356 Ans\u00e4tze mittlerweile deutlich zur\u00fcck \n\u2013 m\u00f6glicherweise zum Nachteil der von den Entscheidungen \nBetroffenen. Dies zeigt sich besonders bei der Generierung \nprognostischen Wissens, also bei der Einsch\u00e4tzung \u00fcber Ge-\nf\u00e4hrdungs- oder Entwicklungspotenziale hilfebed\u00fcrftiger Per -\nsonen. F\u00fcr soziale Professionen, bei denen eine gute Wirkung \nvon Ma\u00dfnahmen im Mittelpunkt stehen muss, d\u00fcrfen die Vor -\nteile evidenzbasierter Instrumente daher nicht vernachl\u00e4ssigt \nwerden.357 In dieser Hinsicht kann die Verwendung von Soft-\nwaresystemen zur Entscheidungsunterst\u00fctzung grunds\u00e4tzlich \nzur Erweiterung professioneller Handlungskompetenz beitra-\ngen. Verbesserte Ergebnisse professioneller Entscheidungen \nf\u00fchren zudem in der Regel zu erweiterten Gestaltungsspielr\u00e4u-\nmen der professionell unterst\u00fctzten Hilfeempfangenden und \ndies ist der entscheidende Ma\u00dfstab zur Bewertung der G\u00fcte \nsozialprofessioneller Interventionen.\nEine Verbesserung der Entscheidungsgrundlage ist beson-\nders wichtig bei der Absch\u00e4tzung von Gef\u00e4hrdungspotenzia-\nlen, denen entweder besonders vulnerable Personen (Stichwort \n\u201eKindeswohlgef\u00e4hrdung\u201c, siehe Infokasten 10) ausgesetzt sind \noder die etwa von straff\u00e4llig gewordenen Personen f\u00fcr Dritte \n355\t Rettenberger\t2018.\n356\tSowohl\tder\taktuarialistische\tals\tauch\tder\tmustererkennende\tAnsatz\tist\t\nein\tmechanisches\tPrognoseverfahren\tund\tberuht\tauf\tspeziellen\tBerech-\nnungen.\tW\u00e4hrend\tdas\taktuarialistische\tVerfahren\tstatistische\tModelle\t\nverwendet,\tdie\tstets\tdurch\tStudien\tvalidiert\twerden\tm\u00fcssen,\tsind\tdie\t\nmustererkennenden\tModelle\tzur\tRisikoeinsch\u00e4tzung\tdynamisch\tangelegt\t\n(Schr\u00f6dter/Bastian/Taylor\t2020).\n357\t Lob-H\u00fcdepohl\t2021.309bzw. f\u00fcr die Allgemeinheit insgesamt ausgehen (siehe Infokas-\nten 11).358 Internationale Studien belegen, dass die Treffsicher -\nheit von Prognosen zur Eintrittswahrscheinlichkeit, die auf der \nBasis standardisiert-versicherungsmathematischer Berech-\nnungen vorgenommen werden, deutlich h\u00f6her ist als jene, die \nsich mehr oder minder allein auf die zwar fachlich geschulte, \ngleichwohl wesentlich intuitivere Einsch\u00e4tzung von Fachkr\u00e4f-\nten selbst mit hoher beruflicher Erfahrung st\u00fctzt.359 Aus die-\nsem Grund bilden besonders in den angels\u00e4chsischen L\u00e4ndern \npr\u00e4diktive Risikomodelle mittlerweile einen festen Bestandteil \nin der Entscheidung von Fachkr\u00e4ften bei der Frage, ob in einer \nbestimmten Fallkonstellation die Familiensituation zum ge-\ngenw\u00e4rtigen Zeitpunkt oder in Zukunft die Gef\u00e4hrdungslage \nf\u00fcr ein Kind ein solches Ausma\u00df angenommen hat oder haben \nwird, dass das gef\u00e4hrdete Kind in staatliche Obhut genommen \nwerden sollte oder aber noch in der Familie verbleiben kann.360\nEine vorschnelle pr\u00e4ventive Inobhutnahme verbietet sich \nnicht nur deshalb, weil damit elterliche Sorgerechte und da-\nmit Kinderrechte insgesamt ber\u00fchrt sind, sondern weil auch \ndie Herausnahme eines Kindes aus der Familie etwa durch den \nVerlust von sozialen Alltagsbindungen sein Wohl belastet. Da-\nmit stehen sich in diesen Entscheidungskonflikten in erster Li-\nnie nicht die moralischen Anspr\u00fcche zweier unterschiedlicher \nPersonen (Eltern gegen Kind) gegen\u00fcber, wohl aber zwei mora-\nlisch relevante G\u00fcter des Kindes (z. B. der Schutz vor \u00fcbergrif-\nfigem, gewaltf\u00f6rmigem Verhalten der Eltern und der Schutz \nder gewachsenen emotionalen Bindungen innerhalb der Fa-\nmilie), die beide zum Kindeswohl geh\u00f6ren, in der konkreten \nSituation aber kollidieren. Bestrebungen gehen nun dahin, \ndiese ethische G\u00fcterabw\u00e4gung mithilfe algorithmenbasierter \n358\tButz\tet\tal.\t2021.\n359\tBastian\t2012;\tBastian/Freres/Schr\u00f6dter\t2017;\tBastian\tet\tal.\t2018;\tGillingham\t\n2021.\n360\tGillingham\t2021.310Entscheidungsunterst\u00fctzung auf eine bessere Grundlage zu \nstellen.361\nInfokasten\t10:\tKindeswohlgef\u00e4hrdung\nADM-Systeme\t im\tKontext\tder\tEntscheidungsfindung\t bei\tKindeswohlgef\u00e4hr -\ndung\tsind\tmittlerweile\t auf\tnahezu\tallen\tKontinenten\t wenigstens\t in\tersten\t\nSchritten\t eingef\u00fchrt.\t Manche\t dieser\tAnwendungen\t sind\thoch\tumstritten,\t\netwa\taufgrund\t von\tUngenauigkeit,\t Fehleranf\u00e4lligkeit\t oder\tdiskriminieren-\nden\tEffekten.\nIn\tDeutschland\t befindet\t sich\tdie\tEinf\u00fchrung\t von\tADM-Systemen\t im\tBereich\t\nder\tKinder-\tund\tJugendhilfe\t zur\tGef\u00e4hrdungsabsch\u00e4tzung\t des\tKindeswohls\t\nin\tder\tPlanungs-\t und\tDiskussionsphase.\t Bereits\tetablierter\t Softwareeinsatz\t\nim\tBereich\tdes\tKindesschutzes\t schafft\tdazu\tdie\tn\u00f6tigen\t Voraussetzungen.\t\nOK.JUS362,\tdas\tBestandteil\t einer\tbreiten\tPalette\tvon\tDigitalanwendungen\t\nin\tder\t\u00f6ffentlichen\t Verwaltung\t ist,\tunterst\u00fctzt\t Jugend\u00e4mter\t bzw.\tdie\tfall-\nf\u00fchrenden\t Professionellen\t in\tder\tWahrnehmung\t ihres\tSchutzauftrags\t bei\t\nKindeswohlgef\u00e4hrdung\t gem\u00e4\u00df\t\u00a7\u00a08a\tSGB\tVIII.\tDieser\tSchutzauftrag\t besteht\t\ndarin,\tdass\tim\tFalle\tvon\tgemeldeten\t Hinweisen\t auf\teine\tKindeswohlgef\u00e4hr -\ndung\tdas\tJugendamt\t auf\tder\tBasis\tbisheriger\t Erkenntnisse\t zuverl\u00e4ssig\t und\t\nangemessen\t reagiert.\t OK.JUS\tdokumentiert\t nach\tvordefinierten\t Standards\t\ndie\tverschiedenen\t Arbeitsabl\u00e4ufe\t ab\tdem\tMeldeeingang\t bis\tzu\tetwaigen\t\nInterventionen\t sowie\tdie\tBewertung\t von\tMeldungen\t einschlie\u00dflich\t die\tzur\t\nEntscheidung\t notwendigen\t Unterlagen.\t Damit\tentstehen\t elektronische\t Ak-\nten,\tdie\tin\tVerbindung\t mit\tOK.JUS\tCAP,\teiner\tControlling-\t und\tAnalyseplatt -\nform\tmit\teiner\tVielzahl\t von\tEinzelberichten,\t der\tfallf\u00fchrenden\t Fachkraft\t\neine\tfundiertere\t Einsch\u00e4tzung\t der\tKindeswohlgef\u00e4hrdung\t erm\u00f6glichen.\t\nZugleich\t entsteht\t ein\tumfangreicher\t Datenpool,\t auf\tden\tdas\tADM-System\t\nzuk\u00fcnftig\tzugreifen\tkann.\nDeutlich\t weiterentwickelt\t sind\tADM-Systeme\t in\tanderen\t europ\u00e4ischen\t\nL\u00e4ndern\t bzw.\tin\t\u00dcbersee.363\tIn\tD\u00e4nemark\t etwa\twar\tdas\tGladsaxe-Modell\t\n\u2013\tbenannt\t nach\teinem\tOrt\tim\tUmkreis\t Kopenhagens\t \u2013\teines\tder\tersten\t\nProfilingsysteme,\t das\tverschiedene\t Risikoindikatoren\t kombiniert,\t um\tfr\u00fch-\nzeitig\tgef\u00e4hrdete\t Kinder\tin\tihren\tFamilien\t zu\terkennen.\t Es\tverbindet\t und\t\ngewichtet\t elternbezogene\t Sachverhalte\t wie\tErwerbslosigkeit,\t seelische\t Ge-\nsundheit,\t nicht\teingehaltene\t medizinische\t bzw.\tzahnmedizinische\t (Termin-)\nVereinbarungen\t oder\tauch\tScheidungen.\t Die\tendg\u00fcltige\t Einf\u00fchrung\t wurde\t\nnach\tersten\tPilotphasen\t auch\taufgrund\t erheblicher\t Proteste\t zur\u00fcckgestellt;\t\ndas\tSystem\twurde\taber\tin\tForschungskontexten\tweiterverwendet.364\nIn\tden\tNiederlanden\tstarteten\t bereits\tEnde\t der\t2000er-Jahre\t Versuche,\t das\t\nin\tden\tUSA\tentwickelte\t California\t Family\tRisk\tAssessment\t f\u00fcr\tden\tnieder-\nl\u00e4ndischen\t Kinderschutz\t nutzbar\t zu\tmachen\t und\tauf\tseine\tprognostische\t\n361\t Vgl.\tetwa\tdas\tForschungsprojekt\t\u201eKAIMo\t\u2013\tKann\tein\tAlgorithmus\tim\tKon-\nflikt\tmoralisch\tkalkulieren?\u201c\t(www.kaimo.bayern);\tGutwald\tet\tal.\t2021.\n362\thttps://www.akdb.de/loesungen/oksoziales/okjus\t[16.01.2023].\n363\tF\u00fcr\teine\tvergleichende\tStudie\tvgl.\tDrake\tet\tal.\t2020.\n364\tAlgorithmWatch\t2020,\t52\u00a0f.311Validit\u00e4t\t hinsichtlich\t des\tRisikos\tf\u00fcr\tGewalt\toder\tVernachl\u00e4ssigung\t von\t\nKindern\t in\tproblemaffinen\t Familien\t hin\tzu\t\u00fcberpr\u00fcfen.365\tDieses\talgorith-\nmenbasierte\t Assessment-Tool\t zielt\tauf\tdie\tSt\u00e4rkung\t standardisierter\t bzw.\t\nstrukturierter\t Fallf\u00fchrung\t (structured decision making).\t Es\tkombiniert\t zehn\t\nverschiedene\t Items,\tdie\tdas\tRisiko\teiner\tzuk\u00fcnftigen\t Vernachl\u00e4ssigung\t in-\ndizieren,\t mit\tweiteren\t zehn,\tdie\tdas\tRisiko\teines\tzuk\u00fcnftigen\t Missbrauchs\t\nanzeigen\t sollen.\tNeben\tAspekten\t wie\tunsichere\t Wohnverh\u00e4ltnisse\t oder\tfr\u00fc-\nher\teingetretene\t Gef\u00e4hrdungssituationen\t beziehen\t sich\tviele\tItems\tauf\tdie\t\n(elterlichen)\t Sorgeberechtigten\t (z.\u00a0B.\tseelische\t Gesundheit,\t Suchtprobleme,\t\nRechtfertigung\t von\tMissbrauch\t durch\tden\tSorgeberechtigten,\t Dominanz\t\nund\tStrenge).\t Studien\tergaben\t eine\tbeachtliche\t Treffsicherheit\t dieses\tPro-\ngnoseinstruments\tf\u00fcr\tein\tfr\u00fchzeitiges\tErkennen\tvon\tGef\u00e4hrdungslagen.366\nDemgegen\u00fcber\t legen\tStudien\taus\tNeuseeland\t und\tden\tUSA\tnahe,\tdass\tsich\t\ndie\tErwartungen\t an\tADM-Systeme\t mit\tBlick\tauf\teine\tverbesserte\t pr\u00e4dikti-\nve\tAnalytik\t nicht\tim\tgew\u00fcnschten\t Umfang\t erf\u00fcllen.367\tDas\tPredictive\t Risk\t\nModelling\t des\tneuseel\u00e4ndischen\t Centre\tfor\tApplied\tResearch\t in\tEconomics\t\nund\tdas\tAllegheny\t Family\tScreening\t Tool\tin\tPennsylvania\t (USA)\terweisen\t\nsich\tetwa\taufgrund\t der\tFehlerhaftigkeit\t der\tgenutzten\t bzw.\talgorithmisch\t\nverarbeiteten\t Items\tals\tzu\twenig\tpr\u00e4zise\toder\tsogar\tals\toffensichtlich\t verf\u00e4l-\nschend\tund\tdiskriminierend,\t was\tdie\tSpielr\u00e4ume\t f\u00fcr\tdie\tLebensgestaltung\t\nder\tBetroffenen\terheblich\tvermindert.\nEine \u00e4hnliche pr\u00e4diktive Risikodiagnostik erfolgt auch in der \nBew\u00e4hrungshilfe.368 Dort sind Fachkr\u00e4fte gehalten, Art und \nWeise ihrer Bew\u00e4hrungsf\u00fchrung dem Gef\u00e4hrdungspotenzial, \ndas von der unter Bew\u00e4hrungsaufsicht stehenden Person nach \nihrer Haftverb\u00fc\u00dfung f\u00fcr andere ausgeht, anzupassen und ent-\nsprechend engmaschig oder weitl\u00e4ufig anzulegen. Auch hier \nist die Entscheidung keinesfalls trivial: Eine engmaschige, also \nmit vielen kontrollierenden Auflagen und Ma\u00dfnahmen beleg-\nte Bew\u00e4hrungsf\u00fchrung geht automatisch zulasten der Freiheit \nder bew\u00e4hrungspflichtigen Person. Umgekehrt k\u00f6nnten bei \neiner weitl\u00e4ufigen Bew\u00e4hrungsf\u00fchrung unzumutbare Risiken \n365\tvan\tder\tPut\tet\tal.\t2016.\n366\tEbd.\n367\tGillingham\t2016;\t2021.\n368\tIn\t\u00e4hnlicher\tWeise\tgehen\tEinsch\u00e4tzungen\t\u00fcber\tdie\tLegalprognose\tbei\trich-\nterlichen\tEntscheidungen\t\u00fcber\tdas\tAussetzen\teiner\tFreiheitsstrafe\tgem\u00e4\u00df\t\n\u00a7\u00a7\u00a056,\t57,\t57a\tStGB\tein.\tAuch\thier\ter\u00f6ffnet\tsich\twie\tbei\tder\tStrafzumessung\t\ninsgesamt\tein\tbreites\tSpektrum\tdenkbarer\tEinsatzfelder\t(Kaspar/H\u00f6ffler/\nHarrendorf\t2020).\tDiese\tEinsatzm\u00f6glichkeiten\twerden\tim\tFolgenden\tnicht\t\nweiter\tthematisiert,\t da\tsie\tnicht\tin\tden\tBereich\tder\t\u00f6ffentlichen\t Verwaltung\t\nfallen.312f\u00fcr Dritte ausgehen. Deshalb versucht etwa der in den USA \nentwickelte und zwischenzeitlich auch in Deutschland in ei-\nnigen Bundesl\u00e4ndern etablierte Risk-Need-Responsivity-An-\nsatz369 mithilfe von algorithmenbasierten statistisch-aktuari-\nschen Prognoseinstrumenten, das individuelle R\u00fcckfallrisiko \nmehr oder minder valide zu ermitteln370 und damit \u2013 wie bei \nEntscheidungen im Rahmen der Kindeswohlgef\u00e4hrdung \u2013 ge-\nrichtsfest zu machen.\nInfokasten\t11:\tBew\u00e4hrungshilfe\nIn\tDeutschland\t orientiert\t sich\tdie\tBew\u00e4hrungshilfe\t in\tder\tAbsch\u00e4tzung\t\nvon\tGef\u00e4hrdungsrisiken\t \u00fcberwiegend\t am\tRisk-Need-Responsivity-Ansatz.\t\nDieser\tbemisst\t die\tLeistungsgestaltung\t der\tBew\u00e4hrungshilfe\t am\tjeweiligen\t\nGef\u00e4hrdungsrisiko,\t den\tdaraus\tsich\tableitenden\t Bedarfen\t sowie\tder\tspezi-\nfischen\tAnsprechbarkeit\t der\tleistungsempfangenden\t Person.\tBei\tder\tindi-\nviduellen\t R\u00fcckfallrisikoabsch\u00e4tzung\t werden\tacht\tRisikofaktoren\t (kriminelle\t\nVorbelastung,\t prokriminelle\t Einstellungen,\t prokriminelle\t Kontakte,\t antiso-\nziale/dissoziale\t Pers\u00f6nlichkeitsbez\u00fcge,\t Bindungen\t im\tBereich\tEhe/Familie,\t\nBindungen\t im\tBereich\t Schule/Arbeit,\t Substanzmittelmissbrauch,\t Freizeit-\naktivit\u00e4ten)\t einbezogen.371\tDiese\tRisikofaktoren\t werden\tunter\tZuhilfenahme\t\nvon\tstatistisch-aktuarischen\t Prognoseinstrumenten\t gewichtet.\t Sie\tbilden\t\ndie\tGrundlage\t f\u00fcr\tdie\tvon\tder\tjeweils\tzust\u00e4ndigen\t Fachkraft\t durchzuf\u00fchren-\nde\tRisikoabsch\u00e4tzung,\t die\tin\tden\teinzelnen\t Bundesl\u00e4ndern\t allerdings\t unter-\nschiedlich\tstrukturiert\tund\tteilweise\tstandardisiert\tist.372\nIn\tder\tSchweiz\t sind\tADM-Systeme\t im\tRahmen\t des\tRisikoorientierten\t Sank-\ntionenvollzugs\t (ROS)\tin\tVollzugs-\t wie\tBew\u00e4hrungsdiensten\t bereits\tetab-\nliert.373\tROS\tsieht\tdie\tAbkl\u00e4rung\t des\tindividuellen\t R\u00fcckfallrisikos\t einer\tge-\nwaltt\u00e4tigen\t Person\tim\tRahmen\t eines\tvierstufigen\t Prozesses\t vor,\tder\terstens\t\naus\teiner\tTriage,\tzweitens\t aus\teiner\tgenaueren\t Abkl\u00e4rung\t des\tFalles,\tdrit-\ntens\taus\tder\tPlanung\t etwaiger\t Interventionsinstrumente\t und\tviertens\t aus\t\ndem\tkontinuierlich\t ausgewerteten\t Verlauf\tbesteht.\t Kern\tder\tersten\tStufe,\tin\t\nder\tdie\tDringlichkeit\t (Triage)\teiner\tgenaueren\t Risikoabsch\u00e4tzung\t abgekl\u00e4rt\t\nwird,\tbildet\tein\tFall-Screening-Tool\t (FaST),\tdas\tals\tADM-System\t die\tjeweili-\ngen\tF\u00e4lle\tdrei\tKategorien\t zuordnet:\t Die\tF\u00e4lle\tder\tKategorie\t A\tmit\teinem\tge-\nringen\tR\u00fcckfallrisiko\t ben\u00f6tigen\t keinerlei\t weitere\tRisikoprognosen;\t die\tF\u00e4lle\t\nder\tKategorie\t B\tmit\teinem\terh\u00f6hten\t R\u00fcckfallrisiko\t ben\u00f6tigen\t als\tweiteren\t\nRisikoprognoseschritt\t eine\tKurzabkl\u00e4rung,\t die\tdie\tfallf\u00fchrende\t Fachkraft\t\nmittels\teiner\tCheckliste\t aus\tverschiedenen\t Quellen\t (z.\u00a0B.\tStrafregister,\t Gut-\nachten)\t erstellt\t(Fallres\u00fcmee);\t die\tF\u00e4lle\tder\tKategorie\t C\tmit\teinem\thohen\t\n369\tPolaschek\t2012.\n370\tCornel/Pruin\t2021.\n371\t Andrews/Bonta\t2010,\t44\u00a0ff.\n372\tCornel/Pruin\t2021.\n373\t Treuthardt/Loewe-Baur/Kr\u00f6ger\t2018.313R\u00fcckfallrisiko\t bed\u00fcrfen\t der\tpr\u00e4zisen\t Beurteilung\t aller\tverf\u00fcgbaren\t Informa-\ntionen\tdurch\teine\tforensisch\t geschulte\t psychologische\t Fachkraft\t (Risikoab-\nkl\u00e4rung)\t im\tSinne\teiner\tstrukturierten\t Urteilsbildung.\t Das\tFaST\tselbst\tkom-\nbiniert\tund\tgewichtet\t unterschiedliche\t Items\tund\tklassifiziert\t den\tjeweils\t\nanstehenden\tFall\tauf\tder\tBasis\tstatistisch-aktuarischer\tVerfahren.374\nBereits\tseit\tAnfang\tder\t2000er-Jahre\t kommt\tin\tmehreren\t US-Bundesstaaten\t\ndie\taufgrund\t diskriminierender\t Prognosen\t sehr\tumstrittene\t Software\t COM-\nPAS\t(Correctional\t Offender\t Management\t Profiling\t for\tAlternative\t Sanc-\ntions)\tzum\tEinsatz.375\tSie\tkann\tsowohl\tbei\tder\trichterlichen\t Strafzumessung\t\nwie\tbeim\tnachfolgenden\t Strafvollzug\t oder\tbeim\tsp\u00e4teren\t Bew\u00e4hrungsdienst\t\nzur\tAnwendung\t kommen.\t Es\twurde\tim\tBem\u00fchen\t einer\tevidenzbasierten\t\nEntscheidungsfindung\t eingef\u00fchrt,\t um\tin\tden\tverschiedenen\t Phasen\teines\t\nFallverlaufes\t sowohl\taufseiten\t der\tentscheidenden\t Person\tdas\tUngewiss -\nheitspotenzial\t als\tauch\taufseiten\t der\tBev\u00f6lkerung\t das\tGef\u00e4hrdungspoten-\nzial\tdurch\tm\u00f6glicherweise\t r\u00fcckf\u00e4llige\t gewaltt\u00e4tige\t Personen\t zu\tverringern.\t\nCOMPAS\t selbst\tkommt\tsowohl\tim\tKontext\tder\tUntersuchungshaft\t wie\tauch\t\nw\u00e4hrend\t und\tnach\tder\tHaftzeit\t (Bew\u00e4hrung)\t zur\tAnwendung.\t Es\tkombiniert\t\n137\tItems\tund\tdifferenziert\t damit\tdrei\tGrobklassifizierungen:\t niedriges,\t\nmittleres\t und\thohes\tR\u00fcckfallrisiko.376\tCOMPAS\t umfasst\t neben\teiner\tRisiko-\nprognose\t auch\tein\tdarauf\taufbauendes\t needs assessment,\t das\tin\tdie\tweitere\t\nInterventionsplanung\t eingeht.\t COMPAS\t gilt\tin\tder\tinternationalen\t Debatte\t\n\u00fcber\tdie\tEinf\u00fchrung\t von\tADM-Systemen\t in\tVollzugs-\t und\tBew\u00e4hrungsdiens -\nte\ttrotz\t\u2013\toder\tgerade\twegen\t\u2013\tder\terheblichen\t Vorbehalte,\t die\tihm\tnational\t\nund\tinternational\tgegen\u00fcberstehen,\tals\tzentraler\tBezugspunkt.377\n8.3.2 Verminderung von Entscheidungskompetenz, \nHandlungsoptionen und Autorschaft\nNachdem vorausgehend insbesondere die Erweiterung von \nHandlungskompetenz im Mittelpunkt stand, ist demgegen-\n\u00fcber zu konstatieren, dass menschliche Autorschaft unter \nZuhilfenahme sachdienlicher Ergebnisse von KI-Algorithmen \nallerdings auch vermindert werden kann. Auf der professio-\nnellen Seite kann dies beispielsweise dann der Fall sein, wenn \nsie unbesehen zu einer blo\u00dfen \u00dcbernahme algorithmisch \n374\tTreuthardt/Kr\u00f6ger\t2019.\n375\t https://www.propublica.org/article/machine-bias-risk-assessments-in-\ncriminal-sentencing\t[17.01.2023].\n376\tHartmann/Wenzelburger\t2021.\n377\thttps://www.propublica.org/article/machine-bias-risk-assessments-in-\ncriminal-sentencing\t[17.01.2023].314vorgeschlagener Ergebnisse f\u00fchrt \u2013 aus welchen Gr\u00fcnden auch \nimmer (z. B. Zeitdruck, allm\u00e4hliche Gew\u00f6hnung oder um im \nFalle einer juristischen Auseinandersetzung auf der vermeint-\nlich sicheren Seite zu sein). Auch f\u00fcr die von den Ergebnis-\nsen betroffenen Personen sind negative Effekte m\u00f6glich, etwa \nwenn ihnen aufgrund algorithmisch unterst\u00fctzter Entschei-\ndungen Handlungs- oder Entwicklungsm\u00f6glichkeiten genom-\nmen werden.\nSo dokumentieren die hier vorgestellten Einsatzm\u00f6glich-\nkeiten pr\u00e4diktiver Diagnosen von Gef\u00e4hrdungspotenzialen in \nden Bereichen Kindeswohlgef\u00e4hrdung und Bew\u00e4hrungshilfe \nauf der einen Seite einen gewissen Zugewinn an Sachange-\nmessenheit und Wirksamkeit von sozialprofessionellen In-\nterventionen, wenn die Entscheidung der Fachkr\u00e4fte durch \nalgorithmenbasierte, statistisch-aktuarische Eintrittswahr -\nscheinlichkeitsberechnungen unterst\u00fctzt wird. Auf der ande-\nren Seite offenbaren sich gleichwohl auch Schwachstellen und \nRisiken f\u00fcr eine sachgem\u00e4\u00dfe und nicht zuletzt personenorien-\ntierte Entscheidung, die den individuellen Hilfebedarfen der \nBetroffenen Rechnung zu tragen hat.\nHier treten wieder die beiden zuvor genannten Problem-\nfelder auf: Einerseits k\u00f6nnen sich bei datenbasierten Systemen \ndiskriminierende Effekte zeigen (Algorithmic Bias). So kann \nbereits die Datenlage, die den standardisierten Entscheidun-\ngen und mehr noch den digitalisierten algorithmischen Pro-\nzessen der Mustererkennung zugrunde liegt, die Sachlage \nverf\u00e4lschen und gef\u00e4hrliche Stereotypisierungen und gesell-\nschaftliche Ungleichheit aus der Vergangenheit in die Gegen-\nwart und Zukunft verl\u00e4ngern. Wenn beispielsweise bei der \nprognostischen Einsch\u00e4tzung der Kindeswohlgef\u00e4hrdung auf \nPr\u00e4diktoren zur\u00fcckgegriffen wird, die \u2013 wie das Beziehen von \nSozialhilfe, alleinerziehende Elternschaft oder fr\u00fcherer Kon-\ntakt mit einer Jugendschutzbeh\u00f6rde \u2013 ohne Beachtung des \nkonkreten Kontextes h\u00f6chst zweifelhaft sind, dann werden sie \ngleichsam automatisch zuk\u00fcnftige Entscheidungen fehlleiten \nsowie bestehende Ungleichheiten (Beziehen von Sozialhilfe) 315und Vorurteilsstrukturen (alleinerziehende Elternschaft, vor -\nurteilsbelastete oder sogar b\u00f6sartige Fehlanzeigen bei Kinder -\nschutzbeh\u00f6rden) unbesehen fortschreiben.378\nAndererseits steigt das Risiko eines Automation Bias mit \nAuswirkungen auf Fragen der Autonomie, Autorschaft und \nVerantwortung.379 Gerade bei Entscheidungen, die mit einer \ngro\u00dfen prognostischen Unsicherheit konfrontiert sind und \nzugleich gravierende Auswirkungen haben, besteht die laten-\nte Tendenz, automatisierten Entscheidungsprozeduren mehr \nzu vertrauen als menschlichen Entscheidungen und damit die \nVerantwortung \u2013 zumindest unbewusst \u2013 von sich auf diese \n\u201eQuasi-Akteure\u201c zu delegieren. Bisweilen wird versucht, die-\nser Gefahr vorzubeugen, indem bei Verwendung eines Ent-\nscheidungsunterst\u00fctzungstools ein entsprechender Warnhin-\nweis gegeben wird.380 Eine weitere denkbare Vorkehrung w\u00e4re \ndie Verpflichtung der entscheidenden Fachkr\u00e4fte, die etwaige \n\u00dcbernahme des algorithmischen Entscheidungsvorschlags \u2013 \netwa mit Verweis auf die eigene erfahrungsbezogen intuitive \noder kollegial er\u00f6rterte Prognose \u2013 ausdr\u00fccklich zu begr\u00fcnden.\nMit Blick auf die Bew\u00e4hrungshilfe birgt die Nutzung sta-\ntistisch-aktuarischer Risikoprofile dar\u00fcber hinaus die Gefahr, \ndass die eigentlich prim\u00e4re Zielsetzung der Bew\u00e4hrungshilfe, \nn\u00e4mlich die subjektiven wie die objektiven Ressourcen der \nbew\u00e4hrungspflichtigen Person f\u00fcr Rehabilitation und Wie-\ndereingliederung in die Gesellschaft zu aktivieren, zur\u00fcckge-\ndr\u00e4ngt wird, zugunsten der Risikominimierung im Bereich \nder Gef\u00e4hrdung f\u00fcr andere.381 Diese Verschiebung geht ein-\ndeutig zulasten der bew\u00e4hrungspflichtigen Person und \n378\tGillingham\t2021,\t32.\n379\tSafdar/Banja/Meltzer\t2020.\n380\tIn\tden\tUSA\twird\tbei\tVerwendung\tdes\tCOMPAS-Systems\tzur\tRisikoprog -\nnose\tvon\t(ehemaligen)\tStrafgefangenen\tein\tentsprechender\tWarnhinweis\t\ngegeben.\t\u00dcber\tdie\tWirksamkeit\tdieses\tWarnhinweises\tliegen\tbislang\taber\t\nkeine\tErkenntnisse\tvor\t(Butz\tet\tal.\t2021,\t252).\n381\t Ghanem\t2021.316vermindert im Falle der Nichtaktivierung ihrer Ressourcen \nihre Lebensf\u00fchrungskompetenz.382\nInsgesamt zeigt sich eine ambivalente Entwicklung f\u00fcr \ndie Entscheidungshoheit der eingesetzten Fachkr\u00e4fte: Algo-\nrithmenbasierte Entscheidungshilfen sollen lediglich fachlich \nweniger angemessene, intuitive Entscheidungsgrundlagen \nersetzen und die Basis f\u00fcr qualitativ bessere Entscheidungen \nder Fachkr\u00e4fte liefern, welche jedoch die letztverantwortliche \nEntscheidungsbefugnis beibehalten. Faktisch aber k\u00f6nnen die \nalgorithmenbasierten Entscheidungshilfen eine pr\u00e4figurative \nWirkmacht entfalten, die die letztendscheidenden Fachkr\u00e4f-\nte schon in ihrer Wahrnehmung von Hilfebedarfen in vor -\ngegebene Deutungs- und Entscheidungsmuster lenkt. Dieser \nEffekt wird verst\u00e4rkt, wenn sich Fachkr\u00e4fte f\u00fcr eine von den \ndigital vorgeschlagenen Optionen abweichende Entscheidung \nrechtfertigen m\u00fcssen \u2013 etwa vor Vorgesetzten oder gar vor \nGerichten. Damit kann es im faktischen Verhalten zu einer \nVerminderung der Entscheidungskompetenz der Fachkr\u00e4fte \nund mithin zu ihrer schleichenden Verdr\u00e4ngung oder sogar \nErsetzung kommen. Die Entscheidungskompetenz der Fach-\nkr\u00e4fte w\u00fcrde prek\u00e4r: formal und prima facie gegeben, faktisch \naber unterwandert durch die Wirkmacht algorithmenbasierter \nEntscheidungsvorgaben.\nAuch in anderen Bereichen der \u00f6ffentlichen Sozialver -\nwaltung kommt es zu \u00e4hnlichen Entwicklungen, wenn algo-\nrithmische Systeme zur Prognose des mutma\u00dflichen Ent-\nwicklungspotenzials von Hilfebed\u00fcrftigen eingesetzt werden, \nbeispielsweise bei Entscheidungen \u00fcber die Gew\u00e4hrung von \nSach-, Geld- und Dienstleistungen (z. B. Sozialhilfe oder Wei-\nterbildungsma\u00dfnahmen f\u00fcr Erwerbslose). Algorithmenbasier -\nte Prognosen und Klassifizierungen k\u00f6nnen hier unmittelbare \nFolgen f\u00fcr die Art und das Ausma\u00df von Unterst\u00fctzungsma\u00df-\nnahmen haben und damit entscheidend f\u00fcr die Gew\u00e4hrung \noder auch Verweigerung von Lebenschancen sein. Dies kann \n382\tButz\tet\tal.\t2021,\t254\u00a0ff.317zur Verminderung von Entwicklungsm\u00f6glichkeiten und Au-\ntorschaft der betroffenen Personen f\u00fchren.\nDie professionell ausgestaltete dialogisch-interaktive Be-\nziehungsarbeit bildet den zentralen Rahmen zur Identifikation \neines individuellen Hilfebedarfs. Der Einsatz standardisierter \nErfassung von Hilfebedarfen birgt demgegen\u00fcber das Risiko \nder Entkopplung aus einer dialogischen Beziehungsarbeit, je-\ndenfalls dann, wenn nicht explizit dialogische Konzepte wei-\nterhin vorgesehen bleiben. Der Hilfebedarf erschlie\u00dft sich \nnicht allein aus objektiven Tatbestandsmerkmalen, sondern \nmuss aus fachlichen Gr\u00fcnden die subjektive Perspektive der \nhilfebed\u00fcrftigen Person auf die eigene Lebenslage einbeziehen. \nEine Einbindung der betroffenen Person ist auch entscheidend \nf\u00fcr die Erfahrung von Selbstwirksamkeit383, ohne die positive \nEffekte selbst materieller Hilfeleistungen schnell verpuffen \nund damit kaum nachhaltig wirken. Die Gefahr, dass die In-\ndividualit\u00e4t von Klientinnen und Klienten ignoriert und da-\nmit die Wirksamkeit der angebotenen Unterst\u00fctzung verfehlt \nwird, steigt im Zuge algorithmenbasierter Informatisierung \ndes Sozialwesens erheblich an.384\nEin eindr\u00fcckliches Beispiel f\u00fcr die letztgenannte Problema-\ntik algorithmischer Chancenprognose ist das Arbeitsmarkt-\nchancen-Assistenzsystem (AMAS), auch AMS-Algorithmus \ngenannt, in \u00d6sterreich.385 Es kommt in der Sozialverwaltung \ndann zum Einsatz, wenn bei einer arbeitssuchenden Person \ndie Chancen ermittelt werden, innerhalb eines bestimmten \nZeitfensters erfolgreich wieder in ein regul\u00e4res Erwerbsar -\nbeitsverh\u00e4ltnis zu gelangen. Das System klassifiziert alle Ar -\nbeitssuchenden in Gruppen mit niedriger, mittlerer oder hoher \nErfolgsprognose. Dementsprechend werden ihnen bestimmte \nService-, Beratungs- oder Betreuungsleistungen angeboten \noder aber auch nicht angeboten. Zwar ist die Entscheidung \n383\tBeck/Greving\t2012;\tGrunwald/Thiersch\t2016.\n384\tLey/Reichmann\t2020;\tG\u00f6rder\t2021.\n385\tAllhutter\tet\tal.\t2020a.318der Fachkr\u00e4fte formal vom Vorschlag des Systems abgetrennt. \nPersonen, die mit ihrer Entscheidung von der algorithemen-\nbasierten Einstufung abweichen und eine Umstufung vorneh-\nmen, m\u00fcssen dies aber ausdr\u00fccklich vermerken und begr\u00fcn-\nden. Der AMS-Algorithmus \u2013 so eine interdisziplin\u00e4re Studie \ndes Instituts f\u00fcr Technikfolgen-Absch\u00e4tzung der \u00d6sterreichi-\nschen Akademie der Wissenschaften \u2013 ist ganz offensichtlich \nan den Werten, Normen und Zielen einer restriktiven Fiskal-\npolitik ausgerichtet.386 Ein solches System ist mitnichten neu-\ntral. Vielmehr l\u00e4uft es den Zielen eines personenorientierten \nHilfesystems, das individuelle Hilfebedarfe betroffener Perso-\nnen fokussieren muss, diametral zuwider.387 Mit dem Einsatz \nsolcher Systeme ist oftmals die Abkehr von einem zentralen \nPrinzip des Sozial- und Wohlfahrtswesens verbunden: der Er -\nmittlung des individuellen Hilfebedarfs und der auf diesem \nHilfebedarf aufruhenden Angebote, neben s\u00e4chlicher und fi-\nnanzieller Unterst\u00fctzung besonders durch Dienstleistungen \nwie Weiterbildungsangebote jeder hilfebed\u00fcrftigen bzw. leis-\ntungsberechtigten Person eine Lebensf\u00fchrung zu erm\u00f6glichen, \ndie \u201eder W\u00fcrde des Menschen entspricht\u201c (\u00a7 1 Abs. 1 SGB II).\nAngesichts der zuvor geschilderten Problematik ist es nicht \nverwunderlich, dass die Automatisierung der \u00f6ffentlichen Ver -\nwaltung im Sozialwesen h\u00e4ufig kritisch gesehen wird. So wird \nin einem vielbeachteten Sonderbericht der Vereinten Natio-\nnen vor der Gefahr einer \u201edigitalen Wohlfahrtsdystopie\u201c, das \nhei\u00dft vor der Schaffung einer menschenrechtsfreien Zone ge-\nwarnt, die insbesondere dann problematisch sei, wenn private \nUnternehmen f\u00fcr die Entwicklung und Implementierung von \nIT-L\u00f6sungen f\u00fcr den Sozialstaat verantwortlich zeichnen.388 \nDiese Kritik ist keine Einzelmeinung. In den letzten Jahren \nhaben sich immer mehr journalistische, wissenschaftliche \nund zivilgesellschaftliche Arbeiten und Initiativen kritisch mit \n386\tEbd.\n387\tAllhutter\tet\tal.\t2020b.\n388\tAlston\t2019,\t2.319den Auswirkungen staatlicher Automatisierungsbem\u00fchungen \nim Sozialwesen befasst. So kommt etwa Virginia Eubanks zu \ndem Schluss, dass automatisierte Entscheidungssysteme das \nsoziale Sicherheitsnetz in den USA unterminieren, mit einem \nVertrauensverlust dem Staat gegen\u00fcber einhergehen und so-\nmit Armut, Ungleichheit und Ungerechtigkeit weiter verst\u00e4r -\nken w\u00fcrden.389 Zu einem \u00e4hnlichen Verdikt kommt Monique \nMann im Zuge ihrer Analyse des \u201eRobodebt Scheme\u201c, eines \nautomatisierten Inkassosystems der australischen Sozialhilfe, \ndas gef\u00e4hrdete und schutzbed\u00fcrftige Bev\u00f6lkerungsgruppen \nunrechtm\u00e4\u00dfig mit Schulden belaste, anstatt Armut und Un-\ngleichheit zu verringern.390\nW\u00e4hrend Automatisierungsprojekte von staatlicher Seite \nmeist als Mittel zur Kostenreduktion und erh\u00f6hter Effizienz \ngepriesen werden, zeigen Analysen wie die oben genannten \nm\u00f6gliche Gefahrenpotenziale und weisen auf die Notwendig-\nkeit einer breiten \u00f6ffentlichen Debatte insbesondere \u00fcber die \nethischen Fragen hin. Die Verminderung menschlicher Au-\ntorschaft hat viele Facetten. Aufseiten der Menschen, die f\u00fcr \nEntscheidungen verantwortlich sind, kann sie in einer Herab-\nstufung der Betrachtung individueller F\u00e4lle zugunsten einer \nstatistik- und datengetriebenen Klassifikation bestehen oder \nauch in der schleichenden Gew\u00f6hnung an ADM-Verfahren. \nDadurch kann auch die Schwelle sinken, trotz eigener anders-\nlautender Einsch\u00e4tzung den Empfehlungen der ADM-Syste-\nme zu folgen und damit die Grenze von einem decision support \nzu einem automated decision making zu \u00fcberschreiten, in dem \nder Maschine die Letztentscheidungsmacht \u00fcberlassen wird. \nAufseiten der von den Entscheidungen jeweils Betroffenen \nzeigt sich die vermindernde Wirkung in der Nichtbeachtung \nvon Aktivierungspotenzialen f\u00fcr eine eigenst\u00e4ndige Lebens-\nf\u00fchrung bis hin zur Verweigerung eigentlich offenstehender \nund nutzbarer Entwicklungschancen.\n389\tEubanks\t2018.\n390\tMann\t2020.3208.4\t Predictive\tPolicing\t\u2013\tKI\tin\tder\t\nKriminalit\u00e4tsbek\u00e4mpfung\nIn der Kriminalit\u00e4tsbek\u00e4mpfung k\u00f6nnen algorithmenbasierte \nRisikoanalysen nicht nur \u2013 wie im Falle der Bew\u00e4hrungshilfe \n\u2013 \u00fcberf\u00fchrte straff\u00e4llige Personen betreffen, sondern auch zur \nIdentifikation potenziell straff\u00e4lliger Personen im Rahmen pr\u00e4-\nventiver Polizeiarbeit eingesetzt werden. \u00dcblicherweise werden \nunter dem Begriff des Predictive Policings analytisch-techni-\nsche, h\u00e4ufig algorithmenbasierte Anwendungen verstanden, \ndie pr\u00e4ventive Polizeiarbeit unterst\u00fctzen und mittels Progno-\nsen k\u00fcnftiger Straftaten, straff\u00e4lliger Personen und Tatorte der \nVerhinderung von Verbrechen dienen (siehe Infokasten 12).391\nDie entsprechenden Programme kommen mit dem Ver -\nsprechen daher, gro\u00dfe Mengen an mitunter heterogenen und \nverstreuten Daten schneller miteinander zu verkn\u00fcpfen und \nso zur Verbrechensbek\u00e4mpfung auswerten zu k\u00f6nnen. Ver -\nwendet werden sowohl raum- als auch personenbezogene Ver -\nfahren. Raumbezogene Methoden identifizieren durch Ver -\nkn\u00fcpfung diverser Datenbest\u00e4nde Orte, an denen mit einer \nbestimmten Wahrscheinlichkeit eine Straftat begangen wird, \nw\u00e4hrend personenbezogene Methoden mit T\u00e4terprofilen und \nOpfermerkmalen arbeiten, um Personen, die mit hoher Wahr -\nscheinlichkeit straff\u00e4llig werden k\u00f6nnten, vorab zu erkennen. \nIn den USA kommen sie seit 2005 zum Einsatz.\nInfokasten\t12:\tPredictive\tPolicing\nIn\tDeutschland\t kommen\t bislang\tin\terster\tLinie\traumbezogene\t Verfahren\t\ndes\tPredictive\t Policings\t zum\tEinsatz,\tdie\tdurch\tdie\tAusweisung\t pr\u00e4diktiver\t\n391\t H\u00e4rtel\t2019,\t54\u00a0f.;\tRademacher\t2017,\t368\u00a0ff.\tAuch\twenn\tBew\u00e4hrungsent -\nscheidungen\tnicht\tdurch\tPolizeibeh\u00f6rden,\tsondern\tGerichte\tgetroffen\t\nwerden,\tlassen\tsich\tauch\tdort\tVerfahren\t\u00e4hnlich\tdem\tPredictive\tPolicing\t\nverwenden,\tweil\tdiese\tEntscheidungen\teinem\tgefahrenabwehrrechtlichen\t\nZweck\tverschrieben\tsind.\tDer\tSache\tnach\tgeht\tes\tum\teine\tGef\u00e4hrlichkeits -\nprognose\tin\tBezug\tauf\teine\tPerson,\tdie\tbereits\teine\tStraftat\tbegangen\that,\t\nanl\u00e4sslich\tdieser\tkonkreten\tTat.321Risikogebiete\t mit\tzeitlicher\t Pr\u00e4ferenz\t gekennzeichnet\t sind.392\tIn\tder\tHaupt-\nsache\trichten\tsich\tdie\tVerfahren\t auf\tdie\tVorhersage\t raumzeitlicher\t Parame-\nter\tbei\tWohnungseinbruchdiebst\u00e4hlen.393\tDabei\tkommen\t folgende\t Program-\nme\tzum\tEinsatz:\t PRECOBS,\t SKALA,\tKrimPro,\t PreMAP\t und\tKLB-operativ.394 \nPRECOBS,\t PreMAP\t und\tKLB-operativ\t beruhen\t auf\tder\tNear-Repeat-Metho-\nde395,\tbasierend\t auf\tdem\tUmstand,\t dass\tnach\teiner\tAusgangstat\t in\tr\u00e4um-\nlich-zeitlicher\t N\u00e4he\th\u00e4ufig\tweitere\tTaten\tbegangen\t werden396,\talso\tdass\tdas\t\nBegehen\t einer\tStraftat\tweitere\tTaten\tin\tunmittelbarer\t N\u00e4he\tund\tinnerhalb\t\neines\tbestimmten\t Zeitraums\t nach\tsich\tziehen\twerde397.\tDabei\twerden\tin\tder\t\nRegel\tpolizeilich\t ermittelte\t Daten\tzugrunde\t gelegt.398\tSKALA\thingegen\t legt\t\nKriminalit\u00e4tstheorien\t zugrunde,\t die\tnach\tAuffassung\t des\tnordrhein-westf\u00e4-\nlischen\tLandeskriminalamtes\t geeignet\t sind,\tein\tm\u00f6glichst\t realistisches\t Bild\t\nvon\tWohnungseinbruchdiebst\u00e4hlen\t zu\tzeichnen.399\tDazu\tgeh\u00f6ren\t Rational-\nChoice-Theorien,\t wonach\t Personen,\t die\teinen\tEinbruch\t planen,\tvor\tder\tTat\t\neine\tKosten-Nutzen-Abw\u00e4gung\t vornehmen400,\tdass\talso\tzum\tBeispiel\t die\t\nerwartete\t H\u00f6he\tdes\tDiebesgutwerts\t die\tWahrscheinlichkeit\t von\tWohnungs -\neinbruchdiebst\u00e4hlen\t in\teinem\tGebiet\terh\u00f6ht401.\tAuch\tKrimPro\t beruht\tauf\t\neinem\tkriminologisch\t komplexeren\t Ansatz\tund\tst\u00fctzt\tseine\tPrognose\t auf\t\nverschiedene\tKriminalit\u00e4tstheorien.402\nPersonenbezogene\t Verfahren\t des\tPredictive\t Policings403\tst\u00fctzen\tdie\tProg-\nnose\tauf\tT\u00e4ter-\tbzw.\tOpfermerkmale404.\tZu\tnennen\t ist\tbeispielhaft\t das\tin\t\n392\tPovalej/Volkmann\t2021,\t58.\n393\tEgbert\t2018,\t244.\n394\tEgbert\t2020,\t33.\n395\tKnobloch\t2018,\t13.\n396\tGluba\t2017,\t369.\n397\tKuhlmann/Trute\t2021,\t105.\n398\tEisele/B\u00f6hm\t2020,\t522.\n399\tLandeskriminalamt\tNRW\t2018,\t10\u00a0ff.;\tEisele/B\u00f6hm\t2020,\t523.\n400\tL\u00fcdemann/Ohlemacher\t2002,\t54.\n401\tLandeskriminalamt\tNRW\t2018,\t12.\n402\tKnobloch\t2018,\t13;\tEisele/B\u00f6hm\t2020,\t524.\n403\tAuch\tTechnologien,\tdie\tim\tKontext\tder\tEntscheidung\t\u00fcber\tdie\tStrafausset -\nzung\tzur\tBew\u00e4hrung\tzum\tEinsatz\tkommen\t(z.\u00a0B.\tdie\tSoftware\tCOMPAS),\t\nlassen\tsich\tals\tVerfahren\tdes\tPredictive\tPolicings\teinstufen,\tinsoweit\t\ndiese\tebenfalls\tauf\tdie\tindividuelle\tGef\u00e4hrlichkeit\tder\tstraff\u00e4lligen\tPerson\t\nabstellen.\tSofern\tletzterer\tn\u00e4mlich\teine\tnegative\tSozialprognose\terteilt\t\nwird,\tsteht\tdies\teiner\tStrafaussetzung\tzur\tBew\u00e4hrung\tentgegen.\tDamit\tist\t\ndie\tBew\u00e4hrungsentscheidung\tder\tSache\tnach\teine\tgefahrenabwehrrechtli-\nche.\tIm\tdeutschen\tRecht\tmuss\tgleichwohl\tber\u00fccksichtigt\twerden,\tdass\tdie\t\nT\u00e4tigkeit\tvon\tGerichten,\tdie\t\u00fcber\tdie\tStrafaussetzung\tzur\tBew\u00e4hrung\tent -\nscheiden,\tklassischerweise\tvon\tder\tPolizeiarbeit\tgetrennt\twird.\tEs\tist\tdaher\t\nweniger\t\u00fcblich,\tdie\tBew\u00e4hrungsentscheidung\tals\tpolizeiliche\tT\u00e4tigkeit\t\neinzuordnen,\twas\tzumindest\tformell\tgegen\tdie\tEinstufung\tals\tPredictive\t\nPolicing\tspricht.\n404\tPovalej/Volkmann\t2021,\t58.\tDie\tDifferenzierung\tzwischen\traum-\tund\tperso-\nnenbezogenen\tVerfahren\tdes\tPredictive\tPolicings\tist\talles\tandere\tals\ttrenn-\nscharf.\t\u00dcberschneidungen\tergeben\tsich\tbereits\tdaraus,\tdass\traumzeitliche\t\nParameter\tnicht\tselten\tauf\tdie\tPerson\tdes\tjeweiligen\tGef\u00e4hrders\tschlie\u00dfen\t\nlassen.\tGleichwohl\thandelt\tes\tsich\tum\teine\tetablierte\tDifferenzierung,\tdie\t\nhier\tebenfalls\therangezogen\twird.322Gro\u00dfbritannien\t eingesetzte\t Programm\t HART405\tsowie\tdie\tsogenannte\t Stra-\ntegic\tSubject\tList\tder\tPolizei\tvon\tChicago\t (USA)406.\tIn\tDeutschland\t wird\tseit\t\n2017\tvom\tBundeskriminalamt\t das\tRisikobewertungsinstrument\t RADAR-iTE\t\neingesetzt.\t Es\tordnet\tPersonen\t aus\tdem\tmilitant-salafistischen\t Spektrum\t\nauf\tBasis\teiner\tVerhaltensanalyse\t als\t\u201eGef\u00e4hrder\u201c\t oder\t\u201eRelevante\t Perso-\nnen\u201c\tauf\teiner\tRisikoskala\t ein.407\tSeit\t2017\twird\tin\tHessen\tdas\tProgramm\t\nhessenDATA,\t basierend\t auf\tder\tAnalysesoftware\t Gotham\t des\tUS-amerika-\nnischen\tUnternehmens\t Palantir\t Technologies,\t im\tRahmen\t der\tTerrorismus -\nbek\u00e4mpfung\t auf\tder\tGrundlage\t von\t\u00a7\u00a025a\tAbs.\t1\tAlt.\t1\tdes\tHessischen\t Geset-\nzes\t\u00fcber\tdie\t\u00f6ffentliche\t Sicherheit\t und\tOrdnung\t (HSOG)\t eingesetzt.408\tEs\t\nnutzt\tInformationen\t aus\tpolizeilichen\t Datenbanken,\t Verkehrsdaten\t aus\tder\t\nTelekommunikations\u00fcberwachung\t und\tvon\tTelekommunikationsanbietern\t\nzur\tVerf\u00fcgung\t gestellte\t Daten.\tEinbezogen\t werden\tau\u00dferdem\t sogenannte\t\nforensische\t Extrakte\t wie\tzum\tBeispiel\t die\tErgebnisse\t der\tBeschlagnahme\t\neines\tMobiltelefons\t und\tInformationen\t aus\tsozialen\t Netzwerken.409\tEine\t\nRechtsgrundlage\t f\u00fcr\tpersonenbezogenes\t Predictive\t Policing\t liefert\tzudem\t\n\u00a7\u00a04\tdes\tFluggastdatengesetzes\t (FlugDaG).\t Darin\twird\tdas\tBundeskriminal-\namt\term\u00e4chtigt,\t Fluggastdaten410\tautomatisiert\t nach\tbestimmten\t Mustern\t\nabzugleichen.\t Dies\tdient\tder\tIdentifikation\t von\tPersonen,\t bei\tdenen\tein\t\ngewisses\t Risiko\tf\u00fcr\tdie\tBegehung\t einer\tterroristischen\t Straftat\t oder\teiner\t\nStraftat\t der\tschweren\t Kriminalit\u00e4t\t besteht.411\tNachdem\t das\tBundesverfas -\nsungsgericht\t unter\tanderem\t die\thessische\t Regelung\t in\t\u00a7\u00a025a\tAbs.\t1\tAlt.\t1\t\nHSOG\tf\u00fcr\tverfassungswidrig\t erkl\u00e4rt\tund\teine\tNeuregelung\t verlangt\t hat,\t\nweil\tsie\tkeine\tausreichende\t Eingriffsschwelle\t enthalte412,\tm\u00fcssen\t die\tein-\nschl\u00e4gigen\t Erm\u00e4chtigungsgrundlagen\t auch\tin\tanderen\t Gesetzen\t an\tdie\tvom\t\nBundesverfassungsgericht\tformulierten\tVorgaben\tangepasst\twerden.\nDer Einsatz digitaler Technologien des Predictive Policings \n\u2013 vor allem im Hinblick auf personenbezogene Verfahren \u2013 \nwird kontrovers diskutiert. Einerseits geht damit die Hoffnung \n405\tOswald\tet\tal.\t2018.\n406\tSommerer\t2020,\t80\u00a0ff.\n407\thttps://www.bka.de/DE/Presse/Listenseite_Pressemitteilungen/2017/\nPresse2017/170202_Radar.html\t[17.01.2023].\n408\tSommerer\t2020,\t90.\n409\tHessischer\tLandtag\t2019,\t18\u00a0f.\n410\tFluggastdaten\ti.S.v.\t\u00a7\u00a02\tAbs.\t2\tFlugDaG\tsind\tunter\tanderem\tAnschrift\tund\t\nKontaktangaben\tder\tReisenden\t(Nr.\t5),\tvollst\u00e4ndige\tGep\u00e4ckangaben\t(Nr.\t\n7),\tInformationen\t\u00fcber\tnicht\tangetretene\tFl\u00fcge\t(Nr.\t14)\tund\tAngaben\t\u00fcber\t\nMitreisende\t(Nr.\t19).\tGem\u00e4\u00df\t\u00a7\u00a04\tAbs.\t3\tFlugDaG\twerden\tdie\tMuster\tf\u00fcr\tden\t\nAbgleich\tvon\tder\tFluggastdatenzentralstelle\tdes\tBundeskriminalamts\tunter\t\nEinbeziehung\tdes\tDatenschutzbeauftragten\terstellt.\tAllerdings\tist\tnach\twie\t\nvor\tungekl\u00e4rt,\twelche\tDaten\tin\tdie\tMustergewinnung\teinbezogen\twerden\t\n(Sommerer\t2020).\tAls\tBeispiele\tf\u00fcr\tMuster,\tdie\t\u00fcber\tFlugg\u00e4ste\tgewonnen\t\nwerden,\tsind\tfolgende\tF\u00e4lle\tzu\tnennen:\tDie\tBuchung\tdes\tFluges\terfolgte\t\nkurzfristig;\tes\twurde\tin\tbar\tgezahlt;\tbisher\tnicht\talleinreisende\tMinderj\u00e4hri-\nge\treisen\tnunmehr\tallein\t(M\u00fcnch,\tin:\tDeutscher\tBundestag\t2017,\t26).\n411\t Sommerer\t2020,\t96.\n412\tUrteil\tvom\t16.\tFebruar\t2023\t\u2013\t1\tBvR\t1547/19,\t1\tBvR\t2634/20\t(NJW\t2023,\t1196).323auf eine Verbesserung der polizeilichen Arbeit und damit den \nbesseren Schutz m\u00f6glicher Opfer einher (vgl. das Beispiel zum \nOnlinegrooming weiter unten).413 Andererseits ist algorith-\nmenbasierte Verbrechensbek\u00e4mpfung bzw. -verhinderung \nmit verschiedenen Risiken und Problemen verbunden. Diese \nbetreffen zun\u00e4chst Fragen der Genauigkeit bzw. Fehlerhaftig-\nkeit von Vorhersagen durch KI-Systeme. Damit verkn\u00fcpft ist \ndie Frage, ob solche Vorhersagen f\u00fcr verschiedene Personen-\ngruppen gleicherma\u00dfen zuverl\u00e4ssig funktionieren. Dar\u00fcber \nhinaus besteht die Gefahr, dass Personen aufgrund ihrer Her -\nkunft, ihres Wohnorts oder ihrer Vorgeschichte diskriminiert \nwerden.414 Das tats\u00e4chliche Vorliegen einer ungerechtfertigten \nUngleichbehandlung h\u00e4ngt ma\u00dfgeblich von den verwendeten \nParametern, deren Gewichtung innerhalb der Prognoseent-\nscheidung, den verf\u00fcgbaren Daten und deren Charakteristik \nab.415 Von nicht nur technischer, sondern auch ethischer Rele-\nvanz sind hierbei auch methodische Entscheidungen, die das \nAusma\u00df und Verh\u00e4ltnis falsch-positiver und falsch-negativer \nErgebnisse vorbestimmen. Auch wenn Fehler selbstverst\u00e4nd-\nlich auch bei menschlichen Urteilen auftreten, so besteht bei \nEntscheidungsunterst\u00fctzung durch Software eine noch gr\u00f6-\n\u00dfere Gefahr, dass Fehler und Verzerrungen systembedingt \nbesondere Breitenwirkung entfalten. Gerade bei polizeilichen \nMa\u00dfnahmen wirken beide Arten von Fehlern folgenschwer \u2013 \nsowohl wenn f\u00e4lschlicherweise eine polizeiliche Ma\u00dfnahme \ngegen eine Person ergriffen wird als auch wenn ein notwen-\ndiger polizeilicher Zugriff auf eine Person unterbleibt. Gesell-\nschaftlich muss also entschieden werden, in welchem Umfang \nentsprechende Risiken hinnehmbar sind, und auch, ob es \n413\t Ob\teine\tsolche\ttats\u00e4chlich\tgelingt,\tist\tumstritten\t(Eisele/B\u00f6hm\t2020,\t531\u00a0f.).\n414\tZu\tdiskriminierenden\tund\tstigmatisierenden\tEffekten\tvgl.\tEgbert/Leese\t\n2020,\t186\u00a0ff.\n415\t Beispielsweise\tl\u00e4sst\tsich\tdar\u00fcber\tstreiten,\tob\tes\tper\tse\tdiskriminierend\t\nist,\tim\tRahmen\teiner\tkriminalrechtlichen\tPrognose\tden\tWohnort\toder\tden\t\nsozio\u00f6konomischen\tStatus\theranzuziehen,\twenn\tdiese\tUmst\u00e4nde\tzugleich\t\nempirisch\tbelegt\tkriminalit\u00e4tssteigernde\tFaktoren\tdarstellen\t(vgl.\tausf\u00fchr -\nlich\t\u2013\tauch\tmit\tBlick\tauf\tPredictive\tPolicing\t\u2013\tKischel,\tin:\tBeckOK\tGG,\t52.\t\nEdition,\tStand:\t15.08.2022,\tArt.\t3\tRn.\t218d).324einen Unterschied macht, wenn der Fehler auf der Technik \noder auf menschlichem Versagen beruht.\nEine weitere Problematik, die Gegenstand intensiver De-\nbatten ist, ist die Frage des Schutzes der Privatsph\u00e4re im Kon-\ntext von Predictive Policing im Allgemeinen und in Bezug auf \nChatkontrollen im Besonderen (siehe Infokasten 13).416 Die \nf\u00fcr die Polizeiarbeit herangezogenen Daten sind in aller Regel \nbesonders sensibel. Bei sogenannten Chatkontrollen zur Pr\u00e4-\nvention und Bek\u00e4mpfung des sexuellen Missbrauchs von Kin-\ndern, zu denen die Europ\u00e4ische Kommission im Mai 2022 ei-\nnen Verordnungsvorschlag (COM/2022/209)417 vorgelegt hat, \ngeht es auch um die Frage, ob eine anlasslose und fl\u00e4chende-\nckende \u00dcberwachung privater Kommunikation gerechtfertigt \nwerden kann, gerade auch in Anbetracht vorhandener Kritik \nbez\u00fcglich der Effektivit\u00e4t solcher Kontrollen f\u00fcr den Schutz \nder Kinder und der generellen Kritik an Ma\u00dfnahmen der Vor -\nratsdatenspeicherung. Nach Einsch\u00e4tzung des Bundesdaten-\nschutzbeauftragten stellt der Verordnungsentwurf einen un-\nverh\u00e4ltnism\u00e4\u00dfig intensiven Eingriff in die Grundrechte dar.418\nInfokasten\t13:\tOnlinegrooming\nIn\tden\tsozialen\t Medien\tund\tdem\tInternet\t sind\tKinder\tund\tJugendliche\t dem\t\nRisiko\tdes\tsogenannten\t Onlinegroomings\t ausgesetzt,\t bei\tdem\tErwachsene\t\neine\temotionale\t Beziehung\t zu\tMinderj\u00e4hrigen\t mit\tdem\tZiel\tdes\tsexuellen\t\nMissbrauchs\t aufbauen.419\tDie\tEurop\u00e4ische\t Kommission\t hat\tim\tMai\t2022\t\neinen\tVerordnungsentwurf\t zur\tPr\u00e4vention\t und\tBek\u00e4mpfung\t des\tsexuellen\t\nMissbrauchs\t von\tKindern\t vorgelegt.\t Dieser\tsieht\tdie\tsystematische\t Identi-\nfizierung\t entsprechender\t Anbahnungen\t in\tChats\tals\tpr\u00e4ventives\t Mittel\tvor,\t\n416\tSingelnstein\t2018.\n417\t https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX:52022PC0209\t\n[17.01.2023].\n418\thttps://www.bfdi.bund.de/SharedDocs/Pressemitteilungen/DE/2022/09_\nChatkontrolle.html?nn=252104\t[02.03.2023];\tvgl.\tauch\tEntwurf\teiner\t\nStellungnahme\tder\tBundesregierung\tvom\t17.\tFebruar\t2023\tzum\tVorschlag\t\neiner\tCSA-Verordnung\tder\tEU-Kommission,\tver\u00f6ffentlicht\tauf\tnetzpolitik.\norg:\thttps://netzpolitik.org/2023/positionspapier-innenministerium-macht-\nwenig-zugestaendnisse-bei-chatkontrolle/#2023-02-17_BMI_Chatkontrolle_\nEntwurf\t[02.03.2023].\n419\tWachs/Wolf/Pan\t2012.325um\tpotenzielle\t Straff\u00e4llige\t noch\tvor\tder\tTat\tzu\tentdecken\t und\tdie\tMinder-\nj\u00e4hrigen\t rechtzeitig\t vor\tder\tSexualstraftat\t zu\tsch\u00fctzen.420\tUm\tGrooming\t\nfr\u00fch\tund\tgenau\tzu\tidentifizieren,\t sollen\tChats\tonline\tbereits\tmittels\tauto-\nmatisierter\t und\tspezifisch\t f\u00fcr\tdiese\tProblematik\t trainierter\t KI-Algorithmen\t\nanalysiert\t werden.\t Die\tvon\tden\tAlgorithmen\t zu\tl\u00f6sende\t Aufgabe\t ist\tkom-\nplex,\tda\tdie\tMissbrauchsstrategie\t sich\terst\t\u00fcber\teinen\tl\u00e4ngeren\t Zeitraum\t\nhinweg\tentfaltet,\t vom\tAufbau\tvon\tVertrauen\t und\tdem\tAustausch\t pers\u00f6nli-\ncher\tInformationen\t bis\thin\tzur\tverharmlosenden\t Kontextualisierung\t sexuel-\nler\tHandlungen\tund\tschlie\u00dflich\tder\tVereinbarung\tpers\u00f6nlicher\tTreffen.\nDie\tTechnologie\t ist\tstark\tumstritten.\t Aufseiten\t der\tChancen\t wird\tinsbe-\nsondere\t die\tVerhinderung\t von\tGewalttaten\t und\tsexuellen\t \u00dcbergriffen\t an\t\nKindern\t und\tsomit\tder\tSchutz\teiner\tbesonders\t vulnerablen\t Bev\u00f6lkerungs -\ngruppe\tin\tden\tVordergrund\t ger\u00fcckt.\t In\tder\tKritik\tstehen\thingegen\t die\tRisi-\nken\teiner\tanlasslosen\t und\tfl\u00e4chendeckenden\t \u00dcberwachung\t privater\t Kom-\nmunikation\t und\tes\tgibt\tZweifel\tan\tder\tGenauigkeit\t und\tUnverzerrtheit\t der\t\nAnalysen\t sowie\tder\tEffektivit\u00e4t\t der\tMa\u00dfnahmen\t in\tBezug\tauf\tden\tSchutz\t\nvon\tKindern.\nZu\tbeachten\t ist\tauch\tder\tZielkonflikt\t zwischen\t der\tGenauigkeit\t und\tder\t\nSchnelligkeit\t einer\tVorhersage,\t dessen\t ethische\t Implikationen\t situati-\nonsad\u00e4quat\t abgewogen\t werden\t m\u00fcssen.\t Sowohl\tfalsch-positive\t als\tauch\t\nfalsch-negative\t Vorhersagen,\t bei\tdenen\talso\tPersonen\t f\u00e4lschlicherweise\t als\t\nStraff\u00e4llige\t klassifiziert\t werden\tbzw.\ttats\u00e4chlich\t straff\u00e4llige\t Personen\t nicht\t\ndetektiert\t werden,\t k\u00f6nnen\t gravierende\t Auswirkungen\t f\u00fcr\tdie\tf\u00e4lschlich\t\nVerd\u00e4chtigten\t oder\tf\u00fcr\tdie\tf\u00e4lschlich\t nicht\tgesch\u00fctzten\t Kinder\thaben.\tEine\t\nKI-basierte\t Detektion\t kann\tdaher\tzun\u00e4chst\t nur\tals\tAlarmzeichen\t dienen,\t\ndas\tdie\t\u00dcberpr\u00fcfung\t der\tChatinhalte\t durch\tmenschliche\t Sachverst\u00e4ndige\t\nerzwingt.\t Im\tFalle\teiner\t\u00fcberpr\u00fcften\t Auff\u00e4lligkeit\t muss\tvom\tAnbieter\t der\t\nChatplattform\t sichergestellt\t werden,\t dass\tdie\tInformationen\t auch\tan\tdie\t\nStrafverfolgungsbeh\u00f6rden\tgemeldet\twerden.\nDer\tErfolg\tvon\tKI-Algorithmen\t bei\tder\trechtzeitigen\t Identifizierung\t Krimi-\nneller\th\u00e4ngt\tauch\tvom\tZugang\tzu\tTrainingsdatens\u00e4tzen\t und\tderen\tQualit\u00e4t\t\nab,\tebenso\twie\tvon\tder\tEffizienz\t der\tAlgorithmen\t bei\tlimitierter\t Rechenka-\npazit\u00e4t,\tda\toftmals\t eine\tzeitnahe,\t lokale\tAnalyse\t auf\tmobilen\t Endger\u00e4ten\t\n(wie\tetwa\tSmartphones)\t erforderlich\t ist.421\tEs\tist\tzu\terwarten,\t dass\tAlgorith-\nmen\tfortw\u00e4hrend\t einer\tAktualisierung\t auf\tder\tGrundlage\t neuer\tTrainings -\ndaten\tbed\u00fcrfen,\t wenn\tdiejenigen,\t die\tsolche\tSexualstraftaten\t planen\tund\t\nbegehen,\t Umgehungsstrategien\t (wie\tetwa\tadaptierte\t sprachliche\t \u00c4u\u00dferun-\ngen)\tentwickeln.\nPersonenbezogene Verfahren des Predictive Policings k\u00f6nnen, \nwie in anderen Feldern auch, menschliche Beurteilung und \nEntscheidung unterst\u00fctzen und dadurch Handlungsm\u00f6glich-\nkeiten insbesondere der Strafverfolgungsbeh\u00f6rden erweitern. \n420\tVogt/Leser/Akbik\t2021.\n421\tEbd.326Andererseits k\u00f6nnen sie die Handlungsm\u00f6glichkeiten der \nverschiedenen Beteiligten aber auch vermindern oder \u2013 im \nFalle einer vollst\u00e4ndigen \u00dcbertragung von Entscheidungen \nan algorithmische Systeme \u2013 gar eliminieren. Wenn bei der \nVerhinderung einer Straftat hohe Anforderungen an Schnel-\nligkeit bestehen, kann es zu einem Konflikt mit dem gleich-\nzeitigen Gebot von m\u00f6glichst gro\u00dfer Sorgfalt und Heranzie-\nhung menschlicher Beurteilung kommen. Nicht zuletzt wird \ndie Sorge ge\u00e4u\u00dfert, dass mit algorithmengesteuerter Polizei-\narbeit das Risiko der Verfestigung eines mechanischen Men-\nschenbildes einhergehen k\u00f6nne, das den einzelnen Menschen \nverobjektiviere, seine Individualit\u00e4t auf eine datengetriebene \nKlassifikation reduziere, jedoch die gesamtgesellschaftlichen \nUrsachen von Kriminalit\u00e4t unber\u00fccksichtigt lasse.422\nDer Einsatz von algorithmischen Verfahren des Predic-\ntive Policings kann die Versuchung bzw. Erwartung einer \nm\u00f6glichst weitgehenden, gar l\u00fcckenlosen Vermeidung von \nStraftaten im Vorfeld ihrer Begehung wecken. F\u00fcr eine wei-\nter voranschreitende Durchdringung des Lebensalltags der \nMenschen mit gefahrenabwehrrechtlichen Ma\u00dfnahmen sind \nim Zeitalter der Digitalisierung die technischen Vorausset-\nzungen erf\u00fcllt. Immer wieder wird dann auch bef\u00fcrchtet, die \nfreiheitliche Ordnung w\u00fcrde allm\u00e4hlich, mit dem Argument \nvon mehr Sicherheit im R\u00fccken, einem \u00dcberwachungsstaat \nweichen, in dem l\u00fcckenlose staatliche \u00dcberwachung wenig bis \nkeinen Raum f\u00fcr individuelle Freiheit lassen w\u00fcrde. Ist diese \nSorge zwar grunds\u00e4tzlich verst\u00e4ndlich, weil der Preis f\u00fcr die \nerzielte Sicherheit und Gefahrenabwehr zu hoch w\u00e4re423, darf \nsie jedoch nicht dazu f\u00fchren, Pauschalurteile gegen Optionen \nwie das Predictive Policing zu f\u00e4llen. Wie in diesem Kapitel an \nvielen Beispielen gezeigt wurde, h\u00e4ngt es vom Design der tech-\nnischen Systeme und vor allem von ihrer organisatorischen \nEinbettung in menschliche Entscheidungsverfahren ab, ob \n422\tZu\tweiteren\tBedenken\tsiehe\tEgbert\t2018,\t256.\n423\tRostalski\t2019,\t484\u00a0f.327die Autorschaft der verschiedenen Beteiligten oder Betroffe-\nnen erweitert oder vermindert wird. Statt eines Pauschalurteils \nbedarf es also der am Ideal menschlicher Urteilsf\u00e4higkeit und \nVerantwortung ausgerichteten Gestaltung der Systeme und \nihres Einsatzes in der polizeilichen Praxis.\nDies entspricht dem Bild menschlicher Autorschaft, die \nprinzipiell dazu in der Lage ist, sich auf der Basis von Einsicht \nin die Richtigkeit eines bestimmten Verhaltens, beispielsweise \nzur Wahrung des K\u00f6rperverletzungsverbots, selbstst\u00e4ndig und \neigenverantwortlich f\u00fcr die Befolgung des Rechts zu entschei-\nden. W\u00fcrde diese Entscheidungsfreiheit in der Folge umfas-\nsender staatlicher Sicherungsinstrumente abhandenkommen, \nw\u00fcrden sich Einzelne nicht l\u00e4nger als verantwortlich f\u00fcr das \nFunktionieren des freiheitlichen Miteinanders begreifen \u2013 mit \nall den Negativfolgen, die es f\u00fcr ein Gemeinwesen hat, wenn \nsich dessen Mitglieder selbst nicht mehr in der Pflicht sehen, \nin der Gestaltung des Rechts und seiner Wahrung eine aktive \nRolle einzunehmen.\n8.5\t\t Fazit\tund\tEmpfehlungen\nDie Digitalisierung der \u00f6ffentlichen Verwaltung wird seit \u00fcber \nzwanzig Jahren zumeist unter Aspekten von Serviceorientie-\nrung, Modernit\u00e4t sowie Effizienz und Effektivit\u00e4t thematisiert. \nKI und dadurch erm\u00f6glichte automatisierte Entscheidungs-\nverfahren f\u00fchren zu neuen M\u00f6glichkeiten und Herausforde-\nrungen, die erheblich weitreichende ethische und demokratie-\ntheoretische Fragen aufwerfen. Denn da staatliches Handeln \nvon vielen Menschen zu einem gro\u00dfen Teil \u00fcber die \u00f6ffentli-\nche Verwaltung erfahren wird, beispielsweise in Finanzverwal-\ntung, Meldebeh\u00f6rden oder Sozialwesen, ist mit der Einf\u00fchrung \nbeispielsweise automatisierter Entscheidungsverfahren un-\nmittelbar das Verh\u00e4ltnis von B\u00fcrgerschaft und Staat betroffen. \nDies gilt etwa in Bezug auf Nachvollziehbarkeit, Erkl\u00e4rbarkeit \nund Vertrauensw\u00fcrdigkeit im Verwaltungshandeln, aber auch 328in Bezug auf Sorgen um Diskriminierung und Technokratie, \nin der menschliche Kommunikation und Abw\u00e4gung hinter \nanonymen Datenmengen und standardisierten Bedienoberfl\u00e4-\nchen verschwinden. Eine in diesen Hinsichten als legitim aner -\nkannte Verwaltung ist f\u00fcr ein funktionierendes Gemeinwesen \nund die Akzeptanz von Demokratie und Staat wesentlich. Die \nErf\u00fcllung dieser auch f\u00fcr den Einsatz von KI in der \u00f6ffentli-\nchen Verwaltung geltenden Anforderung h\u00e4ngt mit den durch \nAutomatisierung ver\u00e4nderten M\u00f6glichkeiten menschlicher \nAutorschaft im Verwaltungshandeln zusammen und f\u00fchrt zu \nden ethischen Fragen nach ihrer Erweiterung oder Verminde-\nrung durch die Einf\u00fchrung KI-gest\u00fctzter Systeme in diesem \nFeld.\nSeit einigen Jahren kommen in vielen Staaten Systeme zur \nEntscheidungsunterst\u00fctzung in der \u00f6ffentlichen Verwaltung \nzusehends zum Einsatz, so etwa zur Bewertung von Arbeits-\nmarktchancen, zur Pr\u00fcfung und Vergabe von Sozialleistungen \nund bei Sicherheitsorganen. Aufgrund des dadurch erm\u00f6glich-\nten R\u00fcckgriffs auf gro\u00dfe Datenmengen und ihrer zielgerichte-\nten Auswertung in kurzer Zeit k\u00f6nnen f\u00fcr die erforderlichen \nEntscheidungen bessere Grundlagen geschaffen und kann die \nmenschliche Autorschaft unterst\u00fctzt werden. Insofern also die \nletztliche Entscheidung, etwa \u00fcber die Bemessung von Sozi-\nalleistungen oder die R\u00fcckfallwahrscheinlichkeit einer straf-\nf\u00e4lligen Person, bei den Personen, die f\u00fcr diese Entscheidung \nzust\u00e4ndig sind, verbleibt, ist der Einsatz der ADM-Systeme in \nethischer Hinsicht grunds\u00e4tzlich zu begr\u00fc\u00dfen. Entscheidend \nist hier, dass die Zwecke ihrer Einf\u00fchrung in \u00dcbereinstim-\nmung mit dem Ziel der Erweiterung menschlicher Autorschaft \nstehen und die Systeme nicht etwa blo\u00dfer Effizienzsteigerung \ndes beh\u00f6rdlichen Funktionierens oder der Einsparung von \nPersonal dienen.\nJedoch kann es durch Gew\u00f6hnung, \u00dcberlastung und Ent-\nscheidungsdruck zu einer allm\u00e4hlichen Verschiebung kom-\nmen, in deren Verlauf die Ergebnisse der ADM-Systeme von \nden Menschen, die eine Entscheidung treffen, zunehmend 329ohne weitere Pr\u00fcfung und Reflexion \u00fcbernommen w\u00fcrden \n(Automation Bias). Auf diesem Weg w\u00fcrde menschliche Au-\ntorschaft allm\u00e4hlich und fast unmerklich verschwinden. Zu-\nr\u00fcckbleiben w\u00fcrde ein automatisiertes Geschehen, in dem \ntechnische Systeme f\u00fcr Betroffene weitreichende, teils existen-\nzielle Festlegungen treffen. Dies ist nicht blo\u00df eine abstrakte \nBef\u00fcrchtung, sondern spiegelt Erfahrungen im allt\u00e4glichen \nVerwaltungshandeln wider. Es kommt also zu Konflikten zwi-\nschen Erwartungen an die Erweiterung menschlicher Autor -\nschaft einerseits und der realen Umsetzung, in der ihre Ver -\nminderung oder gar Ersetzung nicht fernliegen, andererseits. \nEin empirisches Monitoring der realen Adaptation von ADM-\nSystemen und ihren Folgen ist notwendig, um Fehlentwick-\nlungen in ethischer Hinsicht fr\u00fchzeitig erkennen und Gegen-\nma\u00dfnahmen einleiten zu k\u00f6nnen.\nFerner ist an die Forderung nach Diskriminierungsfreiheit \ndes \u00f6ffentlichen Verwaltungshandelns und seiner m\u00f6glichst \nweitgehenden Umsetzung zu erinnern. Automatisiertes Ent-\nscheiden, etwa im Sozialwesen oder im Predictive Policing, \nkann durch die verwendeten Datens\u00e4tze und zur Auswertung \nherangezogenen Algorithmen diskriminierend f\u00fcr bestimmte \nBev\u00f6lkerungsgruppen wirken. Dieses mittlerweile gut bekann-\nte Risiko424 stellt kein Pauschalargument gegen ADM-Systeme \nin der \u00f6ffentlichen Verwaltung dar, zumal auch menschliche \nEntscheidungen vor Diskriminierung nicht gefeit sind, son-\ndern hat zur Folge, dass sowohl das Design der Systeme als \nauch die Trainingsdaten und dann auch ihre realen Operatio-\nnen daraufhin kritisch beobachtet werden m\u00fcssen.\nSchlie\u00dflich ist festzuhalten, dass die von Ergebnissen der \nADM-Systeme Betroffenen, etwa bei Entscheidungen des Ju-\ngendamtes oder in der Steuerbemessung, die gleichen Rechte \netwa auf Erl\u00e4uterung und Widerspruch haben wie bei Institu-\ntionen ohne diese Systeme.\n424\tOrwat\t2019.330Pauschale Aussagen f\u00fcr oder gegen KI bzw. ADM-Systeme \nin der \u00f6ffentlichen Verwaltung sind also nicht sinnvoll. Es \nmuss kontextbezogen im Detail eingesch\u00e4tzt und abgewogen \nwerden, welche Auswirkungen eine entsprechende Ma\u00dfnah-\nme auf die Autorschaft unterschiedlichster Beteiligter und \nBetroffener hat, welche Konflikte auftreten und wie mit ihnen \numgegangen werden kann oder soll.\nEmpfehlungen\n>> Empfehlung Verwaltung 1: Die mit automatisierten Ent-\nscheidungshilfen (ADM-Systeme) einhergehende ver -\nst\u00e4rkte Standardisierung und pauschale Kategorisierung \nvon Einzelf\u00e4llen m\u00fcssen umso st\u00e4rker hinterfragt und um \nspezifisch einzelfallbezogene Erw\u00e4gungen erg\u00e4nzt wer -\nden, je intensiver die betroffene Entscheidung individuelle \nRechtspositionen ber\u00fchrt.\n>> Empfehlung Verwaltung 2: Es m\u00fcssen geeignete technische \nund organisatorische Instrumente zur Vorkehrung gegen \ndie manifeste Gefahr eines Automation Bias bereitgestellt \nwerden, die es den Fachkr\u00e4ften erschweren, selbst bei ei-\nner Letztentscheidungskompetenz der algorithmischen \nEntscheidungsempfehlung unbesehen zu folgen. Es ist zu \npr\u00fcfen, ob eine Umkehrung der Begr\u00fcndungspflicht (nicht \neine Abweichung, sondern ein Befolgen ist zu rechtferti-\ngen) hier eine geeignete Vorkehrung sein kann.\n>> Empfehlung Verwaltung 3: Aufgrund ihrer Grundrechtsbin-\ndung sind an staatliche Einrichtungen bei der Entwicklung \nund Nutzung algorithmischer Systeme hohe Anforderun-\ngen in Bezug auf Transparenz und Nachvollziehbarkeit zu \nstellen, um den Schutz vor Diskriminierung zu gew\u00e4hrleis-\nten sowie Begr\u00fcndungspflichten erf\u00fcllen zu k\u00f6nnen.\n>> Empfehlung Verwaltung 4: F\u00fcr Softwaresysteme in der \n\u00f6ffentlichen Verwaltung m\u00fcssen Qualit\u00e4tskriterien ver -\nbindlich und transparent festgelegt werden (z. B. in Be-\nzug auf Genauigkeit, Fehlervermeidung und Unverzerrt-\nheit). Ebenso bedarf es einer Dokumentation der jeweils 331eingesetzten Methoden. Diesbez\u00fcglich sollten auch aktuel-\nle Beschaffungspraktiken, in deren Verlauf staatliche Be-\nh\u00f6rden Softwarel\u00f6sungen kaufen, einer kritischen Pr\u00fcfung \nunterzogen werden.\n>> Empfehlung Verwaltung 5: \u00dcberall dort, wo algorithmische \nSysteme Einsatz in der \u00f6ffentlichen Verwaltung finden, gilt \nes, Sorge zu tragen, dass die Personen, die diese Systeme \nanwenden, \u00fcber die erforderlichen Kompetenzen im Um-\ngang damit verf\u00fcgen. Dazu geh\u00f6rt neben der Kenntnis der \nVerwendungsweisen auch das Wissen um die Limitationen \nund m\u00f6glichen Verzerrungen, um Systeme angemessen \neinsetzen zu k\u00f6nnen.\n>> Empfehlung Verwaltung 6: Die Einsichts- und Einspruchs-\nrechte Betroffener m\u00fcssen auch beim Einsatz algorith-\nmischer Systeme effektiv gew\u00e4hrleistet werden. Dazu be-\ndarf es gegebenenfalls weiterer wirksamer Verfahren und \nInstitutionen.\n>> Empfehlung Verwaltung 7: In \u00d6ffentlichkeit, Politik und \nVerwaltung sollte eine Sensibilisierung gegen\u00fcber m\u00f6gli-\nchen Gefahren von Automatisierungssystemen, wie etwa \nVerletzungen der Privatsph\u00e4re oder Formen systematisier -\nter Diskriminierung, erfolgen. Dazu geh\u00f6rt eine \u00f6ffentliche \nDebatte dar\u00fcber, ob es in bestimmten Kontexten \u00fcberhaupt \neiner technischen L\u00f6sung bedarf.\n>> Empfehlung Verwaltung 8: Im Bereich des Sozialwesens \nist sicherzustellen, dass ADM-Systeme elementare fach-\nliche Standards von sozialprofessionellen Interaktionen \n(z. B. gemeinsame Sozialdiagnose oder Hilfeplanung als \nTeil therapeutischer bzw. unterst\u00fctzender Hilfeleistung) \nnicht unterlaufen oder verdr\u00e4ngen. Dies beinhaltet ins-\nbesondere Ma\u00dfnahmen, die Vergr\u00f6berungen individuel-\nler Fallkonstellationen und -prognosen durch die ADM-\ninduzierte grobklassifizierende Einteilung von Fall- und/\noder Leistungsberechtigtengruppen verhindern. Dabei ist \nSorge zu tragen, dass die Feststellung individueller Hilfebe-\ndarfe nicht erschwert wird und es zu keiner schleichenden 332Aush\u00f6hlung der sozialrechtlich gebotenen Identifizierung \nindividueller Hilfebedarfe zugunsten einseitiger externer \nInteressen an Gefahrenminimierung oder Kostenersparnis \nkommt.\n>> Empfehlung Verwaltung 9: Die Arbeit von Gefahrenab-\nwehrbeh\u00f6rden einschlie\u00dflich der Polizei betrifft beson-\nders grundrechtssensible Bereiche. Dies wirkt sich auf die \nReichweite eines zul\u00e4ssigen Einsatzes von algorithmischen \nSystemen in der pr\u00e4diktiven Polizeiarbeit aus. Risiken wie \nVerletzungen der Privatsph\u00e4re oder potenziell unzul\u00e4ssige \nDiskriminierungen der von dem Einsatz betroffenen Per -\nsonen m\u00fcssen mit Chancen auf erhebliche Verbesserungen \nder staatlichen Gefahrenabwehr sorgf\u00e4ltig abgewogen und \nin ein angemessenes Verh\u00e4ltnis gebracht werden. Hierf\u00fcr \nerforderliche gesellschaftliche Aushandlungsprozesse soll-\nten umfangreich gef\u00fchrt werden. Dabei ist der diffizilen \nBestimmung des Verh\u00e4ltnisses von Freiheit und Sicherheit \nRechnung zu tragen. Jegliche Gesetzes\u00fcbertretung zu ver -\nhindern, w\u00e4re mit rechtsstaatlichen Mitteln nicht m\u00f6glich.TEIL\tIII:\t\nQUERSCHNITTSTHEMEN \t\nUND\t\u00dcBERGREIFENDE \t\nEMPFEHLUNGEN3349\t \t ZUSAMMENFASSUNG \tDER\t\nBISHERIGEN \tANALYSE\n9.1\t\t Anthropologische\tund\tethische\t\nGrundorientierung\nDer Begriff der K\u00fcnstlichen Intelligenz hat in der \u00f6ffentlichen \nDebatte zunehmend an Aufmerksamkeit gewonnen und wird \nteils mit \u00fcberzogenen Hoffnungen, teils aber auch mit fehlge-\nleiteten Bef\u00fcrchtungen verkn\u00fcpft. Insbesondere in den De-\nbatten rund um die sogenannte starke KI wird zuweilen sogar \nnahegelegt, maschinelle Akteure k\u00f6nnten normativ menschli-\nchen Akteuren \u00e4hnlich oder gleichgestellt sein \u2013 was etwa zu \nDiskussionen um \u201eMenschenrechte f\u00fcr Roboter\u201c f\u00fchrt.\nDer Deutsche Ethikrat geht in seiner Stellungnahme hinge-\ngen von einem normativ grundlegenden Unterschied zwischen \nMensch und Maschine aus.425 Softwaresysteme, auch solche, \ndie der KI zugerechnet werden, verf\u00fcgen weder \u00fcber theoreti-\nsche noch \u00fcber praktische Vernunft. Sie k\u00f6nnen keine Verant-\nwortung f\u00fcr ihr Handeln \u00fcbernehmen, sie sind kein personales \nGegen\u00fcber, auch dann nicht, wenn sie Anteilnahme, Koopera-\ntionsbereitschaft oder Einsichtsf\u00e4higkeit simulieren.\nAnthropomorphe Missverst\u00e4ndnisse sind m\u00f6glicherwei-\nse Folge der Rede von \u201ek\u00fcnstlicher Intelligenz\u201c. Der Begriff \n\u201eIntelligenz\u201c wird bislang ganz \u00fcberwiegend f\u00fcr die Beschrei-\nbung menschlicher kognitiver Leistungen verwendet. Der \nBegriff der menschlichen Intelligenz verweist auf ein En-\nsemble von Leistungen, die eine Reihe von Prim\u00e4rfaktoren \n425\tDiese\tFeststellung\tl\u00e4sst\tzwei\tDeutungen\tzu:\tSie\tkann\teinmal\tim\tSinne\teines\t\nkategorialen\tUnterschieds\tverstanden\twerden,\tder\tauch\tdurch\tweiteren\t\ntechnischen\tFortschritt\tnicht\t\u00fcberwunden\twerden\tkann;\tdieser\tLesart\t\nschlie\u00dft\tsich\tdie\tMehrheit\tdes\tDeutschen\tEthikrates\tan.\tSie\tkann\taber\tauch\t\nlediglich\tim\tSinne\teiner\tFeststellung\thinsichtlich\tdes\tgegenw\u00e4rtigen\tund\t\nallenfalls\tf\u00fcr\tdie\tnahe\tZukunft\t\u00fcberblickbaren\ttechnischen\tEntwicklungs -\nstandes\tverstanden\twerden;\tdieser\tLesart\tschlie\u00dft\tsich\teine\tMinderheit\tdes\t\nDeutschen\tEthikrates\tan.335wie induktives Schlie\u00dfen, r\u00e4umliches Vorstellungsverm\u00f6gen, \nWahrnehmungsgeschwindigkeit, Rechenf\u00e4higkeit, verba-\nles Verst\u00e4ndnis, assoziatives Ged\u00e4chtnis und Wortfl\u00fcssigkeit \numfassen und die sich, jedenfalls auf dem heutigen Stand der \nSoftwareentwicklung, nicht alle auf KI oder zumindest nicht \nvollst\u00e4ndig auf diese \u00fcbertragen lassen. Dies gilt erst recht f\u00fcr \nKonzepte wie die der sozialen oder emotionalen Intelligenz. \nInsofern enth\u00e4lt der Ausdruck \u201ek\u00fcnstliche Intelligenz\u201c eine \nmetaphorische Verwendung von \u201eIntelligenz\u201c, die das Miss-\nverst\u00e4ndnis einer wenigstens weitgehenden \u00c4hnlichkeit oder \nsogar Gleichheit von menschlicher Intelligenz und KI f\u00f6rdert. \nEntsprechend w\u00e4re es in vielen F\u00e4llen hilfreicher, den Begriff \nder K\u00fcnstlichen Intelligenz nicht inflation\u00e4r zu verwenden, \nsondern genauer zu spezifizieren, was eine Software ist, bei-\nspielsweise eine Software zur Entscheidungsunterst\u00fctzung, \noder was sie tut, beispielsweise basierend auf statistischen \nAnalysen diverser Daten Prognosen erstellen.\nNoch deutlicher wird ein kategorialer Unterschied zwi-\nschen Mensch und Maschine, wenn man zum Begriff der Ver -\nnunft \u00fcbergeht. Die theoretische Vernunft richtet sich auf den \nErkenntnisgewinn, um zu wahren empirischen oder apriori-\nschen Urteilen zu gelangen, w\u00e4hrend die praktische Vernunft \nauf ein koh\u00e4rentes, verantwortliches Handeln abzielt, um \nein gutes Leben zu erm\u00f6glichen. Dabei ist menschliche Ver -\nnunft als verleiblicht zu begreifen. Das hei\u00dft, die Vernunft des \nMenschen ist nicht hinreichend beschrieben, wenn sie als ab-\nstrakte allgemeine Menschenvernunft aufgefasst wird. Sie ist \nimmer zugleich eingebunden in die konkrete soziale Mit- und \nUmwelt. Nur so ist zu erkl\u00e4ren, dass sie handlungswirksam \nwird. Als solche bestimmt sie die Sozialit\u00e4t und Kulturalit\u00e4t \ndes Menschen. \u201eVern\u00fcnftig\u201c handelt der einzelne Mensch als \nTeil einer sozialen Mitwelt und einer kulturellen Umgebung. \nSchon deshalb kann den in dieser Stellungnahme besproche-\nnen Softwaresystemen weder theoretische noch praktische \nVernunft zugeschrieben werden (siehe ausf\u00fchrliche Darstel-\nlung und Begr\u00fcndung in Kapitel 3).336Menschen entwickeln digitale Technik und nutzen sie als \nMittel zu menschlichen Zwecken. Jedoch wirken diese Tech-\nnologien zur\u00fcck auf menschliche Handlungsm\u00f6glichkeiten: \nDadurch k\u00f6nnen sich einerseits neue Optionen er\u00f6ffnen und \nim g\u00fcnstigen Fall Freiheitsgrade vergr\u00f6\u00dfern. Andererseits \nkann aber auch die Handlungsf\u00e4higkeit von Menschen einge-\nschr\u00e4nkt und k\u00f6nnen Anpassungen erforderlich werden, die \nnicht w\u00fcnschenswert sind. Bei der Verwendung hoch entwi-\nckelter vernetzter Softwaresysteme haben Menschen teilweise \neine Subjekt-, teilweise aber auch eine Objektrolle inne. Es kann \ndabei bewusst auf den Subjektstatus verzichtet werden, um \nHandlungsm\u00f6glichkeiten zu erweitern oder Routineaufgaben \nan Maschinen zu delegieren. Diese instrumentelle Funktion ist \njedoch von der Selbstzwecklichkeit menschlicher Akteure zu \nunterscheiden. Die F\u00e4higkeit, Urheber eigener Handlungen zu \nsein, die die Grundlage autonomer personaler Praxis ist, bleibt \nMenschen vorbehalten.\nMenschen wirken zweckgerichtet und kontrolliert auf sich \nselbst und ihre Umwelt ein, um damit bestimmte Ver\u00e4nde-\nrungen zu verursachen. Dabei spielt die M\u00f6glichkeit, zwischen \nunterschiedlichen Handlungsoptionen w\u00e4hlen zu k\u00f6nnen, \neine wesentliche Rolle. Auch hoch entwickelte Softwaresys-\nteme oder KI-gest\u00fctzte Roboter sind nicht in der Lage, in \ndiesem anspruchsvollen Sinne zu \u201ehandeln\u201c. Algorithmische \nSysteme, die etwa bei der Auswahl von geeigneten Personen \nf\u00fcr eine Stelle eingesetzt werden, handeln oder entscheiden \nnicht selbst und k\u00f6nnen keine Verantwortung \u00fcbernehmen. \nAllerdings beeinflussen sie, mitunter in hohem Ma\u00dfe, die \nBedingungen, M\u00f6glichkeiten und Grenzen f\u00fcr menschliches \nHandeln und menschliche Verantwortungs\u00fcbernahme. In den \nvorangegangenen Kapiteln wurde dies f\u00fcr die Anwendungsbe-\nreiche der Medizin, der schulischen Bildung, der \u00f6ffentlichen \nKommunikation und Meinungsbildung sowie der \u00f6ffentlichen \nVerwaltung exemplarisch aufgef\u00e4chert. Entscheidungsunter -\nst\u00fctzungssysteme beeinflussen menschliche Handlungsm\u00f6g-\nlichkeiten in Medizin und Verwaltung ebenso wie KI-gest\u00fctzte 337Lernsoftwaresysteme dies im Bildungsbereich tun oder Such-\nmaschinen und Empfehlungssoftware im Bereich der \u00f6ffent-\nlichen Meinungsbildung. Auch wenn Maschinen also nicht \nselbst handeln, so ver\u00e4ndern sie die Handlungsf\u00e4higkeit von \nMenschen tiefgreifend und k\u00f6nnen Handlungsm\u00f6glichkeiten \nerheblich erweitern oder vermindern (vgl. Kapitel 4).\nZiel der Delegation von Handlungssegmenten an Maschi-\nnen sollte prinzipiell die Erweiterung menschlicher Hand-\nlungsf\u00e4higkeit und Autorschaft sein. Umgekehrt gilt es, die \nVerminderung menschlicher Handlungsf\u00e4higkeit und Autor -\nschaft sowie eine Diffusion oder Evasion von Verantwortung zu \nverhindern. Entsprechend ist es erforderlich, dass die \u00dcbertra-\ngung menschlicher T\u00e4tigkeiten auf KI-Systeme gegen\u00fcber den \nBetroffenen transparent erfolgt. Es darf nicht zu einer Ver -\nantwortungsdiffusion kommen, die dazu f\u00fchrt, dass niemand \nmehr f\u00fcr Fehlentscheidungen verantwortlich ist \u2013 etwa, weil \nwichtige Entscheidungselemente, -parameter oder -bedingun-\ngen nicht mehr nachvollziehbar sind.\nEine zentrale Erkenntnis der hier vorgelegten Analysen \nlautet, dass Ausma\u00df und Art sinnvoller und guter Delegati-\non nicht allgemein festgelegt werden k\u00f6nnen, sondern jeweils \nkontextspezifisch bestimmt werden m\u00fcssen. So kann die Ver -\nminderung menschlicher Handlungsf\u00e4higkeit in bestimmten \nKontexten durchaus Vorteile mit sich bringen, wenn beispiels-\nweise durch den Verlass auf teilautomatisierte Diagnostikver -\nfahren in der Medizin Fehldiagnosen reduziert werden. Um \n\u00fcber Wert und Nutzen der Delegation vormals menschlichen \nHandelns an Maschinen zu befinden, m\u00fcssen allerdings auch \ndie langfristigen Auswirkungen dieser Delegation im Sinne \neiner Erweiterung oder Verminderung menschlicher Hand-\nlungsf\u00e4higkeit ber\u00fccksichtigt werden. So kann sich der Verlust \nmenschlicher Expertise, der entsteht, wenn sich bei \u00e4rztlichen \nFachkr\u00e4ften durch den Einsatz von algorithmischen Syste-\nmen die eigene F\u00e4higkeit zur Diagnose verringert, langfristig \nals Nachteil erweisen, zum Beispiel in der Ausbildung oder in 338Situationen, wo die entsprechende Technik nicht (mehr) zur \nVerf\u00fcgung steht.\nHier wird die soziale Dimension des Verh\u00e4ltnisses von \nDelegieren, Erweitern und Vermindern deutlich: Menschen \nk\u00f6nnen durch Prozesse des Delegierens bzw. Ersetzens un-\nterschiedlich betroffen sein. Man denke hier etwa an den Ein-\nsatz von Entscheidungsunterst\u00fctzungssystemen in der Ver -\nwaltung, der Handlungsm\u00f6glichkeiten von Fachkr\u00e4ften und \nunterschiedlichen Betroffenen auf sehr verschiedene Weise \nerweitern oder vermindern kann. Auch im schulischen Kon-\ntext betrifft das Delegieren von Handlungen an Maschinen \nLernende anders als Lehrkr\u00e4fte oder gegebenenfalls noch \nweitere Personen. Beide Kontexte sind von asymmetrischen \nBeziehungs- und Machtverh\u00e4ltnissen gekennzeichnet, denen \nbei der Bewertung der Effekte des Einsatzes von Technolo-\ngien Rechnung getragen werden muss. Dies gilt umso mehr, \nwenn bestimmte Personengruppen aufgrund ihrer Situierung \nbesonders vulnerabel sind, beispielsweise Kinder im Schul-\nkontext oder gar im Falle einer Wohlgef\u00e4hrdung. Bei der \nBeurteilung technologischer Entwicklungen gilt es also, den \nBlick nicht nur auf diejenigen, die Technik verwenden, und \ndirekt davon Betroffene, sondern auch auf indirekt Betroffene \nzu richten. Dar\u00fcber hinaus gilt es, die Rolle von weiteren Be-\nteiligten zu beleuchten, die eher im Hintergrund agieren und \nentweder in besonderer Weise von Einf\u00fchrung und Nutzung \nder Technologien profitieren oder durch ihre Entscheidungen \nzur Gestaltung oder zum Einsatz von Technik M\u00f6glichkeiten \nund Risiken f\u00fcr andere Akteure pr\u00e4konfigurieren. Man denke \nhier sowohl an die gro\u00dfen Plattformen und Softwareanbie-\nter, aber auch an Data Broker, die im Hintergrund Daten zu \nverschiedensten, m\u00f6glicherweise auch sachfremden Zwecken \nverarbeiten oder verkaufen.\nDie Herausforderungen stecken also wie so oft im Detail, \ngenauer: in den Details der Technik, der Einsatzkontexte so-\nwie der institutionellen und soziotechnischen Umgebung. \nNeben den allgemeinen Forderungen nach Transparenz und 339Nachvollziehbarkeit, dem Schutz der Privatsph\u00e4re und der \nMinimierung von Diskriminierung und systematischen Ver -\nzerrungen (Bias) m\u00fcssen das ethische Design und der ethische \nEinsatz von Technologien also immer auch die konkreten in-\nstitutionellen und organisationalen Rahmenbedingungen so-\nwie die individuellen Erfordernisse unterschiedlicher Akteure \nin den Blick nehmen. Im Folgenden werden die Erkenntnisse \naus den Kapiteln 5 bis 8 zusammengefasst und in Kapitel 10 \ndann \u00fcbergreifende Querschnittsthemen und Empfehlungen \nextrahiert. Die detaillierteren, sektorspezifischen Empfehlun-\ngen befinden sich jeweils am Ende der Kapitel 5 bis 8.\n9.2\t\t Einsichten\taus\tden\t\nAnwendungsfeldern\nDie Verwendung von Technologien ver\u00e4ndert und erweitert \ndie Handlungsm\u00f6glichkeiten von Menschen seit Jahrtausen-\nden. Der Einsatz von Technologien hat dabei nicht nur inten-\ndierte Folgen im Nahbereich, sondern wirkt im Positiven wie \nim Negativen auch in gro\u00dfer r\u00e4umlicher und zeitlicher Dis-\ntanz. \u00c4hnlich verh\u00e4lt es sich mit dem Einsatz von KI. Die Dele-\ngation von Entscheidungen, Handlungen und Handlungsseg-\nmenten an Software im Allgemeinen und KI im Besonderen \nschafft neue M\u00f6glichkeiten, birgt aber auch zahlreiche Risiken.\nIn dieser Stellungnahme hat sich der Deutsche Ethikrat \nexemplarisch mit einigen Anwendungen in der Medizin, der \nschulischen Bildung, der \u00f6ffentlichen Kommunikation und \nder \u00f6ffentlichen Verwaltung besch\u00e4ftigt. Dieser Auswahl liegt \ndie \u00dcberzeugung zugrunde, dass erst ein Blick in die jeweiligen \nAnwendungskontexte die besonderen Chancen und Risiken \ndes Einsatzes von KI zutage f\u00f6rdert. Es wurden bewusst Sekto-\nren ausgew\u00e4hlt, in denen die Durchdringung durch KI-basier -\nte Technologien sehr unterschiedlich ausf\u00e4llt. Am einen Ende \ndes Spektrums befindet sich der Bereich der sozialen Medien \nmit seinen Auswirkungen auf die \u00f6ffentliche Kommunikation 340und Meinungsbildung. Hier sind alle, die diese Angebote nut-\nzen, bereits jetzt in ihrem Alltag auf vielf\u00e4ltige Weise bei ihrer \nInformationsauswahl von den Auswirkungen der dort ver -\nwendeten Technologien betroffen. Am anderen Ende befindet \nsich der Bereich der schulischen Bildung, in dem der Einsatz \nvon KI gegenw\u00e4rtig, jedenfalls in Deutschland, noch eher die \nAusnahme darstellen d\u00fcrfte.\nEs wurden in allen Sektoren Beispiele gew\u00e4hlt, die unter -\nschiedliche Ausma\u00dfe des Ersetzens vormals menschlicher \nHandlungen durch KI veranschaulichen. In allen vier Sektoren \ngibt es Einsatzszenarien, die durch teils erhebliche Beziehungs- \nund Machtasymmetrien gekennzeichnet sind, was einen ver -\nantwortungsvollen Einsatz von KI und die Ber\u00fccksichtigung \nder Interessen und des Wohls insbesondere vulnerabler Perso-\nnengruppen umso wichtiger macht. Diese Unterschiedlichkeit \nder Art und Weise des KI-Einsatzes sowie des Ausma\u00dfes der \nDelegation an Maschinen in den Blick zu nehmen, erlaubt es, \nnuancierte ethische Betrachtungen anzustellen.\nIm besonders sensiblen Bereich der Medizin (vgl. Kapitel \n5) kommen digitale Produkte mit KI-Komponenten in rasch \nwachsendem Umfang zum Einsatz. Dabei sind unterschied-\nliche Akteursgruppen zu unterscheiden, die vom KI-Einsatz \nunterschiedlich betroffen sind oder verschiedene Verant-\nwortlichkeiten besitzen: diejenigen, die KI-Instrumente ent-\nwickeln, klinisch t\u00e4tige Personen, Patientinnen und Patien-\nten. Das Spektrum der Delegation an KI-Systeme reicht hier \nvon der punktuellen Unterst\u00fctzung \u00e4rztlichen Handelns \u00fcber \ndessen st\u00e4ndige Begleitung bis hin zur weitgehenden oder gar \nvollst\u00e4ndigen Ersetzung \u00e4rztlicher Fachkr\u00e4fte durch ein KI-\nSystem. Um einen verantwortlichen Einsatz von KI-Systemen \nzu gew\u00e4hrleisten, ist es daher erforderlich, die gesamte Praxis \nvon der Entwicklung der KI-Systeme \u00fcber ihren Einsatz in \nder Forschung bis zur Implementierung in der medizinischen \nVersorgung an ethischen Standards auszurichten.\nEin wichtiges Einsatzfeld f\u00fcr KI-Systeme ist die Unterst\u00fct-\nzung \u00e4rztlicher Entscheidungen in der Diagnostik, da diese 341gro\u00dfe Datenmengen und eine Vielzahl relevanter Parameter \nauswerten und in Gestalt pr\u00e4ziser Mustererkennung gro-\n\u00dfes diagnostisches und therapeutisches Potenzial entwickeln \nk\u00f6nnen. Der verbesserten Diagnostik stehen allerdings auch \nRisiken gegen\u00fcber, etwa der Verlust eigener Diagnosekompe-\ntenz aufseiten des \u00e4rztlichen Fachpersonals im Vertrauen auf \ntechnische Systeme und die Vernachl\u00e4ssigung eigener Urteils-\nkraft. Auch der Aufkl\u00e4rungsbedarf aufseiten der Patientinnen \nund Patienten steigt durch den Einsatz von KI-Instrumenten \nund muss ber\u00fccksichtigt werden, um das Vertrauen und die \npersonale Zuwendung im Arzt-Patienten-Verh\u00e4ltnis nicht zu \nbesch\u00e4digen. Besonders ambivalent ist etwa die Ersetzung psy-\nchotherapeutischer Diagnose oder Therapie durch Chatbots. \nEinerseits erhofft man sich davon einen Beitrag zur Entlastung \ndes Gesundheitssektors und einen erleichterten Zugang zur \npsychotherapeutischen Erstversorgung. Andererseits stellen \nsich zahlreiche Probleme, nicht zuletzt die Gefahr einer Perso-\nnalisierung von Maschinen, die falsche Projektionen beg\u00fcns-\ntigen kann.\nAuch im Bereich der schulischen Bildung (vgl. Kapitel 6) \nkommen KI-gest\u00fctzte Technologien zum Einsatz, insbeson-\ndere um personalisiertes Lernen und Lehren zu unterst\u00fctzen \noder Informationen zum Lerngeschehen bereitzustellen. Die \nmaschinelle Ersetzung bestimmter p\u00e4dagogischer Handlungs-\nsegmente kann auch hier sowohl zur Erweiterung, aber auch \nzur Verminderung der Handlungsoptionen von Lernenden \nund Lehrkr\u00e4ften f\u00fchren. Die Vision einer vollst\u00e4ndigen Erset-\nzung des Lehrpersonals durch Maschinen ist jedoch mit dem \ninterpersonalen Charakter des p\u00e4dagogischen Geschehens \nund dem Fokus auf Pers\u00f6nlichkeitsbildung nicht in Einklang \nzu bringen. Auch d\u00fcrfen durch den Einsatz digitaler Tools we-\nder die ohnehin oft dominierenden Vorstellungen einer tech-\nnisch verstandenen Optimierung von Lernprozessen verst\u00e4rkt \nnoch der Blick auf das (Ab-)Pr\u00fcfbare verengt werden. Im \nMittelpunkt der Bildungspraxis muss vielmehr weiterhin die \nHerausbildung von m\u00fcndigen und freien Personen stehen, die 342urteilsf\u00e4hig und verantwortlich handeln k\u00f6nnen. Der Einsatz \ndigitaler Systeme muss diesen Zielen verpflichtet sein und darf \nnicht lediglich Selbstzweck sein. Er kann dabei je nach Ziel, \nGestaltung und technischen Grundlagen sehr unterschiedlich \nausfallen. So kann er etwa darauf gerichtet sein, Wissen zu ver -\nmitteln oder F\u00e4higkeiten zu trainieren, Feedback zum Lern-\nfortschritt zu geben oder Impulse f\u00fcr das p\u00e4dagogische Ge-\nschehen zu geben. Dabei sollte verst\u00e4rkt auf das Inklusionsziel \nallgemeiner Bildung geachtet werden: KI-Systeme k\u00f6nnen \nSch\u00fclerinnen und Sch\u00fcler mit besonderen Bed\u00fcrfnissen und \nderen individuellen Lerngeschichten adaptiv begleiten, sie \nunterst\u00fctzen, ihre spezifischen p\u00e4dagogischen Bed\u00fcrfnisse zu \nartikulieren, oder neue M\u00f6glichkeiten er\u00f6ffnen, im Krank-\nheitsfall aus der Ferne immersiv am Schulalltag teilzunehmen. \nDas Unterrichtsgeschehen als Praxis der Verst\u00e4ndigung, des \nAustausches von Gr\u00fcnden, der St\u00e4rkung der Urteilskraft und \nder Pers\u00f6nlichkeitsentwicklung sollte durch den Einsatz di-\ngitaler Tools erweitert und nicht vermindert werden. Gleich-\nwohl k\u00f6nnen den Lehrkr\u00e4ften wie den Lernenden dadurch \nneue Handlungsoptionen er\u00f6ffnet und der personalisierte \nAustausch vertieft werden.\nProzesse der \u00f6ffentlichen Kommunikation und Meinungs-\nbildung (vgl. Kapitel 7) sind in zunehmendem Ma\u00dfe durch \nSoftware im Allgemeinen und KI im Speziellen gepr\u00e4gt. Auf \nder einen Seite erweitern soziale Medien mit ihren vielf\u00e4ltigen \nund wirkm\u00e4chtigen soziotechnischen Prozessen der Generie-\nrung, Kuratierung und Sortierung von Inhalten menschliche \nHandlungsm\u00f6glichkeiten, etwa durch den Zugang zu einer zu-\nvor ungekannten Menge und Diversit\u00e4t verf\u00fcgbarer Informa-\ntionen und Kommunikationsm\u00f6glichkeiten. Demgegen\u00fcber \nsteht jedoch auch die \u2013 h\u00e4ufig weniger sichtbare \u2013 Gefahr der \nVerminderung menschlicher Handlungsmacht. Suchmaschi-\nnen, Newsfeeds und Empfehlungssoftware steuern beabsich-\ntigt oder unbeabsichtigt menschliches Verhalten, beeinflussen \nunseren Zugang zu Information und Kommunikation und so-\nmit zur Realit\u00e4t. Solche m\u00f6glichen Einbu\u00dfen informationeller 343Selbstbestimmung sind das Resultat der zuvor geschilderten \nsoziotechnischen und h\u00e4ufig opaken Prozesse. Diese Prozesse \nsind prim\u00e4r auch nicht an den Interessen der Personen, die \nsie zur Information und Kommunikation nutzen, ausgerich-\ntet, sondern an denen der Plattformen selbst sowie der dort \naktiven Werbetreibenden.\nVon den hier behandelten Sektoren ist der Bereich von \nInformation und Kommunikation derjenige, der am st\u00e4rks-\nten von KI durchdrungen ist und in dem sich M\u00f6glichkeiten \nund Risiken bereits entsprechend deutlich abzeichnen. Viele \nAnwendungen w\u00e4ren ohne den Einsatz algorithmischer Sys-\nteme, die Informationen sortieren, nicht m\u00f6glich. Diese starke \nDurchdringung unserer Lebenswelt mit digitalen Technologi-\nen f\u00fchrt jedoch zu einer individuellen und kollektiven Abh\u00e4n-\ngigkeit und schafft Sachzw\u00e4nge, welche die Vulnerabilit\u00e4t der \nGesellschaft erh\u00f6hen.\nDer vierte Sektor, der in dieser Stellungnahme exemp-\nlarisch behandelt wurde, ist die \u00f6ffentliche Verwaltung (vgl. \nKapitel 8). Hier l\u00e4sst sich in den vergangenen Jahren in vielen \nL\u00e4ndern ein zunehmender Einsatz von Software zur Entschei-\ndungsunterst\u00fctzung in einer Vielzahl unterschiedlicher Berei-\nche beobachten, beispielsweise bei der Bewertung der Arbeits-\nmarktchancen Jobsuchender, der Pr\u00fcfung und Vergabe von \nSozialleistungen, bei Vorhersagen im Sozialwesen oder auch in \ndiversen polizeilichen Einsatzkontexten. Auch wenn in diesen \nF\u00e4llen Entscheidungen nach wie vor von Menschen getroffen \nwerden, so pr\u00e4konfigurieren maschinelle Diagnosen und Pro-\ngnosen diese doch in zunehmendem Ausma\u00df.\nH\u00e4ufig wird der Einsatz solcher Systeme einerseits mit ei-\nner Steigerung der Effizienz von Verwaltungsvorg\u00e4ngen be-\ngr\u00fcndet und andererseits mit einer m\u00f6glichen Verbesserung \nder Qualit\u00e4t von \u2013 teils sehr tiefgreifenden \u2013 Entscheidungen, \ninsbesondere bei komplexen Datenlagen. Demgegen\u00fcber ste-\nhen zahlreiche ethische Fragen und Probleme. Es ist nicht \nerwiesen, dass die Verwendung von Entscheidungssyste-\nmen zwangsl\u00e4ufig zu besseren Entscheidungen f\u00fchrt. Zudem 344konnte in zahlreichen Studien gezeigt werden, dass insbe-\nsondere datenbasierte Systeme existierende gesellschaftliche \nUngleichheiten oftmals reproduzieren. Durch den Einbau in \nscheinbar neutrale Entscheidungssysteme wird daher Diskri-\nminierung zum einen perpetuiert und zum anderen unsicht-\nbar gemacht. Gerade in Bezug auf Entscheidungen, die eine \nhohe Tragweite haben oder besonders vulnerable Gruppen \nbetreffen, ist daher Sorge zu tragen, dass diese Systeme nicht \nnur genau sind, sondern auch offengelegt wird, mittels welcher \nMethoden m\u00f6gliche Diskriminierungseffekte gepr\u00fcft und mi-\ntigiert werden.\nUmgekehrt kann der Einsatz von KI auch existierende Dis-\nkriminierungen in menschlicher Entscheidungspraxis iden-\ntifizieren: Mit der Analyse fr\u00fcherer Entscheidungen wird es \nm\u00f6glich, gesellschaftliche Diskriminierung aufzudecken, zu \nbelegen und \u00c4nderungen einzufordern. Die Verbesserung von \nEntscheidungen, die Minimierung von Fehlern und das Ver -\nhindern bzw. Ausgleichen existierender Diskriminierung sind \nwichtige Ziele f\u00fcr den Einsatz von algorithmischen Systemen \nin der \u00f6ffentlichen Verwaltung. Damit diese die Handlungs-\nm\u00f6glichkeiten der verschiedenen Beteiligten jedoch erweitern \nund nicht vermindern, ist es entscheidend, dass Qualit\u00e4tsstan-\ndards verbindlich festgelegt werden und deren \u00dcberpr\u00fcfung \ndurch externe Akteure m\u00f6glich ist. Gerade in staatlichen Kon-\ntexten m\u00fcssen hier h\u00f6chste Anforderungen an Transparenz \nund Diskriminierungsminimierung angelegt werden.34510\t\t ENTFALTUNG \tVON\t\nQUERSCHNITTSTHEMEN \tUND\t\nEMPFEHLUNGEN\nDie Darstellung der soziotechnischen Entwicklungen und \nderen ethische Analyse in den vier Anwendungskontexten \nzeigen, dass es eine Reihe von Querschnittsthemen und -her -\nausforderungen gibt, die sich \u2013 teils in unterschiedlichen Aus-\npr\u00e4gungsgraden und Formvarianten \u2013 durch alle vier Bereiche \nziehen. Sie d\u00fcrften auch in anderen Anwendungskontexten \nvon \u201eintelligenten\u201c Maschinen eine Rolle spielen, die in dieser \nStellungnahme nicht behandelt wurden. Um im Hinblick auf \ndie Erweiterung menschlicher Handlungsf\u00e4higkeit und Autor -\nschaft zuk\u00fcnftig einen guten gesellschaftlichen Umgang und \neine entsprechende Gestaltung zu gew\u00e4hrleisten, k\u00f6nnen sol-\nche Querschnittsfragen nicht nur innerhalb der einzelnen Be-\nreiche \u2013 sektoral \u2013 angegangen werden. Es werden dar\u00fcber hi-\nnaus vernetzte, bereichs\u00fcbergreifende Ans\u00e4tze notwendig, um \nden im Folgenden skizzierten Themen und Fragen ad\u00e4quat \ngerecht zu werden, die gleichzeitig ausreichende Feink\u00f6rnig-\nkeit erlauben, um der ebenso erforderlichen Kontextsensiti-\nvit\u00e4t zu entsprechen. Solches gleicherma\u00dfen horizontale wie \nvertikale gestaltende Denken stellt eine Herausforderung ins-\nbesondere f\u00fcr die Politikgestaltung und die etwaige zuk\u00fcnftige \nRegulierung dar. W\u00e4hrend dies bei einzelnen Themen bereits \nerkannt und \u2013 wenngleich nicht immer hinreichend \u2013 umge-\nsetzt ist, beispielsweise in Bezug auf Probleme und L\u00f6sungen \nhinsichtlich eines verantwortlichen Umgangs mit Daten, be-\nstehen mit Blick auf andere Themen noch erhebliche Defizite, \nbeispielsweise in Bezug auf (Pfad-)Abh\u00e4ngigkeiten und Res-\nilienz technologischer Infrastrukturen. Die folgende Darstel-\nlung von Querschnittsthemen und die Empfehlungen sollen \ndaher als Anregung f\u00fcr eine breitere Debatte dienen, wie f\u00fcr \nzuk\u00fcnftige Politik- und Technikgestaltung gleichzeitig und im 346Zusammenspiel mit sektoralen Aspekten immer auch \u00fcber -\ngreifende Fragen in den Blick genommen werden k\u00f6nnen und \nm\u00fcssen.\n10.1\t Querschnittsthema\t1:\tErweiterung\t\nund\tVerminderung\tvon\t\nHandlungsm\u00f6glichkeiten\nObwohl KI-Anwendungen in allen in dieser Stellungnahme \nerw\u00e4hnten Bereichen neue Handlungsoptionen erschlie\u00dfen \nk\u00f6nnen, fallen die Potenziale f\u00fcr die tats\u00e4chliche Erweiterung \nmenschlicher Handlungsm\u00f6glichkeiten bislang sehr unter -\nschiedlich aus \u2013 nicht nur zwischen den einzelnen Feldern, \nsondern auch innerhalb verschiedener Segmente ein und des-\nselben Bereichs.\nWie das Beispiel der Medizin zeigt, k\u00f6nnen insbesondere \ndatenintensive F\u00e4cher wie die Onkologie von der Implemen-\ntierung solcher Tools zur Verbesserung der Diagnostik und \nTherapie zum Wohle der Patientinnen und Patienten erheb-\nlich profitieren. Entscheidend ist dabei jedoch deren Einbet-\ntung in eine vertrauensvolle Arzt-Patienten-Beziehung, um \nder individuellen Besonderheit der jeweiligen Lebensumst\u00e4n-\nde gerecht zu werden.\nGanz \u00e4hnlich ist auch der Einsatz von KI-Anwendungen \nim weiten Bereich der schulischen Bildung differenziert zu \nbeurteilen. W\u00e4hrend sich etwa auf dem Gebiet von Lehr- und \nLernsystemen sowie intelligenten Tutorsystemen bereits ge-\ngenw\u00e4rtig sinnvolle Einsatzgebiete beispielsweise zur Verbes-\nserung individueller Lernprozesse abzeichnen, ist das Nutzen-\nSchaden-Potenzial bei anderen Anwendungen \u2013 wie zum \nBeispiel die Privatsph\u00e4re der Lernenden stark beeintr\u00e4chtigen-\nden Classroom Analytics \u2013 kritischer zu beurteilen.\nAuch im Bereich der \u00f6ffentlichen Kommunikation und \nMeinungsbildung ergibt sich ein breites Spektrum zwischen \neiner Erweiterung der Handlungsm\u00f6glichkeiten und ihrer 347Verengung. Dies zeigt sich exemplarisch daran, dass die M\u00f6g-\nlichkeiten, sich breit und umfassend zu informieren und mit \nvielen Menschen schnell und kosteng\u00fcnstig zu kommuni-\nzieren, so gro\u00df sind wie nie zuvor. Im Gegenzug kann es je-\ndoch auch zur Verminderung von Handlungsf\u00e4higkeit kom-\nmen, etwa wenn die freie Meinungsbildung gest\u00f6rt oder gar \nmanipuliert wird. Auch wenn Existenz, Beschaffenheit und \nUrsachen von Effekten wie Filterblasen, Echokammern oder \n(Wahl-)Manipulation genauso kontrovers diskutiert werden \nwie m\u00f6gliche Gegenma\u00dfnahmen, so gilt es doch, Sorge zu tra-\ngen, dass Informations- und Kommunikationstechnologien so \ngestaltet werden, dass menschliche Autorschaft gest\u00e4rkt und \nnicht vermindert wird.\nIn der \u00f6ffentlichen Verwaltung werden die Auswirkungen \nvon Technologien auf Handlungsf\u00e4higkeiten ebenso deut-\nlich. Softwaresysteme, die beispielsweise Risikoscores erstel-\nlen, haben das Ziel, Personen dabei zu unterst\u00fctzen, bessere \nEntscheidungen zu treffen. Idealerweise sollen solche Syste-\nme die Handlungsf\u00e4higkeit also erweitern. In der Realit\u00e4t ist \ndies gleichwohl nicht immer der Fall: Zum einen kann durch \nblindes Befolgen algorithmischer Empfehlungen (Automation \nBias) die Handlungsf\u00e4higkeit entscheidender Personen verrin-\ngert werden. Zum anderen ist auch zu betrachten, inwiefern \ndie Delegation von Entscheidungen an Softwaresysteme die \nAutorschaft und Handlungsm\u00f6glichkeit derer beeintr\u00e4chtigt, \ndie von den Entscheidungen betroffen sind.\nEine sektor\u00fcbergreifende Gemeinsamkeit hinsichtlich der \nangestrebten Erweiterung menschlicher Handlungspotenzia-\nle besteht darin, dass die komplette Ersetzung menschlicher \nAkteure durch KI-Systeme sich \u00fcberall dort verbietet, wo die \nkonkrete zwischenmenschliche Begegnung eine notwendige \nVoraussetzung f\u00fcr die Erreichung der jeweiligen Handlungs-\nziele darstellt. Dar\u00fcber hinaus besteht die Notwendigkeit, die \nDifferenzen eines KI-Einsatzes in den einzelnen Handlungs-\nbereichen sorgf\u00e4ltig zu beachten. Diese betreffen nicht nur \ndie unterschiedliche Sensibilit\u00e4t von Daten und ihre jeweilige 348Bedeutung f\u00fcr das Leben und die Privatsph\u00e4re der Betroffe-\nnen, sondern auch den Bezug zu ganz verschiedenen G\u00fctern \n(z. B. Gesundheit, Bildung, Teilhabe, Sicherheit).\nEmpfehlung\n>> Empfehlung Querschnittsthema 1: Da die Vor- und Nachteile \nvon KI-Anwendungen f\u00fcr verschiedene Personengruppen \nsowie die Gefahr des Verlustes bestimmter Kompetenzen \nbei den Personen, die solche Systeme anwenden, erheblich \nvariieren, bedarf es sowohl einer differenzierten Planung \ndes KI-Einsatzes in unterschiedlichen Handlungsfeldern, \nwelche die jeweiligen Zielsetzungen und Verantwortlich-\nkeiten pr\u00e4zise benennt, als auch einer zeitnahen Evaluation \nder tats\u00e4chlichen Folgen eines solchen Einsatzes, um die \nSysteme besser an die spezifischen Handlungskontexte an-\nzupassen und sie fortlaufend zu verbessern.\n10.2\t Querschnittsthema\t2:\t\nWissenserzeugung\tdurch\tKI\t\nund\tUmgang\tmit\tKI-gest\u00fctzten\t\nVoraussagen\nKorrelationen und Datenmuster sind nicht mit Erkl\u00e4rungen \nund Begr\u00fcndungen von Ursachen von Ereignissen gleichzu-\nsetzen. Vielmehr m\u00fcssen Daten nicht nur qualitativ evaluiert, \nsondern auch normativ beurteilt werden. Diese Beurteilung \nsetzt die F\u00e4higkeit voraus, Handlungen als Zweckrealisie-\nrungsversuche auszuf\u00fchren, zu verstehen und zu \u00fcberpr\u00fcfen.\nMit dem Zuwachs qualitativ hochwertiger und relevanter \nDaten sowie verbesserter Methoden der Datenanalyse steigt \nh\u00e4ufig die Genauigkeit von Vorhersagen. Dennoch bestehen \nbei probabilistischen Methoden immer Restunsicherheiten. \nDadurch ergibt sich die Frage, welcher Grad an epistemischer \nSicherheit gesellschaftlich oder individuell f\u00fcr w\u00fcnschens-\nwert bzw. unerl\u00e4sslich gehalten wird, um Handlungen und 349Entscheidungen zu legitimieren. Auch wie Fehler erster oder \nzweiter Art, das hei\u00dft falsch-positive und falsch-negative Er -\ngebnisse, und deren Folgen f\u00fcr unterschiedliche Betroffene zu \nbewerten sind, ist eine normative Frage, die den methodischen \nEntscheidungen in der Technikentwicklung vorausgehen \nmuss.\nEine durch KI instrumentell unterst\u00fctzte Daten- und In-\nformationsbearbeitung sowie Wissensproduktion, die den \nEinfluss menschlicher Schw\u00e4chen (z. B. M\u00fcdigkeit, Lustlo-\nsigkeit, Ehrgeiz, Bestechlichkeit) vermindert, w\u00fcrde epistemi-\nsche und praktische Kompetenzen des Menschen grunds\u00e4tz-\nlich erweitern. Ein KI-gest\u00fctzte Software allerdings, welche \nauf intransparenter Probabilit\u00e4tsbasis praktische Kompetenz \n\u00fcbernimmt, w\u00fcrde die menschliche Handlungssouver\u00e4nit\u00e4t \nund Verantwortung hingegen vermindern. Wollte man ver -\nsuchen, den Menschen als Handlungssouver\u00e4n zu ersetzen, \nk\u00e4me es zu einer Diffusion oder vollst\u00e4ndigen Eliminierung \nvon Verantwortung.\nF\u00fcr die ethische Beurteilung des Einsatzes von KI ist rele-\nvant, dass durch diesen in allen vier in dieser Stellungnahme \nangesprochenen Anwendungsbereichen erhebliche funktio-\nnale Verbesserungen erreicht wurden und weiterhin erwart-\nbar sind. Dies gilt bei Diagnose und Therapie in der Medizin, \nim Unterricht in der schulischen Bildung, bei Information \nund Austausch von Argumenten im Bereich der \u00f6ffentlichen \nKommunikation und Meinungsbildung und schlie\u00dflich in der \n\u00f6ffentlichen Verwaltung. In allen Bereichen wird jedoch eine \ngrunds\u00e4tzlich normativ problematische Schwelle \u00fcberschrit-\nten, wenn funktionale Verbesserungen (eventuell sogar unbe-\nmerkt) in eine Ersetzung moralischer Kompetenz und damit \nverbundener Verantwortung hin\u00fcbergleiten.\nDiese Schwelle ist beispielsweise im Gesundheitsbereich \n\u00fcberschritten, wenn diagnostische und therapeutische Inter -\nventionen unter tats\u00e4chlicher Umgehung einer informierten \nEinwilligung der Patientin oder des Patienten (unter Umst\u00e4n-\nden angetrieben durch Personalmangel) in G\u00e4nze digitalen 350Systemen \u00fcberlassen werden. Im Bereich der Bildung w\u00e4re dies \nder Fall, wenn nicht nur routinierte Lehrprozesse an Software \ndelegiert, sondern Lehrpersonen vollst\u00e4ndig technologisch \nersetzt w\u00fcrden. Im Bereich der \u00f6ffentlichen Kommunikation \nund Meinungsbildung w\u00e4re eine Grenze \u00fcberschritten, wenn \nf\u00fcr die am \u00f6ffentlichen Diskurs Teilnehmenden die morali-\nsche und rechtliche Verantwortung f\u00fcr Meinungen und Tat-\nsachenbehauptungen nicht mehr erkennbar ist oder der Aus-\ntausch von Argumenten durch digitale Ma\u00dfnahmen praktisch \naufgehalten wird. Im Bereich der \u00f6ffentlichen Verwaltung \ngilt Entsprechendes, wenn Menschen nicht erkennen k\u00f6n-\nnen, dass Verwaltungsentscheidungen durch digitale Agenten \n\u00fcbernommen wurden oder eine solche \u00dcbernahme effektive \nKontrollen verhindert. In allen Kontexten ist das entscheiden-\nde Kriterium f\u00fcr eine ethische Beurteilung die M\u00f6glichkeit der \nIdentifizierung und der moralischen bzw. rechtlichen Inan-\nspruchnahme von Agierenden, die in der Lage und auch ver -\npflichtet sind, Handlungsverantwortung zu \u00fcbernehmen.\nEmpfehlung\n>> Empfehlung Querschnittsthema 2: Der Einsatz KI-gest\u00fctzter \ndigitaler Techniken ist im Sinne der Entscheidungsunter -\nst\u00fctzung und nicht der Entscheidungsersetzung zu gestal-\nten, um Diffusion von Verantwortung zu verhindern. Er \ndarf nicht zulasten effektiver Kontrolloptionen gehen. Den \nvon algorithmisch gest\u00fctzten Entscheidungen Betroffenen \nist insbesondere in Bereichen mit hoher Eingriffstiefe die \nM\u00f6glichkeit des Zugangs zu den Entscheidungsgrundlagen \nzu gew\u00e4hren. Das setzt voraus, dass am Ende der techni-\nschen Prozeduren entscheidungsbefugte Personen sichtbar \nbleiben, die in der Lage und verpflichtet sind, Verantwor -\ntung zu \u00fcbernehmen.35110.3\t Querschnittsthema\t3:\tGef\u00e4hrdung\t\ndes\tIndividuums\tdurch\tstatistische\t\nStratifizierung\nMit auf der Grundlage von Big Data erstellten Korrelationen \nwerden menschliche Individuen Kohorten (Strata) zugeordnet \n(z. B. regional definierte Kohorten wie die Anwohnenden ei-\nner Stra\u00dfe oder Alterskohorten), die ohne jede soziale Erleb-\nnisqualit\u00e4t sein k\u00f6nnen. Die Bildung solcher Kohorten und die \nauf ihrer Basis durch Algorithmen produzierten Voraussagen \nk\u00f6nnen f\u00fcr diejenigen, die solche Ans\u00e4tze verwenden, durch-\naus n\u00fctzlich sein, versprechen sie doch \u00fcber die Gesamtmenge \nder Entscheidungen hinweg eine Erh\u00f6hung von Effektivit\u00e4t \nund Qualit\u00e4t. Probleme treten freilich f\u00fcr Individuen auf, die \nvon solchen kollektiven Schl\u00fcssen betroffen sind \u2013 insbeson-\ndere dann, wenn die statistisch getroffene Diagnose oder Pro-\ngnose in ihrem konkreten Fall nicht zutrifft.\nIm Bereich der Medizin zeigt sich diese strukturelle Asym-\nmetrie, wenn beispielsweise ein Individuum aufgrund diagnos-\ntizierter Merkmale einer Kohorte zugeordnet und aufgrund \nvon Algorithmen eine therapeutische Strategie festgelegt wird. \nMan kann von einem \u201estatistischen Kollektivismus\u201c spre-\nchen, gegen\u00fcber dem das Individuum geltend machen k\u00f6nnen \nmuss, als Individuum betrachtet und behandelt zu werden. Das \nbedeutet, dass im Rahmen der Medizin als praktischer Wissen-\nschaft eine korrelative Zuordnung eines Individuums zwar ein \ngutes diagnostisches Indiz sein kann, das wiederum eine gute \npraktische Heuristik rechtfertigt, aber grunds\u00e4tzlich nicht die \neinzige Evidenzgrundlage f\u00fcr eine Behandlung sein darf. Epi-\ndemiologische Studien grenzen entsprechend denkbare priori-\nt\u00e4re Diagnosen ein und legen auf dieser Grundlage bestimmte \nTherapien nahe. Sie sollten jedoch nie allein die Grundlage f\u00fcr \neine Behandlung sein.\nDie gleichen Probleme betreffen auch die datenbasierte \nDiagnostik und Prognose im Bereich der \u00f6ffentlichen Verwal-\ntung oder der schulischen Bildung. Auch wenn solche Systeme 352das Ziel haben, nicht nur die Effektivit\u00e4t, sondern auch die \nQualit\u00e4t von Entscheidungen zu verbessern, so bleibt ein un-\n\u00fcberbr\u00fcckbarer Spalt zwischen der je individuellen Lebenssi-\ntuation und deren statistischer Ann\u00e4herung. Auch wenn 99 \nvon 100 Personen mit einem bestimmten Risikoprofil erneut \nstraff\u00e4llig werden oder keinen Schulabschluss erreichen wer -\nden, so wissen wir doch nicht, ob diese eine Person, \u00fcber die zu \nentscheiden ist, nicht genau die eine Ausnahme ist.\nDas Individuum entzieht sich einer vollst\u00e4ndigen statisti-\nschen Ann\u00e4herung. Jedoch wirkt jeder Versuch einer statis-\ntischen Ann\u00e4herung m\u00f6glicherweise auf das Individuum zu-\nr\u00fcck. Genauer: Die Probleme der datenbasierten Voraussagen \nwerden noch einmal um eine Dimension versch\u00e4rft, wenn das \nReferenzobjekt, auf das sich Wahrscheinlichkeitsaussagen be-\nziehen, durch diese Aussagen selbst beeinflussbar ist, wie das \nf\u00fcr alle Kontexte menschlichen Handelns, so zum Beispiel \nin der Volkswirtschaft oder im Gesundheitssystem, zutrifft. \nDies gilt sowohl f\u00fcr Individuen als auch f\u00fcr Kollektive. Die \nR\u00fcckwirkungen von Klassifikationen und statistischen Vor -\nhersagen insbesondere in Medizin, Sozialwissenschaften und \nPsychologie auf die betroffenen Individuen hat Ian Hacking \nmit dem Begriff \u201eLoopingeffekt\u201c beschrieben.426 Aber auch \nauf kollektiver Ebene k\u00f6nnen beispielsweise aus epidemiolo-\ngischen Studien gewonnene konditionierte Voraussagen bei \npassender \u00f6ffentlicher Verbreitung kollektive Verhaltenswei-\nsen erheblich ver\u00e4ndern \u2013 derart, dass die Datengrundlage \nnicht mehr verl\u00e4sslich ist.\nDiese R\u00fcckwirkung von Klassifikation und Prognostik \nauf Individuen wie Kollektive zeigt sich nicht zuletzt auch in \nBezug auf soziale Medien im Bereich der \u00f6ffentlichen Kom-\nmunikation und Meinungsbildung. Der Begriff des Hyper -\nnudge verweist hierbei auf die Besonderheit datenbasierter \nSysteme, die im Hintergrund und in Echtzeit die Informati-\nonsumgebung von Individuen, basierend auf statistischen \n426\tHacking\t1995.353Analysen, permanent anpassen und dadurch die weitere In-\nformationsauswahl und die Entscheidungsm\u00f6glichkeiten \npr\u00e4konfigurieren.427\nEmpfehlung\n>> Empfehlung Querschnittsthema 3: Neben einer Analyse der \nkonkreten und naheliegenden Probleme datenbasierter \nSoftware, beispielsweise in Bezug auf den Schutz der Pri-\nvatsph\u00e4re oder die Verhinderung von Diskriminierung, \ngilt es, auch die langfristigen Auswirkungen dieser statisti-\nschen Pr\u00e4konfiguration von Individuen sowie deren R\u00fcck-\nwirkung \u2013 im Sinne einer Erweiterung oder Verminderung \nder Handlungsm\u00f6glichkeiten \u2013 auf Individuen wie Kollek-\ntive f\u00fcr alle Sektoren sorgf\u00e4ltig zu beleuchten. Dar\u00fcber hin-\naus gilt, dass Einzelfallbeurteilungen grunds\u00e4tzlich wichtig \nbleiben. KI-basierte Beurteilungen und Vorhersagen k\u00f6n-\nnen unter g\u00fcnstigen Bedingungen ein Hilfsmittel sein, aber \nkein geeignetes Instrument der definitiven Lagebeurteilung \nund Entscheidung. Pragmatische und heuristische Fakto-\nren wie die Pr\u00fcfung der Koh\u00e4renz mit anderen Evidenz-\nquellen oder Erfolgseinsch\u00e4tzungen spielen eine nicht zu \nvernachl\u00e4ssigende Rolle.\n10.4\t Querschnittsthema\t4:\tAuswirkungen\t\nvon\tKI\tauf\tmenschliche\t Kompetenzen\t\nund\tFertigkeiten\nDer Einsatz von KI-Anwendungen in ganz unterschiedlichen \nLebensbereichen beeinflusst menschliche Handlungsf\u00e4higkeit \nund hat erheblichen Einfluss auf den Erwerb und den Erhalt \nmenschlicher Kompetenzen und Fertigkeiten.\nSo zeigt sich im Bereich der Medizin, dass der fachgerechte \nEinsatz von KI-Anwendungen dazu geeignet ist, diagnostische \n427\tYeung\t2017.354Kompetenzen zu verbessern und zu einer deutlichen Redukti-\non von Fehldiagnosen f\u00fchren kann. Auch in der schulischen \nBildung dienen digitale Technologien in vielf\u00e4ltiger Weise der \nKompetenzerweiterung. Im Bereich der \u00f6ffentlichen Kommu-\nnikation und Meinungsbildung erweitern digitale Technologi-\nen die informationellen und kommunikativen M\u00f6glichkeiten \nder Beteiligten und erlauben damit eine eventuell kompeten-\ntere Teilnahme am \u00f6ffentlichen Diskurs. In der \u00f6ffentlichen \nVerwaltung wiederum sollen Softwaresysteme die Kompetenz \nder Besch\u00e4ftigten erh\u00f6hen, gute und angemessene Entschei-\ndungen zu treffen, etwa beim Einsatz von Risikobewertungen \nzur Prognose und Pr\u00e4vention von Gefahrenlagen.\nAllerdings hat der Einsatz von KI-Anwendungen nicht \nnur das Potenzial, Kompetenzen zu erweitern, sondern auch, \ndiese zu vermindern. Dies kann wiederum mit einem Beispiel \naus dem medizinischen Bereich veranschaulicht werden: Eine \nSoftware, die R\u00f6ntgenbilder pr\u00e4zise nach Auff\u00e4lligkeiten un-\ntersucht und dabei statistisch deutlich besser abschneidet als \nder Mensch, erweist sich als signifikante Erweiterung bisheri-\nger menschlicher Handlungsm\u00f6glichkeiten. Zugleich geht mit \ndem Einsatz des Systems das Risiko einher, dass der die An-\nwendung nutzende Mensch die eigenen F\u00e4higkeiten einb\u00fc\u00dft, \nR\u00f6ntgenbilder unter diesem Gesichtspunkt zu analysieren. \nDieser Effekt des Deskillings kann etwa deshalb eintreten, weil \ndie jeweilige F\u00e4higkeit zu ihrem Erhalt der steten Ein\u00fcbung \nbedarf, sie nunmehr aber nicht hinreichend h\u00e4ufig praktiziert \nwird, da die Technologie den Menschen mehr und mehr un-\nterst\u00fctzt bzw. seine Aufgabe vornehmlich \u00fcbernimmt.428 Ein \nweiterer Grund f\u00fcr Deskilling kann das gro\u00dfe Vertrauen in \neine nahezu perfekte Technologie bei gleichzeitigem Misstrau-\nen in die eigenen F\u00e4higkeiten sein (Automation Bias). Der ein-\nzelne Mensch k\u00f6nnte geneigt sein, sich weniger auf das eige-\nne als auf das technisch erzeugte Urteil zu verlassen \u2013 mit der \nFolge, dass wiederum F\u00e4higkeiten nicht einge\u00fcbt werden und \n428\tBainbridge\t1983.355so mit der Zeit verloren gehen. Angesichts des verst\u00e4rkten Ein-\nsatzes von KI-Anwendungen wird Deskilling in verschiedenen \ngesellschaftlichen Bereichen zunehmend bef\u00fcrchtet. Freilich \nist Kompetenzverlust als Effekt nicht allein auf digitale oder \ngar KI-basierte Technologien begrenzt, sondern kann letztlich \nbei nahezu allen Werkzeugen beobachtet werden, derer Men-\nschen sich zur Vereinfachung ihrer Aufgaben bedienen.\nDen offenkundigen Vorteilen der Erweiterung von F\u00e4hig-\nkeiten und Handlungsm\u00f6glichkeiten durch KI-basierte Syste-\nme st\u00fcnden also etwaige Nachteile gegen\u00fcber, die entstehen, \nwenn es zu einer Verringerung von F\u00e4higkeiten und Fertig-\nkeiten menschlicher Akteure in bestimmten gesellschaftli-\nchen Bereichen k\u00e4me. Wann dies in der Gesamtschau akzep-\ntabel und wann problematisch w\u00e4re, l\u00e4sst sich nicht pauschal \noder \u00fcbergreifend beantworten, sondern muss kontext- und \nfallspezifisch bestimmt werden. Weil die Nutzung von KI-\nAnwendungen dazu f\u00fchren kann, dass bedeutsame mensch-\nliche F\u00e4higkeiten nachlassen bzw. ganz verk\u00fcmmern, k\u00f6n-\nnen Abh\u00e4ngigkeiten von diesen Technologien entstehen. Es \nist jedoch gerade angesichts der enormen Zunahme digitaler \nTechnologien nicht ohne Weiteres ausgemacht, dass die Vor -\naussetzungen f\u00fcr deren Einsatz, wie zum Beispiel eine stabile \nStromversorgung, immer sicher gew\u00e4hrleistet werden k\u00f6n-\nnen. Dies kann menschliche F\u00e4higkeiten mitunter kurzfristig \nwieder bedeutsam werden lassen. Das spezifische Risiko von \nKompetenzverlusten im Zusammenhang mit dem Einsatz von \nKI-Anwendungen liegt demnach in der Besonderheit der T\u00e4-\ntigkeiten, die der Technik \u00fcberlassen werden \u2013 handelt es sich \ndabei um gesellschaftlich besonders bedeutsame oder kritische \nEinsatzbereiche, ist ein Verlust von menschlichen Kompeten-\nzen und Fertigkeiten ein ernstzunehmendes Risiko.\nAllerdings lie\u00dfe sich einem solchen Risiko entgegenwirken. \nDroht Kompetenzverlust und ist dieser gesellschaftlich uner -\nw\u00fcnscht, bedarf es daf\u00fcr effektiver Vorkehrungen zur Ver -\nmeidung dieses Effekts. Eine L\u00f6sung kann beispielsweise darin \nliegen, dass die Technologie nur dann zum Einsatz gebracht 356werden darf, wenn sichergestellt ist, dass die Betroffenen die \nFertigkeiten weiter regelm\u00e4\u00dfig trainieren. In der Medizin etwa \nk\u00f6nnte dies neben noch zu entwickelnden spezifischen Fort-\nbildungsprogrammen bedeuten, Befundungen nie ganz an ei-\nnen Algorithmus abzugeben.\nGleichwohl bleibt auch unter dieser Voraussetzung der \nEinwand bestehen, dass infolge eines immer durchgreifende-\nren Einsatzes von KI-Anwendungen in unterschiedlichen Le-\nbensbereichen Menschen mehr und mehr dazu verleitet wer -\nden k\u00f6nnten, eigene Aufgaben an die Technik zu delegieren, \nweil diese als (vermeintlich) \u00fcberlegen angesehen wird. Hier -\naus ergibt sich ein Risiko f\u00fcr die individuelle Selbstwahrneh-\nmung. Mit zunehmender Delegation von Aufgaben an Tech-\nnologien kann der Eindruck entstehen, immer mehr Kontrolle \n\u00fcber wesentliche Bereiche des eigenen Lebens abzugeben. Im \nExtremfall k\u00f6nnte eine regelm\u00e4\u00dfige Delegation von Entschei-\ndungen einen Effekt auf die Wahrnehmung des Selbst als Au-\ntor des eigenen Geschickes haben und sogar b\u00fcrgerschaftliches \nEngagement reduzieren. Vor allem aber k\u00f6nnten \u201eKipppunk-\nte\u201c einer solchen passiven Selbstwahrnehmung schleichend \nerreicht und \u00fcberschritten werden, ohne dass noch effektiv \ninterveniert werden k\u00f6nnte.\nAngesichts dieser \u00dcberlegungen sollten das Ma\u00df an Dele-\ngation, etwaige Verlagerungen von Aufgaben aus einem Le-\nbensbereich in andere sowie die allgemeine gesellschaftliche \nEntwicklung infolge des verst\u00e4rkten Einsatzes von KI-Anwen-\ndungen in dieser Hinsicht sorgsam beobachtet werden. Wenn \ndas beschriebene Risiko jedoch mehr als eine denkbare M\u00f6g-\nlichkeit darstellt, sich also zu einem relevanten Faktor verdich-\ntet, erscheinen Gegensteuerungsma\u00dfnahmen erforderlich.\nEmpfehlung\n>> Empfehlung Querschnittsthema 4: Ob und inwiefern \nbeim Einsatz von KI-Anwendungen Verluste mensch-\nlicher Kompetenz auftreten, die als unerw\u00fcnscht einge-\nstuft werden, muss sorgf\u00e4ltig beobachtet werden. Bei der 357Entwicklung und dem Einsatz neuer Technologien sind \nsolch unerw\u00fcnschte Kompetenzverluste durch eine sinn-\nvolle Gestaltung des Zusammenspiels von Mensch und \nTechnik, durch angemessene institutionelle und organi-\nsatorische Rahmenbedingungen sowie durch gezielte Ge-\ngenma\u00dfnahmen wie etwa spezifische Trainingsprogramme \nzu minimieren bzw. zu kompensieren. Kompetenzverlus-\nte k\u00f6nnen sowohl individueller als auch kollektiver Na-\ntur sein. So gilt es zu verhindern, dass die Delegation von \nAufgaben an Technologien dazu f\u00fchrt, dass Gesellschaf-\nten \u00fcberm\u00e4\u00dfig anf\u00e4llig werden, wenn diese Technologien \n(zeitweise) ausfallen. Jenseits dieser systemischen Aspekte \nm\u00fcssen negative Auswirkungen solcher Delegation auf die \nindividuelle Autonomie oder Selbstwahrnehmung miti-\ngiert werden.\n10.5\t Querschnittsthema\t5:\tSchutz\tvon\t\nPrivatsph\u00e4re\tund\tAutonomie\tversus\t\nGefahren\tdurch\t\u00dcberwachung\tund\t\nChilling-Effekte\nEin weiteres wichtiges \u00fcbergreifendes Thema, welches sich \ndurch alle Anwendungsbereiche zieht, ist die Gefahr der \u00dcber -\nwachung und die M\u00f6glichkeit auftretender Chilling-Effekte, \ndie nicht nur die Privatsph\u00e4re von Menschen, sondern auch \nderen Autonomie gef\u00e4hrden.429 Viele der zuvor behandelten \nTechnologien sind auf die Sammlung und Auswertung gro-\n\u00dfer Mengen an personenbezogenen Daten angewiesen. Die \nErfassung solcher Daten und die M\u00f6glichkeit, auf ihrer Basis \nsensible Prognosen zu erstellen, beeintr\u00e4chtigen nicht nur die \nPrivatsph\u00e4re der Personen, von denen die Daten stammen, \nsondern machen sie auch vulnerabel gegen\u00fcber m\u00f6glichen \n429\tPenney\t2017;\tSolove\t2006.358Benachteiligungen oder Manipulationen, die aus der Verar -\nbeitung der Daten resultieren k\u00f6nnen.\nAber auch wenn Daten nicht personenbezogen ausgewer -\ntet, das hei\u00dft keine R\u00fcckschl\u00fcsse auf das Individuum gezo-\ngen werden, kann sich bereits die Sorge vor der M\u00f6glichkeit \nsolcher R\u00fcckschl\u00fcsse negativ auf die Autonomie und Entfal-\ntungsfreiheit von Menschen auswirken. Der Chilling-Effekt \nbeschreibt in diesem Kontext R\u00fcckwirkungen auf Menschen, \ndie Sorge haben, dass ihr Verhalten beobachtet, aufgezeichnet \noder ausgewertet wird. Besonders sichtbar werden solche Chil-\nling-Effekte im Kontext von \u00f6ffentlicher Kommunikation und \nMeinungsbildung. So k\u00f6nnen Menschen davor zur\u00fcckschre-\ncken, nach relevanten, aber m\u00f6glicherweise sensiblen Themen \nim Internet zu suchen oder als kontrovers wahrgenommene \nInhalte zu lesen, in dem Wissen, dass ihr Onlineverhalten \ngetrackt wird, und aus der Sorge heraus, in welcher Art und \nWeise sich das m\u00f6glicherweise nachteilig auf sie auswirken \nk\u00f6nnte.430 Es geht hier also einerseits um die tats\u00e4chlichen ne-\ngativen Effekte der \u00dcberwachung von Individuen und ande-\nrerseits um Effekte, die als Anpassung an die Sorge vor dieser \n\u00dcberwachung entstehen.\nInvasives Tracking f\u00fchrt nicht nur dazu, dass Menschen \npersonalisierte, passgenaue Werbung zugespielt wird, sondern \nauch, dass Datenspuren, die sie online hinterlassen, im Aggre-\ngat und Zusammenspiel mit weiteren Datenspuren (sowohl \naus anderen Quellen als auch von anderen Personen) etwa \nmittels Datenbroker zu vielf\u00e4ltigen, f\u00fcr die betroffene Per -\nson nicht nachvollziehbaren Zwecken zweitverwertet werden \nk\u00f6nnen. Das Gesch\u00e4ftsmodell von Datenbrokern stellt eine \nBeeintr\u00e4chtigung der Privatsph\u00e4re dar und beruht auf der Fik-\ntion, dass eine Zustimmung zu allgemeinen Gesch\u00e4ftsbedin-\ngungen von Onlineangeboten einer informierten Einwilligung \ngleichkommt.\n430\tB\u00fcchi/Festic/Latzer\t2022.359Chilling-Effekte wiederum sind das Resultat des Wissens \num oder auch nur der Ahnung von solchen Praktiken. Das ei-\ngene Verhalten ver\u00e4ndert sich so, als w\u00fcrde man tats\u00e4chlich \n\u00fcberwacht. Nicht nur der Informationskonsum wird einer Art \nSelbstzensur unterworfen, sondern auch die freie Meinungs-\n\u00e4u\u00dferung kann online beeintr\u00e4chtigt werden. Das Tracking \ninsbesondere des Medienverhaltens von Individuen beein-\ntr\u00e4chtigt somit nicht nur deren intellektuelle Privatsph\u00e4re, \nsondern hat m\u00f6glicherweise auch negative Auswirkungen auf \ndie Kommunikationsfreiheit, auf individuelle Kreativit\u00e4t und \nkann somit der Pers\u00f6nlichkeitsentwicklung und der demokra-\ntischen Selbstverst\u00e4ndigung abtr\u00e4glich sein.\n\u00c4hnliche Probleme k\u00f6nnen auch in gesundheitlichen \nKontexten beziehungsweise an der Schnittstelle zwischen On-\nlineverhalten und Medizin entstehen. Wenn Onlineverhalten \ngetrackt wird und Datenspuren von Brokern weiterverkauft \nwerden, so kann die Sorge, aufgrund der m\u00f6glichen Diagnose \noder Prognose etwa einer psychischen Erkrankung keine pri-\nvate Krankenversicherung mehr zu bekommen, dazu f\u00fchren, \ndass nicht nach Informationen gesucht wird, die etwa Depres-\nsion oder Suchtverhalten nahelegen k\u00f6nnten. Auch bei der \nVerwendung von Technologien im Gesundheitswesen selbst, \nbeispielsweise beim Einsatz von datenbasierten Systemen in \nder Diagnostik oder auch bei der Kommunikation mit thera-\npeutischen Chatbots, k\u00f6nnen Menschen, die solche Angebote \nnutzen, annehmen \u2013 ob berechtigt oder nicht \u2013, dass sensible \nDaten oder Prognosen in die H\u00e4nde unbefugter Dritter gera-\nten k\u00f6nnen, und falsche Angaben machen, die m\u00f6glicherweise \nzu falschen Diagnosen f\u00fchren. Um etwaigen Chilling-Effekten \nentgegenzuwirken, gilt es also, unzul\u00e4ssige Datenweitergaben \nzu verhindern, insbesondere dann, wenn diese nicht im Inte-\nresse der Personen sind, von denen die Daten stammen, oder \ngar fremden, nicht gesundheitsbezogenen Zwecken dienen.\nAuch in der schulischen Bildung m\u00fcssen Gefahren von \n\u00dcberwachung und m\u00f6gliche Chilling-Effekte ernst genommen \nwerden. Dies gilt insbesondere in Bezug auf Technologien, 360welche auf Audio- oder Video\u00fcberwachung des Klassenraums \nbasieren. Emotionserkennung oder Aufmerksamkeitsmoni-\ntoring kann nicht nur die Privatsph\u00e4re der Lernenden sowie \ngegebenenfalls der Lehrkr\u00e4fte auf unzul\u00e4ssige Art und Weise \nbeeintr\u00e4chtigen. Bereits die Sorge vor einer solchen \u00dcberwa-\nchung, selbst wenn die Daten nicht aufbewahrt und nicht per -\nsonenbezogen analysiert und ausgewertet w\u00fcrden, hat unter \nUmst\u00e4nden Auswirkungen auf das Verhalten der Beteiligten.\nDie parallelen Gefahren von \u00dcberwachung und Chilling-\nEffekten stellen sich schlie\u00dflich auch im Bereich der \u00f6ffentli-\nchen Verwaltung. Paradigmatisch hierf\u00fcr sind Ma\u00dfnahmen \nim Kontext von Predictive Policing wie beispielsweise der \nChatkontrolle. Eine anlasslose \u00dcberwachung der Telekommu-\nnikation ist grundrechtlich inakzeptabel; bereits die Sorge vor \neiner solchen \u00dcberwachung k\u00f6nnte dazu f\u00fchren, dass Men-\nschen sich selbst zensieren.\nEmpfehlung\n>> Empfehlung Querschnittsthema 5: Die beschriebenen Ph\u00e4-\nnomene sollten in ihrer Entstehung, Auspr\u00e4gung und Ent-\nwicklung umfassend empirisch untersucht werden. Um \nsowohl dem Problem der \u00dcberwachung sowie den paral-\nlelen Gefahren durch etwaige Chilling-Effekte Rechnung \nzu tragen, m\u00fcssen angemessene und effektive rechtliche \nund technische (z. B. Privacy by Design) Vorkehrungen \ngetroffen werden, die dem \u00fcberm\u00e4\u00dfigen Tracking von On-\nlineverhalten und dem Handel mit personenbeziehbaren \nDaten Einhalt gebieten. Die Interessen der Datensubjekte \nm\u00fcssen hierbei im Mittelpunkt stehen. Insbesondere ist \ndabei auf besonders vulnerable Gruppen zu achten, da vie-\nle der Einsatzkontexte zudem von asymmetrischen Macht-\nverh\u00e4ltnissen gekennzeichnet sind. Es muss Sorge getragen \nwerden, dass die Erweiterung der Handlungsm\u00f6glichkeiten \neiniger nicht zulasten der Verminderung der Handlungs-\nm\u00f6glichkeiten anderer, insbesondere benachteiligter Grup-\npen stattfindet.36110.6\t Querschnittsthema\t6:\t\nDatensouver\u00e4nit\u00e4t\tund\t\ngemeinwohlorientierte\t\nDatennutzung\nWie zuvor erl\u00e4utert, bergen viele der in dieser Stellungnah-\nme vorgestellten Technologien insbesondere aufgrund der \nNutzung vielf\u00e4ltiger Daten zwar zahlreiche Risiken, sie brin-\ngen aber gleichzeitig gro\u00dfe Chancen mit sich, auf die wir als \nGesellschaft ungern verzichten w\u00fcrden. Es m\u00fcssen also L\u00f6-\nsungen entwickelt werden, wie Daten sinnvoll f\u00fcr verschie-\ndene wichtige Zwecke genutzt werden k\u00f6nnen, ohne zugleich \nden Schutz der Privatsph\u00e4re der Datensubjekte unzul\u00e4ssig zu \nbeeintr\u00e4chtigen.431\nIn diesem Zusammenhang stellt sich die Frage, ob das der -\nzeitige Datenschutzrecht bzw. die herrschende Datenschutz-\npraxis diesen beiden Zielen gerecht wird. Hier kommt Kritik \naus beiden Richtungen: Einerseits wird die Privatsph\u00e4re von \ndatenliefernden Personen gerade im Kontext von sozialen Me-\ndien und der zugrundeliegenden Daten\u00f6konomie nicht ausrei-\nchend gesch\u00fctzt. Andererseits wirft die aktuelle Datenschutz-\npraxis gerade in der \u00f6ffentlichen Forschung vielfach Probleme \nauf \u2013 auch und gerade dort, wo es explizit um gemeinwohl-\norientierte Aktivit\u00e4ten und eben nicht um (unbemerkte) \nNachverfolgung geht, die die Privatsph\u00e4re und Interessen der \nPersonen, die ihre Daten zur Verf\u00fcgung stellen, verletzt. W\u00e4h-\nrend also in manchen Handlungsfeldern berechtigte Sorgen \n431\t Diesem\tZielkonflikt\tund\tden\tdamit\tverbundenen,\tvielf\u00e4ltigen\tHerausfor -\nderungen\that\tsich\tbereits\tdie\tStellungnahme\tdes\tDeutschen\tEthikrates\tzu\t\nBig\tData\tund\tGesundheit\taus\tdem\tJahr\t2017\tgewidmet.\tDort\that\ter\tdie\tNot -\nwendigkeit,\tindividuelle\tInteressen\tund\tdie\tPrivatsph\u00e4re\teffektiv\tzu\tsch\u00fct -\nzen,\tsystematische\tSchadenspotenziale\tzu\terkennen\tund\tzu\tverringern\t\nsowie\tgleichzeitig\tgemeinwohlorientierte\tAktivit\u00e4ten\tin\tder\tDatennutzung\t\nzu\term\u00f6glichen,\tim\tnormativen\tKonzept\tder\tDatensouver\u00e4nit\u00e4t\tzusammen-\ngef\u00fchrt.\tDer\tRat\that\tin\tder\tStellungnahme\teine\tVielzahl\tvon\tEmpfehlungen\t\nvorgelegt,\twie\tder\tSchutz\tder\tPrivatsph\u00e4re\tunter\tden\tBedingungen\tdaten-\nges\u00e4ttigter\tLebenswelten\tverbessert\twerden\tkann;\tdiese\tsind\tvielfach\tauch\t\nauf\tdie\thier\tverhandelten\tAnwendungsbereiche\t\u00fcbertragbar\t(Deutscher\t\nEthikrat\t2017).362vor unbemerkten und weitreichenden Verletzungen von Pri-\nvatsph\u00e4re und informationeller Selbstbestimmung herrschen, \nwerden in anderen Kontexten durch strenge Auslegungen von \nDatenschutzregeln wichtige soziale G\u00fcter, etwa mit Blick auf \nPatientenversorgung und wissenschaftlichen Erkenntnisge-\nwinn, aber auch die kommunale Daseinsvorsorge nicht oder \nnur sehr schwer erreicht.\nEine wesentliche Ursache f\u00fcr beide Probleme sind Cha-\nrakteristika des Datenschutzrechts, die in der Vergangenheit \numfassend kritisiert worden sind und die sich, verknappt ge-\nsprochen, aus dem zugrundeliegenden Individualismus und \nder damit verbundenen, \u00fcberbetonten Rolle des Instruments \nder individuellen informierten Einwilligung zur Datennut-\nzung ergeben.\nDas geltende Datenschutzrecht ist auf die aktuellen Her -\nausforderungen von KI nicht optimal vorbereitet. Durch den \nFokus auf das initial datengebende Individuum werden syste-\nmische Risiken und Effekte auf andere Personen unzureichend \nber\u00fccksichtigt. Sogenannte relationale Sch\u00e4den, die durch die \nPreisgabe der Daten anderer erfolgen k\u00f6nnen, k\u00f6nnen oft \nnicht hinreichend erfasst werden, etwa in Bezug auf Gruppen-\nprivatsph\u00e4re oder auch Diskriminierung. Denn die angenom-\nmene enge Zweckbindung von Daten, die dieser Vorstellung \nzugrunde liegt, l\u00e4sst sich allenfalls f\u00fcr die Datennutzung der \nersten Instanz realisieren. Jede Weiterverwendung f\u00fchrt zu ei-\nner De- und Rekontextualisierung, zu der jeweils neue Zweck-\nsetzungen geh\u00f6ren. Die Kaskade der Weiterverwendungen \nf\u00fchrt dabei sehr schnell aus dem \u00dcbersichtsbereich der Per -\nson, von der die Daten stammen, heraus. Zudem erschwert die \nstark auf das Individuum enggef\u00fchrte Perspektive, dass syste-\nmatische Chancen von Datennutzungen nicht bzw. unzurei-\nchend genutzt werden.\nDas weiterhin datenschutzrechtlich zentrale Instrument \nder informierten Einwilligung, das sich aus der individualis-\ntischen Perspektive auf Datennutzung ergibt, f\u00fchrt wiederum \nin verschiedenen Kontexten ins Leere bzw. in die praktische 363Dysfunktionalit\u00e4t: Insbesondere bei den beschriebenen Bei-\nspielen des Datentrackings im Bereich des medizinischen \nOnlineverhaltens, zum Beispiel bei Gesundheits-Apps oder in \nsozialen Medien allgemein, kann regelm\u00e4\u00dfig weder von Infor -\nmiertheit noch von einer Einwilligung der Personen, die diese \nAngebote verwenden, ausgegangen werden. Dies hat sich auch \nim Gefolge der Einf\u00fchrung der Datenschutz-Grundverord-\nnung nicht ver\u00e4ndert; die entsprechenden Details der Einwil-\nligungserkl\u00e4rungen werden bekannterma\u00dfen oft nicht gelesen \nbzw. nicht inhaltlich wahrgenommen. Dort wiederum, wo \nexplizite informierte Einwilligungsformate unabdingbar und \nauch breit in der Praxis eingef\u00fchrt sind \u2013 etwa im Bereich der \nmedizinischen Forschung \u2013, k\u00f6nnen sie offenkundig sinnvolle \nAnwendungen stark erschweren oder verunm\u00f6glichen, weil \nsie, dem Primat der individuell orientierten engen Zweckbin-\ndung folgend, alle weiteren Datennutzungen verunm\u00f6glichen \noder jedenfalls so ausgelegt werden. So wird etwa gerade in der \n\u00f6ffentlich gef\u00f6rderten universit\u00e4ren Forschung durch eine re-\nstriktive Auslegungspraxis mit Blick auf Zweckbindung und \ninformierte Einwilligungsformate die Sekund\u00e4rnutzung von \nPatientendaten stark erschwert, selbst wenn Patientinnen und \nPatienten initial in eine intensive Nutzung ihrer Daten einge-\nwilligt haben; der Spielraum, den die Datenschutz-Grundver -\nordnung hier bietet, wird oft nicht genutzt.\nDabei, so hat es der Deutsche Ethikrat bereits 2017 in sei-\nner Stellungnahme zu Big Data und Gesundheit unterstri-\nchen, sind aus ethischer Sicht nicht nur Pr\u00e4ferenzen der in-\ndividuellen Binnensph\u00e4re, sondern auch Gesichtspunkte der \nSolidarit\u00e4t im Umgang mit Datensammlung und -nutzung zu \nbedenken, die eine besondere Aktualit\u00e4t bei KI-Anwendungen \nerlangen. In der g\u00e4ngigen Metapher gesprochen, sind Daten \ngrunds\u00e4tzlich ein wertvoller Rohstoff, den die einzelne Person \nunter bestimmten Umst\u00e4nden dem Gemeinwesen zur Verf\u00fc-\ngung stellen sollte. Die Einordnung von Daten als potenziel-\nles Gemeingut steht nicht in striktem Widerspruch zum in-\ndividuellen Anspruch auf Schutz der Privatsph\u00e4re. Vielmehr 364widerstreitet sie dessen Absolutsetzung und pauschaler Vor -\nrangstellung und verweist darauf, dass beide Vorgaben \u2013 kon-\ntextspezifisch \u2013 in einen angemessenen Ausgleich zu bringen \nsind. Daher sollte die M\u00f6glichkeit bestehen, dass individuelle \nAkteure selbstbestimmt Daten im Interesse der Allgemeinheit \nzur Verf\u00fcgung zu stellen, beispielsweise f\u00fcr die medizinbezo-\ngene Grundlagenforschung. Dem entspricht der Fokus im uni-\nonalen Data Governance Act auf \u201eDatenaltruismus\u201c.\nDiese Spannungen sind wohlbekannt im Bereich der Me-\ndizin. Dort ist das Ungleichgewicht zwischen \u2013 vereinfacht \ngesprochen \u2013 \u201eTrackingwildwuchs\u201c etwa im App-Bereich auf \nder einen Seite und sehr restriktiver Praxis mit Blick auf kli-\nnische Sekund\u00e4rnutzung von Daten f\u00fcr sinnvolle \u00f6ffentliche \nund gemeinwohlorientierte Forschung auf der anderen Seite \nbesonders ausgepr\u00e4gt sowie bekannt.432 Sie haben aber ebenso \nstarke Relevanz in den anderen Anwendungsfeldern. Offen-\nkundig ist dies auch bei datenintensiven Anwendungen in der \nschulischen Bildung der Fall, wo der Schutz der Privatsph\u00e4re \nsowohl von Lernenden als auch von Lehrkr\u00e4ften essenziell ist \nund immer gew\u00e4hrleistet sein muss, etwa durch entsprechende \ntechnische Voreinstellungen (Privacy by Design). Gleichwohl \nist auch hier offenkundig, dass sich aus einer st\u00e4rker gemein-\nwohlorientierten Perspektive vielf\u00e4ltige wichtige Nutzungen \nf\u00fcr derart gesammelte Daten ableiten lassen. So etwa w\u00e4re die \nverantwortliche Auswertung von Daten aus Tutorsystemen ge-\neignet, um Indikatoren f\u00fcr edukatorische Ungleichheiten oder \nNachteile im Bildungssystem f\u00fcr bestimmte Gruppen von Ler -\nnenden systematischer, schneller und vorausschauender zu er -\nfassen und solche Probleme zielgenauer anzugehen. \u00c4hnliche \nKonstellationen ergeben sich auch in der \u00f6ffentlichen Verwal-\ntung. Dort kann eine pr\u00e4zisere und st\u00e4rker vorausschauende \nErfassung etwa von Risikofaktoren f\u00fcr eine Kindeswohlge-\nf\u00e4hrdung oder in der Bew\u00e4hrungshilfe wichtigen individuellen \n432\tSachverst\u00e4ndigenrat\tzur\tBegutachtung\tder\tEntwicklung\tim\tGesundheits -\nwesen\t2021.365und gesellschaftlichen Zielen dienen. Zugleich erfordert dies \nden hohen Schutz der Privatsph\u00e4re aller Betroffenen, um un-\nzul\u00e4ssige Vorverurteilungen oder Stigmatisierungen zu ver -\nmeiden. Zusammenfassend scheinen sowohl die rechtlichen \nRahmenbedingungen als auch die konkrete Anwendungspra-\nxis in bestimmten Bereichen, insbesondere in den f\u00fcr die \u00f6f-\nfentliche Kommunikation und Meinungsbildung so zentralen \nsozialen Medien und der zugrundeliegenden Daten\u00f6kono-\nmie, nicht nur die Privatsph\u00e4re der Nutzenden unzureichend \nzu sch\u00fctzen. Auch eine m\u00f6gliche Datensouver\u00e4nit\u00e4t wird ad \nabsurdum gef\u00fchrt, da vielfach weder das Kriterium der Infor -\nmiertheit noch jenes der Einwilligung gew\u00e4hrleistet ist. Dies \ngilt vielfach auch f\u00fcr das Datensammeln und -verarbeiten im \nHintergrund kommerzieller Technologien, die im Bildungs-\nwesen, der \u00f6ffentlichen Verwaltung und im Medizinbereich \neingesetzt werden.\nDemgegen\u00fcber werden wichtige Chancen insbesondere im \nBereich der \u00f6ffentlichen Forschung durch eine teils \u00fcberm\u00e4-\n\u00dfig rigide Datenschutzpraxis vergeben, die etwa Fortschrit-\nten bei der Bildungsgerechtigkeit, der Fr\u00fcherkennung von \nErkrankungen oder der fl\u00e4chendeckenden Vermeidung von \nMedikamentenverschreibungsfehlern entgegensteht sowie op-\ntimierter und zugleich ma\u00dfvoller und verantwortlicher Risiko-\nabsch\u00e4tzung im Sozialwesen zuwiderl\u00e4uft.\nEmpfehlung\n>> Empfehlung Querschnittsthema 6: Mit Blick auf KI-An-\nwendungen m\u00fcssen neue Wege gefunden werden, um in-\nnerhalb der jeweiligen Kontexte und bez\u00fcglich der jeweils \nspezifischen Herausforderungen und Nutzenpotenziale \ndie gemeinwohlorientierte Daten(sekund\u00e4r)nutzung zu \nvereinfachen bzw. zu erm\u00f6glichen und damit die Hand-\nlungsoptionen auf diesem Gebiet zu erweitern. Zugleich ist \nes essenziell, einen Bewusstseinswandel sowohl in der \u00d6f-\nfentlichkeit als auch bei den praktisch t\u00e4tigen Personen, die \nDatennutzung gestalten, herbeizuf\u00fchren \u2013 weg von einer 366vornehmlich individualistisch gepr\u00e4gten und damit ver -\nk\u00fcrzten Perspektive hin zu einer Haltung, die auch syste-\nmatische und gemeinwohlbasierte \u00dcberlegungen mit ein-\nbezieht und in einen Ausgleich bringt. Eine solche Haltung \nist auch f\u00fcr die zuk\u00fcnftige Politikgestaltung und Regulie-\nrung deutlich st\u00e4rker als bisher zugrunde zu legen. Nur so \nkann es gelingen, neben den Risiken, die sich aus breiterer \nKI-Anwendung ohne Zweifel ergeben, zugleich die wich-\ntigen Chancen einer verantwortlichen Nutzung nicht aus \ndem Blick zu verlieren.\n10.7\t Querschnittsthema\t7:\tKritische\t\nInfrastrukturen,\tAbh\u00e4ngigkeiten\t\nund\u00a0Resilienz\nInfrastrukturen sind zentrale Elemente moderner Gesellschaf-\nten, die f\u00fcr das Funktionieren gesellschaftlicher Teilbereiche \nessenziell sind und deren Ausfall mit gro\u00dfen gesamtwirt-\nschaftlichen Sch\u00e4den verbunden ist. Im Zuge der Digitalisie-\nrung werden Infrastrukturen wie beispielsweise Stromnetze \nzunehmend digital \u00fcberwacht und \u00fcber das Internet gesteuert. \nAuf der anderen Seite werden digitale Technologien selbst zu \nInfrastrukturen. Dies gilt insbesondere f\u00fcr digitale Medien im \nKontext der \u00f6ffentlichen Kommunikation und Meinungsbil-\ndung: Kommerzielle Plattformen stellen hier zunehmend Inf-\nrastrukturen f\u00fcr den \u00f6ffentlichen Diskurs dar.\nIm Kontext von \u00f6ffentlicher Verwaltung und Bildung, aber \nauch in Teilen der Medizin, stellt sich die infrastrukturelle \nBedeutung digitaler Technologien teilweise \u00e4hnlich, teilweise \nsehr unterschiedlich dar. Die Gemeinsamkeit besteht darin, \ndass es in Teilen dieselben Unternehmen sind, die nicht nur \ndie gro\u00dfen Plattformen betreiben, sondern auch Technologi-\nen f\u00fcr die Bereiche \u00f6ffentliche Verwaltung, Bildung und Me-\ndizin anbieten. Der Unterscheid besteht darin, dass sich die \nVulnerabilit\u00e4t der \u00f6ffentlichen Verwaltung und Schulen und 367teilweise auch der medizinischen Versorgung beispielsweise in \nder Coronapandemie gerade in einer unzureichenden Digita-\nlisierung gezeigt hat.\nDiese doppelte infrastrukturelle Bedeutung digitaler Tech-\nnologien gilt es also zu ber\u00fccksichtigen und unter ethischen \nAspekten zu beleuchten. Hier ist auf folgende m\u00f6gliche Prob-\nlembereiche hinzuweisen:\nW\u00e4hrend Infrastrukturen von Menschen aufgebaut wer -\nden, um bestimmten Zwecken zu dienen, Menschen also die \nSysteme gestalten, hat der infrastrukturelle Charakter zur Fol-\nge, dass sich dieses Verh\u00e4ltnis allm\u00e4hlich verschiebt. Denn am \nVorhandensein und Funktionieren der betreffenden Infra-\nstruktur richten Menschen ihr Handeln aus. Im Zuge dieser \nsozialen Aneignung einer Infrastruktur entstehen Abh\u00e4ngig-\nkeiten, die die menschliche Autonomie gef\u00e4hrden k\u00f6nnen. \nDies zeigt sich beispielsweise im Kontext der \u00dcbernahme von \nTwitter durch Elon Musk. Dabei wurde deutlich, dass es keine \nvergleichbaren Alternativen gibt, auf welche im Falle grund-\nlegender \u00c4nderungen der Gesch\u00e4ftsmodelle oder Moderati-\nonspraktiken ausgewichen werden k\u00f6nnte, ohne dass zentrale \nAspekte der Plattformnutzung wegfallen w\u00fcrden.433\nDie vorstehend geschilderte Problematik gilt f\u00fcr Infra-\nstrukturen generell und ist nicht spezifisch auf KI bezogen. \nWenn jedoch KI-gest\u00fctzte ADM-Systeme zusehends in die \nSteuerung der Infrastrukturen integriert werden, kommt eine \nneue Form von Abh\u00e4ngigkeit hinzu. KI-Systeme sind nicht \nvollst\u00e4ndig transparent und nachvollziehbar. Die infrastruk-\nturelle Abh\u00e4ngigkeit w\u00fcrde also auch die Abh\u00e4ngigkeit von \nSystemen beinhalten, die zumindest zum Teil Blackboxes sind \n(vgl. Abschnitt 10.10). Im Zusammenhang mit dem Ph\u00e4nomen \nmenschlicher Gew\u00f6hnung an entsprechende Systeme kann es \nzur Verfestigung von Verhaltensmustern in soziotechnischen \n433\tZwar\tmigrieren\tderzeit\tviele\tTwitter-Nutzerinnen\tund\t-Nutzer\tzu\tanderen\t\nServices\twie\tbeispielsweise\tMastodon.\tDeren\tFunktionalit\u00e4t\tund\tReichwei-\nte\tsind\tjedoch\tnicht\tmit\tTwitter\tdeckungsgleich.368Konstellationen kommen, die eine kritische Reflexion und \nein Hinterfragen der teils intransparenten ADM-Systeme er -\nschweren k\u00f6nnen. Durch solche Pfadabh\u00e4ngigkeiten (vgl. \nAbschnitt 10.8) wird eine Eigendynamik eingeleitet, die den \nWechsel auf andere Formen erschwert oder unm\u00f6glich macht \nund damit Optionen verbaut. Auch hier kann Twitter zur Il-\nlustration dienen: Sein Mehrwert besteht gerade in der Inter -\naktion mit anderen Nutzenden; durch einen Wechsel auf ein \nanderes, gegebenenfalls dezentrales Medium wie Mastodon \ngeht ein Teil des Nutzens jedoch verloren. Solche sogenannten \nNetzwerkeffekte erschweren den Wechsel zwischen Plattfor -\nmen und erh\u00f6hen die Abh\u00e4ngigkeiten.\nDie Abh\u00e4ngigkeit vom Funktionieren der digitalen Systeme \nbetrifft l\u00e4ngst nicht mehr nur die Informations- und Kommu-\nnikationsinfrastruktur. Dadurch, dass mittlerweile viele Inf-\nrastrukturen digitalisiert sind und \u00fcber das Internet gesteuert \nwerden, sind sie mit dem Internet als Quasi-Nervensystem zu \neiner Mega-Infrastruktur verbunden. Hackerangriffe, techni-\nsches Systemversagen oder soziotechnische Systemrisiken k\u00f6n-\nnen auf diese Weise erheblich gr\u00f6\u00dfere Reichweite haben als in \nseparierten Infrastrukturen. Durch die fortw\u00e4hrende Komple-\nxit\u00e4tssteigerung der Infrastruktursysteme und ihre Steuerung \nsteigt die gesellschaftliche und institutionelle Vulnerabilit\u00e4t \nweiter an. Demgegen\u00fcber ist die allgemeine Erfahrung, dass die \nInfrastrukturen zuverl\u00e4ssig funktionieren und St\u00f6rungen vor\u00fc-\nbergehend sind. Dieses Funktionieren, so etwa die hohe Zuver -\nl\u00e4ssigkeit der Stromversorgung und des Internets in westlichen \nL\u00e4ndern, kann blind f\u00fcr die zunehmende Abh\u00e4ngigkeit von di-\ngitaler Technik machen. Schwere Wirtschaftskrisen, technische \nSystemeffekte, ein Kollaps der staatlichen Ordnung oder Ha-\ncker-Angriffe sind jedoch nicht unm\u00f6glich. Ethisches Vorsor -\ngedenken gebietet, solche Abh\u00e4ngigkeiten zumindest bewusst \nzu machen und Strategien f\u00fcr digitale Blackouts zu entwickeln. \nDies gilt umso mehr f\u00fcr intransparente, KI-getriebene Systeme, \nin denen sowohl Fehler als auch Angriffe noch schwerer zu ent-\ndecken und nachzuweisen sind.369Empfehlung\n>> Empfehlung Querschnittsthema 7: Um die Autorschaft \nmenschlicher Akteure und deren Handlungsm\u00f6glichkeiten \nzu erweitern, m\u00fcssen die Resilienz soziotechnischer Infra-\nstrukturen gest\u00e4rkt und die Abh\u00e4ngigkeit von individuellen \nAkteuren und Systemen minimiert werden. Dies umfasst \nzun\u00e4chst die Notwendigkeit, die infrastrukturelle Bedeu-\ntung digitaler Technologien anzuerkennen und infolgedes-\nsen dem Schutz und der Resilienz kritischer digitaler Infra-\nstrukturen mehr Aufmerksamkeit zuteilwerden zu lassen, \nauch im politischen Handeln. In allen Sektoren gilt es, ein-\nseitige Abh\u00e4ngigkeiten zu vermeiden, welche im Krisenfal-\nle verletzlich und angreifbar machen. F\u00fcr Nutzerinnen und \nNutzer erfordert eine Verringerung der Abh\u00e4ngigkeit die \nM\u00f6glichkeit, zwischen Alternativen zu w\u00e4hlen, ohne gro-\n\u00dfe Teile der Funktionalit\u00e4t einzub\u00fc\u00dfen. Dies umfasst die \nNotwendigkeit von Interoperabilit\u00e4t, um einfach zwischen \nSystemen wechseln zu k\u00f6nnen. Hierf\u00fcr ist auch der Auf- \nund Ausbau alternativer Infrastrukturen von besonderer \nBedeutung. Im Kontext der \u00f6ffentlichen Meinungsbildung \nerscheint die Etablierung unabh\u00e4ngiger, \u00f6ffentlicher digi-\ntal-kommunikativer Plattformen dringend geboten. Aber \nauch in anderen Sektoren wie der Verwaltung, der Bildung \noder der Medizin vermindert eine zu gro\u00dfe Abh\u00e4ngigkeit \nvon wenigen Systemen oder Akteuren potenziell die indi-\nviduelle wie kollektive Handlungsf\u00e4higkeit.\n10.8\t Querschnittsthema\t8:\t\nPfadabh\u00e4ngigkeiten,\t\nZweitverwertung\tund\t\nMissbrauchsgefahren\nEine wichtige und oft vernachl\u00e4ssigte Rolle bei der Entwick-\nlung und Nutzung von Technologien sind Pfadabh\u00e4ngig-\nkeiten. Entscheidungen, die zu Beginn einer bestimmten 370Entwicklung getroffen wurden, k\u00f6nnen noch lange nachwir -\nken und sind teils schwer wieder aufzuheben, auch wenn sich \nder Kontext der Nutzung m\u00f6glicherweise ge\u00e4ndert hat. Dies \ngilt insbesondere dann, wenn es sich hierbei um grundlegende \nTechnologien handelt, die Infrastrukturen pr\u00e4gen, welche in \nkomplexe soziotechnische Zusammenh\u00e4nge eingebettet sind, \noder aber es durch die Nutzung bereits zu Gew\u00f6hnungseffek-\nten gekommen ist. Von besonderer Relevanz f\u00fcr Infrastruktu-\nren sind hier die Festlegungen von Normen und Standards, die \nzuk\u00fcnftige Entwicklungsm\u00f6glichkeiten begrenzen. Man den-\nke hier etwa an standardisierte Stecker und Steckdosen, deren \naktuelle Form nicht notwendigerweise besser oder schlechter \nals Alternativen sind, deren \u00c4nderung aber mit hohen Kosten \nverbunden w\u00e4re. Ein klassisches Beispiel f\u00fcr Pfadabh\u00e4ngigkei-\nten und Beharrungstendenzen durch Gew\u00f6hnungseffekte ist \nauch die Anordnung der Buchstaben auf Tastaturen. Die heute \nnoch weit verbreitete QWERTY/QWERTZ-Tastaturbelegung \nwurde f\u00fcr mechanische Schreibmaschinen entwickelt, um die \nam h\u00e4ufigsten vorkommenden Buchstabenfolgen r\u00e4umlich \naufzuteilen, damit sich die mechanischen Typenhebel dieser \nBuchstaben weniger verhaken. Dass diese vergleichsweise we-\nnig ergonomische Anordnung weiter Bestand hat, liegt an der \nGew\u00f6hnung durch die Nutzenden.\nEine Konsequenz aus dieser Beobachtung lautet, dass \ngrundlegenden Entscheidungen bei der Gestaltung von Inf-\nrastrukturen und dem Festsetzen von Standards und Normen \neine hohe Aufmerksamkeit zukommen sollte. F\u00fcr digitale \nTechnologien, die zunehmend den Status kritischer Infra-\nstrukturen annehmen, gilt dies umso mehr. F\u00fcr Technologi-\nen, die entweder \u00fcber einen weiten Verbreitungsgrad verf\u00fc-\ngen und/oder eine infrastrukturelle Dimension haben, k\u00f6nnte \nes zunehmend schwer und kostspielig werden, \u00c4nderungen \neinzufordern. Das Vorhandensein von Technologien und In-\nfrastrukturen kann zudem selbst auch Erwartungen hinsicht-\nlich der Verf\u00fcgbarkeit und m\u00f6glichst umf\u00e4nglicher Nutzung \nwecken. Gerade bei kostspieligen Technologien d\u00fcrfte eine 371Tendenz auszumachen sein, deren M\u00f6glichkeiten voll aus-\nzusch\u00f6pfen \u2013 auch \u00fcber das urspr\u00fcngliche Anwendungsfeld \nhinaus.\nEine \u201eVerf\u00fchrung\u201c, technologische M\u00f6glichkeiten auch zu \nanderen Zwecken als zun\u00e4chst intendiert zu nutzen, ist nicht \nprinzipiell problematisch. Mit dem Computer als Universal-\nmaschine zeichnen sich digitale Technologien in der Regel \ndurch vielf\u00e4ltige Einsatzszenarien aus. Dennoch \u00f6ffnet dies \nauch die T\u00fcr f\u00fcr fremdn\u00fctzigen Gebrauch oder Missbrauch. \nSo wurden im Kontext der Coronapandemie weltweit sehr \nunterschiedliche Contact-Tracing-Apps entwickelt. W\u00e4hrend \nin Deutschland auf ein dezentrales Modell gesetzt wurde, um \nm\u00f6glichen Missbrauch bereits technisch zu verhindern, gab es \naus anderen L\u00e4ndern Hinweise auf Zweckentfremdung.434\nSobald eine Technologie etabliert ist, kann es schwer \nsein, weitere, auch missbr\u00e4uchliche Nutzungsszenarien aus-\nzuschlie\u00dfen. Diese Tendenz wird oft auch mit dem Potenzi-\nal des sogenannten Dual Use beschrieben. Der Begriff wurde \nurspr\u00fcnglich daf\u00fcr verwendet anzuzeigen, dass Technologien \nsowohl f\u00fcr zivile als auch milit\u00e4rische Zwecke genutzt werden \nk\u00f6nnen. Mittlerweile wird der Begriff aber breiter verwendet, \num darauf zu verweisen, dass Technologien oder Forschungs-\nergebnisse sowohl f\u00fcr friedliche und n\u00fctzliche Zwecke als auch \nzur absichtlichen Sch\u00e4digung von Gesellschaft oder Umwelt, \nbeispielsweise in krimineller oder terroristischer Absicht, ein-\ngesetzt werden k\u00f6nnen.435 In den letzten Jahren sind digitale \nTechnologien im Allgemeinen und KI im Besonderen zuneh-\nmend unter dem Blickwinkel von Dual Use beleuchtet worden. \nDabei zeigt sich, dass die Konzeption von Dual Use hier um \nweitere Komplexit\u00e4tsstufen erg\u00e4nzt werden sollte, da digitale \n434\tSo\twurden\tContact-Tracing-Apps,\twelche\tzur\tNachverfolgung\tvon\tCOVID-19 \t\nentwickelt\twurden,\tzum\tBeispiel\tauch\tzur\tUnterst\u00fctzung\tpolizeilicher \t\nErmittlungen\tin\tSingapur\therangezogen\t(https://www.theguardian.com/\nworld/2021/jan/05/singapore-says-police-will-be-given-access-to-covid-\n19-contact-tracing-data\t[01.02.2023]).\n435\tDeutscher\tEthikrat\t2014;\tsiehe\tauch\thttps://www.sicherheitsrelevante-\nforschung.org\t[01.02.2023].372Technologien und insbesondere Grundlagentechnologien wie \ndas maschinelle Lernen, oft sehr mannigfaltige Nutzungsm\u00f6g-\nlichkeiten er\u00f6ffnen, in denen die Frage der Abgrenzung von \nGe- und Missbrauch zunehmend schwieriger wird.\nEmpfehlung\n>> Empfehlung Querschnittsthema 8: Bei Technologien mit \ngro\u00dfen Auswirkungen oder hohem Verbreitungsgrad und \nvor allem dort, wo sich eine Nutzung von Technologien \nkaum oder gar nicht vermeiden l\u00e4sst, m\u00fcssen bereits zu \nBeginn der Entwicklungsplanung m\u00f6gliche Langzeitfolgen \nwie Pfadabh\u00e4ngigkeiten im Allgemeinen sowie Dual-Use-\nPotenziale im Speziellen regelhaft und explizit mitgedacht \nund antizipiert werden. Dies gilt in besonderem Ma\u00dfe in \nder Anwendungsplanung. Dabei sind neben direkten, \nsektorspezifischen Schadenspotenzialen auch etwaige \u2013 \nnat\u00fcrlich deutlich schwieriger fass- und antizipierbare \n\u2013 sektor\u00fcbergreifende Effekte zu bedenken. Hohe Stan-\ndards f\u00fcr die Sicherheit und den Schutz der Privatsph\u00e4re \n(Security by Design, Privacy by Design) k\u00f6nnen ebenfalls \ndazu beitragen, sp\u00e4tere missbr\u00e4uchliche Anwendungen \neinzuhegen bzw. m\u00f6glichst zu verhindern. Bei besonders \ninvasiven Technologien beispielsweise in der \u00f6ffentlichen \nVerwaltung, die B\u00fcrgerinnen und B\u00fcrger gegebenenfalls \nverpflichtend nutzen m\u00fcssen, sind besonders hohe Stan-\ndards einzuhalten. Um dies sicherzustellen und \u00fcberpr\u00fc-\nfen zu k\u00f6nnen, sind gegebenenfalls Open-Source-Ans\u00e4tze \nangezeigt.\n10.9\t Querschnittsthema\t9:\tBias\tund\t\nDiskriminierung\nDatenbasierte KI-Systeme lernen auf Basis vorhandener Da-\nten. Resultierende Prognosen und Empfehlungen schrei-\nben somit die Vergangenheit in die Zukunft fort, wodurch 373Stereotype, aber auch bestehende gesellschaftliche Ungerech-\ntigkeiten durch den Einbau in scheinbar neutrale Techno-\nlogien reproduziert und sogar verst\u00e4rkt werden k\u00f6nnen. In \nden letzten Jahren wurden die teils diskriminierenden Effek-\nte insbesondere datenbasierter Technologien zur Entschei-\ndungsunterst\u00fctzung in zahlreichen Sektoren nachgewiesen. \nF\u00fcr den Bereich der \u00f6ffentlichen Verwaltung sei hier exem-\nplarisch auf die Debatten rund um die Software COMPAS \nhingewiesen (vgl. Abschnitt 8.3.1). Auch im Kontext der f\u00fcr \n\u00f6ffentliche Kommunikation und Meinungsbildung zentralen \nsozialen Medien und Suchmaschinen konnte gezeigt werden, \ndass algorithmische Systeme gesellschaftliche Stereotype und \nUngerechtigkeiten reproduzieren k\u00f6nnen und dies in syste-\nmatischen diskriminierenden Verzerrungen resultieren kann. \nIn der Medizin wiederum gibt es zahlreiche Beispiele, dass \nverzerrte Trainingsdaten zu diskriminierenden Ergebnissen \nbei der Beurteilung von Patientinnen und Patienten durch KI-\nbasierte Systeme f\u00fchren k\u00f6nnen, so etwa bei der Einsch\u00e4tzung, \nwie viel Nachsorgebehandlungen Menschen nach einem Kran-\nkenhausaufenthalt ben\u00f6tigen \u2013 so wurde in diesem Fall die \nvorhandene Verzerrung in den Trainingsdaten in eine direkte \nBenachteiligung bestimmter Personengruppen \u00fcbersetzt.436 \nAuch im Bildungsbereich k\u00f6nnen systematische Verzerrun-\ngen nachgewiesen werden, insbesondere im Kontext von \nAudio- und Videoanalysen zum Zweck der Emotions- und \nAffekterkennung.\nDie Ursachen f\u00fcr Diskriminierung durch KI-Systeme \nsind vielf\u00e4ltig. Oft liegt bei deren Entwicklung keine unmit-\ntelbare Diskriminierungsabsicht vor. Stattdessen sind diskri-\nminierende Effekte das Resultat gesellschaftlicher Realit\u00e4ten \noder Stereotype in Kombination mit technisch-methodischen \nEntscheidungen wie beispielsweise der Wahl der Zielvari-\nablen und Labels, der Auswahl der Trainingsdaten oder der \nverwendeten statistischen Analysemethoden. Dies erschwert \n436\tObermeyer\tet\tal.\t2019.374einerseits die Anwendung rechtlicher Regulierungen, die auf \nVors\u00e4tzlichkeit von Diskriminierung bauen. Andererseits be-\ndarf es detaillierter Analysen der methodisch-technischen Ur -\nsachen f\u00fcr diskriminierende Effekte, die h\u00e4ufig schwierig zu \nerkennen und nachzuweisen sind.\nVon besonderer Bedeutung sind hier Trainingsdaten. \nMangelnde Qualit\u00e4t, aber auch existierende gesellschaftliche \nUngleichheiten, die sich in Daten widerspiegeln, k\u00f6nnen zu \ndiskriminierenden Modellen f\u00fchren. \u00dcber- und Unterrepr\u00e4-\nsentativit\u00e4t sind weitere Probleme, die diskriminierende Ef-\nfekte haben k\u00f6nnen. Wenn Software im Bereich der Medizin \nzur Diagnostik von Hautkrebs vor allem auf Bildern mit heller \nHaut trainiert wurde, kann dies zu unterschiedlicher Genauig-\nkeit bei der Befundung von verschiedenen Hautfarben f\u00fchren. \nDie Folge w\u00e4ren beispielsweise \u00fcberproportional h\u00e4ufigere \nFehldiagnosen f\u00fcr Patientinnen und Patienten mit dunklerer \nHautfarbe.\nDas Gegenteil dieser mangelnden Ber\u00fccksichtigung von \nPersonengruppen in Datens\u00e4tzen ist die \u00dcberrepr\u00e4sentativit\u00e4t. \nEin Beispiel ist der Einsatz von Software zur Vorhersage von \nStraftaten im Kontext von pr\u00e4diktiver Polizeiarbeit. Falls eine \nSoftware eine bestimmte Gegend aufgrund bisheriger Strafta-\nten als Hochrisikozone kategorisiert, werden dort gegebenen-\nfalls in der Folge Polizeikontrollen verst\u00e4rkt. Gerade aufgrund \nder erh\u00f6hten Kontrolle k\u00f6nnen dort dann noch mehr Strafta-\nten verzeichnet werden. Im Gegenzug bleiben gegebenenfalls \nStraftaten in Niedrigrisikozonen aufgrund ausbleibender Kon-\ntrollen unerkannt. Durch beide Effekte kann sich die Daten-\nlage weiter zuungunsten der Bewohnerschaft einer Hochrisi-\nkozone verschieben \u2013 n\u00e4mlich f\u00fcr jene, die durch verst\u00e4rkte \nKontrollen unter Umst\u00e4nden ungerechtfertigt stigmatisiert \nwerden.\nDar\u00fcber hinaus besteht das Problem der sogenannten red-\nundanten Encodierung: Sensible Attribute wie beispielsweise \nGeschlecht, religi\u00f6se Zugeh\u00f6rigkeit oder sexuelle Orientie-\nrung lassen sich teilweise aus anderen Datenpunkten, etwa 375Bewegungsprofilen, Details des Medienkonsums sowie An-\ngaben \u00fcber Wohnort oder Hobbys, ableiten. Dadurch k\u00f6nnen \ndiese Daten als sogenannte Proxy- bzw. Stellvertretervariab-\nlen f\u00fcr die gesch\u00fctzten Variablen fungieren. Das Resultat ist, \ndass Personen auch dann aufgrund ihres Geschlechts oder \nihrer sexuellen oder religi\u00f6sen Orientierung von der Software \ndiskriminiert werden k\u00f6nnen, wenn diese Angaben gar nicht \nerhoben wurden, eben weil diese Kategorien aus anderen er -\nhobenen Daten ableitbar sind.\nIn den zuvor genannten Beispielen ist Diskriminierung \nder Effekt von technisch-methodischen Entscheidungen, aber \nnicht notwendigerweise intendiert. Es ist allerdings zumin-\ndest denkbar, dass auch explizite Diskriminierungsabsichten \nin komplexen Systemen versteckt werden k\u00f6nnten. Dies gilt \numso mehr f\u00fcr propriet\u00e4re, das hei\u00dft rechtlich gesch\u00fctzte \nSoftware, in welche die Personen, die sie verwenden, nicht \nnur aufgrund von technischer Komplexit\u00e4t, sondern auch aus \nrechtlichen Gr\u00fcnden keine Einsicht haben.\nEmpfehlung\n>> Empfehlung Querschnittsthema 9: Zum Schutz vor Diskri-\nminierung in Anbetracht der zuvor dargelegten Herausfor -\nderungen bedarf es angemessener Aufsicht und Kontrolle von \nKI-Systemen. Besonders in sensiblen Bereichen erfordert \ndies den Auf- oder Ausbau gut ausgestatteter Institutionen. \nHier gilt: je gr\u00f6\u00dfer die Eingriffstiefe und je unumg\u00e4nglicher \ndie Systeme, desto h\u00f6her die Anforderungen an Diskrimi-\nnierungsminimierung. Auch bereits bei der Entwicklung \nvon Technologien gilt es, Diskriminierung zu minimieren \nbzw. Fairness, Transparenz und Nachvollziehbarkeit her -\nzustellen. Dies sollte sowohl durch Anreize \u2013 etwa For -\nschungsf\u00f6rderung \u2013 als auch durch entsprechende gesetz-\nliche Anforderungen bef\u00f6rdert werden, etwa hinsichtlich \nder Offenlegung, welche Ma\u00dfnahmen zur Diskriminie-\nrungsminimierung bei der Softwareentwicklung ergriffen 376wurden.437 Allerdings haben technische wie regulatorische \nMa\u00dfnahmen zur Minimierung von Diskriminierung ihre \nGrenzen, unter anderem weil unterschiedliche Fairness-\nziele technisch nicht gleichzeitig erf\u00fcllt werden k\u00f6nnen. Es \nm\u00fcssen also zugleich ethische und politische Entscheidun-\ngen getroffen werden, welche Kriterien f\u00fcr Gerechtigkeit \nin welchem Kontext zum Tragen kommen sollen. Diese \nEntscheidungen d\u00fcrfen nicht den Personen, die Software \nentwickeln, und anderen direkt Beteiligten \u00fcberlassen wer -\nden. Stattdessen bedarf es der Entwicklung geeigneter Ver -\nfahren und Institutionen, um diese Kriterien kontextspezi-\nfisch und demokratisch, gegebenenfalls immer wieder neu \nauszuhandeln. Je nach Anwendungskontext und Sensibi-\nlit\u00e4t des einzusetzenden Systems kann die Beteiligung der \n\u00d6ffentlichkeit erforderlich sein. Dabei sollte der Schutz der \njeweils bed\u00fcrftigsten bzw. von Entscheidungen besonders \nbetroffenen Gruppen besonders ber\u00fccksichtigt werden.\n10.10\tQuerschnittsthema\t10:\tTransparenz\t\nund\tNachvollziehbarkeit\t\u2013\tKontrolle\t\nund\tVerantwortung\nKI-Systeme sind mitunter wenig transparent und nachvoll-\nziehbar. Diese Opazit\u00e4t hat verschiedene Ursachen, die vom \nSchutz geistigen Eigentums \u00fcber die Komplexit\u00e4t und Nicht-\nnachvollziehbarkeit der Verfahren bis hin zur mangelnden \nDurchsichtigkeit von Entscheidungsstrukturen, in die der \nEinsatz algorithmischer Systeme eingebettet ist, reichen. \nAls Reaktion auf diese vielf\u00e4ltigen Herausforderungen gibt \nes Bem\u00fchungen, die Transparenz und Nachvollziehbarkeit \n437\tDer\tderzeit\tdiskutierte\tVorschlag\tder\tEurop\u00e4ischen\tKommission\tf\u00fcr\teinen\t\nArtificial\tIntelligence\tAct\tverfolgt\tbereits\tdiesen\tAnsatz,\tauf\tder\teinen\tSei-\nte\tdie\tForschung\tzu\tKI-Technologien\tzu\tf\u00f6rdern\tund\tauf\tder\tanderen,\teinen\t\nrechtlichen\tRahmen\tf\u00fcr\tihre\tEntwicklung\tund\tAnwendung\tzu\tschaffen.377durch technische, organisatorische und rechtliche Mittel zu \nerh\u00f6hen.438\nFragen von Transparenz, Erkl\u00e4rbarkeit und Nachvollzieh-\nbarkeit sind mit Fragen von Kontrolle und Verantwortung \nverbunden. Zwar besteht zwischen ihnen ein gewisser Zusam-\nmenhang, doch sind Transparenz und Nachvollziehbarkeit \nalgorithmischer Systeme f\u00fcr die Kontrolle und die Verant-\nwortung f\u00fcr ihren Einsatz weder zwingend notwendig noch \nhinreichend.\nEinerseits kann es auch bei prinzipiell transparenten und \nnachvollziehbaren Methoden wie zum Beispiel Entschei-\ndungsb\u00e4umen dazu kommen, dass verantwortliches Handeln \nund angemessene Kontrolle ausbleiben. Zudem ist in Bezug \nauf Offenlegungspraktiken auf das Problem strategischer \nTransparenz hinzuweisen. So k\u00f6nnten insbesondere im Be-\nreich der \u00f6ffentlichen Kommunikation und Meinungsbildung \nPlattformbetreiber entweder irrelevante und unzureichende \nInformationen transparent machen (z. B.in Bezug auf Prozes-\nse und Effekte von Content-Moderation) oder aber relevante \nInformationen unter einer F\u00fclle irrelevanter Information ver -\nbergen. In diesen F\u00e4llen w\u00fcrde Transparenz also nicht zwin-\ngend zu verantwortlichem Handeln und Kontrolle f\u00fchren.\nAndererseits sind Kontrolle und Verantwortung auch ohne \nvollst\u00e4ndige Transparenz m\u00f6glich. So kann bei der Nutzung \nvon Softwaresystemen, die auf Deep-Learning-Ans\u00e4tzen beru-\nhen, Herstellern oder Anwendern die volle Verantwortung f\u00fcr \nden Einsatz dieser Systeme zugewiesen werden, selbst wenn \nihnen die Details der Verarbeitung unbekannt sind. Sie tr\u00fc-\ngen dann die Verantwortung, derartige Systeme zum Einsatz \ngebracht zu haben, und m\u00fcssten begr\u00fcnden, warum diese In-\ntransparenz akzeptabel ist \u2013 etwa weil der m\u00f6gliche Schaden \ngering oder der zus\u00e4tzliche Nutzen dieser Systeme (z. B. in \n438\tSchlagworte\tdieser\tDebatte\tsind\tneben\tTransparenz\t(transparency)\t\ninsbesondere\tauch\tErkl\u00e4rbarkeit\t(explainability/explainable AI/explicability),\t\nBeobachtbarkeit\t(observability)\tund\tNachvollziehbarkeit\tsowie\tVerantwor -\ntung\tund\tHaftung\t(responsibility,\taccountability\tund\tliability).378Bezug auf eine h\u00f6here Genauigkeit der Prognosen) die Nach-\nteile der Intransparenz \u00fcberwiegt. So kann es einerseits sein, \ndass im medizinischen Kontext aus guten Gr\u00fcnden Software \nin der Krebsdiagnostik eingesetzt wird, deren Prognosen durch \ndiejenigen, die sie einsetzen, zwar nicht mehr nachvollziehbar \nerkl\u00e4rt werden k\u00f6nnen, deren h\u00f6here Genauigkeit jedoch die-\nsen Nachteil \u00fcberwiegt. Umgekehrt k\u00f6nnte in anderen Kon-\ntexten bzw. bei sensiblen Entscheidungen in der \u00f6ffentlichen \nVerwaltung die Notwendigkeit der vollst\u00e4ndig nachvollzieh-\nbaren Begr\u00fcndung von Entscheidungen dazu f\u00fchren, dass in-\ntransparente Systeme nicht eingesetzt werden d\u00fcrfen.\nAnforderungen an Transparenz, Erkl\u00e4rbarkeit und Nach-\nvollziehbarkeit sind dementsprechend in Abh\u00e4ngigkeit von \nden jeweiligen Zielen, die mit Transparenz und Nachvollzieh-\nbarkeit verfolgt werden, nach den Personen, die Informatio-\nnen erhalten, und nach dem jeweiligen Anwendungskontext \nzu konkretisieren. Eine Nutzerin, die Auskunft dar\u00fcber ver -\nlangt, warum sie keinen Kredit bekommen hat, bedarf einer \nanderen Art der Erkl\u00e4rung als eine Aufsichtsbeh\u00f6rde, die \npr\u00fcfen muss, ob eine Software in ihren Prognosen der Kre-\nditw\u00fcrdigkeit systematisch Frauen diskriminiert. Besonders \nhohe Anforderungen gelten f\u00fcr Systeme, die in hochsensib-\nlen Bereichen eingesetzt werden, beispielsweise bei Entschei-\ndungen mit hoher Tragweite f\u00fcr das Leben von Menschen. \nAuch dort, wo Systeme eine Quasi-Monopolstellung erlangen, \nsind hohe Anforderungen an Transparenz, Erkl\u00e4rbarkeit und \nNachvollziehbarkeit zu stellen, die m\u00f6glicherweise den Einsatz \nvon besonders intransparenten Systemen (z. B. basierend auf \nDeep Learning) ausschlie\u00dfen und nach nachvollziehbareren \nVerfahren verlangen (z. B. Entscheidungsb\u00e4ume). Bei der Ent-\nwicklung der Software wiederum m\u00fcssen technische und or -\nganisatorische Voraussetzungen geschaffen und eingefordert \nwerden, beispielsweise durch Dokumentations- und Offenle-\ngungspflichten, damit diese Erkl\u00e4rungen sp\u00e4ter \u00fcberhaupt erst \ngeliefert werden k\u00f6nnen.379Die Spezifizierung und ausgewogene Ausgestaltung von \nOffenlegungspflichten stellen eine besondere Herausforde-\nrung dar, muss doch sichergestellt werden, dass einerseits re-\nlevante Informationen geteilt werden, aber andererseits weder \ndie Gesch\u00e4ftsinteressen von Anbietern \u00fcber Geb\u00fchr untermi-\nniert noch Flanken f\u00fcr Angriffe und Sicherheitsl\u00fccken er\u00f6ff-\nnet werden.\nEmpfehlung\n>> Empfehlung Querschnittsthema 10: Es bedarf der Ent-\nwicklung ausgewogener aufgaben-, adressaten- und kon-\ntextspezifischer Standards f\u00fcr Transparenz, Erkl\u00e4rbarkeit \nund Nachvollziehbarkeit und ihrer Bedeutung f\u00fcr Kontrol-\nle und Verantwortung sowie f\u00fcr deren Umsetzung durch \nverbindliche technische und organisatorische Vorgaben. \nDabei muss den Anforderungen an Sicherheit und Schutz \nvor Missbrauch, Datenschutz sowie dem Schutz von intel-\nlektuellem Eigentum und Gesch\u00e4ftsgeheimnissen in ange-\nmessener Weise Rechnung getragen werden. Je nach Kon-\ntext sind hier unterschiedliche Zeitpunkte (ex ante, ex post, \nRealtime) sowie unterschiedliche Verfahren und Grade der \nOffenlegung zu spezifizieren.\n10.11\t Fazit\nIm Rahmen dieser Stellungnahme wurden die Auswirkungen \neiner zunehmenden Delegation menschlicher T\u00e4tigkeiten an \ndigitale Technologien, insbesondere KI-basierte Softwaresys-\nteme, analysiert. In zahlreichen Beispielen aus den Bereichen \nder Medizin, der schulischen Bildung, der \u00f6ffentlichen Kom-\nmunikation und Meinungsbildung sowie der \u00f6ffentlichen \nVerwaltung zeigte sich, dass dieses Delegieren sowohl mit \nErweiterungen als auch mit Verminderungen menschlicher \nHandlungsm\u00f6glichkeiten einhergeht und sich dadurch sowohl \nf\u00f6rderlich als auch hinderlich auf die Realisierung menschlicher 380Autorschaft auswirken kann. Eine Ber\u00fccksichtigung dieser \nAuswirkungen sollte daher jedweder Entscheidung \u00fcber eine \nDelegation menschlicher T\u00e4tigkeiten an Softwaresysteme \u2013 bis \nm\u00f6glicherweise hin zu einer vollst\u00e4ndigen Ersetzung des Men-\nschen durch algorithmische Systeme \u2013 vorausgehen.\nZiel und Richtschnur ethischer Bewertung muss hierbei \nimmer die Erh\u00f6hung menschlicher Autorschaft sein. Dabei \nist zu ber\u00fccksichtigen, dass die Erweiterung von Handlungs-\nm\u00f6glichkeiten f\u00fcr eine Personengruppe mit deren Verminde-\nrung f\u00fcr andere einhergehen kann. Diesen Unterschieden ist \nRechnung zu tragen, insbesondere im Hinblick auf den Schutz \nund die Verbesserung der Lebensbedingungen vulnerabler \noder benachteiligter Gruppen. Die hier vorgelegte Analyse hat \nzahlreiche \u00fcbergreifende Themen offengelegt, die in allen vier \nuntersuchten Sektoren aufscheinen \u2013 wenn auch nicht immer \nin gleicher Art und Weise. Letztlich zeigt sich, dass die nor -\nmativen Anspr\u00fcche an die Gestaltung und den Einsatz solcher \nTechnologien, beispielsweise in Bezug auf Anforderungen \nhinsichtlich Transparenz und Nachvollziehbarkeit, den Schutz \nder Privatsph\u00e4re sowie die Verhinderung von Diskriminie-\nrung, zwar in allen Bereichen und f\u00fcr alle Betroffenen von \nhoher Bedeutung sind, sie jedoch sektor -, kontext- und adres-\nsatenspezifisch konkretisiert werden m\u00fcssen, um angemessen \nzu sein und wirksam werden zu k\u00f6nnen.381LITERATURVERZEICHNIS\nAd\tHoc\tCommittee\ton\tArtificial\tIntelligence\t(2021):\tPossible\tElements\tof\ta\t\nLegal\tFramework\ton\tArtificial\tIntelligence,\tBased\ton\tthe\tCouncil\tof\tEurope\u2019s\t\nStandards\ton\tHuman\tRights,\tDemocracy\tand\tthe\tRule\tof\tLaw.\thttps://rm.coe.\nint/cahai-2021-09rev-elements/1680a6d90d\t[19.01.2023].\nAhmed,\tH.\tU.\tet\tal.\t(2017):\tDiagnostic\taccuracy\tof\tmulti-parametric\tMRI\tand\t\nTRUS\tbiopsy\tin\tprostate\tcancer\t(PROMIS):\ta\tpaired\tvalidating\tconfirmatory\t\nstudy.\tIn:\tThe\tLancet,\t389\t(10071),\t815\u2013822\t(DOI:\t10.1016/S0140-6736(16)32401-1).\nAlgorithmWatch\t(2020):\tAutomating\tSociety\tReport\t2020.\thttps://\nautomatingsociety.algorithmwatch.org/wp-content/uploads/2020/12/\nAutomating-Society-Report-2020.pdf\t[22.02.2023].\nAlgorithmWatch\t(2019):\tAutomating\tSociety.\tTaking\tStock\tof\tAutomated\t\nDecision-Making\tin\tthe\tEU.\thttps://algorithmwatch.org/en/wp-content/\nuploads/2019/02/Automating_Society_Report_2019.pdf\t[22.02.2023].\nAllem,\tJ.-P.\t(2020):\tSocial\tmedia\tfuels\twave\tof\tcoronavirus\tmisinformation\tas\t\nusers\tfocus\ton\tpopularity,\tnot\taccuracy.\tIn:\tThe\tConversation,\t06.04.2020.\t\nhttps://theconversation.com/social-media-fuels-wave-of-coronavirus-\nmisinformation-as-users-focus-on-popularity-not-accuracy-135179\t[12.01.2023].\nAllhutter,\tD.\tet\tal.\t(2020a):\tDer\tAMS-Algorithmus.\tEine\tSoziotechnische\t\nAnalyse\tdes\tArbeitsmarktchancen-Assistenz-Systems\t(AMAS).\thttps://epub.\noeaw.ac.at/ita/ita-projektberichte/2020-02.pdf\t[08.02.2023].\nAllhutter,\tD.\tet\tal.\t(2020b):\tAlgorithmic\tprofiling\tof\tjob\tseekers\tin\tAustria:\thow\t\nausterity\tpolitics\tare\tmade\teffective.\tIn:\tFrontiers\tin\tBig\tData,\t3,\tArt.-Nr.\t5\t(DOI:\t\n10.3389/fdata.2020.00005).\nAlston,\tJ.\t(2019):\tReport\tof\tthe\tSpecial\tRapporteur\ton\tExtreme\tPoverty\tand\t\nHuman\tRights.\tUN\tDoc.\tA/74/493.\thttps://undocs.org/A/74/493\t[22.02.2023].\nAlzoubi,\tD.\tet\tal.\t(2021):\tTeachActive\tfeedback\tdashboard:\tusing\tautomated\t\nclassroom\tanalytics\tto\tvisualize\tpedagogical\tstrategies\tat\ta\tglance.\tIn:\tCHI\u201921\t\nExtended\tAbstracts,\tArt.-Nr.\t312\t(DOI:\t10.1145/3411763.3451709).\nAndrews,\tD.\tA.;\tBonta,\tJ.\t(2010):\tThe\tPsychology\tof\tCriminal\tConduct.\t\nAbingdon.\nAneesh,\tA.\t(2009):\tGlobal\tlabor:\talgocratic\tmodes\tof\torganization.\tIn:\t\nSociological\tTheory,\t27\t(4),\t347\u2013370\t(DOI:\t10.1111/j.1467-9558.2009.01352.x).\nArnold,\tC.;\tG\u00fcnther,\tJ.\t(Hg.)\t(2022):\tArbeitsrecht\t4.0.\tPraxishandbuch\tzum\t\nArbeits-,\tIP-\tund\tDatenschutzrecht\tin\teiner\tdigitalisierten\tArbeitswelt\t\n(2.\u00a0Auflage).\tM\u00fcnchen.\nBainbridge,\tL.\t(1983):\tIronies\tof\tautomation.\tIn:\tAutomatica,\t19\t(6),\t775\u2013779\t\n(DOI:\t10.1016/0005-1098(83)90046-8).\nBakshy,\tE.;\tMessing,\tS.;\tAdamic,\tL.\tA.\t(2015):\tExposure\tto\tideologically\tdiverse\t\nnews\tand\topinion\ton\tFacebook.\tIn:\tScience,\t348\t(6239),\t1130\u20131132\t(DOI:\t10.1126/\nscience.aaa1160).\nBaltes,\tP.\tB.\t(1987):\tTheoretical\tpropositions\tof\tlife-span\tdevelopmental\t\npsychology:\ton\tthe\tdynamics\tbetween\tgrowth\tand\tdecline.\tIn:\tDevelopmental\t\nPsychology,\t23\t(5),\t611\u2013626\t(10.1037/0012-1649.23.5.611).382Baltzer,\tP.\tA.\tT.\t(2021):\tK\u00fcnstliche\tIntelligenz\tin\tder\tMammadiagnostik.\t\nAnwendungsgebiete\taus\tklinischer\tPerspektive.\tIn:\tDer\tRadiologe,\t61\t(2),\t\n192\u2013198\t(DOI:\t10.1007/s00117-020-00802-2).\nBarocas,\tS.;\tSelbst,\tA.\tD.\t(2016):\tBig\tdata\u2019s\tdisparate\timpact.\tIn:\tCalifornia\tLaw\t\nReview,\t104\t(3),\t671\u2013732\t(DOI:\t10.15779/Z38BG31).\nBastian,\tP.\t(2012):\tDie\t\u00dcberlegenheit\tstatistischer\tUrteilsbildung\tim\t\nKinderschutz.\tPl\u00e4doyer\tf\u00fcr\teinen\tPerspektivwechsel\thin\tzu\teiner\tangemessenen\t\nForm\tsozialp\u00e4dagogischer\tDiagnosen.\tIn:\tMarthaler,\tT.\tet\tal.\t(Hg.):\t\nRationalit\u00e4ten\tdes\tKinderschutzes.\tKindeswohl\tund\tsoziale\tInterventionen\taus\t\npluraler\tPerspektive.\tWiesbaden,\t249\u2013267.\nBastian,\tP.;\tFreres,\tK.;\tSchr\u00f6dter,\tM.\t(2017):\tRisiko\tund\tSicherheit\tals\t\nOrientierung\tim\tKinderschutz.\tDeutschland\tund\tUSA\tim\tVergleich.\tIn:\tSoziale\t\nPassagen,\t9\t(2),\t245\u2013261.\nBastian,\tP.\tet\tal.\t(2018):\tBauchgef\u00fchle\tin\tder\tSozialen\tArbeit.\tIn:\tKommission\t\nSozialp\u00e4dagogik\t(Hg.):\tWa(h)re\tGef\u00fchle?\tSozialp\u00e4dagogische\tEmotionsarbeit\tim\t\nwohlfahrtsstaatlichen\tKontext.\tWeinheim,\t128\u2013140.\nBeauchamp,\tT.\tL.;\tChildress,\tJ.\tF.\t(2001):\tPrinciples\tof\tBiomedical\tEthics.\tNew\t\nYork\t(NY).\nBeck,\tI.;\tGreving,\tH.\t(2012):\tLebenswelt,\tLebenslage.\tIn:\tdies.\t(Hg.):\tLebenslage\t\nund\tLebensbew\u00e4ltigung.\tStuttgart,\t15\u201359.\nBelpaeme,\tT.;\tTanaka,\tF.\t(2021):\tSocial\trobots\tas\teducators.\tIn:\tOECD\tDigital\t\nEducation\tOutlook\t2021.\tPushing\tthe\tFrontiers\twith\tArtificial\tIntelligence,\t\nBlockchain\tand\tRobots.\tParis,\t143\u2013158.\nBennett,\tM.\tet\tal.\t(2007):\tNeuroscience\tand\tPhilosophy.\tBrain,\tMind,\tand\t\nLanguage.\tNew\tYork\t(NY).\nBickle,\tJ.\t(2020):\tMultiple\trealizability.\tIn:\tStanford\tEncyclopedia\tof\tPhilosophy\t\n(Summer\t2020\tEdition).\thttps://plato.stanford.edu/archives/sum2020/entries/\nmultiple-realizability\t[04.01.2023].\nBijker,\tW.\tE.;\tHughes,\tT.\tP.;\tPinch,\tT.\tJ.\t(Hg.)\t(1987):\tThe\tSocial\tConstruction\t\nof\tTechnological\tSystems.\tNew\tDirections\tin\tthe\tSociology\tand\tHistory\tof\t\nTechnology.\tCambridge\t(MA).\nBinet,\tA.;\tSimon,\tT.\t(1905):\tM\u00e9thodes\tnouvelles\tpour\tle\tdiagnostic\tdu\tniveau\t\nintellectuel\tdes\tanormaux.\tIn:\tL\u2019Ann\u00e9e\tPsychologique,\t11,\t191\u2013244\t(DOI:\t\n10.3406/psy.1904.3675).\nBitkom\t(2017):\tK\u00fcnstliche\tIntelligenz.\tWirtschaftliche\tBedeutung,\t\ngesellschaftliche\tHerausforderungen,\tmenschliche\tVerantwortung.\thttps://\nwww.bitkom.org/sites/main/files/file/import/171012-KI-Gipfelpapier-online.pdf\t\n[07.02.2023].\nBlock,\tN.\t(1978):\tTroubles\twith\tfunctionalism.\tIn:\tSavage,\tC.\tW.\t(Hg.):\tPerception\t\nand\tCognition.\tIssues\tin\tthe\tFoundations\tof\tPsychology.\tMinneapolis\t(MN),\t\n261\u2013325.\nBod\u00f3,\tB.;\tHelberger,\tN.;\tde\tVreese,\tC.\tH.\t(2017):\tPolitical\tmicro-targeting:\ta\t\nManchurian\tcandidate\tor\tjust\ta\tdark\thorse?\tIn:\tInternet\tPolicy\tReview,\t6\t(4)\t\n(DOI:\t10.14763/2017.4.776).\nBomhard,\tD.;\tMerkle,\tM.\t(2021):\tRegulation\tof\tartificial\tintelligence.\tThe\tEU\t\nCommission\u2019s\tproposal\tof\tan\tAI\tAct.\tIn:\tJournal\tof\tEuropean\tConsumer\tand\t\nMarket\tLaw,\t10\t(6),\t257\u2013261.383Bormann,\tF.-J.\t(2021):\tIst\tdie\tpraktische\tVernunft\tdes\tMenschen\tdurch\t\nKI-Systeme\tersetzbar?\tZum\tunterschiedlichen\tStatus\tvon\tmenschlichen\t\nPersonen\tund\t(selbst-)lernenden\tMaschinen.\tIn:\tFritz,\tA.\tet\tal.\t(Hg.)\t(2021):\t\nDigitalisierung\tim\tGesundheitswesen.\tAnthropologische\tund\tethische\t\nHerausforderungen\tder\tMensch-Maschine-Interaktion.\tFreiburg\tim\tBreisgau,\t\n41\u201364.\nBottek,\tC.\t(2014):\tUnterlassungen\tund\tihre\tFolgen.\tHandlungs-\tund\t\nkausalit\u00e4tstheoretische\t\u00dcberlegungen.\tT\u00fcbingen.\nBovens,\tL.;\tHartmann,\tS.\t(2003):\tBayesian\tEpistemology.\tOxford.\nBowker,\tG.\tC.;\tStar,\tS.\tL.\t(1999):\tSorting\tThings\tOut.\tClassification\tand\tIts\t\nConsequences.\tCambridge\t(MA).\nBradshaw,\tS.;\tDiResta,\tR.;\tMiller,\tC.\t(2022):\tPlaying\tboth\tsides:\tRussian\t\nstate-backed\tmedia\tcoverage\tof\tthe\t#BlackLivesMatter\tmovement.\tIn:\tThe\t\nInternational\tJournal\tof\tPress/Politics\t(DOI:\t10.1177/19401612221082052).\nBradshaw,\tS.;\tHenle,\tA.\t(2021):\tThe\tgender\tdimensions\tof\tforeign\tinfluence\t\noperations.\tIn:\tInternational\tJournal\tof\tCommunication,\t15,\t4596\u20134618.\nBrady,\tW.\tJ.\tet\tal.\t(2017):\tEmotion\tshapes\tthe\tdiffusion\tof\tmoralized\tcontent\tin\t\nsocial\tnetworks.\tIn:\tPNAS,\t114\t(28),\t7313\u20137318\t(DOI:\t10.1073/pnas.1618923114).\nBrown,\tT.\tB.\tet\tal.\t(2020):\tLanguage\tModels\tare\tFew-Shot\tLearners.\thttps://arxiv.\norg/abs/2005.14165\t[10.02.2023].\nB\u00fcchi,\tM.;\tFestic,\tN.;\tLatzer,\tM.\t(2022):\tThe\tchilling\teffects\tof\tdigital\t\ndataveillance:\ta\ttheoretical\tmodel\tand\tan\tempirical\tresearch\tagenda.\tIn:\tBig\t\nData\t&\tSociety,\t9\t(1)\t(DOI:\t10.1177/20539517211065368).\nBuckley,\tR.\tP.\tet\tal.\t(2021):\tRegulating\tartificial\tintelligence\tin\tfinance:\tputting\t\nthe\thuman\tin\tthe\tloop.\tIn:\tSydney\tLaw\tReview,\t43\t(1),\t43\u201381.\nBundesministerium\tf\u00fcr\tKlimaschutz,\tUmwelt,\tEnergie,\tMobilit\u00e4t,\tInnovation\t\nund\tTechnologie\t(2021):\tStrategie\tder\tBundesregierung\tf\u00fcr\tK\u00fcnstliche\t\nIntelligenz.\tArtificial\tIntelligence\tMission\tAustria\t2030\t(AIM\tAT\t2030).\tWien.\nBurchardi,\tS.\t(2022):\tRisikotragung\tf\u00fcr\tKI-Systeme.\tIn:\tEurop\u00e4ische\tZeitschrift\t\nf\u00fcr\tWirtschaftsrecht,\t33\t(15),\t685\u2013692.\nBurhan,\tR.;\tMoradzadeh,\tJ.\t(2020):\tNeurotransmitter\tdopamine\t(DA)\tand\tits\t\nrole\tin\tthe\tdevelopment\tof\tsocial\tmedia\taddiction.\tIn:\tJournal\tof\tNeurology\t&\t\nNeurophysiology,\t11\t(7),\tArt.-Nr.\t507.\thttps://www.iomcworld.org/open-access/\nneurotransmitter-dopamine-da-and-its-role-in-the-development-of-social-\nmedia-addiction-59222.html\t[13.01.2023].\nButz,\tF.\tet\tal.\t(2021):\tAutomatisierte\tRisikoprognosen\tim\tKontext\tvon\t\nBew\u00e4hrungsentscheidungen.\tIn:\tBew\u00e4hrungshilfe,\t68\t(3),\t241\u2013259.\nBynum,\tT.\t(2015):\tComputer\tand\tinformation\tethics.\tIn:\tStanford\tEncyclopedia\t\nof\tPhilosophy\t(Summer\t2018\tEdition).\thttps://plato.stanford.edu/archives/\nsum2018/entries/ethics-computer\t[20.12.2022].\nCarbonell,\tJ.\tG.;\tMichalski,\tR.\tS.;\tMitchell,\tT.\tM.\t(1983):\tMachine\tlearning:\ta\t\nhistorical\tand\tmethodological\tanalysis.\tIn:\tAI\tMagazine,\t4\t(3),\t69\u201378\t(DOI:\t\n10.1609/aimag.v4i3.406).\nCastanho\tSilva,\tB.;\tVegetti,\tF;\tLittvay,\tL.\t(2017):\tThe\telite\tis\tup\tto\tsomething:\t\nexploring\tthe\trelation\tbetween\tpopulism\tand\tbelief\tin\tconspiracy\ttheories.\tIn:\t\nSwiss\tPolitical\tScience\tReview,\t23\t(4),\t423\u2013443\t(DOI:\t10.1111/spsr.12270).384Cheng,\tC.\tet\tal.\t(2021):\tPrevalence\tof\tsocial\tmedia\taddiction\tacross\t32\t\nnations:\tmeta-analysis\twith\tsubgroup\tanalysis\tof\tclassification\tschemes\tand\t\ncultural\tvalues.\tIn:\tAddictive\tBehaviors,\t117,\tArt.-Nr.\t106845\t(DOI:\t10.1016/j.\naddbeh.2021.106845).\nChuai,\tY.;\tZhao,\tJ.\t(2022):\tAnger\tcan\tmake\tfake\tnews\tviral\tonline.\tIn:\tFrontiers\tin\t\nPhysics,\t10,\tArt.-Nr.\t970174\t(DOI:\t10.3389/fphy.2022.970174).\nCinelli,\tM.\tet\tal.\t(2021):\tThe\techo\tchamber\teffect\ton\tsocial\tmedia.\tIn:\tPNAS,\t118\t\n(9),\tArt.-Nr.\te2023301118\t(DOI:\t10.1073/pnas.2023301118).\nClark,\tA.\t(2012):\tEmbodied,\tembedded,\tand\textended\tcognition.\tIn:\tFrankish,\t\nK.;\tRamsey,\tW.\tM.\t(Hg.):\tThe\tCambridge\tHandbook\tof\tCognitive\tScience.\t\nCambridge,\t275\u2013291.\nCornel,\tH.;\tPruin,\tI.\t(2021):\tDie\tImplementierung\tder\tRisikoorientierung\tin\tden\t\nBundesl\u00e4ndern.\tIn:\tCornel,\tH.;\tKawamura-Reindl,\tG.\t(Hg.):\tBew\u00e4hrungshilfe.\t\nTheorie\tund\tPraxis\teines\tHandlungsfeldes\tSozialer\tArbeit.\tWeinheim,\t105\u2013118.\nCremers,\tA.\tB.\tet\tal.\t(2019):\tVertrauensw\u00fcrdiger\tEinsatz\tvon\tK\u00fcnstlicher\t\nIntelligenz.\tHandlungsfelder\taus\tphilosophischer,\tethischer,\trechtlicher\tund\t\ntechnologischer\tSicht\tals\tGrundlage\tf\u00fcr\teine\tZertifizierung\tvon\tK\u00fcnstlicher\t\nIntelligenz.\thttps://www.iais.fraunhofer.de/content/dam/iais/KINRW/\nWhitepaper_KI-Zertifizierung.pdf\t[09.01.2023].\nCroes,\tE.\tA.\tJ.;\tAntheunis,\tM.\tL.\t(2021):\t36\tquestions\tto\tloving\ta\tchatbot:\tare\t\npeople\twilling\tto\tself-disclose\tto\ta\tchatbot?\tIn:\tF\u00f8lstad,\tA.\tet\tal.\t(Hg.):\tChatbot\t\nResearch\tand\tDesign.\t4th\tInternational\tWorkshop,\tConversations\t2020.\tCham,\t\n81\u201395.\nDanaher,\tJ.\t(2016):\tThe\tthreat\tof\talgocracy:\treality,\tresistance\tand\t\naccommodation.\tIn:\tPhilosophy\t&\tTechnology,\t29\t(3),\t245\u2013268.\nDatenethikkommission\tder\tBundesregierung\t(2019):\tGutachten\tder\t\nDatenethikkommission.\tBerlin.\nDavidson,\tT.;\tBhattacharya,\tD.;\tWeber,\tI.\t(2019):\tRacial\tbias\tin\thate\tspeech\tand\t\nabusive\tlanguage\tdetection\tdatasets.\tIn:\tProceedings\tof\tthe\tThird\tWorkshop\ton\t\nAbusive\tLanguage\tOnline,\t25\u201335\t(DOI:\t10.18653/v1/W19-3504).\nDeary,\tI.\tJ.\t(2020):\tIntelligence.\tA\tVery\tShort\tIntroduction.\tOxford.\nDechsling,\tR.\t(1989):\tDas\tVerh\u00e4ltnism\u00e4ssigkeitsgebot.\tEine\tBestandsaufnahme\t\nder\tLiteratur\tzur\tVerh\u00e4ltnism\u00e4ssigkeit\tstaatlichen\tHandelns.\tM\u00fcnchen.\nDel\tVicario,\tM.\tet\tal.\t(2016):\tThe\tspreading\tof\tmisinformation\tonline.\tIn:\tPNAS,\t\n113\t(3),\t554\u2013559\t(DOI:\t10.1073/pnas.1517441113).\nDenga,\tM.\t(2018):\tDeliktische\tHaftung\tf\u00fcr\tk\u00fcnstliche\tIntelligenz.\t\nWarum\tdie\tVerschuldenshaftung\tdes\tBGB\tauch\tk\u00fcnftig\tdie\tbessere\t\nSchadensausgleichsordnung\tbedeutet.\tIn:\tComputer\tund\tRecht,\t34\t(2),\t69\u201378\t\n(DOI:\t10.9785/cr-2018-0203).\nDennis,\tA.\tR.\tet\tal.\t(2020):\tUser\treactions\tto\tCOVID-19\tscreening\tchatbots\t\nfrom\treputable\tproviders.\tIn:\tJournal\tof\tthe\tAmerican\tMedical\tInformatics\t\nAssociation,\t27\t(11),\t1727\u20131731\t(DOI:\t10.1093/jamia/ocaa167).\nDeutscher\tBundestag\t(2020):\tBericht\tder\tEnquete-Kommission\tK\u00fcnstliche\t\nIntelligenz\t\u2013\tGesellschaftliche\tVerantwortung\tund\twirtschaftliche,\tsoziale\tund\t\n\u00f6kologische\tPotenziale.\tDrucksache\t19/23700.\thttps://dserver.bundestag.de/\nbtd/19/237/1923700.pdf\t[18.01.2023].385Deutscher\tBundestag\t(2017):\tWortprotokoll\tder\t114.\tSitzung\tdes\t\nInnenausschusses.\tProtokoll-Nr.\t18/114.\thttps://www.bundestag.de/resource/\nblob/515144/87bdd46c572ebeb4863d139812f3fc4a/Protokoll-114-data.pdf\t\n[03.03.2023].\nDeutscher\tEthikrat\t(2022a):\tPandemie\tund\tpsychische\tGesundheit.\t\nAufmerksamkeit,\tBeistand\tund\tUnterst\u00fctzung\tf\u00fcr\tKinder,\tJugendliche\tund\t\njunge\tErwachsene\tin\tund\tnach\tgesellschaftlichen\tKrisen.\tBerlin.\nDeutscher\tEthikrat\t(2022b):\tVulnerabilit\u00e4t\tund\tResilienz\tin\tder\tKrise\t\u2013\tEthische\t\nKriterien\tf\u00fcr\tEntscheidungen\tin\teiner\tPandemie.\tBerlin.\nDeutscher\tEthikrat\t(2020a):\tRobotik\tf\u00fcr\tgute\tPflege.\tBerlin.\nDeutscher\tEthikrat\t(2020b):\tTierwohlachtung\t\u2013\tZum\tverantwortlichen\tUmgang\t\nmit\tNutztieren.\tBerlin.\nDeutscher\tEthikrat\t(2017):\tBig\tData\tund\tGesundheit\t\u2013\tDatensouver\u00e4nit\u00e4t\tals\t\ninformationelle\tFreiheitsgestaltung.\tBerlin.\nDeutscher\tEthikrat\t(2014):\tBiosicherheit\t\u2013\tFreiheit\tund\tVerantwortung\tin\tder\t\nWissenschaft.\tBerlin.\nDierkes,\tM.;\tHoffmann,\tU.;\tMarz,\tL.\t(1992):\tLeitbild\tund\tTechnik.\tZur\tEntstehung\t\nund\tSteuerung\ttechnischer\tInnovationen.\tBerlin.\nDillenbourg,\tP.\t(2021):\tClassroom\tanalytics:\tzooming\tout\tfrom\ta\tpupil\tto\ta\t\nclassroom.\tIn:\tOECD\tDigital\tEducation\tOutlook\t2021.\tPushing\tthe\tFrontiers\t\nwith\tArtificial\tIntelligence,\tBlockchain\tand\tRobots.\tParis,\t105\u2013122.\nDiResta,\tR.\tet\tal.\t(2019):\tThe\tTactics\t&\tTropes\tof\tthe\tInternet\tResearch\t\nAgency.\thttps://www.intelligence.senate.gov/sites/default/files/documents/\nNewKnowledge-Disinformation-Report-Whitepaper.pdf\t[12.01.2023].\nDolata,\tU.;\tWerle,\tR.\t(Hg.)\t(2007):\tGesellschaft\tund\tdie\tMacht\tder\tTechnik.\t\nSozio\u00f6konomischer\tund\tinstitutioneller\tWandel\tdurch\tTechnisierung.\tFrankfurt\t\nam\tMain.\nDonelan,\tH.\t(2016):\tSocial\tmedia\tfor\tprofessional\tdevelopment\tand\tnetworking\t\nopportunities\tin\tacademia.\tIn:\tJournal\tof\tFurther\tand\tHigher\tEducation,\t40\t(5),\t\n706\u2013729\t(DOI:\t10.1080/0309877X.2015.1014321).\nDrake,\tB.\tet\tal.\t(2020):\tA\tPractical\tFramework\tfor\tConsidering\tthe\tUse\t\nof\tPredictive\tRisk\tModeling\tin\tChild\tWelfare.\tIn:\tThe\tAnnals\tof\tthe\t\nAmerican\tAcademy\tof\tPolitical\tand\tSocial\tScience,\t692\t(1),\t162\u2013181\t(DOI:\t\n10.1177/0002716220978200).\nDreyfus,\tH.\tL.\t(1992):\tWhat\tComputers\tStill\tCan\u2019t\tDo.\tA\tCritique\tof\tArtificial\t\nReason.\tCambridge\t(MA).\nDubois,\tE.;\tBlank,\tG.\t(2018):\tThe\techo\tchamber\tis\toverstated:\tThe\tmoderating\t\neffect\tof\tpolitical\tinterest\tand\tdiverse\tmedia.\tIn:\tInformation,\tCommunication\t&\t\nSociety,\t21\t(5),\t729\u2013745\t(DOI:\t10.1080/1369118X.2018.1428656).\nE-READ\t(2019):\tStavanger\tDeclaration\tConcerning\tthe\tFuture\tof\tReading.\t\nhttps://ereadcost.eu/wp-content/uploads/2019/01/StavangerDeclaration.pdf\t\n[12.01.2023].\nEbers,\tM.\tet\tal.\t(Hg.)\t(2020):\tK\u00fcnstliche\tIntelligenz\tund\tRobotik.\t\nRechtshandbuch\t(1.\u00a0Auflage).\tM\u00fcnchen.\nEbert,\tD.\tD.\tet\tal.\t(2018):\tInternet-\tand\tmobile-based\tpsychological\t\ninterventions:\tapplications,\tefficacy,\tand\tpotential\tfor\timproving\tmental\thealth.\t\nIn:\tEuropean\tPsychologist,\t23\t(2),\t167\u2013187\t(DOI:\t10.1027/1016-9040/a000318).386Egbert,\tS.\t(2020):\tPredictive\tPolicing\tals\tTreiber\trechtlicher\tInnovation?\tIn:\t\nZeitschrift\tf\u00fcr\tRechtssoziologie,\t40\t(1\u20132),\t26\u201351\t(DOI:\t10.1515/zfrs-2020-0002).\nEgbert,\tS.\t(2018):\tPredictive\tPolicing\tin\tDeutschland.\tGrundlagen,\tRisiken,\t\n(m\u00f6gliche)\tZukunft.\tIn:\tStrafverteidigervereinigungen\t(Hg.):\tR\u00e4ume\tder\t\nUnfreiheit.\tBerlin,\t241\u2013265.\nEgbert,\tS.;\tLeese,\tM.\t(2020):\tCriminal\tFutures.\tPredictive\tPolicing\tand\tEveryday\t\nPolice\tWork.\tLondon.\nEifert,\tM.\tet\tal.\t(2021):\tTaming\tthe\tgiants:\tthe\tDMA/DSA\tpackage.\tIn:\tCommon\t\nMarket\tLaw\tReview,\t58\t(4),\t987\u20131028\t(DOI:\t10.54648/cola2021065).\nEisele,\tJ.;\tB\u00f6hm,\tK.\t(2020):\tPotential\tund\tRisiken\tvon\tPredictive\tPolicing.\tIn:\t\nBeck,\tS.;\tKusche,\tC.;\tValerius,\tB.\t(Hg.):\tDigitalisierung,\tAutomatisierung,\tKI\tund\t\nRecht.\tFestgabe\tzum\t10-j\u00e4hrigen\tBestehen\tder\tForschungsstelle\tRobotRecht.\t\nBaden-Baden,\t519\u2013533.\nEnder,\tA.\tM.\tet\tal.\t(2023):\tThe\trelationship\tbetween\tsocial\tmedia\tuse\tand\t\nbeliefs\tin\tconspiracy\ttheories\tand\tmisinformation.\tIn:\tPolitical\tBehavior,\t45\t(2),\t\n781\u2013804\t(DOI:\t10.1007/s11109-021-09734-6).\nEpping,\tV.;\tHillgruber,\tC.\t(Hg.)\t(2022):\tBeckOK\tGrundgesetz\t(52.\tEdition,\tStand:\t\n15.08.2022).\thttps://beck-online.beck.de/Dokument?vpath=bibdata/komm/\nbeckokgg_52/cont/beckokgg.htm\t[17.01.2023].\nEpstein,\tR.;\tRobertson,\tR.\tE.\t(2015):\tThe\tsearch\tengine\tmanipulation\teffect\t\n(SEME)\tand\tits\tpossible\timpact\ton\tthe\toutcomes\tof\telections.\tIn:\tPNAS,\t112\t(33),\t\nE4512\u2013E4521\t(DOI:\t10.1073/pnas.1419828112).\nEthik-Kommission\tAutomatisiertes\tund\tvernetztes\tFahren\t(2017):\tBericht.\t\nhttps://bmdv.bund.de/goto?id=348344\t[18.01.2023].\nEubanks,\tV.\t(2018):\tAutomating\tInequality.\tHow\tHigh-Tech\tTools\tProfile,\tPolice,\t\nand\tPunish\tthe\tPoor.\tNew\tYork\t(NY).\nEurop\u00e4ische\tKommission\t(2020):\tWei\u00dfbuch\tzur\tK\u00fcnstlichen\tIntelligenz\t\u2013\tEin\t\neurop\u00e4isches\tKonzept\tf\u00fcr\tExzellenz\tund\tVertrauen.\thttps://eur-lex.europa.eu/\nlegal-content/DE/TXT/?uri=CELEX:52020DC0065\t[09.01.2023].\nFaber,\tJ.\tM.;\tLuyten,\tH.;\tVisscher,\tA.\tJ.\t(2017):\tThe\teffects\tof\ta\tdigital\tformative\t\nassessment\ttool\ton\tmathematics\tachievement\tand\tstudent\tmotivation:\tresults\t\nof\ta\trandomized\texperiment.\tIn:\tComputers\t&\tEducation,\t106,\t83\u201396\t(DOI:\t\n10.1016/j.compedu.2016.12.001).\nFan,\tR.\tet\tal.\t(2014):\tAnger\tis\tmore\tinfluential\tthan\tjoy:\tsentiment\tcorrelation\t\nin\tWeibo.\tIn:\tPLOS\tOne,\t9\t(10),\tArt.-Nr.\te110184\t(DOI:\t10.1371/journal.\npone.0110184).\nFerrara,\tE.\tet\tal.\t(2020):\tCharacterizing\tsocial\tmedia\tmanipulation\tin\tthe\t2020\t\nU.S.\tpresidential\telection.\tIn:\tFirst\tMonday,\t25\t(11)\t(DOI:\t10.5210/fm.v25i11.11431).\nFerrara,\tE.\tet\tal.\t(2016):\tThe\trise\tof\tsocial\tbots.\tIn:\tCommunications\tof\tthe\tACM,\t\n59\t(7),\t96\u2013104\t(DOI:\t10.1145/2818717).\nFichtner,\tL.\t(2022):\tContent\tmoderation\tand\tthe\tquest\tfor\tdemocratic\t\nlegitimacy.\tIn:\tWeizenbaum\tJournal\tof\tthe\tDigital\tSociety,\t2\t(2),\tArt.-Nr.\tw2.2.2\t\n(DOI:\t10.34669/wi.wjds/2.2.2).\nFiske,\tA.;\tHenningsen,\tP.;\tBuyx,\tA.\t(2019):\tYour\trobot\ttherapist\twill\tsee\tyou\t\nnow:\tethical\timplications\tof\tembodied\tartificial\tintelligence\tin\tpsychiatry,\t\npsychology,\tand\tpsychotherapy.\tIn:\tJournal\tof\tMedical\tInternet\tResearch,\t21\t(5),\t\nArt.-Nr.\te13216\t(DOI:\t10.2196/13216).387Fjeld,\tJ.\tet\tal.\t(2020):\tPrincipled\tArtificial\tIntelligence:\tMapping\tConsensus\tin\t\nEthical\tand\tRights-based\tApproaches\tto\tPrinciples\tfor\tAI.\thttps://ssrn.com/\nabstract=3518482\t[10.02.2023].\nFloridi,\tL.\t(2016):\tFaultless\tresponsibility:\ton\tthe\tnature\tand\tallocation\tof\tmoral\t\nresponsibility\tfor\tdistributed\tmoral\tactions.\tIn:\tPhilosophical\tTransactions\tA,\t\n374\t(2083),\tArt.-Nr.\t20160112\t(DOI:\t10.1098/rsta.2016.0112).\nFloridi,\tL.\t(2013):\tDistributed\tmorality\tin\tan\tinformation\tsociety.\tIn:\tScience\tand\t\nEngineering\tEthics,\t19\t(3),\t727\u2013743\t(DOI:\t10.1007/s11948-012-9413-4).\nFloridi,\tL.;\tSanders,\tJ.\tW.\t(2004):\tOn\tthe\tmorality\tof\tartificial\tagents.\tIn:\tMinds\t\nand\tMachines,\t14\t(3),\t349\u2013379\t(DOI:\t10.1023/B:MIND.0000035461.63578.9d).\nFloridi,\tL.\tet\tal.\t(2018):\tAI4People\t\u2013\tan\tethical\tframework\tfor\ta\tgood\tAI\tsociety:\t\nopportunities,\trisks,\tprinciples,\tand\trecommendations.\tIn:\tMinds\tand\tMachines,\t\n28\t(4),\t689\u2013707\t(DOI:\t10.1007/s11023-018-9482-5).\nFodor,\tJ.\tA.\t(1974):\tSpecial\tsciences\t(or:\tthe\tdisunity\tof\tscience\tas\ta\tworking\t\nhypothesis).\tIn:\tSynthese,\t28\t(2),\t97\u2013115\t(DOI:\t10.1007/BF00485230).\nFrankfurt,\tH.\tG.\t(1971):\tFreedom\tof\tthe\twill\tand\tthe\tconcept\tof\ta\tperson.\tIn:\tThe\t\nJournal\tof\tPhilosophy,\t68\t(1),\t5\u201320\t(DOI:\t10.2307/2024717).\nFreund,\tG.\t(1992):\tErfolgsdelikt\tund\tUnterlassen.\tZu\tden\t\nLegitimationsbedingungen\tvon\tSchuldspruch\tund\tStrafe.\tK\u00f6ln.\nFriedman,\tB.;\tHendry,\tD.\tG.\t(2019):\tValue\tSensitive\tDesign.\tShaping\tTechnology\t\nwith\tMoral\tImagination.\tCambridge\t(MA).\nFriedman,\tB.;\tNissenbaum,\tH.\t(1996):\tBias\tin\tcomputer\tsystems.\tIn:\t\nACM\tTransactions\ton\tInformation\tSystems,\t14\t(3),\t330\u2013347\t(DOI:\t\n10.1145/230538.230561).\nFrisch,\tW.\t(2016):\tStrafrecht\tund\tSolidarit\u00e4t\t\u2013\tZugleich\tzu\tNotstand\tund\t\nunterlassener\tHilfeleistung.\tIn:\tGoltdammer\u2019s\tArchiv\tf\u00fcr\tStrafrecht,\t163\t(3),\t\n121\u2013137.\nFuchs,\tT.\t(2013):\tVerk\u00f6rperung,\tSozialit\u00e4t\tund\tKultur.\tIn:\tBreyer,\tT.\tet\tal.\t(Hg.):\t\nInterdisziplin\u00e4re\tAnthropologie.\tLeib\t\u2013\tGeist\t\u2013\tKultur.\tHeidelberg,\t11\u201333.\nFuhrmann,\tM.\tet\tal.\t(1989):\tPerson.\tIn:\tRitter,\tJ.;\tGr\u00fcnder,\tK.\t(Hg.):\tHistorisches\t\nW\u00f6rterbuch\tder\tPhilosophie.\tBand\t7:\tP-Q.\tBasel,\tSp.\t269\u2013338.\nGarside,\tJ.;\tPlana,\tL.\tA.\t(2020):\tThe\tSpiNNaker\tchip.\tIn:\tFurber,\tS.;\tBogdan,\tP.\t\n(Hg.):\tSpiNNaker.\tA\tSpiking\tNeural\tNetwork\tArchitecture.\tBoston\t(MA),\t17\u201351.\nGeminn,\tC.\t(2021):\tDie\tRegulierung\tK\u00fcnstlicher\tIntelligenz.\tAnmerkungen\tzum\t\nEntwurf\teines\tArtificial\tIntelligence\tAct.\tIn:\tZeitschrift\tf\u00fcr\tDatenschutz,\t11\t(7),\t\n354\u2013359.\nGerhardinger,\tS.\t(2020).\tEntwicklung\tder\tTherapeutenpers\u00f6nlichkeit.\t\nOrientierungshilfen\tf\u00fcr\tPsychotherapeutinnen\tund\tPsychotherapeuten.\tBerlin.\nGhanem,\tC.\t(2021):\tBew\u00e4hrungshilfe\tzwischen\tRisiko-\tund\t\nRessourcenorientierung.\tIn:\tCornel,\tH.;\tKawamura-Reindl,\tG.\t(Hg.):\t\nBew\u00e4hrungshilfe.\tTheorie\tund\tPraxis\teines\tHandlungsfeldes\tSozialer\tArbeit.\t\nWeinheim,\t84\u201391.\nGibbard,\tA.\t(1973):\tManipulation\tof\tvoting\tschemes:\ta\tgeneral\tresult.\tIn:\t\nEconometrica,\t41\t(4),\t587\u2013601\t(DOI:\t10.2307/1914083).388Gielen,\tN.;\tUphues,\tS.\t(2021):\tDigital\tMarkets\tAct\tund\tDigital\tServices\tAct.\t\nRegulierung\tvon\tMarkt-\tund\tMeinungsmacht\tdurch\tdie\tEurop\u00e4ische\tUnion.\tIn:\t\nEurop\u00e4ische\tZeitschrift\tf\u00fcr\tWirtschaftsrecht,\t32\t(14),\t627\u2013637.\nGigerenzer,\tG.;\tMata,\tJ.;\tFrank,\tR.\t(2009):\tPublic\tknowledge\tof\tbenefits\tof\tbreast\t\nand\tprostate\tcancer\tscreening\tin\tEurope.\tIn:\tJournal\tof\tthe\tNational\tCancer\t\nInstitute,\t101\t(17),\t1216\u20131220\t(DOI:\t10.1093/jnci/djp237).\nGillingham,\tP.\t(2021):\tBig\tData,\tpr\u00e4diktive\tAnalytik\tund\tSoziale\tArbeit.\tEin\t\n\u00dcberblick.\tIn:\tSozial\tExtra,\t45\t(1),\t31\u201335\t(DOI:\t10.1007/s12054-020-00348-6).\nGillingham,\tP.\t(2016):\tPredictive\trisk\tmodelling\tto\tprevent\tchild\tmaltreatment\t\nand\tother\tadverse\toutcomes\tfor\tservice\tusers:\tinside\tthe\t\u2018black\tbox\u2019\tof\tmachine\t\nlearning.\tIn:\tThe\tBritish\tJournal\tof\tSocial\tWork,\t46\t(4),\t1044\u20131058\t(DOI:\t10.1093/\nbjsw/bcv031).\nGluba,\tA.\t(2017):\tDer\tModus\tOperandi\t bei\tF\u00e4llen\tder\tNear\tRepeat-Victimisation.\t\nIn:\tKriminalistik,\t71\t(6),\t369\u2013375.\nGood,\tJ.\t(2021):\tServing\tstudents\twith\tspecial\tneeds\tbetter:\thow\tdigital\t\ntechnology\tcan\thelp.\tIn:\tOECD\tDigital\tEducation\tOutlook\t2021.\tPushing\tthe\t\nFrontiers\twith\tArtificial\tIntelligence,\tBlockchain\tand\tRobots.\tParis,\t123\u2013142.\nG\u00f6rder,\tB.\t(2021):\tDie\tMacht\tder\tMuster.\tDie\tEthik\tder\tSozialen\tArbeit\tvor\t\nprofessionsbezogenen\tund\tgesellschaftlichen\tHerausforderungen\tdurch\t\n\u201ak\u00fcnstliche\tIntelligenz\u2018.\tIn:\tEthik\tJournal,\t7\t(2).\thttps://www.ethikjournal.\nde/fileadmin/user_upload/ethikjournal/Texte_Ausgabe_2021_2/Goerder_\nEthikjournal_2.2021.pdf\t[08.02.2023].\nG\u00f6rz,\tG.;\tSchmid,\tU.;\tBraun,\tT.\t(Hg.)\t(2021):\tHandbuch\tder\tK\u00fcnstlichen\t\nIntelligenz\t(6.\u00a0Auflage).\tBerlin.\nGraesser,\tA.\tC.\tet\tal.\t(2012):\tAutoTutor.\tIn:\tMcCarthy,\tP.\tM.;\tBoonthum-Denecke,\t\nC.\t(Hg.):\tApplied\tNatural\tLanguage\tProcessing:\tIdentification,\tInvestigation\tand\t\nResolution.\tHershey\t(PA),\t169\u2013187.\nGratzer,\tD.;\tGoldbloom,\tD.\t(2020):\tTherapy\tand\te-therapy\t\u2013\tpreparing\tfuture\t\npsychiatrists\tin\tthe\tera\tof\tapps\tand\tchatbots.\tIn:\tAcademic\tPsychiatry,\t44\t(2),\t\n231\u2013234\t(DOI:\t10.1007/s40596-019-01170-3).\nGray,\tC.\tC.;\tPerkins,\tD.\t(2019):\tUtilizing\tearly\tengagement\tand\tmachine\tlearning\t\nto\tpredict\tstudent\toutcomes.\tIn:\tComputers\t&\tEducation,\t131,\t22\u201332\t(DOI:\t\n10.1016/j.compedu.2018.12.006).\nGrunwald,\tA.\t(2022):\tTechnikfolgenabsch\u00e4tzung.\tEinf\u00fchrung.\tBaden-Baden.\nGrunwald,\tA.\t(2021):\tDer\thomo\tresponsibilis.\tEin\tnachdenklicher\tGang\tdurch\t\nden\tGarten\taktueller\tErz\u00e4hlungen.\tIn:\tders.\t(Hg.):\tWer\tbist\tdu,\tMensch?\t\nTransformationen\tmenschlicher\tSelbstverst\u00e4ndnisse\tim\twissenschaftlich-\ntechnischen\tFortschritt.\tFreiburg\tim\tBreisgau,\t216\u2013239.\nGrunwald,\tA.\t(2019):\tTechnology\tAssessment\tin\tPractice\tand\tTheory.\tAbingdon.\nGrunwald,\tA.\t(2014):\tModes\tof\torientation\tprovided\tby\tfutures\tstudies:\tmaking\t\nsense\tof\tdiversity\tand\tdivergence.\tIn:\tEuropean\tJournal\tof\tFutures\tResearch,\t2,\t\nArt.-Nr.\t30\t(DOI\t10.1007/s40309-013-0030-5).\nGrunwald,\tA.\t(2007):\tTechnikdeterminismus\toder\tSozialdeterminismus:\t\nZeitbez\u00fcge\tund\tKausalverh\u00e4ltnisse\taus\tder\tSicht\tdes\t\u201eTechnology\tAssessment\u201c.\t\nIn:\tDolata,\tU.;\tWerle,\tR.\t(Hg.):\tGesellschaft\tund\tdie\tMacht\tder\tTechnik.\t\nSozio\u00f6konomischer\tund\tinstitutioneller\tWandel\tdurch\tTechnisierung.\tFrankfurt\t\nam\tMain,\t63\u201382.389Grunwald,\tK.;\tThiersch,\tH.\t(Hg.)\t(2016):\tPraxishandbuch\tLebensweltorientierte\t\nSoziale\tArbeit.\tHandlungszusammenh\u00e4nge\tund\tMethoden\tin\tunterschiedlichen\t\nArbeitsfeldern\t(3.\u00a0Auflage).\tWeinheim.\nGuckelberger,\tA.\t(2019):\t\u00d6ffentliche\tVerwaltung\tim\tZeitalter\tder\tDigitalisierung.\t\nAnalysen\tund\tStrategien\tzur\tVerbesserung\tdes\tE-Governments\taus\trechtlicher\t\nSicht.\tBaden-Baden.\nGuilford,\tJ.\tP.\t(1950):\tCreativity.\tIn:\tAmerican\tPsychologist,\t5\t(9),\t444\u2013454\t(DOI:\t\n10.1037/h0063487).\nGutwald,\tR.\tet\tal.\t(2021):\tSoziale\tKonflikte\tund\tDigitalisierung.\t\nChancen\tund\tRisiken\tdigitaler\tTechnologien\tbei\tder\tEinsch\u00e4tzung\tvon\t\nKindeswohlgef\u00e4hrdungen.\tIn:\tEthik\tJournal,\t7\t(2).\thttps://www.ethikjournal.\nde/fileadmin/user_upload/ethikjournal/Texte_Ausgabe_2021_2/Gutwald_u.a._\nEthikjournal_2.2021.pdf\t[16.01.2023].\nHabermas,\tJ.\t(1981):\tTheorie\tdes\tkommunikativen\tHandelns.\tFrankfurt\tam\tMain.\nHacking,\tI.\t(1995):\tThe\tlooping\teffect\tof\thuman\tkinds.\tIn:\tSperber,\tD.;\tPremack,\t\nD.;\tPremack,\tA.\tJ.\t(Hg.):\tCausal\tCognition.\tA\tMultidisciplinary\tDebate.\tOxford,\t\n351\u2013383.\nHagendorff,\tT.\t(2020):\tThe\tethics\tof\tAI\tethics:\tan\tevaluation\tof\tguidelines.\tIn:\t\nMinds\tand\tMachines,\t30\t(1),\t99\u2013120\t(DOI:\t10.1007/s11023-020-09517-8).\nHalbig,\tC.\t(2007):\tPraktische\tGr\u00fcnde\tund\tdie\tRealit\u00e4t\tder\tMoral.\tFrankfurt\tam\t\nMain.\nHansen,\tJ.\tet\tal.\t(2020):\tVerhaltenskodex\tf\u00fcr\tTrusted\tLearning\tAnalytics.\t\nEntwurf\tf\u00fcr\tdie\thessischen\tHochschulen.\tFrankfurt\tam\tMain.\nH\u00e4rtel,\tI.\t(2019):\tDigitalisierung\tim\tLichte\tdes\tVerfassungsrechts\t\u2013\tAlgorithmen,\t\nPredictive\tPolicing,\tautonomes\tFahren.\tIn:\tLandes-\tund\tKommunalverwaltung,\t\n29\t(2),\t49\u201360.\nHartong,\tS.\t(2019):\tLearning\tAnalytics\tund\tBig\tData\tin\tder\tBildung.\tZur\t\nnotwendigen\tEntwicklung\teines\tdatenpolitischen\tAlternativprogramms.\t\nFrankfurt\tam\tMain.\nHe,\tQ.;\tTurel,\tO.;\tBechara,\tA.\t(2017):\tBrain\tanatomy\talterations\tassociated\twith\t\nSocial\tNetworking\tSite\t(SNS)\taddiction.\tIn:\tScientific\tReports,\t7,\tArt.-Nr.\t45064\t\n(DOI:\t10.1038/srep45064).\nHealth\tEducation\tEngland\t(2019):\tThe\tTopol\tReview.\tPreparing\tthe\thealthcare\t\nworkforce\tto\tdeliver\tthe\tdigital\tfuture.\thttps://topol.hee.nhs.uk/wp-content/\nuploads/HEE-Topol-Review-2019.pdf\t[22.02.2023].\nHeckmann,\tH.-D.;\tWalter,\tS.\t(Hg.)\t(2006):\tQualia.\tAusgew\u00e4hlte\tBeitr\u00e4ge.\t\nPaderborn.\nHeesen,\tJ.\tet\tal.\t(2020):\tZertifizierung\tvon\tKI-Systemen.\tKompass\tf\u00fcr\tdie\t\nEntwicklung\tund\tAnwendung\tvertrauensw\u00fcrdiger\tKI-Systeme.\thttps://www.\nplattform-lernende-systeme.de/files/Downloads/Publikationen/AG1_3_\nWhitepaper_Zertifizierung_KI_Systemen.pdf\t[07.02.2023].\nHesse,\tJ.\tJ.;\tEllwein,\tT.\t(1992):\tDas\tRegierungssystem\tder\tBundesrepublik\t\nDeutschland\t(7.\u00a0Auflage).\tOpladen.\nHessischer\tLandtag\t(2019):\tZwischenbericht\tdes\tUntersuchungsausschusses\t\n19/3.\tDrucksache\t19/6864.\thttps://starweb.hessen.de/cache/DRS/19/4/06864.\npdf\t[01.03.2023].390He\u00dfler,\tM.;\tLiggieri,\tK.\t(Hg.)\t(2020):\tTechnikanthropologie.\tHandbuch\tf\u00fcr\t\nWissenschaft\tund\tStudium.\tBaden-Baden.\nHevelke,\tA.;\tNida-R\u00fcmelin,\tJ.\t(2015):\tResponsibility\tfor\tcrashes\tof\tautonomous\t\nvehicles:\tan\tethical\tanalysis.\tIn:\tScience\tand\tEngineering\tEthics,\t21\t(3),\t619\u2013630.\nHiggins,\tM.\tK.\t(2021):\tCan\twe\tAlphaFold\tour\tway\tout\tof\tthe\tnext\tpandemic?\t\nIn:\tJournal\tof\tMolecular\tBiology,\t433\t(20),\tArt.-Nr.\t167093\t(DOI:\t10.1016/j.\njmb.2021.167093).\nHildebrandt,\tM.\t(2022):\tThe\tissue\tof\tproxies\tand\tchoice\tarchitectures.\tWhy\tEU\t\nlaw\tmatters\tfor\trecommender\tsystems.\tIn:\tFrontiers\tin\tArtificial\tIntelligence,\t5,\t\nArt.-Nr.\t789076\t(DOI:\t10.3389/frai.2022.789076).\nHilgendorf,\tE.\t(2020):\tDigitalisierung,\tVirtualisierung\tund\tdas\tRecht.\tIn:\t\nKasprowicz,\tD.;\tRieger,\tS.\t(Hg.):\tHandbuch\tVirtualit\u00e4t.\tWiesbaden,\t405\u2013424.\nHilgendorf,\tE.\t(Hg.)\t(2014):\tRobotik\tim\tKontext\tvon\tRecht\tund\tMoral.\tBaden-\nBaden.\nHochrangige\tExpertengruppe\tf\u00fcr\tk\u00fcnstliche\tIntelligenz\t(2019):\tEthik-Leitlinien\t\nf\u00fcr\teine\tvertrauensw\u00fcrdige\tKI.\thttps://data.europa.eu/doi/10.2759/22710\t\n[18.01.2023].\nHoffmann-Riem,\tW.\t(2022):\tRecht\tim\tSog\tder\tdigitalen\tTransformation.\t\nT\u00fcbingen.\nHolohan,\tM.;\tFiske,\tA.\t(2021):\t\u201cLike\tI\u2019m\ttalking\tto\ta\treal\tperson\u201d:\texploring\tthe\t\nmeaning\tof\ttransference\tfor\tthe\tuse\tand\tdesign\tof\tAI-based\tapplications\tin\t\npsychotherapy.\tIn:\tFrontiers\tin\tPsychology,\t12,\tArt.-Nr.\t720476\t(DOI:\t10.3389/\nfpsyg.2021.720476).\nHolthausen,\tJ.\t(2021):\tBig\tData,\tPeople\tAnalytics,\tKI\tund\tGestaltung\tvon\t\nBetriebsvereinbarungen\t\u2013\tGrund-,\tarbeits-\tund\tdatenschutzrechtliche\tAn-\tund\t\nHerausforderungen.\tIn:\tRecht\tder\tArbeit,\t74\t(1),\t19\u201332.\nHorn,\tJ.\tL.;\tCattell,\tR.\tB.\t(1966):\tRefinement\tand\ttest\tof\tthe\ttheory\tof\tfluid\tand\t\ncrystallized\tgeneral\tintelligences.\tIn:\tJournal\tof\tEducational\tPsychology,\t57\t(5),\t\n253\u2013270\t(DOI:\t10.1037/h0023816).\nHorn,\tC.;\tL\u00f6hrer,\tG.\t(Hg.)\t(2010):\tGr\u00fcnde\tund\tZwecke.\tTexte\tzur\taktuellen\t\nHandlungstheorie.\tBerlin.\nHuber,\tL.\t(2021):\tDas\trationale\tTier.\tEine\tkognitionsbiologische\tSpurensuche.\t\nBerlin.\nHubig,\tC.\t(2006):\tDie\tKunst\tdes\tM\u00f6glichen.\tBand\t1:\tTechnikphilosophie\tals\t\nReflexion\tder\tMedialit\u00e4t.\tBielefeld.\nHunt,\tE.;\tLunneborg,\t C.;\tLewis,\tJ.\t(1975):\tWhat\tdoes\tit\tmean\tto\tbe\thigh\tverbal?\tIn:\t\nCognitive\tPsychology,\t7\t(2),\t194\u2013227\t(DOI:\t10.1016/0010-0285(75)90010-9).\nIEEE\t(2019):\tEthically\tAligned\tDesign.\tA\tVision\tfor\tPrioritizing\tHuman\t\nWell-being\twith\tAutonomous\tand\tIntelligent\tSystems.\thttps://ieeexplore.ieee.\norg/document/9398613\t[18.01.2023].\nIhde,\tD.\t(1990):\tTechnology\tand\tthe\tLifeworld.\tFrom\tGarden\tto\tEarth.\t\nBloomington\t(IN).\nJobin,\tA.;\tIenca,\tM.;\tVayena,\tE.\t(2019):\tThe\tglobal\tlandscape\tof\tAI\tethics\t\nguidelines.\tIn:\tNature\tMachine\tIntelligence,\t1\t(9),\t389\u2013399\t(DOI:\t10.1038/\ns42256-019-0088-2).\nJohnson,\tD.\tG.\t(1985):\tComputer\tEthics.\tEnglewood\tCliffs\t(NJ).391Kaiser,\tB.\t(2020):\tDie\tDatendiktatur.\tWie\tWahlen\tmanipuliert\twerden.\tHamburg.\nKaissis,\tG.\tet\tal.\t(2021):\tEnd-to-end\tprivacy\tpreserving\tdeep\tlearning\ton\tmulti-\ninstitutional\tmedical\timaging.\tIn:\tNature\tMachine\tIntelligence,\t3\t(6),\t473\u2013484\t\n(DOI:\t10.1038/s42256-021-00337-8).\nKane,\tR.\t(Hg.)\t(2011):\tThe\tOxford\tHandbook\tof\tFree\tWill.\tNew\tYork\t(NY).\nKant,\tI.\t(1968a):\tKants\tWerke.\tBand\t3:\tKritik\tder\treinen\tVernunft.\tBerlin.\nKant,\tI.\t(1968b):\tKants\tWerke.\tBand\t5:\tKritik\tder\tpraktischen\tVernunft\u00a0/\tKritik\t\nder\tUrtheilskraft.\tBerlin.\nKaspar,\tJ.;\tH\u00f6ffler,\tK.;\tHarrendorf,\tS.\t(2020):\tDatenbanken,\tOnline-Votings\t\nund\tk\u00fcnstliche\tIntelligenz\t\u2013\tPerspektiven\tevidenzbasierter\tStrafzumessung\t\nim\tZeitalter\tvon\t\u201eLegal\tTech\u201c.\tIn:\tNeue\tKriminalpolitik,\t32\t(1),\t35\u201356\t(DOI:\t\n10.5771/0934-9200-2020-1-35).\nKemp,\tS.\t(2023):\tDigital\t2023:\tGlobal\tOverview\tReport.\thttps://datareportal.\ncom/reports/digital-2023-global-overview-report\t[10.03.2023].\nKettemann,\tM.\tC.\t(2022):\tUNESCO-Empfehlung\tzur\tEthik\tK\u00fcnstlicher\t\nIntelligenz.\tBedingungen\tzur\tImplementierung\tin\tDeutschland.\thttps://www.\nunesco.de/sites/default/files/2022-03/DUK_Broschuere_KI-Empfehlung_DS_\nweb_final.pdf\t[19.01.2023].\nKiefer,\tJ.;\tMay,\tM.\tS.\t(2022):\tDiagnostic\taccuracy\tand\tanalysis\tof\tan\tartificial\t\nintelligence\talgorithm\tfor\tthe\tdetection\tof\tintracranial\thaemorrhage.\tIn:\t\nInsights\tinto\tImaging,\t13\t(Suppl.\t4:\tECR\t2022\tBook\tof\tAbstracts),\t182\t(DOI:\t\n10.1186/s13244-022-01337-x).\nKnobloch,\tT.\t(2018):\tVor\tdie\tLage\tkommen:\tPredictive\tPolicing\tin\tDeutschland.\t\nChancen\tund\tGefahren\tdatenanalytischer\tPrognosetechnik\tund\tEmpfehlungen\t\nf\u00fcr\tden\tEinsatz\tin\tder\tPolizeiarbeit.\thttps://www.stiftung-nv.de/sites/default/\nfiles/predictive.policing.pdf\t[10.02.2023].\nKollmer,\tN.;\tKlindt,\tT.;\tSchucht,\tC.\t(Hg.)\t(2021):\tArbeitsschutzgesetz.\tKommentar\t\n(4.\u00a0Auflage).\tM\u00fcnchen.\nKorsgaard,\tC.\tM.\t(1996):\tThe\tSources\tof\tNormativity.\tCambridge.\nKosinski,\tM.;\tStillwell,\tD.;\tGraepel,\tT.\t(2013):\tPrivate\ttraits\tand\tattributes\t\nare\tpredictable\tfrom\tdigital\trecords\tof\thuman\tbehavior.\tIn:\tPNAS,\t110\t(15),\t\n5802\u20135805\t(DOI:\t10.1073/pnas.1218772110).\nKrafft,\tT.\tD.;\tGamer,\tM;\tZweig,\tK.\tA.\t(2018):\tWer\tsieht\twas?\tPersonalisierung,\t\nRegionalisierung\tund\tdie\tFrage\tnach\tder\tFilterblase\tin\tGoogles\tSuchmaschine.\t\nKaiserslautern.\thttps://algorithmwatch.org/de/filterblase-geplatzt-kaum-raum-\nfuer-personalisierung-bei-google-suchen-zur-bundestagswahl-2017\t[12.01.2023].\nKruse,\tA.;\tSchmitt,\tE.\t(2011):\tDie\tAusbildung\tund\tVerwirklichung\tkreativer\t\nPotenziale\tim\tAlter\tim\tKontext\tindividueller\tund\tgesellschaftlicher\tEntwicklung.\t\nIn:\tKruse,\tA.\t(Hg.):\tKreativit\u00e4t\tim\tAlter.\tHeidelberg,\t15\u201346.\nKuhlmann,\tS.;\tTrute,\tH.-H.\t(2021):\tPredictive\tPolicing\tals\tFormen\tpolizeilicher\t\nWissensgenerierung.\tIn:\tZeitschrift\tf\u00fcr\tdas\tGesamte\tSicherheitsrecht,\t4\t(3),\t\n103\u2013110.\nKumkar,\tL.\tK.\t(2022):\tPlattform-Recht\trevisited:\tUmgang\tmit\tden\t\nMarktordnungen\tdigitaler\tPlattformen\tde\tlege\tlata\tet\tferenda.\tIn:\tZeitschrift\tf\u00fcr\t\nEurop\u00e4isches\tPrivatrecht,\t30\t(3),\t530\u2013564.392Kumkar,\tL.\tK.;\tRoth-Isigkeit,\tD.\t(2020):\tErkl\u00e4rungspflichten\tbei\tautomatisierten\t\nDatenverarbeitungen\tnach\tder\tDSGVO.\tIn:\tJuristenzeitung,\t75\t(6),\t277\u2013286\t\n(DOI:\t10.1628/jz-2020-0090).\nKutscher,\tN.\tet\tal.\t(Hg.)\t(2020):\tHandbuch\tSoziale\tArbeit\tund\tDigitalisierung.\t\nWeinheim.\nLandesanstalt\tf\u00fcr\tMedien\tNRW\t(2022):\tHate\tSpeech\tforsa-Studie\t2022.\t\nZentrale\tUntersuchungsergebnisse.\thttps://www.medienanstalt-nrw.de/\nfileadmin/user_upload/NeueWebsite_0120/Themen/Hass/LFM_Hatespeech_\nforsa_2022.pdf\t[12.01.2023].\nLandesanstalt\tf\u00fcr\tMedien\tNRW\t(2020):\tforsa-Befragung\tzu:\tHate\tSpeech\t\n2020.\tErgebnisbericht.\thttps://www.medienanstalt-nrw.de/fileadmin/user_\nupload/NeueWebsite_0120/Themen/Hass/forsa_LFMNRW_Hassrede2020_\nErgebnisbericht.pdf\t[12.01.2023].\nLandeskriminalamt\tNRW\t(2018):\tAbschlussbericht\tProjekt\tSKALA.\thttps://\npolizei.nrw/sites/default/files/2018-07/180628_Abschlussbericht_SKALA.PDF\t\n[17.01.2023].\nLaney,\tD.\t(2001):\t3D\tData\tManagement:\tControlling\tData\tVolume,\tVelocity,\tand\t\nVariety.\thttps://studylib.net/doc/8647594\t[20.12.2022].\nLatour,\tB.\t(2007):\tEine\tneue\tSoziologie\tf\u00fcr\teine\tneue\tGesellschaft.\tEinf\u00fchrung\t\nin\tdie\tAkteur-Netzwerk-Theorie.\tFrankfurt\tam\tMain.\nLaue,\tP.\t(2016):\t\u00d6ffnungsklauseln\tin\tder\tDS -GVO\t\u2013\t\u00d6ffnung\twohin?\tIn:\t\nZeitschrift\tf\u00fcr\tDatenschutz,\t6\t(10),\t463\u2013467.\nLaw,\tJ.;\tHassard,\tJ.\t(Hg.)\t(1999):\tActor\tNetwork\tTheory\tand\tAfter.\tOxford.\nLey,\tT.;\tReichmann,\tU.\t(2020):\tDigitale\tDokumentation\tin\tOrganisationen\t\nSozialer\tArbeit.\tIn:\tKutscher,\tN.\tet\tal.\t(Hg.):\tHandbuch\tSoziale\tArbeit\tund\t\nDigitalisierung.\tWeinheim,\t241\u2013254.\nLibet,\tB.\t(2004):\tMind\tTime.\tThe\tTemporal\tFactor\tin\tConsciousness.\tCambridge\t\n(MA).\nLiesching,\tM.\tet\tal.\t(2021):\tDas\tNetzDG\tin\tder\tpraktischen\tAnwendung.\tEine\t\nTeilevaluation\tdes\tNetzwerkdurchsetzungsgesetzes.\tBerlin.\nLighthill,\tJ.\t(1973):\tArtificial\tintelligence:\ta\tgeneral\tsurvey.\tIn:\tArtificial\t\nIntelligence.\tA\tPaper\tSymposium.\tLondon,\t1\u201321.\nvan\tder\tLinden,\tS.\t(2015):\tThe\tconspiracy-effect:\texposure\tto\tconspiracy\t\ntheories\t(about\tglobal\twarming)\tdecreases\tpro-social\tbehavior\tand\tscience\t\nacceptance.\tIn:\tPersonality\tand\tIndividual\tDifferences,\t87,\t171\u2013173\t(DOI:\t\n10.1016/j.paid.2015.07.045).\nLob-H\u00fcdepohl,\tA.\t(2021):\tMessen\twelcher\tWirkung?\tNormativ-\nhandlungstheoretische\tVorbemerkungen\tzur\tWirkungsmessung\t\nsozialprofessioneller\tInterventionen.\tIn:\tEurich,\tJ.;\tLob-H\u00fcdepohl,\tA.\t(Hg.):\tGute\t\nAssistenz\tf\u00fcr\tMenschen\tin\tBehinderungen.\tWirkungskontrolle\tund\tdie\tFrage\t\nnach\tdem\tgelingenden\tLeben.\tStuttgart,\t70\u201386.\nLob-H\u00fcdepohl,\tA.\t(2002):\tVerantwortung\tim\tVerwaltungshandeln.\tIn:\tDeutsche\t\nVerwaltungspraxis,\t53\t(2),\t45\u201352.\nLoh,\tJ.\t(2017):\tStrukturen\tund\tRelata\tder\tVerantwortung.\tIn:\tHeidbrink,\tL.;\t\nLangbehn,\tC.;\tLoh,\tJ.\t(Hg.):\tHandbuch\tVerantwortung.\tWiesbaden,\t35\u201356.\nLubart,\tT.\t(Hg.)\t(2018):\tThe\tCreative\tProcess.\tPerspectives\tfrom\tMultiple\t\nDomains.\tLondon.393L\u00fcdemann,\tC.;\tOhlemacher,\tT.\t(2002):\tSoziologie\tder\tKriminalit\u00e4t.\tTheoretische\t\nund\tempirische\tPerspektiven.\tM\u00fcnchen.\nMainzer,\tK.\t(1995):\tComputer\t\u2013\tNeue\tFl\u00fcgel\tdes\tGeistes?\tDie\tEvolution\t\ncomputergest\u00fctzter\tTechnik,\tWissenschaft,\tKultur\tund\tPhilosophie.\tBerlin.\nMann,\tM.\t(2020):\tTechnological\tpolitics\tof\tautomated\twelfare\tsurveillance:\t\nsocial\t(and\tdata)\tjustice\tthrough\tcritical\tqualitative\tinquiry.\tIn:\tGlobal\t\nPerspectives,\t1\t(1),\tArt.-Nr.\t12991\t(DOI:\t10.1525/gp.2020.12991).\nMartinez-Maldonado,\tR.\tet\tal.\t(2022):\tMoodoo\tthe\ttracker:\tspatial\tclassroom\t\nanalytics\tfor\tcharacterising\tteachers\u2019\tpedagogical\tapproaches.\tIn:\tInternational\t\nJournal\tof\tArtificial\tIntelligence\tin\tEducation,\t32\t(4),\t1025\u20131051\t(DOI:\t10.1007/\ns40593-021-00276-w).\nMartini,\tM.\tet\tal.\t(2020):\tAutomatisch\terlaubt?\tF\u00fcnf\tAnwendungsf\u00e4lle\t\nalgorithmischer\tSysteme\tauf\tdem\tjuristischen\tPr\u00fcfstand.\tG\u00fctersloh.\nMast,\tT.\t(2023):\tAGB-Recht\tals\tRegulierungsrecht.\tIn:\tJuristenzeitung,\t78\t(7),\t\n287\u2013296.\nMattern,\tF.;\tFl\u00f6rkemeier,\tC.\t(2010):\tVom\tInternet\tder\tComputer\tzum\tInternet\t\nder\tDinge.\tIn:\tInformatik\tSpektrum,\t33\t(2),\t107\u2013121\t(DOI:\t10.1007/s00287-010-\n0417-7).\nMatz,\tS.\tC.;\tAppel,\tR.\tE.;\tKosinski,\tM.\t(2020):\tPrivacy\tin\tthe\tage\tof\tpsychological\t\ntargeting.\tIn:\tCurrent\tOpinion\tin\tPsychology,\t31,\t116\u2013121\t(DOI:\t10.1016/j.\ncopsyc.2019.08.010).\nMayor,\tA.\t(2018):\tGods\tand\tRobots.\tMyths,\tMachines,\tand\tAncient\tDreams\tof\t\nTechnology.\tPrinceton\t(NJ).\nMcCarthy,\tJ.\tet\tal.\t(2006):\tA\tproposal\tfor\tthe\tDartmouth\tSummer\tResearch\t\nProject\ton\tArtificial\tIntelligence.\tIn:\tAI\tMagazine,\t27\t(4),\t12\u201314\t(DOI:\t10.1609/\naimag.v27i4.1904).\nMcDowell,\tJ\t(2002b):\tInterne\tund\texterne\tGr\u00fcnde.\tIn:\tders.:\tWert\tund\t\nWirklichkeit.\tAufs\u00e4tze\tzur\tMoralphilosophie.\tFrankfurt\tam\tMain,\t156\u2013178.\nMcDowell,\tJ.\t(2002a):\tZwei\tArten\tvon\tNaturalismus.\tIn:\tders.:\tWert\tund\t\nWirklichkeit.\tAufs\u00e4tze\tzur\tMoralphilosophie.\tFrankfurt\tam\tMain,\t30\u201373.\nMcDowell,\tJ.\t(2001):\tGeist\tund\tWelt.\tFrankfurt\tam\tMain.\nMcKinney,\tS.\tM.\tet\tal.\t(2020):\tInternational\tevaluation\tof\tan\tAI\tsystem\tfor\t\nbreast\tcancer\tscreening.\tIn:\tNature,\t577\t(7788),\t89\u201394\t(DOI:\t10.1038/s41586-019-\n1799-6).\nMehta,\tA.\tet\tal.\t(2021):\tAcceptability\tand\teffectiveness\tof\tartificial\tintelligence\t\ntherapy\tfor\tanxiety\tand\tdepression\t(Youper):\tlongitudinal\tobservational\t\nstudy.\tIn:\tJournal\tof\tMedical\tInternet\tResearch,\t23\t(6),\tArt.-Nr.\te26771\t(DOI:\t\n10.2196/26771).\nMerleau-Ponty,\tM.\t(1966):\tPh\u00e4nomenologie\tder\tWahrnehmung.\tBerlin.\nMetzinger,\tT.\t(Hg.)\t(2009):\tGrundkurs\tPhilosophie\tdes\tGeistes.\tBand\t1:\t\nPh\u00e4nomenales\tBewusstsein.\tPaderborn.\nMeyer-Drawe,\tK.\t(2001):\tLeiblichkeit\tund\tSozialit\u00e4t.\tPh\u00e4nomenologische\t\nBeitr\u00e4ge\tzu\teiner\tp\u00e4dagogischen\tTheorie\tder\tInter-Subjektivit\u00e4t.\tM\u00fcnchen.\nMickes,\tL.\tet\tal.\t(2013):\tMajor\tmemory\tfor\tmicroblogs.\tIn:\tMemory\t&\tCognition,\t\n41\t(4),\t481\u2013489\t(DOI:\t10.3758/s13421-012-0281-6).394Miller,\tT.\t(2019):\tExplanation\tin\tartificial\tintelligence:\tinsights\tfrom\tthe\tsocial\t\nsciences.\tIn:\tArtificial\tIntelligence,\t267,\t1\u201338\t(DOI:\t10.1016/j.artint.2018.07.007).\nMoch,\tM.\t(2018):\tHilfen\tzur\tErziehung.\tIn:\tOtto,\tH.-U.\tet\tal.\t(Hg.):\tHandbuch\t\nSoziale\tArbeit\t(6.\u00a0Auflage).\tM\u00fcnchen,\t632\u2013645.\nMohammad,\tS.\tM.\t(2022):\tEthics\tsheet\tfor\tautomatic\temotion\trecognition\tand\t\nsentiment\tanalysis.\tIn:\tComputational\tLinguistics,\t48\t(2),\t239\u2013278\t(DOI:\t10.1162/\ncoli_a_00433).\nMolenaar,\tI.\t(2021):\tPersonalisation\tof\tlearning:\ttowards\thybrid\thuman-AI\t\nlearning\ttechnologies.\tIn:\tOECD\tDigital\tEducation\tOutlook\t2021.\tPushing\tthe\t\nFrontiers\twith\tArtificial\tIntelligence,\tBlockchain\tand\tRobots.\tParis,\t57\u201377.\nMoor,\tJ.\tH.\t(1985):\tWhat\tis\tcomputer\tethics?\tIn:\tMetaphilosophy,\t16\t(4),\t266\u2013275\t\n(DOI:\t10.1111/j.1467-9973.1985.tb00173.x).\nMuirhead,\tR.;\tRosenblum,\tN.\tL.\t(2019):\tA\tLot\tof\tPeople\tAre\tSaying.\tThe\tNew\t\nConspiracism\tand\tthe\tAssault\ton\tDemocracy.\tPrinceton\t(NJ).\nMurphy,\tG.\tet\tal.\t(2019):\tFalse\tmemories\tfor\tfake\tnews\tduring\tIreland\u2019s\t\nabortion\treferendum.\tIn:\tPsychological\tScience,\t30\t(10),\t1449\u20131459\t(DOI:\t\n10.1177/0956797619864887).\nNagel,\tT.\t(1981):\tWie\tist\tes,\teine\tFledermaus\tzu\tsein?\tIn:\tBieri,\tP.\t(Hg.):\t\nAnalytische\tPhilosophie\tdes\tGeistes.\tK\u00f6nigstein\tim\tTaunus,\t261\u2013275.\nNationale\tAkademie\tder\tWissenschaften\tLeopoldina\t(2021):\tDigitalisierung\tund\t\nDemokratie.\tHalle\t(Saale).\nNeftci,\tE.\tO.;\tAverbeck,\tB.\tB.\t(2019):\tReinforcement\tlearning\tin\tartificial\tand\t\nbiological\tsystems.\tIn:\tNature\tMachine\tIntelligence,\t1\t(3),\t133\u2013143\t(DOI:\t10.1038/\ns42256-019-0025-4).\nNguyen,\tC.\tT.\t(2021):\tHow\tTwitter\tgamifies\tcommunication.\tIn:\tLackey,\tJ.\t(Hg.):\t\nApplied\tEpistemology.\tOxford,\t410\u2013436.\nNida-R\u00fcmelin,\tJ.\t(2022a):\t\u00dcberblick\t\u00fcber\tdie\tVerwendung\tder\tBegriffe\tstarke\t\n&\tschwache\tK\u00fcnstliche\tIntelligenz.\tIn:\tChibanguza,\tK.;\tKu\u00df,\tC.;\tSteege,\tH.\t\n(Hg.):\tK\u00fcnstliche\tIntelligenz.\tRecht\tund\tPraxis\tautomatisierter\tund\tautonomer\t\nSysteme.\tBaden-Baden,\t75\u201390.\nNida-R\u00fcmelin,\tJ.\t(2022b):\tDigitaler\tHumanismus\t\u2013\tphilosophische\tAspekte\t\nK\u00fcnstlicher\tIntelligenz.\tIn:\tChibanguza,\tK.;\tKu\u00df,\tC.;\tSteege,\tH.\t(Hg.):\tK\u00fcnstliche\t\nIntelligenz.\tRecht\tund\tPraxis\tautomatisierter\tund\tautonomer\tSysteme.\tBaden-\nBaden,\t29\u201340.\nNida-R\u00fcmelin,\tJ.\t(2020a):\tEine\tTheorie\tpraktischer\tVernunft.\tBerlin.\nNida-R\u00fcmelin,\tJ.\t(2020b):\tDie\tgef\u00e4hrdete\tRationalit\u00e4t\tder\tDemokratie.\tEin\t\npolitischer\tTraktat.\tHamburg.\nNida-R\u00fcmelin,\tJ.\t(2011):\tVerantwortung.\tStuttgart.\nNida-R\u00fcmelin,\tJ.\t(2005):\t\u00dcber\tmenschliche\tFreiheit.\tStuttgart.\nNida-R\u00fcmelin,\tJ.;\tWeidenfeld,\tN.\t(2018):\tDigitaler\tHumanismus.\tEine\tEthik\tf\u00fcr\t\ndas\tZeitalter\tder\tK\u00fcnstlichen\tIntelligenz.\tM\u00fcnchen.\nNida-R\u00fcmelin,\tJ.;\tSchulenburg,\tJ.;\tRath,\tB.\t(2012):\tRisikoethik.\tBerlin.\nNilsson,\tN.\tJ.\t(2010):\tThe\tQuest\tfor\tArtificial\tIntelligence.\tA\tHistory\tof\tIdeas\tand\t\nAchievements.\tCambridge.395Nkambou,\tR.;\tBourdeau,\tJ.;\tMizoguchi,\tR.\t(2010):\tIntroduction:\twhat\tare\t\nintelligent\ttutoring\tsystems,\tand\twhy\tthis\tbook?\tIn:\tdies.:\tAdvances\tin\t\nIntelligent\tTutoring\tSystems.\tBerlin,\t1\u201312.\nObermeyer,\tZ.\tet\tal.\t(2019):\tDissecting\tracial\tbias\tin\tan\talgorithm\tused\tto\t\nmanage\tthe\thealth\tof\tpopulations.\tIn:\tScience,\t366\t(6464),\t447\u2013453\t(DOI:\t\n10.1126/science.aax2342).\nOECD\t(2021):\tOECD\tDigital\tEducation\tOutlook\t2021.\tPushing\tthe\tFrontiers\twith\t\nArtificial\tIntelligence,\tBlockchain\tand\tRobots.\tParis.\nOECD\t(2019):\tRecommendation\tof\tthe\tCouncil\ton\tArtificial\tIntelligence.\t\nOECD/LEGAL/0449.\thttps://legalinstruments.oecd.org/en/instruments/\nOECD-LEGAL-0449\t[19.01.2023].\nOrtiz,\tJ.\tet\tal.\t(2019):\tGiving\tvoice\tto\tthe\tvoiceless:\tthe\tuse\tof\tdigital\t\ntechnologies\tby\tmarginalized\tgroups.\tIn:\tCommunications\tof\tthe\tAssociation\t\nfor\tInformation\tSystems,\t45,\t20\u201338\t(DOI:\t10.17705/1CAIS.04502).\nOrwat,\tC.\t(2019):\tDiskriminierungsrisiken\tdurch\tVerwendung\tvon\tAlgorithmen.\t\nHerausgegeben\tvon\tder\tAntidiskriminierungsstelle\tdes\tBundes.\tBerlin.\nOrwat,\tC.\tet\tal.\t(2010):\tSoftware\tals\tInstitution\tund\tihre\tGestaltbarkeit.\tIn:\t\nInformatik\tSpektrum,\t33\t(6),\t626\u2013633.\nOswald,\tM.\tet\tal.\t(2018):\tAlgorithmic\trisk\tassessment\tpolicing\tmodels:\t\nlessons\tfrom\tthe\tDurham\tHART\tmodel\tand\t\u2018experimental\u2019\tproportionality.\tIn:\t\nInformation\t&\tCommunications\tTechnology\tLaw,\t27\t(2),\t223\u2013250\t(DOI:10.1080/1\n3600834.2018.1458455).\nPanoptykon\tFoundation\t(2015):\tProfiling\tthe\tUnemployed\tin\tPoland.\tSocial\tand\t\nPolitical\tImplications\tof\tAlgorithmic\tDecision\tMaking.\thttps://panoptykon.org/\nsites/default/files/leadimage-biblioteka/panoptykon_profiling_report_final.pdf\t\n[30.01.2023].\nPariser,\tE.\t(2011):\tThe\tFilter\tBubble.\tWhat\tthe\tInternet\tIs\tHiding\tfrom\tYou.\tNew\t\nYork\t(NY).\nParviainen,\tJ.;\tRantala,\tJ.\t(2022):\tChatbot\tbreakthrough\tin\tthe\t2020s?\tAn\tethical\t\nreflection\ton\tthe\ttrend\tof\tautomated\tconsultations\tin\thealth\tcare.\tIn:\tMedicine,\t\nHealth\tCare\tand\tPhilosophy,\t25\t(1),\t61\u201371\t(DOI:\t10.1007/s11019-021-10049-w).\nPenney,\tJ.\tW.\t(2017):\tInternet\tsurveillance,\tregulation,\tand\tchilling\teffects\t\nonline:\ta\tcomparative\tcase\tstudy.\tIn:\tInternet\tPolicy\tReview,\t6\t(2)\t(DOI:\t\n10.14763/2017.2.692).\nPennycook.,\tG.;\tCannon,\tT.\tD.;\tRand,\tD.\tG\t(2018):\tPrior\texposure\tincreases\t\nperceived\taccuracy\tof\tfake\tnews.\tIn:\tJournal\tof\tExperimental\tPsychology:\t\nGeneral,\t147\t(12),\t1865\u20131880\t(DOI:\t10.1037/xge0000465).\nPetermann,\tF.\t(Hg.)\t(2012):\tWAIS-IV.\tWechsler\tAdult\tIntelligence\tScale\t\u2013\tFourth\t\nEdition.\tManual\t1:\tGrundlagen,\tTestauswertung\tund\tInterpretation.\tFrankfurt\t\nam\tMain.\nPolaschek,\tD.\tL.\tL.\t(2012):\tAn\tappraisal\tof\tthe\trisk-need-responsivity\t(RNR)\t\nmodel\tof\toffender\trehabilitation\tand\tits\tapplication\tin\tcorrectional\ttreatment.\t\nIn:\tLegal\tand\tCriminological\tPsychology,\t17\t(1),\t1\u201317\t(DOI:\t10.1111/j.2044-\n8333.2011.02038.x).\nPolger,\tT.\tW.;\tShapiro,\tL.\tA.\t(2016):\tThe\tMultiple\tRealization\tBook.\tOxford.\nPovalej,\tR.;\tVolkmann,\tD.\t(2021):\tPredictive\tPolicing.\tIn:\tInformatik\tSpektrum,\t44\t\n(1),\t57\u201361\t(DOI:\t10.1007/s00287-021-01332-4).396Pretschner,\tA.\tet\tal.\t(2023):\tDie\tm\u00e4chtigen\tneuen\tAssistenzsysteme.\tWas\taus\t\nder\tK\u00fcnstlichen\tIntelligenz\tChatGPT\tfolgt,\t\u00fcber\tdie\tgerade\talle\tsprechen.\tIn:\t\nFrankfurter\tAllgemeine\tZeitung,\t09.01.2023,\tS.\t18.\nPugh,\tA.\tJ.\t(2018):\tAutomated\thealth\tcare\toffers\tfreedom\tfrom\tshame,\tbut\t\nis\tit\twhat\tpatients\tneed?\thttps://www.newyorker.com/tech/annals-of-\ntechnology/automated-health-care-offers-freedom-from-shame-but-is-it-what-\npatients-need\t[28.02.2023].\nvan\tder\tPut,\tC.\tE.\tet\tal.\t(2016):\tDetection\tof\tunsafety\tin\tfamilies\twith\tparental\t\nand/or\tchild\tdevelopmental\tproblems\tat\tthe\tstart\tof\tfamily\tsupport.\tIn:\tBMC\t\nPsychiatry,\t16,\tArt.-Nr.\t15\t(DOI:\t10.1186/s12888-016-0715-y).\nPutnam,\tH.\t(1992):\tRenewing\tPhilosophy.\tCambridge\t(MA).\nPutnam,\tH.\t(1975):\tPhilosophy\tand\tour\tmental\tlife.\tIn:\tders.:\tPhilosophical\t\nPapers.\tVolume\t2:\tMind,\tLanguage\tand\tReality.\tCambridge,\t291\u2013303.\nPutnam,\tH.\t(1967):\tPsychological\tpredicates.\tIn:\tCapitan,\tW.\tH.;\tMerrill,\tD.\tD.\t\n(Hg.):\tArt,\tMind,\tand\tReligion.\tPittsburgh\t(PA),\t37\u201348.\nPutnam,\tH.\t(1965):\tBrains\tand\tbehaviour.\tIn:\tButler,\tR.\tJ.\t(Hg.):\tAnalytical\t\nPhilosophy.\tSecond\tSeries.\tOxford,\t1\u201319.\nQuante,\tM.\t(2007):\tPerson.\tBerlin.\nRachels,\tJ.\tR.;\tRockinson-Szapkiw,\tA.\tJ.\t(2018):\tThe\teffects\tof\ta\tmobile\t\ngamification\tapp\ton\telementary\tstudents\u2019\tSpanish\tachievement\tand\t\nself-efficacy.\tIn:\tComputer\tAssisted\tLanguage\tLearning,\t31\t(1\u20132),\t72\u201389\t(DOI:\t\n10.1080/09588221.2017.1382536).\nRademacher,\tT.\t(2017):\tPredictive\tPolicing\tim\tdeutschen\tPolizeirecht.\tIn:\tArchiv\t\ndes\t\u00f6ffentlichen\tRechts,\t142\t(3),\t366\u2013416\t(DOI:\t10.1628/000389117X1505400914\n8798).\nRammert,\tW.;\tSchulz-Schaeffer,\tI.\t(2002):\tTechnik\tund\tHandeln.\tWenn\tsoziales\t\nHandeln\tsich\tauf\tmenschliches\tVerhalten\tund\ttechnische\tArtefakte\tverteilt.\tIn:\t\ndies.\t(Hg.):\tK\u00f6nnen\tMaschinen\thandeln?\tSoziologische\tBeitr\u00e4ge\tzum\tVerh\u00e4ltnis\t\nvon\tMensch\tund\tTechnik.\tFrankfurt\tam\tMain,\t11\u201364.\nRapp,\tF.\t(1978):\tAnalytische\tTechnikphilosophie.\tFreiburg\tim\tBreisgau.\nRau,\tJ.\tP.;\tStier,\tS.\t(2019):\tDie\tEchokammer-Hypothese:\tFragmentierung\t\nder\t\u00d6ffentlichkeit\tund\tpolitische\tPolarisierung\tdurch\tdigitale\tMedien?\tIn:\t\nZeitschrift\tf\u00fcr\tvergleichende\tPolitikwissenschaft,\t13\t(3),\t399\u2013417\t(DOI:\t10.1007/\ns12286-019-00429-1).\nRaue,\tB.\t(2018):\tMeinungsfreiheit\tin\tsozialen\tNetzwerken.\tAnspr\u00fcche\t\nvon\tNutzern\tsozialer\tNetzwerke\tgegen\tdie\tL\u00f6schung\tihrer\tBeitr\u00e4ge.\tIn:\t\nJuristenzeitung,\t73\t(20),\t961\u2013970\t(DOI:\t10.1628/jz-2018-0261).\nReinholz,\tD.\tL.;\tStone-Johnstone,\tA.;\tShah,\tN.\t(2020):\tWalking\tthe\twalk:\tusing\t\nclassroom\tanalytics\tto\tsupport\tinstructors\tto\taddress\timplicit\tbias\tin\tteaching.\t\nIn:\tInternational\tJournal\tfor\tAcademic\tDevelopment,\t25\t(3),\t259\u2013272\t(DOI:\t\n10.1080/1360144X.2019.1692211).\nRettenberger,\tM.\t(2018):\tIntuitive,\tklinisch-idiographische\tund\tstatistische\t\nKriminalprognosen\tim\tVergleich\t\u2013\tdie\t\u00dcberlegenheit\twissenschaftlich\t\nstrukturierten\tVorgehens.\tIn:\tForensische\tPsychiatrie,\tPsychologie,\t\nKriminologie,\t12\t(1),\t28\u201336\t(DOI:\t10.1007/s11757-017-0463-y).\nRibeiro,\tM.\tH.\tet\tal.\t(2020):\tAuditing\tradicalization\tpathways\ton\tYouTube.\tIn:\t\nFAT*\t\u201920\tProceedings,\t131\u2013141\t(DOI:\t10.1145/3351095.3372879).397Riehm,\tT.\t(2020):\tNein\tzur\tePerson!\tGegen\tdie\tAnerkennung\teiner\tdigitalen\t\nRechtspers\u00f6nlichkeit.\tIn:\tRecht\tDigital,\t1\t(1),\t42\u201348.\nRip,\tA.\t(2007):\tDie\tVerzahnung\tvon\ttechnologischen\tund\tsozialen\t\nDeterminismen\tund\tdie\tAmbivalenzen\tvon\tHandlungstr\u00e4gerschaft\t\nim\t\u201eConstructive\tTechnology\tAssessment\u201c.\tIn:\tDolata,\tU.;\tWerle,\tR.\t\n(Hg.):\tGesellschaft\tund\tdie\tMacht\tder\tTechnik.\tSozio\u00f6konomischer\tund\t\ninstitutioneller\tWandel\tdurch\tTechnisierung.\tFrankfurt\tam\tMain,\t83\u2013106.\nRip,\tA.;\tMisa,\tT.\tJ.;\tSchot,\tJ.\t(Hg.)\t(1995):\tManaging\tTechnology\tin\tSociety:\tThe\t\nApproach\tof\tConstructive\tTechnology\tAssessment.\tLondon.\nRobb,\tM.\tB.\t(2020):\tTeens\tand\tthe\tNews.\tThe\tInfluencers,\tCelebrities,\tand\t\nPlatforms\tThey\tSay\tMatter\tMost.\thttps://www.commonsensemedia.org/sites/\ndefault/files/research/report/2020_teensandnews-fullreport_final-release-web.\npdf\t[12.01.2023].\nRopohl,\tG.\t(1982):\tZur\tKritik\tdes\ttechnologischen\tDeterminismus.\tIn:\tRapp,\tF.;\t\nDurbin,\tP.\tT.\t(Hg.):\tTechnikphilosophie\tin\tder\tDiskussion.\tBraunschweig,\t3\u201317.\nRoss,\tW.\tD.\t(1930):\tThe\tRight\tand\tthe\tGood.\tOxford.\nRostalski,\tF.\t(2019):\tBrave\tNew\tWorld.\tVom\t(Alp-)Traum\tl\u00fcckenloser\t\nStraftatenahndung\tin\tZeiten\tder\tDigitalisierung.\tIn:\tGoltdammer\u2019s\tArchiv\tf\u00fcr\t\nStrafrecht,\t166\t(8),\t481\u2013488.\nRoxin,\tC.;\tGreco,\tL.\t(2020):\tStrafrecht\t\u2013\tAllgemeiner\tTeil.\tBand\tI:\tGrundlagen\u00a0/\t\nDer\tAufbau\tder\tVerbrechenslehre\t(5.\u00a0Auflage).\tM\u00fcnchen.\nRudschies,\tC.;\tSchneider,\tI.;\tSimon,\tJ.\t(2021):\tValue\tpluralism\tin\tthe\tAI\tethics\t\ndebate\t\u2013\tdifferent\tactors,\tdifferent\tpriorities.\tIn:\tThe\tInternational\tReview\tof\t\nInformation\tEthics,\t29,\t1\u201315\t(DOI:\t10.29173/irie419).\nRyle,\tG.\t(1949):\tThe\tConcept\tof\tMind.\tLondon.\nSachverst\u00e4ndigenrat\tzur\tBegutachtung\tder\tEntwicklung\tim\tGesundheitswesen\t\n(2021):\tDigitalisierung\tf\u00fcr\tGesundheit.\tZiele\tund\tRahmenbedingungen\teines\t\ndynamisch\tlernenden\tGesundheitssystems.\tBern.\nSafdar,\tN.\tM.;\tBanja,\tJ.\tD.;\tMeltzer,\tC.\tC.\t(2020):\tEthical\tconsiderations\tin\t\nartificial\tintelligence.\tIn:\tEuropean\tJournal\tof\tRadiology,\t122,\tArt.-Nr.\t108768\t\n(DOI:\t10.1016/j.ejrad.2019.108768).\nSamek,\tW.\tet\tal.\t(2021):\tExplaining\tdeep\tneural\tnetworks\tand\tbeyond:\ta\treview\t\nof\tmethods\tand\tapplications.\tIn:\tProceedings\tof\tthe\tIEEE,\t109\t(3),\t247\u2013278\t(DOI:\t\n10.1109/JPROC.2021.3060483).\nSamuel,\tA.\tL.\t(1959):\tSome\tstudies\tin\tmachine\tlearning\tusing\tthe\tgame\tof\t\ncheckers.\tIn:\tIBM\tJournal\tof\tResearch\tand\tDevelopment,\t3\t(3),\t210\u2013229\t(DOI:\t\n10.1147/rd.33.0210).\nSarsam,\tS.\tM.\tet\tal.\t(2020):\tSarcasm\tdetection\tusing\tmachine\tlearning\t\nalgorithms\tin\tTwitter:\ta\tsystematic\treview.\tIn:\tInternational\tJournal\tof\tMarket\t\nResearch,\t62\t(5),\t578\u2013598\t(DOI:\t10.1177/1470785320921779).\nSatterthwaite,\tM.\tA.\t(1975):\tStrategy-proofness\tand\tarrow\u2019s\tconditions:\t\nexistence\tand\tcorrespondence\ttheorems\tfor\tvoting\tprocedures\tand\tsocial\t\nwelfare\tfunctions.\tIn:\tJournal\tof\tEconomic\tTheory,\t10\t(2),\t187\u2013217\t(DOI:\t\n10.1016/0022-0531(75)90050-2).\nvon\tSavigny,\tE.\t(1974):\tDie\tPhilosophie\tder\tnormalen\tSprache.\tEine\tkritische\t\nEinf\u00fchrung\tin\tdie\t\u201eordinary\tlanguage\tphilosophy\u201c.\tFrankfurt\tam\tMain.\nScanlon,\tT.\tM\t(2014):\tBeing\tRealistic\tabout\tReasons.\tOxford.398Scanlon,\tT.\tM\t(1998):\tWhat\tWe\tOwe\tto\tEach\tOther.\tCambridge\t(MA).\nSchelb,\tP.\tet\tal.\t(2019):\tClassification\tof\tcancer\tat\tprostate\tMRI:\tdeep\tlearning\t\nversus\tclinical\tPI-RADS\tassessment.\tIn:\tRadiology,\t293\t(3),\t607\u2013617\t(DOI:\t\n10.1148/radiol.2019190938).\nSchlemmer,\tH.-P.;\tHohenfellner,\tM.\t(2021):\tChancen\tvon\tKI\tin\tder\tOnkologie\tam\t\nBeispiel\tder\tindividualisierten\tDiagnostik\tund\tBehandlung\tvon\tProstatakrebs.\t\nIn:\tZeitschrift\tf\u00fcr\tmedizinische\tEthik,\t67\t(3),\t309\u2013326.\nSchlick,\tM.\t(1930):\tFragen\tder\tEthik.\tWien.\nSchmid,\tU.\t(2022):\tVertrauensw\u00fcrdige\tK\u00fcnstliche\tIntelligenz.\tNachvollziehbar,\t\nTransparent,\tKorrigierbar.\tIn:\tBundesministerium\tf\u00fcr\tUmwelt,\tNaturschutz,\t\nnukleare\tSicherheit\tund\tVerbraucherschutz;\tRostalski,\tF.\t(Hg.):\tK\u00fcnstliche\t\nIntelligenz.\tWie\tgelingt\teine\tvertrauensw\u00fcrdige\tVerwendung\tin\tDeutschland\t\nund\tEuropa?\tT\u00fcbingen,\t287\u2013297.\nSchmidt,\tM.\tG.\t(2010):\tW\u00f6rterbuch\tzur\tPolitik\t(3.\u00a0Auflage).\tStuttgart.\nSchmidt-A\u00dfmann,\tE.\t(1998):\tDas\tallgemeine\tVerwaltungsrecht\tals\t\nOrdnungsidee.\tGrundlagen\tund\tAufgaben\tder\tverwaltungsrechtlichen\t\nSystembildung.\tBerlin.\nSchmitz,\tH.\t(1990):\tDer\tunersch\u00f6pfliche\tGegenstand.\tGrundz\u00fcge\tder\t\nPhilosophie.\tBonn.\nSchneider,\tD.\t(2020):\tDecision\tSupport\tSysteme\tin\tder\tSozialen\tArbeit\t\u2013\t\nHerausforderungen\tan\tdie\tRolle\tder\tTA\tin\tInnovationsprozessen.\tIn:\tNierling,\tL.;\t\nTorgersen,\tH.\t(Hg.):\tDie\tneutrale\tNormativit\u00e4t\tder\tTechnikfolgenabsch\u00e4tzung.\t\nKonzeptionelle\tAuseinandersetzung\tund\tpraktischer\tUmgang.\tBaden-Baden,\t\n117\u2013138.\nSchrittwieser,\tJ.\tet\tal.\t(2020):\tMastering\tAtari,\tGo,\tchess\tand\tshogi\tby\tplanning\t\nwith\ta\tlearned\tmodel.\tIn:\tNature,\t588\t(7839),\t604\u2013609\t(DOI:\t10.1038/s41586-\n020-03051-4).\nSchr\u00f6dter,\tM.;\tBastian,\tP.;\tTaylor,\tB.\t(2020):\tRisikodiagnostik\tund\tBig\tData\t\nAnalytics\tin\tder\tSozialen\tArbeit.\tIn:\tKutscher,\tN.\tet\tal.\t(Hg.):\tHandbuch\tSoziale\t\nArbeit\tund\tDigitalisierung.\tWeinheim,\t255\u2013264.\nSchulz,\tW.;\tSchmees,\tJ.\t(2022):\tM\u00f6glichkeiten\tund\tGrenzen\tder\tK\u00fcnstlichen\t\nIntelligenz\tin\tder\tRechtsanwendung.\tIn:\tAugsberg,\tI.;\tSchuppert,\tG.\tF.\t(Hg.):\t\nWissen\tund\tRecht.\tBaden-Baden,\t561\u2013594.\nSchumpeter,\tJ.\tA.\t(2018):\tKapitalismus,\tSozialismus\tund\tDemokratie.\tT\u00fcbingen.\nSchwabe,\tM.\t(2022):\tDie\t\u201edunklen\tSeiten\u201c\tder\tSozialp\u00e4dagogik.\t\u00dcber\tden\t\nUmgang\tmit\tFehlern,\tUnverm\u00f6gen,\tUngewissheit,\tAmbivalenzen,\tIdealen\tund\t\nDestruktivit\u00e4t.\tWeinheim.\nSchwabe,\tM.\t(2008):\tMethoden\tder\tHilfeplanung.\tZielentwicklung,\tModeration\t\nund\tAushandlung.\tFrankfurt\tam\tMain.\nSchwartz,\tJ.\tT.\t(1986):\tThe\tLimits\tof\tArtificial\tIntelligence.\tArticle\tfor\t\n\u2018Encyclopedia\tof\tArtificial\tIntelligence\u2019.\tNew\tYork\t(NY).\nSearle,\tJ.\tR.\t(1980):\tMinds,\tbrains,\tand\tprograms.\tIn:\tBehavioral\tand\tBrain\t\nSciences,\t3\t(3),\t417\u2013424\t(DOI:\t10.1017/S0140525X00005756).\nSechopoulos,\tI.;\tTeuwen,\tJ.;\tMann,\tR.\t(2021):\tArtificial\tintelligence\tfor\tbreast\t\ncancer\tdetection\tin\tmammography\tand\tdigital\tbreast\ttomosynthesis:\t\nstate\tof\tthe\tart.\tIn:\tSeminars\tin\tCancer\tBiology,\t72,\t214\u2013225\t(DOI:\t10.1016/j.\nsemcancer.2020.06.002).399Shaw,\tS.\tW.\t(1990):\tPattern\trecognition.\tIn:\tAI\tMagazine,\t11\t(2),\t80\u201381\t(DOI:\t\n10.1609/aimag.v11i2.838).\nSimitis,\tS.;\tHornung,\tD.;\tSpiecker\tgen.\tD\u00f6hmann,\tI.\t(Hg.)\t(2019):\t\nDatenschutzrecht.\tDSGVO\tmit\tBDSG\t(1.\u00a0Auflage).\tBaden-Baden.\nSingelnstein,\tT.\t(2018):\tPredictive\tPolicing:\tAlgorithmenbasierte\t\nStraftatprognosen\tzur\tvorausschauenden\tKriminalintervention.\tIn:\tNeue\t\nZeitschrift\tf\u00fcr\tStrafrecht,\t38\t(1),\t1\u20139.\nSinger,\tW.\t(2004):\tVerschaltungen\tlegen\tuns\tfest:\tWir\tsollten\taufh\u00f6ren,\tvon\t\nFreiheit\tzu\tsprechen.\tIn:\tGeyer,\tC.\t(Hg.):\tHirnforschung\tund\tWillensfreiheit.\tZur\t\nDeutung\tder\tneuesten\tExperimente.\tFrankfurt\tam\tMain,\t30\u201365.\nSolove,\tD.\tJ.\t(2006):\tA\ttaxonomy\tof\tprivacy.\tIn:\tUniversity\tof\tPennsylvania\tLaw\t\nReview,\t154\t(3),\t477\u2013564\t(DOI:\t10.2307/40041279).\nSommerer,\tL.\tM.\t(2020):\tPersonenbezogenes\tPredictive\tPolicing.\t\nKriminalwissenschaftliche\tUntersuchung\t\u00fcber\tdie\tAutomatisierung\tder\t\nKriminalprognose.\tBaden-Baden.\nSt\u00e4ndige\tWissenschaftliche\tKommission\tder\tKultusministerkonferenz\t(2022):\t\nDigitalisierung\tim\tBildungssystem.:\tHandlungsempfehlungen\tvon\tder\tKita\tbis\t\nzur\tHochschule.\t https://www.kmk.org/fileadmin/Dateien/pdf/KMK/SWK/2022/\nSWK-2022-Gutachten_Digitalisierung.pdf\t[10.03.2023].\nStark,\tB.;\tMagin,\tM;\tJ\u00fcrgens,\tP.\t(2021):\tMa\u00dflos\t\u00fcbersch\u00e4tzt.\tEin\t\u00dcberblick\t\n\u00fcber\ttheoretische\tAnnahmen\tund\tempirische\tBefunde\tzu\tFilterblasen\tund\t\nEchokammern.\tIn:\tEisenegger,\tM.\tet\tal.\t(Hg.):\tDigitaler\tStrukturwandel\tder\t\n\u00d6ffentlichkeit.\tHistorische\tVerortung,\tModelle\tund\tKonsequenzen.\tWiesbaden,\t\n303\u2013321.\nSternberg,\tR.\tJ.\t(Hg.)\t(2020):\tThe\tCambridge\tHandbook\tof\tIntelligence.\t\nCambridge.\nStewart,\tA.\tJ.\tet\tal.\t(2019):\tInformation\tgerrymandering\tand\tundemocratic\t\ndecisions.\tIn:\tNature,\t573\t(7772),\t117\u2013121\t(DOI:\t10.1038/s41586-019-1507-6).\nStrawson,\tP.\tF.\t(1974):\tFreedom\tand\tResentment\tand\tOther\tEssays.\tLondon.\nSuchman,\tL.\tA.\t(2007):\tHuman-Machine\tReconfigurations.\tPlans\tand\tSituated\t\nActions.\tCambridge.\nSuchman,\tL.\tA.\t(1987).\tPlans\tand\tSituated\tActions.\tThe\tProblem\tof\tHuman-\nMachine\tCommunication.\tCambridge.\nTcherkassof,\tA.;\tDupr\u00e9,\tD.\t(2022):\tThe\temotion-facial\texpression\tlink:\tevidence\t\nfrom\thuman\tand\tautomatic\texpression\trecognition.\tIn:\tPsychological\tResearch,\t\n85\t(8),\t2954\u20132969\t(DOI:\t10.1007/s00426-020-01448-4).\nThaler,\tR.\tH.;\tSunstein,\tC.\tR.\t(2011):\tNudge.\tWie\tman\tkluge\tEntscheidungen\t\nanst\u00f6\u00dft.\tBerlin.\nThurstone,\tL.\tL.\t(1938):\tPrimary\tMental\tAbilities.\tChicago\t(IL).\nThurstone,\tL.\tL.;\tThurstone,\tT.\tG.\t(1941):\tFactorial\tStudies\tof\tIntelligence.\t\nChicago\t(IL).\nT\u00f6rnberg,\tP.\t(2022):\tHow\tdigital\tmedia\tdrive\taffective\tpolarization\tthrough\t\npartisan\tsorting.\tIn:\tPNAS,\t119\t(42),\tArt.-Nr.\te2207159119\t(DOI:\t10.1073/\npnas.2207159119).400Trappe,\tT.\t(2013):\tEthik\tder\t\u00f6ffentlichen\tVerwaltung\t\u2013\teine\tSkizze.\tIn:\tB\u00fcsch,\tD.;\t\nKutscha,\tM.\t(Hg.):\tRecht,\tLehre\tund\tEthik\tder\t\u00f6ffentlichen\tVerwaltung.\tBaden-\nBaden,\t145\u2013162.\nTreuthardt,\tD.;\tKr\u00f6ger,\tM.\t(2019):\tDer\tRisikoorientierte\tSanktionenvollzug\t(ROS)\t\n\u2013\tempirische\t\u00dcberpr\u00fcfung\tdes\tFall-Screening-Tools\t(FaST).\tIn:\tSchweizerische\t\nZeitschrift\tf\u00fcr\tKriminologie,\t18\t(1),\t76\u201385.\nTreuthardt,\tD.;\tLoewe-Baur,\tM.;\tKr\u00f6ger,\tM.\t(2018):\tDer\tRisikoorientierte\t\nSanktionenvollzug\t(ROS)\t\u2013\taktuelle\tEntwicklungen.\tIn:\tSchweizerische\t\nZeitschrift\tf\u00fcr\tKriminologie,\t17\t(2),\t24\u201332.\nTruby,\tJ.;\tBrown,\tR.\t(2021):\tHuman\tdigital\tthought\tclones:\tthe\tHoly\tGrail\t\nof\tartificial\tintelligence\tfor\tbig\tdata.\tIn:\tInformation\t&\tCommunications\t\nTechnology\tLaw,\t30\t(2),\t140\u2013168\t(DOI:\t10.1080/13600834.2020.1850174).\nTuring,\tA.\tM.\t(1950):\tComputing\tMachinery\tand\tIntelligence.\tIn:\tMind,\t59\t(236),\t\n433\u2013460\t(DOI:\t10.1093/mind/LIX.236.433).\nUNESCO\t(2021):\tRecommendation\ton\tthe\tEthics\tof\tArtificial\tIntelligence.\t\nSHS/BIO/REC-AIETHICS/2021.\thttps://unesdoc.unesco.org/ark:/48223/\npf0000380455\t[18.01.2023].\nUnited\tStates\tSenate\t(2018):\tS.\tHrg.\t115-232\t-\tOpen\tHearing:\tSocial\tMedia\t\nInfluence\tin\tthe\t2016\tU.S.\tElection.\thttps://www.govinfo.gov/content/pkg/\nCHRG-115shrg27398/pdf/CHRG-115shrg27398.pdf\t[09.03.2023].\nUscinski,\tJ.\tet\tal.\t(2022):\tHave\tbeliefs\tin\tconspiracy\ttheories\tincreased\t\nover\ttime?\tIn:\tPLOS\tOne,\t17\t(7),\tArt.-Nr.\te0270429\t(DOI:\t10.1371/journal.\npone.0270429).\nVan\tDaele,\tT.\tet\tal.\t(2021).\tDropping\tthe\tE:\tthe\tpotential\tfor\tintegrating\te-mental\t\nhealth\tin\tpsychotherapy.\tIn:\tCurrent\tOpinion\tin\tPsychology,\t41,\t46\u201350\t(DOI:\t\n10.1016/j.copsyc.2021.02.007).\nVincent-Lancrin,\tS.\t(2021):\tFrontiers\tof\tsmart\teducation\ttechnology:\t\nopportunities\tand\tchallenges.\tIn:\tOECD\tDigital\tEducation\tOutlook\t2021.\t\nPushing\tthe\tFrontiers\twith\tArtificial\tIntelligence,\tBlockchain\tand\tRobots.\tParis,\t\n19\u201342.\nVogt,\tM.;\tLeser,\tU.;\tAkbik,\tA.\t(2021):\tEarly\tdetection\tof\tsexual\tpredators\tin\t\nchats.\tIn:\tProceedings\tof\tthe\t59th\tAnnual\tMeeting\tof\tthe\tAssociation\tfor\t\nComputational\tLinguistics\tand\tthe\t11th\tInternational\tJoint\tConference\ton\t\nNatural\tLanguage\tProcessing\t(Volume\t1:\tLong\tPapers),\t4985\u20134999\t(DOI:\t\n10.18653/v1/2021.acl-long.386).\nVosoughi,\tS.;\tRoy,\tD.;\tAral,\tS.\t(2018):\tThe\tspread\tof\ttrue\tand\tfalse\tnews\tonline.\t\nIn:\tScience,\t359\t(6380),\t1146\u20131151\t(DOI:\t10.1126/science.aap9559).\nde\tVries,\tH.\tB.;\tLubart,\tT.\tI.\t(2017):\tScientific\t creativity:\t divergent\t and\tconvergent\t\nthinking\tand\tthe\timpact\tof\tculture.\tIn:\tJournal\tof\tCreative\tBehavior,\t53\t(2),\t\n145\u2013155\t(DOI:\t10.1002/jocb.184).\nWaas,\tB.\t(2022):\tKI\tund\tArbeitsrecht.\tIn:\tRecht\tder\tArbeit,\t75\t(3),\t125\u2013130.\nWachs,\tS;\tWolf,\tK.\tD.;\tPan,\tC.-C.\t(2012):\tCybergrooming:\trisk\tfactors,\tcoping\t\nstrategies\tand\tassociations\twith\tcyberbullying.\tIn:\tPsicothema,\t24\t(4),\t628\u2013633.\nWard,\tA.\tF.\tet\tal.\t(2017):\tBrain\tdrain:\tthe\tmere\tpresence\tof\tone\u2019s\town\t\nsmartphone\treduces\tavailable\tcognitive\tcapacity.\tIn:\tJournal\tof\tthe\tAssociation\t\nfor\tConsumer\tResearch,\t2\t(2),\t140\u2013154\t(DOI:\t10.1086/691462).401Warnat-Herresthal,\tS.\tet\tal.\t(2021):\tSwarm\tLearning\tfor\tdecentralized\tand\t\nconfidential\tclinical\tmachine\tlearning.\tIn:\tNature,\t594\t(7862),\t265\u2013270\t(DOI:\t\n10.1038/s41586-021-03583-3).\nWatson,\tJ.\tB.\t(1930):\tDer\tBehaviorismus.\tStuttgart.\nWechsler,\tD.\t(1944):\tThe\tMeasurement\tof\tAdult\tIntelligence.\tBaltimore\t(MD).\nWeiden,\tH.\t(2022):\tMehr\tFreiheit\tund\tSicherheit\tim\tNetz.\tGutachten\tzum\t\nEntwurf\tdes\tDigital\tServices\tAct\tim\tAuftrag\tder\tFriedrich-Naumann-Stiftung\tf\u00fcr\t\ndie\tFreiheit.\thttps://shop.freiheit.org/#!/Publikation/1201\t[08.02.2023].\nWeingart,\tP.\t(Hg.)\t(1989):\tTechnik\tals\tsozialer\tProzess.\tFrankfurt\tam\tMain.\nWeizenbaum,\tJ.\t(1976):\tComputer\tPower\tand\tHuman\tReason.\tFrom\tJudgment\tto\t\nCalculation.\tSan\tFrancisco\t(CA).\nWeyer,\tJ.\tet\tal.\t(1997):\tTechnik,\tdie\tGesellschaft\tschafft.\tSoziale\tNetzwerke\tals\t\nOrt\tder\tTechnikgenese.\tBerlin.\nWielsch,\tD.\t(2018):\tDie\tOrdnungen\tder\tNetzwerke.\tAGB\t\u2013\tCode\t\u2013\tCommunity\t\nStandards.\tIn:\tEifert,\tM.;\tGostomzyk,\tT.\t(Hg.):\tNetzwerkrecht.\tDie\tZukunft\tdes\t\nNetzDG\tund\tseine\tFolgen\tf\u00fcr\tdie\tNetzwerkkommunikation.\tBaden-Baden,\t\n61\u201394.\nWiener,\tN.\t(1950):\tThe\tHuman\tUse\tof\tHuman\tBeings.\tCybernetics\tand\tSociety.\t\nBoston\t(MA).\nWittgenstein,\tL.\t(1953):\tPhilosophical\tInvestigations.\tOxford.\nWojcik,\tS.\tet\tal.\t(2018):\tBots\tin\tthe\tTwittersphere.\thttps://www.pewresearch.\norg/internet/2018/04/09/bots-in-the-twittersphere\t[12.01.2023].\nYeung,\tK.\t(2017):\t\u2018Hypernudge\u2019:\tbig\tdata\tas\ta\tmode\tof\tregulation\tby\t\ndesign.\tIn:\tInformation,\tCommunication\t&\tSociety,\t20\t(1),\t118\u2013136\t(DOI:\t\n10.1080/1369118X.2016.1186713).\nYeung,\tK.\t(2018):\tA\tStudy\tof\tthe\tImplications\tof\tAdvanced\tDigital\tTechnologies\t\n(Including\tAI\tsystems)\tfor\tthe\tConcept\tof\tResponsibility\twithin\ta\tHuman\tRights\t\nFramework.\thttps://ssrn.com/abstract=3286027\t[10.02.2023].\nZeller,\tC.;\tSchmid,\tU.\t(2017):\tAutomatic\tGeneration\tof\tAnalogous\tProblems\t\nto\tHelp\tResolving\tMisconceptions\tin\tan\tIntelligent\tTutor\tSystem\tfor\tWritten\t\nSubtraction.\thttps://fis.uni-bamberg.de/handle/uniba/41882\t[11.01.2023].\nZentrale\tEthikkommission\tbei\tder\tBundes\u00e4rztekammer\t(2021):\t\nEntscheidungsunterst\u00fctzung\t\u00e4rztlicher\tT\u00e4tigkeit\tdurch\tK\u00fcnstliche\tIntelligenz.\t\nhttps://www.aerzteblatt.de/down.asp?id=28458\t[10.02.2023].402ABK\u00dcRZUNGSVERZEICHNIS\nAbs. Absatz\nADM automated/algorithmic\tdecision\tmaking\nAI artificial\tintelligence\nALLEGRO Arbeitslosengeld\tII\tLeistungsverfahren\tGrundsicherung\t\nOnline\nAMAS Arbeitsmarktchancen-Assistenzsystem\nAMS Arbeitsmarktservice\nArt. Artikel\nCADe computer-aided \tdetection\nCADx computer-aided \tdiagnose\nCOMPAS Correctional\tOffender\tManagement\tProfiling\tfor\t\nAlternative\tSanctions\nCOVID-19 coronavirus\tdisease\t2019\nDSGVO Datenschutz-Grundverordnung\nEEG Elektroenzephalogramm\nEU Europ\u00e4ische\tUnion\nf. folgende\t[Seite]\nff. folgende\t[Seiten]\nFlugDaG Fluggastdatengesetz\nGPT generative\tpre-trained\ttransformer\nHSOG Hessischen\tGesetzes\t\u00fcber\tdie\t\u00f6ffentliche\tSicherheit\tund\t\nOrdnung\nIT Informationstechnologie\nITS intelligentes\tTutorsystem\nKI K\u00fcnstliche\tIntelligenz\nmpMRT multiparametrische \tMagnetresonanztomografie\nMStV Medienstaatsvertrag\nNr. Nummer\nPSA prostataspezifisches\tAntigen\nRn. Randnummer\nROS Risikoorientierter \tSanktionenvollzug\nSGB Sozialgesetzbuch\nStGB Strafgesetzbuch\nUSA United\tStates\tof\tAmerica\nvgl. vergleicheMitglieder des Deutschen Ethikrates\nProf. Dr. med. Alena Buyx (Vorsitzende)\nProf. Dr. iur. Dr. h. c. Volker Lipp (Stellvertretender Vorsitzender)\nProf. Dr. phil. Dr. h. c. Julian Nida-R\u00fcmelin (Stellvertretender Vorsitzender)\nProf. Dr. rer. nat. Susanne Schreiber (Stellvertretende Vorsitzende)\nProf. Dr. iur. Steffen Augsberg\nRegionalbisch\u00f6fin Dr. phil. Petra Bahr\nProf. Dr. theol. Franz-Josef Bormann\nProf. Dr. rer. nat. Hans-Ulrich Demuth\nProf. Dr. iur. Helmut Frister\nProf. Dr. theol. Elisabeth Gr\u00e4b-Schmidt\nProf. Dr. rer. nat. Dr. phil. Sigrid Graumann\nProf. Dr. rer. nat. Armin Grunwald\nProf. Dr. med. Wolfram Henn\nProf. Dr. rer. nat. Ursula Klingm\u00fcller\nStephan Kruip\nProf. Dr. theol. Andreas Lob-H\u00fcdepohl\nProf. Dr. iur. Stephan Rixen\nProf. Dr. iur. Dr. phil. Frauke Rostalski\nProf. Dr. theol. Kerstin Schl\u00f6gl-Flierl\nProf. Dr. phil. Mark Schweda\nProf. Dr. phil. Judith Simon\nProf. Dr. phil. Muna Tatari\nExterner Experte\nProf. Dr. phil. habil. Dr. phil. h. c. lic. phil. Carl Friedrich Gethmann \n(Ratsmitglied bis 13. Februar 2021, danach Mitarbeit als externer Experte)", "language": "PDF", "image": "PDF", "pagetype": "PDF", "links": "PDF"}